<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="二进制安全研究"><meta name="keywords" content="binary security，vulnerability，fuzzing, revese,二进制安全，漏洞，逆向，恶意样本检测"><title>Improving Grey-Box Fuzzing by Modeling Program Behavior | yama0xff's blog</title><link rel="stylesheet" type="text/css" href="//fonts.neworld.org/css?family=Source+Code+Pro"><link rel="stylesheet" type="text/css" href="/css/style.css?v=2.0.1"><link rel="stylesheet" type="text/css" href="/css/highlight.css?v=2.0.1"><link rel="Shortcut Icon" href="/favicon.ico"><link rel="bookmark" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Improving Grey-Box Fuzzing by Modeling Program Behavior</h1><a id="logo" href="/.">yama0xff's blog</a><p class="description">CYBERSECURITY  BETWEEN 0 AND 1</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div><div id="search-form"><div id="result-mask" class="hide"></div><label><input id="search-key" type="text" autocomplete="off" placeholder="Arama"></label><div id="result-wrap" class="hide"><div id="search-result"></div></div><div class="hide"><template id="search-tpl"><div class="item"><a href="/{path}" title="{title}"><div class="title">{title}</div><div class="time">{date}</div><div class="tags">{tags}</div></a></div></template></div></div></div><div id="layout" class="layout-g"><div class="layout-l"><div class="content_container"><div class="post"><h1 class="post-title">Improving Grey-Box Fuzzing by Modeling Program Behavior</h1><div class="post-meta"><a href="/2019/04/27/Improving-Grey-Box-Fuzzing-by-Modeling-Program-Behavior/#comments" class="comment-count"></a><p><span class="date">Apr 27, 2019</span><span><a href="/categories/论文/" class="category">论文</a><a href="/categories/论文/fuzzing/" class="category">fuzzing</a><a href="/categories/论文/fuzzing/测试样本筛选/" class="category">测试样本筛选</a></span><span><i id="busuanzi_container_page_pv"><i id="busuanzi_value_page_pv"></i><i>点击</i></i></span></p></div><div class="post-content"><h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>诸如American Fuzzy Lop（AFL）之类的灰盒模糊器是用于查找程序中的错误和潜在漏洞的流行工具。虽然这些模糊器已经能够在许多广泛使用的程序中找到漏洞，但它们效率不高; AFL在典型的模糊测试中执行的数百万输入中，只有极少数发现看不见的行为或触发崩溃。剩下的输入是多余的，表现出已经观察到的行为。在这里，我们提出了一种方法，通过应用机器学习直接模拟程序的行为来提高像AFL这样的模糊器的效率。我们学习了一种前向预测模型，该模型将程序输入映射到执行轨迹，对标准模糊测试期间收集的数千个输入进行训练。该学习模型通过关注模糊输入来指导探索，模糊输入对我们的模型最不确定（通过预测的执行轨迹分布的熵进行测量）。通过专注于执行输入我们学习的模型不确定，并忽略我们的模型所确定的行为的任何输入，我们表明我们可以显着限制浪费的执行。通过测试我们对作为DARPA网络大挑战的一部分发布的一组二进制文件的方法，我们表明我们的方法能够找到一组输入，导致更多的代码覆盖和发现崩溃，而基线模糊测试的执行次数明显减少。</p>
<p>KEYWORDS：program modeling; binary fuzzing; coverage-based fuzzing </p>
<table>
<thead>
<tr>
<th>relevant information</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td><em>作者</em></td>
<td>Siddharth Karamcheti;Gideon Mann;David Rosenberg</td>
</tr>
<tr>
<td><em>单位</em></td>
<td>Bloomberg CTO Data Science<br>New York, NY, USA</td>
</tr>
<tr>
<td><em>出处</em></td>
<td>期刊Acm Sigplan Notices</td>
</tr>
<tr>
<td><em>原文地址</em></td>
<td><a href="https://arxiv.org/pdf/1811.08973.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1811.08973.pdf</a></td>
</tr>
<tr>
<td><em>源码地址</em></td>
<td></td>
</tr>
<tr>
<td><em>发表时间</em></td>
<td>2018年</td>
</tr>
</tbody>
</table>
<h1 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h1><p>fuzz-testing或fuzzing的目标是发现一组测试输入，以最大化给定程序中的代码覆盖率，希望这样做可以解决错误，崩溃或其他潜在漏洞。虽然有许多模糊测试工具，但像American Fuzzy Lop （AFL）这样的灰盒突变模糊器是最成功的。这些模糊器的工作原理是维护一系列有趣的程序输入或“父母”，它们覆盖程序的不同部分，并使用一组随机变异函数（例如，flip bits，delete bits，insert random bits 等）迭代地对它们进行变换来生成新的“子”输入。然后将这些子项提供给程序的一个版本，该程序已被轻量级插桩以跟踪给定输入的执行。如果输入执行之前未观察到的程序路径，则会将其添加到队列中。否则，它被丢弃。不幸的是，丢弃输入需要付出代价;每次执行都需要时间，从几纳秒到一秒以上，具体取决于程序。在典型的模糊测试运行中，生成了数十亿输入的数量级，只有少数实际上覆盖了看不见的代码路径，导致数百分钟的不必要的执行时间。在这项工作中，我们提出了一种方法，通过使用机器学习模拟程序行为来减少这些冗余执行。</p>
<p>具体来说，我们认为要成功fuzzing，重要的是能够将程序输入与生成的执行路径相关联。通过使用机器学习来预测来自给定输入的执行路径，我们引入了一种与灰盒模糊测试互补的方法，允许我们在执行之前过滤无用的输入。我们的过滤方法背后的直觉很简单：我们专注于执行生成的输入，我们的学习推理模型表达了低的置信度（如果我们无法推断输入会做什么，那么它很可能会做一些不同于我们之前见过的所做的事情的）。通过专注于建模程序行为，我们表明，我们可以通过较少的程序执行来显着提高程序覆盖率。</p>
<p>我们在AFL之上构建我们的方法，AFL是卓越的灰盒模糊器之一。我们通过对DARPA网络大挑战二进制文件的一系列实验表明，我们的方法显着提高了模糊效率，获得了比许多强基线更高的代码覆盖率，包括最佳性能的AFL版本。</p>
<h1 id="2-相关工作"><a href="#2-相关工作" class="headerlink" title="2 相关工作"></a>2 相关工作</h1><p>虽然在程序中有很多种方法可以发现bugs，但我们关注的是两种关键类型：白盒方法[7]，包括符号执行[1,4,6,9,14-16,19]，和灰盒子方法[3,12,13,17,18,22]。这些名称来自所需基础程序的透明度;白盒方法需要很大的透明度（通常可以访问程序源代码，或者将二进制文件提升到中间表示的能力），而灰盒方法需要的很少（通常只需要对程序运行时进行检测，来收集小块信息，例如每当代码进入新的基本块时）。还存在黑盒方法[8,10,11,20]，它们可以非常快速地随机生成输入，并执行程序来发现崩溃。虽然它们可以用于解决浅层漏洞，但它们往往无法深入到程序中。</p>
<p>白盒方法的核心是能够充分利用被测程序的透明度，以明确推断控制流程的性质。像KLEE [4]和SAGE [9]这样的符号执行工具将程序提升到中间表示，其中暴露了整个控制流图。然后，这些方法将输入视为变量，将分支条件视为对这些变量的约束。要输出将传递某个分支的输入（例如，输入if / else语句的if条件），使用SAT或约束求解器。通过明确地求解满足约束的输入，理论上可以找到将到达程序中的任何语句的输入。话虽这么说，这种方法的缺点在于它们的速度和对资源的需求。平均程序可能具有数百到数千个非平凡的分支条件，因此，可能需要延长的时间段来求解相应的方程。这是由几个因素决定的，包括输入的大小，代码中对外部库的依赖，以及人们可以轻松地检测给定程序。</p>
<p>在另一方面，灰盒子方法假设程序的透明度最小。对于许多灰盒方法而言，不是推理整个控制流图，而是在运行时指示程序，仅用于跟踪输入何时触及新的（以前看不见的）基本块，或者基本块之间的新边缘。像American Fuzzy Lop [22]这样的方法，它的许多变体[2,3,12,18]跟踪这些信息来指导一个简单的遗传算法，该遗传算法生成一系列输入并通过程序执行它们。</p>
<p>关键在于速度;产生新的输入以进行测试几乎是瞬时的，唯一真正的限制因素是通过程序执行的速度。在许多情况下，这种执行速度是不可忽视的 - 而且，由于许多生成的输入要么是冗余的，要么是非常不正确的，AFL和相关的方法都是浪的，在输入上花费数千个周期而不会增加新的有意义的信息。我们的工作目标是引入一种新的方法，获得与AFL类似的速度和效率，同时使用机器学习技术获得一些像白盒方法的精确和推理能力。通过这种方法，我们可以限制浪费的周期，同时保留有效和大规模发现错误的能力。</p>
<h1 id="3-方法"><a href="#3-方法" class="headerlink" title="3 方法"></a>3 方法</h1><p>建模程序行为是提高模糊效率的关键。虽然有很多方法可以解决这个建模问题，但在这项工作中，我们专注于学习前向预测模型：给定输入，预测通过程序的相应执行路径。如果我们有一个完美的执行模型，我们可以简单地跳过导致我们已经看到的执行路径的输入，从而节省了大量的时间。如下所示，我们的方法基于模型在它为给定输入预测的执行路径中自信度越低，输入越有可能导致我们以前从未见过的执行路径的启发式方法。</p>
<p>这种方法还有一个额外的好处。当我们执行每个输入时，我们预测模型获得的额外训练数据。基于不确定性选择新输入是众所周知的主动学习技术，因此该输入选择方法还用于加速预测模型的改进，从而加强系统找到好的候选者的能力。</p>
<p>在高层次上，我们的方法是重复执行以下步骤：</p>
<p>1）使用AFL生成一些可能的子输入，2）通过我们的模型输入这些输入以预测执行路径上的分布，3）对这些生成的输入进行置信度排序预测，4）执行那些排名中置信度最小的生成输入，以及5）使用执行的输入来重新训练我们的路径预测模型。此过程在图1中以图形方式描述，并在算法1中进行逻辑描述。在本节的其余部分中，我们提供有关上述内循环中每个步骤的其他详细信息：生成候选输入，学习路径预测模型和使用这个模型来排名和执行候选人。</p>
<p><img src="/2019/04/27/Improving-Grey-Box-Fuzzing-by-Modeling-Program-Behavior/1.jpg" alt=""></p>
<p><img src="/2019/04/27/Improving-Grey-Box-Fuzzing-by-Modeling-Program-Behavior/2.jpg" alt=""></p>
<h2 id="3-1-生成候选输入"><a href="#3-1-生成候选输入" class="headerlink" title="3.1 生成候选输入"></a>3.1 生成候选输入</h2><p>要选择一组有希望通过该程序执行的输入，我们首先需要候选者。我们通过应用AFL的变异逻辑来获得这组候选者。具体来说，给定我们的输入队列，我们首先对父输入进行采样，然后我们应用一组变异运算符来获得我们的新候选者。我们重复这个过程K次以获得一整批有希望的候选人。请注意，此过程非常快，因为我们不会通过程序执行任何生成的输入。</p>
<h2 id="3-2-通过路径预测建模程序"><a href="#3-2-通过路径预测建模程序" class="headerlink" title="3.2 通过路径预测建模程序"></a>3.2 通过路径预测建模程序</h2><p>我们方法的一个关键组成部分是通过程序输入的预测执行路径来理解程序行为。当模糊测试开始时，我们没有用于训练模型的示例，因此我们预测每个示例在单个（空）路径上的均匀分布，这有效地导致在基于置信度排名时对批次进行随机排名（如同将在第3.3节中讨论。但是，在执行第一批输入之后，从算法1的第一次迭代开始，我们有一组初始的标记示例{x，p}，其中x对应于输入的特征化表示（例如，一个袋词表示一个输入字符串），p表示相应的执行路径。请注意，出于我们的目的，执行路径p表示为唯一标签（即每个观察到的执行路径获得其自己的标签），而不是基本块序列或底层控制流图中的边缘。这是因为程序可以有数百个基本块，而我们注意到在实践中，只观察到少数独特的执行路径（遍历的基本块集）。</p>
<p>利用这些示例{x，p}和唯一观察到的执行路径P的总数，我们然后可以训练概率分类器以预测给定输入x的P路径上的分布。在我们的实验中，我们使用多项Logistic回归建立概率分类器（通过一对二减少到P分离二元逻辑回归模型，以获得效率）。我们使用双字节计数对每个输入字符串的字节进行优化输入 - 也就是说，我们计算每个唯一的双字节序列在输入中出现的次数的直方图，并使用该直方图作为我们的表示。我们选择不使用L1或L2惩罚，并训练所有模型进行收敛。</p>
<h2 id="3-3通过熵估计不确定性"><a href="#3-3通过熵估计不确定性" class="headerlink" title="3.3通过熵估计不确定性"></a>3.3通过熵估计不确定性</h2><p>我们的方法的最后一部分是使用我们的模型来决定哪些候选者通过该程序实际执行。为此，我们应用我们的假设，即具有不确定预测的输入更有可能表现出未被观察到的执行路径，而具有相同预测的输入更可能是多余的。</p>
<p>作为不确定性的度量，我们使用预测分布在执行路径上的熵，高熵指的是高不确定性，低熵指的是低不确定性。给定输入x，令Pr（pi | x）为x展示执行路径pi的概率。鉴于此分布，我们将熵计算为：<br>$$<br>H (x) =\sum_{i=1}^P<br>Pr(p_i | x) log(Pr(p_i | x))<br>$$<br>使用此公式，我们然后对给定的迭代对批处理中的每个生成的输入进行评分。然后我们按它们的熵（最高 - 最低）对它们进行排名。最后，我们选择要执行的是最高熵分数α的输入。可以在算法1中找到该过程的完整细分。</p>
<h1 id="4-数据集"><a href="#4-数据集" class="headerlink" title="4 数据集"></a>4 数据集</h1><p>我们对DARPA Cyber Grand Challenge Binaries的一部分进行了初步实验。此数据集包含200个单独的程序，作为2016年挑战的一部分发布，用于创建用于修补，验证和修补错误的工具。构建AFL和基于符号执行的方法的许多新工具都来自于这次竞赛[5,18]，从那时起，这个数据集就被用来对类似工具进行基准测试。每个程序都提供独特的功能，由人类编写（与各种DARPA程序相关）。更重要的是，每个程序都写有一个或多个人为编写的错误，旨在模仿开发人员在编写实际程序时可能犯的错误。此外，该数据集中的程序范围很复杂。</p>
<p>在我们的工作中，我们利用来自该数据集的24个随机选择的程序的子集（由于时间限制，我们无法在完整的200上运行）。我们使用了为x86 Linux编译的DARPA CGC二进制版本（与最初的DARPA-specificc VM相对），通过以下链接发布：https：//github.com/trailofbits/cb-multios</p>
<h1 id="5-实验设置"><a href="#5-实验设置" class="headerlink" title="5 实验设置"></a>5 实验设置</h1><p>我们使用逻辑回归作为我们的预测模型来实现我们的程序建模方法，并通过收集一包双字节（一个每个唯一字节对出现在输入中的次数的直方图）来强化我们的输入字符串。我们将程序建模方法与三个强大的基线进行比较。第一个基线是AFL本身的基线，因为它开箱即用。然而，我们不是使用标准的AFL参数，而是使用“-d”flag或“FidgetyAFL”[12,21]运行AFL，因为它在短的模糊时间周期内比标准AFL表现更好。</p>
<p>我们使用的第二个基线是AFL的批量版本，我们将其称为Batched FidgetyAFL。 Batched FidgetyAFL和FidgetyAFL之间的差异如下：FidgetyAFL在生成并执行每个输入后立即更新其状态（其队列，因此对哪些父输入进行采样以生成下一个子节点）。批量版本将删除此一致状态更新，并将其替换为批量更新，其中多个输入首先一起生成而不进行任何状态更新，然后一次性执行（使用状态更新）。我们选择此基线，因为它可以更好地与我们的程序建模方法进行比较。回想一下，在我们的方法中，我们首先生成一批示例（不执行），然后对批处理中的输入进行排序以选择要执行的分数α。与Batched FidgetyAFL一样，在我们执行所有排名输入之前，我们不会更新AFL队列的状态。</p>
<p>除了FidgetyAFL和Batched FidgetyAFL之外，我们还有第三个基线，Random Batched FidgetyAFL，它探索了生成的输入相对于模糊性能的排名效果。与我们的程序建模方法不同，后者生成大量输入，然后在通过熵对预测进行排名后执行顶部α分数，随机批处理FidgetyAFL随机选取要执行的批处理的分数α。通过这种方式，该基线可以让我们检查我们的熵排序方法是否真正有效。请注意，随机批处理的FidgetyAFL与Batched FidgetyAFL基线明显不同 - 这是因为AFL没有统一对其队列中的输入进行采样 - 相反，它使用启发式调度来对队列输入进行采样，从队列中获取最新的第一个采样元素，然后（在生成许多新输入之后）开始从队列中采样其他元素。通过这种方式，Random Batched FidgetyAFL表现出比Batched FidgetyAFL稍微更随机的行为，因为它反映了各种不同的抽样父母。</p>
<p><img src="/2019/04/27/Improving-Grey-Box-Fuzzing-by-Modeling-Program-Behavior/3.jpg" alt=""></p>
<p>我们在24个DARPA CGC二进制文件上运行我们的实验，每个二进制文件总共执行50,000次。为了快速启动学习，并消除模糊运行中的大部分差异，我们通过让FidgetyAFL运行3分钟来启动所有运行。我们在此窗口期间执行的输入上预先训练我们的逻辑回归模型。然后，我们使用生成的AFL状态和创建的输入队列来作为我们的初始序列，并在顶部启动4种不同的策略（FidgetyAFL，Batched FidgetyAFL，Random和Logistic Regression）。对于所有实验，我们使用AFL版本2.52b。</p>
<p>为了衡量所有策略的相对表现，我们使用我们称之为相对覆盖率的指标。让<code>s</code>对应给定的策略，给<code>t</code>定的执行迭代，<code>T</code>执行迭代的最大数量，以及策略s通过执行迭代t发现的唯一代码路径的数量code_paths~t~(s)。然后将单个程序的相对覆盖率rel-cov定义为：<br>$$<br>rel_cov_t (s) =\frac<br>{code_paths_t(s)}<br>{max_{s^′}[code_paths_T(s′)]}<br>$$<br>或者已经找到的代码路径数量之间的比率，以及最终执行迭代T所有策略的最大代码路径数量。我们报告了所有24个程序的平均值和标准误差。此外，为了更好地了解不同策略在一段时间内的表现如何，我们会在每10,000次执行时报告相对覆盖率统计数据。</p>
<h1 id="6-结果与讨论"><a href="#6-结果与讨论" class="headerlink" title="6 结果与讨论"></a>6 结果与讨论</h1><p>表1报告了每次执行10,000次时四种策略中每种策略的相对覆盖率统计。此外，图2提供了一个图表，报告了发现的代码路径数量 vs 程序Flash文件系统的执行（来自CGC二进制文件的示例程序）。最后，图3包含一个汇总图，汇总了我们测试集中所有24个二进制文件的相对覆盖率，跨二进制文件的间隔为95％。</p>
<p><img src="/2019/04/27/Improving-Grey-Box-Fuzzing-by-Modeling-Program-Behavior/6.jpg" alt=""></p>
<p><img src="/2019/04/27/Improving-Grey-Box-Fuzzing-by-Modeling-Program-Behavior/5.jpg" alt=""></p>
<p><img src="/2019/04/27/Improving-Grey-Box-Fuzzing-by-Modeling-Program-Behavior/4.jpg" alt=""></p>
<p>从这些结果中，有两个关键结论可供选择。首先要意识到，在所有时间步骤中，程序建模方法是明显的赢家，获得比任何基线策略更高的覆盖率。这似乎表明Logistic回归排名的收益明显高于批量更新程序所带来的损失。因此，未来工作的可能途径是通过阈值操作来增强基于熵排序的Logistic回归，以允许模型以在线方式做出是否执行输入的选择。这样做可以消除对批处理的任何需求，并允许该方法产生与传统AFL相同的好处，并持续进行状态更新。</p>
<p>第二个关键观察是，程序建模方法与其他基线方法之间的性能差距随着执行次数的增加而增加。图2和图3中的曲线图最好地展示了这一点。我们看到，在模糊测试开始时，性能差距很小，几乎可以忽略不计，而随着执行的继续，差距越来越大。从中可以得出两个可能的结论：第一个是相当简单的结论，当程序建模方法识别更多代码路径时，AFL的队列被更新，我们开始对更多最近发现的输入进行采样 - 为什么AFL的原因本身就是成功的。但是，另一种可能的解释是程序模型在更多数据可用时的行为方式。随着更多的执行，给了逻辑回归更多标记的例子。因此，它可以更好地识别输入中的模式，并且在推理时分配的协调分数变得更有意义。未来工作的另一个途径是检查学习模型的性质，以及它们如何随着执行的继续而变化。将更强大的学习算法和更多程序特定的特征放入混合中也是值得的，看看是否有办法加强报告的协调分数。</p>
<h1 id="7-结论"><a href="#7-结论" class="headerlink" title="7 结论"></a>7 结论</h1><p>在这项工作中，我们提出了一个系统，用于提高AFL的效率和精度，AFL是首屈一指的灰盒模糊器，利用机器学习技术直接模拟程序行为。具体而言，我们注意到AFL和类似方法的一个主要缺点是浪费在冗余或非信息输入上的程序执行次数。为了解决这个问题，我们提出了一种两阶段方法：1）学习将输入映射到执行路径的前向预测模型，以及2）使用该模型来识别可能有趣的输入。我们使用的直觉是，如果我们能够自信地模拟给定输入在执行时的行为方式，那么就不值得执行。相反，我们应该关注我们的模型表现出低置信度的输入 - 这些输入在执行时可能会触发尚未被观察到的新代码区域。我们的结果表明，我们使用简单的逻辑回归分类法构建的基于排名的方法获得了极强的性能，击败了3个强大的基线，包括AFL本身的标准，开箱即用的实现。此外，我们的结果表明，随着我们继续模糊化，我们的方法变得越来越好，我们的方法和基线之间的性能差距随着时间的推移而不断扩大。这些结果表明，在应用从机器学习和模式识别到模糊测试的技术方面有很大的好处，这是一个非常富有成效的研究途径。</p>
</div><div class="tags"><a href="/tags/2018年/">2018年</a><a href="/tags/fuzzing/">fuzzing</a><a href="/tags/测试样本筛选/">测试样本筛选</a></div><div class="post-share"><div class="bdsharebuttonbox"><span style="float:left;line-height: 28px;height: 28px;font-size:16px;font-weight:blod">分享到：</span><a href="#" data-cmd="more" class="bds_more"></a><a href="#" data-cmd="mshare" title="分享到一键分享" class="bds_mshare"></a><a href="#" data-cmd="fbook" title="分享到Facebook" class="bds_fbook"></a><a href="#" data-cmd="twi" title="分享到Twitter" class="bds_twi"></a><a href="#" data-cmd="linkedin" title="分享到linkedin" class="bds_linkedin"></a><a href="#" data-cmd="youdao" title="分享到有道云笔记" class="bds_youdao"></a><a href="#" data-cmd="evernotecn" title="分享到印象笔记" class="bds_evernotecn"></a><a href="#" data-cmd="weixin" title="分享到微信" class="bds_weixin"></a><a href="#" data-cmd="qzone" title="分享到QQ空间" class="bds_qzone"></a><a href="#" data-cmd="tsina" title="分享到新浪微博" class="bds_tsina"></a></div></div><div class="post-nav"><a href="/2019/04/25/Adaptive-Grey-Box-Fuzz-Testing-with-Thompson-Sampling/" class="next">Adaptive Grey-Box Fuzz-Testing with Thompson Sampling</a></div><div id="comments"></div></div></div></div><div class="layout-r"><div id="sidebar"><div class="search-pla"></div><div id="toc" class="widget"><div class="widget-title"><i class="fa fa-fei">文章目录</i></div><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Abstract"><span class="toc-text">Abstract</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#1-简介"><span class="toc-text">1. 简介</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2-相关工作"><span class="toc-text">2 相关工作</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#3-方法"><span class="toc-text">3 方法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#3-1-生成候选输入"><span class="toc-text">3.1 生成候选输入</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-2-通过路径预测建模程序"><span class="toc-text">3.2 通过路径预测建模程序</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-3通过熵估计不确定性"><span class="toc-text">3.3通过熵估计不确定性</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-数据集"><span class="toc-text">4 数据集</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#5-实验设置"><span class="toc-text">5 实验设置</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#6-结果与讨论"><span class="toc-text">6 结果与讨论</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#7-结论"><span class="toc-text">7 结论</span></a></li></ol></div><div class="widget"><div class="widget-title"><i class="fa fa-xie"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2019/04/27/Improving-Grey-Box-Fuzzing-by-Modeling-Program-Behavior/">Improving Grey-Box Fuzzing by Modeling Program Behavior</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/25/Adaptive-Grey-Box-Fuzz-Testing-with-Thompson-Sampling/">Adaptive Grey-Box Fuzz-Testing with Thompson Sampling</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/23/A-Deep-Learning-based-Approach-to-Automated-Android-App-Testing/">A Deep Learning based Approach to Automated Android App Testing</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/22/Remote-Protocol-Vulnerability-Discovery-for-Intelligent-Transportation-Systems-ITS/">Remote Protocol Vulnerability Discovery for Intelligent Transportation Systems (ITS)</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/19/Automatic-Text-Input-Generation-for-Mobile-Testing/">Automatic Text Input Generation for Mobile Testing</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/18/DeepFuzz-Automatic-Generation-of-Syntax-Valid-C-Programs-for-Fuzz-Testing/">DeepFuzz: Automatic Generation of Syntax Valid C Programs for Fuzz Testing</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/17/Neural-Fuzzing-A-Neural-Approach-to-Generate-Test-Data-for-File-Format-Fuzzing/">Neural Fuzzing: A Neural Approach to Generate Test Data for File Format Fuzzing</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/17/Faster-Fuzzing-Reinitialization-with-Deep-Neural-Models/">Faster Fuzzing: Reinitialization with Deep Neural Models</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/15/Not-all-bytes-are-equal-Neural-byte-sieve-for-fuzzing/">Not all bytes are equal: Neural byte sieve for fuzzing</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/15/Recurrent-Neural-Networks-for-Fuzz-Testing-Web-Browsers/">Recurrent Neural Networks for Fuzz Testing Web Browsers</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-gui"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/科研/">科研</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/论文/">论文</a><span class="category-list-count">36</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/论文/IOT/">IOT</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/论文/fuzzing/">fuzzing</a><span class="category-list-count">27</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/论文/fuzzing/协议/">协议</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/论文/fuzzing/可利用性判定/">可利用性判定</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/论文/fuzzing/机器学习/">机器学习</a><span class="category-list-count">11</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/论文/fuzzing/机器学习/调度策略/">调度策略</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/论文/fuzzing/测试样例生成/">测试样例生成</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/论文/fuzzing/测试样本筛选/">测试样本筛选</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/论文/fuzzing/测试输入生成/">测试输入生成</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/论文/fuzzing/测试输入筛选/">测试输入筛选</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/论文/fuzzing/综述/">综述</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/论文/fuzzing/评估/">评估</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/论文/数据挖掘/">数据挖掘</a><span class="category-list-count">2</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/论文/数据挖掘/综述/">综述</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/论文/自动化利用/">自动化利用</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/论文/软件分析/">软件分析</a><span class="category-list-count">5</span></li></ul></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-biao"> 标签</i></div><div class="tagcloud"><a href="/tags/CFI/" style="font-size: 15px;">CFI</a> <a href="/tags/Double-Fetch-Bugs/" style="font-size: 15px;">Double-Fetch Bugs</a> <a href="/tags/2018年/" style="font-size: 15px;">2018年</a> <a href="/tags/exploitation/" style="font-size: 15px;">exploitation</a> <a href="/tags/heap/" style="font-size: 15px;">heap</a> <a href="/tags/符号执行/" style="font-size: 15px;">符号执行</a> <a href="/tags/USENIX-18/" style="font-size: 15px;">USENIX'18</a> <a href="/tags/防护/" style="font-size: 15px;">防护</a> <a href="/tags/ACM-CCS-18/" style="font-size: 15px;">ACM CCS'18</a> <a href="/tags/fuzzing/" style="font-size: 15px;">fuzzing</a> <a href="/tags/综述/" style="font-size: 15px;">综述</a> <a href="/tags/Lacking-Recheck-Bugs/" style="font-size: 15px;">Lacking-Recheck Bugs</a> <a href="/tags/Kernels/" style="font-size: 15px;">Kernels</a> <a href="/tags/机器学习/" style="font-size: 15px;">机器学习</a> <a href="/tags/2017年/" style="font-size: 15px;">2017年</a> <a href="/tags/测试输入生成/" style="font-size: 15px;">测试输入生成</a> <a href="/tags/二进制反汇编/" style="font-size: 15px;">二进制反汇编</a> <a href="/tags/静态重写技术/" style="font-size: 15px;">静态重写技术</a> <a href="/tags/NDSS-18/" style="font-size: 15px;">NDSS'18</a> <a href="/tags/脱壳/" style="font-size: 15px;">脱壳</a> <a href="/tags/静态符号执行、/" style="font-size: 15px;">静态符号执行、</a> <a href="/tags/逆向/" style="font-size: 15px;">逆向</a> <a href="/tags/二进制分析工具/" style="font-size: 15px;">二进制分析工具</a> <a href="/tags/IOT/" style="font-size: 15px;">IOT</a> <a href="/tags/S-P-19/" style="font-size: 15px;">S&P'19</a> <a href="/tags/2019年/" style="font-size: 15px;">2019年</a> <a href="/tags/科研/" style="font-size: 15px;">科研</a> <a href="/tags/内核/" style="font-size: 15px;">内核</a> <a href="/tags/USENIX-17/" style="font-size: 15px;">USENIX'17</a> <a href="/tags/2016年/" style="font-size: 15px;">2016年</a> <a href="/tags/评估/" style="font-size: 15px;">评估</a> <a href="/tags/AsiaCCS-18/" style="font-size: 15px;">AsiaCCS'18</a> <a href="/tags/ACM-CCS’18/" style="font-size: 15px;">ACM CCS’18</a> <a href="/tags/测试样本筛选/" style="font-size: 15px;">测试样本筛选</a> <a href="/tags/适应性函数/" style="font-size: 15px;">适应性函数</a> <a href="/tags/马尔科夫链/" style="font-size: 15px;">马尔科夫链</a> <a href="/tags/PCFG/" style="font-size: 15px;">PCFG</a> <a href="/tags/深度学习/" style="font-size: 15px;">深度学习</a> <a href="/tags/reinforcement-learning/" style="font-size: 15px;">reinforcement learning</a> <a href="/tags/Android/" style="font-size: 15px;">Android</a> <a href="/tags/堆叠RNN/" style="font-size: 15px;">堆叠RNN</a> <a href="/tags/2019/" style="font-size: 15px;">2019</a> <a href="/tags/污点分析/" style="font-size: 15px;">污点分析</a> <a href="/tags/LAVA/" style="font-size: 15px;">LAVA</a> <a href="/tags/梯度下降算法/" style="font-size: 15px;">梯度下降算法</a> <a href="/tags/S-P-18/" style="font-size: 15px;">S&P'18</a> <a href="/tags/LLVM/" style="font-size: 15px;">LLVM</a> <a href="/tags/变异算子/" style="font-size: 15px;">变异算子</a> <a href="/tags/可利用性判定/" style="font-size: 15px;">可利用性判定</a> <a href="/tags/Word2Vec/" style="font-size: 15px;">Word2Vec</a> <a href="/tags/数据挖掘/" style="font-size: 15px;">数据挖掘</a> <a href="/tags/漏洞检测/" style="font-size: 15px;">漏洞检测</a> <a href="/tags/源代码/" style="font-size: 15px;">源代码</a> <a href="/tags/pin/" style="font-size: 15px;">pin</a> <a href="/tags/静态分析/" style="font-size: 15px;">静态分析</a> <a href="/tags/动态分析/" style="font-size: 15px;">动态分析</a> <a href="/tags/CFG/" style="font-size: 15px;">CFG</a> <a href="/tags/NDSS-17/" style="font-size: 15px;">NDSS'17</a> <a href="/tags/神经网络/" style="font-size: 15px;">神经网络</a> <a href="/tags/S-P‘17/" style="font-size: 15px;">S&P‘17</a> <a href="/tags/SSL-TLS/" style="font-size: 15px;">SSL/TLS</a> <a href="/tags/主动学习/" style="font-size: 15px;">主动学习</a> <a href="/tags/Fuzzing/" style="font-size: 15px;">Fuzzing</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-archive"> 归档</i></div><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/04/">四月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">三月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/02/">二月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">一月 2019</a></li></ul></div></div></div></div><a id="totop" href="#top"></a><div id="footer"><div class="footer-info"><p><!--if theme.baidusitemap--><!--  a(href=config.root+"baidusitemap.xml")= __("baidusitemap")--><!--  |  |  --><!--if theme.feed--><!--  a(href=config.root+"atom.xml")= __("rss")--><!--  |  |  --><!--a(href=config.root+"about/")= __("about")--></p><p>本站总访问量：<i id="busuanzi_container_site_pv"><i id="busuanzi_value_site_pv"></i></i>次</p><p><span> Copyright &copy;<a href="/." rel="nofollow">yama0xff.</a></span><!--span  Theme by--><!--  a(rel='nofollow', target='_blank', href='https://github.com/chaooo/hexo-theme-BlueLake')  BlueLake.--><!--if theme.busuanzi == true--><!-- span  Count by--><!--    a(href="http://busuanzi.ibruce.info/")  busuanzi.--></p><p> <span>Powered by <a rel="nofollow" target="_blank" href="https://hexo.io">Hexo</a></span><span> & Hosted by </span><a rel="nofollow" target="_blank" href="https://github.com/wtwofire">Github</a></p></div></div></div><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?33fc02326009882ae433a2c617961e1d";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();
</script><script type="text/javascript" src="/js/search.json.js?v=2.0.1"></script><script type="text/javascript" src="/js/toctotop.js?v=2.0.1" async></script><script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":["mshare","weixin","tsina","qzone","linkedin","fbook","twi","print","renren","sqq","evernotecn","bdysc","tqq","tqf","bdxc","kaixin001","tieba","douban","bdhome","thx","ibaidu","meilishuo","mogujie","diandian","huaban","duitang","hx","fx","youdao","sdo","qingbiji","people","xinhua","mail","isohu","yaolan","wealink","ty","iguba","h163","copy"],"bdPic":"","bdStyle":"1","bdSize":"16"},"share":{},"image":{"viewList":["tsina","qzone","weixin","fbook","twi","linkedin","youdao","evernotecn","mshare"],"viewText":"分享到：","viewSize":"16"},"selectShare":{"bdContainerClass":null,"bdSelectMiniList":["tsina","qzone","weixin","fbook","twi","linkedin","youdao","evernotecn","mshare"]}};with(document)0[(getElementsByTagName('head')[0]||head).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
</script></body></html>