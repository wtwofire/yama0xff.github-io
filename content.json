[{"title":"A Deep Learning based Approach to Automated Android App Testing","date":"2019-04-23T03:20:17.000Z","path":"2019/04/23/A-Deep-Learning-based-Approach-to-Automated-Android-App-Testing/","text":"Abstract自动输入生成器广泛用于移动应用程序的大规模动态分析和测试。这样的输入生成器必须不断地选择与其交互的UI元素以及如何与其交互，以便在有限的时间预算下实现高覆盖率。目前，大多数输入生成器采用伪随机或强力搜索策略，这可能需要很长时间才能找到可以将应用程序驱动到新的重要状态的正确输入组合。在本文中，我们提出了Humanoid，一种基于深度学习的自动Android应用程序测试方法。我们的见解是，如果我们可以从人类生成的交互跟踪中学习，则可以基于当前UI状态和最新状态转换中的视觉信息生成类似人类的测试输入。我们设计并实现了一个深度神经网络模型，以了解最终用户如何与应用程序进行交互（具体来说，与哪些UI元素进行交互以及如何进行交互），并表明我们可以基于以下任何新UI成功生成类似人类的输入学习的模型。然后，我们将该模型应用于Android应用程序的自动化测试，并证明它能够比最先进的测试输入生成器获得更高的覆盖率和更快的速度。 Index Terms—Software testing, automated test input generation, graphical user interface, deep learning, mobile application relevant information 作者 Yuanchun Liy, Ziyue Yangy, Yao Guoz, Xiangqun Chen 单位 Key Laboratory of High Confidence Software Technologies (Ministry of Education) Peking University 出处 arXiv 原文地址 https://arxiv.org/abs/1901.02633 源码地址 发表时间 2019年 1. 简介移动应用程序（简称应用程序）近年来得到了广泛采用，在Google Play和Apple App Store中可以下载超过300万个应用程序，同时已经累积了数十亿次下载[1]，[2]。这些应用程序需要在发布之前进行充分测试，以便希望确保其应用程序正常运行的应用程序开发人员以及希望阻止恶意应用程序发布的应用程序市场。但是，由于快速的发布周期和有限的人力资源，开发人员和审计人员很难在短时间内手动构建测试用例。因此，移动应用程序的自动测试输入生成器已在学术界和工业界广泛研究。 移动应用程序的测试输入通常由与应用程序的图形用户界面（GUI）的交互来表示。具体地，交互可以包括点击，滚动或输入文本到GUI元素，例如按钮，图像或文本块。输入生成器的工作是为受测试的应用程序(AUT)生成一系列交互，可用于检测软件问题，例如错误，漏洞和安全问题。测试输入生成器的有效性通常通过其测试覆盖率来衡量。给定无限时间，可以尝试所有可能的交互序列和组合以实现完美的测试覆盖。但是，在实际情况下，测试时间有限且AUT可能包含数百个GUI状态和每个状态中的数十个可能的交互，测试输入生成器只能选择一小部分交互序列来探索。 自动化测试输入生成器成功的关键是为给定的UI（测试期间的当前UI）选择正确的交互，以便所选择的交互可以达到新的和重要的UI状态，这反过来将导致额外的UI状态。因为机器很难理解GUI布局和GUI元素内的内容，所以也难以确定点击哪个按钮或应该输入什么。因此，大多数现有的测试生成器[3] - [6]忽略了各种类型的UI元素之间的差异，并应用随机策略来选择一个与之交互。甚至其中一些可能维护应用程序的GUI模型，该模型仅用于记住已探索的状态和交互以避免重复探索。虽然随机策略也可以进一步优化，但它具有固有的局限性，使得难以选择最有效的路径来找到可以在短时间内将应用程序驱动到重要状态的交互。 与随机输入生成器相反，人类测试人员可以轻松识别值得与之交互的UI元素，即使对于他们以前从未见过的新应用程序也是如此。原因是人类测试人员本身就是应用程序用户，因此他们已经获得了有关各种移动应用程序的一些经验和知识。因此，人类测试人员知道在哪里点击以及输入什么，以便获得更高的覆盖率，并且花费更少的时间。我们要在本文中研究的关键问题是：我们可以教一个自动测试输入生成器，使其表现得像人类一样吗？ 本文提出了Humanoid，一种自动GUI测试生成器，能够了解人类如何与移动应用程序交互，然后使用学习模型指导测试生成作为人类测试人员。利用从人工交互轨迹中学到的知识，Humanoid可以根据GUI页面的重要性和意义来确定GUI页面上可能的交互的优先级，从而生成可以更快地导致重要状态的测试输入。 我们可以使用图1中所示的GUI页面作为激励示例。可以在该页面上执行20多个操作，但大多数操作无效或与AUT的核心功能无关，例如在当前页面上向左滑动（实际上不可滚动）或单击广告底部。虽然随机输入生成器可能必须尝试所有可能的选择（包括那些无效的选择），但Humanoid能够增加单击菜单按钮的概率，这更有可能将AUT驱动到其他重要的GUI状态。Humanoid的核心是一个深度神经网络模型，它预测UI页面上的真实用户更有可能与哪些UI元素进行交互以及如何与其进行交互。模型的输入是当前UI状态以及最近的UI转换，表示为一堆图像，而输出是可能的下一个动作的预测分布，包括动作类型和屏幕上的相应位置坐标。通过将预测分布与UI页面上的所有可能动作进行比较，Humanoid能够为每个动作分配概率，并选择具有较高概率的动作作为下一个测试输入。 我们实现了Humanoid，并使用从大规模众包源的UI交互数据集Rico中提取的304,976个人类交互来训练交互模型[7]。只需更换输入选择逻辑，即可轻松将模型与其他测试工具集成。 为了评估Humanoid，我们首先检查了Humanoid是否可以通过使用它来为交互跟踪数据集中的每个UI状态的可能操作划分优先级来学习人类交互模式。结果表明，对于交互痕迹中的大多数UI状态，根据人形预测概率，人类执行的动作在所有动作中排名前10％，这明显优于预期为50％左右的随机策略。 为了评估交互模型在app测试中的有效性，我们将Humanoid与六个最先进的测试生成器进行了比较。用于测试的应用程序包括从AndroTest [8]数据集获得的68个开源应用程序，这是一个广泛使用的基准数据集，用于评估Android测试生成器。我们还测试了来自Google Play的200个热门应用，看看Humanoid在更复杂的应用中是否也有效。根据实验，Humanoid能够为开源应用程序实现43.1％的线路覆盖率，并为市场应用程序实现24.1％的活动覆盖率，在相同的时间内，这显着高于使用其他测试生成器实现的最佳结果（38.8％和19.7％）。 本文的主要贡献如下： 1）据我们所知，这是第一部通过挖掘GUI交互跟踪来介绍通过深度学习生成类人测试输入的想法，以改进自动化移动应用程序测试。 2）我们提出并实现Humanoid，一种基于深度学习的方法，通过学习人类交互痕迹来生成类似人类的测试输入。 3）我们使用开源应用程序和流行的市场应用程序来评估Humanoid。结果表明，Humanoid能够比最先进的方法获得更高的测试覆盖率和更快的速度。 II.背景和相关工作A.Android UI对于移动应用，用户界面（UI）是人与机器之间发生交互的地方。应用程序开发人员设计UI以帮助用户了解其应用程序的功能，并且用户可以通过UI与应用程序进行交互。图形用户界面（GUI）是大多数移动应用程序最重要的UI类型，其中应用程序在屏幕上显示内容和可操作的小部件，用户使用点击，滑动和文本输入等操作与小部件交互。 移动应用程序中显示的GUI页面（或屏幕截图）通常使用树状结构布局。例如，在Android应用程序的屏幕截图中，所有UI元素都是使用View和ViewGroup对象构建的，并组织为tree。视图是一个叶节点，它在屏幕上绘制用户可以看到和交互的内容。 ViewGroup是一个父节点，它包含其他节点以定义接口的布局。UI状态可以被识别为当前UI树中的结构和内容的快照，并且UI树中的节点被称为UI元素。 可以将应用程序视为许多GUI状态及其之间转换的组合。每个GUI状态提供不同的功能或呈现不同的内容。应用程序用户通过与UI元素交互在UI状态之间导航。 B.自动GUI测试生成自从移动应用程序普及以来，自动GUI测试生成已经成为一个活跃的研究领域。大多数研究工作都针对Android平台，部分原因是Android应用程序的普及，以及Android设备和操作系统版本的碎片化。 在Android中，测试工具以与人类相同的方式与应用程序交互：将模拟手势发送到应用程序的GUI。由于UI状态中可接受的手势是有限的，因此不同测试生成器之间的主要区别在于它们用于确定这些操作的优先级的策略。主要有三种策略：随机，基于模型和目标。 使用随机策略的典型示例是Monkey [3]，这是Android中自动应用程序测试的官方工具。 Monkey将随机类型的输入事件发送到屏幕上的随机位置，而不考虑其GUI结构。 DynoDroid [4]也使用随机策略，而DynoDroid发送的输入比Monkey更聪明：许多不可接受的事件根据应用程序中的GUI结构和注册事件监听器被过滤掉。 Sapienz [9]利用遗传算法优化随机测试序列。 Polariz [10]提取并重用人类测试者获得的图案，以帮助生成随机测试序列。 其他几个测试工具构建并使用应用程序的GUI模型来生成测试输入。这些模型通常表示为存储应用程序窗口状态之间转换的有限状态机。这种GUI模型可以动态构建[5]，[6]，[11] - [17]或静态[18]。基于GUI模型，测试工具可以生成快速将应用程序导航到未探测状态的事件。基于模型的策略可以以各种方式进行优化。例如，Stoat [14]可以基于现有的探索迭代地改进测试策略，DroidMate [15]可以通过从其他应用程序挖掘来推断UI元素的可接受动作。 目标策略旨在解决某些应用行为只能通过特定测试输入显示的问题。例如，恶意应用程序可能只在收到某个广播时发送短信[19]。这些测试工具[20] - [22]通常使用复杂的技术，如数据流分析和符号执行，来找到可以导致目标状态的交互。但是，它们的有效性很容易受到应用程序代码的复杂性以及将代码映射到UI元素的困难的影响。 现有测试生成器的一个主要缺点是它们忽略了UI元素的可视信息，这是人类用户或测试人员在探索应用程序时的重要参考。在Humanoid中，我们尝试通过了解应用程序的GUI如何影响用户与其交互的方式来指导测试生成。 C.软件GUI分析GUI是包括Android在内的大多数主要平台上不可或缺的软件部分。分析应用程序的GUI是许多研究人员和从业者非常感兴趣的。该领域主要有两个研究领域。一个是从软件工程的角度理解应用程序的行为。另一种是从人机交互的角度来分析用户界面设计。 如前所述，许多自动化测试工具构建并使用GUI模型来指导测试输入生成。与主要使用UI状态之间的转换来抽象应用程序行为的模型不同，还有一些方法侧重于分析每个UI状态中的信息。例如，Huang等人 [23]和鲁宾等人 [24]提出通过比较实际行为与UI来检测Android应用程序中的隐秘行为。 PERUIM [25]提取了应用程序对其UI的权限之间的映射，以帮助用户理解为何请求每个权限，而AUDACIOUS [26]提供了一种基于UI组件控制权限访问的方法。陈等人[27]引入了一种基于机器学习的方法，从UI图像中提取UI骨架，以便于GUI开发。 在人机交互研究中，软件GUI主要用于挖掘UI设计实践[28]，[29]和交互模式[30]。挖掘的知识可以进一步用于指导UI和UX（用户体验）设计。为了促进移动应用程序设计挖掘，Deka等人收集并发布了一个名为Rico [7]的数据集，其中包含大量UI屏幕和人工交互。 我们的工作在于软件工程与人机交互之间的交叉：我们提出了一种深度学习方法，用于从Rico数据集中挖掘人类交互模式，并使用学习模式来指导自动化测试。 III.我们的方法为了在移动应用程序上运用人类知识来增强移动应用程序测试，本文提出了Humanoid，一种新的自动化测试输入生成器，能够根据人类生成的应用程序交互跟踪中自动学习的知识生成类似人类的测试输入。与许多现有测试工具类似，Humanoid使用GUI模型来理解和探索被测试应用程序的行为。但是，与传统的基于模型的方法不同，传统的基于模型的方法随机选择在探索UI状态时要执行的操作，Humanoid会优先考虑更有可能与人类用户交互的UI元素。我们希望这种类似人类的探索能够比随机策略更快地将应用程序推向重要状态。 A.方法概述图2显示了Humanoid的概述。 Humanoid的核心是一个机器学习模型，它学习人类如何与应用程序交互的模式。基于交互模型，整个系统可以分为两个阶段，包括用于生成具有人类生成的交互轨迹的模型的离线阶段和用于指导测试输入生成的在线阶段。 在离线学习阶段，我们使用深度神经网络模型来学习GUI上下文和用户执行的交互之间的关系。 GUI上下文被表示为当前UI状态和最新UI转换中的视觉信息，而交互被表示为动作类型（触摸，滑动等）和动作的位置坐标。在从大规模人类交互轨迹中学习之后，Humanoid能够预测新UI状态的动作类型和动作位置的概率分布。然后可以使用预测的分布来计算每个UI元素与人交互的概率以及如何与其交互。 在在线测试阶段，Humanoid为被测应用程序（AUT）构建一个名为UI转换图（UTG）的GUI模型。 Humanoid使用GUI模型和交互模型来决定要发送的测试输入。 UTG负责指导Humanoid在已探索的UI状态之间导航，而交互模型则指导探索新的UI状态。 B.交互跟踪预处理首先，我们需要一个带有人工交互跟踪的大型数据集（Rico [7]）来训练用户交互模型，这是Humanoid中的关键组件。因为Rico中的人工交互痕迹不是为我们的目的而设计的，所以我们首先需要预处理交互痕迹。 原始人类交互轨迹通常是发送到屏幕的连续运动事件流[7]，其中每个运动事件由何时（时间戳）和光标（用户的手指）进入的位置（x，y坐标）组成，移动，离开屏幕。由于动画和动态加载的内容，状态更改也是连续的。 我们模型可接受的输入是一组用户交互流程。每个交互流程由一系列UI状态&lt;s~1~, s~2~, s~3~……,s~n~&gt;和在相应的UI状态中获取的一系列动作&lt;a~1~, a~2~,a~3~……,a~n~&gt;组成。要将原始交互跟踪转换为我们模型可接受的格式，我们需要分割光标移动并从中识别用户操作。 我们在Humanoid中考虑七种类型的用户操作，包括touch，long_touch，swipe_ up / down / left / right和input_text。每个操作都由操作类型和屏幕上的目标位置表示。为了从原始光标跟踪中提取用户操作，我们首先将光标移动聚合到交互会话中。 交互会话定义为光标进入屏幕和光标离开屏幕之间的时间段。我们将会话开始和会话结束的时间戳表示为time~start~和time~end~，将光标位置表示为loc~start~和loc~end~。然后我们根据启发式规则列表将交互会话映射到用户操作，如表I所示。 一旦我们提取了行动序列&lt;a~1~, a~2~,a~3~……,a~n~&gt;，我们能够将UI状态更改与基于操作时间戳的操作相匹配。我们使用在a~i~ 的时间戳之前捕获的UI状态作为s~i~来形成状态序列&lt;s~1~, s~2~, s~3~……,s~n~&gt;。状态序列和动作序列一起表示用户交互流，其将用作我们的人交互模型的训练数据。 C.模型训练本节详细介绍了我们如何使用机器学习模型从人类交互痕迹中学习人类交互模式。最终用户根据他们想要对应用程序执行的操作以及他们在GUI上看到的内容与应用程序进行交互。由于不同的应用程序通常共享通用的UI设计模式，因此直观的是人类与GUI交互的方式可以在不同的应用程序中进行推广。交互模型的目标是捕获这种可推广的交互模式。 我们引入了一个概念UI上下文来模拟人们在与应用程序交互时引用的内容。 UI上下文 context~i~ 包括当前UI状态s~i~和三个最新UI转换（s~i-1~, a~i-1~）, （s~i-2~, a~i-2~）, （s~i-3~, a~i-3~）。当前UI状态表示用户在执行操作时看到的内容，而最新的UI转换用于在当前交互会话期间对用户的潜在意图进行建模。 图3显示了我们如何在模型中表示UI状态和操作。每个UI状态表示为双通道UI骨架图像，其中第一个通道（红色通道）呈现文本UI元素的边界框区域，第二个通道（绿色通道）呈现非文本UI的边界框区域元素。我们使用UI骨架而不是原始屏幕截图的原因是屏幕截图上的大多数字符不会影响人类与应用程序的交互方式。例如，同一应用程序的UI样式（字体大小，按钮样式，背景颜色等）可能会在不同的操作系统和应用程序版本中发生变化，而用户使用应用程序的方式则保持不变。有些应用甚至提供“夜间模式”等功能，允许用户在内部更改UI样式。这样的UI样式字符可能会给我们的模型带来噪声并影响模型的泛化能力，因此我们将它们从输入表示中排除。 每个动作由其动作类型和目标位置坐标表示。动作类型被编码为三维向量，其中每个维度映射到前面描述的七种动作类型之一。操作目标位置编码为热图。热图中的每个像素是像素在动作目标位置的概率。我们使用热图而不是原始坐标来表示动作位置，因为原始坐标是高度非线性的并且更难以学习[31]。 总之，UI上下文的表示，即我们的交互模型的输入特征，是一堆图像，包括用于当前UI状态的一个2通道图像和用于三个最新UI转换的三个3通道图像（每个转换包括一个用于UI状态的双通道图像和一个用于动作的单通道图像）。所有图像都缩放到180x320像素的大小。为了便于学习，我们还为当前UI状态添加了一个零填充通道。最后，UI上下文表示为4x180x320x3向量。 给定UI上下文向量，交互模型的输出是可能由人在当前状态下执行的“动作”。请注意，预测的“动作”不是当前UI状态中的实际可接受动作。相反，它是预期的类人行为的类型和位置的概率分布。具体而言，该模型的目标是学习两个条件概率分布： 1）p~type~（t | context~i~）其中t ∈ {touch, long_touch;swipe_up,…… }，意思是给定当前UI 上下文的情况，下一个动作a~i~的类型的概率分布t。 2）ploc（x, y | context~i~）其中0 &lt;x &lt;screen_width和0 &lt;y &lt;screen_height，表示在给定当前UI上下文的情况下，下一个动作a~i~的目标位置x,y的概率分布。 图4显示了用于学习上面定义的两个条件概率分布的深度神经网络模型。它接受当前UI上下文 context~i~ 的表示作为输入，并输出a~i~的位置和类型分布。该模型由五个主要部分组成：卷积层，残余LSTM模块，去卷积层，完全连接层和 损失函数。 卷积层。卷积网络结构已经成为一种流行的图像特征提取方法，因为它已被证明在大型真实世界数据集上的计算机视觉任务中非常强大[32]。在我们的模型中，我们使用具有RELU激活的5个卷积层来从UI骨架图像和动作热图提取特征。在每个卷积层之后，有一个stride-2 max-pooling层，它将输入的宽度和高度减少到一半。池化层还有助于模型识别具有相同形状但环境不同的UI元素。 剩余的LSTM模块。 LSTM（长短期记忆）网络在序列建模问题中被广泛采用，例如机器翻译[33]，视频分类[34]等。在我们的模型中，从历史转换中提取特征也是序列建模问题。我们在最后3个卷积层的每一个之后插入残余LSTM模块，以便捕获不同分辨率级别上的UI转换序列特征。在残余LSTM模块中，输入的最后一维和正常LSTM的输出通过剩余路径直接相加。 这种残留结构使神经网络更容易优化[35]，并提示动作的位置应位于UI元素内。为了降低模型复杂度，我们还在每个残余LSTM模块之前添加了1x1卷积层，以减少特征维度。 去卷积层。该组件用于从残余LSTM模块的低分辨率输出生成高分辨率概率分布。有几种方法可以实现这一点，例如双线性插值，反卷积等。我们使用反卷积层，因为它更容易与深度神经网络集成，并且比插值方法更通用。将不同分辨率级别的特征组合在一起，以提高生成热图的质量[36]。接下来使用softmax层来标准化生成的热图，使得热图中的所有像素总和为1，这是动作位置的概率分布。 完全连接的层。使用softmax的单个完全连接层用于生成动作类型的概率分布。 损失函数。该模型将行动位置和行动类型预测为概率分布。因此，它们对地面事实（由人类执行的动作）的交叉熵损失适合于模型优化。我们使用这两个损失的总和和层权重正则化器作为训练过程中的最终损失函数。 在训练期间，交互流中的每个动作ai（&lt;s~1~, s~2~, s~3~ ……, s~n~&gt;，&lt;a~1~, a~2~, a~3~…… a~n~&gt;）将转换为以下概率分布： 和$$p_{loc}（x, y）= f（x - a_i.x, y - a_i.y）$$其中f是方差= 20的高斯分布的密度函数，我们使用高斯分布来逼近实际屏幕的概率分布当多个人多次交互相同的UI元素时，设备识别的坐标。 类似地，在应用模型时，我们使用当前UI状态的表示来提供它，以预测下一个动作的概率分布p~type~（t）和p~loc~（x, y）。由于预测的分布不能直接用于指导测试生成，我们需要进一步将它们转换为可以在当前状态下执行的操作的概率。为此，我们首先遍历UI树以查找当前状态中的所有可能操作，每个操作包含操作类型（表示为action.type）和操作目标元素（表示为action.element）。然后我们根据模型预测的分布计算每个动作的概率：$$p(action) = p_{type}(action.type) ∗ \\sum_{x，y在action.element}p_{loc}(x, y)$$动作概率可能最终用于指导下一步的测试输入生成。 D.引导测试生成在本节中，我们将描述如何应用人类交互模型来生成类似人类的测试输入。 Humanoid生成两种类型的测试输入，包括探索和导航。探索输入用于发现应用程序中看不见的行为，而导航输入将应用程序驱动到包含未探测操作的已知状态。当从探索输入中选择时，测试生成器不知道每个测试输入的结果，并且基于人类交互模型的指导做出决定（传统的测试生成器通常随机选择输入）。当生成导航输入时，测试生成器知道输入的目标状态，因为它已经保存了转换的存储器。 与许多现有的测试生成器类似，Humanoid使用GUI模型来保存转换的内存。我们使用的GUI模型表示为UI转换图（简称UTG），它是有向图，其节点是UI状态，边是导致UI状态转换的动作。 UTG是在运行时构造的：每次测试生成器观察到新的状态si时，它都会添加一个新的边&lt;s~i-1~; a~i-1~; s~i~&gt;到UTG，其中s~i-1~是最后观察到的UI状态，a~i-i~是在s~i-1~中执行的动作。图5显示了UTG的一个例子。使用UTG，测试生成器可以通过遵循状态路径导航到任何已知状态。 为了在探索和导航之间做出决定并生成输入动作，Humanoid采用了一种简单但有效的策略，如算法1所示。在每个步骤中，Humanoid检查当前状态中是否存在未探测的动作。如果存在未探测的动作，Humanoid会选择探索（第8行），如果完全探索当前状态，则选择导航（第10行到第12行）。导航过程很简单。在探索过程中，Humanoid获取交互模型预测动作的概率，并基于概率进行加权选择。由于人类将采取的行动将被赋予更高的概率，因此人类生物体作为测试输入被选择的机会更高。因此，Humanoid生成的输入比随机选择的输入更像人类。 与现有的测试工具相比，Humanoid的主要特征（以及不同基于模型的测试生成器之间的主要区别）是如何选择探索输入（第8行）。 Humanoid基于交互模型对勘探中更有价值的行为进行优先级排序，交互模型已经从人类交互痕迹进行了训练。此功能可以更快地发现正确的输入序列，从而将应用程序驱动到重要的UI状态，从而提高测试覆盖率。 IV.评估我们主要通过以下几个方面评估Humanoid： 1）Humanoid能否学习人类交互模式？具体而言，交互模型能否以高精度预测UI状态下的用户操作？ 2）Humanoid需要多长时间才能使用交互模型？具体而言，训练模型和预测行动概率需要多长时间？ 3）当训练好的交互模型用于指导测试生成时，Humanoid可以实际上实现更高和更快的覆盖吗？ 我们进行了两次实验来回答这些问题。首先，我们使用人类交互痕迹的数据集来训练和测试交互模型。我们研究了该实验中的模型精度和时间效率。其次，我们将在数据集上训练的模型集成到测试生成器中，并使用测试生成器对两组不同的Android应用程序进行测试。我们测量了Humanoid的测试覆盖率和测试进度，并将结果与几种最先进的测试工具进行了比较。 A.实验设置我们用于训练和测试Humanoid模型的数据集是从Rico [7]处理的，Rico [7]是人类交互的大量人群源数据集。我们通过识别动作序列和状态序列从原始数据中提取交互流。最后，我们获得了12,278个属于10,477个应用程序的交互流程。每个交互流平均包含24.8个状态。每个UI状态中可能的动作数量的累积分布函数（CDF）如图6所示。平均而言，每个UI状态有50.7个可能的动作候选者，而超过10％的UI状态包括100多个动作候选者。 我们用来训练和测试交互模型的机器是一个带有两个Intel Xeon E5-2620 CPU，64GB RAM和一个NVidia GeForce GTX 1080 Ti GPU的工作站。该机器的操作系统是Ubuntu 16.04。该模型采用Tensorflow [37]实施。 在测试覆盖率评估实验中，我们使用了4台计算机，其硬件和软件与上述相同。我们在每台机器上运行了4个Android模拟器实例，以并行测试应用程序。我们用于测试的应用程序包括从AndroTest [8]获得的68个开源应用程序，这是一个用于评估Android测试输入生成器的常用数据集，以及从Google Play下载的200个流行商业应用程序。在测试开源应用程序时，我们使用Emma [38]来测量行覆盖率。对于没有源代码的商业应用程序，我们使用活动覆盖率（达到的活动的百分比）来衡量测试性能。 B.交互模型的准确性在这个实验中，我们在现有的人类交互痕迹上训练和测试了我们的交互模型，以了解该模型是否能够了解人类如何与应用程序交互。 我们从数据集中随机选择了100个应用程序，并使用它们的交互跟踪进行测试。其余10,377个应用程序的交互痕迹用于训练。总的来说，我们有302,382个用于训练的UI状态和用于测试的2,594个UI状态。对于测试集中的每个UI状态，我们使用交互模型来预测所有可能操作的概率，并按预测概率的降序对操作进行排序。人类所采取的行动被视为基本事实。 表II示出了在每个UI状态中对人类执行的动作进行优先级排序时Humanoid人交互模型的准确性。具体而言，我们计算了地面实况（人类执行的动作）按照交互模型预测的动作顺序排在前N（N = 1,3,5,10）内的概率。为了比较，我们还计算了随机策略的topN准确度，即如果动作是随机顺序，则地面实况排名前N的概率。根据结果，我们的交互模型可以更准确地识别人类生成的行为并确定其优先级。 特别是，Humanoid能够为超过50％的UI状态分配人类生成动作的最高概率。我们还计算了每个UI状态中人为操作的百分位数。平均百分位数排名为20.6％，中位数为9.5％，这意味着Humanoid能够将类似人类的行为优先于大多数UI状态的前10％。 C.交互模型的开销我们然后评估了交互模型的开销。使用包含304,976个人为操作的数据集训练交互模型大约需要66个小时。这是可以接受的，因为模型在用于测试之前只需要训练一次。用于预测UI状态的动作概率所花费的平均时间是107.9毫秒。鉴于Android测试生成器通常需要2秒以上的时间来发送测试输入并等待加载新页面，我们的交互模型将给测试生成器带来的时间开销很小。 D.引导测试的覆盖率在该实验中，我们使用在先前实验中训练的交互模型来指导测试生成。我们通过检查它是否能真正提高测试覆盖率来评估指导测试发生器。 我们测试了两套应用程序，包括68个开源应用程序和200个流行的市场应用程序。我们将Humanoid与六款最先进的Android测试生成器进行了比较，包括Monkey [3]，PUMA [12]，Stoat [14]，DroidMate [15]，Sapienz [9]和DroidBot [11]。所有工具都使用其默认配置。 PUMA，Stoat，DroidMate和DroidBot的输入速度接近600个事件/小时，因为他们都需要在执行操作之前读取UI状态并在发送输入后等待状态转换，而Monkey和Sapienz可以发送输入事件速度非常快（在我们的实验中大约6000次/小时）。 我们使用每个测试工具运行每个开源应用程序1小时，每个市场应用程序运行3个小时。为了适应最近的市场应用程序，大多数工具都是在Android 6.0上进行评估的，因为它得到了大多数工具的支持（一些工具经过了少量修改）。然而，由于Sapienz是近源的并且仅支持Android 4.4，因此它在Android 4.4上进行了评估。对于每个应用和工具，我们记录了每个操作执行后的最终覆盖率和渐进覆盖率。我们重复这个过程三次，并使用平均值作为最终结果。 1）开源应用程序的行覆盖率：开源应用程序上的测试工具实现的行覆盖率的总体比较如图7所示。平均而言，Humanoid实现了43.1％的行覆盖率，这是最高的跨所有测试输入生成器。 有趣的是，采用随机探索策略的Monkey实现了比除Humanoid之外的所有其他基于模型的测试工具更高的覆盖率。 Monkey比其他大多数测试工具表现更好的事实也得到了其他研究人员的证实[39]。因为Monkey能够在相同的时间内生成比其他工具更多的输入。但是，我们的工作证明了基于模型的方法的可扩展性的好处。如果正确使用GUI信息，基于模型的测试工具具有实现更好测试性能的巨大潜力。 每个应用程序的详细行覆盖范围如表III所示。对于一些应用程序，如＃3，＃36和＃45，Monkey的覆盖范围要高得多。原因是Monkey可以生成许多其他工具不支持的输入（例如意图和广播）。对于大多数其他应用程序，Humanoid取得了最佳效果，特别是对于＃6，＃18，＃30等应用程序。 我们进一步研究了为什么Humanoid能够通过检查详细的测试痕迹来超越其他测试工具。我们仔细检查了五个应用程序，其中Humanoid实现了更高的覆盖率。我们发现了一些Humanoid表现优于其他人的情况，如表IV所示。总而言之，Humanoid的高覆盖率主要是由于两个原因：首先，当有大量UI元素可供选择时，Humanoid能够识别关键UI元素并确定其优先级。其次，Humanoid有更高的机会执行一系列有意义的操作，这可以将应用程序推向未开发的核心功能。 图8显示了渐进式覆盖范围w.r.t。每个测试工具发送的输入事件数。请注意，我们没有将Sapienz包含在渐进式覆盖数据中，因为它发送的事件太快，我们无法将其放慢速度，因为它是近源的。在最初的几个步骤中，所有测试工具的行覆盖率迅速增加，因为应用程序刚刚启动，所有UI状态都是新的。 PUMA在前10个步骤中实现了最高覆盖率，因为它有一个在开始时重新启动应用程序的策略，这导致在许多应用程序中覆盖资源回收代码。Humanoid在大约20个事件后开始领先。那是因为那时已经涵盖了易于访问的代码，其他状态隐藏在其他测试工具难以产生的特定交互之后。 在第600个事件点，除了Monkey之外，大多数测试工具的线路覆盖率几乎已经收敛。这是因为Monkey的随机策略产生了大量无效和重复的输入事件，当我们计算事件数量时，这对于覆盖率改善没有帮助。但是，Monkey能够在相同的时间内生成更多的事件。其覆盖率将在第600步后继续增加，并在测试结束时达到约39％（相同的一小时测试持续时间）。 2）市场应用程序的活动覆盖率：与开源应用程序相比，市场应用程序通常具有不同且更复杂的功能和UI结构。因此，我们进一步对市场应用程序进行了实验，以确定Humanoid是否仍然更有效。 由测试工具和渐进覆盖实现的最终活动覆盖分别如图9和图10所示。与开源应用类似，Humanoid与其他工具相比也实现了最高覆盖率（24.1％）。由于市场应用程序的复杂性，一些应用程序的覆盖范围在测试结束时没有收敛。但是，我们相信Humanoid即使在更长的测试时间内也能保持优势。 （由于与上述相同的原因，请注意这两个数字中Monkey的覆盖范围的差异。） V.限制和未来工作更多输入类型。有些类型的输入，例如系统广播，传感器事件等，本文未考虑这些类型。这是Humanoid的限制，因为这些输入很难从人类交互中收集，并且在我们的交互模型中也难以表示。但是，目前这不是一个大问题，因为大多数应用程序可以在没有这些操作的情况下进行良好测试Humanoid也不会在发送文本输入操作时预测文本，通过扩展模型以支持文本预测或集成其他文本输入生成技术，可以在将来修复文本输入操作[40]。 覆盖范围进一步改善。虽然Humanoid已经能够从现有的测试工具中显着改善覆盖范围，但测试覆盖率仍然相对较低（比完美覆盖更差）。特别是，某些应用的覆盖率低于10％。这是因为许多应用程序需要特定的输入，例如电子邮件和密码，甚至无法自动生成。一种可能的解决方案是设计更好的半自动化测试方法，其中人类测试人员可以用最少的努力为自动工具提供必要的指导。 利用文本信息。在学习人类交互模式时，我们使用UI框架来表示模型中的每个UI状态，而不使用每个UI元素中的文本。文本信息对于人类使用该应用程序非常重要。我们相信，如果可以在交互模型中正确地表示和学习文本信息，则可以进一步提高Humanoid的性能。 学习非人类互动的痕迹。我们的方法在很大程度上依赖于人工交互轨迹，如果我们想要从更大的数据集中学习更多交互模式，这些轨迹可能难以扩展。由于模型实际从人类交互中学到的是每个UI中动作的重要性，因此只要可以分析动作的重要性，就可以直接训练机器生成的轨迹。 VI.结束语本文介绍Humanoid，一种用于Android应用程序的新GUI测试输入生成器，能够通过深度学习生成类似人类的测试输入。 Humanoid采用深度神经网络模型来了解最终用户更可能与哪些UI元素进行交互以及如何与大量用户生成的交互跟踪进行交互。在学习模型的指导下，Humanoid能够准确预测与Android应用程序的真人交互。根据对大量开源应用程序和流行的商业应用程序的实验，Humanoid能够比六种最先进的测试工具实现更高的测试覆盖率和更快的速度","content":"<h1 id=\"Abstract\"><a href=\"#Abstract\" class=\"headerlink\" title=\"Abstract\"></a>Abstract</h1><p>自动输入生成器广泛用于移动应用程序的大规模动态分析和测试。这样的输入生成器必须不断地选择与其交互的UI元素以及如何与其交互，以便在有限的时间预算下实现高覆盖率。目前，大多数输入生成器采用伪随机或强力搜索策略，这可能需要很长时间才能找到可以将应用程序驱动到新的重要状态的正确输入组合。在本文中，我们提出了Humanoid，一种基于深度学习的自动Android应用程序测试方法。我们的见解是，如果我们可以从人类生成的交互跟踪中学习，则可以基于当前UI状态和最新状态转换中的视觉信息生成类似人类的测试输入。我们设计并实现了一个深度神经网络模型，以了解最终用户如何与应用程序进行交互（具体来说，与哪些UI元素进行交互以及如何进行交互），并表明我们可以基于以下任何新UI成功生成类似人类的输入学习的模型。然后，我们将该模型应用于Android应用程序的自动化测试，并证明它能够比最先进的测试输入生成器获得更高的覆盖率和更快的速度。</p>\n<p>Index Terms—Software testing, automated test input generation, graphical user interface, deep learning, mobile application </p>\n<table>\n<thead>\n<tr>\n<th>relevant information</th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><em>作者</em></td>\n<td>Yuanchun Liy, Ziyue Yangy, Yao Guoz, Xiangqun Chen</td>\n</tr>\n<tr>\n<td><em>单位</em></td>\n<td>Key Laboratory of High Confidence Software Technologies (Ministry of Education) Peking University</td>\n</tr>\n<tr>\n<td><em>出处</em></td>\n<td>arXiv</td>\n</tr>\n<tr>\n<td><em>原文地址</em></td>\n<td><a href=\"https://arxiv.org/abs/1901.02633\" target=\"_blank\" rel=\"noopener\">https://arxiv.org/abs/1901.02633</a></td>\n</tr>\n<tr>\n<td><em>源码地址</em></td>\n<td></td>\n</tr>\n<tr>\n<td><em>发表时间</em></td>\n<td>2019年</td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"1-简介\"><a href=\"#1-简介\" class=\"headerlink\" title=\"1. 简介\"></a>1. 简介</h1><p>移动应用程序（简称应用程序）近年来得到了广泛采用，在Google Play和Apple App Store中可以下载超过300万个应用程序，同时已经累积了数十亿次下载[1]，[2]。这些应用程序需要在发布之前进行充分测试，以便希望确保其应用程序正常运行的应用程序开发人员以及希望阻止恶意应用程序发布的应用程序市场。但是，由于快速的发布周期和有限的人力资源，开发人员和审计人员很难在短时间内手动构建测试用例。因此，移动应用程序的自动测试输入生成器已在学术界和工业界广泛研究。</p>\n<p>移动应用程序的测试输入通常由与应用程序的图形用户界面（GUI）的交互来表示。具体地，交互可以包括点击，滚动或输入文本到GUI元素，例如按钮，图像或文本块。输入生成器的工作是为受测试的应用程序(AUT)生成一系列交互，可用于检测软件问题，例如错误，漏洞和安全问题。测试输入生成器的有效性通常通过其测试覆盖率来衡量。给定无限时间，可以尝试所有可能的交互序列和组合以实现完美的测试覆盖。但是，在实际情况下，测试时间有限且AUT可能包含数百个GUI状态和每个状态中的数十个可能的交互，测试输入生成器只能选择一小部分交互序列来探索。</p>\n<p>自动化测试输入生成器成功的关键是为给定的UI（测试期间的当前UI）选择正确的交互，以便所选择的交互可以达到新的和重要的UI状态，这反过来将导致额外的UI状态。因为机器很难理解GUI布局和GUI元素内的内容，所以也难以确定点击哪个按钮或应该输入什么。因此，大多数现有的测试生成器[3]  -  [6]忽略了各种类型的UI元素之间的差异，并应用随机策略来选择一个与之交互。甚至其中一些可能维护应用程序的GUI模型，该模型仅用于记住已探索的状态和交互以避免重复探索。虽然随机策略也可以进一步优化，但它具有固有的局限性，使得难以选择最有效的路径来找到可以在短时间内将应用程序驱动到重要状态的交互。</p>\n<p>与随机输入生成器相反，人类测试人员可以轻松识别值得与之交互的UI元素，即使对于他们以前从未见过的新应用程序也是如此。原因是人类测试人员本身就是应用程序用户，因此他们已经获得了有关各种移动应用程序的一些经验和知识。因此，人类测试人员知道在哪里点击以及输入什么，以便获得更高的覆盖率，并且花费更少的时间。我们要在本文中研究的关键问题是：我们可以教一个自动测试输入生成器，使其表现得像人类一样吗？</p>\n<p><img src=\"/2019/04/23/A-Deep-Learning-based-Approach-to-Automated-Android-App-Testing/1.jpg\" alt=\"\"></p>\n<p>本文提出了Humanoid，一种自动GUI测试生成器，能够了解人类如何与移动应用程序交互，然后使用学习模型指导测试生成作为人类测试人员。利用从人工交互轨迹中学到的知识，Humanoid可以根据GUI页面的重要性和意义来确定GUI页面上可能的交互的优先级，从而生成可以更快地导致重要状态的测试输入。</p>\n<p>我们可以使用图1中所示的GUI页面作为激励示例。可以在该页面上执行20多个操作，但大多数操作无效或与AUT的核心功能无关，例如在当前页面上向左滑动（实际上不可滚动）或单击广告底部。虽然随机输入生成器可能必须尝试所有可能的选择（包括那些无效的选择），但Humanoid能够增加单击菜单按钮的概率，这更有可能将AUT驱动到其他重要的GUI状态。<br>Humanoid的核心是一个深度神经网络模型，它预测UI页面上的真实用户更有可能与哪些UI元素进行交互以及如何与其进行交互。模型的输入是当前UI状态以及最近的UI转换，表示为一堆图像，而输出是可能的下一个动作的预测分布，包括动作类型和屏幕上的相应位置坐标。通过将预测分布与UI页面上的所有可能动作进行比较，Humanoid能够为每个动作分配概率，并选择具有较高概率的动作作为下一个测试输入。</p>\n<p>我们实现了Humanoid，并使用从大规模众包源的UI交互数据集Rico中提取的304,976个人类交互来训练交互模型[7]。只需更换输入选择逻辑，即可轻松将模型与其他测试工具集成。</p>\n<p>为了评估Humanoid，我们首先检查了Humanoid是否可以通过使用它来为交互跟踪数据集中的每个UI状态的可能操作划分优先级来学习人类交互模式。结果表明，对于交互痕迹中的大多数UI状态，根据人形预测概率，人类执行的动作在所有动作中排名前10％，这明显优于预期为50％左右的随机策略。</p>\n<p>为了评估交互模型在app测试中的有效性，我们将Humanoid与六个最先进的测试生成器进行了比较。用于测试的应用程序包括从AndroTest [8]数据集获得的68个开源应用程序，这是一个广泛使用的基准数据集，用于评估Android测试生成器。我们还测试了来自Google Play的200个热门应用，看看Humanoid在更复杂的应用中是否也有效。根据实验，Humanoid能够为开源应用程序实现43.1％的线路覆盖率，并为市场应用程序实现24.1％的活动覆盖率，在相同的时间内，这显着高于使用其他测试生成器实现的最佳结果（38.8％和19.7％）。</p>\n<p>本文的主要贡献如下：</p>\n<ul>\n<li>1）据我们所知，这是第一部通过挖掘GUI交互跟踪来介绍通过深度学习生成类人测试输入的想法，以改进自动化移动应用程序测试。</li>\n<li>2）我们提出并实现Humanoid，一种基于深度学习的方法，通过学习人类交互痕迹来生成类似人类的测试输入。</li>\n<li>3）我们使用开源应用程序和流行的市场应用程序来评估Humanoid。结果表明，Humanoid能够比最先进的方法获得更高的测试覆盖率和更快的速度。</li>\n</ul>\n<h1 id=\"II-背景和相关工作\"><a href=\"#II-背景和相关工作\" class=\"headerlink\" title=\"II.背景和相关工作\"></a>II.背景和相关工作</h1><h2 id=\"A-Android-UI\"><a href=\"#A-Android-UI\" class=\"headerlink\" title=\"A.Android UI\"></a>A.Android UI</h2><p>对于移动应用，用户界面（UI）是人与机器之间发生交互的地方。应用程序开发人员设计UI以帮助用户了解其应用程序的功能，并且用户可以通过UI与应用程序进行交互。图形用户界面（GUI）是大多数移动应用程序最重要的UI类型，其中应用程序在屏幕上显示内容和可操作的小部件，用户使用点击，滑动和文本输入等操作与小部件交互。</p>\n<p>移动应用程序中显示的GUI页面（或屏幕截图）通常使用树状结构布局。例如，在Android应用程序的屏幕截图中，所有UI元素都是使用View和ViewGroup对象构建的，并组织为tree。视图是一个叶节点，它在屏幕上绘制用户可以看到和交互的内容。 ViewGroup是一个父节点，它包含其他节点以定义接口的布局。UI状态可以被识别为当前UI树中的结构和内容的快照，并且UI树中的节点被称为UI元素。</p>\n<p>可以将应用程序视为许多GUI状态及其之间转换的组合。每个GUI状态提供不同的功能或呈现不同的内容。应用程序用户通过与UI元素交互在UI状态之间导航。 </p>\n<h2 id=\"B-自动GUI测试生成\"><a href=\"#B-自动GUI测试生成\" class=\"headerlink\" title=\"B.自动GUI测试生成\"></a>B.自动GUI测试生成</h2><p>自从移动应用程序普及以来，自动GUI测试生成已经成为一个活跃的研究领域。大多数研究工作都针对Android平台，部分原因是Android应用程序的普及，以及Android设备和操作系统版本的碎片化。</p>\n<p>在Android中，测试工具以与人类相同的方式与应用程序交互：将模拟手势发送到应用程序的GUI。由于UI状态中可接受的手势是有限的，因此不同测试生成器之间的主要区别在于它们用于确定这些操作的优先级的策略。主要有三种策略：随机，基于模型和目标。</p>\n<p>使用随机策略的典型示例是Monkey [3]，这是Android中自动应用程序测试的官方工具。 Monkey将随机类型的输入事件发送到屏幕上的随机位置，而不考虑其GUI结构。 DynoDroid [4]也使用随机策略，而DynoDroid发送的输入比Monkey更聪明：许多不可接受的事件根据应用程序中的GUI结构和注册事件监听器被过滤掉。 Sapienz [9]利用遗传算法优化随机测试序列。 Polariz [10]提取并重用人类测试者获得的图案，以帮助生成随机测试序列。</p>\n<p>其他几个测试工具构建并使用应用程序的GUI模型来生成测试输入。这些模型通常表示为存储应用程序窗口状态之间转换的有限状态机。这种GUI模型可以动态构建[5]，[6]，[11]  -  [17]或静态[18]。基于GUI模型，测试工具可以生成快速将应用程序导航到未探测状态的事件。基于模型的策略可以以各种方式进行优化。例如，Stoat [14]可以基于现有的探索迭代地改进测试策略，DroidMate [15]可以通过从其他应用程序挖掘来推断UI元素的可接受动作。</p>\n<p>目标策略旨在解决某些应用行为只能通过特定测试输入显示的问题。例如，恶意应用程序可能只在收到某个广播时发送短信[19]。这些测试工具[20]  -  [22]通常使用复杂的技术，如数据流分析和符号执行，来找到可以导致目标状态的交互。但是，它们的有效性很容易受到应用程序代码的复杂性以及将代码映射到UI元素的困难的影响。</p>\n<p>现有测试生成器的一个主要缺点是它们忽略了UI元素的可视信息，这是人类用户或测试人员在探索应用程序时的重要参考。在Humanoid中，我们尝试通过了解应用程序的GUI如何影响用户与其交互的方式来指导测试生成。</p>\n<h2 id=\"C-软件GUI分析\"><a href=\"#C-软件GUI分析\" class=\"headerlink\" title=\"C.软件GUI分析\"></a>C.软件GUI分析</h2><p>GUI是包括Android在内的大多数主要平台上不可或缺的软件部分。分析应用程序的GUI是许多研究人员和从业者非常感兴趣的。该领域主要有两个研究领域。一个是从软件工程的角度理解应用程序的行为。另一种是从人机交互的角度来分析用户界面设计。</p>\n<p>如前所述，许多自动化测试工具构建并使用GUI模型来指导测试输入生成。与主要使用UI状态之间的转换来抽象应用程序行为的模型不同，还有一些方法侧重于分析每个UI状态中的信息。例如，Huang等人 [23]和鲁宾等人 [24]提出通过比较实际行为与UI来检测Android应用程序中的隐秘行为。 PERUIM [25]提取了应用程序对其UI的权限之间的映射，以帮助用户理解为何请求每个权限，而AUDACIOUS [26]提供了一种基于UI组件控制权限访问的方法。陈等人[27]引入了一种基于机器学习的方法，从UI图像中提取UI骨架，以便于GUI开发。</p>\n<p>在人机交互研究中，软件GUI主要用于挖掘UI设计实践[28]，[29]和交互模式[30]。挖掘的知识可以进一步用于指导UI和UX（用户体验）设计。为了促进移动应用程序设计挖掘，Deka等人收集并发布了一个名为Rico [7]的数据集，其中包含大量UI屏幕和人工交互。</p>\n<p>我们的工作在于软件工程与人机交互之间的交叉：我们提出了一种深度学习方法，用于从Rico数据集中挖掘人类交互模式，并使用学习模式来指导自动化测试。</p>\n<h1 id=\"III-我们的方法\"><a href=\"#III-我们的方法\" class=\"headerlink\" title=\"III.我们的方法\"></a>III.我们的方法</h1><p>为了在移动应用程序上运用人类知识来增强移动应用程序测试，本文提出了Humanoid，一种新的自动化测试输入生成器，能够根据人类生成的应用程序交互跟踪中自动学习的知识生成类似人类的测试输入。与许多现有测试工具类似，Humanoid使用GUI模型来理解和探索被测试应用程序的行为。但是，与传统的基于模型的方法不同，传统的基于模型的方法随机选择在探索UI状态时要执行的操作，Humanoid会优先考虑更有可能与人类用户交互的UI元素。我们希望这种类似人类的探索能够比随机策略更快地将应用程序推向重要状态。</p>\n<h2 id=\"A-方法概述\"><a href=\"#A-方法概述\" class=\"headerlink\" title=\"A.方法概述\"></a>A.方法概述</h2><p>图2显示了Humanoid的概述。 Humanoid的核心是一个机器学习模型，它学习人类如何与应用程序交互的模式。基于交互模型，整个系统可以分为两个阶段，包括用于生成具有人类生成的交互轨迹的模型的离线阶段和用于指导测试输入生成的在线阶段。</p>\n<p><img src=\"/2019/04/23/A-Deep-Learning-based-Approach-to-Automated-Android-App-Testing/2.jpg\" alt=\"\"></p>\n<p>在离线学习阶段，我们使用深度神经网络模型来学习GUI上下文和用户执行的交互之间的关系。 GUI上下文被表示为当前UI状态和最新UI转换中的视觉信息，而交互被表示为动作类型（触摸，滑动等）和动作的位置坐标。在从大规模人类交互轨迹中学习之后，Humanoid能够预测新UI状态的动作类型和动作位置的概率分布。然后可以使用预测的分布来计算每个UI元素与人交互的概率以及如何与其交互。</p>\n<p>在在线测试阶段，Humanoid为被测应用程序（AUT）构建一个名为UI转换图（UTG）的GUI模型。 Humanoid使用GUI模型和交互模型来决定要发送的测试输入。 UTG负责指导Humanoid在已探索的UI状态之间导航，而交互模型则指导探索新的UI状态。</p>\n<h2 id=\"B-交互跟踪预处理\"><a href=\"#B-交互跟踪预处理\" class=\"headerlink\" title=\"B.交互跟踪预处理\"></a>B.交互跟踪预处理</h2><p>首先，我们需要一个带有人工交互跟踪的大型数据集（Rico [7]）来训练用户交互模型，这是Humanoid中的关键组件。因为Rico中的人工交互痕迹不是为我们的目的而设计的，所以我们首先需要预处理交互痕迹。</p>\n<p>原始人类交互轨迹通常是发送到屏幕的连续运动事件流[7]，其中每个运动事件由何时（时间戳）和光标（用户的手指）进入的位置（x，y坐标）组成，移动，离开屏幕。由于动画和动态加载的内容，状态更改也是连续的。</p>\n<p>我们模型可接受的输入是一组用户交互流程。每个交互流程由一系列UI状态&lt;s~1~, s~2~, s~3~……,s~n~&gt;和在相应的UI状态中获取的一系列动作&lt;a~1~, a~2~,a~3~……,a~n~&gt;组成。要将原始交互跟踪转换为我们模型可接受的格式，我们需要分割光标移动并从中识别用户操作。</p>\n<p>我们在Humanoid中考虑七种类型的用户操作，包括touch，long_touch，swipe_ up / down / left / right和input_text。每个操作都由操作类型和屏幕上的目标位置表示。为了从原始光标跟踪中提取用户操作，我们首先将光标移动聚合到交互会话中。</p>\n<p>交互会话定义为光标进入屏幕和光标离开屏幕之间的时间段。我们将会话开始和会话结束的时间戳表示为time~start~和time~end~，将光标位置表示为loc~start~和loc~end~。然后我们根据启发式规则列表将交互会话映射到用户操作，如表I所示。</p>\n<p>一旦我们提取了行动序列&lt;a~1~, a~2~,a~3~……,a~n~&gt;，我们能够将UI状态更改与基于操作时间戳的操作相匹配。我们使用在a~i~ 的时间戳之前捕获的UI状态作为s~i~来形成状态序列&lt;s~1~, s~2~, s~3~……,s~n~&gt;。状态序列和动作序列一起表示用户交互流，其将用作我们的人交互模型的训练数据。</p>\n<p><img src=\"/2019/04/23/A-Deep-Learning-based-Approach-to-Automated-Android-App-Testing/3.jpg\" alt=\"\"></p>\n<h2 id=\"C-模型训练\"><a href=\"#C-模型训练\" class=\"headerlink\" title=\"C.模型训练\"></a>C.模型训练</h2><p>本节详细介绍了我们如何使用机器学习模型从人类交互痕迹中学习人类交互模式。最终用户根据他们想要对应用程序执行的操作以及他们在GUI上看到的内容与应用程序进行交互。由于不同的应用程序通常共享通用的UI设计模式，因此直观的是人类与GUI交互的方式可以在不同的应用程序中进行推广。交互模型的目标是捕获这种可推广的交互模式。</p>\n<p>我们引入了一个概念UI上下文来模拟人们在与应用程序交互时引用的内容。 UI上下文 context~i~ 包括当前UI状态s~i~和三个最新UI转换（s~i-1~, a~i-1~）, （s~i-2~, a~i-2~）, （s~i-3~, a~i-3~）。当前UI状态表示用户在执行操作时看到的内容，而最新的UI转换用于在当前交互会话期间对用户的潜在意图进行建模。</p>\n<p><img src=\"/2019/04/23/A-Deep-Learning-based-Approach-to-Automated-Android-App-Testing/4.jpg\" alt=\"\"></p>\n<p>图3显示了我们如何在模型中表示UI状态和操作。每个UI状态表示为双通道UI骨架图像，其中第一个通道（红色通道）呈现文本UI元素的边界框区域，第二个通道（绿色通道）呈现非文本UI的边界框区域元素。我们使用UI骨架而不是原始屏幕截图的原因是屏幕截图上的大多数字符不会影响人类与应用程序的交互方式。例如，同一应用程序的UI样式（字体大小，按钮样式，背景颜色等）可能会在不同的操作系统和应用程序版本中发生变化，而用户使用应用程序的方式则保持不变。有些应用甚至提供“夜间模式”等功能，允许用户在内部更改UI样式。这样的UI样式字符可能会给我们的模型带来噪声并影响模型的泛化能力，因此我们将它们从输入表示中排除。</p>\n<p>每个动作由其动作类型和目标位置坐标表示。动作类型被编码为三维向量，其中每个维度映射到前面描述的七种动作类型之一。操作目标位置编码为热图。热图中的每个像素是像素在动作目标位置的概率。我们使用热图而不是原始坐标来表示动作位置，因为原始坐标是高度非线性的并且更难以学习[31]。</p>\n<p>总之，UI上下文的表示，即我们的交互模型的输入特征，是一堆图像，包括用于当前UI状态的一个2通道图像和用于三个最新UI转换的三个3通道图像（每个转换包括一个用于UI状态的双通道图像和一个用于动作的单通道图像）。所有图像都缩放到180x320像素的大小。为了便于学习，我们还为当前UI状态添加了一个零填充通道。最后，UI上下文表示为4x180x320x3向量。</p>\n<p>给定UI上下文向量，交互模型的输出是可能由人在当前状态下执行的“动作”。请注意，预测的“动作”不是当前UI状态中的实际可接受动作。相反，它是预期的类人行为的类型和位置的概率分布。具体而言，该模型的目标是学习两个条件概率分布：</p>\n<p>1）p~type~（t | context~i~）其中t ∈ {touch, long_touch;swipe_up,…… }，意思是给定当前UI 上下文的情况，下一个动作a~i~的类型的概率分布t。</p>\n<p>2）ploc（x, y | context~i~）其中0 &lt;x &lt;screen_width和0 &lt;y &lt;screen_height，表示在给定当前UI上下文的情况下，下一个动作a~i~的目标位置x,y的概率分布。</p>\n<p><img src=\"/2019/04/23/A-Deep-Learning-based-Approach-to-Automated-Android-App-Testing/5.jpg\" alt=\"\"></p>\n<p>图4显示了用于学习上面定义的两个条件概率分布的深度神经网络模型。它接受当前UI上下文 context~i~ 的表示作为输入，并输出a~i~的位置和类型分布。该模型由五个主要部分组成：卷积层，残余LSTM模块，去卷积层，完全连接层和 损失函数。</p>\n<p><strong>卷积层</strong>。卷积网络结构已经成为一种流行的图像特征提取方法，因为它已被证明在大型真实世界数据集上的计算机视觉任务中非常强大[32]。在我们的模型中，我们使用具有RELU激活的5个卷积层来从UI骨架图像和动作热图提取特征。在每个卷积层之后，有一个stride-2 max-pooling层，它将输入的宽度和高度减少到一半。池化层还有助于模型识别具有相同形状但环境不同的UI元素。</p>\n<p><strong>剩余的LSTM模块</strong>。 LSTM（长短期记忆）网络在序列建模问题中被广泛采用，例如机器翻译[33]，视频分类[34]等。在我们的模型中，从历史转换中提取特征也是序列建模问题。我们在最后3个卷积层的每一个之后插入残余LSTM模块，以便捕获不同分辨率级别上的UI转换序列特征。在残余LSTM模块中，输入的最后一维和正常LSTM的输出通过剩余路径直接相加。</p>\n<p>这种残留结构使神经网络更容易优化[35]，并提示动作的位置应位于UI元素内。为了降低模型复杂度，我们还在每个残余LSTM模块之前添加了1x1卷积层，以减少特征维度。</p>\n<p><strong>去卷积层</strong>。该组件用于从残余LSTM模块的低分辨率输出生成高分辨率概率分布。有几种方法可以实现这一点，例如双线性插值，反卷积等。我们使用反卷积层，因为它更容易与深度神经网络集成，并且比插值方法更通用。将不同分辨率级别的特征组合在一起，以提高生成热图的质量[36]。接下来使用softmax层来标准化生成的热图，使得热图中的所有像素总和为1，这是动作位置的概率分布。</p>\n<p><strong>完全连接的层</strong>。使用softmax的单个完全连接层用于生成动作类型的概率分布。</p>\n<p><strong>损失函数</strong>。该模型将行动位置和行动类型预测为概率分布。因此，它们对地面事实（由人类执行的动作）的交叉熵损失适合于模型优化。我们使用这两个损失的总和和层权重正则化器作为训练过程中的最终损失函数。</p>\n<p>在训练期间，交互流中的每个动作ai（&lt;s~1~, s~2~, s~3~ ……, s~n~&gt;，&lt;a~1~, a~2~, a~3~…… a~n~&gt;）将转换为以下概率分布：</p>\n<p><img src=\"/2019/04/23/A-Deep-Learning-based-Approach-to-Automated-Android-App-Testing/6.jpg\" alt=\"\"></p>\n<p>和<br>$$<br>p_{loc}（x, y）= f（x - a_i.x, y - a_i.y）<br>$$<br>其中f是方差= 20的高斯分布的密度函数，我们使用高斯分布来逼近实际屏幕的概率分布当多个人多次交互相同的UI元素时，设备识别的坐标。</p>\n<p>类似地，在应用模型时，我们使用当前UI状态的表示来提供它，以预测下一个动作的概率分布p~type~（t）和p~loc~（x, y）。由于预测的分布不能直接用于指导测试生成，我们需要进一步将它们转换为可以在当前状态下执行的操作的概率。为此，我们首先遍历UI树以查找当前状态中的所有可能操作，每个操作包含操作类型（表示为action.type）和操作目标元素（表示为action.element）。然后我们根据模型预测的分布计算每个动作的概率：<br>$$<br>p(action) = p_{type}(action.type) ∗ \\sum_{x，y在action.element}p_{loc}(x, y)<br>$$<br>动作概率可能最终用于指导下一步的测试输入生成。</p>\n<h2 id=\"D-引导测试生成\"><a href=\"#D-引导测试生成\" class=\"headerlink\" title=\"D.引导测试生成\"></a>D.引导测试生成</h2><p>在本节中，我们将描述如何应用人类交互模型来生成类似人类的测试输入。</p>\n<p>Humanoid生成两种类型的测试输入，包括探索和导航。探索输入用于发现应用程序中看不见的行为，而导航输入将应用程序驱动到包含未探测操作的已知状态。当从探索输入中选择时，测试生成器不知道每个测试输入的结果，并且基于人类交互模型的指导做出决定（传统的测试生成器通常随机选择输入）。当生成导航输入时，测试生成器知道输入的目标状态，因为它已经保存了转换的存储器。</p>\n<p>与许多现有的测试生成器类似，Humanoid使用GUI模型来保存转换的内存。我们使用的GUI模型表示为UI转换图（简称UTG），它是有向图，其节点是UI状态，边是导致UI状态转换的动作。 UTG是在运行时构造的：每次测试生成器观察到新的状态si时，它都会添加一个新的边&lt;s~i-1~; a~i-1~; s~i~&gt;到UTG，其中s~i-1~是最后观察到的UI状态，a~i-i~是在s~i-1~中执行的动作。图5显示了UTG的一个例子。使用UTG，测试生成器可以通过遵循状态路径导航到任何已知状态。</p>\n<p><img src=\"/2019/04/23/A-Deep-Learning-based-Approach-to-Automated-Android-App-Testing/7.jpg\" alt=\"\"></p>\n<p><img src=\"/2019/04/23/A-Deep-Learning-based-Approach-to-Automated-Android-App-Testing/8.jpg\" alt=\"\"></p>\n<p>为了在探索和导航之间做出决定并生成输入动作，Humanoid采用了一种简单但有效的策略，如算法1所示。在每个步骤中，Humanoid检查当前状态中是否存在未探测的动作。如果存在未探测的动作，Humanoid会选择探索（第8行），如果完全探索当前状态，则选择导航（第10行到第12行）。导航过程很简单。在探索过程中，Humanoid获取交互模型预测动作的概率，并基于概率进行加权选择。由于人类将采取的行动将被赋予更高的概率，因此人类生物体作为测试输入被选择的机会更高。因此，Humanoid生成的输入比随机选择的输入更像人类。</p>\n<p>与现有的测试工具相比，Humanoid的主要特征（以及不同基于模型的测试生成器之间的主要区别）是如何选择探索输入（第8行）。 Humanoid基于交互模型对勘探中更有价值的行为进行优先级排序，交互模型已经从人类交互痕迹进行了训练。此功能可以更快地发现正确的输入序列，从而将应用程序驱动到重要的UI状态，从而提高测试覆盖率。</p>\n<h1 id=\"IV-评估\"><a href=\"#IV-评估\" class=\"headerlink\" title=\"IV.评估\"></a>IV.评估</h1><p>我们主要通过以下几个方面评估Humanoid：</p>\n<ul>\n<li>1）Humanoid能否学习人类交互模式？具体而言，交互模型能否以高精度预测UI状态下的用户操作？</li>\n<li>2）Humanoid需要多长时间才能使用交互模型？具体而言，训练模型和预测行动概率需要多长时间？</li>\n<li>3）当训练好的交互模型用于指导测试生成时，Humanoid可以实际上实现更高和更快的覆盖吗？</li>\n</ul>\n<p>我们进行了两次实验来回答这些问题。首先，我们使用人类交互痕迹的数据集来训练和测试交互模型。我们研究了该实验中的模型精度和时间效率。其次，我们将在数据集上训练的模型集成到测试生成器中，并使用测试生成器对两组不同的Android应用程序进行测试。我们测量了Humanoid的测试覆盖率和测试进度，并将结果与几种最先进的测试工具进行了比较。</p>\n<h2 id=\"A-实验设置\"><a href=\"#A-实验设置\" class=\"headerlink\" title=\"A.实验设置\"></a>A.实验设置</h2><p>我们用于训练和测试Humanoid模型的数据集是从Rico [7]处理的，Rico [7]是人类交互的大量人群源数据集。我们通过识别动作序列和状态序列从原始数据中提取交互流。最后，我们获得了12,278个属于10,477个应用程序的交互流程。每个交互流平均包含24.8个状态。每个UI状态中可能的动作数量的累积分布函数（CDF）如图6所示。平均而言，每个UI状态有50.7个可能的动作候选者，而超过10％的UI状态包括100多个动作候选者。</p>\n<p><img src=\"/2019/04/23/A-Deep-Learning-based-Approach-to-Automated-Android-App-Testing/9.jpg\" alt=\"\"></p>\n<p>我们用来训练和测试交互模型的机器是一个带有两个Intel Xeon E5-2620 CPU，64GB RAM和一个NVidia GeForce GTX 1080 Ti GPU的工作站。该机器的操作系统是Ubuntu 16.04。该模型采用Tensorflow [37]实施。</p>\n<p>在测试覆盖率评估实验中，我们使用了4台计算机，其硬件和软件与上述相同。我们在每台机器上运行了4个Android模拟器实例，以并行测试应用程序。我们用于测试的应用程序包括从AndroTest [8]获得的68个开源应用程序，这是一个用于评估Android测试输入生成器的常用数据集，以及从Google Play下载的200个流行商业应用程序。在测试开源应用程序时，我们使用Emma [38]来测量行覆盖率。对于没有源代码的商业应用程序，我们使用活动覆盖率（达到的活动的百分比）来衡量测试性能。</p>\n<h2 id=\"B-交互模型的准确性\"><a href=\"#B-交互模型的准确性\" class=\"headerlink\" title=\"B.交互模型的准确性\"></a>B.交互模型的准确性</h2><p>在这个实验中，我们在现有的人类交互痕迹上训练和测试了我们的交互模型，以了解该模型是否能够了解人类如何与应用程序交互。</p>\n<p>我们从数据集中随机选择了100个应用程序，并使用它们的交互跟踪进行测试。其余10,377个应用程序的交互痕迹用于训练。总的来说，我们有302,382个用于训练的UI状态和用于测试的2,594个UI状态。对于测试集中的每个UI状态，我们使用交互模型来预测所有可能操作的概率，并按预测概率的降序对操作进行排序。人类所采取的行动被视为基本事实。</p>\n<p>表II示出了在每个UI状态中对人类执行的动作进行优先级排序时Humanoid人交互模型的准确性。具体而言，我们计算了地面实况（人类执行的动作）按照交互模型预测的动作顺序排在前N（N = 1,3,5,10）内的概率。为了比较，我们还计算了随机策略的topN准确度，即如果动作是随机顺序，则地面实况排名前N的概率。根据结果，我们的交互模型可以更准确地识别人类生成的行为并确定其优先级。</p>\n<p>特别是，Humanoid能够为超过50％的UI状态分配人类生成动作的最高概率。我们还计算了每个UI状态中人为操作的百分位数。平均百分位数排名为20.6％，中位数为9.5％，这意味着Humanoid能够将类似人类的行为优先于大多数UI状态的前10％。</p>\n<h2 id=\"C-交互模型的开销\"><a href=\"#C-交互模型的开销\" class=\"headerlink\" title=\"C.交互模型的开销\"></a>C.交互模型的开销</h2><p>我们然后评估了交互模型的开销。使用包含304,976个人为操作的数据集训练交互模型大约需要66个小时。这是可以接受的，因为模型在用于测试之前只需要训练一次。用于预测UI状态的动作概率所花费的平均时间是107.9毫秒。鉴于Android测试生成器通常需要2秒以上的时间来发送测试输入并等待加载新页面，我们的交互模型将给测试生成器带来的时间开销很小。</p>\n<h2 id=\"D-引导测试的覆盖率\"><a href=\"#D-引导测试的覆盖率\" class=\"headerlink\" title=\"D.引导测试的覆盖率\"></a>D.引导测试的覆盖率</h2><p>在该实验中，我们使用在先前实验中训练的交互模型来指导测试生成。我们通过检查它是否能真正提高测试覆盖率来评估指导测试发生器。</p>\n<p>我们测试了两套应用程序，包括68个开源应用程序和200个流行的市场应用程序。我们将Humanoid与六款最先进的Android测试生成器进行了比较，包括Monkey [3]，PUMA [12]，Stoat [14]，DroidMate [15]，Sapienz [9]和DroidBot [11]。所有工具都使用其默认配置。 PUMA，Stoat，DroidMate和DroidBot的输入速度接近600个事件/小时，因为他们都需要在执行操作之前读取UI状态并在发送输入后等待状态转换，而Monkey和Sapienz可以发送输入事件速度非常快（在我们的实验中大约6000次/小时）。</p>\n<p>我们使用每个测试工具运行每个开源应用程序1小时，每个市场应用程序运行3个小时。为了适应最近的市场应用程序，大多数工具都是在Android 6.0上进行评估的，因为它得到了大多数工具的支持（一些工具经过了少量修改）。然而，由于Sapienz是近源的并且仅支持Android 4.4，因此它在Android 4.4上进行了评估。对于每个应用和工具，我们记录了每个操作执行后的最终覆盖率和渐进覆盖率。我们重复这个过程三次，并使用平均值作为最终结果。</p>\n<p><img src=\"/2019/04/23/A-Deep-Learning-based-Approach-to-Automated-Android-App-Testing/11.jpg\" alt=\"\"></p>\n<p><strong>1）开源应用程序的行覆盖率</strong>：开源应用程序上的测试工具实现的行覆盖率的总体比较如图7所示。平均而言，Humanoid实现了43.1％的行覆盖率，这是最高的跨所有测试输入生成器。</p>\n<p>有趣的是，采用随机探索策略的Monkey实现了比除Humanoid之外的所有其他基于模型的测试工具更高的覆盖率。 Monkey比其他大多数测试工具表现更好的事实也得到了其他研究人员的证实[39]。因为Monkey能够在相同的时间内生成比其他工具更多的输入。但是，我们的工作证明了基于模型的方法的可扩展性的好处。如果正确使用GUI信息，基于模型的测试工具具有实现更好测试性能的巨大潜力。</p>\n<p><img src=\"/2019/04/23/A-Deep-Learning-based-Approach-to-Automated-Android-App-Testing/10.jpg\" alt=\"\"></p>\n<p>每个应用程序的详细行覆盖范围如表III所示。对于一些应用程序，如＃3，＃36和＃45，Monkey的覆盖范围要高得多。原因是Monkey可以生成许多其他工具不支持的输入（例如意图和广播）。对于大多数其他应用程序，Humanoid取得了最佳效果，特别是对于＃6，＃18，＃30等应用程序。</p>\n<p>我们进一步研究了为什么Humanoid能够通过检查详细的测试痕迹来超越其他测试工具。我们仔细检查了五个应用程序，其中Humanoid实现了更高的覆盖率。我们发现了一些Humanoid表现优于其他人的情况，如表IV所示。总而言之，Humanoid的高覆盖率主要是由于两个原因：首先，当有大量UI元素可供选择时，Humanoid能够识别关键UI元素并确定其优先级。其次，Humanoid有更高的机会执行一系列有意义的操作，这可以将应用程序推向未开发的核心功能。</p>\n<p><img src=\"/2019/04/23/A-Deep-Learning-based-Approach-to-Automated-Android-App-Testing/12.jpg\" alt=\"\"></p>\n<p>图8显示了渐进式覆盖范围w.r.t。每个测试工具发送的输入事件数。请注意，我们没有将Sapienz包含在渐进式覆盖数据中，因为它发送的事件太快，我们无法将其放慢速度，因为它是近源的。在最初的几个步骤中，所有测试工具的行覆盖率迅速增加，因为应用程序刚刚启动，所有UI状态都是新的。 PUMA在前10个步骤中实现了最高覆盖率，因为它有一个在开始时重新启动应用程序的策略，这导致在许多应用程序中覆盖资源回收代码。Humanoid在大约20个事件后开始领先。那是因为那时已经涵盖了易于访问的代码，其他状态隐藏在其他测试工具难以产生的特定交互之后。</p>\n<p>在第600个事件点，除了Monkey之外，大多数测试工具的线路覆盖率几乎已经收敛。这是因为Monkey的随机策略产生了大量无效和重复的输入事件，当我们计算事件数量时，这对于覆盖率改善没有帮助。但是，Monkey能够在相同的时间内生成更多的事件。其覆盖率将在第600步后继续增加，并在测试结束时达到约39％（相同的一小时测试持续时间）。</p>\n<p><strong>2）市场应用程序的活动覆盖率</strong>：与开源应用程序相比，市场应用程序通常具有不同且更复杂的功能和UI结构。因此，我们进一步对市场应用程序进行了实验，以确定Humanoid是否仍然更有效。</p>\n<p>由测试工具和渐进覆盖实现的最终活动覆盖分别如图9和图10所示。与开源应用类似，Humanoid与其他工具相比也实现了最高覆盖率（24.1％）。由于市场应用程序的复杂性，一些应用程序的覆盖范围在测试结束时没有收敛。但是，我们相信Humanoid即使在更长的测试时间内也能保持优势。 （由于与上述相同的原因，请注意这两个数字中Monkey的覆盖范围的差异。）</p>\n<h1 id=\"V-限制和未来工作\"><a href=\"#V-限制和未来工作\" class=\"headerlink\" title=\"V.限制和未来工作\"></a>V.限制和未来工作</h1><p><strong>更多输入类型</strong>。有些类型的输入，例如系统广播，传感器事件等，本文未考虑这些类型。这是Humanoid的限制，因为这些输入很难从人类交互中收集，并且在我们的交互模型中也难以表示。但是，目前这不是一个大问题，因为大多数应用程序可以在没有这些操作的情况下进行良好测试Humanoid也不会在发送文本输入操作时预测文本，通过扩展模型以支持文本预测或集成其他文本输入生成技术，可以在将来修复文本输入操作[40]。</p>\n<p><strong>覆盖范围进一步改善</strong>。虽然Humanoid已经能够从现有的测试工具中显着改善覆盖范围，但测试覆盖率仍然相对较低（比完美覆盖更差）。特别是，某些应用的覆盖率低于10％。这是因为许多应用程序需要特定的输入，例如电子邮件和密码，甚至无法自动生成。一种可能的解决方案是设计更好的半自动化测试方法，其中人类测试人员可以用最少的努力为自动工具提供必要的指导。</p>\n<p><strong>利用文本信息</strong>。在学习人类交互模式时，我们使用UI框架来表示模型中的每个UI状态，而不使用每个UI元素中的文本。文本信息对于人类使用该应用程序非常重要。我们相信，如果可以在交互模型中正确地表示和学习文本信息，则可以进一步提高Humanoid的性能。</p>\n<p><strong>学习非人类互动的痕迹</strong>。我们的方法在很大程度上依赖于人工交互轨迹，如果我们想要从更大的数据集中学习更多交互模式，这些轨迹可能难以扩展。由于模型实际从人类交互中学到的是每个UI中动作的重要性，因此只要可以分析动作的重要性，就可以直接训练机器生成的轨迹。</p>\n<h1 id=\"VI-结束语\"><a href=\"#VI-结束语\" class=\"headerlink\" title=\"VI.结束语\"></a>VI.结束语</h1><p>本文介绍Humanoid，一种用于Android应用程序的新GUI测试输入生成器，能够通过深度学习生成类似人类的测试输入。 Humanoid采用深度神经网络模型来了解最终用户更可能与哪些UI元素进行交互以及如何与大量用户生成的交互跟踪进行交互。在学习模型的指导下，Humanoid能够准确预测与Android应用程序的真人交互。根据对大量开源应用程序和流行的商业应用程序的实验，Humanoid能够比六种最先进的测试工具实现更高的测试覆盖率和更快的速度</p>\n","categories":[{"name":"论文","slug":"论文","permalink":"http://yama0xff.com/categories/论文/"},{"name":"fuzzing","slug":"论文/fuzzing","permalink":"http://yama0xff.com/categories/论文/fuzzing/"},{"name":"机器学习","slug":"论文/fuzzing/机器学习","permalink":"http://yama0xff.com/categories/论文/fuzzing/机器学习/"}],"tags":[{"name":"fuzzing","slug":"fuzzing","permalink":"http://yama0xff.com/tags/fuzzing/"},{"name":"机器学习","slug":"机器学习","permalink":"http://yama0xff.com/tags/机器学习/"},{"name":"2019年","slug":"2019年","permalink":"http://yama0xff.com/tags/2019年/"},{"name":"Android","slug":"Android","permalink":"http://yama0xff.com/tags/Android/"}]},{"title":"Remote Protocol Vulnerability Discovery for Intelligent Transportation Systems (ITS)","date":"2019-04-22T03:40:43.000Z","path":"2019/04/22/Remote-Protocol-Vulnerability-Discovery-for-Intelligent-Transportation-Systems-ITS/","text":"AbstractITS是当今典型的智能应用。为了实现更安全和更高效的运输系统的目标，发现ITS的脆弱性起着重要作用。本文基于ITS的通信视图分析了ITS的威胁源。提出了一个协议漏洞发现框架，用于基于模糊测试和自动分析保护ITS应用程序，支持机器学习，遗传算法和模式识别技术。最后，还给出了ITS中开放网络视频接口论坛（ONVIF）协议上的漏洞发现的典型案例，以证明所提议的协议漏洞发现框架的有效性和实用性。该案例的实验结果表明，协议漏洞发现框架支持以有效的方式发现ITS的漏洞。将不同协议模糊测试模式和分析模式组合到一个框架中的挑战，以及限制也被报告和讨论。最后，本文总结了ITS框架的未来研究方向和应用。（没啥新思路） Keywords—ITS, protocol vulnerability discovery, threat model,fuzzing, automatic analysis relevant information 作者 Liang Ming, Gang Zhao, Minhuan HuangЪ, Ling PangЪ, Jin Li, Jingzhe Zhang, Dan Li, Shuaibing Lu 单位 National Key Laboratory of Science and Technology on Information System Security 出处 2018 IEEE Third International Conference on Data Science in Cyberspace 原文地址 https://ieeexplore.ieee.org/iel7/8411555/8411822/08411968.pdf 源码地址 发表时间 2018年 I. 引言智能交通系统（ITS）是一种重要的交通基础设施，在自动事件检测，智能视频监控，车辆到基础设施，动态交通灯序列等方面有着快速发展[1]。 ITS中涉及许多用户，控制器，演员和操作员。中心或领域中的每个实体直接或间接地改变了商品的流动方式。中心到现场（C2F）通信和中心到中心（C2C）通信使中心系统之间以及中心系统与该中心管理的多个控制或监视设备之间能够进行通信，从而有效地交换控制指令和状态以及交通流量信息[2]。 但保护ITS是他们为公共交通提供信息服务的基础。发现ITS的脆弱性是保护ITS并使流量畅通的有效方法[3]。 2015年，一则新闻震惊全国，黑客远程控制了一辆吉普车并在高速公路上杀死了它的发动机[4]。作为一种信息系统，ITS将比传统的计算机系统和网络遇到类似甚至更多的网络威胁。在ITS中，C2F通信和C2C通信是两种根本不同类型的交通控制通信，并且已经研究了许多方法来提高通信的安全性[5]。然而，ITS总体上继承了与计算机系统和无线网络相关的固有问题。 Fuzzing是一种黑盒测试方法，是一种黑盒软件测试技术，已广泛应用于发现通信协议的漏洞。有一些通用的模糊测试框架，如SPIKE [6]和ProtoFuzz [7]，它们不支持ITS应用程序。其他工具如ircfuzz [8]，dhcpfuzz [9]和InfigoFTPStressFuzzer [10]分别用于模糊特殊协议，但没有用于ITS协议漏洞发现的特殊模糊测试工具。 本文探讨了在实际网络中发现和分析ITS协议漏洞的有效性。各种应用协议可能会导致ITS的风险。本文将研究ITS的安全性，威胁和协议漏洞发现问题。本文的其余部分安排如下：第二部分总结了ITS的ITS通信视图和威胁源。在第III节中，提出了ITS的协议漏洞发现框架及其模糊设计，自动分析和概念验证案例。第四节讨论了这种提议的测试方法的挑战和局限性。最后一节第五节总结了整篇论文 II.通信视图和威胁源A. ITS的通信视图协同和智能交通的架构参考（ARC-IT）是ITS的最新参考架构模型[11]。 ARC-IT提供了一个用于规划，定义和集成智能交通系统的通用框架，包括所有连接的车辆应用。它涵盖了国家ITS架构7.1版和互联汽车参考ITS架构（CVRIA）2.2版的所有范围和内容。此体系结构中有企业视图，功能视图以及物理视图和通信视图。特别地，图1中的通信视图描述了提供物理对象之间的互操作性所必需的协议，其提供了保护ITS的一般方式。 在通信视图中，ITS上面的IP协议栈中使用了大量协议。典型的信息层协议包括NTCIP（ITS协议的国家运输通信）系列，ONVIF（开放式网络视频接口论坛）等，应用层协议包括SNMP，STMP，HTTP，FTP，SOAP，C2C XML，DATEX [12] ]， 等等。每个协议都负责ITS中相应类型的应用程序。特别是NTCIP标准为运营运输管理系统的机构提供了更高的灵活性和选择。 NTCIP标准的使用消除了跨机构协调的障碍，并允许不同类型和不同制造商的设备混合在同一通信线路上。例如，NTCIP 1203是用于动态消息标志（DMS）的NTCIP对象定义，ONVIF规范定义了网络客户端和设备之间的通信过程，这使得使用已定义的通用和良好的接口来构建不同制造商的设备和接收器网络视频系统成为可能。 B. ITS的威胁来源除了未经授权的攻击外，还有一些攻击者可能伪装成合法用户。由于有很多用户，谁可以生成数据，在ITS发送消息和接收警报，因此内部攻击将越来越受欢迎。根据通信视图，以下列出了ITS中存在的安全威胁和攻击： 应用层威胁包括消息重放攻击，消息篡改攻击，恶意消息攻击以及其他人员攻击，欺骗，嗅探和拒绝服务的攻击方式。消息重放攻击意味着攻击者重新发送合法用户最初发送的旧消息，以增加网络流量并导致拥塞。消息篡改攻击意味着攻击者作为中间人修改消息，然后将其发送出去以造成问题或误导用户。恶意消息攻击包括C2F，C2C和V2V通信中的恶意消息攻击，攻击者向网络中的其他节点发送虚假信息;从而误导用户并可能造成严重破坏。 传输层和网络层威胁包括伪造RSU攻击，拒绝服务，基础密钥泄漏以及其他通信干扰攻击。伪造RSU攻击是获取车辆节点的信息，然后扰乱车辆网络通信。传输和网络层中的拒绝服务是通过临时或无限期地中断连接到车辆网络的节点中的服务来使其预期用户无法使用网络资源。基础密钥泄漏是一种威胁，因为V2V通信中使用的主密钥可能被攻击者嗅探和滥用。 数据链路层和物理层威胁包括物理损坏，构建障碍和能源干扰。物理损坏是使汽车中的RSU或传感器物理损坏或混乱。建筑障碍是通过设置建筑物，墙壁等障碍物来中断车辆网络的无线信号通信。能量扰动是通过能量和功率控制来干扰车辆网络的无线通信。 在上述威胁中，中间人攻击可能会危及ITS的机密性。嗅探可能会损害ITS的信息完整性。嗅探和欺骗可能会损害ITS的消息不可否认性。拒绝服务，物理攻击，信号中断和能源干扰可能会影响ITS的可用性。 显然，与通信有关的威胁是关键问题，发现协议漏洞和安全协议是ITS安全的基础。除了这些技术威胁之外，ITS还面临着许多安全管理风险，例如操作故障，个人安全设置错误，车辆丢失引起的钥匙泄漏，租车误用等。总之，所有这些威胁和对抗方法都会给ITS带来风险，并大大提高ITS协议漏洞的可能性 III.基于模糊的远程协议漏洞发现的自动框架A.漏洞发现框架协议漏洞发现是ITS安全的关键问题。在下文中，我们将介绍基于模糊测试的ITS协议的自动漏洞发现框架。 ITS中的信息层和应用层中有许多协议用于各种功能，服务和场景。 ITS中的所有设备都将与各自的协议进行通信。为了对各种应用层协议和信息层协议（如IETF HTTP，IETP FTP，SOAP，NTCIP系列和ONVIF）进行模糊测试，我们将构建ITS协议漏洞分析的通用框架。 在NTCIP系列中，应用程序级别采用SNMP，STMP，FTP，TFTP，C2C XML，DATEX等。在ONVIF标准中，应用程序级别采用SOAP / HTTP。所有这些应用程序级协议都可以在TCP / IP堆栈上运行。由于ITS中的几乎所有通信协议都在IP网络上工作，因此可以基于IP数据包通信以一般方式构建漏洞发现框架，如图2所示。 在图2中，ITS的协议漏洞发现框架包括三个组件：数据包捕获，模糊测试生成器和漏洞分析。 Packet Capture组件负责在线捕获软件包并将其输出到Fuzzing Generator组件以进行消息自定义，并将其输出到Vulnerability Analysis组件以发现漏洞。Fuzzing Generator组件负责自定义模糊测试消息，这些消息将发送到ITS中的目标并触发其漏洞。在Fuzzing Generator组件中，ITS，C2F和C2C通信都支持许多应用层协议，如SNMP，STMP，FTP，TFTP，C2C XML，DATEX和SOAP。并且可以使用各种模糊变量（例如静态模糊测试向量，源代码和随机数据）来组成请求模糊消息，这将在第III B节中详细描述。漏洞分析组件负责通过比较和分析来自Fuzzing Generator组件的请求消息和来自Packet Capture组件的响应消息来发现ITS中目标的漏洞。在漏洞分析组件中，机器学习算法，遗传算法和模式识别技术可用于自动发现漏洞以获得更高的效率，这将在第III节C中详细描述。通过使用学习和培训，漏洞分析组件可以构建一个强大的机器学习模型进行分类。通过将响应消息与关联的请求模糊消息进行比较，分类模型可以识别目标设备中的协议漏洞。一旦发现漏洞，模糊测试生成器组件将停止模糊测试，并且漏洞分析组件将存储所有请求模糊消息，模式和响应消息以供进一步验证。 该协议漏洞发现框架扩展了传统的计算机网络协议测试思想，为发现ITS的协议漏洞提供了一整套功能。通过漏洞分析组件，我们可以解码响应消息来检查关联请求消息的回复，并找出ITS的漏洞。此外，请求模糊消息有时可能会将目标设备堵塞在ITS中。为了确保目标仍然有效，Fuzzing Generator组件应定期运行探测工具，例如ping，以检查ITS中目标的工作状态。 B.漏洞发现中的模糊设计模糊测试是一种有效的信息定制方法，可以发现网络和信息系统中的协议漏洞。生成模糊消息的工作流程如图3所示。在工作流程图中，模糊消息定制是一个关键组件，它将模糊测试数据排列成与测试协议规范兼容的消息。为了自动生成请求模糊消息，可以通过下面详细描述的模糊模式对该过程进行形式化和编程。可以从静态模糊测试向量，随机数据和IP数据包捕获工具获得的源代码导入模糊测试数据。 基于TCP / IP，有一些典型的漏洞发现模糊模式，我们可以在形式化中描述它们，如下所示。 模式1：方法+目标地址+ [标题] + &lt;协议名称&gt; + [数据] + [功能] 模式2：方法+目标地址+ [标题] + &lt;随机数据&gt; +数据 模式3：[方法] +目标地址+ [标题] + [数据] + [功能] 在模式1，模式2和模式3中，METHOD是自定义请求消息中的操作。它包括GET，POST，PUT，SET，GET-REQUEST，GET-NEXT-REQUEST，SET-REQUEST，GET-RESPONSE，TRAP等，它们在SOAP，SNMP和STMP中使用。 METHOD部分通常可以填充静态模糊矢量。 TARGET ADDRESS指定目标设备，可以是URI，请求ID，IP地址，服务地址等。对于目标设备，TARGET ADDRESS是确定的。 HEADERS包括各种标头信息，例如Accept，Cache-Control，Content-Encoding，Content-Language，Content-Length，Content-Type，Error Status，Error Index等。 HEADERS通常可以从捕获的数据包中填充源代码。 PROTOCOL NAME是经过测试的协议及其版本的名称，例如HTTP / 1.0，HTTP / 1.1等。而PROTOCOL NAME是模式中的可选部分。 DATA指定协议规范下的消息内容，它可以是认证，功能和其他静态文本的全部或部分，通常可以通过在线捕获的数据包填充源代码。RANDOM DATA可以是任何随机字符，可用于模糊认证，功能等。 FUNCTIONS包括协议中的所有可用操作函数，例如GetUsers，CreatUser，GetDeviceInformation，SystemReboot等，它们可以在协议规范下填充静态模糊测试向量。随机数据和函数也可以是DATA的一部分。在所有模式中，方括号[]表示内部变量是静态模糊矢量，而天使括号&lt;&gt;表示内部变量是可选的。 显然，模式1，模式2和模式3只是请求消息的可用漏洞模糊模式的三个代表，它们适合ITS中的相应模糊测试应用。模式1侧重于通过修改消息数据来发现消息重放和消息修改中的协议漏洞。模式2侧重于通过修改部分消息数据来发现认证信息中协议的漏洞。模式3侧重于通过修改方法（如GET，SET等）来发现协议的漏洞。此外，对于各种协议，根据需要，还可以在模糊消息中使用一些新的模糊化请求消息模式。 事实上，漏洞模糊测试模式只是抽象了请求消息的关键字符。例如，在模式2中，METHOD，目标地址，若干HEADERS，变量RANDOM DATA和其他DATA组成关键字符向量，其表示具有类似模糊测试模式的一些请求消息。这些关键字符对于自动分析请求消息和响应消息非常有帮助，这将在下面进一步描述。 C.漏洞发现中的自动分析模糊测试后，我们可以通过智能方法比较请求消息和响应消息，如机器学习模型，遗传算法，模式识别等。这是实现自动分析的关键步骤。一些典型的漏洞分析模式包括但不限于以下内容。 模式4：[请求字符] + [状态代码] -&gt;“通过/失败” 在模式4中，“请求字符”是请求模糊消息的关键字符。 STATUS CODES是响应消息的状态，例如HTTP状态码，并且可以在摘要中反映模糊消息的结果。 PASS / FAIL是漏洞发现的分类标签。例如，如果STATUS CODE为“200 OK”且REQUEST CHARACTER为“HTTP / 1.1”，则相应的SOAP请求消息可能会发现目标设备上的漏洞，并且漏洞发现的分类标签应为“PASS”。另一方面，如果STATUS CODE是“401 Unauthorized”且REQUEST CHARACTER是模式2，则相应的SOAP请求消息可能不会在目标设备上发现身份验证漏洞，并且漏洞发现的分类标签应为“FAIL”。 STATUS CODE可以通过源代码从在线捕获的数据包或协议规范获得。 模式5：[请求字符] + [敏感字符] -&gt;“通过/失败” 在模式5中，“请求字符”是模糊请求消息的关键字符。敏感字符是指响应消息中的敏感信息，例如用户名和执行结果，可以在捕获的数据包的源代码中找到。PASS / FAIL是漏洞发现的分类标签。例如，如果REQUEST CHARACTERS为“HTTP / 1.1”且SENSITIVE CHARACTERS为“&lt;tt：UserLevel&gt; Administrator &lt;/ tt：UserLevel&gt;”，则相应的请求消息可能会在目标设备上发现身份验证漏洞，并且分类标签为漏洞发现应该是“PASS”。另一方面，如果REQUEST CHARACTERS为“HTTP / 1.1”且敏感字符不匹配，则相应的请求消息可能无法在目标设备上发现身份验证漏洞，并且漏洞发现的分类标签应为 “FAIL ”。 模式6：[请求字符] + [错误字符] -&gt;“通过/失败” 在模式6中，请求字符是请求模糊消息的关键字符。错误字符是指响应消息中的错误警报或不合理的信息，例如输入文本，未记录的服务等。 PASS / FAIL是漏洞发现的分类标签。例如，如果REQUEST CHARACTERS是“Fuzzing work？”，这是一个有意识的输入字符串，并且响应消息还包含一个ERROR CHARACTERS“Fuzzing work？”，这与我们在请求消息中的输入相同，那么相应的请求消息可能会发现目标设备中的XSS漏洞，并且漏洞发现的分类标签应为“PASS”。相反，如果没有匹配的ERROR CHARACTERS，则相应的请求消息可能不会在目标设备上发现身份验证漏洞，并且漏洞发现的分类标签应为“FAIL”。错误字符可以通过源代码从线上捕获的数据包获得，也可以通过故意输入获得。 模式7：[请求字符] + [请求超时] -&gt; 通过/失败 在模式7中，REQUEST CHARACTERS是模糊请求消息的关键字符。 REQUEST TIMEOUT表示响应消息无法在所需时间内到达。 PASS / FAIL是漏洞发现的分类标签。例如，如果请求CHARACTERS是一个SNMP请求，和该请求后请求超时出现时，则对应的请求消息可能发现在目标装置中的拒绝服务（DoS）的脆弱性，以及脆弱性发现的分类标签应该是“PASS” 。相反，如果没有匹配的REQUEST TIMEOUTS，则DoS漏洞发现的分类标签应为“FAIL”。 REQUEST TIMEOUTS可以通过源代码从在线捕获的数据包或协议规范获得。 在模式4，模式5，模式6和模式7中，方括号[]表示内部变量是静态模糊矢量，它允许构建数据集以定义包含大量值的变量。例如，[REQUEST CHARACTERS]可以是请求消息的字符数据集。通过这些模式，可以创建足够的训练样本并将其用于机器学习模型。经过训练，我们可以使用该机器学习模型自动判断响应并在线请求消息。如果结果是PASS，这意味着请求消息发现漏洞，那么我们可以深入研究漏洞及其漏洞利用工具。实际上，除了这种自动分析方法之外，模式4，模式5，模式6和模式7也可以用于手动响应消息识别。通过这些精心设计的模式和字符，我们可以确定当前设备中是否存在漏洞。 如上所述，模式4，模式5，模式6和模式7中的请求字符可以是模式1，模式2和模式3的全部或任何部分。并且所有模式为处理请求消息和响应消息提供了良好的参考。 自动实现ITS的漏洞发现。在发现具有漏洞的可疑目标设备后，我们可以进一步分析并找到确切的漏洞地址，然后给出漏洞描述和改进建议。 D.漏洞发现案例在这种情况下，我们将使用第III节中描述的漏洞发现框架对ITS中的ONVIF摄像机进行实际漏洞分析.ONVIF规范与SOA兼容，并且所有设备功能都被抽象为Web服务并使用简单对象访问协议（SOAP）通过HTTP进行通信。不幸的是，SOAP 1.1没有包含签名消息的条款，因此缺乏安全性。因此，我们使用设计良好的SOAP消息来模糊此漏洞所涉及的远程ONVIF设备。 基于上面的漏洞发现框架，我们在真实的网络实验环境中执行漏洞分析。实验场景是交叉路口上方的视频监控应用程序，如图4所示。我们可以访问ITS并访问此ONVIF摄像机，但我们没有摄像机的管理员权限。 为了在框架中实现Fuzzing Generator组件来制作模糊消息，我们使用Python语言开发了一个原型来修改具有与ONVIF规范兼容的各种功能的实际消息，然后将自定义消息发送到实际网络中的测试相机。真实的消息由Wireshark工具在线捕获。我们使用模式1作为自定义请求消息的参考，字符及其值如表I所示。因此，根据模式1，METHOD是POST，TARGET ADDRESS是摄像机IP地址，HEADERS是典型的HTTP标题和PROTOCOL NAME是HTTP / 1.1，DATA专注于从真实消息解码的认证信息，而FUNCTIONS是功能向量，包括Getusers，CreatUser，GetDeviceInformation，SystemReboot等。 Fuzzing Generator原型可以向ONVIF摄像机保留模糊消息，所有这些请求消息都存储在数据库中以供进一步分析。自定义请求消息之一如下。 1234567891011121314151617181920&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;soap:Envelopexmlns:soap=&quot;http://www.w3.org/2003/05/soap-envelope&quot;xmlns:tds=&quot;http://www.onvif.org/ver10/device/wsdl&quot;xmlns:tt=&quot;http://www.onvif.org/ver10/schema&quot;&gt; &lt;s:Headerxmlns:s=&quot;http://www.w3.org/2003/05/soap-envelop&lt;wsse:Security xmlns:wsse=&quot;http://docs.oasisopen.org/wss/2004/01/oasis-200401-wss-wssecurity-secext-1.0.xsd&quot; xmlns:wsu=&quot;http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-wssecurity-utility-1.0.xsd&quot;&gt;&lt;wsse:UsernameToken&gt;&lt;wsse:Username&gt;username&lt;/wsse:Username&gt;&lt;wsse:Password Type=&quot;http://docs.oasisopen.org/wss/2004/01/oasis-200401-wss-username-tokenprofile-1.0#PasswordDigest&quot;&gt;keys&lt;/wsse:Password&gt;&lt;wsse:Nonce&gt;keys&lt;/wsse:Nonce&gt;&lt;wsu:Created&gt;time&lt;/wsu:Created&gt;&lt;/wsse:UsernameToken&gt;&lt;/wsse:Security&gt;&lt;/s:Header&gt;&lt;soap:Body&gt;&lt;tds: Getusers /&gt;&lt;/soap:Body&gt;&lt;/soap:Envelope&gt; 在这种情况下，自动漏洞分析组件使用模式4实现。模式4中的参数及其值如表II所示。因此，根据模式4，REQUEST CHARACTERS是模式1，一旦响应消息的STATUS CODE为“200 OK”就会出现PASS。为了简化漏洞分析过程，我们使用模式识别来演示此步骤。我们在线捕获响应数据包并检查其状态代码，并将所有响应数据包存储在数据库中，以便与其请求消息进行相关性分析。与上述请求消息相关联的响应消息之一如下所示。 1234567891011121314151617HTTP/1.1 200 OKDate: Wed, 28 Mar 2018 14:05:02 GMTServer: App-webs/Connection: closeContent-Length: 2300Content-Type: application/soap+xml; charset=utf-8&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;env:Envelope xmlns:env=&quot;http://www.w3.org/2003/05/soapenvelope&quot; …&gt;&lt;env:Body&gt;&lt;tds:GetUsersResponse&gt;&lt;tds:User&gt;&lt;tt:Username&gt;admin&lt;/tt:Username&gt;&lt;tt:UserLevel&gt;Administrator&lt;/tt:UserLevel&gt;&lt;/tds:User&gt;&lt;tds:User&gt;&lt;tt:Username&gt;user6&lt;/tt:Username&gt;&lt;tt:UserLevel&gt;User&lt;/tt:UserLevel&gt;&lt;/tds:User&gt;&lt;/tds:GetUsersResponse&gt;&lt;/env:Body&gt;&lt;/env:Envelope&gt; 上面的响应消息回复状态代码“200 OK”，这意味着根据模式4，其请求消息触发了漏洞。实际上，经过测试的ONVIF摄像机会错误地响应管理员用户。在请求消息和响应消息中进行分析后，我们发现测试的摄像机存在ONVIF认证漏洞，漏洞位置是SOAP标头中的标识认证片段。由于它是ONVIF协议中的致命漏洞，因此我们还可以通过使用此框架对相机的云台变焦和录制服务进行模糊处理时发现类似的现象。从这个案例中，我们可以发现第III节A中提出的漏洞发现框架可以有效地远程发现ITS的协议漏洞。 IV.测试方法的挑战和限制分析协议漏洞发现框架提供了一种通过请求模糊消息来查找ITS及其设备的协议漏洞的方法。但是仍然存在许多安全问题，例如社会工程威胁，结构脆弱性，能量干扰物理层中的电源中断等等。在这种情况下，ITS不仅应该通过通信视图中的协议测试进行分析，还要检查系统级和物理视图。随着ITS应用的发展，应用协议将来会越来越多，因此将不同的消息定制协议组合到一个框架中将是一个挑战，需要在框架中用新的协议栈模块扩展第三节A中的框架。 V.结论协议漏洞发现是保护ITS本身的关键问题。由于ITS在公共交通中公开广泛部署，越来越多的攻击和威胁会极大地影响ITS的可用性并损害其完整性和机密性，甚至使道路交通比以前更加糟糕。本文从ITS通信的角度提出了ITS威胁的分类，为ITS协议漏洞发现提供了良好的指导。接下来，提出了一种协议漏洞发现框架，用于通过使用模糊消息定制和自动分析来保护ITS，其支持机器学习算法，遗传算法和模式识别技术。最后，还给出了关于ITS中ONVIF协议漏洞的选定概念验证案例，以证明所提议的协议漏洞发现框架的有效性和实用性。可以在丰富可用的请求消息模式和漏洞分析模式以及扩展协议栈模块方面做进一步的工作，以提高协议漏洞发现框架对更多协议的能力。","content":"<h1 id=\"Abstract\"><a href=\"#Abstract\" class=\"headerlink\" title=\"Abstract\"></a>Abstract</h1><p>ITS是当今典型的智能应用。为了实现更安全和更高效的运输系统的目标，发现ITS的脆弱性起着重要作用。本文基于ITS的通信视图分析了ITS的威胁源。提出了一个协议漏洞发现框架，用于基于模糊测试和自动分析保护ITS应用程序，支持机器学习，遗传算法和模式识别技术。最后，还给出了ITS中开放网络视频接口论坛（ONVIF）协议上的漏洞发现的典型案例，以证明所提议的协议漏洞发现框架的有效性和实用性。该案例的实验结果表明，协议漏洞发现框架支持以有效的方式发现ITS的漏洞。将不同协议模糊测试模式和分析模式组合到一个框架中的挑战，以及限制也被报告和讨论。最后，本文总结了ITS框架的未来研究方向和应用。（没啥新思路）</p>\n<p>Keywords—ITS, protocol vulnerability discovery, threat model,fuzzing, automatic analysis </p>\n<table>\n<thead>\n<tr>\n<th>relevant information</th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><em>作者</em></td>\n<td>Liang Ming, Gang Zhao, Minhuan HuangЪ, Ling PangЪ, Jin Li, Jingzhe Zhang, Dan Li, Shuaibing Lu</td>\n</tr>\n<tr>\n<td><em>单位</em></td>\n<td>National Key Laboratory of Science and Technology on Information System Security</td>\n</tr>\n<tr>\n<td><em>出处</em></td>\n<td>2018 IEEE Third International Conference on Data Science in Cyberspace</td>\n</tr>\n<tr>\n<td><em>原文地址</em></td>\n<td><a href=\"https://ieeexplore.ieee.org/iel7/8411555/8411822/08411968.pdf\" target=\"_blank\" rel=\"noopener\">https://ieeexplore.ieee.org/iel7/8411555/8411822/08411968.pdf</a></td>\n</tr>\n<tr>\n<td><em>源码地址</em></td>\n<td></td>\n</tr>\n<tr>\n<td><em>发表时间</em></td>\n<td>2018年</td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"I-引言\"><a href=\"#I-引言\" class=\"headerlink\" title=\"I. 引言\"></a>I. 引言</h1><p>智能交通系统（ITS）是一种重要的交通基础设施，在自动事件检测，智能视频监控，车辆到基础设施，动态交通灯序列等方面有着快速发展[1]。 ITS中涉及许多用户，控制器，演员和操作员。中心或领域中的每个实体直接或间接地改变了商品的流动方式。中心到现场（C2F）通信和中心到中心（C2C）通信使中心系统之间以及中心系统与该中心管理的多个控制或监视设备之间能够进行通信，从而有效地交换控制指令和状态以及交通流量信息[2]。</p>\n<p>但保护ITS是他们为公共交通提供信息服务的基础。发现ITS的脆弱性是保护ITS并使流量畅通的有效方法[3]。 2015年，一则新闻震惊全国，黑客远程控制了一辆吉普车并在高速公路上杀死了它的发动机[4]。作为一种信息系统，ITS将比传统的计算机系统和网络遇到类似甚至更多的网络威胁。在ITS中，C2F通信和C2C通信是两种根本不同类型的交通控制通信，并且已经研究了许多方法来提高通信的安全性[5]。然而，ITS总体上继承了与计算机系统和无线网络相关的固有问题。</p>\n<p>Fuzzing是一种黑盒测试方法，是一种黑盒软件测试技术，已广泛应用于发现通信协议的漏洞。有一些通用的模糊测试框架，如SPIKE [6]和ProtoFuzz [7]，它们不支持ITS应用程序。其他工具如ircfuzz [8]，dhcpfuzz [9]和InfigoFTPStressFuzzer [10]分别用于模糊特殊协议，但没有用于ITS协议漏洞发现的特殊模糊测试工具。</p>\n<p>本文探讨了在实际网络中发现和分析ITS协议漏洞的有效性。各种应用协议可能会导致ITS的风险。本文将研究ITS的安全性，威胁和协议漏洞发现问题。本文的其余部分安排如下：第二部分总结了ITS的ITS通信视图和威胁源。在第III节中，提出了ITS的协议漏洞发现框架及其模糊设计，自动分析和概念验证案例。第四节讨论了这种提议的测试方法的挑战和局限性。最后一节第五节总结了整篇论文</p>\n<h1 id=\"II-通信视图和威胁源\"><a href=\"#II-通信视图和威胁源\" class=\"headerlink\" title=\"II.通信视图和威胁源\"></a>II.通信视图和威胁源</h1><h2 id=\"A-ITS的通信视图\"><a href=\"#A-ITS的通信视图\" class=\"headerlink\" title=\"A. ITS的通信视图\"></a>A. ITS的通信视图</h2><p>协同和智能交通的架构参考（ARC-IT）是ITS的最新参考架构模型[11]。 ARC-IT提供了一个用于规划，定义和集成智能交通系统的通用框架，包括所有连接的车辆应用。它涵盖了国家ITS架构7.1版和互联汽车参考ITS架构（CVRIA）2.2版的所有范围和内容。此体系结构中有企业视图，功能视图以及物理视图和通信视图。特别地，图1中的通信视图描述了提供物理对象之间的互操作性所必需的协议，其提供了保护ITS的一般方式。</p>\n<p><img src=\"/2019/04/22/Remote-Protocol-Vulnerability-Discovery-for-Intelligent-Transportation-Systems-ITS/1.jpg\" alt=\"\"></p>\n<p>在通信视图中，ITS上面的IP协议栈中使用了大量协议。典型的信息层协议包括NTCIP（ITS协议的国家运输通信）系列，ONVIF（开放式网络视频接口论坛）等，应用层协议包括SNMP，STMP，HTTP，FTP，SOAP，C2C XML，DATEX [12] ]， 等等。每个协议都负责ITS中相应类型的应用程序。特别是NTCIP标准为运营运输管理系统的机构提供了更高的灵活性和选择。 NTCIP标准的使用消除了跨机构协调的障碍，并允许不同类型和不同制造商的设备混合在同一通信线路上。例如，NTCIP 1203是用于动态消息标志（DMS）的NTCIP对象定义，ONVIF规范定义了网络客户端和设备之间的通信过程，这使得使用已定义的通用和良好的接口来构建不同制造商的设备和接收器网络视频系统成为可能。</p>\n<h2 id=\"B-ITS的威胁来源\"><a href=\"#B-ITS的威胁来源\" class=\"headerlink\" title=\"B. ITS的威胁来源\"></a>B. ITS的威胁来源</h2><p>除了未经授权的攻击外，还有一些攻击者可能伪装成合法用户。由于有很多用户，谁可以生成数据，在ITS发送消息和接收警报，因此内部攻击将越来越受欢迎。根据通信视图，以下列出了ITS中存在的安全威胁和攻击：</p>\n<ul>\n<li>应用层威胁包括消息重放攻击，消息篡改攻击，恶意消息攻击以及其他人员攻击，欺骗，嗅探和拒绝服务的攻击方式。消息重放攻击意味着攻击者重新发送合法用户最初发送的旧消息，以增加网络流量并导致拥塞。消息篡改攻击意味着攻击者作为中间人修改消息，然后将其发送出去以造成问题或误导用户。恶意消息攻击包括C2F，C2C和V2V通信中的恶意消息攻击，攻击者向网络中的其他节点发送虚假信息;从而误导用户并可能造成严重破坏。</li>\n<li>传输层和网络层威胁包括伪造RSU攻击，拒绝服务，基础密钥泄漏以及其他通信干扰攻击。伪造RSU攻击是获取车辆节点的信息，然后扰乱车辆网络通信。传输和网络层中的拒绝服务是通过临时或无限期地中断连接到车辆网络的节点中的服务来使其预期用户无法使用网络资源。基础密钥泄漏是一种威胁，因为V2V通信中使用的主密钥可能被攻击者嗅探和滥用。</li>\n<li>数据链路层和物理层威胁包括物理损坏，构建障碍和能源干扰。物理损坏是使汽车中的RSU或传感器物理损坏或混乱。建筑障碍是通过设置建筑物，墙壁等障碍物来中断车辆网络的无线信号通信。能量扰动是通过能量和功率控制来干扰车辆网络的无线通信。</li>\n</ul>\n<p>在上述威胁中，中间人攻击可能会危及ITS的机密性。嗅探可能会损害ITS的信息完整性。嗅探和欺骗可能会损害ITS的消息不可否认性。拒绝服务，物理攻击，信号中断和能源干扰可能会影响ITS的可用性。</p>\n<p> 显然，与通信有关的威胁是关键问题，发现协议漏洞和安全协议是ITS安全的基础。除了这些技术威胁之外，ITS还面临着许多安全管理风险，例如操作故障，个人安全设置错误，车辆丢失引起的钥匙泄漏，租车误用等。总之，所有这些威胁和对抗方法都会给ITS带来风险，并大大提高ITS协议漏洞的可能性</p>\n<h1 id=\"III-基于模糊的远程协议漏洞发现的自动框架\"><a href=\"#III-基于模糊的远程协议漏洞发现的自动框架\" class=\"headerlink\" title=\"III.基于模糊的远程协议漏洞发现的自动框架\"></a>III.基于模糊的远程协议漏洞发现的自动框架</h1><h2 id=\"A-漏洞发现框架\"><a href=\"#A-漏洞发现框架\" class=\"headerlink\" title=\"A.漏洞发现框架\"></a>A.漏洞发现框架</h2><p>协议漏洞发现是ITS安全的关键问题。在下文中，我们将介绍基于模糊测试的ITS协议的自动漏洞发现框架。 ITS中的信息层和应用层中有许多协议用于各种功能，服务和场景。 ITS中的所有设备都将与各自的协议进行通信。为了对各种应用层协议和信息层协议（如IETF HTTP，IETP FTP，SOAP，NTCIP系列和ONVIF）进行模糊测试，我们将构建ITS协议漏洞分析的通用框架。</p>\n<p><img src=\"/2019/04/22/Remote-Protocol-Vulnerability-Discovery-for-Intelligent-Transportation-Systems-ITS/2.jpg\" alt=\"\"></p>\n<p>在NTCIP系列中，应用程序级别采用SNMP，STMP，FTP，TFTP，C2C XML，DATEX等。在ONVIF标准中，应用程序级别采用SOAP / HTTP。所有这些应用程序级协议都可以在TCP / IP堆栈上运行。由于ITS中的几乎所有通信协议都在IP网络上工作，因此可以基于IP数据包通信以一般方式构建漏洞发现框架，如图2所示。</p>\n<p>在图2中，ITS的协议漏洞发现框架包括三个组件：数据包捕获，模糊测试生成器和漏洞分析。 Packet Capture组件负责在线捕获软件包并将其输出到Fuzzing Generator组件以进行消息自定义，并将其输出到Vulnerability Analysis组件以发现漏洞。Fuzzing Generator组件负责自定义模糊测试消息，这些消息将发送到ITS中的目标并触发其漏洞。在Fuzzing Generator组件中，ITS，C2F和C2C通信都支持许多应用层协议，如SNMP，STMP，FTP，TFTP，C2C XML，DATEX和SOAP。并且可以使用各种模糊变量（例如静态模糊测试向量，源代码和随机数据）来组成请求模糊消息，这将在第III B节中详细描述。漏洞分析组件负责通过比较和分析来自Fuzzing Generator组件的请求消息和来自Packet Capture组件的响应消息来发现ITS中目标的漏洞。在漏洞分析组件中，机器学习算法，遗传算法和模式识别技术可用于自动发现漏洞以获得更高的效率，这将在第III节C中详细描述。通过使用学习和培训，漏洞分析组件可以构建一个强大的机器学习模型进行分类。通过将响应消息与关联的请求模糊消息进行比较，分类模型可以识别目标设备中的协议漏洞。一旦发现漏洞，模糊测试生成器组件将停止模糊测试，并且漏洞分析组件将存储所有请求模糊消息，模式和响应消息以供进一步验证。</p>\n<p>该协议漏洞发现框架扩展了传统的计算机网络协议测试思想，为发现ITS的协议漏洞提供了一整套功能。通过漏洞分析组件，我们可以解码响应消息来检查关联请求消息的回复，并找出ITS的漏洞。此外，请求模糊消息有时可能会将目标设备堵塞在ITS中。为了确保目标仍然有效，Fuzzing Generator组件应定期运行探测工具，例如ping，以检查ITS中目标的工作状态。</p>\n<h2 id=\"B-漏洞发现中的模糊设计\"><a href=\"#B-漏洞发现中的模糊设计\" class=\"headerlink\" title=\"B.漏洞发现中的模糊设计\"></a>B.漏洞发现中的模糊设计</h2><p>模糊测试是一种有效的信息定制方法，可以发现网络和信息系统中的协议漏洞。生成模糊消息的工作流程如图3所示。在工作流程图中，模糊消息定制是一个关键组件，它将模糊测试数据排列成与测试协议规范兼容的消息。为了自动生成请求模糊消息，可以通过下面详细描述的模糊模式对该过程进行形式化和编程。可以从静态模糊测试向量，随机数据和IP数据包捕获工具获得的源代码导入模糊测试数据。</p>\n<p><img src=\"/2019/04/22/Remote-Protocol-Vulnerability-Discovery-for-Intelligent-Transportation-Systems-ITS/3.jpg\" alt=\"\"></p>\n<p>基于TCP / IP，有一些典型的漏洞发现模糊模式，我们可以在形式化中描述它们，如下所示。</p>\n<ul>\n<li><p><strong>模式1：方法+目标地址+ [标题] + &lt;协议名称&gt; + [数据] + [功能]</strong></p>\n</li>\n<li><p><strong>模式2：方法+目标地址+ [标题] + &lt;随机数据&gt; +数据</strong></p>\n</li>\n<li><p><strong>模式3：[方法] +目标地址+  [标题] + [数据] + [功能]</strong></p>\n</li>\n</ul>\n<p>在模式1，模式2和模式3中，METHOD是自定义请求消息中的操作。它包括GET，POST，PUT，SET，GET-REQUEST，GET-NEXT-REQUEST，SET-REQUEST，GET-RESPONSE，TRAP等，它们在SOAP，SNMP和STMP中使用。 METHOD部分通常可以填充静态模糊矢量。 TARGET ADDRESS指定目标设备，可以是URI，请求ID，IP地址，服务地址等。对于目标设备，TARGET ADDRESS是确定的。 HEADERS包括各种标头信息，例如Accept，Cache-Control，Content-Encoding，Content-Language，Content-Length，Content-Type，Error Status，Error Index等。 HEADERS通常可以从捕获的数据包中填充源代码。 PROTOCOL NAME是经过测试的协议及其版本的名称，例如HTTP / 1.0，HTTP / 1.1等。而PROTOCOL NAME是模式中的可选部分。 DATA指定协议规范下的消息内容，它可以是认证，功能和其他静态文本的全部或部分，通常可以通过在线捕获的数据包填充源代码。RANDOM DATA可以是任何随机字符，可用于模糊认证，功能等。 FUNCTIONS包括协议中的所有可用操作函数，例如GetUsers，CreatUser，GetDeviceInformation，SystemReboot等，它们可以在协议规范下填充静态模糊测试向量。随机数据和函数也可以是DATA的一部分。在所有模式中，方括号[]表示内部变量是静态模糊矢量，而天使括号&lt;&gt;表示内部变量是可选的。</p>\n<p>显然，模式1，模式2和模式3只是请求消息的可用漏洞模糊模式的三个代表，它们适合ITS中的相应模糊测试应用。模式1侧重于通过修改消息数据来发现消息重放和消息修改中的协议漏洞。模式2侧重于通过修改部分消息数据来发现认证信息中协议的漏洞。模式3侧重于通过修改方法（如GET，SET等）来发现协议的漏洞。此外，对于各种协议，根据需要，还可以在模糊消息中使用一些新的模糊化请求消息模式。</p>\n<p>事实上，漏洞模糊测试模式只是抽象了请求消息的关键字符。例如，在模式2中，METHOD，目标地址，若干HEADERS，变量RANDOM DATA和其他DATA组成关键字符向量，其表示具有类似模糊测试模式的一些请求消息。这些关键字符对于自动分析请求消息和响应消息非常有帮助，这将在下面进一步描述。</p>\n<h2 id=\"C-漏洞发现中的自动分析\"><a href=\"#C-漏洞发现中的自动分析\" class=\"headerlink\" title=\"C.漏洞发现中的自动分析\"></a>C.漏洞发现中的自动分析</h2><p>模糊测试后，我们可以通过智能方法比较请求消息和响应消息，如机器学习模型，遗传算法，模式识别等。这是实现自动分析的关键步骤。一些典型的漏洞分析模式包括但不限于以下内容。</p>\n<ul>\n<li><strong>模式4：[请求字符] + [状态代码] -&gt;“通过/失败”</strong></li>\n</ul>\n<p>在模式4中，“请求字符”是请求模糊消息的关键字符。 STATUS CODES是响应消息的状态，例如HTTP状态码，并且可以在摘要中反映模糊消息的结果。 PASS / FAIL是漏洞发现的分类标签。例如，如果STATUS CODE为“200 OK”且REQUEST CHARACTER为“HTTP / 1.1”，则相应的SOAP请求消息可能会发现目标设备上的漏洞，并且漏洞发现的分类标签应为“PASS”。另一方面，如果STATUS CODE是“401 Unauthorized”且REQUEST CHARACTER是模式2，则相应的SOAP请求消息可能不会在目标设备上发现身份验证漏洞，并且漏洞发现的分类标签应为“FAIL”。 STATUS CODE可以通过源代码从在线捕获的数据包或协议规范获得。</p>\n<ul>\n<li><strong>模式5：[请求字符] + [敏感字符] -&gt;“通过/失败”</strong></li>\n</ul>\n<p>在模式5中，“请求字符”是模糊请求消息的关键字符。敏感字符是指响应消息中的敏感信息，例如用户名和执行结果，可以在捕获的数据包的源代码中找到。PASS / FAIL是漏洞发现的分类标签。例如，如果REQUEST CHARACTERS为“HTTP / 1.1”且SENSITIVE CHARACTERS为“&lt;tt：UserLevel&gt; Administrator &lt;/ tt：UserLevel&gt;”，则相应的请求消息可能会在目标设备上发现身份验证漏洞，并且分类标签为漏洞发现应该是“PASS”。另一方面，如果REQUEST CHARACTERS为“HTTP / 1.1”且敏感字符不匹配，则相应的请求消息可能无法在目标设备上发现身份验证漏洞，并且漏洞发现的分类标签应为 “FAIL ”。</p>\n<ul>\n<li><strong>模式6：[请求字符] + [错误字符] -&gt;“通过/失败”</strong></li>\n</ul>\n<p>在模式6中，请求字符是请求模糊消息的关键字符。错误字符是指响应消息中的错误警报或不合理的信息，例如输入文本，未记录的服务等。 PASS / FAIL是漏洞发现的分类标签。例如，如果REQUEST CHARACTERS是“Fuzzing work？”，这是一个有意识的输入字符串，并且响应消息还包含一个ERROR CHARACTERS“Fuzzing work？”，这与我们在请求消息中的输入相同，那么相应的请求消息可能会发现目标设备中的XSS漏洞，并且漏洞发现的分类标签应为“PASS”。相反，如果没有匹配的ERROR CHARACTERS，则相应的请求消息可能不会在目标设备上发现身份验证漏洞，并且漏洞发现的分类标签应为“FAIL”。错误字符可以通过源代码从线上捕获的数据包获得，也可以通过故意输入获得。</p>\n<ul>\n<li><strong>模式7：[请求字符] + [请求超时] -&gt; 通过/失败</strong></li>\n</ul>\n<p>在模式7中，REQUEST CHARACTERS是模糊请求消息的关键字符。 REQUEST TIMEOUT表示响应消息无法在所需时间内到达。 PASS / FAIL是漏洞发现的分类标签。例如，如果请求CHARACTERS是一个SNMP请求，和该请求后请求超时出现时，则对应的请求消息可能发现在目标装置中的拒绝服务（DoS）的脆弱性，以及脆弱性发现的分类标签应该是“PASS” 。相反，如果没有匹配的REQUEST TIMEOUTS，则DoS漏洞发现的分类标签应为“FAIL”。 REQUEST TIMEOUTS可以通过源代码从在线捕获的数据包或协议规范获得。</p>\n<p>在模式4，模式5，模式6和模式7中，方括号[]表示内部变量是静态模糊矢量，它允许构建数据集以定义包含大量值的变量。例如，[REQUEST CHARACTERS]可以是请求消息的字符数据集。通过这些模式，可以创建足够的训练样本并将其用于机器学习模型。经过训练，我们可以使用该机器学习模型自动判断响应并在线请求消息。如果结果是PASS，这意味着请求消息发现漏洞，那么我们可以深入研究漏洞及其漏洞利用工具。实际上，除了这种自动分析方法之外，模式4，模式5，模式6和模式7也可以用于手动响应消息识别。通过这些精心设计的模式和字符，我们可以确定当前设备中是否存在漏洞。</p>\n<p>如上所述，模式4，模式5，模式6和模式7中的请求字符可以是模式1，模式2和模式3的全部或任何部分。并且所有模式为处理请求消息和响应消息提供了良好的参考。 自动实现ITS的漏洞发现。在发现具有漏洞的可疑目标设备后，我们可以进一步分析并找到确切的漏洞地址，然后给出漏洞描述和改进建议。</p>\n<h2 id=\"D-漏洞发现案例\"><a href=\"#D-漏洞发现案例\" class=\"headerlink\" title=\"D.漏洞发现案例\"></a>D.漏洞发现案例</h2><p>在这种情况下，我们将使用第III节中描述的漏洞发现框架对ITS中的ONVIF摄像机进行实际漏洞分析.ONVIF规范与SOA兼容，并且所有设备功能都被抽象为Web服务并使用简单对象访问协议（SOAP）通过HTTP进行通信。不幸的是，SOAP 1.1没有包含签名消息的条款，因此缺乏安全性。因此，我们使用设计良好的SOAP消息来模糊此漏洞所涉及的远程ONVIF设备。</p>\n<p><img src=\"/2019/04/22/Remote-Protocol-Vulnerability-Discovery-for-Intelligent-Transportation-Systems-ITS/4.jpg\" alt=\"\"></p>\n<p>基于上面的漏洞发现框架，我们在真实的网络实验环境中执行漏洞分析。实验场景是交叉路口上方的视频监控应用程序，如图4所示。我们可以访问ITS并访问此ONVIF摄像机，但我们没有摄像机的管理员权限。</p>\n<p><img src=\"/2019/04/22/Remote-Protocol-Vulnerability-Discovery-for-Intelligent-Transportation-Systems-ITS/5.jpg\" alt=\"\"></p>\n<p>为了在框架中实现Fuzzing Generator组件来制作模糊消息，我们使用Python语言开发了一个原型来修改具有与ONVIF规范兼容的各种功能的实际消息，然后将自定义消息发送到实际网络中的测试相机。真实的消息由Wireshark工具在线捕获。我们使用模式1作为自定义请求消息的参考，字符及其值如表I所示。因此，根据模式1，METHOD是POST，TARGET ADDRESS是摄像机IP地址，HEADERS是典型的HTTP标题和PROTOCOL NAME是HTTP / 1.1，DATA专注于从真实消息解码的认证信息，而FUNCTIONS是功能向量，包括Getusers，CreatUser，GetDeviceInformation，SystemReboot等。 Fuzzing Generator原型可以向ONVIF摄像机保留模糊消息，所有这些请求消息都存储在数据库中以供进一步分析。自定义请求消息之一如下。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;soap:Envelope</span><br><span class=\"line\">xmlns:soap=&quot;http://www.w3.org/2003/05/soap-envelope&quot;</span><br><span class=\"line\">xmlns:tds=&quot;http://www.onvif.org/ver10/device/wsdl&quot;</span><br><span class=\"line\">xmlns:tt=&quot;http://www.onvif.org/ver10/schema&quot;&gt; &lt;s:Header</span><br><span class=\"line\">xmlns:s=&quot;http://www.w3.org/2003/05/soap-envelop</span><br><span class=\"line\">&lt;wsse:Security xmlns:wsse=&quot;http://docs.oasisopen.org/wss/2004/01/oasis-200401-wss-wssecurity-secext-1.0.xsd&quot; xmlns:wsu=&quot;http://docs.oasis-open.org/wss/2004/01/</span><br><span class=\"line\">oasis-200401-wss-wssecurity-utility-1.0.xsd&quot;&gt;</span><br><span class=\"line\">&lt;wsse:UsernameToken&gt;</span><br><span class=\"line\">&lt;wsse:Username&gt;username&lt;/wsse:Username&gt;</span><br><span class=\"line\">&lt;wsse:Password Type=&quot;http://docs.oasisopen.org/wss/2004/01/oasis-200401-wss-username-tokenprofile-</span><br><span class=\"line\">1.0#PasswordDigest&quot;&gt;keys&lt;/wsse:Password&gt;&lt;wsse:Nonce&gt;k</span><br><span class=\"line\">eys&lt;/wsse:Nonce&gt;</span><br><span class=\"line\">&lt;wsu:Created&gt;time&lt;/wsu:Created&gt;</span><br><span class=\"line\">&lt;/wsse:UsernameToken&gt;</span><br><span class=\"line\">&lt;/wsse:Security&gt;</span><br><span class=\"line\">&lt;/s:Header&gt;</span><br><span class=\"line\">&lt;soap:Body&gt;</span><br><span class=\"line\">&lt;tds: Getusers /&gt;</span><br><span class=\"line\">&lt;/soap:Body&gt;</span><br><span class=\"line\">&lt;/soap:Envelope&gt;</span><br></pre></td></tr></table></figure>\n<p>在这种情况下，自动漏洞分析组件使用模式4实现。模式4中的参数及其值如表II所示。因此，根据模式4，REQUEST CHARACTERS是模式1，一旦响应消息的STATUS CODE为“200 OK”就会出现PASS。为了简化漏洞分析过程，我们使用模式识别来演示此步骤。我们在线捕获响应数据包并检查其状态代码，并将所有响应数据包存储在数据库中，以便与其请求消息进行相关性分析。与上述请求消息相关联的响应消息之一如下所示。</p>\n<p><img src=\"/2019/04/22/Remote-Protocol-Vulnerability-Discovery-for-Intelligent-Transportation-Systems-ITS/6.jpg\" alt=\"\"></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">HTTP/1.1 200 OK</span><br><span class=\"line\">Date: Wed, 28 Mar 2018 14:05:02 GMT</span><br><span class=\"line\">Server: App-webs/</span><br><span class=\"line\">Connection: close</span><br><span class=\"line\">Content-Length: 2300</span><br><span class=\"line\">Content-Type: application/soap+xml; charset=utf-8</span><br><span class=\"line\">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span><br><span class=\"line\">&lt;env:Envelope xmlns:env=&quot;http://www.w3.org/2003/05/soapenvelope&quot; …&gt;&lt;env:Body&gt;&lt;tds:GetUsersResponse&gt;&lt;tds:User</span><br><span class=\"line\">&gt;&lt;tt:Username&gt;admin&lt;/tt:Username&gt;</span><br><span class=\"line\">&lt;tt:UserLevel&gt;Administrator&lt;/tt:UserLevel&gt;</span><br><span class=\"line\">&lt;/tds:User&gt;</span><br><span class=\"line\">&lt;tds:User&gt;&lt;tt:Username&gt;user6&lt;/tt:Username&gt;</span><br><span class=\"line\">&lt;tt:UserLevel&gt;User&lt;/tt:UserLevel&gt;</span><br><span class=\"line\">&lt;/tds:User&gt;</span><br><span class=\"line\">&lt;/tds:GetUsersResponse&gt;</span><br><span class=\"line\">&lt;/env:Body&gt;</span><br><span class=\"line\">&lt;/env:Envelope&gt;</span><br></pre></td></tr></table></figure>\n<p>上面的响应消息回复状态代码“200 OK”，这意味着根据模式4，其请求消息触发了漏洞。实际上，经过测试的ONVIF摄像机会错误地响应管理员用户。在请求消息和响应消息中进行分析后，我们发现测试的摄像机存在ONVIF认证漏洞，漏洞位置是SOAP标头中的标识认证片段。由于它是ONVIF协议中的致命漏洞，因此我们还可以通过使用此框架对相机的云台变焦和录制服务进行模糊处理时发现类似的现象。从这个案例中，我们可以发现第III节A中提出的漏洞发现框架可以有效地远程发现ITS的协议漏洞。</p>\n<h1 id=\"IV-测试方法的挑战和限制分析\"><a href=\"#IV-测试方法的挑战和限制分析\" class=\"headerlink\" title=\"IV.测试方法的挑战和限制分析\"></a>IV.测试方法的挑战和限制分析</h1><p>协议漏洞发现框架提供了一种通过请求模糊消息来查找ITS及其设备的协议漏洞的方法。但是仍然存在许多安全问题，例如社会工程威胁，结构脆弱性，能量干扰物理层中的电源中断等等。在这种情况下，ITS不仅应该通过通信视图中的协议测试进行分析，还要检查系统级和物理视图。<br>随着ITS应用的发展，应用协议将来会越来越多，因此将不同的消息定制协议组合到一个框架中将是一个挑战，需要在框架中用新的协议栈模块扩展第三节A中的框架。</p>\n<h1 id=\"V-结论\"><a href=\"#V-结论\" class=\"headerlink\" title=\"V.结论\"></a>V.结论</h1><p>协议漏洞发现是保护ITS本身的关键问题。由于ITS在公共交通中公开广泛部署，越来越多的攻击和威胁会极大地影响ITS的可用性并损害其完整性和机密性，甚至使道路交通比以前更加糟糕。本文从ITS通信的角度提出了ITS威胁的分类，为ITS协议漏洞发现提供了良好的指导。接下来，提出了一种协议漏洞发现框架，用于通过使用模糊消息定制和自动分析来保护ITS，其支持机器学习算法，遗传算法和模式识别技术。最后，还给出了关于ITS中ONVIF协议漏洞的选定概念验证案例，以证明所提议的协议漏洞发现框架的有效性和实用性。可以在丰富可用的请求消息模式和漏洞分析模式以及扩展协议栈模块方面做进一步的工作，以提高协议漏洞发现框架对更多协议的能力。</p>\n","categories":[{"name":"论文","slug":"论文","permalink":"http://yama0xff.com/categories/论文/"},{"name":"fuzzing","slug":"论文/fuzzing","permalink":"http://yama0xff.com/categories/论文/fuzzing/"},{"name":"机器学习","slug":"论文/fuzzing/机器学习","permalink":"http://yama0xff.com/categories/论文/fuzzing/机器学习/"}],"tags":[{"name":"fuzzing","slug":"fuzzing","permalink":"http://yama0xff.com/tags/fuzzing/"},{"name":"机器学习","slug":"机器学习","permalink":"http://yama0xff.com/tags/机器学习/"}]},{"title":"Automatic Text Input Generation for Mobile Testing","date":"2019-04-19T03:41:06.000Z","path":"2019/04/19/Automatic-Text-Input-Generation-for-Mobile-Testing/","text":"Abstract已经提出许多设计来改进自动化移动手机测试。尽管有这些改进，但提供适当的文本输入仍然是一个突出的障碍，这阻碍了大规模采用自动化测试方法。关键的挑战是如何在用例上下文中自动生成最相关的文本。例如，应在移动浏览器应用程序的地址栏中输入有效的网站地址，以继续测试应用程序;应在音乐推荐应用的搜索栏中输入歌手的姓名。如果没有正确的文本输入，测试将会卡住。我们提出了一种新颖的基于深度学习的方法来应对挑战，将问题简化为最小化问题。另一个挑战是如何使该方法通常适用于受过训练的应用程序和未经训练的应用程序。我们利用Word2Vec模型来应对挑战。我们已经将我们的方法构建为工具，并使用包括Firefox和Wikipedia在内的50种iOS移动应用程序对其进行评估。结果表明，我们的方法明显优于现有的自动文本输入生成方法。 relevant information 作者 Peng Liu, Xiangyu Zhang, Marco Pistoia, Yunhui Zheng, Manoel Marques and Lingfei Zeng 单位 IBM T. J. Watson Research Center, Yorktown Heights, New York, USA 出处 2017 IEEE/ACM 39th International Conference on Software Engineering 原文地址 https://dl.acm.org/citation.cfm?id=3097445 源码地址 https://github.com/dkhamsing 发表时间 2017年 I. 简介移动设备已成为我们生活中不可或缺的一部分。移动应用程序是提供各种便捷和高质量服务的工具，例如网页浏览，娱乐，交通信息辅助，银行和社交网络。为了满足日益增长的需求，移动市场正以每天1000多个新应用的速度快速增长[1] [6]。因此，开发团队一直处于激烈的竞争中，在发布截止日期前面临巨大的压力。遗憾的是，这通常会导致移动应用程序中的错误，例如运行时应用程序崩溃，UI设计中的缺陷以及未完全实现的功能。 移动测试的目标是在应用程序发布之前发现它们中的错误。有两种主流的移动测试方法：手动测试和自动monkey测试。在手动测试中，测试人员手动执行操作以尽可能多地运用用例。这种方法的缺点是需要大量的人力，因为测试人员需要在整个测试期间与应用程序密切交互。此外，通常专注于演示常见用例中的功能的人类测试人员可能经常会错过可能触发异常的极端情况。 自动化monkey测试[8]，[28]，[18]，[19]，[37]，[21]，[20]，[24]，[27]被提议用于减少人类的努力并最大化用例覆盖率。 “monkey”是描述这种测试如何运作的隐喻;像monkey一样，该工具执行随机动作序列，包括单击UI视图（或UI屏幕）上的按钮并执行随机击键。为了涵盖尽可能多的动作序列，研究人员提出了各种新颖的搜索算法，与monkey随机搜索策略形成对比。尽管有这些改进，但在monkey测试期间提供适当的文本输入仍然是一个突出的障碍，这阻碍了monkey测试方法的大规模采用。在许多用例中，大多数现有技术很难提供有意义的文本输入。例如，对于电影应用程序，monkey测试几乎无法提供有意义的输入，例如星际迷航。相反，它会产生不相关的输入，如4t6。因此，没有找到任何结果，从而使Monkey无法前往显示适当结果的屏幕。手动规范可以缓解这个问题，但需要大量的人力。 在本文中，我们提出了一个解决方案，让Monkey自动生成相关的文本输入。有了这样的输入，Monkey可以通过长动作序列进入工作流深处的UI屏幕（简称深UI屏幕），而不是一开始就卡住。一旦它到达深度UI屏幕，Monkey可以应用其他面向bug披露的测试技术，例如基于搜索的测试[26]，符号测试生成[22]，甚至是随机测试[34]来识别复杂工作流中的错误。 A.生成相关输入输入生成的关键要求是生成与上下文相关的输入。$$Movie -&gt; search -&gt; star trek$$ $$Weather -&gt; search -&gt; New York$$ 在用例1中，在单击标记为“电影”的菜单项并且触发了标记为“搜索”的搜索栏后，应用程序将需要用户的电影标题。因此，输入星际迷航是相关的;在用例2中，单击标记为“天气”的菜单项并触发标记为“搜索”的搜索栏后，应用程序将使用该用户的城市名称。因此输入纽约是相关的。相反，在一个上下文中相关的输入可能在不同的上下文中不相关。例如，单击菜单项Weather时，输入Star Trek将不合适。我们还在第七节中将读者引用到更真实的例子中。 挑战。上述要求对自动文本输入生成提出了很大的挑战。首先，相关性特定于自然语言语义，只有人类测试者才能理解。因此，传统的自动输入生成方法，例如基于符号执行的测试[22]，是不适用的。其次，包含确定相关文本输入的信息的动作（例如，点击菜单项电影或天气）可能不会立即在动作序列中的输入动作之前。因此，维护和查找文本输入与紧接在先行动的信息之间的映射是一种难以奏效的方法。 我们的深度学习方法。我们提出了一种新颖的基于深度学习的方法来解决上述挑战。在高层次上，我们的解决方案包括两个阶段：在训练阶段，monkey学习测试人员的手动输入并统计地将他们与上下文相关联，例如行动历史和文本框标签;在预测阶段，monkey根据观察到的上下文自动预测文本输入。我们的方法的核心是递归神经网络（RNN）模型。这种类型的模型在许多自然语言处理（NLP）应用程序中取得了巨大成功，例如机器翻译和输入法自动完成。以输入法自动完成为例，RNN模型将单词之间的语义连接量化为非线性函数，其中参数用大的文本语料库进行训练。给定一个词，非线性函数计算其旁边的单词的概率分布，然后从分布中采样下一个单词。此外，RNN模型保持存储器状态以汇总来自先前单词的重要信息，并在推荐下一单词时将其用作另一输入源。据我们所知，我们是第一个将深度学习应用于自动测试移动设备的文本输入生成问题的人。 根据Mikolov等人的实证研究 [32]，RNN模型比传统的统计模型（如n-gram模型和隐马尔可夫模型）更精确。具体而言，与传统模型相比，RNN导致18％的误差减少，假设它们在相同的数据上训练，并且即使传统模型训练的数据比RNN模型多5倍，也导致12％的误差减少。 B.与应用无关的输入生成输入生成的另一个重要要求是应用独立性。这意味着在一组应用程序上训练的RNN模型也应该适用于其他应用程序。 挑战。在不同的应用程序中使用不同的单词来表示相同的概念对应用程序独立性提出了重大挑战。$$Film -&gt; search -&gt; ?$$假设在训练阶段没有看到标签Film。人类测试人员可以很容易地找出用例1中标签movie和film之间的语义相似性。因此，我们可以预测相关的文本输入 - 例如，星际迷航。然而，RNN模型完全忽略了标签film，因为它没有出现在训练阶段。因此，RNN模型无法预测标签Film的相关文本输入。 我们基于Word2Vec的解决方案。我们通过从Google新闻语料库统计学习同义词的人类知识来应对挑战。同义词存储在等价类中。每个等价类的代表用于替换训练和预测期间属于该类的单词。 我们的方法建立在Word2Vec模型的基础上，这是NLP研究人员最近提出的统计模型。该模型将一个单词映射到一个向量，向量之间的距离测量单词的相似性。 Word2Vec模型通过求解优化问题来学习矢量编码。具体而言，它最小化相似单词之间的距离，并最大化不相关单词之间的距离。 Word2Vec是一种无监督学习算法，这意味着它不需要手动标记训练数据。Word2Vec在结果质量方面优于其他现有模型[33]。这主要是因为Word2Vec可以训练比先前工作多2到3个数量级的数据，而这只是之前工作所需时间的一小部分。 我们已经构建了一个工具，并使用50个iOS应用程序对其进行评估，包括Firefox和Wikipedia等热门应用程序。评估结果证实了我们的方法的有效性。 RNN预测平均将Monkey测试的覆盖率提高了21％，而RNN模型和Word2Vec模型的组合将覆盖率提高了28％。此外，如果我们排除基准套件中可用UI屏幕很少的简单应用程序，我们发现RNN预测可将覆盖率提高46％，两种模型的组合可提高60％。同样重要的是，我们的预测非常有效，通常在1毫秒内完成。 总之，我们在本文中做出以下贡献： 我们提出了一种基于深度学习的新方法，以自动生成移动UI测试的相关文本输入。 我们提出了Word2Vec NLP模型的新颖组合，以及使输入生成应用独立的学习。 我们已将我们的方法作为一个系统实施，并对包括Firefox和Wikipedia在内的50个iOS应用程序进行了实验。结果表明，我们的方法显着增加了Monkey测试的覆盖范围。 II.系统设计概述系统设计如图1所示。monkey测试引擎通过单击屏幕上的按钮来探索移动应用程序。当遇到文本框时，它会从文本输入服务器请求相关输入，如1、2所示。服务器通过进一步将其分派给人工测试人员或RNN运行实例来解析请求，该实例对应于两种模式：手动模式和AI模式。在手动模型中，在收到帮助请求3后，人工测试人员可以输入与上下文相关的文本输入4。如果她认为上下文不符合实际中的任何动作序列，则忽略它。然后，由测试者录入的输入和相应的上下文记录在与服务器相关联的数据库中。在AI模式中，我们首先使用记录在数据库5中的训练数据集训练RNN模型，之后RNN实例可以自动预测文本输入6。 在预测阶段6中，Monkey利用RNN模型来预测给定上下文中的文本输入值。基本上，考虑到Monkey测试引擎维护的上下文，模型预测文本输入值。但是，由于我们预测输入的应用程序与我们训练模型的应用程序不同，因此RNN模型可能无法识别Monkey测试期间遇到的某些上下文信息。为了解决这一挑战，我们使用Word2Vec模型改进了RNN模型，该模型有助于识别语义相似的上下文，尽管它们具有不同的句法形式（例如，“moive”和“film”）。通过RNN模型和Word2Vec模型的新颖组合，我们有效地解决了这个问题。 在下文中，我们首先介绍第III节中的背景，然后解释我们如何应用深度学习技术来自动预测第IV节中的文本输入。在第五节中，我们将解释实现细节。在第六节中，我们讨论了这项工作的假设。第七节介绍评估结果。 III. 背景深度介绍本节介绍了递归神经网络（RNN）和Word2Vec的背景。 RNN和Word2Vec都是神经网络的特殊形式。为了讨论这两个，我们首先要简要介绍一下神经网络。 神经网络（NN）有两种形式：图形形式和数学形式。在图形形式（图2a）中，NN具有输入层，输出层，一个或多个隐藏层。每个层（输入层除外）包括多个神经元，它们与前一层和下一层中的神经元相连。 每个神经元，如图2b所示，是一个基本的计算单元。它首先将沿着传入边传递的值线性组合为∑ ~i~ p~i~x~i~ + b，其中p~i~和b是要训练的参数。然后它应用激活函数f~a~，例如tanh函数[12]或sigmoid函数[11]。激活函数对于使神经元非线性非常重要。没有激活函数，神经元仅仅是线性函数，神经网络也是线性函数，不能表征许多复杂模型。 在数学形式中，NN是由神经元代表的函数的组合。设f：R^n^→R^m^表示由神经网络表示的复合函数。设输入向量I∈R^n^表示输入层中n个神经元的输入。设输出向量O∈R^m^表示输出层中m个神经元的输出。神经网络的训练可以被视为一个优化问题： 更新参数以最小化预测输出和训练数据集上的实际输出之间的总损失，其中损失函数可以被定义为距离或其他形式。无论损失函数的复杂性如何，梯度下降算法[16]通常用于最小化其值。 A.递归神经网络 RNN是一种特殊形式的神经网络，具有反馈回路，如图3所示。为清楚起见，我们使用箭头来表示神经元之间的连接。 循环允许在网络执行步骤中导出的信息传递到下一个，类似于人类的长期记忆。图4显示了概念上展开的版本，其中神经网络在概念上被复制以通过多个步骤服务于一系列输入。 注意神经网络副本之间的连接。 RNN考虑输入法自动完成的应用，我们应用RNN生成句子“how are you doing”。这些单词一个接一个地输入到输入层。每个字在单热矢量表示中被编码以使得能够学习，例如，单词“how”被编码为[1,0,0,0]。简单地说，向量的每个条目对应于词汇表中的单词（[“how”，“are”，“you”，“doing”]），向量中值1的位置表示编码的单词。从概率的角度来看，向量表示具有100％概率的单词，而其他概率表示具有0％概率的单词。 利用初始参数设置，给定输入字与从最后一步传递的信息相结合，神经网络输出概率向量，其中第i个条目估计词汇表中的第i个单词接下来出现的概率。例如，基于输入“how”，假设它将下一个词预测为[0.4,0.2,0.1,0.3]，即，最可能的下一个词是“how”。但是，我们从训练数据集中观察到下一个单词应该是“are”。因此，训练算法需要更新参数，使得单词“are”的预测概率变得显着大于其他单词。同样，给定“are”这个词，神经网络需要预测“you”作为下一个词的概率高于其他词。 B.Word2VecWord2Vec算法学习空间R^k^中每个单词的向量表示，其中相似的单词可能具有相似的向量。 Word2Vec通常应用于非常大的语料库。为了获得更好的可扩展性，Word2Vec采用传统的神经网络结构。 Word2Vec采用的矢量表示与上述RNN中使用的单热表示明显不同。 Word2Vec将每个单词映射到空间R^k^中的实值向量，其中k远小于词汇量s，而单热表示将每个单词映射到空间{0,1}^s^中的向量。首先，通过在低维空间中编码矢量，Word2Vec降低了计算的空间复杂度。更重要的是，Word2Vec的矢量表示处于连续空间中，并且两个矢量之间的距离（即，余弦相似距离）有效地测量了单词的相似性。相反，单热表示不能测量相似性。在我们的工作中，我们将Word2Vec视为黑盒子。 IV.将深度学习应用于输入生成在高级别，我们的方法在统计学上学习文本输入值与训练阶段的上下文之间的相关性（第IV-B节）。然后是预测阶段（第IV-C节），一旦Monkey需要在文本框中提供某些值，我们的方法就会根据Monkey目前观察到的上下文来预测值。第IV-D节进一步解释了我们如何推广输入生成以使其独立于应用程序。为便于讨论，我们首先介绍在训练阶段使用的训练数据集（第IV-A节）。 A.训练数据集在不失一般性的情况下，我们假设简化的用户行为模型。在模型中，我们只对两种类型的UI元素感兴趣：按钮和文本框∈domain T~ui~。各种可点击的UI元素（如菜单和tableview单元格）具有类似于按钮的行为，因此在我们的模型中具有相同的抽象。类似地，接受用户输入的一系列文本字段（例如安全文本字段和搜索字段）被抽象为文本框。请注意，我们的实现完全支持所有这些UI元素。我们只对两种类型的动作感兴趣，tap和typeText∈T~action~，它们是UI元素∈T~ui~的最具代表性的行为。 用户动作α∈A是一个元组，包括UI元素类型τ~ui~∈T~ui~，动作类型τ~action~∈T~action~、显示在UI元素中的标签 δ（例如，图5中的按钮中的“Moive”），以及在动作中涉及的可选值v，例如文本输入值。 训练数据集基本上记录了动作序列（α~0~，α~1~，…. ，α~n~），其中α~i~表示在第i步的用户动作。 α~n~之前的子序列指的是用户到达发生α~n~的UI屏幕所采取的动作。有关动作序列的更多细节将在第VI节中讨论。 我们观察到标签δ是用户在使用应用程序时所感知的最突出的信息，考虑提供什么作为输入值。基于这种观察，我们用动作序列中的每个动作α表示标签δ~α~，同时抽象掉所有其他信息。此外，我们还对在动作α~n~中输入的输入值v~αn~感兴趣。因此，上述动作序列简单地表示为（δα~0~，δα~1~，…. ，δa~n~，va~n~ ）.为了便于演示，我们还提到δα~0~，δα~1~，…. ，δa~n~作为输入值vα~n~的上下文。 考虑图5中的示例，假设测试人员执行操作以触发UI屏幕转换并输入输入值。在第一个屏幕中，测试人员点击（或点击）标有“Moive”的按钮，通向第二个屏幕，搜索栏标有“搜索”。在第三个屏幕中，测试仪在搜索栏中输入输入值“Star Trek”。在用户操作模型之后，我们有两个操作：单击带有标签Movie的按钮，然后在搜索栏中输入带有标签Search的“Star Trek”。因此，记录的序列是“Moive”，“search”，“star Trek”。 B.训练阶段不失一般性，我们假设每个标签δ或输入值v是单个单词，而不是短语。第VI节介绍了一种确保假设的简单预处理。 设Vocabulary V =L∪Val表示训练数据集中出现的所有标签和输入值的列表。在下文中，除非另有说明，否则我们不区分标签和输入值。相反，我们用一般术语词来引用它们。 为了实现学习，我们提出了每个单词的以下向量表示。给定单词ω，其矢量形式ω‘具有与词汇相同的大小。并且向量的每个条目被定义为， 因为只有一个条目可以取值1，所以向量表示也被称为单热表示。考虑图4.在步骤2，输入向量为[0,1,0,0]，如输入层所示。 在每个步骤，RNN模型接受单词的向量表示作为输入。输入以及隐藏层的先前状态（也被编码为矢量）用于预测输出，该概率矢量表征序列中接下来出现的每个单词的概率。训练的目标是更新RNN模型的参数，使得下一个词的预测概率分布接近从数据集观察到的真实概率分布。 我们将训练正式化为优化问题： 给定上下文δα~0~，δα~1~，….，δa~n~，我们找到具有最大条件概率的输入值vα~n~= x。在训练阶段，我们建立一个RNN模型来预测条件概率。自动计算模型的内部参数，以使预测的概率分布近似于从训练数据集中观察到的真实概率分布。然后，在假设上下文与文本框的输入值之间的概率关联没有显着改变的情况下，将训练的模型用于预测。我们在网站上解释了有关形式化的更多细节[4]。 C.预测阶段训练模型后，可以将其用于预测。通常，RNN模型接受一系列单词作为输入，并输出概率向量，该概率向量表征词汇表中的每个单词紧接在序列之后出现的概率（我们称之为下一个单词）。概率分布的采样将选择具有分布中描述的概率的单词。 在我们的问题设置中，当Monkey遇到文本框时，它会将动作历史记录和文本框的标签序列化为序列，然后将序列发送到训练模型以预测下一个单词的概率分布。最后，它对概率分布进行采样以获得下一个单词的值。 通常，词汇表中的任何单词都可以是下一个单词。词汇表中的单词可以对应于动作标签，文本框标签或文本输入值，但我们只对预测文本输入值感兴趣。如果采样结果不表示文本输入值（即，它不属于文本输入值的词汇表），我们将其丢弃并重新对分布进行采样。 对概率分布进行采样的想法如下。令o’ 表示RNN模型的输出向量，其表征概率分布。我们首先将0到1之间的范围分成| o ‘|间隔。区间i（0 ≤ i &lt;| o ‘|）从开始并以结束。均匀随机变量X~U（0,1）落入具有概率o’ [i]的区间，即区间的长度。换句话说，均匀随机变量X落入区间i的概率与我们选择单词＃ - V [i]的概率相同。因此，如果随机变量落入区间i，我们返回单词V’ [i]。 请考虑以下示例。假设输出概率向量为[0.1,0.7,0.1,0.1]，如图4所示。图6显示了四个间隔。假设均匀随机变量的值为0.5，则它落入区间1（注意区间为0）。因此，我们返回单词V’ [1]，即单词“are”。 D.独立于应用程序的输入生成我们的最终目标是预测我们尚未接受过训练的应用程序的输入。主要挑战是使输入生成应用独立。 我们的想法是，如果我们遇到一个在训练阶段没有看到的单词，我们可以将它连接到在训练阶段看到的一些类似的单词，利用Word2Vec。我们使用预先使用非常大的Google新闻语料库训练的Word2Vec模型。当遇到不在词汇表中的单词时，例如，在训练期间没有出现在任何应用程序中的文本框标签时，我们的系统会查询Word2Vec以查找词汇表中最相似的单词（更确切地说，词汇表动作标签和文本框标签）。如果可以从两个单词的矢量表示计算的相似度低于预设阈值0.7，则我们认为该单词在训练数据集中没有对应物并且在预测期间简单地忽略它。在最坏的情况下，如果这个词在确定文本输入值时很重要，那么我们的技术就会降低到传统的Monkey测试。这些情况的发生主要是因为应用程序属于一个与我们训练过的应用程序类型非常不同的新类别。 V.实现我们在第II节中介绍了系统设计的概述。在本节中，我们将解释图1中所示的每个组件的实现细节。 a）Monkey测试引擎：我们的monkey在探索动作序列时采用深度优先搜索策略，即在填充当前屏幕中所有文本框元素的值之后逐个点击可用按钮。可以以随机顺序或以某种顺序（例如，按钮标签的字母顺序）单击同一屏幕内的按钮。我们实现了两个选项并在我们的实验中采用了随机顺序。另外，为了避免重复探索同一个屏幕，我们构建了每个屏幕的签名，其中包括屏幕标题和屏幕中按钮的标签。具有相同签名的屏幕被视为同一屏幕，仅被探索一次。 请注意，除文本输入外，我们的系统还可以轻松扩展以预测下一步操作。然而，我们认为这会不利地限制Monkey实现良好覆盖的能力，因为它往往会跟随人类测试者的动作序列，这些动作序列是有限的。因此，我们系统的一个重要设计原则是使用随机探索动作和RNN预测文本输入。 我们使用Xcode IDE附带的测试自动化框架XCTest实现了iOS Monkey。该框架提供了一组API [9]，允许我们在屏幕中找到按钮或文本框元素。例如，我们可以使用以下API调用轻松找到当前屏幕中的所有按钮： descendantsMatchingType（.Button） b）文本输入服务器：使用python web框架Bottle [2]实现的文本输入服务器是一个隐藏了如何生成输入的详细信息的抽象层。由于它是用Python实现的，而Monkey测试引擎是在Swift中实现的，因此两个组件之间存在编程语言障碍。为了打破障碍，他们通过以JSON格式发送HTTP消息来相互通信。输入服务器通过函数调用与RNN实例通信，因为它们都是用Python实现的。此外，我们为输入服务器维护了一个数据库，用于存储人类测试人员在某些上下文中输入的输入。我们采用了MongoDB [7]。输入服务器使用Python驱动程序PyMongo [10]与数据库交互。 c）RNN实例：我们在Python深度学习框架Tensorflow [13]之上构建了RNN模型，它提供了高级API，同时隐藏了许多低级细节。通过Tensorflow的抽象，可以使用仅40行代码构建RNN模型，如我们的网站[3]所示。我们通过首先使用Word2Vec预处理数据集然后将它们输入RNN模型来训练模型。此外，经过训练的RNN模型可以保存到磁盘上并随时加载以供进一步使用。 VI.讨论在本节中，我们将讨论我们在这项工作中所做的假设。我们在训练/预测中做出的假设是标签或输入值是单个单词，而不是短语或句子。如果标签确实是一个短语，我们将其分解为单词并将每个单词视为单独的标签上下文。通过在单词级别推理，只要其中的单词属于我们的词汇表，我们的方法就可以处理任何短语。相反，对于作为短语的文本输入值，我们将短语视为原子单位，以便在整个训练和预测期间不对它们进行分区。 我们的方法的另一个重要假设是我们训练Monkey的应用程序和Monkey将测试的应用程序应该分享一些相似性，例如，它们属于App市场上的相同类别。否则，如果我们在娱乐应用程序上训练Monkey并将其应用于测试Tax应用程序，那么预测的文本输入将毫无意义。为了避免这种情况，我们收集尽可能多的不同类型的应用程序，并将它们用作训练主题。 在我们的方法中，我们假设上下文仅包含文本标签。在真实世界的应用程序中，开发人员可能会使用图标而不是文本标签。我们目前不支持非文字标签。我们注意到我们的方法可以扩展到支持非文本标签，例如，利用image2text工具[14]。 当我们记录动作序列时，我们维护一个列表并将每个动作附加到列表中。但是，如果我们遇到撤消上一个操作的操作，我们会放弃操作并从列表中删除上一个操作;如果我们遇到导致应用程序主屏幕的操作，我们只需清除列表即可。最后，我们的工作补充了自动行动序列生成的大量最新进展[28]，[24]，[27]。虽然我们期待很大的协同作用，但我们将把它留给我们未来的工作。 七.评估在我们的实验中，我们对以下研究问题感兴趣： 与其他用于移动测试的自动输入生成方法相比，我们的自动化方法的效果如何？ 与仅使用RNN模型相比，Word2Vec是否允许更好的结果？ 我们的工具产生的性能开销是多少？ 为了解决第一个问题，我们与自动随机输入生成方法进行比较，该方法从常用输入值池中随机选择[30]输入值。 我们通过计算屏幕覆盖率来测量有效性，即，在固定时间窗口内已经探索了多少不同的UI屏幕。通常采用monkey测试来探索尽可能多的用例。但是，识别独特的用例需要领域知识。相反，我们使用屏幕覆盖来客观地估计用例覆盖范围。 请注意，屏幕覆盖范围与功能测试中的经典覆盖标准（例如，语句覆盖率和路径覆盖率）不同。我们认为两者都很重要。特别是，我们的方法补充了功能测试，因为通过提供有意义的输入值，我们的技术允许Monkey访问有趣的UI屏幕。从这样的UI屏幕开始，可以应用现有的功能测试工作来暴露应用程序崩溃。此外，我们认为一些UI屏幕很有趣，即使它们与任何应用程序崩溃都不对应。我们将读者引用到我们的网站[5]以获取此类示例。 请注意，我们的方法与自动事件序列生成方法正交。在这项工作中，我们采用现有的深度优先搜索策略。我们的贡献主要在于根据上下文生成相关的文本输入，并容忍在不同的应用程序中使用不同的单词。 为了解决第二个研究问题，我们比较了仅启用RNN的版本以及启用了RNN和Word2Vec的版本。第VII-B节通过将三个版本比较在一起来解决上述两个问题。 最后，性能开销很重要，特别是考虑到在Monkey测试期间交互式预测。理想情况下，该方法应该以低性能开销实现有效性。性能的测量见第VII-A节。 a）实验设置：我们在OS X EI Capitan的MacBook Pro上进行实验。 iOS应用程序在iPhone 6S Plus（iOS 9.2）的模拟器中运行。我们从Github收集了200个开源iOS应用程序，主要来自https：//github.com/dkhamsing/open-source-ios-apps。它们分为不同的类别，包括电影，新闻，图像，浏览器，旅行，广播，日历，天气和任务。它们包括流行的应用程序，如Firefox和维基百科。我们对150个应用程序进行了训练，并测试了其余50个应用程序的预测功能。 我们的训练数据集共包含14061个单词。当我们收集训练数据集时，我们尝试尽可能多地重用输入值。例如，当我们需要在不同的应用程序中输入电影名称时，我们会坚持使用相同的电影名称。 A.性能开销学习/训练过程需要多次迭代。我们用于预测的模型训练了6个小时，但我们在更短的时间内测量了性能。我们测量每1000次迭代的计算时间并报告迭代的平均时间。我们还使用每1000次迭代后生成的模型，使用数据集中的随机序列预测下一个单词。这是为了抽样模型的准确性。我们还测量RNN模型用于训练和预测的时间。如图7所示，除初始步骤外，训练/预测时间保持不变。这是因为每次迭代处理固定数量的数据，并且神经网络结构不会动态变化。另一个重要的观察是每个预测平均需要0.7毫秒，与测试中的其他操作相比可以忽略不计（例如，输入文本） 我们还测量了Word2Vec模型的加载时间以及每个查询类似单词的时间。加载大约需要54秒，而每次查询大约需要0.7毫秒。由于空间限制，我们不显示数字。加载时间很长，因为模型很大，在Google新闻语料库中训练有30亿个运行单词。我们的文本输入服务器通过在服务器初始化期间加载模型来解决此问题。加载后，该模型可用于所有传入的查询。 B.我们方法的有效性为了衡量有效性，我们比较了三个版本：（1）随机，随机从常用输入值池中选取一个值。请注意，随机版本忽略了上下文信息。 （2）RNN，其应用RNN预测模型并因此知道上下文信息，（3）RNN + Word2Vec，其启用RNN预测和Word2Vec模型。 我们计算在5分钟内不同版本探索的屏幕数量。对于每个版本，我们重复实验三次并报告最大数量。图8中报告了50个应用程序的结果。RNN版本检测到的屏幕比随机版本多21.1％，而RNN + Word2Vec版本检测到的屏幕比随机版本多28.6％。由于有许多应用程序具有简单的功能，因此屏幕数量较少，因此这三个版本可以为这些应用程序探索相同数量的屏幕。通过排除这些情况，我们观察到RNN版本优于随机版本46％，而RNN + Word2Vec版本优于60％。请注意，RNN版本与RNN + Word2Vec版本之间的差异突出了使用Word2Vec的有效性。 我们手动检查详细结果并进行一些有趣的观察。首先，这三个版本为27个应用程序产生相同的结果。原因是这些应用程序要么不需要任何用户输入，要么使用任何类型的输入值。例如，在PropertyFinder中，即使Monkey在搜索栏中输入了无意义的输入值，该值也不会导致匹配，该应用程序仍会检索并显示待售房地产属性的列表。在另一个应用程序聊天中，该应用程序用于接收/发送消息，无论消息是什么，它都可以正常工作。 其次，我们观察到RNN版本可以探索随机版本无法探索的许多UI屏幕。直观地，当文本框需要特殊格式或特殊含义的输入值时，RNN版本知道上下文并根据从训练数据集中学习的经验产生适当的输入值。相比之下，无视上下文的随机版本通常会产生不符合特殊要求的输入值。例如，在sip-calculator应用程序中，有一个标签为“amount”的文本框，这意味着它需要一些数字输入（即，app将对输入数字执行一些算术运算）。使用我们的RNN模型的monkey知道上下文信息并且已经知道上下文与数字输入值强烈相关。结果，Monkey输入数字输入值并进入新屏幕。相反，随机版本不会产生任何数字输入，因此无法继续。 在极端情况下，AlzPrevent应用程序（即研究实验室的调查应用程序）要求用户在进行调查之前填写注册表。 AlzPrevent有10个用于注册过程的屏幕，包括用户名，身高，体重和其他一些信息。随机版本卡在第一页，而我们的RNN版本（以及RNN + Word2Vec版本）知道如何填写输入值，因为它已经过多个需要注册的应用程序的训练。因此，我们的RNN版本优于随机版本112％，RNN + Word2Vec版本优于212％。 第三，当上下文与受过训练的应用程序中的上下文略有不同时，我们发现RNN + Word2Vec版本的性能优于RNN版本。使用Word2Vec模型，该版本识别来自不同应用程序的上下文之间的语义相似性。基于相似性信息，版本基于与来自训练的应用的上下文相关联的知识来预测相关输入值。对RNN模型的改进表明了组合RNN模型和Word2Vec模型的重要性和有效性。 我们还在第VII-C节中介绍了案例研究，以展示我们技术的优势。 C.案例研究 a）Firefox：第一个案例来自官方的Firefox iOS应用程序。这个案例说明了生成相关输入值的重要性，并说明了我们的方法如何产生它们。如图9所示，在屏幕1上，缺少主页按钮（默认情况下），因此无法测试与按钮相关的功能。要显示主页按钮，必须点击设置按钮更改设置。但是，屏幕2上的输入值需要有效的网页URL。否则主页按钮不会显示。我们的Monkey可以根据其标签“输入网页”和操作历史设置→主页（屏幕2）预测文本框的有效URL，从而启用主页按钮，如屏幕3所示。 随机版本忽略了文本框中的“输入网页”标签，产生随机输入值“New York”。 Firefox应用程序不接受输入，因此不启用“主页”按钮。事实上，Firefox不会在其数据库中记录无效输入。在Monkey导航到另一个屏幕然后返回之后，Random版本输入的输入值将丢失。通过在训练数据集中手动搜索预测的网页URL，我们可以识别出一些有趣的连接。该网址由网络抓取工具应用使用，并与应用中的“网站”标签相关联。我们的方法首先基于Word2Vec识别“网站”和“网页”（屏幕2）之间的相似性，然后基于RNN模型预测最可能的输入值。此示例演示了我们的技术在探索新UI屏幕方面的有效性，即使这两个应用程序具有不同的用例或业务逻辑。 b）第三方Github应用程序：图10显示了Github的第三方应用程序的案例。在这种情况下，我们的工具点击搜索菜单项（屏幕1），然后选择存储库类别（屏幕2）。它还成功预测了搜索栏的输入值Java，这导致了一些匹配的存储库返回的进一步进展（屏幕3）。我们的工具进一步单击每个存储库，从而发现异常。 如图11所示，异常发生在第116行。通过使用Swift语言[15]中的感叹号，开发人员假定变量repoDescription（即存储库的描述）不能为零（即，没有值）。但是，在实践中，某些存储库没有任何描述，这打破了开发人员的假设。因此，移动应用程序在尝试解包可选值为nil时崩溃。 相比之下，随机版本产生的输入值Benjamin Franklin在当前环境中是不合适的。因此，此版本无法找到上述错误。这个案例清楚地表明了我们工具的用处。 c）Frameless：Frameless是一款采用极简主义UI设计的全屏网页浏览器。 我们的工具发现了类似于Github应用程序中发现的bug的错误，如图12所示。查找错误需要Monkey测试才能生成有效的输入。考虑图13，在第一个屏幕中，搜索栏显示网站URL或搜索。鉴于这样的背景，我们的工具基于从训练数据集学习的统计相关性在第二屏幕中产生有效的网站。移动应用程序然后转换到第三个屏幕。通过单击登录按钮，我们的工具暴露了图12中所示的异常。通过检查代码，我们发现单击登录按钮会导致内部执行一些错误修复代码，遗憾的是错误处理了URL的内容。在这种情况下，上下文由四个单词组成，所有单词都被发送到RNN模型以在搜索栏中产生有效输入。相比之下，Random版本没有生成有效的URL，因此无法找到上述错误。 八.相关工作我们的工作与Android应用程序的自动测试生成密切相关。 Monkey [8]和Dynodroid [28]是基于随机探索的UI事件生成工具。 GUIRipper [18]（MobiGUITAR [19]），ORBIT [37]，A3E [21]，SwiftHand [23]和PUMA [25]为UI构建有限状态模型并生成事件以系统地探索模型中的状态。 Contest [20]基于一种复杂的执行方法生成事件，并通过检查事件序列之间的条件来修剪搜索空间。 Ermuth和Pradel [24]介绍了宏事件，它总结了单个步骤的低级UI事件的重复序列。通过将宏事件与随机测试相结合，它们利用记录的用户交互序列并自动生成新测试。与我们的方法相比，大多数自动化测试生成工作侧重于生成事件序列（或动作序列）。 除了事件和意图之外，生成测试输入值也很重要，因为只有满足输入值的谓词才能暴露某些行为。还应用了基于符号执行和进化算法的技术。 JPF-Android [36]扩展了Java PathFinder（JPF），是一个模型检查工具，用于探索所有路径并识别运行时故障。 EvoDroid [29]基于进化算法框架生成测试（包括事件和输入）。它使用随机方法生成输入。 Sapienz [30]是一款基于多目标搜索的Android应用测试工具。它结合了随机模糊测试，系统和基于搜索的探索，利用种子和多级插桩。虽然它可以提供字符串作为测试输入，但是这些字符串是通过逆向工程APK从应用程序中提取的，并随机播种到文本字段中。随机选择的输入在特定上下文中不太可能相关。 Afshan等 [17]应用基于n-gram语言模型的引导搜索来产生可读字符串输入而不是随机字符序列。但是，该方法不是为在用例上下文中生成字符串输入而设计的。 我们的工作还涉及基于机器学习的文本建模和生成技术。 Sutskever等人 [35]通过将大量训练的RNN应用于预测文本流中的下一个字符的任务，展示了它们的强大功能。 Melicher等 [31]提出了一种基于神经网络的方法来模拟人类选择的密码并测量其对猜测攻击的抵抗力。 IX.结论我们已经开发了一种基于深度学习的方法来自动生成移动测试的文本输入。它在上下文中生成最相关的输入值。此外，我们利用Word2Vec模型实现了独立性。对50多个iOS应用程序的评估证实了我们设计的有效性和效率。","content":"<h1 id=\"Abstract\"><a href=\"#Abstract\" class=\"headerlink\" title=\"Abstract\"></a>Abstract</h1><p>已经提出许多设计来改进自动化移动手机测试。尽管有这些改进，但提供适当的文本输入仍然是一个突出的障碍，这阻碍了大规模采用自动化测试方法。关键的挑战是如何在用例上下文中自动生成最相关的文本。例如，应在移动浏览器应用程序的地址栏中输入有效的网站地址，以继续测试应用程序;应在音乐推荐应用的搜索栏中输入歌手的姓名。如果没有正确的文本输入，测试将会卡住。我们提出了一种新颖的基于深度学习的方法来应对挑战，将问题简化为最小化问题。另一个挑战是如何使该方法通常适用于受过训练的应用程序和未经训练的应用程序。我们利用Word2Vec模型来应对挑战。我们已经将我们的方法构建为工具，并使用包括Firefox和Wikipedia在内的50种iOS移动应用程序对其进行评估。结果表明，我们的方法明显优于现有的自动文本输入生成方法。</p>\n<table>\n<thead>\n<tr>\n<th>relevant information</th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><em>作者</em></td>\n<td>Peng Liu, Xiangyu Zhang, Marco Pistoia, Yunhui Zheng, Manoel Marques and Lingfei Zeng</td>\n</tr>\n<tr>\n<td><em>单位</em></td>\n<td>IBM T. J. Watson Research Center, Yorktown Heights, New York, USA</td>\n</tr>\n<tr>\n<td><em>出处</em></td>\n<td>2017 IEEE/ACM 39th International Conference on Software Engineering</td>\n</tr>\n<tr>\n<td><em>原文地址</em></td>\n<td><a href=\"https://dl.acm.org/citation.cfm?id=3097445\" target=\"_blank\" rel=\"noopener\">https://dl.acm.org/citation.cfm?id=3097445</a></td>\n</tr>\n<tr>\n<td><em>源码地址</em></td>\n<td><a href=\"https://github.com/dkhamsing\" target=\"_blank\" rel=\"noopener\">https://github.com/dkhamsing</a></td>\n</tr>\n<tr>\n<td><em>发表时间</em></td>\n<td>2017年</td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"I-简介\"><a href=\"#I-简介\" class=\"headerlink\" title=\"I. 简介\"></a>I. 简介</h1><p>移动设备已成为我们生活中不可或缺的一部分。移动应用程序是提供各种便捷和高质量服务的工具，例如网页浏览，娱乐，交通信息辅助，银行和社交网络。为了满足日益增长的需求，移动市场正以每天1000多个新应用的速度快速增长[1] [6]。因此，开发团队一直处于激烈的竞争中，在发布截止日期前面临巨大的压力。遗憾的是，这通常会导致移动应用程序中的错误，例如运行时应用程序崩溃，UI设计中的缺陷以及未完全实现的功能。</p>\n<p>移动测试的目标是在应用程序发布之前发现它们中的错误。有两种主流的移动测试方法：手动测试和自动monkey测试。在手动测试中，测试人员手动执行操作以尽可能多地运用用例。这种方法的缺点是需要大量的人力，因为测试人员需要在整个测试期间与应用程序密切交互。此外，通常专注于演示常见用例中的功能的人类测试人员可能经常会错过可能触发异常的极端情况。</p>\n<p>自动化monkey测试[8]，[28]，[18]，[19]，[37]，[21]，[20]，[24]，[27]被提议用于减少人类的努力并最大化用例覆盖率。 “monkey”是描述这种测试如何运作的隐喻;像monkey一样，该工具执行随机动作序列，包括单击UI视图（或UI屏幕）上的按钮并执行随机击键。为了涵盖尽可能多的动作序列，研究人员提出了各种新颖的搜索算法，与monkey随机搜索策略形成对比。尽管有这些改进，但在monkey测试期间提供适当的文本输入仍然是一个突出的障碍，这阻碍了monkey测试方法的大规模采用。在许多用例中，大多数现有技术很难提供有意义的文本输入。例如，对于电影应用程序，monkey测试几乎无法提供有意义的输入，例如星际迷航。相反，它会产生不相关的输入，如4t6。因此，没有找到任何结果，从而使Monkey无法前往显示适当结果的屏幕。手动规范可以缓解这个问题，但需要大量的人力。</p>\n<p>在本文中，我们提出了一个解决方案，让Monkey自动生成相关的文本输入。有了这样的输入，Monkey可以通过长动作序列进入工作流深处的UI屏幕（简称深UI屏幕），而不是一开始就卡住。一旦它到达深度UI屏幕，Monkey可以应用其他面向bug披露的测试技术，例如基于搜索的测试[26]，符号测试生成[22]，甚至是随机测试[34]来识别复杂工作流中的错误。</p>\n<h2 id=\"A-生成相关输入\"><a href=\"#A-生成相关输入\" class=\"headerlink\" title=\"A.生成相关输入\"></a>A.生成相关输入</h2><p>输入生成的关键要求是生成与上下文相关的输入。<br>$$<br>Movie -&gt; search -&gt; star trek<br>$$</p>\n<p>$$<br>Weather -&gt; search -&gt; New York<br>$$</p>\n<p>在用例1中，在单击标记为“电影”的菜单项并且触发了标记为“搜索”的搜索栏后，应用程序将需要用户的电影标题。因此，输入星际迷航是相关的;在用例2中，单击标记为“天气”的菜单项并触发标记为“搜索”的搜索栏后，应用程序将使用该用户的城市名称。因此输入纽约是相关的。相反，在一个上下文中相关的输入可能在不同的上下文中不相关。例如，单击菜单项Weather时，输入Star Trek将不合适。我们还在第七节中将读者引用到更真实的例子中。</p>\n<p><strong>挑战</strong>。上述要求对自动文本输入生成提出了很大的挑战。首先，相关性特定于自然语言语义，只有人类测试者才能理解。因此，传统的自动输入生成方法，例如基于符号执行的测试[22]，是不适用的。其次，包含确定相关文本输入的信息的动作（例如，点击菜单项电影或天气）可能不会立即在动作序列中的输入动作之前。因此，维护和查找文本输入与紧接在先行动的信息之间的映射是一种难以奏效的方法。</p>\n<p><strong>我们的深度学习方法</strong>。我们提出了一种新颖的基于深度学习的方法来解决上述挑战。在高层次上，我们的解决方案包括两个阶段：在训练阶段，monkey学习测试人员的手动输入并统计地将他们与上下文相关联，例如行动历史和文本框标签;在预测阶段，monkey根据观察到的上下文自动预测文本输入。我们的方法的核心是递归神经网络（RNN）模型。这种类型的模型在许多自然语言处理（NLP）应用程序中取得了巨大成功，例如机器翻译和输入法自动完成。以输入法自动完成为例，RNN模型将单词之间的语义连接量化为非线性函数，其中参数用大的文本语料库进行训练。给定一个词，非线性函数计算其旁边的单词的概率分布，然后从分布中采样下一个单词。此外，RNN模型保持存储器状态以汇总来自先前单词的重要信息，并在推荐下一单词时将其用作另一输入源。据我们所知，我们是第一个将深度学习应用于自动测试移动设备的文本输入生成问题的人。</p>\n<p>根据Mikolov等人的实证研究 [32]，RNN模型比传统的统计模型（如n-gram模型和隐马尔可夫模型）更精确。具体而言，与传统模型相比，RNN导致18％的误差减少，假设它们在相同的数据上训练，并且即使传统模型训练的数据比RNN模型多5倍，也导致12％的误差减少。</p>\n<h2 id=\"B-与应用无关的输入生成\"><a href=\"#B-与应用无关的输入生成\" class=\"headerlink\" title=\"B.与应用无关的输入生成\"></a>B.与应用无关的输入生成</h2><p>输入生成的另一个重要要求是应用独立性。这意味着在一组应用程序上训练的RNN模型也应该适用于其他应用程序。</p>\n<p><strong>挑战</strong>。在不同的应用程序中使用不同的单词来表示相同的概念对应用程序独立性提出了重大挑战。<br>$$<br>Film -&gt; search -&gt; ?<br>$$<br>假设在训练阶段没有看到标签Film。人类测试人员可以很容易地找出用例1中标签movie和film之间的语义相似性。因此，我们可以预测相关的文本输入 - 例如，星际迷航。然而，RNN模型完全忽略了标签film，因为它没有出现在训练阶段。因此，RNN模型无法预测标签Film的相关文本输入。</p>\n<p><strong>我们基于Word2Vec的解决方案</strong>。我们通过从Google新闻语料库统计学习同义词的人类知识来应对挑战。同义词存储在等价类中。每个等价类的代表用于替换训练和预测期间属于该类的单词。</p>\n<p>我们的方法建立在Word2Vec模型的基础上，这是NLP研究人员最近提出的统计模型。该模型将一个单词映射到一个向量，向量之间的距离测量单词的相似性。 Word2Vec模型通过求解优化问题来学习矢量编码。具体而言，它最小化相似单词之间的距离，并最大化不相关单词之间的距离。 Word2Vec是一种无监督学习算法，这意味着它不需要手动标记训练数据。Word2Vec在结果质量方面优于其他现有模型[33]。这主要是因为Word2Vec可以训练比先前工作多2到3个数量级的数据，而这只是之前工作所需时间的一小部分。</p>\n<p>我们已经构建了一个工具，并使用50个iOS应用程序对其进行评估，包括Firefox和Wikipedia等热门应用程序。评估结果证实了我们的方法的有效性。</p>\n<p>RNN预测平均将Monkey测试的覆盖率提高了21％，而RNN模型和Word2Vec模型的组合将覆盖率提高了28％。<br>此外，如果我们排除基准套件中可用UI屏幕很少的简单应用程序，我们发现RNN预测可将覆盖率提高46％，两种模型的组合可提高60％。同样重要的是，我们的预测非常有效，通常在1毫秒内完成。</p>\n<p>总之，我们在本文中做出以下贡献：</p>\n<ul>\n<li>我们提出了一种基于深度学习的新方法，以自动生成移动UI测试的相关文本输入。</li>\n<li>我们提出了Word2Vec NLP模型的新颖组合，以及使输入生成应用独立的学习。</li>\n<li>我们已将我们的方法作为一个系统实施，并对包括Firefox和Wikipedia在内的50个iOS应用程序进行了实验。结果表明，我们的方法显着增加了Monkey测试的覆盖范围。</li>\n</ul>\n<h1 id=\"II-系统设计概述\"><a href=\"#II-系统设计概述\" class=\"headerlink\" title=\"II.系统设计概述\"></a>II.系统设计概述</h1><p>系统设计如图1所示。monkey测试引擎通过单击屏幕上的按钮来探索移动应用程序。当遇到文本框时，它会从文本输入服务器请求相关输入，如1、2所示。服务器通过进一步将其分派给人工测试人员或RNN运行实例来解析请求，该实例对应于两种模式：手动模式和AI模式。在手动模型中，在收到帮助请求3后，人工测试人员可以输入与上下文相关的文本输入4。如果她认为上下文不符合实际中的任何动作序列，则忽略它。然后，由测试者录入的输入和相应的上下文记录在与服务器相关联的数据库中。在AI模式中，我们首先使用记录在数据库5中的训练数据集训练RNN模型，之后RNN实例可以自动预测文本输入6。</p>\n<p><img src=\"/2019/04/19/Automatic-Text-Input-Generation-for-Mobile-Testing/1.jpg\" alt=\"\"></p>\n<p>在预测阶段6中，Monkey利用RNN模型来预测给定上下文中的文本输入值。基本上，考虑到Monkey测试引擎维护的上下文，模型预测文本输入值。但是，由于我们预测输入的应用程序与我们训练模型的应用程序不同，因此RNN模型可能无法识别Monkey测试期间遇到的某些上下文信息。为了解决这一挑战，我们使用Word2Vec模型改进了RNN模型，该模型有助于识别语义相似的上下文，尽管它们具有不同的句法形式（例如，“moive”和“film”）。通过RNN模型和Word2Vec模型的新颖组合，我们有效地解决了这个问题。</p>\n<p>在下文中，我们首先介绍第III节中的背景，然后解释我们如何应用深度学习技术来自动预测第IV节中的文本输入。<br>在第五节中，我们将解释实现细节。在第六节中，我们讨论了这项工作的假设。第七节介绍评估结果。</p>\n<h1 id=\"III-背景深度介绍\"><a href=\"#III-背景深度介绍\" class=\"headerlink\" title=\"III. 背景深度介绍\"></a>III. 背景深度介绍</h1><p>本节介绍了递归神经网络（RNN）和Word2Vec的背景。 RNN和Word2Vec都是神经网络的特殊形式。为了讨论这两个，我们首先要简要介绍一下神经网络。</p>\n<p><img src=\"/2019/04/19/Automatic-Text-Input-Generation-for-Mobile-Testing/2.jpg\" alt=\"\"></p>\n<p>神经网络（NN）有两种形式：图形形式和数学形式。在图形形式（图2a）中，NN具有输入层，输出层，一个或多个隐藏层。每个层（输入层除外）包括多个神经元，它们与前一层和下一层中的神经元相连。</p>\n<p>每个神经元，如图2b所示，是一个基本的计算单元。它首先将沿着传入边传递的值线性组合为∑ ~i~ p~i~x~i~ + b，其中p~i~和b是要训练的参数。然后它应用激活函数f~a~，例如tanh函数[12]或sigmoid函数[11]。激活函数对于使神经元非线性非常重要。<br>没有激活函数，神经元仅仅是线性函数，神经网络也是线性函数，不能表征许多复杂模型。</p>\n<p>在数学形式中，NN是由神经元代表的函数的组合。设f：R^n^→R^m^表示由神经网络表示的复合函数。设输入向量I∈R^n^表示输入层中n个神经元的输入。设输出向量O∈R^m^表示输出层中m个神经元的输出。神经网络的训练可以被视为一个优化问题：</p>\n<p><img src=\"/2019/04/19/Automatic-Text-Input-Generation-for-Mobile-Testing/3.jpg\" alt=\"\"></p>\n<p>更新参数以最小化预测输出和训练数据集上的实际输出之间的总损失，其中损失函数可以被定义为距离或其他形式。无论损失函数的复杂性如何，梯度下降算法[16]通常用于最小化其值。</p>\n<p>A.递归神经网络</p>\n<p>RNN是一种特殊形式的神经网络，具有反馈回路，如图3所示。为清楚起见，我们使用箭头来表示神经元之间的连接。</p>\n<p><img src=\"/2019/04/19/Automatic-Text-Input-Generation-for-Mobile-Testing/4.jpg\" alt=\"\"></p>\n<p>循环允许在网络执行步骤中导出的信息传递到下一个，类似于人类的长期记忆。图4显示了概念上展开的版本，其中神经网络在概念上被复制以通过多个步骤服务于一系列输入。</p>\n<p><img src=\"/2019/04/19/Automatic-Text-Input-Generation-for-Mobile-Testing/5.jpg\" alt=\"\"></p>\n<p>注意神经网络副本之间的连接。 RNN考虑输入法自动完成的应用，我们应用RNN生成句子“how are you doing”。这些单词一个接一个地输入到输入层。每个字在单热矢量表示中被编码以使得能够学习，例如，单词“how”被编码为[1,0,0,0]。简单地说，向量的每个条目对应于词汇表中的单词（[“how”，“are”，“you”，“doing”]），向量中值1的位置表示编码的单词。从概率的角度来看，向量表示具有100％概率的单词，而其他概率表示具有0％概率的单词。</p>\n<p>利用初始参数设置，给定输入字与从最后一步传递的信息相结合，神经网络输出概率向量，其中第i个条目估计词汇表中的第i个单词接下来出现的概率。例如，基于输入“how”，假设它将下一个词预测为[0.4,0.2,0.1,0.3]，即，最可能的下一个词是“how”。但是，我们从训练数据集中观察到下一个单词应该是“are”。因此，训练算法需要更新参数，使得单词“are”的预测概率变得显着大于其他单词。同样，给定“are”这个词，神经网络需要预测“you”作为下一个词的概率高于其他词。 </p>\n<h2 id=\"B-Word2Vec\"><a href=\"#B-Word2Vec\" class=\"headerlink\" title=\"B.Word2Vec\"></a>B.Word2Vec</h2><p>Word2Vec算法学习空间R^k^中每个单词的向量表示，其中相似的单词可能具有相似的向量。 Word2Vec通常应用于非常大的语料库。为了获得更好的可扩展性，Word2Vec采用传统的神经网络结构。</p>\n<p>Word2Vec采用的矢量表示与上述RNN中使用的单热表示明显不同。 Word2Vec将每个单词映射到空间R^k^中的实值向量，其中k远小于词汇量s，而单热表示将每个单词映射到空间{0,1}^s^中的向量。首先，通过在低维空间中编码矢量，Word2Vec降低了计算的空间复杂度。更重要的是，Word2Vec的矢量表示处于连续空间中，并且两个矢量之间的距离（即，余弦相似距离）有效地测量了单词的相似性。相反，单热表示不能测量相似性。在我们的工作中，我们将Word2Vec视为黑盒子。</p>\n<h1 id=\"IV-将深度学习应用于输入生成\"><a href=\"#IV-将深度学习应用于输入生成\" class=\"headerlink\" title=\"IV.将深度学习应用于输入生成\"></a>IV.将深度学习应用于输入生成</h1><p>在高级别，我们的方法在统计学上学习文本输入值与训练阶段的上下文之间的相关性（第IV-B节）。然后是预测阶段（第IV-C节），一旦Monkey需要在文本框中提供某些值，我们的方法就会根据Monkey目前观察到的上下文来预测值。第IV-D节进一步解释了我们如何推广输入生成以使其独立于应用程序。为便于讨论，我们首先介绍在训练阶段使用的训练数据集（第IV-A节）。</p>\n<h2 id=\"A-训练数据集\"><a href=\"#A-训练数据集\" class=\"headerlink\" title=\"A.训练数据集\"></a>A.训练数据集</h2><p>在不失一般性的情况下，我们假设简化的用户行为模型。在模型中，我们只对两种类型的UI元素感兴趣：按钮和文本框∈domain T~ui~。各种可点击的UI元素（如菜单和tableview单元格）具有类似于按钮的行为，因此在我们的模型中具有相同的抽象。类似地，接受用户输入的一系列文本字段（例如安全文本字段和搜索字段）被抽象为文本框。请注意，我们的实现完全支持所有这些UI元素。我们只对两种类型的动作感兴趣，tap和typeText∈T~action~，它们是UI元素∈T~ui~的最具代表性的行为。</p>\n<p>用户动作α∈A是一个元组，包括UI元素类型τ~ui~∈T~ui~，动作类型τ~action~∈T~action~、显示在UI元素中的标签 δ（例如，图5中的按钮中的“Moive”），以及在动作中涉及的可选值v，例如文本输入值。</p>\n<p>训练数据集基本上记录了动作序列（α~0~，α~1~，….  ，α~n~），其中α~i~表示在第i步的用户动作。 α~n~之前的子序列指的是用户到达发生α~n~的UI屏幕所采取的动作。有关动作序列的更多细节将在第VI节中讨论。</p>\n<p>我们观察到标签δ是用户在使用应用程序时所感知的最突出的信息，考虑提供什么作为输入值。基于这种观察，我们用动作序列中的每个动作α表示标签δ~α~，同时抽象掉所有其他信息。此外，我们还对在动作α~n~中输入的输入值v~αn~感兴趣。因此，上述动作序列简单地表示为（δα~0~，δα~1~，…. ，δa~n~，va~n~ ）.为了便于演示，我们还提到δα~0~，δα~1~，…. ，δa~n~作为输入值vα~n~的上下文。</p>\n<p><img src=\"/2019/04/19/Automatic-Text-Input-Generation-for-Mobile-Testing/6.jpg\" alt=\"\"></p>\n<p>考虑图5中的示例，假设测试人员执行操作以触发UI屏幕转换并输入输入值。在第一个屏幕中，测试人员点击（或点击）标有“Moive”的按钮，通向第二个屏幕，搜索栏标有“搜索”。在第三个屏幕中，测试仪在搜索栏中输入输入值“Star Trek”。<br>在用户操作模型之后，我们有两个操作：单击带有标签Movie的按钮，然后在搜索栏中输入带有标签Search的“Star Trek”。因此，记录的序列是“Moive”，“search”，“star Trek”。 </p>\n<h2 id=\"B-训练阶段\"><a href=\"#B-训练阶段\" class=\"headerlink\" title=\"B.训练阶段\"></a>B.训练阶段</h2><p>不失一般性，我们假设每个标签δ或输入值v是单个单词，而不是短语。第VI节介绍了一种确保假设的简单预处理。</p>\n<p>设Vocabulary V =L∪Val表示训练数据集中出现的所有标签和输入值的列表。在下文中，除非另有说明，否则我们不区分标签和输入值。相反，我们用一般术语词来引用它们。</p>\n<p>为了实现学习，我们提出了每个单词的以下向量表示。给定单词ω，其矢量形式ω‘具有与词汇相同的大小。并且向量的每个条目被定义为，</p>\n<p><img src=\"/2019/04/19/Automatic-Text-Input-Generation-for-Mobile-Testing/7.jpg\" alt=\"\"></p>\n<p>因为只有一个条目可以取值1，所以向量表示也被称为单热表示。考虑图4.在步骤2，输入向量为[0,1,0,0]，如输入层所示。</p>\n<p>在每个步骤，RNN模型接受单词的向量表示作为输入。输入以及隐藏层的先前状态（也被编码为矢量）用于预测输出，该概率矢量表征序列中接下来出现的每个单词的概率。训练的目标是更新RNN模型的参数，使得下一个词的预测概率分布接近从数据集观察到的真实概率分布。</p>\n<p>我们将训练正式化为优化问题：</p>\n<p><img src=\"/2019/04/19/Automatic-Text-Input-Generation-for-Mobile-Testing/8.jpg\" alt=\"\"></p>\n<p>给定上下文δα~0~，δα~1~，….，δa~n~，我们找到具有最大条件概率的输入值vα~n~= x。在训练阶段，我们建立一个RNN模型来预测条件概率。自动计算模型的内部参数，以使预测的概率分布近似于从训练数据集中观察到的真实概率分布。然后，在假设上下文与文本框的输入值之间的概率关联没有显着改变的情况下，将训练的模型用于预测。我们在网站上解释了有关形式化的更多细节[4]。</p>\n<h2 id=\"C-预测阶段\"><a href=\"#C-预测阶段\" class=\"headerlink\" title=\"C.预测阶段\"></a>C.预测阶段</h2><p>训练模型后，可以将其用于预测。通常，RNN模型接受一系列单词作为输入，并输出概率向量，该概率向量表征词汇表中的每个单词紧接在序列之后出现的概率（我们称之为下一个单词）。概率分布的采样将选择具有分布中描述的概率的单词。</p>\n<p>在我们的问题设置中，当Monkey遇到文本框时，它会将动作历史记录和文本框的标签序列化为序列，然后将序列发送到训练模型以预测下一个单词的概率分布。最后，它对概率分布进行采样以获得下一个单词的值。</p>\n<p>通常，词汇表中的任何单词都可以是下一个单词。词汇表中的单词可以对应于动作标签，文本框标签或文本输入值，但我们只对预测文本输入值感兴趣。如果采样结果不表示文本输入值（即，它不属于文本输入值的词汇表），我们将其丢弃并重新对分布进行采样。</p>\n<p>对概率分布进行采样的想法如下。令o’ 表示RNN模型的输出向量，其表征概率分布。我们首先将0到1之间的范围分成| o ‘|间隔。区间i（0 ≤ i &lt;| o ‘|）从<img src=\"/2019/04/19/Automatic-Text-Input-Generation-for-Mobile-Testing/9.jpg\" alt=\"\">开始并以<img src=\"/2019/04/19/Automatic-Text-Input-Generation-for-Mobile-Testing/10.jpg\" alt=\"\">结束。均匀随机变量X~U（0,1）落入具有概率o’ [i]的区间，即区间的长度。换句话说，均匀随机变量X落入区间i的概率与我们选择单词＃ -  V [i]的概率相同。因此，如果随机变量落入区间i，我们返回单词V’ [i]。</p>\n<p>请考虑以下示例。假设输出概率向量为[0.1,0.7,0.1,0.1]，如图4所示。图6显示了四个间隔。假设均匀随机变量的值为0.5，则它落入区间1（注意区间为0）。因此，我们返回单词V’ [1]，即单词“are”。</p>\n<p><img src=\"/2019/04/19/Automatic-Text-Input-Generation-for-Mobile-Testing/11.jpg\" alt=\"\"></p>\n<h2 id=\"D-独立于应用程序的输入生成\"><a href=\"#D-独立于应用程序的输入生成\" class=\"headerlink\" title=\"D.独立于应用程序的输入生成\"></a>D.独立于应用程序的输入生成</h2><p>我们的最终目标是预测我们尚未接受过训练的应用程序的输入。主要挑战是使输入生成应用独立。</p>\n<p>我们的想法是，如果我们遇到一个在训练阶段没有看到的单词，我们可以将它连接到在训练阶段看到的一些类似的单词，利用Word2Vec。我们使用预先使用非常大的Google新闻语料库训练的Word2Vec模型。当遇到不在词汇表中的单词时，例如，在训练期间没有出现在任何应用程序中的文本框标签时，我们的系统会查询Word2Vec以查找词汇表中最相似的单词（更确切地说，词汇表动作标签和文本框标签）。如果可以从两个单词的矢量表示计算的相似度低于预设阈值0.7，则我们认为该单词在训练数据集中没有对应物并且在预测期间简单地忽略它。在最坏的情况下，如果这个词在确定文本输入值时很重要，那么我们的技术就会降低到传统的Monkey测试。这些情况的发生主要是因为应用程序属于一个与我们训练过的应用程序类型非常不同的新类别。</p>\n<h1 id=\"V-实现\"><a href=\"#V-实现\" class=\"headerlink\" title=\"V.实现\"></a>V.实现</h1><p>我们在第II节中介绍了系统设计的概述。在本节中，我们将解释图1中所示的每个组件的实现细节。</p>\n<p><strong>a）Monkey测试引擎</strong>：我们的monkey在探索动作序列时采用深度优先搜索策略，即在填充当前屏幕中所有文本框元素的值之后逐个点击可用按钮。可以以随机顺序或以某种顺序（例如，按钮标签的字母顺序）单击同一屏幕内的按钮。我们实现了两个选项并在我们的实验中采用了随机顺序。另外，为了避免重复探索同一个屏幕，我们构建了每个屏幕的签名，其中包括屏幕标题和屏幕中按钮的标签。具有相同签名的屏幕被视为同一屏幕，仅被探索一次。</p>\n<p>请注意，除文本输入外，我们的系统还可以轻松扩展以预测下一步操作。然而，我们认为这会不利地限制Monkey实现良好覆盖的能力，因为它往往会跟随人类测试者的动作序列，这些动作序列是有限的。因此，我们系统的一个重要设计原则是使用随机探索动作和RNN预测文本输入。</p>\n<p>我们使用Xcode IDE附带的测试自动化框架XCTest实现了iOS Monkey。该框架提供了一组API [9]，允许我们在屏幕中找到按钮或文本框元素。例如，我们可以使用以下API调用轻松找到当前屏幕中的所有按钮：</p>\n<p>descendantsMatchingType（.Button）</p>\n<p><strong>b）文本输入服务器</strong>：使用python web框架Bottle [2]实现的文本输入服务器是一个隐藏了如何生成输入的详细信息的抽象层。由于它是用Python实现的，而Monkey测试引擎是在Swift中实现的，因此两个组件之间存在编程语言障碍。为了打破障碍，他们通过以JSON格式发送HTTP消息来相互通信。输入服务器通过函数调用与RNN实例通信，因为它们都是用Python实现的。此外，我们为输入服务器维护了一个数据库，用于存储人类测试人员在某些上下文中输入的输入。我们采用了MongoDB [7]。输入服务器使用Python驱动程序PyMongo [10]与数据库交互。</p>\n<p><strong>c）RNN实例</strong>：我们在Python深度学习框架Tensorflow [13]之上构建了RNN模型，它提供了高级API，同时隐藏了许多低级细节。通过Tensorflow的抽象，可以使用仅40行代码构建RNN模型，如我们的网站[3]所示。我们通过首先使用Word2Vec预处理数据集然后将它们输入RNN模型来训练模型。此外，经过训练的RNN模型可以保存到磁盘上并随时加载以供进一步使用。</p>\n<h1 id=\"VI-讨论\"><a href=\"#VI-讨论\" class=\"headerlink\" title=\"VI.讨论\"></a>VI.讨论</h1><p>在本节中，我们将讨论我们在这项工作中所做的假设。<br>我们在训练/预测中做出的假设是标签或输入值是单个单词，而不是短语或句子。如果标签确实是一个短语，我们将其分解为单词并将每个单词视为单独的标签上下文。通过在单词级别推理，只要其中的单词属于我们的词汇表，我们的方法就可以处理任何短语。相反，对于作为短语的文本输入值，我们将短语视为原子单位，以便在整个训练和预测期间不对它们进行分区。</p>\n<p>我们的方法的另一个重要假设是我们训练Monkey的应用程序和Monkey将测试的应用程序应该分享一些相似性，例如，它们属于App市场上的相同类别。否则，如果我们在娱乐应用程序上训练Monkey并将其应用于测试Tax应用程序，那么预测的文本输入将毫无意义。为了避免这种情况，我们收集尽可能多的不同类型的应用程序，并将它们用作训练主题。</p>\n<p>在我们的方法中，我们假设上下文仅包含文本标签。在真实世界的应用程序中，开发人员可能会使用图标而不是文本标签。我们目前不支持非文字标签。我们注意到我们的方法可以扩展到支持非文本标签，例如，利用image2text工具[14]。</p>\n<p>当我们记录动作序列时，我们维护一个列表并将每个动作附加到列表中。但是，如果我们遇到撤消上一个操作的操作，我们会放弃操作并从列表中删除上一个操作;如果我们遇到导致应用程序主屏幕的操作，我们只需清除列表即可。最后，我们的工作补充了自动行动序列生成的大量最新进展[28]，[24]，[27]。虽然我们期待很大的协同作用，但我们将把它留给我们未来的工作。</p>\n<h1 id=\"七-评估\"><a href=\"#七-评估\" class=\"headerlink\" title=\"七.评估\"></a>七.评估</h1><p>在我们的实验中，我们对以下研究问题感兴趣：</p>\n<ul>\n<li>与其他用于移动测试的自动输入生成方法相比，我们的自动化方法的效果如何？</li>\n<li>与仅使用RNN模型相比，Word2Vec是否允许更好的结果？</li>\n<li>我们的工具产生的性能开销是多少？</li>\n</ul>\n<p>为了解决第一个问题，我们与自动随机输入生成方法进行比较，该方法从常用输入值池中随机选择[30]输入值。</p>\n<p>我们通过计算屏幕覆盖率来测量有效性，即，在固定时间窗口内已经探索了多少不同的UI屏幕。通常采用monkey测试来探索尽可能多的用例。但是，识别独特的用例需要领域知识。相反，我们使用屏幕覆盖来客观地估计用例覆盖范围。</p>\n<p>请注意，屏幕覆盖范围与功能测试中的经典覆盖标准（例如，语句覆盖率和路径覆盖率）不同。我们认为两者都很重要。特别是，我们的方法补充了功能测试，因为通过提供有意义的输入值，我们的技术允许Monkey访问有趣的UI屏幕。从这样的UI屏幕开始，可以应用现有的功能测试工作来暴露应用程序崩溃。此外，我们认为一些UI屏幕很有趣，即使它们与任何应用程序崩溃都不对应。我们将读者引用到我们的网站[5]以获取此类示例。</p>\n<p>请注意，我们的方法与自动事件序列生成方法正交。在这项工作中，我们采用现有的深度优先搜索策略。我们的贡献主要在于根据上下文生成相关的文本输入，并容忍在不同的应用程序中使用不同的单词。</p>\n<p>为了解决第二个研究问题，我们比较了仅启用RNN的版本以及启用了RNN和Word2Vec的版本。第VII-B节通过将三个版本比较在一起来解决上述两个问题。</p>\n<p>最后，性能开销很重要，特别是考虑到在Monkey测试期间交互式预测。理想情况下，该方法应该以低性能开销实现有效性。性能的测量见第VII-A节。</p>\n<p>  a）实验设置：我们在OS X EI Capitan的MacBook Pro上进行实验。 iOS应用程序在iPhone 6S Plus（iOS 9.2）的模拟器中运行。我们从Github收集了200个开源iOS应用程序，主要来自https：//github.com/dkhamsing/open-source-ios-apps。它们分为不同的类别，包括电影，新闻，图像，浏览器，旅行，广播，日历，天气和任务。它们包括流行的应用程序，如Firefox和维基百科。我们对150个应用程序进行了训练，并测试了其余50个应用程序的预测功能。</p>\n<p>我们的训练数据集共包含14061个单词。当我们收集训练数据集时，我们尝试尽可能多地重用输入值。例如，当我们需要在不同的应用程序中输入电影名称时，我们会坚持使用相同的电影名称。</p>\n<h2 id=\"A-性能开销\"><a href=\"#A-性能开销\" class=\"headerlink\" title=\"A.性能开销\"></a>A.性能开销</h2><p>学习/训练过程需要多次迭代。我们用于预测的模型训练了6个小时，但我们在更短的时间内测量了性能。我们测量每1000次迭代的计算时间并报告迭代的平均时间。我们还使用每1000次迭代后生成的模型，使用数据集中的随机序列预测下一个单词。这是为了抽样模型的准确性。我们还测量RNN模型用于训练和预测的时间。如图7所示，除初始步骤外，训练/预测时间保持不变。这是因为每次迭代处理固定数量的数据，并且神经网络结构不会动态变化。另一个重要的观察是每个预测平均需要0.7毫秒，与测试中的其他操作相比可以忽略不计（例如，输入文本）</p>\n<p><img src=\"/2019/04/19/Automatic-Text-Input-Generation-for-Mobile-Testing/12.jpg\" alt=\"\"></p>\n<p>我们还测量了Word2Vec模型的加载时间以及每个查询类似单词的时间。加载大约需要54秒，而每次查询大约需要0.7毫秒。由于空间限制，我们不显示数字。加载时间很长，因为模型很大，在Google新闻语料库中训练有30亿个运行单词。<br>我们的文本输入服务器通过在服务器初始化期间加载模型来解决此问题。加载后，该模型可用于所有传入的查询。</p>\n<h2 id=\"B-我们方法的有效性\"><a href=\"#B-我们方法的有效性\" class=\"headerlink\" title=\"B.我们方法的有效性\"></a>B.我们方法的有效性</h2><p>为了衡量有效性，我们比较了三个版本：（1）随机，随机从常用输入值池中选取一个值。请注意，随机版本忽略了上下文信息。 （2）RNN，其应用RNN预测模型并因此知道上下文信息，（3）RNN + Word2Vec，其启用RNN预测和Word2Vec模型。</p>\n<p>我们计算在5分钟内不同版本探索的屏幕数量。对于每个版本，我们重复实验三次并报告最大数量。图8中报告了50个应用程序的结果。RNN版本检测到的屏幕比随机版本多21.1％，而RNN + Word2Vec版本检测到的屏幕比随机版本多28.6％。由于有许多应用程序具有简单的功能，因此屏幕数量较少，因此这三个版本可以为这些应用程序探索相同数量的屏幕。通过排除这些情况，我们观察到RNN版本优于随机版本46％，而RNN + Word2Vec版本优于60％。请注意，RNN版本与RNN + Word2Vec版本之间的差异突出了使用Word2Vec的有效性。</p>\n<p><img src=\"/2019/04/19/Automatic-Text-Input-Generation-for-Mobile-Testing/13.jpg\" alt=\"\"></p>\n<p>我们手动检查详细结果并进行一些有趣的观察。首先，这三个版本为27个应用程序产生相同的结果。原因是这些应用程序要么不需要任何用户输入，要么使用任何类型的输入值。例如，在PropertyFinder中，即使Monkey在搜索栏中输入了无意义的输入值，该值也不会导致匹配，该应用程序仍会检索并显示待售房地产属性的列表。在另一个应用程序聊天中，该应用程序用于接收/发送消息，无论消息是什么，它都可以正常工作。</p>\n<p>其次，我们观察到RNN版本可以探索随机版本无法探索的许多UI屏幕。直观地，当文本框需要特殊格式或特殊含义的输入值时，RNN版本知道上下文并根据从训练数据集中学习的经验产生适当的输入值。相比之下，无视上下文的随机版本通常会产生不符合特殊要求的输入值。例如，在sip-calculator应用程序中，有一个标签为“amount”的文本框，这意味着它需要一些数字输入（即，app将对输入数字执行一些算术运算）。使用我们的RNN模型的monkey知道上下文信息并且已经知道上下文与数字输入值强烈相关。结果，Monkey输入数字输入值并进入新屏幕。相反，随机版本不会产生任何数字输入，因此无法继续。</p>\n<p>在极端情况下，AlzPrevent应用程序（即研究实验室的调查应用程序）要求用户在进行调查之前填写注册表。 AlzPrevent有10个用于注册过程的屏幕，包括用户名，身高，体重和其他一些信息。随机版本卡在第一页，而我们的RNN版本（以及RNN + Word2Vec版本）知道如何填写输入值，因为它已经过多个需要注册的应用程序的训练。因此，我们的RNN版本优于随机版本112％，RNN + Word2Vec版本优于212％。</p>\n<p>第三，当上下文与受过训练的应用程序中的上下文略有不同时，我们发现RNN + Word2Vec版本的性能优于RNN版本。使用Word2Vec模型，该版本识别来自不同应用程序的上下文之间的语义相似性。基于相似性信息，版本基于与来自训练的应用的上下文相关联的知识来预测相关输入值。对RNN模型的改进表明了组合RNN模型和Word2Vec模型的重要性和有效性。</p>\n<p>   我们还在第VII-C节中介绍了案例研究，以展示我们技术的优势。</p>\n<h2 id=\"C-案例研究\"><a href=\"#C-案例研究\" class=\"headerlink\" title=\"C.案例研究\"></a>C.案例研究</h2><p><img src=\"/2019/04/19/Automatic-Text-Input-Generation-for-Mobile-Testing/14.jpg\" alt=\"\"></p>\n<p><strong>a）Firefox</strong>：第一个案例来自官方的Firefox iOS应用程序。这个案例说明了生成相关输入值的重要性，并说明了我们的方法如何产生它们。如图9所示，在屏幕1上，缺少主页按钮（默认情况下），因此无法测试与按钮相关的功能。要显示主页按钮，必须点击设置按钮更改设置。但是，屏幕2上的输入值需要有效的网页URL。否则主页按钮不会显示。我们的Monkey可以根据其标签“输入网页”和操作历史设置→主页（屏幕2）预测文本框的有效URL，从而启用主页按钮，如屏幕3所示。</p>\n<p>随机版本忽略了文本框中的“输入网页”标签，产生随机输入值“New York”。 Firefox应用程序不接受输入，因此不启用“主页”按钮。事实上，Firefox不会在其数据库中记录无效输入。在Monkey导航到另一个屏幕然后返回之后，Random版本输入的输入值将丢失。通过在训练数据集中手动搜索预测的网页URL，我们可以识别出一些有趣的连接。该网址由网络抓取工具应用使用，并与应用中的“网站”标签相关联。我们的方法首先基于Word2Vec识别“网站”和“网页”（屏幕2）之间的相似性，然后基于RNN模型预测最可能的输入值。此示例演示了我们的技术在探索新UI屏幕方面的有效性，即使这两个应用程序具有不同的用例或业务逻辑。</p>\n<p><strong>b）第三方Github应用程序</strong>：图10显示了Github的第三方应用程序的案例。在这种情况下，我们的工具点击搜索菜单项（屏幕1），然后选择存储库类别（屏幕2）。它还成功预测了搜索栏的输入值Java，这导致了一些匹配的存储库返回的进一步进展（屏幕3）。我们的工具进一步单击每个存储库，从而发现异常。</p>\n<p>如图11所示，异常发生在第116行。通过使用Swift语言[15]中的感叹号，开发人员假定变量repoDescription（即存储库的描述）不能为零（即，没有值）。但是，在实践中，某些存储库没有任何描述，这打破了开发人员的假设。因此，移动应用程序在尝试解包可选值为nil时崩溃。</p>\n<p><img src=\"/2019/04/19/Automatic-Text-Input-Generation-for-Mobile-Testing/15.jpg\" alt=\"\"></p>\n<p>相比之下，随机版本产生的输入值Benjamin Franklin在当前环境中是不合适的。因此，此版本无法找到上述错误。这个案例清楚地表明了我们工具的用处。</p>\n<p><strong>c）Frameless</strong>：Frameless是一款采用极简主义UI设计的全屏网页浏览器。</p>\n<p><img src=\"/2019/04/19/Automatic-Text-Input-Generation-for-Mobile-Testing/16.jpg\" alt=\"\"></p>\n<p><img src=\"/2019/04/19/Automatic-Text-Input-Generation-for-Mobile-Testing/17.jpg\" alt=\"\"></p>\n<p>我们的工具发现了类似于Github应用程序中发现的bug的错误，如图12所示。查找错误需要Monkey测试才能生成有效的输入。考虑图13，在第一个屏幕中，搜索栏显示网站URL或搜索。鉴于这样的背景，我们的工具基于从训练数据集学习的统计相关性在第二屏幕中产生有效的网站。移动应用程序然后转换到第三个屏幕。通过单击登录按钮，我们的工具暴露了图12中所示的异常。通过检查代码，我们发现单击登录按钮会导致内部执行一些错误修复代码，遗憾的是错误处理了URL的内容。在这种情况下，上下文由四个单词组成，所有单词都被发送到RNN模型以在搜索栏中产生有效输入。相比之下，Random版本没有生成有效的URL，因此无法找到上述错误。</p>\n<h1 id=\"八-相关工作\"><a href=\"#八-相关工作\" class=\"headerlink\" title=\"八.相关工作\"></a>八.相关工作</h1><p>我们的工作与Android应用程序的自动测试生成密切相关。 Monkey [8]和Dynodroid [28]是基于随机探索的UI事件生成工具。 GUIRipper [18]（MobiGUITAR [19]），ORBIT [37]，A3E [21]，SwiftHand [23]和PUMA [25]为UI构建有限状态模型并生成事件以系统地探索模型中的状态。 Contest [20]基于一种复杂的执行方法生成事件，并通过检查事件序列之间的条件来修剪搜索空间。 Ermuth和Pradel [24]介绍了宏事件，它总结了单个步骤的低级UI事件的重复序列。通过将宏事件与随机测试相结合，它们利用记录的用户交互序列并自动生成新测试。与我们的方法相比，大多数自动化测试生成工作侧重于生成事件序列（或动作序列）。</p>\n<p>除了事件和意图之外，生成测试输入值也很重要，因为只有满足输入值的谓词才能暴露某些行为。还应用了基于符号执行和进化算法的技术。 JPF-Android [36]扩展了Java PathFinder（JPF），是一个模型检查工具，用于探索所有路径并识别运行时故障。 EvoDroid [29]基于进化算法框架生成测试（包括事件和输入）。它使用随机方法生成输入。 Sapienz [30]是一款基于多目标搜索的Android应用测试工具。它结合了随机模糊测试，系统和基于搜索的探索，利用种子和多级插桩。虽然它可以提供字符串作为测试输入，但是这些字符串是通过逆向工程APK从应用程序中提取的，并随机播种到文本字段中。随机选择的输入在特定上下文中不太可能相关。 Afshan等 [17]应用基于n-gram语言模型的引导搜索来产生可读字符串输入而不是随机字符序列。但是，该方法不是为在用例上下文中生成字符串输入而设计的。</p>\n<p>我们的工作还涉及基于机器学习的文本建模和生成技术。 Sutskever等人 [35]通过将大量训练的RNN应用于预测文本流中的下一个字符的任务，展示了它们的强大功能。 Melicher等 [31]提出了一种基于神经网络的方法来模拟人类选择的密码并测量其对猜测攻击的抵抗力。</p>\n<h1 id=\"IX-结论\"><a href=\"#IX-结论\" class=\"headerlink\" title=\"IX.结论\"></a>IX.结论</h1><p>我们已经开发了一种基于深度学习的方法来自动生成移动测试的文本输入。它在上下文中生成最相关的输入值。此外，我们利用Word2Vec模型实现了独立性。对50多个iOS应用程序的评估证实了我们设计的有效性和效率。</p>\n","categories":[{"name":"论文","slug":"论文","permalink":"http://yama0xff.com/categories/论文/"},{"name":"fuzzing","slug":"论文/fuzzing","permalink":"http://yama0xff.com/categories/论文/fuzzing/"},{"name":"机器学习","slug":"论文/fuzzing/机器学习","permalink":"http://yama0xff.com/categories/论文/fuzzing/机器学习/"}],"tags":[{"name":"fuzzing","slug":"fuzzing","permalink":"http://yama0xff.com/tags/fuzzing/"},{"name":"机器学习","slug":"机器学习","permalink":"http://yama0xff.com/tags/机器学习/"},{"name":"2017年","slug":"2017年","permalink":"http://yama0xff.com/tags/2017年/"},{"name":"Word2Vec","slug":"Word2Vec","permalink":"http://yama0xff.com/tags/Word2Vec/"}]},{"title":"DeepFuzz: Automatic Generation of Syntax Valid C Programs for Fuzz Testing","date":"2019-04-18T03:11:49.000Z","path":"2019/04/18/DeepFuzz-Automatic-Generation-of-Syntax-Valid-C-Programs-for-Fuzz-Testing/","text":"Abstract编译器是构建软件最基本的编程工具之一。但是，生产编译器仍然存在问题。模糊测试通常用于新生成或突变输入，以便发现新的错误或安全漏洞。在本文中，我们提出了一种名为DEEPFUZZ的基于语法的模糊测试工具。基于生成的seq2seq模型，DEEPFUZZ自动且连续地生成格式良好的C程序。我们使用这组新的C程序来模糊现成的C编译器，例如GCC和Clang / LLVM。我们提供了一个详细的案例研究来分析生成的C程序的模糊测试的成功率和覆盖率改进。我们用三种采样方法和三种生成策略来分析DEEPFUZZ的性能。因此，DEEPFUZZ在行，函数和分支覆盖方面提高了测试效率。在我们的初步研究中，我们发现并报告了8个GCC漏洞，所有这些漏洞都由开发人员积极处理。 relevant information 作者 Xiao Liu, Xiaoting Li, Rupesh Prajapati, Dinghao Wu 单位 College of Information Sciences and TechnologyThe Pennsylvania State University 出处 AAAI-19 原文地址 https://faculty.ist.psu.edu/wu/papers/DeepFuzz.pdf 源码地址 https://github.com/wtwofire/deepfuzz 发表时间 2019年 1. 简介编译器是最重要的计算系统软件之一，它们通常是信任计算基础的一部分，但它们仍然存在问题。例如，GCC是1987年发布的一款长效软件，是许多类Unix操作系统的标准编译器。自创建以来，已经捕获了超过3,410个内部错误（Yang et al.2011）。同样，对于Java，Python和JavaScript，在那些广泛使用的编译器和解释器中发现了数千个错误。这些编译器错误可能导致意外的程序执行，并导致安全敏感应用程序的灾难性后果。当在应用程序或编译器中无法确定根本原因时，它还可能妨碍开发人员在调试程序时的工作效率。因此，提高编译器的正确性至关重要。但用不断增长的代码库验证编译器并不容易：今天的GCC代码库大约有1500万行代码（Sun et al.2016），接近整个Linux内核，大约有1900万行代码。 使编译器可靠是至关重要的。在过去十年中，编译器验证一直是计算研究中验证授权挑战的一个重要且活跃的领域（Hoare 2003）。主流研究侧重于形式验证（Leroy和Grall 2009），翻译验证（Necula 2000）和随机测试（Lidbury等人2015; Le，Afshari和Su 2014; Le，Sun和Su 2015）。前两个类别尝试提供经过认证的编译器。例如，CompCert（Leroy等人，2016）在这一领域取得了有希望的进展。但实际上，应用形式化技术来完全验证生成编译器（如GCC）是一项挑战，尤其是当证明不是与编译器一起构造时。因此，测试仍然是编译器验证的主要方法。 我们的工作重点是编译器测试。通过向不同的生产编译器提供不同功能的程序，启用不同级别的优化，可以在编译期间触发内部编译器错误（编译器的真正错误），并显示错误消息指示错误的位置和内容。但是，生成“好”程序以提高测试效率并通过自动化此过程构建连续测试框架具有挑战性。在现有方法中，每个测试（包括人工测试）都涵盖了一些功能，现在通常可以看到现代编译器越来越大的测试套件。这提高了测试覆盖率，但构建这些测试需要花费大量人力。然而，荣国模糊测试的实用方法可以减少人力。 Fuzzing（Bird和Munoz 1983）是一种发现漏洞或安全漏洞的方法。程序通过自动生成或修改的输入重复执行，以检测程序崩溃等异常行为。目前使用的输入模糊测试的主要技术是黑盒随机模糊测试（Zalewski 2015），基于白盒约束的模糊测试（Godefroid，Kiezun和Levin 2008），以及基于语法的模糊测试（Dewey，Roesch和Hardekopf 2014）。黑盒子和白盒模糊是完全自动的，并且历史证明在二进制格式文件解析器中找到安全漏洞是有效的。相反，基于语法的模糊测试需要输入语法，该输入语法指定被测应用程序的输入格式，该输入格式通常是手工编写的。这个过程费力，耗时且容易出错。然而，基于语法的模糊测试是当今已知的用于具有复杂结构化输入格式的模糊应用的最有效的模糊测试技术，例如编译器。在编译器测试的场景中，部署基于语法的模糊测试的一种方法是将C语法编码为测试用例生成的规则。但实际上，C11（国际标准化组织（ISO）2011），C编程语言的当前标准，有696页的详细规范，这为工程师构建这样一个基于语法的引擎带来了障碍。在本文中，我们考虑使用生成递归神经网络自动生成语法有效输入的语法有效输入的问题。更具体地说，我们的目标是训练生成神经网络，以学习输入数据的“语法”，或者更确切地说，语言模式。我们建议在监督学习策略中训练序列到序列模型（Sutskever，Vinyals和Le 2014），利用生产编译器提供的原始测试套件。最初，序列到序列模型广泛用于机器翻译（Klein等人2017）和文本生成（Sutskever，Martens和Hinton 2011）。从理论上讲，通过训练原始段落的模型，我们隐含地将正确的单词拼写，句子的有效语法，写作行为的详细风格编码到生成模型中。同样的想法可以应用于程序综合，其中我们只需要训练模型以在种子数据集之上生成不同的语法上有效的程序。对于训练数据集，我们采用了原始的GCC测试套件，其中有超过10,000个短程序或小程序，涵盖了C11标准中规定的大多数功能。在训练阶段，我们调整参数以将C程序的语言模式编码到模型中，基于此，我们不断生成用于编译器模糊测试的新程序。贡献。我们的工作是第一个使用生成递归神经网络进行基于语法的编译器模糊测试。 首先，拟议的框架是全自动的。通过训练序列到序列模型，可以将其视为训练数据语言模式的隐式表示，在我们的上下文中使用C语法，我们的框架DEEPFUZZ将不断提供新的语法正确的C程序。 其次，我们构建了一个用于模糊现成的C编译器的实用工具。我们详细分析了关键因素将如何影响生成模型和模糊性能的准确性。 •第三，我们应用DEEPFUZZ技术测试GCC和Clang / LLVM。在我们的初步分析期间，测试覆盖范围（线路，功能和分支）增加，我们发现并报告了8个真实的错误。 Fuzzing（Bird和Munoz 1983）是一种发现漏洞或安全漏洞的方法。程序通过自动生成或修改的输入重复执行，以检测程序崩溃等异常行为。目前使用的输入模糊测试的主要技术是黑盒随机模糊测试（Zalewski 2015），基于白盒约束的模糊测试（Godefroid，Kiezun和Levin 2008），以及基于语法的模糊测试（Dewey，Roesch和Hardekopf 2014）。黑盒子和白盒模糊是完全自动的，并且历史证明在二进制格式文件解析器中找到安全漏洞是有效的。相反，基于语法的模糊测试需要输入语法，该输入语法指定被测应用程序的输入格式，该输入格式通常是手工编写的。这个过程费力，耗时且容易出错。然而，基于语法的模糊测试是当今已知的用于具有复杂结构化输入格式的模糊应用的最有效的模糊测试技术，例如编译器。在编译器测试的场景中，部署基于语法的模糊测试的一种方法是将C语法编码为测试用例生成的规则。但实际上，C11（国际标准化组织（ISO）2011），C编程语言的当前标准，有696页的详细规范，这为工程师构建这样一个基于语法的引擎带来了障碍。 在本文中，我们考虑使用生成递归神经网络自动生成语法有效输入用于基于语法的fuzzing。更具体地说，我们的目标是训练生成神经网络，以学习输入数据的“语法”，或者更确切地说，语言模式。我们建议在监督学习策略中训练seq2seq模型（Sutskever，Vinyals和Le 2014），利用生产编译器提供的原始测试套件。最初，seq2seq模型广泛用于机器翻译（Klein等人2017）和文本生成（Sutskever，Martens和Hinton 2011）。从理论上讲，通过训练原始段落的模型，我们隐含地将正确的单词拼写，句子的有效语法，写作行为的详细风格编码到生成模型中。同样的想法可以应用于程序综合，其中我们只需要训练模型以在种子数据集之上生成不同的语法上有效的程序。对于训练数据集，我们采用了原始的GCC测试套件，其中有超过10,000个短程序或小程序，涵盖了C11标准中规定的大多数功能。在训练阶段，我们调整参数以将C程序的语言模式编码到模型中，基于此，我们不断生成用于编译器模糊测试的新程序。 贡献。我们的工作是第一个使用生成递归神经网络进行基于语法的编译器模糊测试。 首先，拟议的框架是全自动的。通过训练seq2seq模型，可以将其视为训练数据语言模式的隐式表示，在我们的上下文中使用C语法，我们的框架DEEPFUZZ将不断提供新的语法正确的C程序。 其次，我们构建了一个用于模糊现成的C编译器的实用工具。我们详细分析了关键因素将如何影响生成模型和模糊性能的准确性。 第三，我们应用DEEPFUZZ技术测试GCC和Clang / LLVM。在我们的初步分析期间，测试覆盖范围（行，函数和分支）增加，我们发现并报告了8个真实的错误。 2.概述2.1 seq2seq模型我们在seq2seq模型的基础上构建DEEPFUZZ，该模型实现了两个用于字符级序列预测的递归神经网络（RNN）。 RNN是由隐藏状态h和可选输出y组成的神经网络。它在可变长度序列上运行，x =（x~1~, x~2~……x~T~）。在每个步骤t，更新RNN的隐藏状态h~~$$h_{} = f(h_{t−1}, x_t)$$其中f是非线性激活函数。 RNN可以学习字符序列上的概率分布以预测下一个符号。因此，在每个时间步t，来自RNN的输出是条件分布p（x~t~ |x~t-1~……x~1~）。例如，在我们的例子中，在下一个字符的多项分布时，我们使用softmax激活函数作为输出$$p(x_{t,j} = 1| x_{t−1},……,x_1) = \\frac{ exp(w_jh_{})}{\\sum_{j=1}^Kexp(w_jh_{})}$$对于所有可能的符号j = 1,……,K ，其中 w~j~ 是权重矩阵W的行。通过组合这些概率，我们计算序列x使用的概率$$p(x) =\\prod_{t=1}^Tp(x_{t,j} = 1| x_{t−1},……,x_1)$$通过学习的分布，通过在每个时间步迭代地采样新字符来生成新序列是直截了当的。 seq2seq模型由两个RNN，编码器和解码器组成。编码器学习将可变长度序列编码为固定长度矢量表示，并且解码器将该固定长度矢量表示解码为可变长度序列。它最初是由Cho等人 （2014）提出的，用于统计机器翻译。编码器RNN读取输入序列x的每个字符，同时RNN的隐藏状态改变。在读取该序列的结束之后，RNN的隐藏状态是整个输入序列的概要c。同时，训练解码器RNN以通过预测给定隐藏状态h~~的下一个字符y~t~来产生输出序列。然而，与纯RNN不同，y~t~和h~~也都以y~t-1~和输入序列的摘要c为条件。在这种情况下，为了计算解码器的隐藏状态，我们有$$h_{}= f(h_{}, y_{t−1}, c)$$同样地，下一个字符的条件分布是$$p(y_t|y_{t−1}，……，y_1， c) = g(hti; yt−1; c);$$其中 f 和 g 是激活函数。总的来说，两个RNN编码器 - 解码器被联合训练以在给定输入序列的情况下生成目标序列。所有RNN在循环层中都有反馈循环。 这种设计允许他们随着时间的推移将信息保存在“记忆”中。然而，训练标准RNN以学习长期时间依赖性可能是困难的，但这在程序中是常见的。这是因为损失函数的梯度随时间呈指数衰减（Chung et al.2014）。因此，在我们的设计中，我们采用RNN的变体，长短期记忆（LSTM），特别是在我们的编码器和解码器中。 LSTM单元包括“存储器单元”，其可以将信息长时间保存在存储器中，在这种情况下可以存储长历史信息。 在以前的研究中，seq2seq模型已经过训练，可以生成语法正确的PDF对象来模糊PDF解析器（Godefroid，Peleg和Singh 2017）。这项工作背后的核心思想是，源语言语法可以作为字符串对的训练副产品来学习。 Shi，Padhi和Knight（2016）通过实验研究了seq2seq模型可以学习关于源句的局部和全局句法信息。这项工作为RNN的正式语言合成奠定了基础。在我们的论文中，我们对编译器模糊测试应用了类似的想法。在训练期间，我们将序列分成固定大小为d的多个训练序列。通过剪切序列，我们得到第i个训练序列xi = s [i d：（i + 1） d]，其中s [k：l]是索引k和l之间s的子序列。每个训练序列的输出序列是下一个字符，即yt = s [（i + 1）* d + 1]。我们将此训练过程配置为学习一组训练序列的生成模型。 2.2 工作流程一般而言，我们建议DEEPFUZZ用于两个主要目标。第一种是从一组语法正确的程序中生成遵循合法语法的新程序。主要挑战来自长序列处理和语言语法表示。第二个目标是提高编译器测试效率。我们的目标是提高覆盖率并捕获生产编译器中的更多内部错误。 图1显示了DEEPFUZZ的工作流程。整个工作流程分为两个阶段，即程序生成和编译器测试。我们的目标是生产编译器。如GCC，GNU Compiler Collection（2018）和LLVM / Clang（Clang：LLVM 2018的C语言系列前端）。在第一阶段，我们使用来自原始人工编译器测试套件的收集数据训练生成的Sequence-to-Sequence模型。在我们将序列输入训练模型之前，我们对它们进行预处理以避免噪声数据。我们稍后在预处理中详细说明预处理步骤。我们要拟合的模型是一个通用的Sequence-to-Sequence模型，它有2层，每层有512个隐藏单元。我们将模型配置与实验设置中最先进的序列生成研究进行比较。对于程序生成，我们尝试不同的生成策略。我们详细介绍了生成策略及其在生成策略中的基本原理。因为我们的目标是模糊生产编译器，所以我们的目标是生成涵盖C语言最多功能的程序。因此，我们还采用了采样变量中详述的一些采样方法，以使生成的程序多样化。 在第二阶段，我们将生成的C程序（在语法上正确或不正确）提供给不同优化级别的编译器，并记录编译消息。除了编译消息之外，我们还记录执行跟踪以提供覆盖信息。总之，对于此程序生成任务，我们有三个目标：生成语法有效程序，改进代码覆盖率以及检测新错误。我们针对评估中的三个目标，对三个相关指标，合格率，覆盖率和错误进行了研究。 2.3 设计我们提出DEEPFUZZ持续性的为模糊测试生成编译器语法正确的C程序。如概述中所述，完整的工作流程包含两个阶段，即程序生成和编译器测试。在本节中，我们将介绍更多详细信息。 预处理在我们设置训练阶段之前，我们将序列分成多个固定大小的训练序列。每个训练序列的输出序列是输入序列旁边的下一个字符。我们将此训练过程配置为学习所有训练序列集的生成模型。但是，我们注意到连接序列中存在一些需要妥善处理的噪声。在预处理中，我们主要处理三个问题：注释，空格和宏。 注释。我们首先使用训练数据中正则表达式中的模式删除所有注释，包括行注释和块注释。 空格。根据POSIX标准，空白字符包括公共空格，水平制表符，垂直制表符，回车符，换行符和换页符。为了统一程序样式，我们用一个空格替换了所有空白字符。 宏。宏是C编程语言的常见特性。宏是一个代码片段，它已被赋予一个新名称。在我们的实现中，每当使用名称时，它总是被宏的内容替换。 2.4 采样变量我们使用学习的seq2seq模型来生成新的C程序。例如，利用前缀序列“int”，学习的分布很可能预测接下来是“main”。但是，我们的目标是使原始程序多样化，以生成更多生成的语句，如“int foo = 1;”或“int foo = bar（1）;”。因此，我们建议采用一些抽样方法来抽样学习的分布。我们在这里描述了我们用于生成新C程序的三种抽样方法：NoSample，Sample和SampleSpace。 NoSample。在这种抽样方法中，我们直接依靠学习的分布来贪婪地预测给定前缀的最佳下一个字符。 sample。为了克服NoSample方法的局限性，给定前缀序列，我们建议对下一个字符进行采样，而不是选择顶部预测的字符。 SampleSpace。此采样方法是Sample和NoSample的组合。在这种方法中，当前缀序列以空格结束时，我们只对阈值中所有预测值的下一个字符进行采样。 2.5 生成策略为了不断模糊生产编译器，我们使用学习模型生成C编程语言的新序列。我们将原始测试套件中的程序视为种子。基于原始程序中的序列作为前缀，我们将生成新代码。为了充分利用生成的序列，我们提出了三种生成策略：G1）我们将基于相同前缀序列的新生成的代码插入到原始格式良好的程序中; G2）我们生成新的代码片段，但是它们将使用从原始程序中的不同位置随机挑选的前缀序列生成，然后分别插回; G3）我们在原始程序的前缀序列之后删除相同数量的行，并将新生成的新行插入到已被删除的句子的位置。此外，可以在我们的框架内方便地建立更多的生成策略，但我们对这三种进行初步研究。 3 评估3.1实验设置为了评估DEEPFUZZ，我们流程化了一个原型工作流程，该工作流程基于一组语法正确的C程序训练了一个seq2seq模型。最初，收集了包含10,000个格式良好的C程序的训练数据集，并从GCC测试套件中采样。我们训练了具有2层的序列到序列模型，每层有512个LSTM单元。我们将dropout rate 设定为0.2。我们已经发布了源代码。 在先前关于文本生成的研究中（Sutskever，Martens和Hinton 2011），研究人员训练了一个具有超过100 MB训练数据的单层RNN，并且在这个单层模型中有1,500个隐藏单元。对于最接近的相关工作，Learn＆Fuzz（Godefroid，Peleg和Singh 2017）采用生成的序列到序列模型为PDF解析器模糊测试生成新的PDF对象，研究人员训练了一个具有两层的模型，并在每个层中，有128个隐藏单位。他们在包含534个格式良好的PDF文件的数据集上训练了这个模型。在我们的研究中，我们训练了一个两层模型，其中DEEPFUZZ框架的每一层都有512个LSTM单元。训练数据集包含从生产编译器测试套件中采样的10,000个语法正确的C程序，比以前的任何研究都要大。 我们在监督设置中训练了序列到序列模型。为了分析训练表现，我们训练了由通过次数或迭代参数化的多个模型。迭代被定义为学习算法的迭代，以遍历整套训练数据。我们在具有2.90GHz Intel Xeon（R）E5-2690 CPU和128GB内存的服务器机器上训练了50次迭代的模型。我们在五个不同数量的时期保留了模型的快照：10,20,30,40和50。训练一个迭代花了大约30分钟，整个训练阶段花了25个小时。对于新程序生成，如设计中所述，我们使用不同的采样方法和各种生成策略来生成新的C程序。新生成的程序仍然基于原始训练数据;换句话说，我们使用原始的C程序作为种子，我们从中随机选择前缀序列。通过插入新行或用新行替换行到种子中，我们可以获得新程序。由于新生成的部分将引入新的标识符，新的分支，新的功能等，它将使新生成的程序的控制流更复杂，从而提高测试效率。在我们的研究中，我们使用三个指标来衡量DEEPFUZZ的有效性： 通过率是衡量所有新生成的C程序中语法有效程序的比率的度量。序列到序列模型可能会将C语言模式编码到神经网络中。因此，通过率将是该网络在输入序列上的训练程度的良好指标。我们使用gcc的命令行来解析新生成的程序，如果没有报告错误，则表示该程序的语法正确性。 覆盖率是测试的特定度量。直观地说，测试涵盖的代码越多，我们就越确定测试的完整性。我们在分析过程中收集了三种覆盖信息：行覆盖范围，函数覆盖范围和分支覆盖范围。我们使用gcc支持的命令行工具gcov来收集覆盖信息。 错误检测是测试的目标。对于编译器测试，通过向不同优化级别的编译器提供更多程序，预计会触发崩溃或其他代码错误等错误。作为一种自我保护机制，像GCC和Clang / LLVM这样的编译器定义了一种称为“内部编译器错误”的特殊错误。此错误表示编译过程中编译器本身的问题，错误消息将帮助我们找到编译器中的错误。 3.2 通过率通过率是生成的语法有效程序与整个新生成程序集的比率。它是在所提出的序列到序列模型中C语言模式的编码程度的指标。在我们的评估中，具体而言，我们将分析通过率如何随着训练时期的数量，不同的采样方法和不同的生成策略而变化。 迭代迭代被定义为学习算法的迭代，以遍历整套训练数据。我们对模型进行了总共50个迭代的训练，我们在不同的时期拍摄了模型的快照：10,20,30,40,50，并将模型应用于新的C程序生成。我们在生成策略G1下尝试了所有三种抽样方法的过程。 结果：图2显示了结果。 通过率随着训练的迭代次数从10到30个增加而增加。 30个迭代周期后的合格率下降可能是过度拟合的结果。 所有采样方法的最佳通过率均在30个迭代周期的训练中实现。最高合格率为82.63％。 采样。训练模型后，我们采用了不同的采样方法。正如我们所提出的，采样方法决定了如何根据预测的分布选择新字符，它可以影响合格率。因此，我们根据种子程序在不同的采样方法下记录了新生成的10,000个程序的通过率：NoSample，Sample和SampleSpace。 结果：图2显示了结果。注意，该实验在生成策略G1下进行。 对于所有采样方法，通过率在训练的30个迭代周期内增加，之后，有一个小的下降。 比较所有三种采样方法的通过率，NoSample为每个快照模型实现了比其他两种方法Sample和SampleSpace更好的通过率。最高合格率为82.63％。 生成策略。为了生成新程序，我们引入了三代策略：G1）在一个位置插入两行，G2）在不同位置插入两行，并且G3）替换两条新行。新生成的行基于种子程序中选择的前缀序列。为了分析通过率如何随着不同的生成策略而变化，我们记录了在30个迭代之后使用训练模型执行程序生成的结果。另外，我们在这个实验中使用了NoSample。 结果：表1显示了结果。 三个生成策略的合格率分别为82.63％，79.86％和73.23％。比较这三种不同生成策略下的通过率，我们得出结论，在NoSample下，G1在通过率方面表现最佳。 G1和G2的结果在通过率方面相似，高于G3的通过率。原因可能是，删除行会引入不平衡的语句，例如未闭括号，括号或大括号。 3.3 覆盖率除了通过率之外，如本节开头所述，由于我们正在进行测试，因此覆盖率信息是另一个重要指标。在这一部分中，我们分析了如何通过不同的采样方法和生成策略实现覆盖率改进（行，函数，分支）。 采样。为了比较覆盖范围的改进，我们记录了覆盖率信息，包括原始种子测试套件（10,000）覆盖了多少行，函数和分支以及GCC-5和Clang-3新生成的测试套件（10,000） 。此外，为了分析抽样方法如何影响覆盖率的改善，我们记录了不同抽样方法下的覆盖率改善百分比。 结果：覆盖改进信息如表2所示，其中包含来自GEP-5的DEEPFUZZ的10,000个新生成的C程序的增强测试套件，并且比较指标，我们也在图3中显示。 在三种不同的采样方法中，Sample在行，函数和分支覆盖改进方面实现了最佳性能。例如，在生成策略G2下，NoSample，Sample和SampleSpace的线覆盖率改善分别为5.41％，7.76％和7.14％。 不同采样方法的不同生成策略的覆盖率改善模式相似。G2总是最好的，G1在三者中总是最差的。换句话说，抽样方法的表现与生成策略略有关联。 生成策略。除了抽样方法，我们还对如何在不同的生成策略下改进这三种不同的覆盖范围感兴趣。 结果：图3显示了使用G1，G2和G3如何改善覆盖范围。 比较三种不同发电策略下的覆盖范围改进，G2，即在不同位置插入两条新线路，在大多数情况下，在行，函数和分支覆盖范围改进方面实现了最佳性能。 与采样方法相比，采用生成策略是提高覆盖率的一个更有影响力的因素。例如，在SampleSpace下，三种生成策略的函数覆盖率改善百分比分别为0.17％，2.44％和1.72％。从G1变为G2后，覆盖率提高了42倍。 G2和G3在覆盖率改善方面表现相似，远高于G1。 总体。为了演示我们的工具如何在编译器模糊测试中执行，我们将DEEPFUZZ与用于编译器测试的精心设计的实用工具进行了比较。 Csmith（Yang et al.2011）是一个可以生成随机C程序的工具。为了进行公平的比较，我们记录了Csmith和DEEPFUZZ的覆盖范围改进，通过增加GCC和LLVM测试套件以及表3中的10,000个生成程序。 请注意，我们在进行此分析时使用Sample作为采样方法，使用G2作为我们的生成策略。我们还记录了图4中程序生成过程中的覆盖率改进。它演示了随着新测试数量的增加，行，函数和分支覆盖范围如何得到改善。 结果： 对于所有案例，Csmith将覆盖率提高了不到1％，而DEEPFUZZ分别将行，函数和分支的覆盖率提高了7.14％，2.44％和3.21％。 DEEPFUZZ实现了比Csmith更好的覆盖率改善。 DEEPFUZZ的覆盖率改善模式的性能与GCC-5和Clang-3相似。 3.4新错误使用不同的生成策略和抽样方法，基于GCC测试套件中的种子程序，我们可以生成新程序。因为我们的目标是编译器模糊，所以检测到的错误数量是DEEPFUZZ功效的重要指标。在我们的初步研究中，我们发现了8个新确认的GCC错误，我们将详细说明我们检测到的两个错误。 GCC错误84290：这是我们报告的错误。 DEEP FUZZ生成两个新行（第5行和第6行），它们触发内置函数原子载荷n的内部编译器错误。触发错误是因为此函数的第一个参数应该是指针，但它指向不完整的类型。此错误已修复，并且新测试（atomic-pr81231.c）已添加到GCC中的最新测试套件中。 这个检测到的错误显示了使用语法良好但语义无意义的测试进行编译器测试的重要性。 12345678double f () &#123; double r; asm (\"mov %S1,%S0; mov %R1,%R0\" : \"=r\" (r) : \"i\" (20)); asm (\"mov %S1,%S0; mov %R1,%R0\" : \"+r\" (r) : \"i\" (20.)); atomic load n ((enum E ∗) 0, 0); ; return r;&#125; GCC Bug 85443：这是我们报告的错误。 DEEPFUZZ生成两条新行（第5行和第6行），引入了新的崩溃。生成的Atomic是用于定义原子类型的关键字，第6行的赋值触发了分段错误。这是GCC-5上新确认的错误，已在最新版本中修复。这个由DEEPFUZZ检测到的错误再次显示了使用语法上格式良好但语义无意义的测试进行编译器测试的重要性。 1234567891011121314char acDummy[0xf0] attribute (( BELOW100 ));unsigned short B100 attribute (( BELOW100 ));unsigned short ∗p = &amp;B100;unsigned short wData = 0x1234;Atomic int i = 3;int a1 = sizeof (i + 1);void Do (void) fB100 = wData;gint main (void) f∗p = 0x9876;Do ();return (∗p == 0x1234) ? 0 : 1;g 4 限制观察生成的程序，我们注意到许多不正常的生成是由预期的表达式引起的。更具体地说，此错误消息表示错误，如不平衡的括号，括号或大括号。我们总结了导致这一问题的两个主要原因：缺乏训练和全局信息丢失。 由于第一个原因，训练数据很丰富，但在当前训练数据集中仍然缺乏足够的重复模式来训练良好的生成模型。在我们未来的工作中，我们可以通过枚举原始测试套件中具有新变量或函数名称的所有结构来创建更大的训练数据集。另一方面，因为生成基于前缀序列，所以它将丢失一些超出前缀序列范围的全局信息。为了解决这个问题，我们要么增加训练序列的长度以确保捕获足够的信息，要么我们可以使用一些启发式方法来帮助进行模型训练。前一种方法可能导致生成的程序中的多样性较少，后一种方法需要静态程序分析的帮助。 另外，我们提出的方法基于字符级序列到序列模型。我们为当前模型提供了一系列字符，这需要在处理令牌级语法时付出很多努力。它也会损害培训的可扩展性和通过率。在C中，少于32个关键字和100多个内置函数。如果我们通过Sequenceto-Sequence模型执行令牌级序列预测，则通过率和可伸缩性都将增加。 5 相关工作多年来，人们广泛讨论了基于AI的软件安全和软件分析应用程序（Zamir，Stern和Kalech 2014; Elmishali，Stern和Kalech 2016; Nath和Domingos 2016）。基于神经网络的模型在各种应用中占主导地位，并且使用它们进行程序分析（Allamanis和Sutton 2013; Nguyen等人2013）和合成（Lin等人2017; Devlin等人2017年）的兴趣大幅增长。 ）。循环神经网络，尤其是基于序列到序列的模型，已经开发用于从大型代码语料库中学习源代码的语言模型，然后将这些模型用于多种应用，例如学习自然编码约定，代码建议，自动完成和修复语法错误（ Bhatia和Singh 2016; Hindle等人，2012）。事实证明，在提供大量数据时，提高系统效率以及节省人力是有效的。此外，基于RNN的模型适用于基于语法的模糊测试（Godefroid，Peleg和Singh 2017; Cummins等。2018）学习生成模型以生成PDF文件以模糊PDF解析器。 6 结论和未来工作编译器测试对于确保计算系统的正确性至关重要。在本文中，我们提出了一种基于语法的自动模糊测试工具，称为DEEPFUZZ，它学习生成的递归神经网络，不断生成语法正确的C程序，以模糊现成的生产编译器。 DEEPFUZZ生成了82.63％语法有效的C程序，并提高了行，函数和分支覆盖的测试效率。我们还发现了开发人员正在积极解决的新漏洞。","content":"<h1 id=\"Abstract\"><a href=\"#Abstract\" class=\"headerlink\" title=\"Abstract\"></a>Abstract</h1><p>编译器是构建软件最基本的编程工具之一。但是，生产编译器仍然存在问题。模糊测试通常用于新生成或突变输入，以便发现新的错误或安全漏洞。在本文中，我们提出了一种名为DEEPFUZZ的基于语法的模糊测试工具。基于生成的seq2seq模型，DEEPFUZZ自动且连续地生成格式良好的C程序。我们使用这组新的C程序来模糊现成的C编译器，例如GCC和Clang / LLVM。我们提供了一个详细的案例研究来分析生成的C程序的模糊测试的成功率和覆盖率改进。我们用三种采样方法和三种生成策略来分析DEEPFUZZ的性能。因此，DEEPFUZZ在行，函数和分支覆盖方面提高了测试效率。在我们的初步研究中，我们发现并报告了8个GCC漏洞，所有这些漏洞都由开发人员积极处理。</p>\n<table>\n<thead>\n<tr>\n<th>relevant information</th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><em>作者</em></td>\n<td>Xiao Liu, Xiaoting Li, Rupesh Prajapati, Dinghao Wu</td>\n</tr>\n<tr>\n<td><em>单位</em></td>\n<td>College of Information Sciences and Technology<br>The Pennsylvania State University</td>\n</tr>\n<tr>\n<td><em>出处</em></td>\n<td><em>AAAI-19</em></td>\n</tr>\n<tr>\n<td><em>原文地址</em></td>\n<td><a href=\"https://faculty.ist.psu.edu/wu/papers/DeepFuzz.pdf\" target=\"_blank\" rel=\"noopener\">https://faculty.ist.psu.edu/wu/papers/DeepFuzz.pdf</a></td>\n</tr>\n<tr>\n<td><em>源码地址</em></td>\n<td><a href=\"https://github.com/wtwofire/deepfuzz\" target=\"_blank\" rel=\"noopener\">https://github.com/wtwofire/deepfuzz</a></td>\n</tr>\n<tr>\n<td><em>发表时间</em></td>\n<td>2019年</td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"1-简介\"><a href=\"#1-简介\" class=\"headerlink\" title=\"1. 简介\"></a>1. 简介</h1><p>编译器是最重要的计算系统软件之一，它们通常是信任计算基础的一部分，但它们仍然存在问题。例如，GCC是1987年发布的一款长效软件，是许多类Unix操作系统的标准编译器。自创建以来，已经捕获了超过3,410个内部错误（Yang et al.2011）。同样，对于Java，Python和JavaScript，在那些广泛使用的编译器和解释器中发现了数千个错误。这些编译器错误可能导致意外的程序执行，并导致安全敏感应用程序的灾难性后果。当在应用程序或编译器中无法确定根本原因时，它还可能妨碍开发人员在调试程序时的工作效率。因此，提高编译器的正确性至关重要。但用不断增长的代码库验证编译器并不容易：今天的GCC代码库大约有1500万行代码（Sun et al.2016），接近整个Linux内核，大约有1900万行代码。</p>\n<p>使编译器可靠是至关重要的。在过去十年中，编译器验证一直是计算研究中验证授权挑战的一个重要且活跃的领域（Hoare 2003）。主流研究侧重于形式验证（Leroy和Grall 2009），翻译验证（Necula 2000）和随机测试（Lidbury等人2015; Le，Afshari和Su 2014; Le，Sun和Su 2015）。前两个类别尝试提供经过认证的编译器。例如，CompCert（Leroy等人，2016）在这一领域取得了有希望的进展。但实际上，应用形式化技术来完全验证生成编译器（如GCC）是一项挑战，尤其是当证明不是与编译器一起构造时。因此，测试仍然是编译器验证的主要方法。</p>\n<p>我们的工作重点是编译器测试。通过向不同的生产编译器提供不同功能的程序，启用不同级别的优化，可以在编译期间触发内部编译器错误（编译器的真正错误），并显示错误消息指示错误的位置和内容。但是，生成“好”程序以提高测试效率并通过自动化此过程构建连续测试框架具有挑战性。在现有方法中，每个测试（包括人工测试）都涵盖了一些功能，现在通常可以看到现代编译器越来越大的测试套件。这提高了测试覆盖率，但构建这些测试需要花费大量人力。然而，荣国模糊测试的实用方法可以减少人力。</p>\n<p>Fuzzing（Bird和Munoz 1983）是一种发现漏洞或安全漏洞的方法。程序通过自动生成或修改的输入重复执行，以检测程序崩溃等异常行为。目前使用的输入模糊测试的主要技术是黑盒随机模糊测试（Zalewski 2015），基于白盒约束的模糊测试（Godefroid，Kiezun和Levin 2008），以及基于语法的模糊测试（Dewey，Roesch和Hardekopf 2014）。黑盒子和白盒模糊是完全自动的，并且历史证明在二进制格式文件解析器中找到安全漏洞是有效的。相反，基于语法的模糊测试需要输入语法，该输入语法指定被测应用程序的输入格式，该输入格式通常是手工编写的。这个过程费力，耗时且容易出错。然而，基于语法的模糊测试是当今已知的用于具有复杂结构化输入格式的模糊应用的最有效的模糊测试技术，例如编译器。在编译器测试的场景中，部署基于语法的模糊测试的一种方法是将C语法编码为测试用例生成的规则。但实际上，C11（国际标准化组织（ISO）2011），C编程语言的当前标准，有696页的详细规范，这为工程师构建这样一个基于语法的引擎带来了障碍。<br>在本文中，我们考虑使用生成递归神经网络自动生成语法有效输入的语法有效输入的问题。更具体地说，我们的目标是训练生成神经网络，以学习输入数据的“语法”，或者更确切地说，语言模式。我们建议在监督学习策略中训练序列到序列模型（Sutskever，Vinyals和Le 2014），利用生产编译器提供的原始测试套件。最初，序列到序列模型广泛用于机器翻译（Klein等人2017）和文本生成（Sutskever，Martens和Hinton 2011）。从理论上讲，通过训练原始段落的模型，我们隐含地将正确的单词拼写，句子的有效语法，写作行为的详细风格编码到生成模型中。同样的想法可以应用于程序综合，其中我们只需要训练模型以在种子数据集之上生成不同的语法上有效的程序。对于训练数据集，我们采用了原始的GCC测试套件，其中有超过10,000个短程序或小程序，涵盖了C11标准中规定的大多数功能。在训练阶段，我们调整参数以将C程序的语言模式编码到模型中，基于此，我们不断生成用于编译器模糊测试的新程序。<br>贡献。我们的工作是第一个使用生成递归神经网络进行基于语法的编译器模糊测试。</p>\n<ul>\n<li>首先，拟议的框架是全自动的。通过训练序列到序列模型，可以将其视为训练数据语言模式的隐式表示，在我们的上下文中使用C语法，我们的框架DEEPFUZZ将不断提供新的语法正确的C程序。</li>\n<li>其次，我们构建了一个用于模糊现成的C编译器的实用工具。我们详细分析了关键因素将如何影响生成模型和模糊性能的准确性。</li>\n<li>•第三，我们应用DEEPFUZZ技术测试GCC和Clang / LLVM。在我们的初步分析期间，测试覆盖范围（线路，功能和分支）增加，我们发现并报告了8个真实的错误。</li>\n</ul>\n<p>Fuzzing（Bird和Munoz 1983）是一种发现漏洞或安全漏洞的方法。程序通过自动生成或修改的输入重复执行，以检测程序崩溃等异常行为。目前使用的输入模糊测试的主要技术是黑盒随机模糊测试（Zalewski 2015），基于白盒约束的模糊测试（Godefroid，Kiezun和Levin 2008），以及基于语法的模糊测试（Dewey，Roesch和Hardekopf 2014）。黑盒子和白盒模糊是完全自动的，并且历史证明在二进制格式文件解析器中找到安全漏洞是有效的。相反，基于语法的模糊测试需要输入语法，该输入语法指定被测应用程序的输入格式，该输入格式通常是手工编写的。这个过程费力，耗时且容易出错。然而，基于语法的模糊测试是当今已知的用于具有复杂结构化输入格式的模糊应用的最有效的模糊测试技术，例如编译器。在编译器测试的场景中，部署基于语法的模糊测试的一种方法是将C语法编码为测试用例生成的规则。但实际上，C11（国际标准化组织（ISO）2011），C编程语言的当前标准，有696页的详细规范，这为工程师构建这样一个基于语法的引擎带来了障碍。</p>\n<p>在本文中，我们考虑使用生成递归神经网络自动生成语法有效输入用于基于语法的fuzzing。更具体地说，我们的目标是训练生成神经网络，以学习输入数据的“语法”，或者更确切地说，语言模式。我们建议在监督学习策略中训练seq2seq模型（Sutskever，Vinyals和Le 2014），利用生产编译器提供的原始测试套件。最初，seq2seq模型广泛用于机器翻译（Klein等人2017）和文本生成（Sutskever，Martens和Hinton 2011）。从理论上讲，通过训练原始段落的模型，我们隐含地将正确的单词拼写，句子的有效语法，写作行为的详细风格编码到生成模型中。同样的想法可以应用于程序综合，其中我们只需要训练模型以在种子数据集之上生成不同的语法上有效的程序。对于训练数据集，我们采用了原始的GCC测试套件，其中有超过10,000个短程序或小程序，涵盖了C11标准中规定的大多数功能。在训练阶段，我们调整参数以将C程序的语言模式编码到模型中，基于此，我们不断生成用于编译器模糊测试的新程序。</p>\n<p><strong>贡献</strong>。我们的工作是第一个使用生成递归神经网络进行基于语法的编译器模糊测试。</p>\n<ul>\n<li>首先，拟议的框架是全自动的。通过训练seq2seq模型，可以将其视为训练数据语言模式的隐式表示，在我们的上下文中使用C语法，我们的框架DEEPFUZZ将不断提供新的语法正确的C程序。</li>\n<li>其次，我们构建了一个用于模糊现成的C编译器的实用工具。我们详细分析了关键因素将如何影响生成模型和模糊性能的准确性。</li>\n<li>第三，我们应用DEEPFUZZ技术测试GCC和Clang / LLVM。在我们的初步分析期间，测试覆盖范围（行，函数和分支）增加，我们发现并报告了8个真实的错误。</li>\n</ul>\n<h1 id=\"2-概述\"><a href=\"#2-概述\" class=\"headerlink\" title=\"2.概述\"></a>2.概述</h1><h2 id=\"2-1-seq2seq模型\"><a href=\"#2-1-seq2seq模型\" class=\"headerlink\" title=\"2.1 seq2seq模型\"></a>2.1 seq2seq模型</h2><p>我们在seq2seq模型的基础上构建DEEPFUZZ，该模型实现了两个用于字符级序列预测的递归神经网络（RNN）。 RNN是由隐藏状态h和可选输出y组成的神经网络。它在可变长度序列上运行，x =（x~1~, x~2~……x~T~）。在每个步骤t，更新RNN的隐藏状态h~<t>~<br>$$<br>h_{<t>} = f(h_{t−1}, x_t)<br>$$<br>其中f是非线性激活函数。 RNN可以学习字符序列上的概率分布以预测下一个符号。因此，在每个时间步t，来自RNN的输出是条件分布p（x~t~ |x~t-1~……x~1~）。例如，在我们的例子中，在下一个字符的多项分布时，我们使用softmax激活函数作为输出<br>$$<br>p(x_{t,j} = 1| x_{t−1},……,x_1) = \\frac{ exp(w_jh_{<t>})}<br>{\\sum_{j=1}^Kexp(w_jh_{<t>})}<br>$$<br>对于所有可能的符号j = 1,……,K ，其中 w~j~ 是权重矩阵W的行。通过组合这些概率，我们计算序列x使用的概率<br>$$<br>p(x) =\\prod_{t=1}^T<br>p(x_{t,j} = 1| x_{t−1},……,x_1)<br>$$<br>通过学习的分布，通过在每个时间步迭代地采样新字符来生成新序列是直截了当的。</t></t></t></t></p>\n<p>seq2seq模型由两个RNN，编码器和解码器组成。编码器学习将可变长度序列编码为固定长度矢量表示，并且解码器将该固定长度矢量表示解码为可变长度序列。它最初是由Cho等人 （2014）提出的，用于统计机器翻译。编码器RNN读取输入序列x的每个字符，同时RNN的隐藏状态改变。在读取该序列的结束之后，RNN的隐藏状态是整个输入序列的概要c。同时，训练解码器RNN以通过预测给定隐藏状态h~<t>~的下一个字符y~t~来产生输出序列。然而，与纯RNN不同，y~t~和h~<t>~也都以y~t-1~和输入序列的摘要c为条件。在这种情况下，为了计算解码器的隐藏状态，我们有<br>$$<br>h_{<t>}= f(h_{<t-1>}, y_{t−1}, c)<br>$$<br>同样地，下一个字符的条件分布是<br>$$<br>p(y_t|y_{t−1}，……，y_1， c) = g(hti; yt−1; c);<br>$$<br>其中 f 和 g 是激活函数。总的来说，两个RNN编码器 - 解码器被联合训练以在给定输入序列的情况下生成目标序列。<br>所有RNN在循环层中都有反馈循环。</t-1></t></t></t></p>\n<p>这种设计允许他们随着时间的推移将信息保存在“记忆”中。然而，训练标准RNN以学习长期时间依赖性可能是困难的，但这在程序中是常见的。这是因为损失函数的梯度随时间呈指数衰减（Chung et al.2014）。因此，在我们的设计中，我们采用RNN的变体，长短期记忆（LSTM），特别是在我们的编码器和解码器中。 LSTM单元包括“存储器单元”，其可以将信息长时间保存在存储器中，在这种情况下可以存储长历史信息。</p>\n<p>在以前的研究中，seq2seq模型已经过训练，可以生成语法正确的PDF对象来模糊PDF解析器（Godefroid，Peleg和Singh 2017）。这项工作背后的核心思想是，源语言语法可以作为字符串对的训练副产品来学习。 Shi，Padhi和Knight（2016）通过实验研究了seq2seq模型可以学习关于源句的局部和全局句法信息。这项工作为RNN的正式语言合成奠定了基础。在我们的论文中，我们对编译器模糊测试应用了类似的想法。在训练期间，我们将序列分成固定大小为d的多个训练序列。通过剪切序列，我们得到第i个训练序列xi = s [i <em> d：（i + 1）</em> d]，其中s [k：l]是索引k和l之间s的子序列。每个训练序列的输出序列是下一个字符，即yt = s [（i + 1）* d + 1]。我们将此训练过程配置为学习一组训练序列的生成模型。</p>\n<h2 id=\"2-2-工作流程\"><a href=\"#2-2-工作流程\" class=\"headerlink\" title=\"2.2 工作流程\"></a>2.2 工作流程</h2><p>一般而言，我们建议DEEPFUZZ用于两个主要目标。第一种是从一组语法正确的程序中生成遵循合法语法的新程序。主要挑战来自长序列处理和语言语法表示。第二个目标是提高编译器测试效率。我们的目标是提高覆盖率并捕获生产编译器中的更多内部错误。</p>\n<p><img src=\"/2019/04/18/DeepFuzz-Automatic-Generation-of-Syntax-Valid-C-Programs-for-Fuzz-Testing/1.jpg\" alt=\"\"></p>\n<p>图1显示了DEEPFUZZ的工作流程。整个工作流程分为两个阶段，即程序生成和编译器测试。我们的目标是生产编译器。如GCC，GNU Compiler Collection（2018）和LLVM / Clang（Clang：LLVM 2018的C语言系列前端）。在第一阶段，我们使用来自原始人工编译器测试套件的收集数据训练生成的Sequence-to-Sequence模型。在我们将序列输入训练模型之前，我们对它们进行预处理以避免噪声数据。我们稍后在预处理中详细说明预处理步骤。我们要拟合的模型是一个通用的Sequence-to-Sequence模型，它有2层，每层有512个隐藏单元。我们将模型配置与实验设置中最先进的序列生成研究进行比较。对于程序生成，我们尝试不同的生成策略。我们详细介绍了生成策略及其在生成策略中的基本原理。因为我们的目标是模糊生产编译器，所以我们的目标是生成涵盖C语言最多功能的程序。因此，我们还采用了采样变量中详述的一些采样方法，以使生成的程序多样化。</p>\n<p>在第二阶段，我们将生成的C程序（在语法上正确或不正确）提供给不同优化级别的编译器，并记录编译消息。除了编译消息之外，我们还记录执行跟踪以提供覆盖信息。总之，对于此程序生成任务，我们有三个目标：生成语法有效程序，改进代码覆盖率以及检测新错误。我们针对评估中的三个目标，对三个相关指标，合格率，覆盖率和错误进行了研究。</p>\n<h2 id=\"2-3-设计\"><a href=\"#2-3-设计\" class=\"headerlink\" title=\"2.3 设计\"></a>2.3 设计</h2><p>我们提出DEEPFUZZ持续性的为模糊测试生成编译器语法正确的C程序。如概述中所述，完整的工作流程包含两个阶段，即程序生成和编译器测试。在本节中，我们将介绍更多详细信息。</p>\n<p>预处理在我们设置训练阶段之前，我们将序列分成多个固定大小的训练序列。每个训练序列的输出序列是输入序列旁边的下一个字符。我们将此训练过程配置为学习所有训练序列集的生成模型。但是，我们注意到连接序列中存在一些需要妥善处理的噪声。在预处理中，我们主要处理三个问题：注释，空格和宏。</p>\n<ul>\n<li><p><strong>注释</strong>。我们首先使用训练数据中正则表达式中的模式删除所有注释，包括行注释和块注释。</p>\n</li>\n<li><p><strong>空格</strong>。根据POSIX标准，空白字符包括公共空格，水平制表符，垂直制表符，回车符，换行符和换页符。为了统一程序样式，我们用一个空格替换了所有空白字符。</p>\n</li>\n<li><p><strong>宏</strong>。宏是C编程语言的常见特性。宏是一个代码片段，它已被赋予一个新名称。在我们的实现中，每当使用名称时，它总是被宏的内容替换。</p>\n</li>\n</ul>\n<h2 id=\"2-4-采样变量\"><a href=\"#2-4-采样变量\" class=\"headerlink\" title=\"2.4 采样变量\"></a>2.4 采样变量</h2><p>我们使用学习的seq2seq模型来生成新的C程序。例如，利用前缀序列“int”，学习的分布很可能预测接下来是“main”。但是，我们的目标是使原始程序多样化，以生成更多生成的语句，如“int foo = 1;”或“int foo = bar（1）;”。因此，我们建议采用一些抽样方法来抽样学习的分布。我们在这里描述了我们用于生成新C程序的三种抽样方法：NoSample，Sample和SampleSpace。</p>\n<p><strong>NoSample</strong>。在这种抽样方法中，我们直接依靠学习的分布来贪婪地预测给定前缀的最佳下一个字符。</p>\n<p><strong>sample</strong>。为了克服NoSample方法的局限性，给定前缀序列，我们建议对下一个字符进行采样，而不是选择顶部预测的字符。</p>\n<p><strong>SampleSpace</strong>。此采样方法是Sample和NoSample的组合。在这种方法中，当前缀序列以空格结束时，我们只对阈值中所有预测值的下一个字符进行采样。</p>\n<h2 id=\"2-5-生成策略\"><a href=\"#2-5-生成策略\" class=\"headerlink\" title=\"2.5 生成策略\"></a>2.5 生成策略</h2><p>为了不断模糊生产编译器，我们使用学习模型生成C编程语言的新序列。我们将原始测试套件中的程序视为种子。基于原始程序中的序列作为前缀，我们将生成新代码。为了充分利用生成的序列，我们提出了三种生成策略：G1）我们将基于相同前缀序列的新生成的代码插入到原始格式良好的程序中; G2）我们生成新的代码片段，但是它们将使用从原始程序中的不同位置随机挑选的前缀序列生成，然后分别插回; G3）我们在原始程序的前缀序列之后删除相同数量的行，并将新生成的新行插入到已被删除的句子的位置。此外，可以在我们的框架内方便地建立更多的生成策略，但我们对这三种进行初步研究。</p>\n<h1 id=\"3-评估\"><a href=\"#3-评估\" class=\"headerlink\" title=\"3 评估\"></a>3 评估</h1><h2 id=\"3-1实验设置\"><a href=\"#3-1实验设置\" class=\"headerlink\" title=\"3.1实验设置\"></a>3.1实验设置</h2><p>为了评估DEEPFUZZ，我们流程化了一个原型工作流程，该工作流程基于一组语法正确的C程序训练了一个seq2seq模型。最初，收集了包含10,000个格式良好的C程序的训练数据集，并从GCC测试套件中采样。我们训练了具有2层的序列到序列模型，每层有512个LSTM单元。我们将dropout rate 设定为0.2。我们已经发布了源代码。</p>\n<p>在先前关于文本生成的研究中（Sutskever，Martens和Hinton 2011），研究人员训练了一个具有超过100 MB训练数据的单层RNN，并且在这个单层模型中有1,500个隐藏单元。对于最接近的相关工作，Learn＆Fuzz（Godefroid，Peleg和Singh 2017）采用生成的序列到序列模型为PDF解析器模糊测试生成新的PDF对象，研究人员训练了一个具有两层的模型，并在每个层中，有128个隐藏单位。他们在包含534个格式良好的PDF文件的数据集上训练了这个模型。在我们的研究中，我们训练了一个两层模型，其中DEEPFUZZ框架的每一层都有512个LSTM单元。训练数据集包含从生产编译器测试套件中采样的10,000个语法正确的C程序，比以前的任何研究都要大。</p>\n<p>我们在监督设置中训练了序列到序列模型。为了分析训练表现，我们训练了由通过次数或迭代参数化的多个模型。迭代被定义为学习算法的迭代，以遍历整套训练数据。我们在具有2.90GHz Intel Xeon（R）E5-2690 CPU和128GB内存的服务器机器上训练了50次迭代的模型。我们在五个不同数量的时期保留了模型的快照：10,20,30,40和50。训练一个迭代花了大约30分钟，整个训练阶段花了25个小时。对于新程序生成，如设计中所述，我们使用不同的采样方法和各种生成策略来生成新的C程序。新生成的程序仍然基于原始训练数据;换句话说，我们使用原始的C程序作为种子，我们从中随机选择前缀序列。通过插入新行或用新行替换行到种子中，我们可以获得新程序。由于新生成的部分将引入新的标识符，新的分支，新的功能等，它将使新生成的程序的控制流更复杂，从而提高测试效率。<br>在我们的研究中，我们使用三个指标来衡量DEEPFUZZ的有效性：</p>\n<ul>\n<li><strong>通过率</strong>是衡量所有新生成的C程序中语法有效程序的比率的度量。序列到序列模型可能会将C语言模式编码到神经网络中。因此，通过率将是该网络在输入序列上的训练程度的良好指标。我们使用gcc的命令行来解析新生成的程序，如果没有报告错误，则表示该程序的语法正确性。</li>\n<li><strong>覆盖率</strong>是测试的特定度量。直观地说，测试涵盖的代码越多，我们就越确定测试的完整性。我们在分析过程中收集了三种覆盖信息：行覆盖范围，函数覆盖范围和分支覆盖范围。我们使用gcc支持的命令行工具gcov来收集覆盖信息。</li>\n<li>错误检测是测试的目标。对于编译器测试，通过向不同优化级别的编译器提供更多程序，预计会触发崩溃或其他代码错误等错误。作为一种自我保护机制，像GCC和Clang / LLVM这样的编译器定义了一种称为“内部编译器错误”的特殊错误。此错误表示编译过程中编译器本身的问题，错误消息将帮助我们找到编译器中的错误。</li>\n</ul>\n<h2 id=\"3-2-通过率\"><a href=\"#3-2-通过率\" class=\"headerlink\" title=\"3.2 通过率\"></a>3.2 通过率</h2><p>通过率是生成的语法有效程序与整个新生成程序集的比率。它是在所提出的序列到序列模型中C语言模式的编码程度的指标。在我们的评估中，具体而言，我们将分析通过率如何随着训练时期的数量，不同的采样方法和不同的生成策略而变化。</p>\n<p><strong>迭代</strong>迭代被定义为学习算法的迭代，以遍历整套训练数据。我们对模型进行了总共50个迭代的训练，我们在不同的时期拍摄了模型的快照：10,20,30,40,50，并将模型应用于新的C程序生成。我们在生成策略G1下尝试了所有三种抽样方法的过程。</p>\n<p>结果：图2显示了结果。</p>\n<ul>\n<li>通过率随着训练的迭代次数从10到30个增加而增加。 30个迭代周期后的合格率下降可能是过度拟合的结果。</li>\n<li>所有采样方法的最佳通过率均在30个迭代周期的训练中实现。最高合格率为82.63％。</li>\n</ul>\n<p><strong>采样</strong>。训练模型后，我们采用了不同的采样方法。正如我们所提出的，采样方法决定了如何根据预测的分布选择新字符，它可以影响合格率。因此，我们根据种子程序在不同的采样方法下记录了新生成的10,000个程序的通过率：NoSample，Sample和SampleSpace。</p>\n<p><img src=\"/2019/04/18/DeepFuzz-Automatic-Generation-of-Syntax-Valid-C-Programs-for-Fuzz-Testing/2.jpg\" alt=\"\"></p>\n<p>结果：图2显示了结果。注意，该实验在生成策略G1下进行。</p>\n<ul>\n<li>对于所有采样方法，通过率在训练的30个迭代周期内增加，之后，有一个小的下降。</li>\n<li>比较所有三种采样方法的通过率，NoSample为每个快照模型实现了比其他两种方法Sample和SampleSpace更好的通过率。最高合格率为82.63％。</li>\n</ul>\n<p><strong>生成策略</strong>。为了生成新程序，我们引入了三代策略：G1）在一个位置插入两行，G2）在不同位置插入两行，并且G3）替换两条新行。新生成的行基于种子程序中选择的前缀序列。为了分析通过率如何随着不同的生成策略而变化，我们记录了在30个迭代之后使用训练模型执行程序生成的结果。另外，我们在这个实验中使用了NoSample。</p>\n<p>结果：表1显示了结果。</p>\n<p><img src=\"/2019/04/18/DeepFuzz-Automatic-Generation-of-Syntax-Valid-C-Programs-for-Fuzz-Testing/3.jpg\" alt=\"\"></p>\n<ul>\n<li><p>三个生成策略的合格率分别为82.63％，79.86％和73.23％。比较这三种不同生成策略下的通过率，我们得出结论，在NoSample下，G1在通过率方面表现最佳。</p>\n</li>\n<li><p>G1和G2的结果在通过率方面相似，高于G3的通过率。原因可能是，删除行会引入不平衡的语句，例如未闭括号，括号或大括号。</p>\n</li>\n</ul>\n<h2 id=\"3-3-覆盖率\"><a href=\"#3-3-覆盖率\" class=\"headerlink\" title=\"3.3 覆盖率\"></a>3.3 覆盖率</h2><p>除了通过率之外，如本节开头所述，由于我们正在进行测试，因此覆盖率信息是另一个重要指标。在这一部分中，我们分析了如何通过不同的采样方法和生成策略实现覆盖率改进（行，函数，分支）。</p>\n<p><strong>采样</strong>。为了比较覆盖范围的改进，我们记录了覆盖率信息，包括原始种子测试套件（10,000）覆盖了多少行，函数和分支以及GCC-5和Clang-3新生成的测试套件（10,000） 。此外，为了分析抽样方法如何影响覆盖率的改善，我们记录了不同抽样方法下的覆盖率改善百分比。</p>\n<p>结果：覆盖改进信息如表2所示，其中包含来自GEP-5的DEEPFUZZ的10,000个新生成的C程序的增强测试套件，并且比较指标，我们也在图3中显示。</p>\n<p><img src=\"/2019/04/18/DeepFuzz-Automatic-Generation-of-Syntax-Valid-C-Programs-for-Fuzz-Testing/4.jpg\" alt=\"\"></p>\n<p><img src=\"/2019/04/18/DeepFuzz-Automatic-Generation-of-Syntax-Valid-C-Programs-for-Fuzz-Testing/5.jpg\" alt=\"\"></p>\n<ul>\n<li>在三种不同的采样方法中，Sample在行，函数和分支覆盖改进方面实现了最佳性能。例如，在生成策略G2下，NoSample，Sample和SampleSpace的线覆盖率改善分别为5.41％，7.76％和7.14％。</li>\n<li>不同采样方法的不同生成策略的覆盖率改善模式相似。G2总是最好的，G1在三者中总是最差的。换句话说，抽样方法的表现与生成策略略有关联。</li>\n</ul>\n<p><strong>生成策略</strong>。除了抽样方法，我们还对如何在不同的生成策略下改进这三种不同的覆盖范围感兴趣。</p>\n<p>结果：图3显示了使用G1，G2和G3如何改善覆盖范围。</p>\n<ul>\n<li>比较三种不同发电策略下的覆盖范围改进，G2，即在不同位置插入两条新线路，在大多数情况下，在行，函数和分支覆盖范围改进方面实现了最佳性能。</li>\n<li>与采样方法相比，采用生成策略是提高覆盖率的一个更有影响力的因素。例如，在SampleSpace下，三种生成策略的函数覆盖率改善百分比分别为0.17％，2.44％和1.72％。从G1变为G2后，覆盖率提高了42倍。</li>\n<li>G2和G3在覆盖率改善方面表现相似，远高于G1。</li>\n</ul>\n<p><strong>总体</strong>。为了演示我们的工具如何在编译器模糊测试中执行，我们将DEEPFUZZ与用于编译器测试的精心设计的实用工具进行了比较。 Csmith（Yang et al.2011）是一个可以生成随机C程序的工具。为了进行公平的比较，我们记录了Csmith和DEEPFUZZ的覆盖范围改进，通过增加GCC和LLVM测试套件以及表3中的10,000个生成程序。</p>\n<p>请注意，我们在进行此分析时使用Sample作为采样方法，使用G2作为我们的生成策略。我们还记录了图4中程序生成过程中的覆盖率改进。它演示了随着新测试数量的增加，行，函数和分支覆盖范围如何得到改善。</p>\n<p><img src=\"/2019/04/18/DeepFuzz-Automatic-Generation-of-Syntax-Valid-C-Programs-for-Fuzz-Testing/6.jpg\" alt=\"\"></p>\n<p>结果：</p>\n<ul>\n<li>对于所有案例，Csmith将覆盖率提高了不到1％，而DEEPFUZZ分别将行，函数和分支的覆盖率提高了7.14％，2.44％和3.21％。 DEEPFUZZ实现了比Csmith更好的覆盖率改善。</li>\n<li>DEEPFUZZ的覆盖率改善模式的性能与GCC-5和Clang-3相似。</li>\n</ul>\n<p><img src=\"/2019/04/18/DeepFuzz-Automatic-Generation-of-Syntax-Valid-C-Programs-for-Fuzz-Testing/7.jpg\" alt=\"\"></p>\n<h2 id=\"3-4新错误\"><a href=\"#3-4新错误\" class=\"headerlink\" title=\"3.4新错误\"></a>3.4新错误</h2><p>使用不同的生成策略和抽样方法，基于GCC测试套件中的种子程序，我们可以生成新程序。因为我们的目标是编译器模糊，所以检测到的错误数量是DEEPFUZZ功效的重要指标。在我们的初步研究中，我们发现了8个新确认的GCC错误，我们将详细说明我们检测到的两个错误。</p>\n<p><strong>GCC错误84290</strong>：这是我们报告的错误。 DEEP FUZZ生成两个新行（第5行和第6行），它们触发内置函数原子载荷n的内部编译器错误。触发错误是因为此函数的第一个参数应该是指针，但它指向不完整的类型。此错误已修复，并且新测试（atomic-pr81231.c）已添加到GCC中的最新测试套件中。  这个检测到的错误显示了使用语法良好但语义无意义的测试进行编译器测试的重要性。</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">double</span> <span class=\"title\">f</span> <span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">double</span> r;</span><br><span class=\"line\">\t<span class=\"keyword\">asm</span> (<span class=\"string\">\"mov %S1,%S0; mov %R1,%R0\"</span> : <span class=\"string\">\"=r\"</span> (r) : <span class=\"string\">\"i\"</span> (<span class=\"number\">20</span>));</span><br><span class=\"line\">\t<span class=\"keyword\">asm</span> (<span class=\"string\">\"mov %S1,%S0; mov %R1,%R0\"</span> : <span class=\"string\">\"+r\"</span> (r) : <span class=\"string\">\"i\"</span> (<span class=\"number\">20.</span>));</span><br><span class=\"line\">\t<span class=\"function\">atomic load <span class=\"title\">n</span> <span class=\"params\">((<span class=\"keyword\">enum</span> E ∗) <span class=\"number\">0</span>, <span class=\"number\">0</span>)</span></span>;</span><br><span class=\"line\">\t;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> r;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><strong>GCC Bug 85443</strong>：这是我们报告的错误。 DEEPFUZZ生成两条新行（第5行和第6行），引入了新的崩溃。生成的Atomic是用于定义原子类型的关键字，第6行的赋值触发了分段错误。这是GCC-5上新确认的错误，已在最新版本中修复。这个由DEEPFUZZ检测到的错误再次显示了使用语法上格式良好但语义无意义的测试进行编译器测试的重要性。</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">char</span> acDummy[<span class=\"number\">0xf0</span>] attribute (( BELOW100 ));</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">unsigned</span> <span class=\"keyword\">short</span> B100 <span class=\"title\">attribute</span> <span class=\"params\">(( BELOW100 ))</span></span>;</span><br><span class=\"line\"><span class=\"keyword\">unsigned</span> <span class=\"keyword\">short</span> ∗p = &amp;B100;</span><br><span class=\"line\"><span class=\"keyword\">unsigned</span> <span class=\"keyword\">short</span> wData = <span class=\"number\">0x1234</span>;</span><br><span class=\"line\">Atomic <span class=\"keyword\">int</span> i = <span class=\"number\">3</span>;</span><br><span class=\"line\"><span class=\"keyword\">int</span> a1 = <span class=\"keyword\">sizeof</span> (i + <span class=\"number\">1</span>);</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">Do</span> <span class=\"params\">(<span class=\"keyword\">void</span>)</span> f</span></span><br><span class=\"line\"><span class=\"function\">B100 </span>= wData;</span><br><span class=\"line\">g</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span> <span class=\"params\">(<span class=\"keyword\">void</span>)</span> f</span></span><br><span class=\"line\">∗p = 0x9876;</span><br><span class=\"line\">Do ();</span><br><span class=\"line\"><span class=\"keyword\">return</span> (∗p == <span class=\"number\">0x1234</span>) ? <span class=\"number\">0</span> : <span class=\"number\">1</span>;</span><br><span class=\"line\">g</span><br></pre></td></tr></table></figure>\n<h1 id=\"4-限制\"><a href=\"#4-限制\" class=\"headerlink\" title=\"4 限制\"></a>4 限制</h1><p>观察生成的程序，我们注意到许多不正常的生成是由预期的表达式引起的。更具体地说，此错误消息表示错误，如不平衡的括号，括号或大括号。我们总结了导致这一问题的两个主要原因：缺乏训练和全局信息丢失。</p>\n<p>由于第一个原因，训练数据很丰富，但在当前训练数据集中仍然缺乏足够的重复模式来训练良好的生成模型。在我们未来的工作中，我们可以通过枚举原始测试套件中具有新变量或函数名称的所有结构来创建更大的训练数据集。另一方面，因为生成基于前缀序列，所以它将丢失一些超出前缀序列范围的全局信息。为了解决这个问题，我们要么增加训练序列的长度以确保捕获足够的信息，要么我们可以使用一些启发式方法来帮助进行模型训练。前一种方法可能导致生成的程序中的多样性较少，后一种方法需要静态程序分析的帮助。</p>\n<p>另外，我们提出的方法基于字符级序列到序列模型。我们为当前模型提供了一系列字符，这需要在处理令牌级语法时付出很多努力。它也会损害培训的可扩展性和通过率。在C中，少于32个关键字和100多个内置函数。如果我们通过Sequenceto-Sequence模型执行令牌级序列预测，则通过率和可伸缩性都将增加。</p>\n<h1 id=\"5-相关工作\"><a href=\"#5-相关工作\" class=\"headerlink\" title=\"5 相关工作\"></a>5 相关工作</h1><p>多年来，人们广泛讨论了基于AI的软件安全和软件分析应用程序（Zamir，Stern和Kalech 2014; Elmishali，Stern和Kalech 2016; Nath和Domingos 2016）。基于神经网络的模型在各种应用中占主导地位，并且使用它们进行程序分析（Allamanis和Sutton 2013; Nguyen等人2013）和合成（Lin等人2017; Devlin等人2017年）的兴趣大幅增长。 ）。循环神经网络，尤其是基于序列到序列的模型，已经开发用于从大型代码语料库中学习源代码的语言模型，然后将这些模型用于多种应用，例如学习自然编码约定，代码建议，自动完成和修复语法错误（ Bhatia和Singh 2016; Hindle等人，2012）。事实证明，在提供大量数据时，提高系统效率以及节省人力是有效的。此外，基于RNN的模型适用于基于语法的模糊测试（Godefroid，Peleg和Singh 2017; Cummins等。2018）学习生成模型以生成PDF文件以模糊PDF解析器。</p>\n<h1 id=\"6-结论和未来工作\"><a href=\"#6-结论和未来工作\" class=\"headerlink\" title=\"6 结论和未来工作\"></a>6 结论和未来工作</h1><p>编译器测试对于确保计算系统的正确性至关重要。在本文中，我们提出了一种基于语法的自动模糊测试工具，称为DEEPFUZZ，它学习生成的递归神经网络，不断生成语法正确的C程序，以模糊现成的生产编译器。 DEEPFUZZ生成了82.63％语法有效的C程序，并提高了行，函数和分支覆盖的测试效率。我们还发现了开发人员正在积极解决的新漏洞。</p>\n","categories":[{"name":"论文","slug":"论文","permalink":"http://yama0xff.com/categories/论文/"},{"name":"fuzzing","slug":"论文/fuzzing","permalink":"http://yama0xff.com/categories/论文/fuzzing/"},{"name":"机器学习","slug":"论文/fuzzing/机器学习","permalink":"http://yama0xff.com/categories/论文/fuzzing/机器学习/"}],"tags":[{"name":"fuzzing","slug":"fuzzing","permalink":"http://yama0xff.com/tags/fuzzing/"},{"name":"机器学习","slug":"机器学习","permalink":"http://yama0xff.com/tags/机器学习/"}]},{"title":"Neural Fuzzing: A Neural Approach to Generate Test Data for File Format Fuzzing","date":"2019-04-17T08:53:14.000Z","path":"2019/04/17/Neural-Fuzzing-A-Neural-Approach-to-Generate-Test-Data-for-File-Format-Fuzzing/","text":"Abstract本文旨在设计和实现文件格式模糊器。文件是大多数实际应用程序的重要输入。将输入文件生成为测试数据的实质难点在于重新调整文件的基础结构和格式。为了区分存储在文件中的纯数据和描述文件格式的元数据，本文提出了一种基于神经语言模型的深度学习方法。得到的学习模型可以作为混合测试数据生成器应用，以生成和模糊输入文件的文本和非文本部分。此外，该模型可以应用于生成测试数据以模糊元数据和存储在文件中的普通数据。我们使用两个已知的模糊测试工具AFL和Learn＆Fuzz进行的实验证明了我们提出的方法的代码覆盖率相对较高。实验还表明，简单的神经语言模型提供了比复杂的编码器 - 解码器模型更准确的学习模型。 relevant information 作者 Morteza Zakeri Nasrabadi, Saeed Parsa, Akram Kalaee 单位 Iran University of Science and Technology, Tehran, Iran. 出处 arXiv 原文地址 https://arxiv.org/abs/1812.09961 源码地址 https://github.com/m-zakeri/iust_deep_fuzz 发表时间 2018 1. 简介Fuzzing [1,2,3,4]是一种动态软件测试技术，用于检测程序中的故障和漏洞。为此目的，只要程序崩溃，或者观察到意外行为，就会生成测试数据集并将其注入到被测软件（SUT）中。在软件处理格式错误和不受信任的文件（包括Web浏览器，便携式文档格式（PDF）阅读器和多媒体播放器[5,6]）的情况下，文件格式模糊测试具有重要意义。 与文件格式模糊器有关的主要挑战是将测试数据生成为文件，覆盖SUT的执行路径。要为处理文件程序作为主要输入的模糊测试生成测试数据，模糊器需要知道文件格式。事实上，在没有文件格式的先验知识的情况下，大多数生成的测试数据可能在运行SUT后很快被拒绝，这可能导致代码覆盖率低[7]。手动提取文件格式是解决此问题的常用解决方案。然而，这种解决方案昂贵且耗时，并且总是需要可能不可用的文件格式规范。因此，文件格式的自动检测一直是测试数据生成方法的重点[8,9]。 与文件格式的自动检测有关的主要困境是区分用于定义格式的元数据（例如用于定义格式的标签和参数）与存储在文件中的纯数据。除了格式良好的测试数据外，还要对程序进行模糊处理，还需要格式错误的数据。畸形数据应保存在输入文件中的适当位置，以便揭示相应SUT的缺陷[9]。 通常，诸如MuPDF [10]之类的程序在解析和渲染的两个不同阶段处理给定的PDF文件[11] [12,7]。解析器检查格式，同时将检查的格式复制到主存储器中的某些数据结构中。在呈现阶段，处理加载的数据。例如，向用户显示文件的内容。因此，观察到文件格式模糊器应该在解析和呈现阶段模糊SUT。因此，模糊器应该能够区分数据和保存在文件中的元数据以确定其格式。 实现相对较高的代码覆盖率存在巨大挑战。例如，AFL [13]是一种众所周知的基于变异的文件格式模糊器，它采用进化方法，旨在生成具有最大代码覆盖率的测试数据。 AFL改变随机选择的文件群以实现文件，覆盖尚未观察到的新路径。然而，据观察，对于大量执行路径，AFL在合理的时间内不能满足可接受的代码覆盖率，并且它不适合具有复杂输入结构的模糊程序[14]。一种有前景的方法是使用学习技术来模糊测试数据生成。为此，Learn＆Fuzz [8]作为基于生成的文件格式模糊器，采用seq2seq[15,16]方法，以将输入文件的结构学习为生成模型。然后使用生成模型生成文件作为输入测试数据。 最初，seq2seq旨在映射不同域的两个序列[15]。但是，学习文件的结构不是映射问题，可以使用更简单的模型来完成。在Learn＆Fuzz [8]中，只学习文本数据，而复杂的文件格式包含文本和非文本数据。此外，在Learn＆Fuzz中，生成数据始终以固定前缀obj开头，导致测试数据种类繁多，最后，所提出的模糊算法（称为SampleFuzz [8]）可能不会在所有执行中终止。 在本文中，为了缓解上述挑战，我们提出了一种新的测试数据生成方法，应用于文件格式的模糊器。我们的方法通过使用基于深度递归神经网络（RNN）的神经语言模型（NLM）而不是seq2seq模型来学习复杂输入文件的结构。引入了两个新的模糊算法来模糊输入文件的文本和二进制部分，每个部分都针对文件执行过程的一个阶段。我们还设计并实现了IUST DeepFuzz，这是一种新的模块化文件格式模糊器，可进行模糊测试。 IUST DeepFuzz可以学习任何复杂的文件格式并全自动生成新的测试数据。总之，我们的主要贡献如下： 我们引入了混合测试数据生成方法，利用基于突变和基于生成的方案。 我们设计并实现了一种新的文件格式模糊器IUST DeepFuzz。 我们提供了一个新的数据集，IUST PDF Corpus，用于训练和测试描述PDF文件格式的模型。 我们应用NLM来学习具有长依赖性的复杂文件格式的结构。 通过学习PDF文件格式[11]来评估所提出的方法，然后使用结果格式生成PDF文件作为测试数据来模糊开源PDF查看器MuPDF [10]。我们的评估结果表明，相比较先进的文件格式模糊器，代码覆盖率相对较高[8,13]。此外，在本文中，我们表明NLM优于学习和模糊序列，以及关于学习文件格式准确性的序列模型。 本文的其余部分安排如下。在第2节中，我们简要介绍语言模型（LM）和RNN作为我们提出的方法中使用的基本概念。在第3节中，我们描述了我们提出的用于学习文件结构，生成和模糊新测试数据的方法。第4节涉及各种实验和评估，通过将我们的方法与现有方法进行比较而提供。相关的工作在第5节中讨论。最后，在第6节中，我们总结了我们提出的方法，并讨论了一些关于模糊测试的未来工作。 2.语言模型和递归神经网络我们已经应用语言模型来学习文件的结构作为符号序列。语言模型是NLP中的基本概念，它允许预测序列中的下一个符号[17]。更确切地说，LM是在一系列单词/符号上的概率分布，其识别给定序列的概率。通过使用LM，我们可以在一些现有的序列中选择更可能的序列。序列的LM为x = &lt;x^（1）^…… x^（n）^&gt;定义如下[18]： 在等式1中，每个单独的项p（x^（t）^| x ^&lt;t^）指示给定先前符号x ^&lt;t^的当前符号x^（t）^的条件概率，也称为上下文。在实践中，以等式1的形式计算该概率几乎是不可能的，因为我们需要查看所有可能的序列。为了克服计算挑战，传统的n-gram LM仅考虑基于某种马尔可夫假设的n-1个单词的固定上下文窗口。虽然很有希望，但在许多情况下，这些模型不适用于长序列（超过4或5个符号）或看不见的序列[18]。 为了解决n-gram问题，可以使用一系列深度神经网络，即用于构建LM的递归神经网络，这被称为神经语言模型[19]。 NLM可以扩展到更长的上下文而不会遇到零概率问题。 RNN用于处理顺序数据。它以一系列时间步长处理输入序列，并更新其内存以产生隐藏状态h（i）。图1显示了一个带有一个隐藏层的简单RNN。在每个时间步t中，处理输入序列的一个矢量。 RNN的前馈方程定义为方程2至5 [20]： 其中b和c是偏置矢量，矩阵U，V和W分别是在网络训练期间学习的输入 - 隐藏，隐藏 - 输出和隐藏 - 隐藏连接的权重。通过定义损失（目标）函数并使用优化方法来最小化它来实现学习。 σ是一种激活函数，如sigmoid。 softmax函数应用于输出层，以将网络输出转换为有效的概率分布。 LM作为生成模型，在一系列符号上提供概率分布。通过从这样的分布中采样，可以生成新的序列。在我们提出的方法中，每个文件都被视为一个字节序列，从文件的语言派生而来。然后，我们将为每种文件格式构建相应的语言模型。 3.神经模糊测试我们提出的测试数据生成方法包括三个主要步骤。首先，收集一些样本数据，即输入文件，并对它们进行预处理。其次，在提供的训练集上训练语言模型。第三，通过学习模型生成和模糊测试数据。生成测试数据后，我们就可以对任何给定目标进行模糊测试。图2显示了我们提出的方法的流程图，将在以下部分中进行更详细的讨论。 3.1.概述如图2所示，在开始时（步骤1），我们以我们想要学习的格式收集大量样本文件，例如HTML或PDF文件。然后，每个样本文件中的二进制（非ASCII）部分被替换为唯一令牌，称为二进制令牌（BT）。例如，我们用令牌流替换PDF文件中的所有流。通过使用这种简单的策略，我们可以仅使用一组ASCII序列训练LM。这样的模型可能在生成阶段预测BT，因此我们可以用突变的二进制部分替换BT，其先前由基于突变的方法生成。当然，我们需要保留原始二进制元素以用于未来的突变和替换。这样，与忽略二进制部分[8]的当前方法不同，我们可以同时生成测试数据的二进制和文本部分。 在预处理阶段，我们还在每个文件的末尾添加一个结束标记（ET），指示已处理文件的完整性。然后，我们将所有文件连接在一起并构建大量文件。该序列用于训练LM，但在训练之前，我们将其分为三个独立的集合，如训练集，测试集和验证集。需要这样的划分来测量对看不见的数据的模型准确性和困惑度。它也有助于我们生成新数据（参见第3.3节）。某些文件格式明确具有ET。例如，HTML文件以令牌&lt;/ html&gt;结束。在这种情况下，不需要添加额外的令牌。现在，我们可以定义我们的模型并在提供的数据集上训练它们（步骤2）。 最后，我们的两个新引入的模糊算法用于生成和模糊新的测试数据，称为DataNeuralFuzz和MetadataNeuralFuzz（步骤3）。前者用于模糊测试数据中的数据，后者用于模糊文件的格式。 为了研究模型复杂性在学习文件结构中的作用以及使用结果结构生成测试数据，我们构建了四个具有不同超参数的模型和基于RNN的体系结构，如表1所示。乍一看，它似乎模型越复杂，描述所需文件格式的语言模型就越准确。但是，我们的实验表明，情况并非总是如此。我们使用不同复杂性模型得到的语言模型应用实验表明，相比之下，更简单的模型导致语言模型可以达到相对较高的代码覆盖率。 表1中列出的每个模型使用长短期记忆（LSTM）单元[21]作为可以学习长序列输入的RNN单元。前三个模型是单向多对一LSTM [22]，其架构类似于图1.这些模型是不同的w.r.t.每个图层中隐藏图层和单位的大小会影响每个模型的训练参数数量。最后一个模型（模型4）是双向LSTM。双向LSTM以后向和前向顺序访问输入序列。双向LSTM由两个单向LSTM组成。其中一个处理输入序列从左到右，另一个从右到左处理。结果，每个前向传递具有两个输出。需要合并功能来组合这些输出并生成单个输出。我们选择使用sum函数，它按元素添加两个输出向量。 3.2.训练模型表1中显示的所有模型的训练过程是相同的。神经网络以监督模式进行训练;也就是说，网络的每个输入都需要输出标签。为了训练每个模型，我们需要指定相应的深度神经网络的输入和输出。我们将训练集序列S分成具有固定长度d的多个较小子序列，使得第i个子序列xi将是： 其中S [l：u]是索引l和u之间S的子序列，j是跳跃步骤，表示从原始序列S中选择下一个子序列的前向跳转; xi是模型的输入序列。每个输入序列xi的相应输出或换句话说标签定义为： 实际上，输出是输入序列的下一个符号。在生成所有输入序列及其相应的输出符号之后，可以训练模型。在训练期间，模型学习条件概率p(x^(i+d+1)^ | &lt; x^(i)^，……， x^(i+d)^ &gt;) 这将最终使它能够预测给定子序列xi的下一个符号x^（i+d+1）^的出现。 图3显示了上述示例HTML文件的训练方法的示例。前三个训练序列及其对网络的呈现如图所示。参数d和j分别设置为3和1。在实践中，d可以设置为大数，即40或甚至100，这使得可以学习长依赖性。 3.3.生成新的测试数据训练过程完成后，我们可以使用学习的模型生成新数据。为此，我们首先从测试集序列中随机选择长度为d的前缀P，并将其提供给模型。该模型将下一个符号的预测作为所有符号的有效分布。然后，选择符号形式的该分布，并将其扩展到P的末尾。接下来，去除P的第一个符号，而P的长度为d。现在，我们使用更新的前缀查询模型并生成下一个符号。此过程将继续，直到生成结束令牌ET。 从输出分布中选择一个符号有很多策略。一个简单的策略是贪婪地选择具有最高概率的符号。这样的策略导致格式良好的文件。但是，生成的测试数据总是限于前缀的数量，即测试集的大小。另一种常见策略是将预测分布作为多项分布进行采样。采样可以产生各种测试数据，但并不能保证它们都是格式良好的。因此，我们需要一种机制来控制采样期间生成的测试数据的多样性。 在[8]中，作者引入了SampleSpace，它结合了贪婪选择和采样，但该方法有点复杂，并不是生成新测试数据的明确方法。他们的纯采样策略产生了更好的结果。我们在采样策略中引入了超参数，多样性。分集D是区间（0， 1）中的实数。在生成阶段，模型预测值除以分集，D。应用softmax函数后，进行抽样。结果，较低多样性导致采样策略关闭贪婪策略并产生较少的各种但格式良好的测试数据。另一方面，更高的多样性使得采样策略远离贪婪策略并创建更多种不同但形成错误的测试数据。 3.4.模糊测试数据当我们使用表1中的模型和上一节中概述的采样策略生成测试数据时，生成的数据将存在固有的变化，因此这些数据可用作测试数据。然而，学习文件结构和模糊它是光谱的两端。学习希望捕获格式良好的文件的结构，并生成可以通过文件解析器的文件，而模糊测试打算破坏文件结构，希望使程序执行失败。在本节中，我们介绍了神经模糊算法，目的是在前两个目标和文件格式模糊测试的最终生成测试数据之间建立权衡。我们的算法扩展和改进了SampleFuzz算法[8]。正如我们所提到的，文件由数据和元数据的两部分组成，每个部分都在一个单独的阶段中处理。我们引入了两个名为DataNeuralFuzz的算法，用于模糊数据，针对渲染阶段，MetadataNeuralFuzz用于模糊元数据，针对解析阶段。 DataNeuralFuzz显示在算法1中，MetadataNeuralFuzz显示在算法2中。两种算法都将学习模型M，序列前缀P，分集D，模糊率FR，结束标记ET，二进制标记BT作为输入，并作为输出返回测试数据T D.每个算法都有一个主循环，一直持续到没有生成ET。在while循环内，M用D采样。然后在算法中不同的某些条件下修改（模糊）预测符号。退出while循环后，算法检查T D是否包含BT。如果它包括BT，则BT被实际二进制部分替换，该实际二进制部分在基于突变的方法中被模糊化，例如随机地。请记住，在将二进制部件与原始数据集分离时，我们已经存储了它们。最后，算法返回T D. 这两种算法的主要特征之一是与SampleFuzz不同，它们总是终止。在每个算法进入其while循环之前，将具有最小值a和最大值b的随机整数设置为T D的最大长度MaxLen变量。如果ET不是由模型产生并且T D的长度大于MaxLen，则在while循环中生成T D期间，然后通过算法将ET添加到T D的末尾，并且while循环将断开。 a和b的值应由测试者确定。一个好的做法是将它们设置在数据集文件的平均长度附近。 3.4.1. DataNeuralFuzzDataNeuralFuzz算法旨在模糊存储在文件中的数据。存储在不同文件中的数据最明显的特性是其多样性。因此，观察到学习模型预测存储数据的概率低于描述文件格式的元数据。这意味着包含纯数据的位置中的模型预测向量比包含元数据的位置更平滑。使用存储在预测矢量中的概率的这种特性，可以确定数据的类型，如纯数据或元数据。为了确定数据类型，如纯数据或元数据，我们将通过实验获得的阈值α设置为边界线。如果符号c的概率，即p（c）小于α，则c被认为是纯数据。 DataNeuralFuzz用c’替换纯数据项c，其中c‘具有最低似然性，条件是： 符号c的概率p（c）小于给定阈值α。 符号c既不属于BT也不属于ET。 测试仪给出的模糊率FR高于随机数p_fuzz，它是由i.i.d.3随机生成器生成的。 模糊率FR表示在测试数据生成期间要模糊的数据百分比。例如，如果FR设置为0.1，则算法只会对10％的数据进行模糊测试。此外，我们不愿意模糊关键令牌，即BT和ET，因为这些令牌被插入到文件中以分别处理文件的二进制部分和结尾。这就是为什么确保纯数据项c不属于BT和ET的原因。 纯数据的另一个方面是它看起来像长度大于1的标记。我们的DataNeuralFuzz算法旨在通过更改令牌的一个或多个符号来模糊纯数据令牌。建议[23,6]使用最高可能值更改数据令牌，具体取决于令牌的类型。 在实验上，模糊测试的最佳实践是用其边界值替换数据标记。例如，使用999…… 9而不是整数数据是个好主意。通常，众所周知，用作输入数据的边界值可能导致SUT执行的呈现阶段中的崩溃。 学习的模型可用于生成任何文件，作为模糊SUT的输入。为此，将一个文件（作为固定长度的输入字符串）提供给模型，模型生成下一个符号。下一次输入字符串向前移动一个符号，这次输入字符串将包括新生成的符号。将得到的字符串再次馈送到学习模型以生成第二符号。只要创建了足够的符号并构建了新的输入文件，就会重复此过程。为了提高生成的输入文件的有效性，每次学习模型生成新符号时，只要保持上述三个条件，我们就在使用符号之前对符号进行模糊处理。每次模型决定通过将此符号添加到下一个前缀来模糊数据令牌的第一个符号时，我们让模型保持模糊预测状态。下一次学习模型想要预测符号时，其预测将受到模糊符号的影响，这可能导致另一个格式错误的符号。我们称这种机制为“将模糊传播到前缀”。 3.4.2. MetadataNeuralFuzz如上所述，我们的fuzzing算法由两个不同的部分DataNeuralFuzz和MetadataNeuralFuzz组成，分别用于生成和模糊生成文件的纯数据和格式/元数据。实际上，生成的文件进一步格式错误，以实现使SUT执行崩溃的更高概率。 MetadataNeuralFuzz尝试使SUT的文件格式解析器崩溃。为了避免被SUT解析阶段中使用的异常处理机制所困，MetadataNeuralFuzz尝试： 应用学习的模型，描述文件的适当结构，以生成新文件，以测试SUT。 使用测试人员给出的特定百分比来模糊描述文件格式的一些符号。 MetadataNeuralFuzz算法旨在模糊文件格式，同时尽可能保留整个文件结构。通过这种方式，MetadataNeuralFuzz可以检查解析器对无效或格式错误的文件格式的健壮性。学习模型本身对元数据和纯数据没有任何假设。它只是在生成文件时预测下一个符号出现的概率。 MetadataNeuralFuzz在生成元数据时对其进行模糊处理。为了区分元数据和纯数据，MetadataNeuralFuzz使用在训练步骤中获得的符号频率。通常，元数据比语料库中的纯数据重复得多。据观察，学习模型比纯数据更高概率地预测元数据，非常接近于1。如果预测符号c的概率大于给定阈值β，则算法猜测符号c可能属于文件格式并用最低发生概率的符号替换它。为了控制模糊符号的百分比，使用模糊率FR。 MetadataNeuralFuzz模糊元数据，假设随机生成的数字p模糊小于由测试者给出的预定模糊测试速率FR。 MetadataNeuralFuzz将ET和BT视为模糊测试，因为这些标记是格式的一部分。当由学习模型生成的符号被模糊时，它仅存储在目标文件中，并且不影响学习模型对下一个符号的预测。以这种方式，确保模糊符号不传播到下一个前缀（MetadataNeuralFuzz算法的第10行）。两个算法MetadataNeuralFuzz和DataNeuralFuzz之间的差异在MetadataNeuralFuzz算法中突出显示，算法2中显示了该算法。 3.5实现为了实现深度NLM，我们使用了一个高级深度学习库Keras [24]。 Keras包含一组高级API，用于构建用Python编写的深度学习模型，并需要一个低级运行时后端来执行深度学习代码。我们决定使用TensorFlow [25]，一个用于机器学习任务的Google框架，作为Keras的后端。我们使用交叉熵作为目标函数，Adam [26]将学习率1×10^-4^和1×10^-3^作为训练过程中的优化算法。我们还应用了Dropout[27]技术来防止我们的模型过度拟合。 本文的目的是提供一种自动生成测试数据的方法。但是，单独测试数据生成还不足以进行模糊测试。为了评估提出的方法，我们需要一个文件格式模糊器。模糊器将测试数据注入SUT并检查意外结果，例如使SUT的存储器崩溃。我们设计并实现了IUST DeepFuzz作为模块化文件格式模糊器。 IUST DeepFuzz使用Microsoft Application Verifier[28]，一个免费的运行时监控工具，作为监控模块来捕获任何内存损坏。它还使用微软的另一个工具VSPerfMon` [29]来测量代码覆盖率。 IUST DeepFuzz的主要模块是一个测试数据生成器，它实现了我们的神经模糊算法。这些模块使用适当的Python和批处理脚本连接。以上配置中的IUST DeepFuzz可以在Windows操作系统上运行。要在其他操作系统上使用它，我们需要更换监视工具，即Application Verifier [28]。测试数据生成器是用Python编写的，可以在任何平台上运行。代码覆盖率测量模块仅用于评估目的，我们的模糊测试不需要它。 IUST DeepFuzz是一款带有混合测试数据生成器的黑盒子模糊器[1]。每个生成的测试数据在注入SUT之前存储在磁盘上，因此如果Application Verifier报告崩溃，则可以检索导致该崩溃的测试数据以进行故障本地化过程。图4显示了IUST DeepFuzz的体系结构和数据流。 4.实验和评估在本节中，我们将介绍使用IUST DeepFuzz进行实验的结果。我们使用IUST DeepFuzz来模糊MuPDF [10]，这是一个免费的开源PDF，XPS和电子书阅读器，它将复杂的PDF文件[11]作为输入进行处理。 PDF是一种复杂的文件格式。 Adobe PDF规范[11]中描述了PDF文件的完整规范。同样，简要介绍[8]中指定的PDF文件的基本部分。 PDF文件的主要部分是表示文件的所有功能和方面的数据对象。按照[8]中提出的方法，我们在PDF对象集上训练我们的模型，然后生成新的PDF文件到模糊MuPDF查看器[10]。 我们还实现了Learn＆Fuzz方法[8]并在MuPDF查看器[10]上进行了评估，因为Edge PDF解析器和Learn＆Fuzz的其他材料包括数据集和模型超参数，并未公开提供。通过这种方式，我们能够在我们提出的方法和提到的方法之间进行有意义的比较，作为该领域最相关的工作。 4.1.评估指标模糊测试的主要目的是在SUT中查找与代码覆盖率有关的故障和漏洞。学习文件结构的主要目标是生成与模型精度相关的格式良好的文件。根据这些事实，我们在实验中考虑以下指标来衡量我们提出的方法的有效性。 模型准确度和误差：这些指标基于Keras [24]在训练每个模型时报告的目标函数。精度和误差是根据验证集数据计算的，验证集数据是从预处理阶段的数据集中导出的。 模型困惑度：困惑度是评估LM的最常见指标，它被定义为[30]： 在等式8中，x是具有长度n的序列以评估困惑度。困惑表明预测序列和测试集序列之间的差异。因此，较低的困惑意味着更好的LM。对于每个模型，我们在训练期间计算验证集的困惑度。我们使用困惑来评估所提出的模型在捕获输入文件的结构方面的优异性以及比较不同的建议NLM。 代码覆盖：对于每个测试数据执行，基本块覆盖由VSPerfMon工具[29]测量。基本块覆盖是语句覆盖的扩展，其中每个非分支语句序列被视为一个语句单元。基本块覆盖的主要优点是它可以低开销应用于目标代码。测试集的总覆盖范围是各个覆盖范围的并集。 VSPerfMon还报告行覆盖率，这与高级代码的语句覆盖率相同。 故障和漏洞：对于每个测试数据执行，Application Verifier [28]创建一个日志文件。然后，我们使用简单的脚本搜索这些日志文件，以查找任何错误或安全警告。 前两个指标确定了学习文件格式的有效性，接下来的两个指标衡量了模糊测试的质量和实用性。 4.2.实验设置表1中的训练模型是在具有单个Nvidia GTX 1080 GPU，Intel Core i7 CPU和20 GB RAM的物理ubuntu 16.04机器上进行的。模糊测试在具有Intel Core i7 CPU和8 GB RAM的虚拟Windows 10计算机上完成。我们在进行实验时使用了最终版本的MuPDF查看器[10]，即版本MuPDF 2017-04-114。 在我们生成测试数据之前，我们应该训练我们的模型。表2显示了我们模型的关键超参数以及每个模型的时期数和训练时间。模型的复杂性，即训练参数的数量，随着模型的ID而增加。对于更复杂的模型，获得更多训练样本是合理的。因此，在模型3和4中，我们减少跳跃步骤，这导致增加训练样本。在模型3中，我们使用Dropout [27]和p = 0.3进行正则化。 4.3.数据集和主机文件深度神经网络的成功训练需要大量且足够的数据集。因此，我们从各种来源收集了大量PDF文件，包括Mozilla PDF.js开放测试语料库[31]，AFL [13]中使用的一些PDF作为初始种子，以及从不同语言的公共网络收集的PDF。 最后，我们发布了IUST PDF Corpus超过6000个PDF文件。此类语料库之前未公开发布，也可用于其他类型的PDF操作和测试。 为了学习PDF对象的统计结构，我们从IUST PDF Corpus提取了500000的个对象。这些对象中约有27％具有二进制流。我们用二进制令牌流替换二进制流，提取并将它们存储到单独的数据集中，并在我们的训练过程中包含修改后的对象。与[8]的一个关键区别是我们在提取对象之前没有应用种子最小化，因为我们想要学习文件的结构，更多的数据可能会改善学习。整个提取的PDF数据对象集可在IUST PDF Corpus中找到。 由于我们只学习和生成PDF对象，因此我们需要一种机制来创建完整的PDF文件。按照[8]中提出的方法，我们决定将新生成的对象附加到现有的格式良好的PDF文件中，称为host。PDF文件可以按照PDF参考指南[11]中的说明逐步更新。新对象附加到现有PDF的末尾，其偏移量将添加到交叉引用表中。此方法允许用户更新PDF文件而无需重写整个文件。实际上，新对象重写现有对象的内容，该对象由ID标识并且绝对是旧标识。有关增量更新的更多详细信息，请参见[11]。 下一步是选择主机文件。在[8]提出的工作中，这几乎是随机的，只从他们的语料库中选择最小的三个PDF文件。针对这项工作，为了研究主机复杂性对代码覆盖率的影响，我们首先通过运行MuPDF计算语料库中所有PDF文件的代码覆盖率，然后选择具有最大，最小和平均代码的三个文件覆盖范围分别为host1_max，host2_min和host3_avg。 4.4.代码覆盖的基线为了将新生成的PDF文件的代码覆盖率与现有的PDF文件进行比较，我们首先测量了每个主机的MuPDF [10]代码覆盖率，然后构建了1 000个PDF文件，其中包含从测试集中随机选择的对象。这些对象以两种不同的模式附加到主机文件： 单个对象更新（SOU）：查找主机文件中的最后一个对象ID，并用新对象重写它。在此模式下，每个文件中只会更改一个对象。 多个对象更新（MOU）：重写每个PDF文件中对象的固定部分。首先，在此模式中，计算主机中的总对象数，然后新对象将覆盖随机选择的对象ID列表。 表3显示了每个主机中的对象数以及MOU模式下重写对象的部分。图5显示了通过在三个主机上运行MuPDF查看器获得的代码覆盖率，除了两个测试套件的覆盖范围，一个用于SOU，称为基线源，一个用于MOU，称为基线mou。 host123表示从主机1,2和3获得的代码覆盖的并集。观察到以下结果。 每个基线的代码覆盖率高于单个主机的覆盖范围。这意味着更改主机会增加代码覆盖率。 基线覆盖范围与主机覆盖范围有直接关系。例如，host1_max在host1_max，host2_min和host3_avg中具有最高的代码覆盖率。这表明选择合适的主机文件是一项基本工作，并对基线覆盖率产生重大影响。 在所有情况下，基线mou的代码覆盖率均大于基线。 这意味着进一步修改文件内容会增加代码覆盖率。 最大代码覆盖率属于host123，表示每个主机已执行不同的基本块。 最后，覆盖代码的顺序在20,000个基本块的范围内，显示MuPDF查看器[10]是一个大型应用程序，PDF文件具有复杂的格式。 4.5.模型评估 表4显示了在50个时期训练后我们的模型的困惑，准确性和误差。名为laf的最后一列显示了Learn＆Fuzz模型的这个值[8]。 Keras报告了这些指标。困惑由公式8计算。准确度和误差来自交叉熵损失函数。图6还显示了训练过程中模型2和模型laf的验证错误图。模型2已在此图中说明，因为它与架构和超参数设置中的laf最相似。观察到以下结果。 所有NLM的误差小于laf误差，并且它们的准确度大于它。这意味着NLM在文件的学习语法中优于编码器 - 解码器模型。 最大精度属于模型4，我们唯一的双向LSTM。该网络以从左到右和从右到左的方向处理输入序列。因此它可以达到较高的准确度，从而导致较低的困惑。 在图6中，模型2的错误图始终位于模型laf下当然，迭代有不同的时期，因此点对点比较可能并不令人兴奋。但是，我们也看到这种关系在训练过程开始时的相等间隔内是正确的。 在我们的数据集中，所有模型的最大困惑是在没有NLM的情况下是困惑的。 50个训练时期之后的困惑度小于1.5，这表明NLM可以学习如此优秀的文件语言。最小困惑属于具有最大可训练参数数量的模型3。 4.6.采样多样性和代码覆盖率为了研究生成测试数据时多样性对代码覆盖率的影响，我们使用不同多样性0.5,1.0和1.5的采样策略在每个主机上生成1,000个PDF文件。该实验提供了关于代码覆盖中的最佳模型，主机，分集和更新模式（即，SOU和MOU）的信息。因此，我们可以选择用于模糊测试的最佳配置。 我们在训练时间的每个时期结束时保存一个检查点，然后选择所有检查点之间具有最小验证误差的模型。我们选择最佳学习模型进行抽样。 在SOU模式下使用我们的模型生成1,000个PDF文件大约需要60分钟，在MOU模式下大约需要190分钟。在MuPDF查看器上运行每个测试套件并获得覆盖平均花费65分钟。总的来说，我们在此实验中生成并测试了72,000个PDF文件。所有代码覆盖率如图7所示。观察到以下结果。 在大多数情况下，生成数据的代码覆盖率小于基线代码覆盖率，因为生成的对象在我们的测试集中并不是真正的PDF对象。但是，在这种情况下，我们会看到代码覆盖率的增加，例如在图表host2_min_mou中。这意味着对于小型主机，添加更多内容会导致更好的代码覆盖率。 增加多样性会导致双向LSTM（模型4）中的代码覆盖率增加，但其他模型则不然。通常，在大多数模型和大多数主机上生成具有分集一的数据似乎更有效，而不是SUT的代码覆盖。 几乎在所有图表中，模型2在代码覆盖率方面优于其他模型。这意味着更简单的NLM比更复杂的NLM更好。 通过查看host123图表，作为结果的汇总，我们可以得出结论，具有多样性的模型2是模糊测试的最佳模型。因此，我们选择此模型用于4.7节中的神经模糊算法。 4.8.神经模糊测试在第四次和最后一次实验中，我们将MuPDF [10]放在真正的模糊测试上。我们使用DataNeuralFuzz和MetadataNeuralFuzz算法生成10,000个PDF文件，然后使用IUST DeepFuzz进行模糊测试。除了模糊我们的神经模糊算法外，我们还通过FileFuzz [5]进行模糊测试，这是一种基于变异的简单文件格式模糊器，以及Learn＆Fuzz（即SampleFuzz算法）[8]。在所有实验中，我们使用host1_max作为主机文件或FileFuzz的初始种子。在这个实验中，我们用40,000个PDF文件模糊了MuPDF查看器。 表5显示了为DataNeuralFuzz和MetadataNeuralFuzz算法设置的输入和常量值，以便在可用值中生成测试数据。表6显示了各种模糊测试方法的代码覆盖率结果，包括Learn＆Fuzz [8]和FileFuzz [5]。最后，表7显示了我们提出的方法和其他四种已知文件格式模糊器的代码覆盖率之间的差异：Learn＆Fuzz，AFL [13]，Augmented-AFL [14]和FileFuzz。微软研究最近推出了增强型AFL作为AFL的改进。观察到以下结果。 MetadataNeuralFuzz代码覆盖率低于DataNeuralFuzz。正如我们已经说过的那样，操作文件格式的一小部分可能会使其完全无效，因此解析器会尽快拒绝该文件并导致代码覆盖率降低。但是，更改文件中的数据会影响文件执行的呈现阶段。结果证明两种算法都符合我们的预期。一个fuzzes格式，另一个fuzzes数据。 与SampleFuzz [8]相比，DataNeuralFuzz和MetadataNeuralFuzz都覆盖了MuPDF查看器代码的更多基本块（当然还有更多行）。这表明带有RNN的NLM在模糊测试中优于编码器 - 解码器模型。另一种解释是混合测试数据生成优于基于生成的方法。 我们的混合测试数据生成方法也优于基于突变的模糊器，如AFL和AugmentAFL，如表7所示.AFL和增强AFL的代码覆盖率取自[14]作为基准。 基于模糊测试的测试数据生成部分，智能算法与随机变 异的优势是显而易见的。随机算法无法访问复杂输入结构中的高代码覆盖率。 DataNeuralFuzz算法的覆盖范围是FileFuzz [5]中使用的算法的三倍多。 尽管我们在模糊测试过程中改进了MuPDF查看器[10]的代码覆盖率，如表6所示，覆盖代码的百分比仍然低于25％。这意味着大多数观众代码都没有被执行，这不是好消息。另一方面，我们应该知道MuPDF查看器可以解析和播放不同的文件格式，如XPS。这意味着当输入采用这样的格式时，将使用部分未执行的代码。因此，我们不希望仅通过生成和注入PDF文件来运行它们。 4.9.故障和漏洞可用于评估模糊器的最佳度量标准是在模糊测试期间发现的故障和漏洞的数量。在每次测试执行后，我们没有看到Application Verifier [28]生成的报告中出现任何错误。鉴于我们测试了MuPDF软件的最终版本[10]，假设其大多数错误在试用版本中得到修复，因此很难找到新的错误。另一方面，MuPDF是正在积极开发的软件，它拥有出色的开发人员和用户社区，使其成为强大的软件。但是，DataNeuralFuzz算法检测到不安全功能的多种用法，并将其报告为安全警告。 似乎Application Verifier [28]在Windows 10 x64上运行时无法检测到32位应用程序的内存错误。我们尝试使用已知错误对一个简单的32位应用程序进行模糊测试，但ApplicationVerifier不会报告任何内容。 64位应用程序但没有这样的问题，它们的错误由ApplicationVerifier检测到。因此，我们测试了32位和64位版本的MuPDF查看器[10]。 IUST DeepFuzz打开带有测试数据的SUT并在固定时间后关闭它，尝试在测试套件中注入下一个测试数据。在我们的配置中，每个测试套件包含10,000个测试数据，需要大约28个小时进行处理。模糊测试是一种压力测试，通常在几天或几周内完成，以发现故障和漏洞。我们计划在更大规模的测试服上测试MuPDF，其中包含100,000个PDF文件以及更多可能会破坏MuPDF的文件。 5.相关工作在本节中，我们将讨论一些相关的模糊测试工作，并解释他们在测试数据生成方面存在的问题。根据测试数据生成方法，模糊器分为基于突变和基于生成[32,33,34]。将各种技术应用于两种方法以改进它们。大多数这些技术都专注于人工智能算法。 I.基于突变的模糊测试。在基于突变的情况下，使用一个或多个有效输入数据作为初始种子。然后该种子发生变异以产生另一个测试数据。很容易构建基于突变的模糊器并用它生成错误形成的测试数据。在这种情况下，不需要事先理解输入数据结构。基于突变的方法的缺点是该方法取决于初始种子的变化。如果没有不同的样本输入，基于突变的模糊器就无法实现高代码覆盖率[35]，这表明初始种子在基于突变的方法中的重要性。 AFL [13]和FileFuzz [5]是基于突变的模糊器的例子。 II.基于生成的模糊测试。基于生成的方法完全随机地生成测试数据，或者从诸如语法，模板或模型的形式描述生成测试数据。最新的使用输入格式规范来构建生成模型。此方法通常应用于某些文档可用的格式。通常，与基于突变的模糊器相比，它实现了更高的代码覆盖率[35]。但是，正如我们所说，应该花费大量的时间和金钱来完全理解文件格式的规范，并为它构建正确的语法，模板或模型。 SAGE [36]和Peach [37]是基于生成的模糊器的例子。还存在利用两种方法的特征的混合方法。 IUST DeepFuzz在本文中提出了一种混合模糊器，它通过生成模型生成结构化文本数据，通过突变生成非结构化二进制数据。 III.进化模糊。通过应用遗传等进化算法[38]，首次尝试将模拟带入模糊测试。进化模糊器从运行时信息（通常是代码覆盖率信息）接收反馈，并将导致新执行路径的测试数据添加到队列中。之后，当模糊器想要生成测试数据时，它只会改变队列中存在的测试数据，希望能够运行代码的新部分。 AFL [13]是最先进的进化文件格式，模糊器的工作方式与上面完全相同。通过使用先前运行的反馈，AFL可以选择更好的测试数据，但是，它会随机改变它们。结果，将生成大量重复的测试数据，这些数据不一定影响包括代码覆盖的测试标准。另一方面，在复杂的输入结构中，更改某些关键部分会导致输入测试数据在解析的初始阶段被解析器拒绝。因此，我们需要一种机制来告知fuzzer输入文件的变异（偏移）。 IV.基于变异和进化方法的深度学习。Augmented-AFL [14]作为AFL [13]的改进补丁，尝试使用深度学习技术找到适合变异的位置。在Augmented-AFL创建新的测试数据后，它会查询模型以查看生成的测试数据是否足够好？这种方法提高了测试速度，但是大量数据在生成时被模型（否决）拒绝。此外，Augmented-AFL在MuPDF解析器的代码覆盖率方面没有显着改进[10]。对于具有复杂输入结构的应用程序而言，基于突变的方法似乎无法丰富高代码覆盖率。 V.基于生成方法的深度学习。 Godefroid等人最初提出了应用基于神经网络的统计学习从样本输入自动生成输入语法。 [8]。他们还提出了一种生成模糊输入的算法。这项工作的主要思想是学习一组PDF文件的生成模型[11]。为此目的，他们使用一种序列来对结构进行排序[15,16]，其最初用于将来自不同域的两个序列映射到一起，例如机器翻译的任务。他们称他们的方法为Learn＆Fuzz。在整篇论文中，我们讨论了Learn＆Fuzz方法的一些弱点，并为它们提供了一些解决方案。基于这项工作，Cummins 等人介绍了使用RNN [21]的LSTM架构对程序代码进行建模的DeepSmith [39]。他们将该工具应用于OpenCL编程语言的模糊编译器。他们的模型不是混合模型，只能用于生成文本测试数据。 6.结论本文旨在为复杂的输入结构（如PDF文件）引入新的智能测试数据生成技术。由递归神经网络构建的深度神经语言模型可以最好地应用于将复杂输入文件的结构学习为符号序列。可以简单地学习输入文件的文本部分。但是，学习二进制部分的格式是一项艰巨的任务。为了解决这个难题，我们建议暂时删除二进制部分，并用特定的标记替换这些部分。在训练阶段完成之后并且当应用学习模型来生成测试数据时，将令牌替换为已删除部分的变异形式。为了提高模糊效率，我们在应用学习模型时将数据和元数据模糊，以生成新的输入文件作为测试数据。我们相信，无论代码覆盖范围如何，在完成模糊测试时都需要这两种算法。神经模糊算法旨在测试程序的不同部分。 MetadaaNeuralFuzz测试文件格式的解析器和DataNeuralFuzz测试文件格式的渲染器。 测试数据生成器是模糊器中最重要的模块。提供可以在被测软件中实现高代码覆盖率的自动测试数据生成器，尤其是具有复杂输入结构的目标，对于发现故障至关重要。已经成功地应用基于生成和基于突变的方法来生成用于模糊测试的测试数据。但是，前者不是完全自动的，后者的代码覆盖率很差。 为了解决这些问题，我们提出了一种基于NLM和深度学习技术的方法。我们的混合测试数据生成方法自动学习输入文件的结构，然后通过模糊输入格式的文本和二进制部分来生成新的多样化测试数据。由于该方法智能地确定了模糊的位置以及应该用于模糊的值，因此可以有望地应用于测试复杂目标。 我们以复杂的文件格式（即PDF）进行了实验，结果证实了与以前的方法相比，代码覆盖率和我们提出的方法的准确性得到了显着改善。除了一般结论之外，我们的分析揭示了一些有价值的经验事实，最值得注意的是： 混合测试数据生成用于模糊复杂输入结构的文本和二进制部分，增加SUT的代码覆盖率。 人们普遍认为，作为LM的双向LSTM可以在同一数据集上获得更高的精度和更少的误差。然而，观察到更简单的NLM，例如没有丢失的单向LSTM，例如本文中的模型2，在代码覆盖中可以胜过更复杂的方法。[14]报道了类似的结果。 基于具有高代码覆盖率的PDF文件的增量更新过程会导致更多代码覆盖。 尽管提供比随机和现有智能模糊器更高的代码覆盖率，但我们提出的模糊器可以改进，以便为复杂的输入结构（如PDF文件结构）提供更高的覆盖率。 关于这个主题，未来有很多工作要做。一种是使用其他强大的深度学习模型，如生成对抗网络（GAN）[40]来生成测试数据。另一个方向是应用这些模型在其他类型的模糊器（如网络协议模糊器）中生成测试数据。为了生成更有效的测试数据，我们打算向IUST DeepFuzz添加一个反馈循环，旨在接收运行时信息并微调学习模型。 SUT中有部分代码处理用户交互。然而，诸如AFL [13]和IUST DeepFuzz之类的模糊器不利用用户交互部件进行模糊测试，并且不支持执行这些部分代码。目前，我们计划支持用户与SUT交互的自动化","content":"<h1 id=\"Abstract\"><a href=\"#Abstract\" class=\"headerlink\" title=\"Abstract\"></a>Abstract</h1><p>本文旨在设计和实现文件格式模糊器。文件是大多数实际应用程序的重要输入。将输入文件生成为测试数据的实质难点在于重新调整文件的基础结构和格式。为了区分存储在文件中的纯数据和描述文件格式的元数据，本文提出了一种基于神经语言模型的深度学习方法。得到的学习模型可以作为混合测试数据生成器应用，以生成和模糊输入文件的文本和非文本部分。此外，该模型可以应用于生成测试数据以模糊元数据和存储在文件中的普通数据。我们使用两个已知的模糊测试工具AFL和Learn＆Fuzz进行的实验证明了我们提出的方法的代码覆盖率相对较高。实验还表明，简单的神经语言模型提供了比复杂的编码器 - 解码器模型更准确的学习模型。</p>\n<table>\n<thead>\n<tr>\n<th>relevant information</th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><em>作者</em></td>\n<td>Morteza Zakeri Nasrabadi, Saeed Parsa, Akram Kalaee</td>\n</tr>\n<tr>\n<td><em>单位</em></td>\n<td>Iran University of Science and Technology, Tehran, Iran.</td>\n</tr>\n<tr>\n<td><em>出处</em></td>\n<td>arXiv</td>\n</tr>\n<tr>\n<td><em>原文地址</em></td>\n<td><a href=\"https://arxiv.org/abs/1812.09961\" target=\"_blank\" rel=\"noopener\">https://arxiv.org/abs/1812.09961</a></td>\n</tr>\n<tr>\n<td><em>源码地址</em></td>\n<td><a href=\"https://github.com/m-zakeri/iust_deep_fuzz\" target=\"_blank\" rel=\"noopener\">https://github.com/m-zakeri/iust_deep_fuzz</a></td>\n</tr>\n<tr>\n<td><em>发表时间</em></td>\n<td>2018</td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"1-简介\"><a href=\"#1-简介\" class=\"headerlink\" title=\"1. 简介\"></a>1. 简介</h1><p>Fuzzing [1,2,3,4]是一种动态软件测试技术，用于检测程序中的故障和漏洞。为此目的，只要程序崩溃，或者观察到意外行为，就会生成测试数据集并将其注入到被测软件（SUT）中。在软件处理格式错误和不受信任的文件（包括Web浏览器，便携式文档格式（PDF）阅读器和多媒体播放器[5,6]）的情况下，文件格式模糊测试具有重要意义。</p>\n<p>与文件格式模糊器有关的主要挑战是将测试数据生成为文件，覆盖SUT的执行路径。要为处理文件程序作为主要输入的模糊测试生成测试数据，模糊器需要知道文件格式。事实上，在没有文件格式的先验知识的情况下，大多数生成的测试数据可能在运行SUT后很快被拒绝，这可能导致代码覆盖率低[7]。手动提取文件格式是解决此问题的常用解决方案。然而，这种解决方案昂贵且耗时，并且总是需要可能不可用的文件格式规范。因此，文件格式的自动检测一直是测试数据生成方法的重点[8,9]。</p>\n<p>与文件格式的自动检测有关的主要困境是区分用于定义格式的元数据（例如用于定义格式的标签和参数）与存储在文件中的纯数据。除了格式良好的测试数据外，还要对程序进行模糊处理，还需要格式错误的数据。畸形数据应保存在输入文件中的适当位置，以便揭示相应SUT的缺陷[9]。</p>\n<p>通常，诸如MuPDF [10]之类的程序在解析和渲染的两个不同阶段处理给定的PDF文件[11] [12,7]。解析器检查格式，同时将检查的格式复制到主存储器中的某些数据结构中。在呈现阶段，处理加载的数据。例如，向用户显示文件的内容。因此，观察到文件格式模糊器应该在解析和呈现阶段模糊SUT。因此，模糊器应该能够区分数据和保存在文件中的元数据以确定其格式。</p>\n<p>实现相对较高的代码覆盖率存在巨大挑战。例如，AFL [13]是一种众所周知的基于变异的文件格式模糊器，它采用进化方法，旨在生成具有最大代码覆盖率的测试数据。 AFL改变随机选择的文件群以实现文件，覆盖尚未观察到的新路径。<br>然而，据观察，对于大量执行路径，AFL在合理的时间内不能满足可接受的代码覆盖率，并且它不适合具有复杂输入结构的模糊程序[14]。一种有前景的方法是使用学习技术来模糊测试数据生成。为此，Learn＆Fuzz [8]作为基于生成的文件格式模糊器，采用seq2seq[15,16]方法，以将输入文件的结构学习为生成模型。然后使用生成模型生成文件作为输入测试数据。</p>\n<p>最初，seq2seq旨在映射不同域的两个序列[15]。但是，学习文件的结构不是映射问题，可以使用更简单的模型来完成。在Learn＆Fuzz [8]中，只学习文本数据，而复杂的文件格式包含文本和非文本数据。此外，在Learn＆Fuzz中，生成数据始终以固定前缀obj开头，导致测试数据种类繁多，最后，所提出的模糊算法（称为SampleFuzz [8]）可能不会在所有执行中终止。</p>\n<p>在本文中，为了缓解上述挑战，我们提出了一种新的测试数据生成方法，应用于文件格式的模糊器。我们的方法通过使用基于深度递归神经网络（RNN）的神经语言模型（NLM）而不是seq2seq模型来学习复杂输入文件的结构。引入了两个新的模糊算法来模糊输入文件的文本和二进制部分，每个部分都针对文件执行过程的一个阶段。我们还设计并实现了IUST DeepFuzz，这是一种新的模块化文件格式模糊器，可进行模糊测试。 IUST DeepFuzz可以学习任何复杂的文件格式并全自动生成新的测试数据。总之，我们的主要贡献如下：</p>\n<ul>\n<li>我们引入了混合测试数据生成方法，利用基于突变和基于生成的方案。 </li>\n<li>我们设计并实现了一种新的文件格式模糊器IUST DeepFuzz。</li>\n<li>我们提供了一个新的数据集，IUST PDF Corpus，用于训练和测试描述PDF文件格式的模型。</li>\n<li>我们应用NLM来学习具有长依赖性的复杂文件格式的结构。</li>\n</ul>\n<p>通过学习PDF文件格式[11]来评估所提出的方法，然后使用结果格式生成PDF文件作为测试数据来模糊开源PDF查看器MuPDF [10]。我们的评估结果表明，相比较先进的文件格式模糊器，代码覆盖率相对较高[8,13]。此外，在本文中，我们表明NLM优于学习和模糊序列，以及关于学习文件格式准确性的序列模型。</p>\n<p>本文的其余部分安排如下。在第2节中，我们简要介绍语言模型（LM）和RNN作为我们提出的方法中使用的基本概念。在第3节中，我们描述了我们提出的用于学习文件结构，生成和模糊新测试数据的方法。第4节涉及各种实验和评估，通过将我们的方法与现有方法进行比较而提供。相关的工作在第5节中讨论。最后，在第6节中，我们总结了我们提出的方法，并讨论了一些关于模糊测试的未来工作。</p>\n<h1 id=\"2-语言模型和递归神经网络\"><a href=\"#2-语言模型和递归神经网络\" class=\"headerlink\" title=\"2.语言模型和递归神经网络\"></a>2.语言模型和递归神经网络</h1><p>我们已经应用语言模型来学习文件的结构作为符号序列。语言模型是NLP中的基本概念，它允许预测序列中的下一个符号[17]。更确切地说，LM是在一系列单词/符号上的概率分布，其识别给定序列的概率。通过使用LM，我们可以在一些现有的序列中选择更可能的序列。序列的LM为x = &lt;x^（1）^…… x^（n）^&gt;定义如下[18]：</p>\n<p><img src=\"/2019/04/17/Neural-Fuzzing-A-Neural-Approach-to-Generate-Test-Data-for-File-Format-Fuzzing/1.jpg\" alt=\"\"></p>\n<p>在等式1中，每个单独的项p（x^（t）^| x ^&lt;t^）指示给定先前符号x ^&lt;t^的当前符号x^（t）^的条件概率，也称为上下文。在实践中，以等式1的形式计算该概率几乎是不可能的，因为我们需要查看所有可能的序列。为了克服计算挑战，传统的n-gram LM仅考虑基于某种马尔可夫假设的n-1个单词的固定上下文窗口。虽然很有希望，但在许多情况下，这些模型不适用于长序列（超过4或5个符号）或看不见的序列[18]。</p>\n<p>为了解决n-gram问题，可以使用一系列深度神经网络，即用于构建LM的递归神经网络，这被称为神经语言模型[19]。 NLM可以扩展到更长的上下文而不会遇到零概率问题。 RNN用于处理顺序数据。它以一系列时间步长处理输入序列，并更新其内存以产生隐藏状态h（i）。图1显示了一个带有一个隐藏层的简单RNN。在每个时间步t中，处理输入序列的一个矢量。 RNN的前馈方程定义为方程2至5 [20]：</p>\n<p><img src=\"/2019/04/17/Neural-Fuzzing-A-Neural-Approach-to-Generate-Test-Data-for-File-Format-Fuzzing/2.jpg\" alt=\"\"></p>\n<p><img src=\"/2019/04/17/Neural-Fuzzing-A-Neural-Approach-to-Generate-Test-Data-for-File-Format-Fuzzing/4.jpg\" alt=\"\"></p>\n<p><img src=\"/2019/04/17/Neural-Fuzzing-A-Neural-Approach-to-Generate-Test-Data-for-File-Format-Fuzzing/3.jpg\" alt=\"\"></p>\n<p>其中b和c是偏置矢量，矩阵U，V和W分别是在网络训练期间学习的输入 - 隐藏，隐藏 - 输出和隐藏 - 隐藏连接的权重。通过定义损失（目标）函数并使用优化方法来最小化它来实现学习。 σ是一种激活函数，如sigmoid。 softmax函数应用于输出层，以将网络输出转换为有效的概率分布。</p>\n<p>LM作为生成模型，在一系列符号上提供概率分布。通过从这样的分布中采样，可以生成新的序列。在我们提出的方法中，每个文件都被视为一个字节序列，从文件的语言派生而来。然后，我们将为每种文件格式构建相应的语言模型。</p>\n<h1 id=\"3-神经模糊测试\"><a href=\"#3-神经模糊测试\" class=\"headerlink\" title=\"3.神经模糊测试\"></a>3.神经模糊测试</h1><p>我们提出的测试数据生成方法包括三个主要步骤。首先，收集一些样本数据，即输入文件，并对它们进行预处理。其次，在提供的训练集上训练语言模型。第三，通过学习模型生成和模糊测试数据。生成测试数据后，我们就可以对任何给定目标进行模糊测试。图2显示了我们提出的方法的流程图，将在以下部分中进行更详细的讨论。</p>\n<p><img src=\"/2019/04/17/Neural-Fuzzing-A-Neural-Approach-to-Generate-Test-Data-for-File-Format-Fuzzing/5.jpg\" alt=\"\"></p>\n<h2 id=\"3-1-概述\"><a href=\"#3-1-概述\" class=\"headerlink\" title=\"3.1.概述\"></a>3.1.概述</h2><p>如图2所示，在开始时（步骤1），我们以我们想要学习的格式收集大量样本文件，例如HTML或PDF文件。然后，每个样本文件中的二进制（非ASCII）部分被替换为唯一令牌，称为二进制令牌（BT）。例如，我们用令牌流替换PDF文件中的所有流。通过使用这种简单的策略，我们可以仅使用一组ASCII序列训练LM。这样的模型可能在生成阶段预测BT，因此我们可以用突变的二进制部分替换BT，其先前由基于突变的方法生成。当然，我们需要保留原始二进制元素以用于未来的突变和替换。这样，与忽略二进制部分[8]的当前方法不同，我们可以同时生成测试数据的二进制和文本部分。</p>\n<p>在预处理阶段，我们还在每个文件的末尾添加一个结束标记（ET），指示已处理文件的完整性。然后，我们将所有文件连接在一起并构建大量文件。该序列用于训练LM，但在训练之前，我们将其分为三个独立的集合，如训练集，测试集和验证集。需要这样的划分来测量对看不见的数据的模型准确性和困惑度。它也有助于我们生成新数据（参见第3.3节）。某些文件格式明确具有ET。例如，HTML文件以令牌&lt;/ html&gt;结束。在这种情况下，不需要添加额外的令牌。现在，我们可以定义我们的模型并在提供的数据集上训练它们（步骤2）。</p>\n<p>最后，我们的两个新引入的模糊算法用于生成和模糊新的测试数据，称为DataNeuralFuzz和MetadataNeuralFuzz（步骤3）。前者用于模糊测试数据中的数据，后者用于模糊文件的格式。</p>\n<p>为了研究模型复杂性在学习文件结构中的作用以及使用结果结构生成测试数据，我们构建了四个具有不同超参数的模型和基于RNN的体系结构，如表1所示。乍一看，它似乎模型越复杂，描述所需文件格式的语言模型就越准确。但是，我们的实验表明，情况并非总是如此。我们使用不同复杂性模型得到的语言模型应用实验表明，相比之下，更简单的模型导致语言模型可以达到相对较高的代码覆盖率。</p>\n<p>表1中列出的每个模型使用长短期记忆（LSTM）单元[21]作为可以学习长序列输入的RNN单元。前三个模型是单向多对一LSTM [22]，其架构类似于图1.这些模型是不同的w.r.t.每个图层中隐藏图层和单位的大小会影响每个模型的训练参数数量。最后一个模型（模型4）是双向LSTM。双向LSTM以后向和前向顺序访问输入序列。双向LSTM由两个单向LSTM组成。其中一个处理输入序列从左到右，另一个从右到左处理。结果，每个前向传递具有两个输出。需要合并功能来组合这些输出并生成单个输出。我们选择使用sum函数，它按元素添加两个输出向量。</p>\n<p><img src=\"/2019/04/17/Neural-Fuzzing-A-Neural-Approach-to-Generate-Test-Data-for-File-Format-Fuzzing/6.jpg\" alt=\"\"></p>\n<h2 id=\"3-2-训练模型\"><a href=\"#3-2-训练模型\" class=\"headerlink\" title=\"3.2.训练模型\"></a>3.2.训练模型</h2><p>表1中显示的所有模型的训练过程是相同的。神经网络以监督模式进行训练;也就是说，网络的每个输入都需要输出标签。为了训练每个模型，我们需要指定相应的深度神经网络的输入和输出。我们将训练集序列S分成具有固定长度d的多个较小子序列，使得第i个子序列xi将是：</p>\n<p><img src=\"/2019/04/17/Neural-Fuzzing-A-Neural-Approach-to-Generate-Test-Data-for-File-Format-Fuzzing/7.jpg\" alt=\"\"></p>\n<p>其中S [l：u]是索引l和u之间S的子序列，j是跳跃步骤，表示从原始序列S中选择下一个子序列的前向跳转; xi是模型的输入序列。每个输入序列xi的相应输出或换句话说标签定义为：</p>\n<p><img src=\"/2019/04/17/Neural-Fuzzing-A-Neural-Approach-to-Generate-Test-Data-for-File-Format-Fuzzing/8.jpg\" alt=\"\"></p>\n<p>实际上，输出是输入序列的下一个符号。在生成所有输入序列及其相应的输出符号之后，可以训练模型。在训练期间，模型学习条件概率p(x^(i+d+1)^ | &lt; x^(i)^，……， x^(i+d)^ &gt;) 这将最终使它能够预测给定子序列xi的下一个符号x^（i+d+1）^的出现。</p>\n<p><img src=\"/2019/04/17/Neural-Fuzzing-A-Neural-Approach-to-Generate-Test-Data-for-File-Format-Fuzzing/9.jpg\" alt=\"\"></p>\n<p>图3显示了上述示例HTML文件的训练方法的示例。前三个训练序列及其对网络的呈现如图所示。参数d和j分别设置为3和1。在实践中，d可以设置为大数，即40或甚至100，这使得可以学习长依赖性。</p>\n<h2 id=\"3-3-生成新的测试数据\"><a href=\"#3-3-生成新的测试数据\" class=\"headerlink\" title=\"3.3.生成新的测试数据\"></a>3.3.生成新的测试数据</h2><p>训练过程完成后，我们可以使用学习的模型生成新数据。为此，我们首先从测试集序列中随机选择长度为d的前缀P，并将其提供给模型。该模型将下一个符号的预测作为所有符号的有效分布。然后，选择符号形式的该分布，并将其扩展到P的末尾。接下来，去除P的第一个符号，而P的长度为d。现在，我们使用更新的前缀查询模型并生成下一个符号。此过程将继续，直到生成结束令牌ET。</p>\n<p>从输出分布中选择一个符号有很多策略。<br>一个简单的策略是贪婪地选择具有最高概率的符号。这样的策略导致格式良好的文件。但是，生成的测试数据总是限于前缀的数量，即测试集的大小。另一种常见策略是将预测分布作为多项分布进行采样。采样可以产生各种测试数据，但并不能保证它们都是格式良好的。因此，我们需要一种机制来控制采样期间生成的测试数据的多样性。</p>\n<p>在[8]中，作者引入了SampleSpace，它结合了贪婪选择和采样，但该方法有点复杂，并不是生成新测试数据的明确方法。他们的纯采样策略产生了更好的结果。我们在采样策略中引入了超参数，多样性。分集D是区间（0， 1）中的实数。在生成阶段，模型预测值除以分集，D。应用softmax函数后，进行抽样。结果，较低多样性导致采样策略关闭贪婪策略并产生较少的各种但格式良好的测试数据。另一方面，更高的多样性使得采样策略远离贪婪策略并创建更多种不同但形成错误的测试数据。</p>\n<h2 id=\"3-4-模糊测试数据\"><a href=\"#3-4-模糊测试数据\" class=\"headerlink\" title=\"3.4.模糊测试数据\"></a>3.4.模糊测试数据</h2><p>当我们使用表1中的模型和上一节中概述的采样策略生成测试数据时，生成的数据将存在固有的变化，因此这些数据可用作测试数据。然而，学习文件结构和模糊它是光谱的两端。学习希望捕获格式良好的文件的结构，并生成可以通过文件解析器的文件，而模糊测试打算破坏文件结构，希望使程序执行失败。在本节中，我们介绍了神经模糊算法，目的是在前两个目标和文件格式模糊测试的最终生成测试数据之间建立权衡。我们的算法扩展和改进了SampleFuzz算法[8]。正如我们所提到的，文件由数据和元数据的两部分组成，每个部分都在一个单独的阶段中处理。我们引入了两个名为DataNeuralFuzz的算法，用于模糊数据，针对渲染阶段，MetadataNeuralFuzz用于模糊元数据，针对解析阶段。</p>\n<p>DataNeuralFuzz显示在算法1中，MetadataNeuralFuzz显示在算法2中。两种算法都将学习模型M，序列前缀P，分集D，模糊率FR，结束标记ET，二进制标记BT作为输入，并作为输出返回测试数据T D.每个算法都有一个主循环，一直持续到没有生成ET。在while循环内，M用D采样。然后在算法中不同的某些条件下修改（模糊）预测符号。退出while循环后，算法检查T D是否包含BT。如果它包括BT，则BT被实际二进制部分替换，该实际二进制部分在基于突变的方法中被模糊化，例如随机地。请记住，在将二进制部件与原始数据集分离时，我们已经存储了它们。最后，算法返回T D.</p>\n<p><img src=\"/2019/04/17/Neural-Fuzzing-A-Neural-Approach-to-Generate-Test-Data-for-File-Format-Fuzzing/10.jpg\" alt=\"\"></p>\n<p><img src=\"/2019/04/17/Neural-Fuzzing-A-Neural-Approach-to-Generate-Test-Data-for-File-Format-Fuzzing/11.jpg\" alt=\"\"></p>\n<p>这两种算法的主要特征之一是与SampleFuzz不同，它们总是终止。在每个算法进入其while循环之前，将具有最小值a和最大值b的随机整数设置为T D的最大长度MaxLen变量。如果ET不是由模型产生并且T D的长度大于MaxLen，则在while循环中生成T D期间，然后通过算法将ET添加到T D的末尾，并且while循环将断开。 a和b的值应由测试者确定。一个好的做法是将它们设置在数据集文件的平均长度附近。</p>\n<h3 id=\"3-4-1-DataNeuralFuzz\"><a href=\"#3-4-1-DataNeuralFuzz\" class=\"headerlink\" title=\"3.4.1. DataNeuralFuzz\"></a>3.4.1. DataNeuralFuzz</h3><p>DataNeuralFuzz算法旨在模糊存储在文件中的数据。存储在不同文件中的数据最明显的特性是其多样性。因此，观察到学习模型预测存储数据的概率低于描述文件格式的元数据。这意味着包含纯数据的位置中的模型预测向量比包含元数据的位置更平滑。使用存储在预测矢量中的概率的这种特性，可以确定数据的类型，如纯数据或元数据。为了确定数据类型，如纯数据或元数据，我们将通过实验获得的阈值α设置为边界线。如果符号c的概率，即p（c）小于α，则c被认为是纯数据。 DataNeuralFuzz用c’替换纯数据项c，其中c‘具有最低似然性，条件是：</p>\n<ol>\n<li>符号c的概率p（c）小于给定阈值α。</li>\n<li>符号c既不属于BT也不属于ET。</li>\n<li>测试仪给出的模糊率FR高于随机数p_fuzz，它是由i.i.d.3随机生成器生成的。</li>\n</ol>\n<p>模糊率FR表示在测试数据生成期间要模糊的数据百分比。例如，如果FR设置为0.1，则算法只会对10％的数据进行模糊测试。此外，我们不愿意模糊关键令牌，即BT和ET，因为这些令牌被插入到文件中以分别处理文件的二进制部分和结尾。这就是为什么确保纯数据项c不属于BT和ET的原因。</p>\n<p> 纯数据的另一个方面是它看起来像长度大于1的标记。我们的DataNeuralFuzz算法旨在通过更改令牌的一个或多个符号来模糊纯数据令牌。建议[23,6]使用最高可能值更改数据令牌，具体取决于令牌的类型。  在实验上，模糊测试的最佳实践是用其边界值替换数据标记。例如，使用999…… 9而不是整数数据是个好主意。通常，众所周知，用作输入数据的边界值可能导致SUT执行的呈现阶段中的崩溃。</p>\n<p> 学习的模型可用于生成任何文件，作为模糊SUT的输入。为此，将一个文件（作为固定长度的输入字符串）提供给模型，模型生成下一个符号。下一次输入字符串向前移动一个符号，这次输入字符串将包括新生成的符号。将得到的字符串再次馈送到学习模型以生成第二符号。只要创建了足够的符号并构建了新的输入文件，就会重复此过程。为了提高生成的输入文件的有效性，每次学习模型生成新符号时，只要保持上述三个条件，我们就在使用符号之前对符号进行模糊处理。每次模型决定通过将此符号添加到下一个前缀来模糊数据令牌的第一个符号时，我们让模型保持模糊预测状态。下一次学习模型想要预测符号时，其预测将受到模糊符号的影响，这可能导致另一个格式错误的符号。我们称这种机制为“将模糊传播到前缀”。</p>\n<h3 id=\"3-4-2-MetadataNeuralFuzz\"><a href=\"#3-4-2-MetadataNeuralFuzz\" class=\"headerlink\" title=\"3.4.2. MetadataNeuralFuzz\"></a>3.4.2. MetadataNeuralFuzz</h3><p>如上所述，我们的fuzzing算法由两个不同的部分DataNeuralFuzz和MetadataNeuralFuzz组成，分别用于生成和模糊生成文件的纯数据和格式/元数据。实际上，生成的文件进一步格式错误，以实现使SUT执行崩溃的更高概率。 MetadataNeuralFuzz尝试使SUT的文件格式解析器崩溃。为了避免被SUT解析阶段中使用的异常处理机制所困，MetadataNeuralFuzz尝试：</p>\n<ol>\n<li>应用学习的模型，描述文件的适当结构，以生成新文件，以测试SUT。</li>\n<li>使用测试人员给出的特定百分比来模糊描述文件格式的一些符号。</li>\n</ol>\n<p>MetadataNeuralFuzz算法旨在模糊文件格式，同时尽可能保留整个文件结构。通过这种方式，MetadataNeuralFuzz可以检查解析器对无效或格式错误的文件格式的健壮性。学习模型本身对元数据和纯数据没有任何假设。它只是在生成文件时预测下一个符号出现的概率。 MetadataNeuralFuzz在生成元数据时对其进行模糊处理。为了区分元数据和纯数据，MetadataNeuralFuzz使用在训练步骤中获得的符号频率。通常，元数据比语料库中的纯数据重复得多。据观察，学习模型比纯数据更高概率地预测元数据，非常接近于1。如果预测符号c的概率大于给定阈值β，则算法猜测符号c可能属于文件格式并用最低发生概率的符号替换它。为了控制模糊符号的百分比，使用模糊率FR。 MetadataNeuralFuzz模糊元数据，假设随机生成的数字p模糊小于由测试者给出的预定模糊测试速率FR。</p>\n<p>MetadataNeuralFuzz将ET和BT视为模糊测试，因为这些标记是格式的一部分。当由学习模型生成的符号被模糊时，它仅存储在目标文件中，并且不影响学习模型对下一个符号的预测。以这种方式，确保模糊符号不传播到下一个前缀（MetadataNeuralFuzz算法的第10行）。两个算法MetadataNeuralFuzz和DataNeuralFuzz之间的差异在MetadataNeuralFuzz算法中突出显示，算法2中显示了该算法。</p>\n<h2 id=\"3-5实现\"><a href=\"#3-5实现\" class=\"headerlink\" title=\"3.5实现\"></a>3.5实现</h2><p>为了实现深度NLM，我们使用了一个高级深度学习库Keras [24]。 Keras包含一组高级API，用于构建用Python编写的深度学习模型，并需要一个低级运行时后端来执行深度学习代码。我们决定使用TensorFlow [25]，一个用于机器学习任务的Google框架，作为Keras的后端。我们使用交叉熵作为目标函数，<code>Adam</code> [26]将学习率1×10^-4^和1×10^-3^作为训练过程中的优化算法。我们还应用了<code>Dropout</code>[27]技术来防止我们的模型过度拟合。</p>\n<p>本文的目的是提供一种自动生成测试数据的方法。但是，单独测试数据生成还不足以进行模糊测试。<br>为了评估提出的方法，我们需要一个文件格式模糊器。模糊器将测试数据注入SUT并检查意外结果，例如使SUT的存储器崩溃。我们设计并实现了IUST DeepFuzz作为模块化文件格式模糊器。 IUST DeepFuzz使用<code></code>Microsoft Application Verifier<code>[28]，一个免费的运行时监控工具，作为监控模块来捕获任何内存损坏。它还使用微软的另一个工具</code>VSPerfMon` [29]来测量代码覆盖率。</p>\n<p>IUST DeepFuzz的主要模块是一个测试数据生成器，它实现了我们的神经模糊算法。这些模块使用适当的Python和批处理脚本连接。以上配置中的IUST DeepFuzz可以在Windows操作系统上运行。要在其他操作系统上使用它，我们需要更换监视工具，即Application Verifier [28]。测试数据生成器是用Python编写的，可以在任何平台上运行。代码覆盖率测量模块仅用于评估目的，我们的模糊测试不需要它。 IUST DeepFuzz是一款带有混合测试数据生成器的黑盒子模糊器[1]。每个生成的测试数据在注入SUT之前存储在磁盘上，因此如果Application Verifier报告崩溃，则可以检索导致该崩溃的测试数据以进行故障本地化过程。图4显示了IUST DeepFuzz的体系结构和数据流。</p>\n<p><img src=\"/2019/04/17/Neural-Fuzzing-A-Neural-Approach-to-Generate-Test-Data-for-File-Format-Fuzzing/12.jpg\" alt=\"\"></p>\n<h1 id=\"4-实验和评估\"><a href=\"#4-实验和评估\" class=\"headerlink\" title=\"4.实验和评估\"></a>4.实验和评估</h1><p>在本节中，我们将介绍使用IUST DeepFuzz进行实验的结果。我们使用IUST DeepFuzz来模糊MuPDF [10]，这是一个免费的开源PDF，XPS和电子书阅读器，它将复杂的PDF文件[11]作为输入进行处理。 PDF是一种复杂的文件格式。 Adobe PDF规范[11]中描述了PDF文件的完整规范。同样，简要介绍[8]中指定的PDF文件的基本部分。 PDF文件的主要部分是表示文件的所有功能和方面的数据对象。按照[8]中提出的方法，我们在PDF对象集上训练我们的模型，然后生成新的PDF文件到模糊MuPDF查看器[10]。</p>\n<p>我们还实现了Learn＆Fuzz方法[8]并在MuPDF查看器[10]上进行了评估，因为Edge PDF解析器和Learn＆Fuzz的其他材料包括数据集和模型超参数，并未公开提供。通过这种方式，我们能够在我们提出的方法和提到的方法之间进行有意义的比较，作为该领域最相关的工作。</p>\n<h2 id=\"4-1-评估指标\"><a href=\"#4-1-评估指标\" class=\"headerlink\" title=\"4.1.评估指标\"></a>4.1.评估指标</h2><p>模糊测试的主要目的是在SUT中查找与代码覆盖率有关的故障和漏洞。学习文件结构的主要目标是生成与模型精度相关的格式良好的文件。根据这些事实，我们在实验中考虑以下指标来衡量我们提出的方法的有效性。</p>\n<ol>\n<li><strong>模型准确度和误差</strong>：这些指标基于Keras [24]在训练每个模型时报告的目标函数。精度和误差是根据验证集数据计算的，验证集数据是从预处理阶段的数据集中导出的。</li>\n<li><strong>模型困惑度</strong>：困惑度是评估LM的最常见指标，它被定义为[30]：</li>\n</ol>\n<p><img src=\"/2019/04/17/Neural-Fuzzing-A-Neural-Approach-to-Generate-Test-Data-for-File-Format-Fuzzing/13.jpg\" alt=\"\"></p>\n<p>在等式8中，x是具有长度n的序列以评估困惑度。困惑表明预测序列和测试集序列之间的差异。因此，较低的困惑意味着更好的LM。对于每个模型，我们在训练期间计算验证集的困惑度。我们使用困惑来评估所提出的模型在捕获输入文件的结构方面的优异性以及比较不同的建议NLM。</p>\n<ol start=\"3\">\n<li><strong>代码覆盖</strong>：对于每个测试数据执行，基本块覆盖由VSPerfMon工具[29]测量。基本块覆盖是语句覆盖的扩展，其中每个非分支语句序列被视为一个语句单元。基本块覆盖的主要优点是它可以低开销应用于目标代码。测试集的总覆盖范围是各个覆盖范围的并集。 VSPerfMon还报告行覆盖率，这与高级代码的语句覆盖率相同。</li>\n<li><strong>故障和漏洞</strong>：对于每个测试数据执行，Application Verifier [28]创建一个日志文件。然后，我们使用简单的脚本搜索这些日志文件，以查找任何错误或安全警告。</li>\n</ol>\n<p>前两个指标确定了学习文件格式的有效性，接下来的两个指标衡量了模糊测试的质量和实用性。 </p>\n<h2 id=\"4-2-实验设置\"><a href=\"#4-2-实验设置\" class=\"headerlink\" title=\"4.2.实验设置\"></a>4.2.实验设置</h2><p>表1中的训练模型是在具有单个Nvidia GTX 1080 GPU，Intel Core i7 CPU和20 GB RAM的物理ubuntu 16.04机器上进行的。模糊测试在具有Intel Core i7 CPU和8 GB RAM的虚拟Windows 10计算机上完成。我们在进行实验时使用了最终版本的MuPDF查看器[10]，即版本MuPDF 2017-04-114。</p>\n<p><img src=\"/2019/04/17/Neural-Fuzzing-A-Neural-Approach-to-Generate-Test-Data-for-File-Format-Fuzzing/14.jpg\" alt=\"\"></p>\n<p>在我们生成测试数据之前，我们应该训练我们的模型。表2显示了我们模型的关键超参数以及每个模型的时期数和训练时间。模型的复杂性，即训练参数的数量，随着模型的ID而增加。对于更复杂的模型，获得更多训练样本是合理的。因此，在模型3和4中，我们减少跳跃步骤，这导致增加训练样本。在模型3中，我们使用Dropout [27]和p = 0.3进行正则化。</p>\n<h2 id=\"4-3-数据集和主机文件\"><a href=\"#4-3-数据集和主机文件\" class=\"headerlink\" title=\"4.3.数据集和主机文件\"></a>4.3.数据集和主机文件</h2><p>深度神经网络的成功训练需要大量且足够的数据集。因此，我们从各种来源收集了大量PDF文件，包括Mozilla PDF.js开放测试语料库[31]，AFL [13]中使用的一些PDF作为初始种子，以及从不同语言的公共网络收集的PDF。 最后，我们发布了IUST PDF Corpus超过6000个PDF文件。此类语料库之前未公开发布，也可用于其他类型的PDF操作和测试。</p>\n<p>为了学习PDF对象的统计结构，我们从IUST PDF Corpus提取了500000的个对象。这些对象中约有27％具有二进制流。我们用二进制令牌流替换二进制流，提取并将它们存储到单独的数据集中，并在我们的训练过程中包含修改后的对象。与[8]的一个关键区别是我们在提取对象之前没有应用种子最小化，因为我们想要学习文件的结构，更多的数据可能会改善学习。整个提取的PDF数据对象集可在IUST PDF Corpus中找到。</p>\n<p>由于我们只学习和生成PDF对象，因此我们需要一种机制来创建完整的PDF文件。按照[8]中提出的方法，我们决定将新生成的对象附加到现有的格式良好的PDF文件中，称为host。PDF文件可以按照PDF参考指南[11]中的说明逐步更新。新对象附加到现有PDF的末尾，其偏移量将添加到交叉引用表中。此方法允许用户更新PDF文件而无需重写整个文件。实际上，新对象重写现有对象的内容，该对象由ID标识并且绝对是旧标识。有关增量更新的更多详细信息，请参见[11]。</p>\n<p>下一步是选择主机文件。在[8]提出的工作中，这几乎是随机的，只从他们的语料库中选择最小的三个PDF文件。<br>针对这项工作，为了研究主机复杂性对代码覆盖率的影响，我们首先通过运行MuPDF计算语料库中所有PDF文件的代码覆盖率，然后选择具有最大，最小和平均代码的三个文件覆盖范围分别为host1_max，host2_min和host3_avg。</p>\n<h2 id=\"4-4-代码覆盖的基线\"><a href=\"#4-4-代码覆盖的基线\" class=\"headerlink\" title=\"4.4.代码覆盖的基线\"></a>4.4.代码覆盖的基线</h2><p>为了将新生成的PDF文件的代码覆盖率与现有的PDF文件进行比较，我们首先测量了每个主机的MuPDF [10]代码覆盖率，然后构建了1 000个PDF文件，其中包含从测试集中随机选择的对象。这些对象以两种不同的模式附加到主机文件：</p>\n<ol>\n<li>单个对象更新（SOU）：查找主机文件中的最后一个对象ID，并用新对象重写它。在此模式下，每个文件中只会更改一个对象。</li>\n<li>多个对象更新（MOU）：重写每个PDF文件中对象的固定部分。首先，在此模式中，计算主机中的总对象数，然后新对象将覆盖随机选择的对象ID列表。</li>\n</ol>\n<p><img src=\"/2019/04/17/Neural-Fuzzing-A-Neural-Approach-to-Generate-Test-Data-for-File-Format-Fuzzing/15.jpg\" alt=\"\"></p>\n<p>表3显示了每个主机中的对象数以及MOU模式下重写对象的部分。图5显示了通过在三个主机上运行MuPDF查看器获得的代码覆盖率，除了两个测试套件的覆盖范围，一个用于SOU，称为基线源，一个用于MOU，称为基线mou。 host123表示从主机1,2和3获得的代码覆盖的并集。观察到以下结果。 </p>\n<ul>\n<li>每个基线的代码覆盖率高于单个主机的覆盖范围。这意味着更改主机会增加代码覆盖率。</li>\n<li>基线覆盖范围与主机覆盖范围有直接关系。例如，host1_max在host1_max，host2_min和host3_avg中具有最高的代码覆盖率。这表明选择合适的主机文件是一项基本工作，并对基线覆盖率产生重大影响。</li>\n<li>在所有情况下，基线mou的代码覆盖率均大于基线。  这意味着进一步修改文件内容会增加代码覆盖率。</li>\n<li>最大代码覆盖率属于host123，表示每个主机已执行不同的基本块。</li>\n<li>最后，覆盖代码的顺序在20,000个基本块的范围内，显示MuPDF查看器[10]是一个大型应用程序，PDF文件具有复杂的格式。 </li>\n</ul>\n<h2 id=\"4-5-模型评估\"><a href=\"#4-5-模型评估\" class=\"headerlink\" title=\"4.5.模型评估\"></a>4.5.模型评估</h2><p><img src=\"/2019/04/17/Neural-Fuzzing-A-Neural-Approach-to-Generate-Test-Data-for-File-Format-Fuzzing/16.jpg\" alt=\"\"></p>\n<p>表4显示了在50个时期训练后我们的模型的困惑，准确性和误差。名为laf的最后一列显示了Learn＆Fuzz模型的这个值[8]。 Keras报告了这些指标。困惑由公式8计算。准确度和误差来自交叉熵损失函数。图6还显示了训练过程中模型2和模型laf的验证错误图。模型2已在此图中说明，因为它与架构和超参数设置中的laf最相似。观察到以下结果。</p>\n<ul>\n<li>所有NLM的误差小于laf误差，并且它们的准确度大于它。这意味着NLM在文件的学习语法中优于编码器 - 解码器模型。</li>\n<li>最大精度属于模型4，我们唯一的双向LSTM。该网络以从左到右和从右到左的方向处理输入序列。因此它可以达到较高的准确度，从而导致较低的困惑。</li>\n<li>在图6中，模型2的错误图始终位于模型laf下当然，迭代有不同的时期，因此点对点比较可能并不令人兴奋。但是，我们也看到这种关系在训练过程开始时的相等间隔内是正确的。</li>\n<li>在我们的数据集中，所有模型的最大困惑是在没有NLM的情况下是困惑的。 50个训练时期之后的困惑度小于1.5，这表明NLM可以学习如此优秀的文件语言。最小困惑属于具有最大可训练参数数量的模型3。</li>\n</ul>\n<p><img src=\"/2019/04/17/Neural-Fuzzing-A-Neural-Approach-to-Generate-Test-Data-for-File-Format-Fuzzing/17.jpg\" alt=\"\"></p>\n<h2 id=\"4-6-采样多样性和代码覆盖率\"><a href=\"#4-6-采样多样性和代码覆盖率\" class=\"headerlink\" title=\"4.6.采样多样性和代码覆盖率\"></a>4.6.采样多样性和代码覆盖率</h2><p>为了研究生成测试数据时多样性对代码覆盖率的影响，我们使用不同多样性0.5,1.0和1.5的采样策略在每个主机上生成1,000个PDF文件。该实验提供了关于代码覆盖中的最佳模型，主机，分集和更新模式（即，SOU和MOU）的信息。因此，我们可以选择用于模糊测试的最佳配置。 我们在训练时间的每个时期结束时保存一个检查点，然后选择所有检查点之间具有最小验证误差的模型。我们选择最佳学习模型进行抽样。</p>\n<p>在SOU模式下使用我们的模型生成1,000个PDF文件大约需要60分钟，在MOU模式下大约需要190分钟。在MuPDF查看器上运行每个测试套件并获得覆盖平均花费65分钟。总的来说，我们在此实验中生成并测试了72,000个PDF文件。所有代码覆盖率如图7所示。观察到以下结果。</p>\n<ul>\n<li>在大多数情况下，生成数据的代码覆盖率小于基线代码覆盖率，因为生成的对象在我们的测试集中并不是真正的PDF对象。但是，在这种情况下，我们会看到代码覆盖率的增加，例如在图表host2_min_mou中。这意味着对于小型主机，添加更多内容会导致更好的代码覆盖率。</li>\n<li>增加多样性会导致双向LSTM（模型4）中的代码覆盖率增加，但其他模型则不然。通常，在大多数模型和大多数主机上生成具有分集一的数据似乎更有效，而不是SUT的代码覆盖。</li>\n<li>几乎在所有图表中，模型2在代码覆盖率方面优于其他模型。这意味着更简单的NLM比更复杂的NLM更好。</li>\n<li>通过查看host123图表，作为结果的汇总，我们可以得出结论，具有多样性的模型2是模糊测试的最佳模型。<br>因此，我们选择此模型用于4.7节中的神经模糊算法。</li>\n</ul>\n<p><img src=\"/2019/04/17/Neural-Fuzzing-A-Neural-Approach-to-Generate-Test-Data-for-File-Format-Fuzzing/18.jpg\" alt=\"\"></p>\n<h2 id=\"4-8-神经模糊测试\"><a href=\"#4-8-神经模糊测试\" class=\"headerlink\" title=\"4.8.神经模糊测试\"></a>4.8.神经模糊测试</h2><p>在第四次和最后一次实验中，我们将MuPDF [10]放在真正的模糊测试上。我们使用DataNeuralFuzz和MetadataNeuralFuzz算法生成10,000个PDF文件，然后使用IUST DeepFuzz进行模糊测试。除了模糊我们的神经模糊算法外，我们还通过FileFuzz [5]进行模糊测试，这是一种基于变异的简单文件格式模糊器，以及Learn＆Fuzz（即SampleFuzz算法）[8]。在所有实验中，我们使用host1_max作为主机文件或FileFuzz的初始种子。在这个实验中，我们用40,000个PDF文件模糊了MuPDF查看器。</p>\n<p>表5显示了为DataNeuralFuzz和MetadataNeuralFuzz算法设置的输入和常量值，以便在可用值中生成测试数据。表6显示了各种模糊测试方法的代码覆盖率结果，包括Learn＆Fuzz [8]和FileFuzz [5]。最后，表7显示了我们提出的方法和其他四种已知文件格式模糊器的代码覆盖率之间的差异：Learn＆Fuzz，AFL [13]，Augmented-AFL [14]和FileFuzz。微软研究最近推出了增强型AFL作为AFL的改进。观察到以下结果。</p>\n<p><img src=\"/2019/04/17/Neural-Fuzzing-A-Neural-Approach-to-Generate-Test-Data-for-File-Format-Fuzzing/19.jpg\" alt=\"\"></p>\n<p><img src=\"/2019/04/17/Neural-Fuzzing-A-Neural-Approach-to-Generate-Test-Data-for-File-Format-Fuzzing/20.jpg\" alt=\"\"></p>\n<p><img src=\"/2019/04/17/Neural-Fuzzing-A-Neural-Approach-to-Generate-Test-Data-for-File-Format-Fuzzing/21.jpg\" alt=\"\"></p>\n<p><img src=\"/2019/04/17/Neural-Fuzzing-A-Neural-Approach-to-Generate-Test-Data-for-File-Format-Fuzzing/22.jpg\" alt=\"\"></p>\n<ul>\n<li>MetadataNeuralFuzz代码覆盖率低于DataNeuralFuzz。正如我们已经说过的那样，操作文件格式的一小部分可能会使其完全无效，因此解析器会尽快拒绝该文件并导致代码覆盖率降低。但是，更改文件中的数据会影响文件执行的呈现阶段。结果证明两种算法都符合我们的预期。一个fuzzes格式，另一个fuzzes数据。</li>\n<li>与SampleFuzz [8]相比，DataNeuralFuzz和MetadataNeuralFuzz都覆盖了MuPDF查看器代码的更多基本块（当然还有更多行）。这表明带有RNN的NLM在模糊测试中优于编码器 - 解码器模型。另一种解释是混合测试数据生成优于基于生成的方法。</li>\n<li>我们的混合测试数据生成方法也优于基于突变的模糊器，如AFL和AugmentAFL，如表7所示.AFL和增强AFL的代码覆盖率取自[14]作为基准。</li>\n<li>基于模糊测试的测试数据生成部分，智能算法与随机变 异的优势是显而易见的。随机算法无法访问复杂输入结构中的高代码覆盖率。 DataNeuralFuzz算法的覆盖范围是FileFuzz [5]中使用的算法的三倍多。</li>\n<li>尽管我们在模糊测试过程中改进了MuPDF查看器[10]的代码覆盖率，如表6所示，覆盖代码的百分比仍然低于25％。这意味着大多数观众代码都没有被执行，这不是好消息。另一方面，我们应该知道MuPDF查看器可以解析和播放不同的文件格式，如XPS。这意味着当输入采用这样的格式时，将使用部分未执行的代码。因此，我们不希望仅通过生成和注入PDF文件来运行它们。</li>\n</ul>\n<h2 id=\"4-9-故障和漏洞\"><a href=\"#4-9-故障和漏洞\" class=\"headerlink\" title=\"4.9.故障和漏洞\"></a>4.9.故障和漏洞</h2><p>可用于评估模糊器的最佳度量标准是在模糊测试期间发现的故障和漏洞的数量。在每次测试执行后，我们没有看到Application Verifier [28]生成的报告中出现任何错误。鉴于我们测试了MuPDF软件的最终版本[10]，假设其大多数错误在试用版本中得到修复，因此很难找到新的错误。另一方面，MuPDF是正在积极开发的软件，它拥有出色的开发人员和用户社区，使其成为强大的软件。但是，DataNeuralFuzz算法检测到不安全功能的多种用法，并将其报告为安全警告。</p>\n<p>似乎Application Verifier [28]在Windows 10 x64上运行时无法检测到32位应用程序的内存错误。我们尝试使用已知错误对一个简单的32位应用程序进行模糊测试，但ApplicationVerifier不会报告任何内容。 64位应用程序但没有这样的问题，它们的错误由ApplicationVerifier检测到。因此，我们测试了32位和64位版本的MuPDF查看器[10]。 IUST DeepFuzz打开带有测试数据的SUT并在固定时间后关闭它，尝试在测试套件中注入下一个测试数据。在我们的配置中，每个测试套件包含10,000个测试数据，需要大约28个小时进行处理。模糊测试是一种压力测试，通常在几天或几周内完成，以发现故障和漏洞。我们计划在更大规模的测试服上测试MuPDF，其中包含100,000个PDF文件以及更多可能会破坏MuPDF的文件。</p>\n<h1 id=\"5-相关工作\"><a href=\"#5-相关工作\" class=\"headerlink\" title=\"5.相关工作\"></a>5.相关工作</h1><p>在本节中，我们将讨论一些相关的模糊测试工作，并解释他们在测试数据生成方面存在的问题。根据测试数据生成方法，模糊器分为基于突变和基于生成[32,33,34]。将各种技术应用于两种方法以改进它们。大多数这些技术都专注于人工智能算法。</p>\n<p><strong>I.基于突变的模糊测试</strong>。在基于突变的情况下，使用一个或多个有效输入数据作为初始种子。然后该种子发生变异以产生另一个测试数据。很容易构建基于突变的模糊器并用它生成错误形成的测试数据。在这种情况下，不需要事先理解输入数据结构。基于突变的方法的缺点是该方法取决于初始种子的变化。如果没有不同的样本输入，基于突变的模糊器就无法实现高代码覆盖率[35]，这表明初始种子在基于突变的方法中的重要性。 AFL [13]和FileFuzz [5]是基于突变的模糊器的例子。</p>\n<p><strong>II.基于生成的模糊测试</strong>。基于生成的方法完全随机地生成测试数据，或者从诸如语法，模板或模型的形式描述生成测试数据。最新的使用输入格式规范来构建生成模型。此方法通常应用于某些文档可用的格式。通常，与基于突变的模糊器相比，它实现了更高的代码覆盖率[35]。但是，正如我们所说，应该花费大量的时间和金钱来完全理解文件格式的规范，并为它构建正确的语法，模板或模型。 SAGE [36]和Peach [37]是基于生成的模糊器的例子。还存在利用两种方法的特征的混合方法。 IUST DeepFuzz在本文中提出了一种混合模糊器，它通过生成模型生成结构化文本数据，通过突变生成非结构化二进制数据。</p>\n<p><strong>III.进化模糊</strong>。通过应用遗传等进化算法[38]，首次尝试将模拟带入模糊测试。进化模糊器从运行时信息（通常是代码覆盖率信息）接收反馈，并将导致新执行路径的测试数据添加到队列中。之后，当模糊器想要生成测试数据时，它只会改变队列中存在的测试数据，希望能够运行代码的新部分。 AFL [13]是最先进的进化文件格式，模糊器的工作方式与上面完全相同。通过使用先前运行的反馈，AFL可以选择更好的测试数据，但是，它会随机改变它们。结果，将生成大量重复的测试数据，这些数据不一定影响包括代码覆盖的测试标准。另一方面，在复杂的输入结构中，更改某些关键部分会导致输入测试数据在解析的初始阶段被解析器拒绝。因此，我们需要一种机制来告知fuzzer输入文件的变异（偏移）。</p>\n<p><strong>IV.基于变异和进化方法的深度学习</strong>。Augmented-AFL [14]作为AFL [13]的改进补丁，尝试使用深度学习技术找到适合变异的位置。在Augmented-AFL创建新的测试数据后，它会查询模型以查看生成的测试数据是否足够好？这种方法提高了测试速度，但是大量数据在生成时被模型（否决）拒绝。此外，Augmented-AFL在MuPDF解析器的代码覆盖率方面没有显着改进[10]。对于具有复杂输入结构的应用程序而言，基于突变的方法似乎无法丰富高代码覆盖率。</p>\n<p><strong>V.基于生成方法的深度学习</strong>。 Godefroid等人最初提出了应用基于神经网络的统计学习从样本输入自动生成输入语法。 [8]。他们还提出了一种生成模糊输入的算法。这项工作的主要思想是学习一组PDF文件的生成模型[11]。为此目的，他们使用一种序列来对结构进行排序[15,16]，其最初用于将来自不同域的两个序列映射到一起，例如机器翻译的任务。他们称他们的方法为Learn＆Fuzz。在整篇论文中，我们讨论了Learn＆Fuzz方法的一些弱点，并为它们提供了一些解决方案。基于这项工作，Cummins 等人介绍了使用RNN [21]的LSTM架构对程序代码进行建模的DeepSmith [39]。他们将该工具应用于OpenCL编程语言的模糊编译器。他们的模型不是混合模型，只能用于生成文本测试数据。</p>\n<h1 id=\"6-结论\"><a href=\"#6-结论\" class=\"headerlink\" title=\"6.结论\"></a>6.结论</h1><p>本文旨在为复杂的输入结构（如PDF文件）引入新的智能测试数据生成技术。由递归神经网络构建的深度神经语言模型可以最好地应用于将复杂输入文件的结构学习为符号序列。可以简单地学习输入文件的文本部分。但是，学习二进制部分的格式是一项艰巨的任务。为了解决这个难题，我们建议暂时删除二进制部分，并用特定的标记替换这些部分。在训练阶段完成之后并且当应用学习模型来生成测试数据时，将令牌替换为已删除部分的变异形式。为了提高模糊效率，我们在应用学习模型时将数据和元数据模糊，以生成新的输入文件作为测试数据。我们相信，无论代码覆盖范围如何，在完成模糊测试时都需要这两种算法。神经模糊算法旨在测试程序的不同部分。 MetadaaNeuralFuzz测试文件格式的解析器和DataNeuralFuzz测试文件格式的渲染器。</p>\n<p>测试数据生成器是模糊器中最重要的模块。提供可以在被测软件中实现高代码覆盖率的自动测试数据生成器，尤其是具有复杂输入结构的目标，对于发现故障至关重要。已经成功地应用基于生成和基于突变的方法来生成用于模糊测试的测试数据。但是，前者不是完全自动的，后者的代码覆盖率很差。</p>\n<p>为了解决这些问题，我们提出了一种基于NLM和深度学习技术的方法。我们的混合测试数据生成方法自动学习输入文件的结构，然后通过模糊输入格式的文本和二进制部分来生成新的多样化测试数据。由于该方法智能地确定了模糊的位置以及应该用于模糊的值，因此可以有望地应用于测试复杂目标。</p>\n<p>我们以复杂的文件格式（即PDF）进行了实验，结果证实了与以前的方法相比，代码覆盖率和我们提出的方法的准确性得到了显着改善。除了一般结论之外，我们的分析揭示了一些有价值的经验事实，最值得注意的是：</p>\n<ul>\n<li>混合测试数据生成用于模糊复杂输入结构的文本和二进制部分，增加SUT的代码覆盖率。</li>\n<li>人们普遍认为，作为LM的双向LSTM可以在同一数据集上获得更高的精度和更少的误差。然而，观察到更简单的NLM，例如没有丢失的单向LSTM，例如本文中的模型2，在代码覆盖中可以胜过更复杂的方法。[14]报道了类似的结果。</li>\n<li>基于具有高代码覆盖率的PDF文件的增量更新过程会导致更多代码覆盖。</li>\n<li>尽管提供比随机和现有智能模糊器更高的代码覆盖率，但我们提出的模糊器可以改进，以便为复杂的输入结构（如PDF文件结构）提供更高的覆盖率。</li>\n</ul>\n<p>关于这个主题，未来有很多工作要做。一种是使用其他强大的深度学习模型，如生成对抗网络（GAN）[40]来生成测试数据。另一个方向是应用这些模型在其他类型的模糊器（如网络协议模糊器）中生成测试数据。为了生成更有效的测试数据，我们打算向IUST DeepFuzz添加一个反馈循环，旨在接收运行时信息并微调学习模型。 SUT中有部分代码处理用户交互。然而，诸如AFL [13]和IUST DeepFuzz之类的模糊器不利用用户交互部件进行模糊测试，并且不支持执行这些部分代码。目前，我们计划支持用户与SUT交互的自动化</p>\n","categories":[{"name":"论文","slug":"论文","permalink":"http://yama0xff.com/categories/论文/"},{"name":"fuzzing","slug":"论文/fuzzing","permalink":"http://yama0xff.com/categories/论文/fuzzing/"},{"name":"机器学习","slug":"论文/fuzzing/机器学习","permalink":"http://yama0xff.com/categories/论文/fuzzing/机器学习/"}],"tags":[{"name":"fuzzing","slug":"fuzzing","permalink":"http://yama0xff.com/tags/fuzzing/"},{"name":"机器学习","slug":"机器学习","permalink":"http://yama0xff.com/tags/机器学习/"}]},{"title":"Faster Fuzzing: Reinitialization with Deep Neural Models","date":"2019-04-17T03:48:08.000Z","path":"2019/04/17/Faster-Fuzzing-Reinitialization-with-Deep-Neural-Models/","text":"Abstract我们通过使用生成对抗网络（GAN）模型来改进美国模糊Lop（AFL）模糊测试框架的性能，以使用新的种子文件重新初始化他的系统。我们根据生成新颖和看不见的代码路径的时间速率来评估性能。我们将此方法与在训练种子文件中观察到的随机抽取字节的种子文件生成进行比较。代码路径长度和变化不够多，无法完全取代AFL输入生成。但是，使用这些额外的代码路径扩充原始AFL表明比原AFL有所改进。具体而言，实验表明，GAN比LSTM更快，更有效，并且优于随机增强策略，通过发现的唯一代码路径的数量来衡量。 GAN帮助AFL在相同的CPU时间内发现比随机策略多14.23％的代码路径，找到6.16％的唯一代码路径，并找到平均13.84％的路径。使用GAN有望成为AFL的重新初始化策略，以帮助模糊测试人员在软件中运行深入的路径。 relevant information 作者 Nicole Nichols, Mark Raugas, Robert Jasper, Nathan Hilliard 单位 nicole.nichols@pnnl.govmark.raugas@pnnl.gov robert.jasper@pnnl.govnathan.hilliard@pnnl.gov || 出处 | arxiv || 原文地址 | https://arxiv.org/abs/1711.02807 || 源码地址 | || 发表时间 | 2017 | 1. 简介通过测试识别软件缺陷是一个具有挑战性的问题。多年来，已经开发了许多方法来测试软件，包括随机变异测试（黑盒模糊测试）Doupéu.a （2012），Woo.u.a（2013），抽象解释（来通过源源代码或机器代码）Cousot和Cousot（1977），Cadar.u.a （2008），Ma.u.a （2011年），和基于性能的测试Arts.u.a （2006年）,Claessen und Hughes（2011年）。 符号执行等方法提高了程序的分析保真度Schwartz.u.a （2010年）。 Z3，Boolector等可满足性模数理论（SMT）求解器的开发使得对软件的推理进行了强有力的程序化分析，De MouraundBjørner（2008） Brummayer und Biere（2009）。分离逻辑允许将分析应用于复杂的数据结构Reynolds（2002）; Dongol.u.a（2015年）。 American Fuzzy Lop（AFL）是一种先进的模糊测试框架，用于发现许多新颖的软件漏洞（https://github.com/mrash/afl-cve）。 AFL使用字节串的随机变换来识别唯一的代码路径并发现目标程序中的缺陷。然后，成功生成唯一代码路径的输入被记录为“种子文件”。我们建议使用这些原生种子文件作为深度生成模型的训练数据，以创建增强的种子文件。我们提出的重新初始化方法是一个可扩展的过程，可以缩短发现软件缺陷的时间。 其他研究人员使用机器学习来增强模糊测试框架，包括：Godefroid .u.a （2017），wang.u.a （2017年）。为了识别更深层次的错误和代码路径，Steelix Li.u.a（2017）使用基于程序状态的二进制模糊方法和Driller Stephens .u.a（2016）演示了使用模糊测试和选择性执行的混合方法。 AFLFASTBöhme.u.a（2016）使用马尔可夫链模型扩展AFL。深度神经网络（DNNs）Bengio.u.a（2015），在自然语言处理（NLP）Jones（2014）领域取得了巨大成功；Wu.u,a （2016）计算机视觉Krizhevsky.u.a（2012年），以及像Go Mnih.u.a（2013）这样的有界游戏，或像ATARI Silver.u.a （2016）等视频游戏。。这些DNN可以帮助现有的程序分析工具更好地运行吗？在我们的工作中，我们调查了这个问题，我们使用Generative Adversarial Networks（GAN）Goodfellow.u.a（2014）和长期短期记忆（LSTM）Sak.u.a （2014）增加其唯一代码路径发现率从而来增强AFL Zalewski，一个先进的模糊测试框架。 我们的工作量化了生成模型等增强策略可以提供的好处，即使受到少量培训数据的限制。通过在探索输入空间时周期性地干扰AFL的状态，我们能够改善其性能，如通过唯一代码路径所测量的。具体来说，我们测试了我们围绕以太坊木业（2014）项目的软件生态系统的方法。作为一个金融系统，以太坊代码库的正确性对于保证事务或计算无故障运行非常重要。我们选择Ethkey作为最初的模糊测试目标。Ethkey是一个小型C ++程序，作为cpp-ethereum项目的一部分提供，用于对以太坊钱包进行加载，解析和执行维护，更重要的是，它采用简单的输入文件，使用AFL进行测试变得容易。 2 实验设计首先，我们描述AFL的基本功能，突出显示与建议的增强框架相关的关键功能。接下来，我们将介绍用于创建LSTM和GAN生成的种子文件的方法。作为基线，我们还考虑从用于构建LSTM和GAN模型的训练数据中随机生成种子文件。 AFL扩展了GCC编译器，它与遗传算法结合使用，用于创建种子文件。每个种子文件记录产生唯一代码路径的输入，发现时间，并用作生成未来种子文件的变异（或模糊测试）的基础。我们的扩充策略利用了这样一个事实：如果外部工具在AFL工作目录中放置其他种子文件，AFL将在后续模糊测试运行中将这些文件用作输入。 为了生成我们方法的训练数据，我们在目标程序P上运行AFL一段固定的时间。对于通过P获取的每个唯一执行轨迹τ，AFL生成初始种子文件集S = {S0，…，SK}。我们使用S作为LSTM和GAN模型的训练样例，这些模型都使用Keras Chollet（2017）进行训练。 我们的LSTM通过将AFL生成的种子文件语料库S连接到单个文件中进行训练，并生成最大长度为40个字符的新种子文件。 LSTM模型具有128宽的初始层，内部隐藏层和最终的softmax激活层。为了训练LSTM模型，我们使用RMS传播作为我们的优化器和分类交叉熵损失函数。该模型接收从训练语料库中采样的种子序列，并预测序列中的下一个字符。我们另外调整单独的温度参数以使从网络中的输出种子文件多样化。生成的种子文件记为SL。 在我们的GAN架构中，构建了两个模型，一个生成器G，它与鉴别器D进行对比。G被优化以生成真实的输出，鉴别器D的任务是预测数据是真还是假。这种训练策略是无人监督的，特别富有表现力。生成模型G是完全连接的2层DNN，具有ReLU非线性作为内部激活和tanh输出激活。它通过随机梯度下降训练二元交叉熵损失函数。辨别模型D是3层DNN，但是第一层具有25％的丢失，接着是两个完全连接的层。它使用Adam优化器进行随机梯度下降，并将GAN过程产生的种子文件记为SG。 另外，给定原始AFL种子文件S，我们从该训练集中随机抽取字节并产生与SG相同长度的新的随机种子文件SR。这作为基线来确定基于GAN和LSTM的种子生成的增加的时间和复杂性是否真正提供了优于随机扰动AFL状态的简单策略的优势。 小实验：仅种子文件（SR，SG和SL）不是最终目标。但是，我们感兴趣的是描述它们的可变性和其他属性，因为它们将在AFL重新启动时提供一组初始条件。在单个CPU内核的模糊运行中，我们生成936个用于训练初始GAN和LSTM模型的唯一代码路径。通过从/ dev / urandom绘制随机字节来执行随机种子生成。对于每种方法，我们生成200个样本，在单个CPU上重新初始化AFL，仅使用一种方法的种子文件，再运行72小时以测量对代码路径发现的影响。 LSTM和GAN模型都非常出色地进行AFL重新初始化的随机抽样。我们总结了在表1中发现新代码路径的平均时间。 每个种子文件在作为ethkey的输入提供时会生成程序跟踪。具有不同长度的代码路径将在至少一个基本块或分支指令中不同。唯一的代码路径长度可以快速计算，但只能在使用AFL的模糊运行中提供测试框架所执行的唯一代码路径数量的下限。具有相同长度的两个代码路径可以由唯一跟踪产生，因此需要详细评估以确定来自种子文件执行的代码路径的真实唯一性。 大型实验：为了演示此扩充策略的可扩展性，我们在200个CPU内核上执行了延长的AFL运行72小时。 AFL运行中的每个核心在前10到12个小时的模糊测试后停止查找种子文件，并在49个工作日中累积了39,185个种子文件。由于AFL的内部簿记机制，已知在给定节点内生成的所有种子文件都是唯一的。但是，内容在节点之间不同的种子文件原则上可以使用相同的代码路径。通过测量每个程序跟踪（代码路径）的长度，我们可以计算仅通过计算具有唯一长度的路径而发现的唯一路径数的下限。在从节点之间移除相同的种子文件并且导致导致相同代码路径长度的种子文件之后，我们估计初始文件的802与独立工作者节点重复。删除这些重复项会导致总共38,384个唯一文件。然后，我们在唯一种子文件的总语料库上训练GAN和LSTM网络，并分别从每种方法生成大约20,000个样本，以用作合成种子文件以重新初始化AFL。 GAN花了大约30分钟来训练和生成合成种子文件，而LSTM需要14个小时才能完成。 在表2中，我们总结了与来自原始AFL的种子文件和来自该较大实验的合成生成方法相关联的程序轨迹（即，代码路径）的长度的均值和方差。与AFL相比，合成种子文件作为被测程序的输入提供时，不会导致探索深层路径。因此，我们不能简单地用生成模型取代AFL。相反，我们寻求将生成模型与AFL结合起来以提高其性能。我们从这些数据中看到，实际上，LSTM和GAN生成的种子文件在生成的代码路径的均值和方差方面不能代表分布S.这强化了使用SG和SL作为增强策略而不是直接替代AFL种子的需要。 接下来，我们使用来自初始种子文件的随机字节采样（即，不对种子文件进行学习）对GAN，LSTM和随机重新初始化策略进行24小时模糊测试。表3总结了我们的结果。所有这三种策略都允许生成其他种子文件。基于GAN的方法产生的种子文件比随机方法快14.23％，比使用LSTM快60.72％。我们确实失去了30分钟的GAN训练时间，否则可以使用随机抽样方法进行模糊测试;按这段时间折扣会使代码路径速率降低11.85％。但是，我们对唯一的代码路径最感兴趣。 GAN发现了最多的种子文件，其相关的代码路径在初始模糊测试中没有找到长度，优于随机控制方法6.16％。GAN发现的平均代码路径长度比随机控制长13.84％，因此GAN能够在程序中执行更深的路径。 LSTM模型的表现落后于GAN和随机抽样，并且花费了相当长的时间（14小时）进行训练。 3 结论在这项工作中，我们探索了使用深度神经模型增强随机变异测试的效用。原始AFL通过使用编译器插件将来自遗传算法的文件变异策略与程序设备相结合。当我们使用从GAN模型构建的新种子文件重新开始中间模糊运行时，我们观察到AFL性能的最大改进。尽管合成种子文件统计平均具有相似的路径长度，但是当重新启动模糊测试系统时，GAN从随机或LSTM策略中执行重新初始化。 LSTM模型在训练时间和代码路径发现时间方面都存在缺陷。这两种方法都没有使用手动分析或有关被测程序的文件格式的信息。 GAN和随机策略都改善了AFL的性能，即使程序的内部状态永远不会直接暴露。 未来的工作包括对其他目标的实验，包括DARPA网络大挑战问题，开源OS网络服务，字节码解释器以及其他容易生成输入数据的系统应用程序和程序。我们还计划探索暴露被测试程序的内部状态，以便为强化学习定义奖励功能。我们设想这种内部状态可以通过以下方式公开：1）插桩AFL通过其GCC编译器插件添加到程序中，2）使用英特尔的PIN工具输出每个代码路径的长度或关于给定迹线的摘要信息3）记录程序跟踪使用诸如Mozilla的rr工具之类的重放框架来收集其他描述性统计信息。","content":"<h1 id=\"Abstract\"><a href=\"#Abstract\" class=\"headerlink\" title=\"Abstract\"></a>Abstract</h1><p>我们通过使用生成对抗网络（GAN）模型来改进美国模糊Lop（AFL）模糊测试框架的性能，以使用新的种子文件重新初始化他的系统。我们根据生成新颖和看不见的代码路径的时间速率来评估性能。我们将此方法与在训练种子文件中观察到的随机抽取字节的种子文件生成进行比较。代码路径长度和变化不够多，无法完全取代AFL输入生成。但是，使用这些额外的代码路径扩充原始AFL表明比原AFL有所改进。具体而言，实验表明，GAN比LSTM更快，更有效，并且优于随机增强策略，通过发现的唯一代码路径的数量来衡量。 GAN帮助AFL在相同的CPU时间内发现比随机策略多14.23％的代码路径，找到6.16％的唯一代码路径，并找到平均13.84％的路径。使用GAN有望成为AFL的重新初始化策略，以帮助模糊测试人员在软件中运行深入的路径。</p>\n<table>\n<thead>\n<tr>\n<th>relevant information</th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><em>作者</em></td>\n<td>Nicole Nichols, Mark Raugas, Robert Jasper, Nathan Hilliard</td>\n</tr>\n<tr>\n<td><em>单位</em></td>\n<td><a href=\"mailto:nicole.nichols@pnnl.gov\" target=\"_blank\" rel=\"noopener\">nicole.nichols@pnnl.gov</a><br><a href=\"mailto:mark.raugas@pnnl.gov\" target=\"_blank\" rel=\"noopener\">mark.raugas@pnnl.gov</a></td>\n</tr>\n</tbody>\n</table>\n<p><a href=\"mailto:robert.jasper@pnnl.gov\" target=\"_blank\" rel=\"noopener\">robert.jasper@pnnl.gov</a><br><a href=\"mailto:nathan.hilliard@pnnl.gov\" target=\"_blank\" rel=\"noopener\">nathan.hilliard@pnnl.gov</a> |<br>| <em>出处</em>               | arxiv                                                        |<br>| <em>原文地址</em>           | <a href=\"https://arxiv.org/abs/1711.02807\" target=\"_blank\" rel=\"noopener\">https://arxiv.org/abs/1711.02807</a>                           |<br>| <em>源码地址</em>           |                                                              |<br>| <em>发表时间</em>           | 2017                                                         |</p>\n<h1 id=\"1-简介\"><a href=\"#1-简介\" class=\"headerlink\" title=\"1. 简介\"></a>1. 简介</h1><p>通过测试识别软件缺陷是一个具有挑战性的问题。多年来，已经开发了许多方法来测试软件，包括随机变异测试（黑盒模糊测试）Doupéu.a （2012），Woo.u.a（2013），抽象解释（来通过源源代码或机器代码）Cousot和Cousot（1977），Cadar.u.a （2008），Ma.u.a （2011年），和基于性能的测试Arts.u.a （2006年）,Claessen und Hughes（2011年）。</p>\n<p>符号执行等方法提高了程序的分析保真度Schwartz.u.a （2010年）。 Z3，Boolector等可满足性模数理论（SMT）求解器的开发使得对软件的推理进行了强有力的程序化分析，De MouraundBjørner（2008） Brummayer und Biere（2009）。分离逻辑允许将分析应用于复杂的数据结构Reynolds（2002）; Dongol.u.a（2015年）。</p>\n<p>American Fuzzy Lop（AFL）是一种先进的模糊测试框架，用于发现许多新颖的软件漏洞（<a href=\"https://github.com/mrash/afl-cve）。\" target=\"_blank\" rel=\"noopener\">https://github.com/mrash/afl-cve）。</a> AFL使用字节串的随机变换来识别唯一的代码路径并发现目标程序中的缺陷。然后，成功生成唯一代码路径的输入被记录为“种子文件”。我们建议使用这些原生种子文件作为深度生成模型的训练数据，以创建增强的种子文件。我们提出的重新初始化方法是一个可扩展的过程，可以缩短发现软件缺陷的时间。</p>\n<p>其他研究人员使用机器学习来增强模糊测试框架，包括：Godefroid .u.a （2017），wang.u.a （2017年）。为了识别更深层次的错误和代码路径，Steelix Li.u.a（2017）使用基于程序状态的二进制模糊方法和Driller Stephens .u.a（2016）演示了使用模糊测试和选择性执行的混合方法。 AFLFASTBöhme.u.a（2016）使用马尔可夫链模型扩展AFL。深度神经网络（DNNs）Bengio.u.a（2015），在自然语言处理（NLP）Jones（2014）领域取得了巨大成功；Wu.u,a （2016）计算机视觉Krizhevsky.u.a（2012年），以及像Go Mnih.u.a（2013）这样的有界游戏，或像ATARI Silver.u.a （2016）等视频游戏。。这些DNN可以帮助现有的程序分析工具更好地运行吗？在我们的工作中，我们调查了这个问题，我们使用Generative Adversarial Networks（GAN）Goodfellow.u.a（2014）和长期短期记忆（LSTM）Sak.u.a （2014）增加其唯一代码路径发现率从而来增强AFL Zalewski，一个先进的模糊测试框架。</p>\n<p>我们的工作量化了生成模型等增强策略可以提供的好处，即使受到少量培训数据的限制。通过在探索输入空间时周期性地干扰AFL的状态，我们能够改善其性能，如通过唯一代码路径所测量的。具体来说，我们测试了我们围绕以太坊木业（2014）项目的软件生态系统的方法。作为一个金融系统，以太坊代码库的正确性对于保证事务或计算无故障运行非常重要。我们选择Ethkey作为最初的模糊测试目标。Ethkey是一个小型C ++程序，作为cpp-ethereum项目的一部分提供，用于对以太坊钱包进行加载，解析和执行维护，更重要的是，它采用简单的输入文件，使用AFL进行测试变得容易。</p>\n<h1 id=\"2-实验设计\"><a href=\"#2-实验设计\" class=\"headerlink\" title=\"2 实验设计\"></a>2 实验设计</h1><p>首先，我们描述AFL的基本功能，突出显示与建议的增强框架相关的关键功能。接下来，我们将介绍用于创建LSTM和GAN生成的种子文件的方法。作为基线，我们还考虑从用于构建LSTM和GAN模型的训练数据中随机生成种子文件。 AFL扩展了GCC编译器，它与遗传算法结合使用，用于创建种子文件。每个种子文件记录产生唯一代码路径的输入，发现时间，并用作生成未来种子文件的变异（或模糊测试）的基础。我们的扩充策略利用了这样一个事实：如果外部工具在AFL工作目录中放置其他种子文件，AFL将在后续模糊测试运行中将这些文件用作输入。</p>\n<p>为了生成我们方法的训练数据，我们在目标程序P上运行AFL一段固定的时间。对于通过P获取的每个唯一执行轨迹τ，AFL生成初始种子文件集S = {S<sub>0</sub>，…，S<sub>K</sub>}。我们使用S作为LSTM和GAN模型的训练样例，这些模型都使用Keras Chollet（2017）进行训练。</p>\n<p>我们的LSTM通过将AFL生成的种子文件语料库S连接到单个文件中进行训练，并生成最大长度为40个字符的新种子文件。 LSTM模型具有128宽的初始层，内部隐藏层和最终的softmax激活层。为了训练LSTM模型，我们使用RMS传播作为我们的优化器和分类交叉熵损失函数。该模型接收从训练语料库中采样的种子序列，并预测序列中的下一个字符。我们另外调整单独的温度参数以使从网络中的输出种子文件多样化。生成的种子文件记为S<sub>L</sub>。</p>\n<p>在我们的GAN架构中，构建了两个模型，一个生成器G，它与鉴别器D进行对比。G被优化以生成真实的输出，鉴别器D的任务是预测数据是真还是假。这种训练策略是无人监督的，特别富有表现力。生成模型G是完全连接的2层DNN，具有ReLU非线性作为内部激活和tanh输出激活。它通过随机梯度下降训练二元交叉熵损失函数。辨别模型D是3层DNN，但是第一层具有25％的丢失，接着是两个完全连接的层。它使用Adam优化器进行随机梯度下降，并将GAN过程产生的种子文件记为SG。</p>\n<p><img src=\"/2019/04/17/Faster-Fuzzing-Reinitialization-with-Deep-Neural-Models/1.jpg\" alt=\"\"></p>\n<p>另外，给定原始AFL种子文件S，我们从该训练集中随机抽取字节并产生与SG相同长度的新的随机种子文件SR。这作为基线来确定基于GAN和LSTM的种子生成的增加的时间和复杂性是否真正提供了优于随机扰动AFL状态的简单策略的优势。</p>\n<p><strong>小实验</strong>：仅种子文件（SR，SG和SL）不是最终目标。但是，我们感兴趣的是描述它们的可变性和其他属性，因为它们将在AFL重新启动时提供一组初始条件。在单个CPU内核的模糊运行中，我们生成936个用于训练初始GAN和LSTM模型的唯一代码路径。通过从/ dev / urandom绘制随机字节来执行随机种子生成。对于每种方法，我们生成200个样本，在单个CPU上重新初始化AFL，仅使用一种方法的种子文件，再运行72小时以测量对代码路径发现的影响。 LSTM和GAN模型都非常出色地进行AFL重新初始化的随机抽样。我们总结了在表1中发现新代码路径的平均时间。</p>\n<p>每个种子文件在作为ethkey的输入提供时会生成程序跟踪。具有不同长度的代码路径将在至少一个基本块或分支指令中不同。唯一的代码路径长度可以快速计算，但只能在使用AFL的模糊运行中提供测试框架所执行的唯一代码路径数量的下限。具有相同长度的两个代码路径可以由唯一跟踪产生，因此需要详细评估以确定来自种子文件执行的代码路径的真实唯一性。</p>\n<p><strong>大型实验</strong>：为了演示此扩充策略的可扩展性，我们在200个CPU内核上执行了延长的AFL运行72小时。 AFL运行中的每个核心在前10到12个小时的模糊测试后停止查找种子文件，并在49个工作日中累积了39,185个种子文件。由于AFL的内部簿记机制，已知在给定节点内生成的所有种子文件都是唯一的。但是，内容在节点之间不同的种子文件原则上可以使用相同的代码路径。通过测量每个程序跟踪（代码路径）的长度，我们可以计算仅通过计算具有唯一长度的路径而发现的唯一路径数的下限。在从节点之间移除相同的种子文件并且导致导致相同代码路径长度的种子文件之后，我们估计初始文件的802与独立工作者节点重复。删除这些重复项会导致总共38,384个唯一文件。<br>然后，我们在唯一种子文件的总语料库上训练GAN和LSTM网络，并分别从每种方法生成大约20,000个样本，以用作合成种子文件以重新初始化AFL。 GAN花了大约30分钟来训练和生成合成种子文件，而LSTM需要14个小时才能完成。</p>\n<p><img src=\"/2019/04/17/Faster-Fuzzing-Reinitialization-with-Deep-Neural-Models/2.jpg\" alt=\"\"></p>\n<p>在表2中，我们总结了与来自原始AFL的种子文件和来自该较大实验的合成生成方法相关联的程序轨迹（即，代码路径）的长度的均值和方差。与AFL相比，合成种子文件作为被测程序的输入提供时，不会导致探索深层路径。因此，我们不能简单地用生成模型取代AFL。相反，我们寻求将生成模型与AFL结合起来以提高其性能。我们从这些数据中看到，实际上，LSTM和GAN生成的种子文件在生成的代码路径的均值和方差方面不能代表分布S.这强化了使用SG和SL作为增强策略而不是直接替代AFL种子的需要。</p>\n<p>接下来，我们使用来自初始种子文件的随机字节采样（即，不对种子文件进行学习）对GAN，LSTM和随机重新初始化策略进行24小时模糊测试。表3总结了我们的结果。所有这三种策略都允许生成其他种子文件。基于GAN的方法产生的种子文件比随机方法快14.23％，比使用LSTM快60.72％。我们确实失去了30分钟的GAN训练时间，否则可以使用随机抽样方法进行模糊测试;按这段时间折扣会使代码路径速率降低11.85％。但是，我们对唯一的代码路径最感兴趣。 GAN发现了最多的种子文件，其相关的代码路径在初始模糊测试中没有找到长度，优于随机控制方法6.16％。<br>GAN发现的平均代码路径长度比随机控制长13.84％，因此GAN能够在程序中执行更深的路径。 LSTM模型的表现落后于GAN和随机抽样，并且花费了相当长的时间（14小时）进行训练。</p>\n<h1 id=\"3-结论\"><a href=\"#3-结论\" class=\"headerlink\" title=\"3 结论\"></a>3 结论</h1><p>在这项工作中，我们探索了使用深度神经模型增强随机变异测试的效用。原始AFL通过使用编译器插件将来自遗传算法的文件变异策略与程序设备相结合。当我们使用从GAN模型构建的新种子文件重新开始中间模糊运行时，我们观察到AFL性能的最大改进。尽管合成种子文件统计平均具有相似的路径长度，但是当重新启动模糊测试系统时，GAN从随机或LSTM策略中执行重新初始化。 LSTM模型在训练时间和代码路径发现时间方面都存在缺陷。这两种方法都没有使用手动分析或有关被测程序的文件格式的信息。 GAN和随机策略都改善了AFL的性能，即使程序的内部状态永远不会直接暴露。</p>\n<p>未来的工作包括对其他目标的实验，包括DARPA网络大挑战问题，开源OS网络服务，字节码解释器以及其他容易生成输入数据的系统应用程序和程序。我们还计划探索暴露被测试程序的内部状态，以便为强化学习定义奖励功能。我们设想这种内部状态可以通过以下方式公开：1）插桩AFL通过其GCC编译器插件添加到程序中，2）使用英特尔的PIN工具输出每个代码路径的长度或关于给定迹线的摘要信息3）记录程序跟踪使用诸如Mozilla的rr工具之类的重放框架来收集其他描述性统计信息。</p>\n","categories":[{"name":"论文","slug":"论文","permalink":"http://yama0xff.com/categories/论文/"},{"name":"fuzzing","slug":"论文/fuzzing","permalink":"http://yama0xff.com/categories/论文/fuzzing/"},{"name":"机器学习","slug":"论文/fuzzing/机器学习","permalink":"http://yama0xff.com/categories/论文/fuzzing/机器学习/"}],"tags":[{"name":"fuzzing","slug":"fuzzing","permalink":"http://yama0xff.com/tags/fuzzing/"},{"name":"机器学习","slug":"机器学习","permalink":"http://yama0xff.com/tags/机器学习/"},{"name":"2017年","slug":"2017年","permalink":"http://yama0xff.com/tags/2017年/"}]},{"title":"Not all bytes are equal: Neural byte sieve for fuzzing","date":"2019-04-15T12:34:54.000Z","path":"2019/04/15/Not-all-bytes-are-equal-Neural-byte-sieve-for-fuzzing/","text":"AbstractFuzzing是一种流行的动态程序分析技术，用于发现复杂软件中的漏洞。模糊测试涉及使用精心设计的恶意输入来呈现目标程序，该输入旨在导致崩溃，缓冲，内存错误和异常。以有效的方式制作恶意输入是一个难以解决的开放问题，通常产生此类输入的最佳方法是通过对预先存在的有效输入（种子文件）应用统一的随机突变。我们提出了一种学习技术，该技术使用神经网络从过去的模糊探索中学习输入文件中的模式，以指导未来的模糊探索。特别地，神经模型学习一种功能，以预测输入文件中的好（和坏）位置，以基于过去的突变和相应的代码覆盖信息执行模糊突变。我们实现了几个神经模型，包括LSTM和可以编码可变长度输入文件的序列到序列模型。我们将模型整合到最先进的AFL（American Fuzzy Lop）模糊器中，并在代码覆盖范围，独特的代码路径以及各种输入格式（包括ELF，PNG，PDF和XML）的崩溃方面显示出显着的改进。 relevant information 作者 Mohit Rajpal; William Blum; Rishabh Singh 单位 Microsoft Research 出处 CoRR杂志 原文地址 https://arxiv.org/abs/1711.04596 源码地址 https://github.com/arvindrao7589/augmented-afl-fuzz 发表时间 2017年 I 简介模糊测试[18]，[12]是最广泛使用的自动化软件测试技术之一，已成功地在复杂程序中自动发现大量安全漏洞。模糊测试的关键思想是不断生成新的恶意输入，对目标程序进行压力测试，以发现崩溃，缓冲流或异常等意外行为。通常，模糊器以一组初始种子输入文件启动，通过随机突变，约束求解或使用一组手动定义的启发法连续转换以生成恶意输入。由于输入格式可能非常复杂，因此生成恶意输入通常需要数百万个突变，因此模糊测试过程可以被视为一个巨大的搜索问题，可以识别出一组良好的突变，从而导致更高的代码覆盖率和更多的崩溃。在本文中，我们提出了一种学习技术，该技术使用神经网络从先前的模糊探索中学习输入文件中的模式，以指导未来的模糊探索。特别是，神经模型学习输入文件中不同位置的分布以应用突变，这反过来又用于指导模糊过程以探索新的唯一代码路径和崩溃。 目前的模糊测试技术大致可分为三大类：i）Blackbox模糊测试[18]，[14]，[1]，ii）Whitebox模糊测试[12]，以及iii）Greybox模糊测试[26]。Blackbox模糊器将目标程序视为黑盒子，程序内部没有内部检查。相比之下，白盒模糊器需要知道正在测试的程序的结构（可能但不一定是通过程序源代码的分析）来生成输入突变以特定地针对某些代码片段。Greybox模糊器形成了一个中间地带，他们执行有限的源代码检查，例如使用轻量级代码检测计算代码覆盖率。尽管所有模糊测试技术都有不同的优点和缺点，但基于随机突变的灰盒模糊技术已经导致AFL（American Fuzzy Lop）[26]等模糊测试，它已经成功地在复杂程序中发现了大量的实际错误。 greybox模糊器的成功很大程度上源于其简单性，允许有效的低级实现。在本文中，我们探讨是否有可能使用机器学习来学习基于先前执行输入历史和代码覆盖率信息来指导输入突变的策略。更具体地说，我们的目标是学习一种能够预测输入文件中最佳位置以执行突变的功能。我们首先在有限时间内运行传统的模糊测试技术，以获取有关哪些突变导致新代码覆盖的数据，然后使用此数据来学习一种功能，以指导进一步的输入修改以产生新的有前景的输入。虽然我们的技术适用于任何模糊测试系统，但我们在当前最先进的AFL模糊器[26]上实例化它，这是一种基于遗传算法的灰盒模糊器。AFL对一组种子输入文件执行随机变换，并维护有希望的新输入文件的输入队列，这导致执行新的代码路径。由于难以使用随机突变精确地改变输入文件，通常会丢弃数百万新生成的输入，并且只考虑其中的少数（在输入队列中）以用于将来的突变。我们的技术旨在学习如何指导这一输入生成过程，以最大限度地减少生成无意义输入所花费的时间，从而增加模糊器覆盖新代码路径的机会。 我们实现了几种神经网络架构，以学习在给定一组输入修改的情况下预测预期代码覆盖图的功能。由于输入文件可以有不同的长度，我们使用LSTM（长短期记忆）[15]和序列到序列的结构，注意[3]可以编码可变长度序列。在模糊测试时，我们使用学习函数来预测完整输入文件的热图，其对应于导致新代码覆盖的每个文件位置的突变的可能性。然后，我们使用覆盖图来确定突变位置的优先级。为了训练这些功能，我们首先在种子文件子集上运行AFL一段有限的时间，并获得突变覆盖的训练数据信息。 我们在几种输入格式（如ELF，PNG，PDF和XML）上评估我们的技术。我们观察到神经增强AFL导致ELF和PNG解析器的代码覆盖率明显高于AFL，而对于PDF和XML解析器，覆盖范围具有可比性。我们观察到神经增强AFL始终导致为ELF，PNG和XML解析器探索显着更多数量的唯一代码路径。最重要的是，对于ELF和XML解析器，神经引导AFL的观察到的崩溃次数显着增加。我们观察到PDF解析器的覆盖率改善较小，因为学习模型需要额外的时间来预测大型PDF输入文件上的覆盖图，但我们相信通过一些额外的性能工程可以提高性能。本文的主要贡献如下： 我们使用不同的神经网络架构模拟了在输入文件中模拟有前途位置的模糊问题。 我们提出了一种技术，可以有效地训练位置预测功能，然后使用学习的功能进行模糊测试。 我们在最先进的AFL模糊器中实现我们学习的神经模型，并表明它会导致更多的代码覆盖，独特的代码路径以及不同输入格式的崩溃。 II AFL背景AFL是最先进的greybox进化模糊器。AFL有一个简单的策略来制作恶意输入：尝试许多小的局部突变到种子文件，以及一些堆叠突变，同时突变种子中的许多位置。 AFL的优势在于其遗传算法。 AFL仪器在编译期间获取源代码，以便在执行期间访问代码覆盖率。在执行目标程序期间，AFL观察到变异种子诱导的代码覆盖。如果一个变异的种子诱导了一些前所未见的代码要执行，或者如果它改变了之前看到的代码片段的执行频率，那么它就被认为是有趣的。这被称为输入增益。 AFL保存突变的输入，这些输入诱导输入增益并将它们视为进一步的种子文件以进行变异。种子池的这种不断演变有助于达到许多模糊的代码路径，这需要许多迭代的小突变才能到达。这个池也经常被淘汰，以挑选最好的种子进行变异。AFL的策略在成熟的开源项目中发现了许多错误，例如Mozilla Firefox，ffmpeg，OpenSSL，clang等。简单的黑盒随机模糊器和AFL模糊器的核心算法的比较如图1所示。 模糊测试是计算密集型的。即使很小的输入增益也需要数千到数百万的随机突变才能发现。然而，并非所有突变都是平等的。文件格式及其解析器是异构的。我们认为文件头或其他关键部分的突变更有可能产生输入增益。这可能是一种情况，因为许多条件分支依赖于小的关键部分。相反，包含原始数据的部分不太可能产生输入增益，因为它们通常由紧密循环中的小块代码读取。然而，在没有大量领域专业知识的情况下手动识别复杂输入格式的这些位置是困难的。 自然的下一步是编纂定量技术，以自动识别最佳位置以进行变异。我们研究基于神经网络的机器学习技术，使用代码覆盖反馈自动识别输入文件中的有用位置。 III 框架概述我们的框架由一个模糊器和一个模型组成，它突出了输入文件中的有用位置。在运行期间，模糊器查询每个种子文件的模型，并将突变集中在突出显示的位置上。突出显示种子文件的样本如图2所示。给定以字节序列格式的输入文件，该模型注释热图函数，突出显示改变输入文件中每个位置的相对效率。由于种子文件的长度可变，该模型被定义为一系列函数。 为简单起见，我们将这一系列函数表示为简单的f，它可以将任意数量k的输入位置作为输入。该函数将输入文件中的每个位置与产生输入增益的突变概率相关联。在增强执行期间，模糊器首先在执行突变之前查询该模型，并使用所得到的热图来指导突变朝向有用位置。针对少数有用位置的潜在输入在增强执行期间被否决;这可以通过避免对不太可能提供输入增益的输入执行来节省时间。形式上，变异输入被否决，除非它满足等式2中所示的所需截止值。 这里 面上，x ⊙ x’ 是相对于种子的变异输入的差异。等式2中的关键思想是仅考虑修改许多有用字节位置的差异，如 f(x) 所示。α参数控制必须突变的“有用”字节数。热图功能f的这种表达很容易并且有效地与任何模糊系统集成，因为它在任何种子文件的开始执行一次热图计算。 为了训练模型来学习函数f，需要输入文件和相应的代码覆盖。特别是，以下元素用于训练模型： x：种子文件被模糊; b：通过在x上执行目标程序产生的代码覆盖位图; x’：变异的种子文件; b’：通过在上执行目标程序产生的代码覆盖位图。 请注意，这些数据元素是大多数greybox模糊器的第一类公民，不需要额外的工具来生成。Blackbox模糊器也可以轻松扩充，以生成目标程序的代码覆盖率信息。 虽然很明显代码覆盖率缺乏变化表明突变应用于无用位置，但没有直接的方法通过（输入，代码覆盖）元组确定有用的位置。在b,b’的一些评分上创建监督的训练数据集对的一般框架，表示为s(b,b’)，是： 对于某些实值截止值γ。给定训练数据集，目标是学习一个模型，该模型可以将输入文件x映射到差异热图x ⊙ x’，这反过来可以用于识别可能有用的位置，以集中模糊变形的注意力。 上述方法的优点在于它导致剔除无用突变，其得分低于有用突变。从数据集学习的模型将在监督设置中获得许多得分良好的(x, x ⊙ x’)对。单个种子通常与许多突变配对。为了最大限度地减少这种“一对多”关系的总损失，学习了给出x：E[(x ⊙ x’)| x ]的diff x ⊙ x’的期望值。这捕获了在某些位置移动字节的相对有用性。 原则上，s(b,b’)的有效化身具有挑战性。s(b,b’)的所需行为突出显示导致输入增益的突变，从而导致目标程序中“从未见过”的执行行为。这种对模糊测试历史的顺序依赖需要一个以先前的覆盖历史为条件的函数s，遗憾的是，这对于学习模型的方法来说是困难的。因此，我们选择 s 的直观近似： 其中bi表示位图b的第i位，|b| 表示位图的长度。表I中给出了按位严格小于函数的真值表。 按位’严格小于’评分函数突出显示未在b中执行但在 b’ 中执行的代码段。此功能奖励代码覆盖率增加。在实践中，我们发现这种评分功能可以在很多目标计划中取得良好的效果。 IV 学习增强模糊我们用于学习增强模糊测试的设计包括对AFL的修改以及用于预测模糊的最佳位置的神经网络模型。 A.增强型AFL我们为这项工作增加了AFL模糊器以利用神经模型。Augmented-AFL在模糊测试之前使用每个种子查询神经网络模型。神经模型将种子分类为字节粒度的有用和无用部分，该部分在模糊测试期间使用。在执行之前，没有针对没有有用部分的突变被否决。这种增强方法如图3所示。 AFL模糊测试策略应用以下小的局部突变。请注意，以下所有突变均在连续切片上进行。 位flips：通过一次移位[1/2/4]位来改变输入。 Byte flips：通过应用exclusve或[1/2/4]字节（0xFF）来改变输入。 算术突变：通过以[1/2/4]字节粒度添加/减去感兴趣的量来改变输入。 有趣的替换：通过以[1/2/4]字节粒度拼接“有趣”值来改变输入。 字典替换：通过用用户提供的“有趣”值替换字节来改变输入。这些长度可能超过4个字节。 上述所有突变都是小的局部变化，对于给定的种子，其变化非常大。在确定性阶段结束后，AFL开始堆叠许多这些小的局部突变，这些突变是非局部的并且相对于输入具有显着的汉明距离。AFL可以应用于均匀选择的2到128个堆叠变化之间。除了前面提到的位置突变，还可以应用以下突变： 随机字节分配：将随机值分配给随机字节。 删除字节：删除输入文件的一部分。 克隆字节：将字节附加到输入文件的一部分。 覆盖字节：覆盖输入文件的一部分。 由于AFL模糊测试的位置和上下文不敏感性，大多数突变不会产生任何输入增益。增强模糊测试的目标是提高突变的命中率。使用模型提供的注释种子，避免了不太可能提供输入增益的突变。我们使用了一种高度宽容的否决方法来拒绝不针对任何有用位置的突变。增强变异算法如图4所示。 B.神经网络架构我们现在描述用于学习覆盖热图预测功能的不同神经网络架构。回想一下，要学习的函数族具有以下格式： 该系列函数的可能编码方案是将输入“按原样”提供给底层神经网络。这将涉及将数据编码为[0, 255]范围内的实值浮点数序列。然而，这是次优的，因为二进制数据不一定代表量值，但也可以代表状态。假设每个字节表示数字量，它可以表示位掩码或其他非数字值是不正确的。因此，我们以“比特序列”格式编码字节级信息： 此函数以比特粒度确定有用性。我们通过平均每个字节的组成位值来重构给定的f’。 由于输入的长度和顺序性质不同，回归神经网络（RNN）是显而易见的选择。每个输入文件是顺序数据，最有可能由目标程序顺序解析。 RNN能够统计[21]。这对于在固定偏移处包含标题信息的文件格式进行注释很有用。RNN已经成功地用于统计机器翻译[6]，[3]，这个任务很相似，因为二进制文件格式可以被认为是一种语言。已知RNN具有较长序列的问题。由于这个原因，我们选择长期短期记忆（LSTM）作为我们的基础复发单位[15]。LSTM将循环单元的存储能力扩展到更长的序列。这是通过一个独立的记忆流程来完成的。LSTM还可以“忘记”已经失去其实用性的记忆，这使得更长的序列具有更强的表现力。回想一下，循环单元计算状态更新和输出ht,ot，如下所示。 LSTM将上述整体框架分解为以下子组件。 这里 σ = Sigmoid激活函数 W* = 学习的权重向量 b* = 学习的偏向量 忘记门ft和输入门it控制是否忘记旧存储器，以及当前输入是否值得记忆。这种相互作用允许LSTM的存储器信息通过更长的序列持续存在。 我们使用LSTM作为我们的基本重复单元来探索几种架构，以确定输入注释和神经结构。神经机器翻译的最新进展突出了一些重要的架构，如Seq2Seq [6]和Seq2Seq与注意[3]。在学习二进制格式的结构时，这些以翻译为中心的架构是否也能很好地工作？总的来说，我们评估了以下架构： LSTM：简单的单向LSTM [15]。 双向LSTM：双向LSTM，可以向前和向后看输入。 Seq2Seq：序列到序列架构[6]。 Seq2Seq + Attn：序列到序列架构，注意[3]。 双向LSTM以向后和向前的顺序查看输入。双向LSTM由两个单向LSTM组成，每个LSTM在前向和后向各一个。给定长度为n的序列，为计算时间步长t的值，前向LSTM的h(t-1)和后向LSTM的h(n-t-1)结合使用。合并函数用于合并单向LSTM的输出。合并函数可以是组合两个相似大小的向量（例如求和，乘法或连接）的许多函数之一。我们选择将sum函数用于单层双向LSTM，并将LSTM的连接函数用于两层或更多层。 我们还尝试了每个时间步长提供的层数和LSTM输入的块大小。目的是确定复杂的字节预测是多么复杂，以及更复杂的模型是否优于更简单的模型。 我们的模型每次迭代消耗k位，并且每次迭代也输出k位。我们尝试将输入序列分块为64位或128位块。我们提出的架构和可训练参数的总数详见表II。 单层双向LSTM使用求和合并功能，而双层双向LSTM使用串联功能。双层双向LSTM的第二层是单向LSTM。Seq2Seq和Seq2Seq + Attn由一个编码和一个解码层组成。编码层是双向LSTM，它使用concatenate函数合并。解码层是单向LSTM。我们没有探索单向Seq2Seq或Seq2Seq + Attn。 V 评估我们评估增强型AFL对四个目标计划的有效性，目的是评估实践中遇到的各种程序中的增强策略。选择的目标程序是readpng [22]，readelf [10]，mupdf [16]和libxml [24]。我们调查了这些程序的几个指标，主要包括代码覆盖率和输入增益。代码覆盖率和输入增益是AFL使用的第一类指标。输入增益通过输入总数来测量，这些输入会在模糊器的运行时间内产生输入增益。还测量了使用增强AFL和AFL发现的碰撞次数。 我们从大样本群体中为每个程序收集了180个随机选择的种子文件。种子文件被均匀地分成训练和测试集。为了收集用于训练模型的数据，AFL运行了24小时。以均匀的1％采样率收集输入，代码覆盖对。该收集策略在图5中突出显示。在训练之前，数据以严格小于函数的方式进行过滤，截止值为0以形成训练集。也就是说，给定一组(x,x’,b,b’)，训练数据集X Y如下构造。 模型实现是使用Keras [7]设计的，这是一个高级深度学习库。我们选择使用Tensorflow [2]作为Keras的低级后端。 训练数据的长度是异质的，并且可以包括长达200千字节的非常大的输入文件。为了缓解这些问题，超过10kB的输入数据被分段为一组10kB段。在分段之后，根据长度对数据进行分箱并填充到最近的块大小的边界。每个训练步骤包括选择与箱尺寸成比例的箱，以及在所选箱中构建元件的小批量。这些模型经过12小时的训练，以确保收敛，并在具有12千兆字节RAM的Nvidia K40M GPU上进行培训。我们使用平均绝对误差（MAE）的损失函数，并使用具有5 x 10^-5^学习率的Adam优化器[17]来训练模型。 尽管Augmented-AFL可以利用以前学过的模式来提高突变的命中率，但它并没有像基准AFL算法那样进行探索。为了抵消这种趋势，对于每个种子，增强型AFL可以以50％的概率选择使用未增强的模糊测试策略。这允许在勘探和开采之间进行良好的混合。有许多技术可以更好地实现我们希望在未来追求的探索和开发之间的平衡。为了评估学习模型，我们在种子文件的测试集上重新启动AFL和Augmented-AFL。该评估阶段进行24小时。为了最小化方差，一次运行许多AFL实例。对于AFL，16个AFL实例在16核机器上运行。对于AugmentedAFL，在16核计算机上运行8个AFL实例，其中8个核保留用于模型查询。对于大多数验证，我们使用Azure标准F16s机器，配备2.40GHz的Intel Xeon E5-2673 v3 CPU和32GB RAM。由于内存不足问题，Azure Standard D14大小的VM仅用于少数情况。Azure标准D14 VM与标准F16相同，只有112GB的RAM。验证期间未启用动态CPU频率缩放。执行24小时后，数据在许多实例上取平均值。 A.代码覆盖范围报告表III中所有程序的所有体系结构的代码覆盖率。我们可以观察到readelf和readpng程序的代码覆盖率指标的显着改进。几乎所有模型都优于这些程序的基准（基线AFL）。通常，最简单的单向模型优于其他更复杂的模型。但是，使用mupdf和libxml没有观察到代码覆盖率指标的显着改进。对于mupdf，大多数增强模型的性能都比基准测试差。唯一的例外是mupdf的Seq2Seq + Attn模型，它的性能优于基准。对于libxml，所有模型的代码覆盖率都相似。报告的代码覆盖率都集中在2.10％左右，并且在误差范围内。 B.输入增益衡量效率的第二个指标是输入增益。输入增益是在目标程序中发现的从未见过的行为的路径数。此行为的特征在于执行新的代码块，或者增加先前执行的代码块的执行频率。图6显示了每个程序的两个性能最高的模型的输入增益与时间曲线。 对于除PDF之外的所有程序，都会观察到输入增益的显着改善。这对于readpdf和readelf是预期的，因为这些程序的代码覆盖率通常会增加。但是，libxml在验证期间没有显示代码覆盖率增加。这可能意味着相同的代码部分在执行频率的变化下得到更彻底的运用。 mupdf解析器在代码覆盖率或输入增益方面没有显着改进。我们相信这显示了所提出的设计中的模型查询与执行权衡。由于典型的PDF文件大小非常大（超过100kB），因此模型查询时间会对Augmented-AFL的性能产生负面影响。在对每个种子文件进行模糊测试之前，必须对该种子文件查询模型，对于这样的大种子文件可以是几秒钟。在模糊器的运行时间内，此查询时间会对总模糊测试性能产生负面影响，因为模型查询通常会阻止执行。我们相信，模型查询的吞吐量和性能改进将提高增强型AFL技术对PDF等冗长格式的有效性。 C.崩溃测量模糊效应的最重要指标是发现的恶意输入数量，我们通过记录执行期间发现的唯一崩溃数量来衡量。我们只观察了readelf和libxml的崩溃，因此我们省略了readpng和mupdf的图。随着时间的推移发现的独特崩溃图显示在图7中的readelf和libxml中。 增强AFL优于两个程序的AFL基准。对于readelf，在24小时标记处观察到几次独特的崩溃（超过20次），而基准测试没有观察到崩溃。同样，与AFL发现大约80个独特崩溃相比，增强AFL导致在24小时标记内发现大约110个libxml的唯一崩溃。这些结果显示出相对于基线的显着改善。 这些结果显示了AFL的改进，AFL是一种遗传算法greybox fuzzer。使用机器学习来预测感兴趣的有趣位置，我们能够改善各种目标程序和文件格式的模糊测试性能。因此，我们认为机器学习引导模糊是一种很有前途的技术，可以改进greybox和blacbkox模糊器，并且可以应用类似的技术来学习将来的其他几个模糊测试参数。 VI 相关工作我们现在简要讨论一下使用机器学习技术（特别是基于神经网络的模型）来指导程序模糊测试和程序分析的一些相关工作。 a）基于语法的模糊测试的机器学习：最近开发了用于训练神经网络（LSTM）的Learn＆Fuzz [13]方法，以学习基于语法的模糊测试的输入格式的生成模型。对于复杂的输入格式（如PDF），随机改变输入会很快导致无效输入，因此通常使用基于语法的模糊测试技术来定义这些格式的输入语法。但是，手动编写语法是繁琐且容易出错的，尤其是对于复杂的输入格式。Learn＆Fuzz介绍了一种使用LSTM来学习使用字符级模型的PDF对象的语法（分布）的技术，然后可以对其进行采样以生成新的输入。我们的技术不是学习语法，而是使用神经网络来学习预测种子文件中有希望的位置以执行突变的功能。我们相信我们的技术可以补充Learn＆Fuzz，以进一步改善基于神经语法的模糊测试。 b）Fuzzing的强盗配方：通过强盗优化技术激发了我们的工作。将模糊测试和强盗优化与模糊配置调度相结合已有一些工作[25]。特别是，Woo等人 [25]将模糊化的配置选项建模为强盗问题。然而，我们的工作通过将模糊测试模拟为强盗问题来进一步采用这种方法。我们认为模糊测试是一个离散的优化问题，可以通过识别具有最高收益的字节位置子集来简化，并且最佳字节位置的识别是通过多臂匪徒方法最好地解决的问题。这种“bytesas-bandits”方法值得进一步研究，特别是，我们希望进一步阐明识别最佳字节的理论上最佳方法。 c）进化模糊测试：进化模糊测试使用执行反馈来指导未来的变异决策。沿着这个方向的一些早期工作包括DeMott等人的进化模糊系统（EFS） [8]。EFS使用遗传算法技术来演化种子池，其中定义函数被定义为诱导代码覆盖。EFS使用几种复杂的交叉方法来随时间推移种子池。与AFL相比，EFS仅使用基因交叉方法来“模糊”种子文件集。进化模糊测试的最新进展包括基于Taint的Directed Whitebox Fuzzing [11]和VUzzer [20]。基于污染的定向白盒模糊测试使用动态污点跟踪来识别可能导致危险代码段执行的种子部分。突变针对这些部分以发现错误。VUzzer采用类似的方法使用动态污点跟踪，但不会尝试识别和关注危险的代码段。VUzzer致力于提高代码覆盖率并彻底运用代码。 上述技术中的共同主题是依赖于过去执行行为的反馈循环。虽然我们的方法也包含反馈循环，但我们赞成使用神经方法来指导未来的模糊测试操作。这是新颖的，因为易于开发和集成。我们的神经引导可以使用现成的Deep Learning库快速开发方法，并且可以轻松地将其集成到现有的Greybox或Blackbox模糊器中。我们的方法具有相对较低的开销，因为简单模型具有低查询时间并且可以有效地计算覆盖图。 d）用于程序分析的神经网络：最近有几项工作用于训练神经网络以执行程序分析，例如程序修复[4]，程序优化[5]和程序综合[19]，[9]，[23] ]。这些工作学习程序的神经表示来执行各种预测任务，而在我们的工作中，我们训练神经模型代替输入文件。此外，我们的工作提出了训练神经网络的第一个应用，以学习输入文件中有前途的模糊位置。 VII 未来的工作和结论我们已经演示了一种新的基于神经的增强灰色框模糊测试。这种增强确定了在种子文件中模糊的有用位置。我们认为大多数二进制文件格式包含很小的部分，这些部分会严重影响程序的执行行为。在这些小部分上聚焦模糊是有用的，因为它们可能在目标程序中产生新颖的执行行为。 我们的增强目标是针对像AFL这样的灰盒模糊器。Greybox模糊器是完美的测试平台，因为它们为每次执行提供代码覆盖率反馈。该反馈用于训练神经网络模型以识别最有希望的模糊测试位置。我们的方法简单易用，可与大多数灰盒模糊器集成。 我们发现像LSTM这样的复现模型很适合这项任务。此任务可以被视为类似于统计机器翻译。近年来，循环模型在统计机器翻译任务上取得了巨大成功。我们使用各种目标二进制文件格式（如PDF，XML，PNG和ELF）评估模型。该模型在除PDF之外的所有目标程序上都明显优于最先进的AFL模糊器。通常，最简单的模型优于更复杂的模型。我们相信PDF上的模型性能显示了在大输入文件上查询模型的成本优势。但是，我们相信可以通过一些额外的性能工程改进PDF等大文件格式的结果。 虽然我们的结果很有希望，但还有很多途径需要进一步开展工作。我们在一个受监督的环境中训练我们当前的模型。这项工作的一个自然延伸是使用强化学习在线学习，以便随着模糊测试过程的进行，模型不断改进。我们相信通过“反馈循环模糊测试”可以大大增强模糊测试，其中过去的执行行为指导未来的突变。我们设想了一种新型的模糊器，它利用机器学习模型来指导其变异决策。Fuzzing提供了高质量结构化数据的宝库。信噪比很高。沿着这条道路的另一个可能的扩展是使用生成模型。我们的模型是限制性的，其中AFL提出的突变被否决。一种更有趣的方法是生成应用于种子文件的突变，我们计划在不久的将来考虑这些突变。","content":"<h1 id=\"Abstract\"><a href=\"#Abstract\" class=\"headerlink\" title=\"Abstract\"></a>Abstract</h1><p>Fuzzing是一种流行的动态程序分析技术，用于发现复杂软件中的漏洞。模糊测试涉及使用精心设计的恶意输入来呈现目标程序，该输入旨在导致崩溃，缓冲，内存错误和异常。以有效的方式制作恶意输入是一个难以解决的开放问题，通常产生此类输入的最佳方法是通过对预先存在的有效输入（种子文件）应用统一的随机突变。我们提出了一种学习技术，该技术使用神经网络从过去的模糊探索中学习输入文件中的模式，以指导未来的模糊探索。特别地，神经模型学习一种功能，以预测输入文件中的好（和坏）位置，以基于过去的突变和相应的代码覆盖信息执行模糊突变。我们实现了几个神经模型，包括LSTM和可以编码可变长度输入文件的序列到序列模型。我们将模型整合到最先进的AFL（American Fuzzy Lop）模糊器中，并在代码覆盖范围，独特的代码路径以及各种输入格式（包括ELF，PNG，PDF和XML）的崩溃方面显示出显着的改进。</p>\n<table>\n<thead>\n<tr>\n<th>relevant information</th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><em>作者</em></td>\n<td>Mohit Rajpal; William Blum; Rishabh Singh</td>\n</tr>\n<tr>\n<td><em>单位</em></td>\n<td>Microsoft Research</td>\n</tr>\n<tr>\n<td><em>出处</em></td>\n<td>CoRR杂志</td>\n</tr>\n<tr>\n<td><em>原文地址</em></td>\n<td><a href=\"https://arxiv.org/abs/1711.04596\" target=\"_blank\" rel=\"noopener\">https://arxiv.org/abs/1711.04596</a></td>\n</tr>\n<tr>\n<td><em>源码地址</em></td>\n<td><a href=\"https://github.com/arvindrao7589/augmented-afl-fuzz\" target=\"_blank\" rel=\"noopener\">https://github.com/arvindrao7589/augmented-afl-fuzz</a></td>\n</tr>\n<tr>\n<td><em>发表时间</em></td>\n<td>2017年</td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"I-简介\"><a href=\"#I-简介\" class=\"headerlink\" title=\"I  简介\"></a>I  简介</h1><p>模糊测试[18]，[12]是最广泛使用的自动化软件测试技术之一，已成功地在复杂程序中自动发现大量安全漏洞。模糊测试的关键思想是不断生成新的恶意输入，对目标程序进行压力测试，以发现崩溃，缓冲流或异常等意外行为。通常，模糊器以一组初始种子输入文件启动，通过随机突变，约束求解或使用一组手动定义的启发法连续转换以生成恶意输入。由于输入格式可能非常复杂，因此生成恶意输入通常需要数百万个突变，因此模糊测试过程可以被视为一个巨大的搜索问题，可以识别出一组良好的突变，从而导致更高的代码覆盖率和更多的崩溃。在本文中，我们提出了一种学习技术，该技术使用神经网络从先前的模糊探索中学习输入文件中的模式，以指导未来的模糊探索。特别是，神经模型学习输入文件中不同位置的分布以应用突变，这反过来又用于指导模糊过程以探索新的唯一代码路径和崩溃。</p>\n<p>目前的模糊测试技术大致可分为三大类：i）Blackbox模糊测试[18]，[14]，[1]，ii）Whitebox模糊测试[12]，以及iii）Greybox模糊测试[26]。Blackbox模糊器将目标程序视为黑盒子，程序内部没有内部检查。相比之下，白盒模糊器需要知道正在测试的程序的结构（可能但不一定是通过程序源代码的分析）来生成输入突变以特定地针对某些代码片段。Greybox模糊器形成了一个中间地带，他们执行有限的源代码检查，例如使用轻量级代码检测计算代码覆盖率。尽管所有模糊测试技术都有不同的优点和缺点，但基于随机突变的灰盒模糊技术已经导致AFL（American Fuzzy Lop）[26]等模糊测试，它已经成功地在复杂程序中发现了大量的实际错误。 greybox模糊器的成功很大程度上源于其简单性，允许有效的低级实现。在本文中，我们探讨是否有可能使用机器学习来学习基于先前执行输入历史和代码覆盖率信息来指导输入突变的策略。更具体地说，我们的目标是学习一种能够预测输入文件中最佳位置以执行突变的功能。我们首先在有限时间内运行传统的模糊测试技术，以获取有关哪些突变导致新代码覆盖的数据，然后使用此数据来学习一种功能，以指导进一步的输入修改以产生新的有前景的输入。虽然我们的技术适用于任何模糊测试系统，但我们在当前最先进的AFL模糊器[26]上实例化它，这是一种基于遗传算法的灰盒模糊器。AFL对一组种子输入文件执行随机变换，并维护有希望的新输入文件的输入队列，这导致执行新的代码路径。由于难以使用随机突变精确地改变输入文件，通常会丢弃数百万新生成的输入，并且只考虑其中的少数（在输入队列中）以用于将来的突变。我们的技术旨在学习如何指导这一输入生成过程，以最大限度地减少生成无意义输入所花费的时间，从而增加模糊器覆盖新代码路径的机会。</p>\n<p>我们实现了几种神经网络架构，以学习在给定一组输入修改的情况下预测预期代码覆盖图的功能。由于输入文件可以有不同的长度，我们使用LSTM（长短期记忆）[15]和序列到序列的结构，注意[3]可以编码可变长度序列。在模糊测试时，我们使用学习函数来预测完整输入文件的热图，其对应于导致新代码覆盖的每个文件位置的突变的可能性。然后，我们使用覆盖图来确定突变位置的优先级。为了训练这些功能，我们首先在种子文件子集上运行AFL一段有限的时间，并获得突变覆盖的训练数据信息。</p>\n<p>我们在几种输入格式（如ELF，PNG，PDF和XML）上评估我们的技术。我们观察到神经增强AFL导致ELF和PNG解析器的代码覆盖率明显高于AFL，而对于PDF和XML解析器，覆盖范围具有可比性。我们观察到神经增强AFL始终导致为ELF，PNG和XML解析器探索显着更多数量的唯一代码路径。最重要的是，对于ELF和XML解析器，神经引导AFL的观察到的崩溃次数显着增加。我们观察到PDF解析器的覆盖率改善较小，因为学习模型需要额外的时间来预测大型PDF输入文件上的覆盖图，但我们相信通过一些额外的性能工程可以提高性能。本文的主要贡献如下：</p>\n<ul>\n<li><p>我们使用不同的神经网络架构模拟了在输入文件中模拟有前途位置的模糊问题。</p>\n</li>\n<li><p>我们提出了一种技术，可以有效地训练位置预测功能，然后使用学习的功能进行模糊测试。</p>\n</li>\n<li><p>我们在最先进的AFL模糊器中实现我们学习的神经模型，并表明它会导致更多的代码覆盖，独特的代码路径以及不同输入格式的崩溃。</p>\n</li>\n</ul>\n<h1 id=\"II-AFL背景\"><a href=\"#II-AFL背景\" class=\"headerlink\" title=\"II AFL背景\"></a>II AFL背景</h1><p>AFL是最先进的greybox进化模糊器。AFL有一个简单的策略来制作恶意输入：尝试许多小的局部突变到种子文件，以及一些堆叠突变，同时突变种子中的许多位置。 AFL的优势在于其遗传算法。 AFL仪器在编译期间获取源代码，以便在执行期间访问代码覆盖率。在执行目标程序期间，AFL观察到变异种子诱导的代码覆盖。如果一个变异的种子诱导了一些前所未见的代码要执行，或者如果它改变了之前看到的代码片段的执行频率，那么它就被认为是有趣的。这被称为输入增益。 AFL保存突变的输入，这些输入诱导输入增益并将它们视为进一步的种子文件以进行变异。种子池的这种不断演变有助于达到许多模糊的代码路径，这需要许多迭代的小突变才能到达。这个池也经常被淘汰，以挑选最好的种子进行变异。AFL的策略在成熟的开源项目中发现了许多错误，例如Mozilla Firefox，ffmpeg，OpenSSL，clang等。简单的黑盒随机模糊器和AFL模糊器的核心算法的比较如图1所示。</p>\n<p><img src=\"/2019/04/15/Not-all-bytes-are-equal-Neural-byte-sieve-for-fuzzing/1.jpg\" alt=\"\"></p>\n<p>模糊测试是计算密集型的。即使很小的输入增益也需要数千到数百万的随机突变才能发现。然而，并非所有突变都是平等的。文件格式及其解析器是异构的。我们认为文件头或其他关键部分的突变更有可能产生输入增益。这可能是一种情况，因为许多条件分支依赖于小的关键部分。相反，包含原始数据的部分不太可能产生输入增益，因为它们通常由紧密循环中的小块代码读取。然而，在没有大量领域专业知识的情况下手动识别复杂输入格式的这些位置是困难的。</p>\n<p>自然的下一步是编纂定量技术，以自动识别最佳位置以进行变异。我们研究基于神经网络的机器学习技术，使用代码覆盖反馈自动识别输入文件中的有用位置。</p>\n<h1 id=\"III-框架概述\"><a href=\"#III-框架概述\" class=\"headerlink\" title=\"III 框架概述\"></a>III 框架概述</h1><p>我们的框架由一个模糊器和一个模型组成，它突出了输入文件中的有用位置。在运行期间，模糊器查询每个种子文件的模型，并将突变集中在突出显示的位置上。突出显示种子文件的样本如图2所示。给定以字节序列格式的输入文件，该模型注释热图函数，突出显示改变输入文件中每个位置的相对效率。由于种子文件的长度可变，该模型被定义为一系列函数。</p>\n<p><img src=\"/2019/04/15/Not-all-bytes-are-equal-Neural-byte-sieve-for-fuzzing/2.jpg\" alt=\"\"></p>\n<p><img src=\"/2019/04/15/Not-all-bytes-are-equal-Neural-byte-sieve-for-fuzzing/3.jpg\" alt=\"\"></p>\n<p>为简单起见，我们将这一系列函数表示为简单的f，它可以将任意数量k的输入位置作为输入。该函数将输入文件中的每个位置与产生输入增益的突变概率相关联。在增强执行期间，模糊器首先在执行突变之前查询该模型，并使用所得到的热图来指导突变朝向有用位置。针对少数有用位置的潜在输入在增强执行期间被否决;这可以通过避免对不太可能提供输入增益的输入执行来节省时间。形式上，变异输入被否决，除非它满足等式2中所示的所需截止值。</p>\n<p><img src=\"/2019/04/15/Not-all-bytes-are-equal-Neural-byte-sieve-for-fuzzing/4.jpg\" alt=\"\"></p>\n<p>这里</p>\n<p><img src=\"/2019/04/15/Not-all-bytes-are-equal-Neural-byte-sieve-for-fuzzing/5.jpg\" alt=\"\"></p>\n<p>面上，x ⊙ x’ 是相对于种子的变异输入的差异。等式2中的关键思想是仅考虑修改许多有用字节位置的差异，如 f(x) 所示。α参数控制必须突变的“有用”字节数。热图功能f的这种表达很容易并且有效地与任何模糊系统集成，因为它在任何种子文件的开始执行一次热图计算。</p>\n<p>为了训练模型来学习函数f，需要输入文件和相应的代码覆盖。特别是，以下元素用于训练模型：</p>\n<ul>\n<li><p>x：种子文件被模糊; </p>\n</li>\n<li><p>b：通过在x上执行目标程序产生的代码覆盖位图; </p>\n</li>\n<li>x’：变异的种子文件; </li>\n<li>b’：通过在上执行目标程序产生的代码覆盖位图。</li>\n</ul>\n<p>请注意，这些数据元素是大多数greybox模糊器的第一类公民，不需要额外的工具来生成。Blackbox模糊器也可以轻松扩充，以生成目标程序的代码覆盖率信息。</p>\n<p>虽然很明显代码覆盖率缺乏变化表明突变应用于无用位置，但没有直接的方法通过（输入，代码覆盖）元组确定有用的位置。在b,b’的一些评分上创建监督的训练数据集对的一般框架，表示为s(b,b’)，是：</p>\n<p><img src=\"/2019/04/15/Not-all-bytes-are-equal-Neural-byte-sieve-for-fuzzing/6.jpg\" alt=\"\"></p>\n<p>对于某些实值截止值γ。给定训练数据集，目标是学习一个模型，该模型可以将输入文件x映射到差异热图x ⊙ x’，这反过来可以用于识别可能有用的位置，以集中模糊变形的注意力。</p>\n<p>上述方法的优点在于它导致剔除无用突变，其得分低于有用突变。从数据集学习的模型将在监督设置中获得许多得分良好的(x, x ⊙ x’)对。单个种子通常与许多突变配对。为了最大限度地减少这种“一对多”关系的总损失，学习了给出x：E[(x ⊙ x’)| x ]的diff  x ⊙ x’的期望值。这捕获了在某些位置移动字节的相对有用性。</p>\n<p>原则上，s(b,b’)的有效化身具有挑战性。s(b,b’)的所需行为突出显示导致输入增益的突变，从而导致目标程序中“从未见过”的执行行为。这种对模糊测试历史的顺序依赖需要一个以先前的覆盖历史为条件的函数s<em>，遗憾的是，这对于学习模型的方法来说是困难的。因此，我们选择 s </em>的直观近似：</p>\n<p><img src=\"/2019/04/15/Not-all-bytes-are-equal-Neural-byte-sieve-for-fuzzing/7.jpg\" alt=\"\"></p>\n<p>其中b<sub>i</sub>表示位图b的第i位，|b| 表示位图的长度。表I中给出了按位严格小于函数的真值表。</p>\n<p><img src=\"/2019/04/15/Not-all-bytes-are-equal-Neural-byte-sieve-for-fuzzing/8.jpg\" alt=\"\"></p>\n<p>按位’严格小于’评分函数突出显示未在b中执行但在 b’ 中执行的代码段。此功能奖励代码覆盖率增加。在实践中，我们发现这种评分功能可以在很多目标计划中取得良好的效果。</p>\n<h1 id=\"IV-学习增强模糊\"><a href=\"#IV-学习增强模糊\" class=\"headerlink\" title=\"IV 学习增强模糊\"></a>IV 学习增强模糊</h1><p>我们用于学习增强模糊测试的设计包括对AFL的修改以及用于预测模糊的最佳位置的神经网络模型。</p>\n<h2 id=\"A-增强型AFL\"><a href=\"#A-增强型AFL\" class=\"headerlink\" title=\"A.增强型AFL\"></a>A.增强型AFL</h2><p>我们为这项工作增加了AFL模糊器以利用神经模型。Augmented-AFL在模糊测试之前使用每个种子查询神经网络模型。神经模型将种子分类为字节粒度的有用和无用部分，该部分在模糊测试期间使用。在执行之前，没有针对没有有用部分的突变被否决。这种增强方法如图3所示。</p>\n<p><img src=\"/2019/04/15/Not-all-bytes-are-equal-Neural-byte-sieve-for-fuzzing/9.jpg\" alt=\"\"></p>\n<p>AFL模糊测试策略应用以下小的局部突变。请注意，以下所有突变均在连续切片上进行。</p>\n<ul>\n<li><p>位flips：通过一次移位[1/2/4]位来改变输入。</p>\n</li>\n<li><p>Byte flips：通过应用exclusve或[1/2/4]字节（0xFF）来改变输入。</p>\n</li>\n<li><p>算术突变：通过以[1/2/4]字节粒度添加/减去感兴趣的量来改变输入。</p>\n</li>\n<li><p>有趣的替换：通过以[1/2/4]字节粒度拼接“有趣”值来改变输入。</p>\n</li>\n<li><p>字典替换：通过用用户提供的“有趣”值替换字节来改变输入。这些长度可能超过4个字节。</p>\n</li>\n</ul>\n<p>上述所有突变都是小的局部变化，对于给定的种子，其变化非常大。在确定性阶段结束后，AFL开始堆叠许多这些小的局部突变，这些突变是非局部的并且相对于输入具有显着的汉明距离。AFL可以应用于均匀选择的2到128个堆叠变化之间。除了前面提到的位置突变，还可以应用以下突变：</p>\n<ul>\n<li><p>随机字节分配：将随机值分配给随机字节。</p>\n</li>\n<li><p>删除字节：删除输入文件的一部分。</p>\n</li>\n<li><p>克隆字节：将字节附加到输入文件的一部分。</p>\n</li>\n<li><p>覆盖字节：覆盖输入文件的一部分。</p>\n</li>\n</ul>\n<p>由于AFL模糊测试的位置和上下文不敏感性，大多数突变不会产生任何输入增益。增强模糊测试的目标是提高突变的命中率。使用模型提供的注释种子，避免了不太可能提供输入增益的突变。我们使用了一种高度宽容的否决方法来拒绝不针对任何有用位置的突变。增强变异算法如图4所示。</p>\n<p><img src=\"/2019/04/15/Not-all-bytes-are-equal-Neural-byte-sieve-for-fuzzing/10.jpg\" alt=\"\"></p>\n<h2 id=\"B-神经网络架构\"><a href=\"#B-神经网络架构\" class=\"headerlink\" title=\"B.神经网络架构\"></a>B.神经网络架构</h2><p>我们现在描述用于学习覆盖热图预测功能的不同神经网络架构。回想一下，要学习的函数族具有以下格式：</p>\n<p><img src=\"/2019/04/15/Not-all-bytes-are-equal-Neural-byte-sieve-for-fuzzing/11.jpg\" alt=\"\"></p>\n<p>该系列函数的可能编码方案是将输入“按原样”提供给底层神经网络。这将涉及将数据编码为[0, 255]范围内的实值浮点数序列。然而，这是次优的，因为二进制数据不一定代表量值，但也可以代表状态。假设每个字节表示数字量，它可以表示位掩码或其他非数字值是不正确的。因此，我们以“比特序列”格式编码字节级信息：</p>\n<p><img src=\"/2019/04/15/Not-all-bytes-are-equal-Neural-byte-sieve-for-fuzzing/12.jpg\" alt=\"\"></p>\n<p>此函数以比特粒度确定有用性。我们通过平均每个字节的组成位值来重构给定的f’。</p>\n<p>由于输入的长度和顺序性质不同，回归神经网络（RNN）是显而易见的选择。每个输入文件是顺序数据，最有可能由目标程序顺序解析。 RNN能够统计[21]。这对于在固定偏移处包含标题信息的文件格式进行注释很有用。RNN已经成功地用于统计机器翻译[6]，[3]，这个任务很相似，因为二进制文件格式可以被认为是一种语言。已知RNN具有较长序列的问题。由于这个原因，我们选择长期短期记忆（LSTM）作为我们的基础复发单位[15]。LSTM将循环单元的存储能力扩展到更长的序列。这是通过一个独立的记忆流程来完成的。LSTM还可以“忘记”已经失去其实用性的记忆，这使得更长的序列具有更强的表现力。回想一下，循环单元计算状态更新和输出h<sub>t</sub>,o<sub>t</sub>，如下所示。</p>\n<p><img src=\"/2019/04/15/Not-all-bytes-are-equal-Neural-byte-sieve-for-fuzzing/13.jpg\" alt=\"\"></p>\n<p>LSTM将上述整体框架分解为以下子组件。</p>\n<p><img src=\"/2019/04/15/Not-all-bytes-are-equal-Neural-byte-sieve-for-fuzzing/14.jpg\" alt=\"\"></p>\n<p>这里</p>\n<ul>\n<li><p>σ = Sigmoid激活函数</p>\n</li>\n<li><p>W<sub>*</sub> = 学习的权重向量</p>\n</li>\n<li><p>b<sub>*</sub> = 学习的偏向量</p>\n</li>\n</ul>\n<p>忘记门f<sub>t</sub>和输入门i<sub>t</sub>控制是否忘记旧存储器，以及当前输入是否值得记忆。这种相互作用允许LSTM的存储器信息通过更长的序列持续存在。</p>\n<p>我们使用LSTM作为我们的基本重复单元来探索几种架构，以确定输入注释和神经结构。神经机器翻译的最新进展突出了一些重要的架构，如Seq2Seq [6]和Seq2Seq与注意[3]。在学习二进制格式的结构时，这些以翻译为中心的架构是否也能很好地工作？总的来说，我们评估了以下架构：</p>\n<ul>\n<li><p>LSTM：简单的单向LSTM [15]。</p>\n</li>\n<li><p>双向LSTM：双向LSTM，可以向前和向后看输入。</p>\n</li>\n<li><p>Seq2Seq：序列到序列架构[6]。</p>\n</li>\n<li><p>Seq2Seq + Attn：序列到序列架构，注意[3]。</p>\n</li>\n</ul>\n<p>双向LSTM以向后和向前的顺序查看输入。双向LSTM由两个单向LSTM组成，每个LSTM在前向和后向各一个。给定长度为n的序列，为计算时间步长t的值，前向LSTM的h<sub>(t-1)</sub>和后向LSTM的h<sub>(n-t-1)</sub>结合使用。合并函数用于合并单向LSTM的输出。合并函数可以是组合两个相似大小的向量（例如求和，乘法或连接）的许多函数之一。我们选择将sum函数用于单层双向LSTM，并将LSTM的连接函数用于两层或更多层。</p>\n<p>我们还尝试了每个时间步长提供的层数和LSTM输入的块大小。目的是确定复杂的字节预测是多么复杂，以及更复杂的模型是否优于更简单的模型。</p>\n<p>我们的模型每次迭代消耗k位，并且每次迭代也输出k位。我们尝试将输入序列分块为64位或128位块。我们提出的架构和可训练参数的总数详见表II。</p>\n<p><img src=\"/2019/04/15/Not-all-bytes-are-equal-Neural-byte-sieve-for-fuzzing/15.jpg\" alt=\"\"></p>\n<p>单层双向LSTM使用求和合并功能，而双层双向LSTM使用串联功能。双层双向LSTM的第二层是单向LSTM。Seq2Seq和Seq2Seq + Attn由一个编码和一个解码层组成。编码层是双向LSTM，它使用concatenate函数合并。解码层是单向LSTM。我们没有探索单向Seq2Seq或Seq2Seq + Attn。</p>\n<h1 id=\"V-评估\"><a href=\"#V-评估\" class=\"headerlink\" title=\"V 评估\"></a>V 评估</h1><p>我们评估增强型AFL对四个目标计划的有效性，目的是评估实践中遇到的各种程序中的增强策略。选择的目标程序是readpng [22]，readelf [10]，mupdf [16]和libxml [24]。我们调查了这些程序的几个指标，主要包括代码覆盖率和输入增益。代码覆盖率和输入增益是AFL使用的第一类指标。输入增益通过输入总数来测量，这些输入会在模糊器的运行时间内产生输入增益。还测量了使用增强AFL和AFL发现的碰撞次数。</p>\n<p><img src=\"/2019/04/15/Not-all-bytes-are-equal-Neural-byte-sieve-for-fuzzing/16.jpg\" alt=\"\"></p>\n<p>我们从大样本群体中为每个程序收集了180个随机选择的种子文件。种子文件被均匀地分成训练和测试集。为了收集用于训练模型的数据，AFL运行了24小时。以均匀的1％采样率收集输入，代码覆盖对。该收集策略在图5中突出显示。在训练之前，数据以严格小于函数的方式进行过滤，截止值为0以形成训练集。也就是说，给定一组(x,x’,b,b’)，训练数据集X Y如下构造。</p>\n<p><img src=\"/2019/04/15/Not-all-bytes-are-equal-Neural-byte-sieve-for-fuzzing/17.jpg\" alt=\"\"></p>\n<p>模型实现是使用Keras [7]设计的，这是一个高级深度学习库。我们选择使用Tensorflow [2]作为Keras的低级后端。</p>\n<p>训练数据的长度是异质的，并且可以包括长达200千字节的非常大的输入文件。为了缓解这些问题，超过10kB的输入数据被分段为一组10kB段。在分段之后，根据长度对数据进行分箱并填充到最近的块大小的边界。每个训练步骤包括选择与箱尺寸成比例的箱，以及在所选箱中构建元件的小批量。这些模型经过12小时的训练，以确保收敛，并在具有12千兆字节RAM的Nvidia K40M GPU上进行培训。我们使用平均绝对误差（MAE）的损失函数，并使用具有5 x 10^-5^学习率的Adam优化器[17]来训练模型。</p>\n<p>尽管Augmented-AFL可以利用以前学过的模式来提高突变的命中率，但它并没有像基准AFL算法那样进行探索。为了抵消这种趋势，对于每个种子，增强型AFL可以以50％的概率选择使用未增强的模糊测试策略。这允许在勘探和开采之间进行良好的混合。有许多技术可以更好地实现我们希望在未来追求的探索和开发之间的平衡。为了评估学习模型，我们在种子文件的测试集上重新启动AFL和Augmented-AFL。该评估阶段进行24小时。为了最小化方差，一次运行许多AFL实例。对于AFL，16个AFL实例在16核机器上运行。对于AugmentedAFL，在16核计算机上运行8个AFL实例，其中8个核保留用于模型查询。对于大多数验证，我们使用Azure标准F16s机器，配备2.40GHz的Intel Xeon E5-2673 v3 CPU和32GB RAM。由于内存不足问题，Azure Standard D14大小的VM仅用于少数情况。Azure标准D14 VM与标准F16相同，只有112GB的RAM。验证期间未启用动态CPU频率缩放。执行24小时后，数据在许多实例上取平均值。</p>\n<h2 id=\"A-代码覆盖范围\"><a href=\"#A-代码覆盖范围\" class=\"headerlink\" title=\"A.代码覆盖范围\"></a>A.代码覆盖范围</h2><p>报告表III中所有程序的所有体系结构的代码覆盖率。我们可以观察到readelf和readpng程序的代码覆盖率指标的显着改进。几乎所有模型都优于这些程序的基准（基线AFL）。通常，最简单的单向模型优于其他更复杂的模型。但是，使用mupdf和libxml没有观察到代码覆盖率指标的显着改进。对于mupdf，大多数增强模型的性能都比基准测试差。唯一的例外是mupdf的Seq2Seq + Attn模型，它的性能优于基准。对于libxml，所有模型的代码覆盖率都相似。报告的代码覆盖率都集中在2.10％左右，并且在误差范围内。</p>\n<p><img src=\"/2019/04/15/Not-all-bytes-are-equal-Neural-byte-sieve-for-fuzzing/18.jpg\" alt=\"\"></p>\n<h2 id=\"B-输入增益\"><a href=\"#B-输入增益\" class=\"headerlink\" title=\"B.输入增益\"></a>B.输入增益</h2><p>衡量效率的第二个指标是输入增益。输入增益是在目标程序中发现的从未见过的行为的路径数。此行为的特征在于执行新的代码块，或者增加先前执行的代码块的执行频率。图6显示了每个程序的两个性能最高的模型的输入增益与时间曲线。</p>\n<p><img src=\"/2019/04/15/Not-all-bytes-are-equal-Neural-byte-sieve-for-fuzzing/19.jpg\" alt=\"\"></p>\n<p>对于除PDF之外的所有程序，都会观察到输入增益的显着改善。这对于readpdf和readelf是预期的，因为这些程序的代码覆盖率通常会增加。但是，libxml在验证期间没有显示代码覆盖率增加。这可能意味着相同的代码部分在执行频率的变化下得到更彻底的运用。</p>\n<p>mupdf解析器在代码覆盖率或输入增益方面没有显着改进。我们相信这显示了所提出的设计中的模型查询与执行权衡。由于典型的PDF文件大小非常大（超过100kB），因此模型查询时间会对Augmented-AFL的性能产生负面影响。在对每个种子文件进行模糊测试之前，必须对该种子文件查询模型，对于这样的大种子文件可以是几秒钟。在模糊器的运行时间内，此查询时间会对总模糊测试性能产生负面影响，因为模型查询通常会阻止执行。我们相信，模型查询的吞吐量和性能改进将提高增强型AFL技术对PDF等冗长格式的有效性。</p>\n<h2 id=\"C-崩溃\"><a href=\"#C-崩溃\" class=\"headerlink\" title=\"C.崩溃\"></a>C.崩溃</h2><p>测量模糊效应的最重要指标是发现的恶意输入数量，我们通过记录执行期间发现的唯一崩溃数量来衡量。我们只观察了readelf和libxml的崩溃，因此我们省略了readpng和mupdf的图。随着时间的推移发现的独特崩溃图显示在图7中的readelf和libxml中。</p>\n<p>增强AFL优于两个程序的AFL基准。对于readelf，在24小时标记处观察到几次独特的崩溃（超过20次），而基准测试没有观察到崩溃。同样，与AFL发现大约80个独特崩溃相比，增强AFL导致在24小时标记内发现大约110个libxml的唯一崩溃。这些结果显示出相对于基线的显着改善。</p>\n<p><img src=\"/2019/04/15/Not-all-bytes-are-equal-Neural-byte-sieve-for-fuzzing/20.jpg\" alt=\"\"></p>\n<p>这些结果显示了AFL的改进，AFL是一种遗传算法greybox fuzzer。使用机器学习来预测感兴趣的有趣位置，我们能够改善各种目标程序和文件格式的模糊测试性能。因此，我们认为机器学习引导模糊是一种很有前途的技术，可以改进greybox和blacbkox模糊器，并且可以应用类似的技术来学习将来的其他几个模糊测试参数。</p>\n<h1 id=\"VI-相关工作\"><a href=\"#VI-相关工作\" class=\"headerlink\" title=\"VI 相关工作\"></a>VI 相关工作</h1><p>我们现在简要讨论一下使用机器学习技术（特别是基于神经网络的模型）来指导程序模糊测试和程序分析的一些相关工作。</p>\n<p><strong>a）基于语法的模糊测试的机器学习</strong>：最近开发了用于训练神经网络（LSTM）的Learn＆Fuzz [13]方法，以学习基于语法的模糊测试的输入格式的生成模型。对于复杂的输入格式（如PDF），随机改变输入会很快导致无效输入，因此通常使用基于语法的模糊测试技术来定义这些格式的输入语法。但是，手动编写语法是繁琐且容易出错的，尤其是对于复杂的输入格式。Learn＆Fuzz介绍了一种使用LSTM来学习使用字符级模型的PDF对象的语法（分布）的技术，然后可以对其进行采样以生成新的输入。我们的技术不是学习语法，而是使用神经网络来学习预测种子文件中有希望的位置以执行突变的功能。我们相信我们的技术可以补充Learn＆Fuzz，以进一步改善基于神经语法的模糊测试。</p>\n<p><strong>b）Fuzzing的强盗配方</strong>：通过强盗优化技术激发了我们的工作。将模糊测试和强盗优化与模糊配置调度相结合已有一些工作[25]。特别是，Woo等人 [25]将模糊化的配置选项建模为强盗问题。然而，我们的工作通过将模糊测试模拟为强盗问题来进一步采用这种方法。我们认为模糊测试是一个离散的优化问题，可以通过识别具有最高收益的字节位置子集来简化，并且最佳字节位置的识别是通过多臂匪徒方法最好地解决的问题。这种“bytesas-bandits”方法值得进一步研究，特别是，我们希望进一步阐明识别最佳字节的理论上最佳方法。</p>\n<p><strong>c）进化模糊测试</strong>：进化模糊测试使用执行反馈来指导未来的变异决策。沿着这个方向的一些早期工作包括DeMott等人的进化模糊系统（EFS） [8]。EFS使用遗传算法技术来演化种子池，其中定义函数被定义为诱导代码覆盖。EFS使用几种复杂的交叉方法来随时间推移种子池。与AFL相比，EFS仅使用基因交叉方法来“模糊”种子文件集。进化模糊测试的最新进展包括基于Taint的Directed Whitebox Fuzzing [11]和VUzzer [20]。基于污染的定向白盒模糊测试使用动态污点跟踪来识别可能导致危险代码段执行的种子部分。突变针对这些部分以发现错误。VUzzer采用类似的方法使用动态污点跟踪，但不会尝试识别和关注危险的代码段。VUzzer致力于提高代码覆盖率并彻底运用代码。</p>\n<p>上述技术中的共同主题是依赖于过去执行行为的反馈循环。虽然我们的方法也包含反馈循环，但我们赞成使用神经方法来指导未来的模糊测试操作。这是新颖的，因为易于开发和集成。我们的神经引导可以使用现成的Deep Learning库快速开发方法，并且可以轻松地将其集成到现有的Greybox或Blackbox模糊器中。我们的方法具有相对较低的开销，因为简单模型具有低查询时间并且可以有效地计算覆盖图。</p>\n<p><strong>d）用于程序分析的神经网络</strong>：最近有几项工作用于训练神经网络以执行程序分析，例如程序修复[4]，程序优化[5]和程序综合[19]，[9]，[23] ]。这些工作学习程序的神经表示来执行各种预测任务，而在我们的工作中，我们训练神经模型代替输入文件。此外，我们的工作提出了训练神经网络的第一个应用，以学习输入文件中有前途的模糊位置。</p>\n<h1 id=\"VII-未来的工作和结论\"><a href=\"#VII-未来的工作和结论\" class=\"headerlink\" title=\"VII  未来的工作和结论\"></a>VII  未来的工作和结论</h1><p>我们已经演示了一种新的基于神经的增强灰色框模糊测试。这种增强确定了在种子文件中模糊的有用位置。我们认为大多数二进制文件格式包含很小的部分，这些部分会严重影响程序的执行行为。在这些小部分上聚焦模糊是有用的，因为它们可能在目标程序中产生新颖的执行行为。</p>\n<p>我们的增强目标是针对像AFL这样的灰盒模糊器。Greybox模糊器是完美的测试平台，因为它们为每次执行提供代码覆盖率反馈。该反馈用于训练神经网络模型以识别最有希望的模糊测试位置。我们的方法简单易用，可与大多数灰盒模糊器集成。</p>\n<p>我们发现像LSTM这样的复现模型很适合这项任务。此任务可以被视为类似于统计机器翻译。近年来，循环模型在统计机器翻译任务上取得了巨大成功。我们使用各种目标二进制文件格式（如PDF，XML，PNG和ELF）评估模型。该模型在除PDF之外的所有目标程序上都明显优于最先进的AFL模糊器。通常，最简单的模型优于更复杂的模型。我们相信PDF上的模型性能显示了在大输入文件上查询模型的成本优势。但是，我们相信可以通过一些额外的性能工程改进PDF等大文件格式的结果。</p>\n<p>虽然我们的结果很有希望，但还有很多途径需要进一步开展工作。我们在一个受监督的环境中训练我们当前的模型。这项工作的一个自然延伸是使用强化学习在线学习，以便随着模糊测试过程的进行，模型不断改进。我们相信通过“反馈循环模糊测试”可以大大增强模糊测试，其中过去的执行行为指导未来的突变。我们设想了一种新型的模糊器，它利用机器学习模型来指导其变异决策。Fuzzing提供了高质量结构化数据的宝库。信噪比很高。沿着这条道路的另一个可能的扩展是使用生成模型。我们的模型是限制性的，其中AFL提出的突变被否决。一种更有趣的方法是生成应用于种子文件的突变，我们计划在不久的将来考虑这些突变。</p>\n","categories":[{"name":"论文","slug":"论文","permalink":"http://yama0xff.com/categories/论文/"},{"name":"fuzzing","slug":"论文/fuzzing","permalink":"http://yama0xff.com/categories/论文/fuzzing/"},{"name":"机器学习","slug":"论文/fuzzing/机器学习","permalink":"http://yama0xff.com/categories/论文/fuzzing/机器学习/"}],"tags":[{"name":"fuzzing","slug":"fuzzing","permalink":"http://yama0xff.com/tags/fuzzing/"},{"name":"机器学习","slug":"机器学习","permalink":"http://yama0xff.com/tags/机器学习/"},{"name":"2017年","slug":"2017年","permalink":"http://yama0xff.com/tags/2017年/"}]},{"title":"Recurrent Neural Networks for Fuzz Testing Web Browsers","date":"2019-04-15T01:40:54.000Z","path":"2019/04/15/Recurrent-Neural-Networks-for-Fuzz-Testing-Web-Browsers/","text":"Abstract基于生成的模糊测试是一种软件测试方法，能够发现软件中不同类型的错误和漏洞。然而，已知设计和微调经典模糊器以实现可接受的覆盖是非常耗时的，即使对于小规模软件系统也是如此。为了解决这个问题，我们研究了一种基于机器学习的模糊测试方法，其中我们概述了一系列基于递归神经网络（RNN）的测试用例生成器，并使用最少的人工微调来训练那些现成的数据集。与先前的工作相比，所提出的生成器不依赖于启发式采样策略，而是依赖于预测分布的原理采样。我们提供详细的分析，以在具有挑战性的Web浏览器测试场景中演示所提出的生成器的特征和功效。实证结果表明，基于RNN的发生器能够提供比基于突变的方法更好的覆盖，并且能够发现经典模糊器未发现的路径。我们的研究结果补充了其他领域的研究结果，表明使用RNN进行基于代数的模糊测试是通过使用合适的模型选择/分析程序来获得更好软件质量的可行途径 Keywords: Software security, fuzz testing, browser security relevant information 作者 Martin Sablotny, Bjørn Sand Jensen, Chris W. Johnson 单位 University of Glasgow, School of Computing Science, Glasgow, Scotland 出处 ICISC 原文地址 https://arxiv.org/abs/1812.04852 源码地址 https://github.com/susperius/icisc_rnnfuzz 发表时间 2018 1. 简介最近，模糊测试在理论和实际软件测试中越来越受欢迎。这主要归因于在复杂软件系统中触发非预期行为的明显能力，例如，美国模糊Lop（AFL）[28]发现的错误摘要，并通过在微软和谷歌等软件公司中使用模糊测试进一步证明（例如通过他们的开源工具ClusterFuzz [12]），它在许多不同的领域显示了成功和适用性。然而，将一组输入示例上的变异与进化方法相结合的标准方法有其局限性，即增加关键词的必要性和对句法规则的遵从性（例如，在本工作中考虑的HTML）。这些问题可以通过基于生成的模糊器解决，这些模糊器能够遵守这些规则，使用正确的关键字并生成新的输入。传统上，开发基于生成的模糊器所需的时间取决于输入规范的复杂性。例如，为网络协议开发生成器的时间较少，与使用各种字段和状态实现文件传输协议（FTP）[16]相比，它具有三个不同可能值的单个字段。此外，有必要在引入的错误和总体正确性之间找到适当的平衡，以触发导致意外行为的代码路径。 开发基于生成的模糊器的主要瓶颈是需要严格理解和实现输入文件格式。因此，必须仔细研究潜在的复杂输入规范，将其转换为测试用例生成器，然后需要对其进行微调，以便在测试用例中找到正确性和引入错误之间的正确平衡。这种隐式优化过程通过生成在给定规范的某些区域中偏离的测试用例来寻求最大化代码覆盖，因此能够执行不同的低级执行路径。因此，很明显，可以自动推导或减少输入规范的方法将能够通过更快地部署基于生成的模糊测试技术来加速软件测试。这可能会导致软件安全性和稳定性的提高。 学习输入规范（例如语法规则）显然不是微不足道的，特别是由于可以应用输入规范的长时间依赖性。这些依赖性对特定位置的可能输出具有直接影响，因此必须通过学习算法捕获以产生规范附加输出。然而，生成机器学习模型的最新进展（[26]，[3]，[6]，[2]）已经证明了机器学习模型如何用于从实例中学习复杂的规则和分布，并从获得的知识中生成新的例子。 Godefroid等人的模糊测试已经对这些进行了改进[11]。他们演示了如何使用深度神经网络生成PDF对象，这些对象被用作渲染引擎的输入。这些输入文件能够在渲染引擎中触发新指令。然而，他们关注的是学习正确的输入结构和模糊测试之间的紧张关系，换句话说，他们在遵守学习规范和偏离规范之间寻求平衡。他们没有提供对学习过程本身的分析，也没有对基于简单变异的基线进行比较。此外，他们没有提供有关基线与其拟议抽样策略之间重叠的任何信息。为了在模糊测试中使用深度学习模型，重要的是要看它是否值得探索和训练。因此，有必要将其与易于实现的方法进行比较，如简单的变异算法。对不同方法之间现有重叠的分析还可以更深入地了解模型和采样选择，因为在测试期间触发尽可能多的新执行路径以找到触发意外行为的路径非常重要。 在这项工作中，我们研究了如何训练具有不同类型细胞的递归神经网络（RNN）并将其用作HTML模糊器。模型在基于生成的HTML-fuzzer创建的数据集上进行训练，这使我们能够快速，系统地调整数据集大小和复杂性。我们使用这些模型从生成的概率分布中生成新的HTML标记，这些标记用于形成测试用例。这些是用Firefox [19]执行的，用于收集他们的代码覆盖率数据，并与来自数据集的HTML标记和简单变异数据集生成的基线进行比较。因此，本文的贡献包括： 用于训练和评估具有不同类型细胞的递归神经网络的系统且稳健的方法，用于HTML模糊测试。 用于模型选择的过程和度量，并比较机器学习模糊器与标准和基于普通突变的方法（包括基于相似性的分析） 对Web浏览器进行广泛的实证评估，证明学习的模糊测试器能够胜过标准测试方法。 通过Github 开源了实现代码和数据。 2.背景2.1模糊测试模糊测试是一种动态软件测试方法，因此动态意味着被测软件实际上是与静态分析相对应的。模糊测试的目标是引发在早期测试阶段未检测到的意外行为，因此测试中的软件使用由所谓的模糊器创建的输入执行。这些输入不完全符合基础输入规范，以便找到导致触发意外行为的状态的路径。我们对非预期行为采用广义定义，这使其适用于各种软件和设备[27]。例如，在模糊测试桌面软件期间，意外行为可能是正在运行的进程的终止，甚至可能是对进程进行控制的可能性。在Web应用程序测试期间，非预期行为可能被定义为信息泄漏或规避访问限制，这两种情况都可能由于SQL注入漏洞而发生，其中任意输入用作有效的SQL语句。 正如这些例子所强调的那样，如果可以为攻击者提供优势，那么意外行为就会变得更加严重。这里的优势可能意味着从访问受限信息到接管设备的控制。为了找到这些漏洞，使用了模糊测试。模糊测试期间的一般工作流程如图1所示。测试本身分为两部分，第一部分是测试用例生成，第二部分是行为分析。通常，在模糊测试期间创建测试用例可以分为两类：基于突变和基于生成[27]，[8]和[20]。基于突变的模糊测试使用有效的输入集和变异模糊，以便从输入集中导出新的测试用例。如果输入示例可用（例如JPG文件），则可以快速实现这种类型的模糊测试。主要缺点是基于普通变异的模糊测试创建的测试用例无法快速发现调用树深处的代码路径，因为许多创建的测试用例在早期程序执行阶段被过滤掉。这一类别的一个非常突出和成功的例子是前面提到的fuzzer AFL及其进化突变方法。其次，基于生成的模糊测试使用一种从头开始创建测试样例的方法，例如通过基于语法的创建。在研究输入结构和开发生成器时，这种方法需要付出很多努力，但一般来说它能够发现更深层次的代码路径。但是，必须找到遵守规则和打破规则之间的平衡，以便在目标中引发意外行为。 2.2 回归神经网络许多软件产品的输入数据在互联网上很容易获得（例如HTML，JPG，PNG），深度学习算法已经在不同的使用案例中显示出它们的性能，特别是在大型可用数据集上训练的情况下，例如文本生成[26]，程序创建[3]和机器翻译[6]，[2]。这导致我们在模糊测试期间使用生成模型来创建测试用例。此外，HTML和其他输入格式的结构，其中实际字符或字节依赖于序列中的先前位置导致使用RNN。 RNN用于建模顺序数据，例如用于文本生成[26]，语言建模和音乐预测[21]。他们使用隐藏状态作为短期记忆，在时间步之间传递信息。传统RNN通过输入xt和隐藏状态向量ht和输出 y^t在时间步骤 t 定义如下:$$h_t = f_h(x_t; h_{t−1}) ; y_t = f_o(h_t);$$fh和fo分别是隐藏层转换函数和输出函数。因此，输入xt可以是N维向量，表示输入结构，例如位置t处的单个像素的RGB值。 正如Hochreiter [13]和后来的Bengio等人所述[4]，RNN受到消失或爆炸梯度问题的影响。这意味着在训练期间权重更新变得无穷小，这会消耗大量时间但不会导致更好的网络优化。 Hochreiter和Schmidhuber引入了长短期记忆（LSTM）细胞的概念[14]使用这些细胞的RNN不会遭受消失（爆炸）梯度问题。 LSTM单元使用隐藏状态，候选值和三个门，即忘记门，输入门和输出门。门控制了多少信息被遗忘，从输入中使用并分别控制流进入新的隐藏状态。它们是默认的前馈神经网络，每个都有自己的可训练参数。 另一种流行的RNN细胞，门控递归单位（GRU）由Cho等人引入 [6]。该单元仅使用两个门，一个重置门和一个更新门。这里，重置门控制忘记过去隐藏状态的哪些信息，并且更新门控制信息流进入新的隐藏状态。这种更简单的模型可以说比基于标准LSTM的模型更容易训练。 当学习用于测试用例生成的输入格式结构时，学习顺序结构的能力（其中存在对先前输入的依赖性）显然是重要的特征。这在例如HTML中尤其明显，其中在开始标记和对应的结束标记之间存在长期依赖性。 3堆叠RNN用于HTML-Fuzzing本工作中使用的模型的基本概念如图2所示。该模型由三个模块组成。首先，输入模块，让X = {x1, x2,… xn}是输入值的序列，其中xt ∈N0 | 1 ≤ t ≤ N，其中xt是表示输入序列中位置t处的字符的自然数。例如，字符’f’在输入序列中的位置t，其分配的数字是17，xt = 17。 然后输入模块采用这样的xt并将其转换为 I = max（X）+ 1的单热编码矢量 x’t ∈ R^I^，使用0来添加到条目中。设x‘t =（ x’1， x‘ 2，… x‘I）|然后$$x’_j = 0 \\forall 1≤ j≤ I：j \\neq x_t ∨ x_j = 1 \\Leftrightarrow j = x_t$$对于前一个示例字符’f’，所有 x’j = 0，除了x’17，等于1.从整数值转换是必要的，因为我们将输入解释为分类数据（每个字符是它自己的类别），这些类别是在训练过程中作为特征处理。 其次，循环模块由LSTM或GRU节点组成，如2.2节所述，s,l ∈N。这里s是节点的内部大小，l是所使用的层的数量，例如，如图2所示对于基于LSTM的模型，l = 2。与Chung等人证明的基本RNN方法相比，LSTM细胞已经证明了高性能增益 [7]。 Cho等人[6]介绍的门控递归单元（GRU）表现类似于LSTM细胞[7]，但Jozefowicz等人 [17]表明LSTM细胞在XML建模过程中表现更好。我们决定评估两个单元的性能，以分析XML建模结果是否可以转换为HTML建模。 最后，输出层由具有I节点的默认前馈网络组成。它将最后一个回归层ht^l^ ∈ R^s^的输出作为输入值，并且在计算其输出之后应用softmax函数。得到的y’t提供用于预测输入序列的下一个值的概率分布。训练期间的目标是最小化交叉熵损失函数$$L(Θ) = − \\frac{1}{N}\\sum_{i=1}^Ny_ilog(y’_i) + (1 − y_i) log(1 − y’_i);$$其中Θ表示模型的参数（即W和b的集合）。为了找到使上述损失L最小化的Θ，应用ADAM [18]优化算法。它是一种基于梯度的优化算法，与其他算法相比，它只需要一阶梯度并且具有减少的内存占用。此外，Dropout（30％丢失概率）[25]用作正则化。 4 实验以下部分介绍了用于验证我们的RNN应用程序的方法，以生成模糊测试复杂系统中网络安全性的测试用例。 基本思想是在大量HTML标签上训练具有不同深度的上述神经网络。在训练之后，这些模型用于直接使用给定序列的字符的概率分布来生成HTML标签。然后将生成的输出用作Web浏览器的输入。对该浏览器进行检测，以便在基本块的基础上执行期间收集代码覆盖率数据。然后使用所收集的代码覆盖率数据来与通过执行数据集的HTML标签收集的代码覆盖率数据以及对该HTML标签执行的普通变异策略比较模型的性能。 4.1环境设置和实现模型训练在配备单个NVIDIA GeForce 1080 Ti和NVIDIA GeForce TITAN Xp的Ubuntu 16.04系统上进行，通过利用其并行计算功能缩短了必要的训练时间。这些模型是使用Google的TensorFlow框架[1]及其Python绑定实现的。该框架已经为我们的模型提供了必要的单元类型，优化算法和损失函数，缩短了开发时间。 代码覆盖率数据是在运行Ubuntu 16.04和Firefox 57.0.1的虚拟机（VM）上收集的，它允许在所谓的无头模式下运行。在此模式下，Firefox不显示图形用户界面，但仍会呈现网页。我们还修改了标准配置，以便禁用内部服务，以避免尽可能多的错误代码覆盖数据。此外，安全模式已禁用，因为在自动代码覆盖率收集期间，Firefox未正确关闭，因此可能会在几个测试用例后尝试以安全模式启动。无头模式的使用还节省了代码覆盖率收集期间的时间，这是由DynamoRIO的drcov工具收集的（参见第4.4小节）。 VM本身使用16 GB的RAM和固态硬盘。 VM用于通过克隆和部署到多个主机系统来促进并行数据收集。 4.2数据集生成为了提供可重复和可控的实验，训练（和地面实况）数据集由PyFuzz2 [24]中包含的现有HTML-fuzzer生成。它提供了一个可控制的发生器，从而确保与从互联网收集数据集相比，训练数据集内变化的不确定性更小。因此，可以在每个标记的基础上控制生成的HTML的复杂性，而必须解析收集的集合，然后对不需要的HTML标记进行过滤以控制结果数据集。 修改了预先存在的模糊器，以避免嵌套HTML标记，删除所有级联样式表并每行输出一个HTML标记。由于没有嵌套HTML标签的限制，有些像td或th被排除在外，因为它们需要在此示例表中使用外部标记。引入这些限制是为了通过降低整体数据集的复杂性来减少对基本问题的关注。这进一步降低了必要的模型复杂性并有效地缩短了训练这些模型所需的时间。 清单1.1显示了用于训练模型的数据集的摘录，其中突出了上述修改。创建的文件由409,000个HTML标记组成，总大小为36MB。 4.3训练所有模型都经过训练可以预测每个字符的输入其中一个偏移。例如，将清单1.1中第1行的“&lt;h2 i”作为长度为5的输入序列，然后该特定输入序列的标签将为“h2 id”。在训练期间使用的实际序列长度是150个字符，并且每个模型被训练50个时期，这已经足以使模型收敛。为了训练模型，我们使用了前面提到的ADAM [18]优化算法。起始学习率设定为0.001，每10个时期减半。训练模型的分批大小为512。对于所有受过训练的模型，LSTM和GRU单元的内部大小设置为256，层数从1到6变化。层的权重由Glorot uniform initializer初始化[10]。因此，权重是从区间中的均匀分布 中绘制的，其中nj是层j的内部大小。 数据集的前30MB用于训练，另外1MB用于验证。所有模型都经过5次不同的训练/验证分裂训练，重复3次，不同的初始化（以减轻极差的局部最小值），这导致每个细胞类型共有90个训练模型。随机选择分割而没有重叠部分。 4.4 数据收集代码覆盖率数据是通过执行由DynamoRIO的drcov [9]插桩Firefox收集的。该工具收集有关被测程序的已执行基本块的数据。收集的代码覆盖率数据被解析为Firefox的libxul.so库中唯一执行的基本块，其中包括负责HTML呈现的整个Web引擎。即使重新启动过程，也可以识别这些基本块，因为记录的数据使用基本块与存储器中库的基址的偏移量，并且对于固定版本，此偏移量始终相同。因此，基本块被定义为具有单个入口（分支目标）和单个出口（分支指令）的机器指令的线性序列。 所有测试用例都包含一个基本的HTML模板，HTML标签插入到body标签中。初步实验表明，多次执行相同的测试用例会返回不同的代码覆盖率数据。这是由于捆绑在libxul.so库中的其他函数，它们不是Web引擎本身的一部分。例如，这些功能可以仅在多次重启之后或以固定的时间间隔执行。为了识别相应的基本块，执行空白HTML模板1024次，并将结果代码覆盖存储起来供以后使用。 通过使用HTML模糊器创建6×16384 HTML标签来建立比较基线然后使用16384个HTML标签的每个集合来创建两个数据集，一个包含64个文件，每个文件具有256个HTML标签，第二个包含128个文件包含128个HTML标签。这导致了12个数据集。 通过使用HTML模糊器创建6×16384 HTML标签来建立比较基线然后使用16384个HTML标签的每个集合来创建两个数据集，一个包含64个文件，每个文件具有256个HTML标签，第二个包含128个文件包含128个HTML标签。这导致了12个数据集。为了建立第二个比较基线，通过改变数据集测试用例并从中收集代码覆盖率来创建其他测试集。应用了一个简单的变异函数，其中一个位置被随机选择的字符（只有已经存在于数据集中的字符）替换。结果是另外20个测试用例集，10组由128个案例组成，每个案例有128个HTML标签，10个组由64个案例组成，每个案例有256个HTML标签，总共有1920个案例。替换概率在0：1％和51.2％之间变化。这样做是为了确保存在差异，因此有动机使用经过训练的模型来创建测试用例，而不是实现基于简单变异的方法。对于每个训练的模型，生成总共16384个HTML标签，然后用于创建两组不同的测试用例。第一组每个案例使用128个HTML标签，每个模型训练产生128个案例，而第二个案例每个案例使用256个HTML标签，每个模型产生64个案例。这样做是为了分析HTML标记对代码覆盖率的影响，并观察与模型性能的关系。 HTML标签是通过使用“&lt;”字符作为起始输入生成的，从得到的概率分布中抽取下一个字符，然后将其用作新输入。重复此操作直到采样“\\n”（换行符），因为它标记了HTML标记的结束。 最后，计算来自测试用例的基本块集合和空白案例之间的集合差异，以过滤掉上述不相关的基本块。 4.5 结果训练阶段已显示两种细胞类型之间的行为差异。基于LSTM的模型显示平均验证损失和标准偏差降低至三层，如图3a所示，之后有所增加。特别是，与其他模型相比，6层模型显示出较大的标准偏差和平均验证损失的大幅增加。这表明这些模型具有太多参数，以便对我们的问题和训练集进行训练。从一般的机器学习角度来看，这种行为是可以预期的，并且因为与使用生成神经网络的其他类似应用相比，训练过程是相同的，例如生成文本。 相比之下，基于GRU的模型的训练显示从1层模型到2层情况的小幅增加，但之后随着标准偏差的总体小差异而减小。这表明基于GRU的模型或者更适合于再现输入结构，或者没有达到基于6层LSTM的模型的整体复杂性，这也通过比较这些模型的可训练参数来支持。基于GRU的模型有2, 276,971比3, 026, 795。 总的来说，验证丢失的一个小的数字差异可能导致生成的HTML标签的质量有很大差异。例如，清单1.2显示了由1层LSTM模型生成的摘录。它几乎不可识别为HTML，并且模型没有生成现有的HTML开放和结束标记，并且在这个特定示例中，两个生成的HTML属性拼写错误。与此相反，清单1.3显示了由3层LSTM模型生成的两个HTML标记。两者都只使用现有的HTML标记，但第二个不使用正确的结束标记和拼写错误的一个属性名称。图4提供了关于两种细胞类型模型之间质量差异的进一步证据。它显示了每个标记的HTML错误率如何跟随验证损失的趋势，并突出显示小差异对HTML质量的影响很大。 6层LSTM HTML错误率的高扩散反映了训练期间观察到的大标准偏差。 具有128个HTML标签的测试用例 在 代码覆盖性能方面，整体趋势也遵循验证损失和标准偏差，其中较小的验证损失和标准偏差表示更好的性能。图5a显示了每层两种细胞类型的总发现基本块。它强调两种类型的4层模型和GRU 5和6层模型都能够发现数据集范围内的基本块，甚至超越它。 此外，图6a显示了基本块数量与性能最佳数据集的差异。它表明所有模型都能够发现不是由数据集触发的基本块，而5层GRU模型平均表现最佳。与不同的突变组相比，最大重叠率达到90％，突变几率为1.6％，这并不奇怪，因为相同的突变组与性能最佳的数据集重叠87.6％，如同图7.表现最佳的5层GRU模型与不同突变机会的结合重叠78％，突出了模型发现基本块的能力，这是简单突变方法无法触发的。总体上表现最佳的模型也是与数据集重叠最多的模型。 具有256个HTML标记的测试用例 具有256个HTML标记的测试用例的代码覆盖率结果各自显示类似的探索，但总体性能略低，如图5b和图6b所示。预期整体性能较低，因为两个运行基本上使用相同的HTML标签，并且只有插入的HTML标签的数量不同。 就绝对基本块而言，4层模型是最好的基于LSTM的模型，但是在此设置中它没有到达数据集覆盖区域。然而，基于4层，5层和6层GRU的模型能够到达数据集覆盖区域，其中6层模型具有最多数量的唯一触发的基本块。考虑到与突变测试用例的重叠，总体结果与128个HTML标签的情况相同。表现最佳的四层模型与74.6％的突变集平均重叠。这表明256个HTML标签案例也能够在Web渲染引擎中触发新的代码路径。 5讨论结果表明，使用基于RNN的模型成功训练模型和生成测试HTML案例确实是可能的。但是，监控此过程以获得稳健的结果至关重要，例如，6层LSTM模型无法以可靠的方式进行训练。这很可能是由于缺乏训练数据或优化中涉及的大量参数。 一旦对模型进行了训练，结果表明平均验证损失可以用作良好的初始选择标准，用于选择用于生成测试用例的良好模型，尽管隐式耦合代码覆盖度量。这是特别有趣的，因为在模型选择阶段没有可用的代码覆盖数据，并且在模糊测试期间覆盖尽可能多的代码路径对于发现软件错误很重要。结果还表明，HTML错误率可用于确定良好的生成模型，从而增加选择过程。这尤其有用，因为仅平均验证损失和标准偏差可能表明两个模型之间的差异较小，例如参见清单1.2和1.3。这些模型之间的最高平均验证损失差异≤0.02，但HTML错误率的差异为0.3。这意味着性能最差的单层LSTM模型每个标签的误差是最佳性能的3层LSTM模型的两倍。 总体而言，表现最佳的模型比其他模型生成更有效的HTML标签，从而导致使用现有的HTML标签。那些生成的和通常有效的HTML标签并不总是用正确的相应HTML标签关闭。这导致性能最佳的模型偶然构建嵌套的有效HTML标记，因为这些模型使用有效的开始HTML标记，但不生成相应的结束HTML标记。但是，这可能仍会在文件的后续阶段生成。假定的呈现行为和嵌套HTML标记的创建会触发基线集未触发的代码路径，因为在基线集中，每个打开的标记都会被关闭，每行中都有相应的结束标记。 LSTM模型与基线集之间的重叠基本块（参见图7a）的相似性低于128个HTML标签情况下与突变集和彼此之间的模型的重叠。这可能表明模型无法完全复制给定的输入结构，因此另一个模型选择更适合学习此结构，或者所提供的训练集太小而无法使用所选的模型体系结构捕获输入结构。对于GRU模型，表现最佳的模型还显示与数据集的重叠高于具有变异集的重叠（参见图7b）。这进一步加强了这样的假设，即模型必须达到一定的质量才能表现良好。 总的来说，我们能够证明特别是基于GRU的RNN能够创建HTML标签，然后可以在浏览器的模糊测试中使用。至关重要的是，生成的HTML测试用例还能够触发大量独特的基本块，而数据集的基线和简单突变方法无法实现这些基本块。 6 相关工作最接近的相关工作由Godefroid等人完成 [11]。他们使用两层堆叠RNN来研究可实现的代码覆盖率，以对PDF对象进行采样，并重点关注训练持续时间对此的影响。将他们实现的代码覆盖率结果与基线进行比较，该基线是从训练集中随机选择的。与此相反，我们使用模型在训练阶段未见的数据来建立我们的比较基线。此外，他们分析了创建测试用例的不同方法并对其进行了比较。他们还强调了学习和模糊测试之间观察到的紧张关系，并提出了一种名为SampleFuzz的算法。如果模型的最高预测概率高于某个阈值并且随机抛硬币成功，则该算法使用最低预测概率。虽然我们的工作研究了不同的输入格式，即HTML，与PDF对象相比，它是一种结构更依赖的输入格式。我们还研究了模型深度对结果代码覆盖率的影响。我们无法观察到前面描述的学习和模糊测试之间的紧张关系。这可能与我们训练集的相对较大的大小有关，或者表明他们的模型开始过度拟合训练样本，因此需要额外的随机性来产生新的测试用例。无论如何，我们没有确定是否需要引入额外的随机值（例如，通过使用SampleFuzz）。 其他相关工作在执行期间利用控制和数据流来生成新的测试用例。 Rawat等人[23]利用所谓的进化算法来推导新的测试用例。而Hochele等人[15]从收集的执行信息中导出输入语法。这两种方法都需要直接访问被测程序以对其进行检测并收集必要的数据。相反，我们的方法能够直接从输入示例中学习输入结构，这缩短了设计和学习过程。 Bohme等人提出了一种利用代码覆盖和基于突变的模糊测试的不同方法 [5]。他们在突变过程中用马尔可夫链增强了AFL。他们的AFLFast调用方法使用Markov链来确定状态转换为新的测试输入。他们已经证明，他们缩短了在一组经过测试的软件中发现错误所需的时间。但是，它们没有提供任何有关高度依赖结构的输入格式的信息，如HTML，这被描述为一般AFL方法的不足之处。 Pradel等人评估了另一种结合深度学习以便在软件中发现错误的方法 [22]。他们使用训练有素的模型来分类潜在的错误源代码。因此，他们将他们的模型训练为特定错误类别的单独分类器。与之相反，我们训练模型生成输入，然后可以用来触发和观察软件中的错误。此外，他们的方法需要直接访问源代码，而我们需要访问足够的输入示例来训练RNN模型。 7 结论和未来工作我们的工作提供了证据，证明可以使用堆叠的RNN生成HTML标签，以便为浏览器的渲染引擎进行模糊测试生成新的测试用例。结果还清楚地表明，即使训练参数较少，基于GRU的模型也能够胜过LSTM模型。此外，所提出的评估程序和基于相似性的分析表明，数据集与模型生成的测试用例之间的基本块的重叠平均非常低。此外，与简单突变组的重叠平均约为70％，这表明训练的网络能够发现以前未通过具有不同突变机会的幼稚突变方法发现的新代码路径。这提供了一个明确的证据，即只要应用合适的模型选择和分析程序，RNN就可以被训练并用作有效的HTML模糊器。 我们目前正在寻求以至少三种方式扩展目前的工作：首先，研究更复杂/更合适的神经网络模型对于提高生成的HTML的整体质量是必要的，因为其他流行的Web技术（如JavaScript）不能用于破坏的HTML标签都有效。其次，重要的是验证当前关于真实HTML示例的工作的概括，与此处考虑的模糊器生成的训练数据形成对比。最后，我们正在探索在训练过程中利用收集的代码覆盖率数据的方法，并在发现意外行为或新代码路径时奖励学习算法。我们推测这可以通过强化学习来实现，以系统地权衡模型拟合与探索。","content":"<h1 id=\"Abstract\"><a href=\"#Abstract\" class=\"headerlink\" title=\"Abstract\"></a>Abstract</h1><p>基于生成的模糊测试是一种软件测试方法，能够发现软件中不同类型的错误和漏洞。然而，已知设计和微调经典模糊器以实现可接受的覆盖是非常耗时的，即使对于小规模软件系统也是如此。为了解决这个问题，我们研究了一种基于机器学习的模糊测试方法，其中我们概述了一系列基于递归神经网络（RNN）的测试用例生成器，并使用最少的人工微调来训练那些现成的数据集。与先前的工作相比，所提出的生成器不依赖于启发式采样策略，而是依赖于预测分布的原理采样。我们提供详细的分析，以在具有挑战性的Web浏览器测试场景中演示所提出的生成器的特征和功效。实证结果表明，基于RNN的发生器能够提供比基于突变的方法更好的覆盖，并且能够发现经典模糊器未发现的路径。我们的研究结果补充了其他领域的研究结果，表明使用RNN进行基于代数的模糊测试是通过使用合适的模型选择/分析程序来获得更好软件质量的可行途径</p>\n<p>Keywords: Software security, fuzz testing, browser security </p>\n<table>\n<thead>\n<tr>\n<th>relevant information</th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><em>作者</em></td>\n<td>Martin Sablotny, Bjørn Sand Jensen, Chris W. Johnson</td>\n</tr>\n<tr>\n<td><em>单位</em></td>\n<td>University of Glasgow, School of Computing Science, Glasgow, Scotland</td>\n</tr>\n<tr>\n<td><em>出处</em></td>\n<td>ICISC</td>\n</tr>\n<tr>\n<td><em>原文地址</em></td>\n<td><a href=\"https://arxiv.org/abs/1812.04852\" target=\"_blank\" rel=\"noopener\">https://arxiv.org/abs/1812.04852</a></td>\n</tr>\n<tr>\n<td><em>源码地址</em></td>\n<td><a href=\"https://github.com/susperius/icisc_rnnfuzz\" target=\"_blank\" rel=\"noopener\">https://github.com/susperius/icisc_rnnfuzz</a></td>\n</tr>\n<tr>\n<td><em>发表时间</em></td>\n<td>2018</td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"1-简介\"><a href=\"#1-简介\" class=\"headerlink\" title=\"1. 简介\"></a>1. 简介</h1><p>最近，模糊测试在理论和实际软件测试中越来越受欢迎。这主要归因于在复杂软件系统中触发非预期行为的明显能力，例如，美国模糊Lop（AFL）[28]发现的错误摘要，并通过在微软和谷歌等软件公司中使用模糊测试进一步证明（例如通过他们的开源工具ClusterFuzz [12]），它在许多不同的领域显示了成功和适用性。然而，将一组输入示例上的变异与进化方法相结合的标准方法有其局限性，即增加关键词的必要性和对句法规则的遵从性（例如，在本工作中考虑的HTML）。这些问题可以通过基于生成的模糊器解决，这些模糊器能够遵守这些规则，使用正确的关键字并生成新的输入。传统上，开发基于生成的模糊器所需的时间取决于输入规范的复杂性。例如，为网络协议开发生成器的时间较少，与使用各种字段和状态实现文件传输协议（FTP）[16]相比，它具有三个不同可能值的单个字段。此外，有必要在引入的错误和总体正确性之间找到适当的平衡，以触发导致意外行为的代码路径。</p>\n<p>开发基于生成的模糊器的主要瓶颈是需要严格理解和实现输入文件格式。因此，必须仔细研究潜在的复杂输入规范，将其转换为测试用例生成器，然后需要对其进行微调，以便在测试用例中找到正确性和引入错误之间的正确平衡。这种隐式优化过程通过生成在给定规范的某些区域中偏离的测试用例来寻求最大化代码覆盖，因此能够执行不同的低级执行路径。因此，很明显，可以自动推导或减少输入规范的方法将能够通过更快地部署基于生成的模糊测试技术来加速软件测试。这可能会导致软件安全性和稳定性的提高。</p>\n<p>学习输入规范（例如语法规则）显然不是微不足道的，特别是由于可以应用输入规范的长时间依赖性。这些依赖性对特定位置的可能输出具有直接影响，因此必须通过学习算法捕获以产生规范附加输出。然而，生成机器学习模型的最新进展（[26]，[3]，[6]，[2]）已经证明了机器学习模型如何用于从实例中学习复杂的规则和分布，并从获得的知识中生成新的例子。</p>\n<p>Godefroid等人的模糊测试已经对这些进行了改进[11]。他们演示了如何使用深度神经网络生成PDF对象，这些对象被用作渲染引擎的输入。这些输入文件能够在渲染引擎中触发新指令。然而，他们关注的是学习正确的输入结构和模糊测试之间的紧张关系，换句话说，他们在遵守学习规范和偏离规范之间寻求平衡。他们没有提供对学习过程本身的分析，也没有对基于简单变异的基线进行比较。此外，他们没有提供有关基线与其拟议抽样策略之间重叠的任何信息。为了在模糊测试中使用深度学习模型，重要的是要看它是否值得探索和训练。因此，有必要将其与易于实现的方法进行比较，如简单的变异算法。对不同方法之间现有重叠的分析还可以更深入地了解模型和采样选择，因为在测试期间触发尽可能多的新执行路径以找到触发意外行为的路径非常重要。</p>\n<p>在这项工作中，我们研究了如何训练具有不同类型细胞的递归神经网络（RNN）并将其用作HTML模糊器。模型在基于生成的HTML-fuzzer创建的数据集上进行训练，这使我们能够快速，系统地调整数据集大小和复杂性。<br>我们使用这些模型从生成的概率分布中生成新的HTML标记，这些标记用于形成测试用例。这些是用Firefox [19]执行的，用于收集他们的代码覆盖率数据，并与来自数据集的HTML标记和简单变异数据集生成的基线进行比较。因此，本文的贡献包括： </p>\n<ul>\n<li><p>用于训练和评估具有不同类型细胞的递归神经网络的系统且稳健的方法，用于HTML模糊测试。</p>\n</li>\n<li><p>用于模型选择的过程和度量，并比较机器学习模糊器与标准和基于普通突变的方法（包括基于相似性的分析）</p>\n</li>\n<li><p>对Web浏览器进行广泛的实证评估，证明学习的模糊测试器能够胜过标准测试方法。</p>\n</li>\n<li><p>通过Github 开源了实现代码和数据。</p>\n</li>\n</ul>\n<h1 id=\"2-背景\"><a href=\"#2-背景\" class=\"headerlink\" title=\"2.背景\"></a>2.背景</h1><h2 id=\"2-1模糊测试\"><a href=\"#2-1模糊测试\" class=\"headerlink\" title=\"2.1模糊测试\"></a>2.1模糊测试</h2><p>模糊测试是一种动态软件测试方法，因此动态意味着被测软件实际上是与静态分析相对应的。模糊测试的目标是引发在早期测试阶段未检测到的意外行为，因此测试中的软件使用由所谓的模糊器创建的输入执行。这些输入不完全符合基础输入规范，以便找到导致触发意外行为的状态的路径。我们对非预期行为采用广义定义，这使其适用于各种软件和设备[27]。例如，在模糊测试桌面软件期间，意外行为可能是正在运行的进程的终止，甚至可能是对进程进行控制的可能性。在Web应用程序测试期间，非预期行为可能被定义为信息泄漏或规避访问限制，这两种情况都可能由于SQL注入漏洞而发生，其中任意输入用作有效的SQL语句。</p>\n<p>正如这些例子所强调的那样，如果可以为攻击者提供优势，那么意外行为就会变得更加严重。这里的优势可能意味着从访问受限信息到接管设备的控制。为了找到这些漏洞，使用了模糊测试。模糊测试期间的一般工作流程如图1所示。测试本身分为两部分，第一部分是测试用例生成，第二部分是行为分析。通常，在模糊测试期间创建测试用例可以分为两类：基于突变和基于生成[27]，[8]和[20]。基于突变的模糊测试使用有效的输入集和变异模糊，以便从输入集中导出新的测试用例。如果输入示例可用（例如JPG文件），则可以快速实现这种类型的模糊测试。主要缺点是基于普通变异的模糊测试创建的测试用例无法快速发现调用树深处的代码路径，因为许多创建的测试用例在早期程序执行阶段被过滤掉。这一类别的一个非常突出和成功的例子是前面提到的fuzzer AFL及其进化突变方法。其次，基于生成的模糊测试使用一种从头开始创建测试样例的方法，例如通过基于语法的创建。在研究输入结构和开发生成器时，这种方法需要付出很多努力，但一般来说它能够发现更深层次的代码路径。但是，必须找到遵守规则和打破规则之间的平衡，以便在目标中引发意外行为。</p>\n<p><img src=\"/2019/04/15/Recurrent-Neural-Networks-for-Fuzz-Testing-Web-Browsers/1.jpg\" alt=\"\"></p>\n<h2 id=\"2-2-回归神经网络\"><a href=\"#2-2-回归神经网络\" class=\"headerlink\" title=\"2.2 回归神经网络\"></a>2.2 回归神经网络</h2><p>许多软件产品的输入数据在互联网上很容易获得（例如HTML，JPG，PNG），深度学习算法已经在不同的使用案例中显示出它们的性能，特别是在大型可用数据集上训练的情况下，例如文本生成[26]，程序创建[3]和机器翻译[6]，[2]。这导致我们在模糊测试期间使用生成模型来创建测试用例。此外，HTML和其他输入格式的结构，其中实际字符或字节依赖于序列中的先前位置导致使用RNN。</p>\n<p>RNN用于建模顺序数据，例如用于文本生成[26]，语言建模和音乐预测[21]。他们使用隐藏状态作为短期记忆，在时间步之间传递信息。传统RNN通过输入x<sub>t</sub>和隐藏状态向量h<sub>t</sub>和输出 y^<sub>t</sub>在时间步骤 t 定义如下:<br>$$<br>h_t = f_h(x_t; h_{t−1}) ; y_t = f_o(h_t);<br>$$<br>f<sub>h</sub>和f<sub>o</sub>分别是隐藏层转换函数和输出函数。因此，输入x<sub>t</sub>可以是N维向量，表示输入结构，例如位置t处的单个像素的RGB值。</p>\n<p>正如Hochreiter [13]和后来的Bengio等人所述[4]，RNN受到消失或爆炸梯度问题的影响。这意味着在训练期间权重更新变得无穷小，这会消耗大量时间但不会导致更好的网络优化。 Hochreiter和Schmidhuber引入了长短期记忆（LSTM）细胞的概念[14]使用这些细胞的RNN不会遭受消失（爆炸）梯度问题。 LSTM单元使用隐藏状态，候选值和三个门，即忘记门，输入门和输出门。门控制了多少信息被遗忘，从输入中使用并分别控制流进入新的隐藏状态。它们是默认的前馈神经网络，每个都有自己的可训练参数。</p>\n<p>另一种流行的RNN细胞，门控递归单位（GRU）由Cho等人引入 [6]。该单元仅使用两个门，一个重置门和一个更新门。这里，重置门控制忘记过去隐藏状态的哪些信息，并且更新门控制信息流进入新的隐藏状态。这种更简单的模型可以说比基于标准LSTM的模型更容易训练。</p>\n<p>当学习用于测试用例生成的输入格式结构时，学习顺序结构的能力（其中存在对先前输入的依赖性）显然是重要的特征。这在例如HTML中尤其明显，其中在开始标记和对应的结束标记之间存在长期依赖性。</p>\n<h1 id=\"3堆叠RNN用于HTML-Fuzzing\"><a href=\"#3堆叠RNN用于HTML-Fuzzing\" class=\"headerlink\" title=\"3堆叠RNN用于HTML-Fuzzing\"></a>3堆叠RNN用于HTML-Fuzzing</h1><p>本工作中使用的模型的基本概念如图2所示。该模型由三个模块组成。首先，输入模块，让X = {x1, x2,… xn}是输入值的序列，其中xt ∈N0 | 1 ≤ t ≤ N，其中xt是表示输入序列中位置t处的字符的自然数。例如，字符’f’在输入序列中的位置t，其分配的数字是17，xt = 17。</p>\n<p>然后输入模块采用这样的xt并将其转换为 I = max（X）+ 1的单热编码矢量 x’t ∈ R^I^，使用0来添加到条目中。<br>设x‘t =（ x’1， x‘ 2，… x‘I）|然后<br>$$<br>x’_j = 0 \\forall 1≤ j≤ I：j \\neq x_t ∨ x_j = 1 \\Leftrightarrow j = x_t<br>$$<br>对于前一个示例字符’f’，所有 x’j = 0，除了x’17，等于1.从整数值转换是必要的，因为我们将输入解释为分类数据（每个字符是它自己的类别），这些类别是在训练过程中作为特征处理。</p>\n<p> 其次，循环模块由LSTM或GRU节点组成，如2.2节所述，s,l ∈N。这里s是节点的内部大小，l是所使用的层的数量，例如，如图2所示对于基于LSTM的模型，l = 2。与Chung等人证明的基本RNN方法相比，LSTM细胞已经证明了高性能增益 [7]。 Cho等人[6]介绍的门控递归单元（GRU）表现类似于LSTM细胞[7]，但Jozefowicz等人 [17]表明LSTM细胞在XML建模过程中表现更好。我们决定评估两个单元的性能，以分析XML建模结果是否可以转换为HTML建模。</p>\n<p><img src=\"/2019/04/15/Recurrent-Neural-Networks-for-Fuzz-Testing-Web-Browsers/2.jpg\" alt=\"\"></p>\n<p>最后，输出层由具有I节点的默认前馈网络组成。它将最后一个回归层ht^l^  ∈ R^s^的输出作为输入值，并且在计算其输出之后应用softmax函数。得到的y’t提供用于预测输入序列的下一个值的概率分布。训练期间的目标是最小化交叉熵损失函数<br>$$<br>L(Θ) = − \\frac{1}{N}<br>\\sum_{i=1}^N<br>y_ilog(y’_i) + (1 − y_i) log(1 − y’_i);<br>$$<br>其中Θ表示模型的参数（即W和b的集合）。为了找到使上述损失L最小化的Θ，应用ADAM [18]优化算法。它是一种基于梯度的优化算法，与其他算法相比，它只需要一阶梯度并且具有减少的内存占用。此外，Dropout（30％丢失概率）[25]用作正则化。</p>\n<h1 id=\"4-实验\"><a href=\"#4-实验\" class=\"headerlink\" title=\"4 实验\"></a>4 实验</h1><p>以下部分介绍了用于验证我们的RNN应用程序的方法，以生成模糊测试复杂系统中网络安全性的测试用例。</p>\n<p>基本思想是在大量HTML标签上训练具有不同深度的上述神经网络。在训练之后，这些模型用于直接使用给定序列的字符的概率分布来生成HTML标签。然后将生成的输出用作Web浏览器的输入。对该浏览器进行检测，以便在基本块的基础上执行期间收集代码覆盖率数据。然后使用所收集的代码覆盖率数据来与通过执行数据集的HTML标签收集的代码覆盖率数据以及对该HTML标签执行的普通变异策略比较模型的性能。</p>\n<h2 id=\"4-1环境设置和实现\"><a href=\"#4-1环境设置和实现\" class=\"headerlink\" title=\"4.1环境设置和实现\"></a>4.1环境设置和实现</h2><p>模型训练在配备单个NVIDIA GeForce 1080 Ti和NVIDIA GeForce TITAN Xp的Ubuntu 16.04系统上进行，通过利用其并行计算功能缩短了必要的训练时间。这些模型是使用Google的TensorFlow框架[1]及其Python绑定实现的。该框架已经为我们的模型提供了必要的单元类型，优化算法和损失函数，缩短了开发时间。</p>\n<p>代码覆盖率数据是在运行Ubuntu 16.04和Firefox 57.0.1的虚拟机（VM）上收集的，它允许在所谓的无头模式下运行。在此模式下，Firefox不显示图形用户界面，但仍会呈现网页。我们还修改了标准配置，以便禁用内部服务，以避免尽可能多的错误代码覆盖数据。<br>此外，安全模式已禁用，因为在自动代码覆盖率收集期间，Firefox未正确关闭，因此可能会在几个测试用例后尝试以安全模式启动。无头模式的使用还节省了代码覆盖率收集期间的时间，这是由DynamoRIO的drcov工具收集的（参见第4.4小节）。 VM本身使用16 GB的RAM和固态硬盘。 VM用于通过克隆和部署到多个主机系统来促进并行数据收集。</p>\n<h2 id=\"4-2数据集生成\"><a href=\"#4-2数据集生成\" class=\"headerlink\" title=\"4.2数据集生成\"></a>4.2数据集生成</h2><p>为了提供可重复和可控的实验，训练（和地面实况）数据集由PyFuzz2 [24]中包含的现有HTML-fuzzer生成。它提供了一个可控制的发生器，从而确保与从互联网收集数据集相比，训练数据集内变化的不确定性更小。因此，可以在每个标记的基础上控制生成的HTML的复杂性，而必须解析收集的集合，然后对不需要的HTML标记进行过滤以控制结果数据集。</p>\n<p>修改了预先存在的模糊器，以避免嵌套HTML标记，删除所有级联样式表并每行输出一个HTML标记。由于没有嵌套HTML标签的限制，有些像td或th被排除在外，因为它们需要在此示例表中使用外部标记。引入这些限制是为了通过降低整体数据集的复杂性来减少对基本问题的关注。这进一步降低了必要的模型复杂性并有效地缩短了训练这些模型所需的时间。</p>\n<p>清单1.1显示了用于训练模型的数据集的摘录，其中突出了上述修改。创建的文件由409,000个HTML标记组成，总大小为36MB。</p>\n<p><img src=\"/2019/04/15/Recurrent-Neural-Networks-for-Fuzz-Testing-Web-Browsers/3.jpg\" alt=\"\"></p>\n<h2 id=\"4-3训练\"><a href=\"#4-3训练\" class=\"headerlink\" title=\"4.3训练\"></a>4.3训练</h2><p>所有模型都经过训练可以预测每个字符的输入其中一个偏移。例如，将清单1.1中第1行的“&lt;h2 i”作为长度为5的输入序列，然后该特定输入序列的标签将为“h2 id”。在训练期间使用的实际序列长度是150个字符，并且每个模型被训练50个时期，这已经足以使模型收敛。为了训练模型，我们使用了前面提到的ADAM [18]优化算法。起始学习率设定为0.001，每10个时期减半。训练模型的分批大小为512。对于所有受过训练的模型，LSTM和GRU单元的内部大小设置为256，层数从1到6变化。层的权重由Glorot uniform initializer初始化[10]。因此，权重是从区间中的均匀分布</p>\n<p><img src=\"/2019/04/15/Recurrent-Neural-Networks-for-Fuzz-Testing-Web-Browsers/4.jpg\" alt=\"\"></p>\n<p>中绘制的，其中nj是层j的内部大小。</p>\n<p>数据集的前30MB用于训练，另外1MB用于验证。所有模型都经过5次不同的训练/验证分裂训练，重复3次，不同的初始化（以减轻极差的局部最小值），这导致每个细胞类型共有90个训练模型。随机选择分割而没有重叠部分。</p>\n<h2 id=\"4-4-数据收集\"><a href=\"#4-4-数据收集\" class=\"headerlink\" title=\"4.4 数据收集\"></a>4.4 数据收集</h2><p>代码覆盖率数据是通过执行由DynamoRIO的drcov [9]插桩Firefox收集的。该工具收集有关被测程序的已执行基本块的数据。收集的代码覆盖率数据被解析为Firefox的libxul.so库中唯一执行的基本块，其中包括负责HTML呈现的整个Web引擎。即使重新启动过程，也可以识别这些基本块，因为记录的数据使用基本块与存储器中库的基址的偏移量，并且对于固定版本，此偏移量始终相同。因此，基本块被定义为具有单个入口（分支目标）和单个出口（分支指令）的机器指令的线性序列。</p>\n<p>所有测试用例都包含一个基本的HTML模板，HTML标签插入到body标签中。初步实验表明，多次执行相同的测试用例会返回不同的代码覆盖率数据。这是由于捆绑在libxul.so库中的其他函数，它们不是Web引擎本身的一部分。例如，这些功能可以仅在多次重启之后或以固定的时间间隔执行。为了识别相应的基本块，执行空白HTML模板1024次，并将结果代码覆盖存储起来供以后使用。</p>\n<p>通过使用HTML模糊器创建6×16384 HTML标签来建立比较基线然后使用16384个HTML标签的每个集合来创建两个数据集，一个包含64个文件，每个文件具有256个HTML标签，第二个包含128个文件包含128个HTML标签。这导致了12个数据集。</p>\n<p>通过使用HTML模糊器创建6×16384 HTML标签来建立比较基线然后使用16384个HTML标签的每个集合来创建两个数据集，一个包含64个文件，每个文件具有256个HTML标签，第二个包含128个文件包含128个HTML标签。这导致了12个数据集。<br>为了建立第二个比较基线，通过改变数据集测试用例并从中收集代码覆盖率来创建其他测试集。应用了一个简单的变异函数，其中一个位置被随机选择的字符（只有已经存在于数据集中的字符）替换。结果是另外20个测试用例集，10组由128个案例组成，每个案例有128个HTML标签，10个组由64个案例组成，每个案例有256个HTML标签，总共有1920个案例。<br>替换概率在0：1％和51.2％之间变化。这样做是为了确保存在差异，因此有动机使用经过训练的模型来创建测试用例，而不是实现基于简单变异的方法。<br>对于每个训练的模型，生成总共16384个HTML标签，然后用于创建两组不同的测试用例。第一组每个案例使用128个HTML标签，每个模型训练产生128个案例，而第二个案例每个案例使用256个HTML标签，每个模型产生64个案例。这样做是为了分析HTML标记对代码覆盖率的影响，并观察与模型性能的关系。 HTML标签是通过使用“&lt;”字符作为起始输入生成的，从得到的概率分布中抽取下一个字符，然后将其用作新输入。重复此操作直到采样“\\n”（换行符），因为它标记了HTML标记的结束。</p>\n<p>最后，计算来自测试用例的基本块集合和空白案例之间的集合差异，以过滤掉上述不相关的基本块。</p>\n<h2 id=\"4-5-结果\"><a href=\"#4-5-结果\" class=\"headerlink\" title=\"4.5 结果\"></a>4.5 结果</h2><p>训练阶段已显示两种细胞类型之间的行为差异。基于LSTM的模型显示平均验证损失和标准偏差降低至三层，如图3a所示，之后有所增加。特别是，与其他模型相比，6层模型显示出较大的标准偏差和平均验证损失的大幅增加。这表明这些模型具有太多参数，以便对我们的问题和训练集进行训练。从一般的机器学习角度来看，这种行为是可以预期的，并且因为与使用生成神经网络的其他类似应用相比，训练过程是相同的，例如生成文本。</p>\n<p>相比之下，基于GRU的模型的训练显示从1层模型到2层情况的小幅增加，但之后随着标准偏差的总体小差异而减小。这表明基于GRU的模型或者更适合于再现输入结构，或者没有达到基于6层LSTM的模型的整体复杂性，这也通过比较这些模型的可训练参数来支持。基于GRU的模型有2, 276,971比3, 026, 795。</p>\n<p><img src=\"/2019/04/15/Recurrent-Neural-Networks-for-Fuzz-Testing-Web-Browsers/5.jpg\" alt=\"\"></p>\n<p><img src=\"/2019/04/15/Recurrent-Neural-Networks-for-Fuzz-Testing-Web-Browsers/6.jpg\" alt=\"\"></p>\n<p>总的来说，验证丢失的一个小的数字差异可能导致生成的HTML标签的质量有很大差异。例如，清单1.2显示了由1层LSTM模型生成的摘录。它几乎不可识别为HTML，并且模型没有生成现有的HTML开放和结束标记，并且在这个特定示例中，两个生成的HTML属性拼写错误。与此相反，清单1.3显示了由3层LSTM模型生成的两个HTML标记。两者都只使用现有的HTML标记，但第二个不使用正确的结束标记和拼写错误的一个属性名称。图4提供了关于两种细胞类型模型之间质量差异的进一步证据。它显示了每个标记的HTML错误率如何跟随验证损失的趋势，并突出显示小差异对HTML质量的影响很大。 6层LSTM HTML错误率的高扩散反映了训练期间观察到的大标准偏差。</p>\n<p><img src=\"/2019/04/15/Recurrent-Neural-Networks-for-Fuzz-Testing-Web-Browsers/7.jpg\" alt=\"\"></p>\n<p><img src=\"/2019/04/15/Recurrent-Neural-Networks-for-Fuzz-Testing-Web-Browsers/8.jpg\" alt=\"\"></p>\n<ul>\n<li><strong>具有128个HTML标签的测试用例</strong></li>\n</ul>\n<p>在 代码覆盖性能方面，整体趋势也遵循验证损失和标准偏差，其中较小的验证损失和标准偏差表示更好的性能。图5a显示了每层两种细胞类型的总发现基本块。它强调两种类型的4层模型和GRU 5和6层模型都能够发现数据集范围内的基本块，甚至超越它。</p>\n<p>此外，图6a显示了基本块数量与性能最佳数据集的差异。它表明所有模型都能够发现不是由数据集触发的基本块，而5层GRU模型平均表现最佳。与不同的突变组相比，最大重叠率达到90％，突变几率为1.6％，这并不奇怪，因为相同的突变组与性能最佳的数据集重叠87.6％，如同图7.表现最佳的5层GRU模型与不同突变机会的结合重叠78％，突出了模型发现基本块的能力，这是简单突变方法无法触发的。总体上表现最佳的模型也是与数据集重叠最多的模型。</p>\n<p><img src=\"/2019/04/15/Recurrent-Neural-Networks-for-Fuzz-Testing-Web-Browsers/9.jpg\" alt=\"\"></p>\n<ul>\n<li><strong>具有256个HTML标记的测试用例</strong></li>\n</ul>\n<p>具有256个HTML标记的测试用例的代码覆盖率结果各自显示类似的探索，但总体性能略低，如图5b和图6b所示。预期整体性能较低，因为两个运行基本上使用相同的HTML标签，并且只有插入的HTML标签的数量不同。</p>\n<p><img src=\"/2019/04/15/Recurrent-Neural-Networks-for-Fuzz-Testing-Web-Browsers/10.jpg\" alt=\"\"></p>\n<p>就绝对基本块而言，4层模型是最好的基于LSTM的模型，但是在此设置中它没有到达数据集覆盖区域。然而，基于4层，5层和6层GRU的模型能够到达数据集覆盖区域，其中6层模型具有最多数量的唯一触发的基本块。<br>考虑到与突变测试用例的重叠，总体结果与128个HTML标签的情况相同。表现最佳的四层模型与74.6％的突变集平均重叠。这表明256个HTML标签案例也能够在Web渲染引擎中触发新的代码路径。</p>\n<h1 id=\"5讨论\"><a href=\"#5讨论\" class=\"headerlink\" title=\"5讨论\"></a>5讨论</h1><p>结果表明，使用基于RNN的模型成功训练模型和生成测试HTML案例确实是可能的。但是，监控此过程以获得稳健的结果至关重要，例如，6层LSTM模型无法以可靠的方式进行训练。这很可能是由于缺乏训练数据或优化中涉及的大量参数。</p>\n<p>一旦对模型进行了训练，结果表明平均验证损失可以用作良好的初始选择标准，用于选择用于生成测试用例的良好模型，尽管隐式耦合代码覆盖度量。这是特别有趣的，因为在模型选择阶段没有可用的代码覆盖数据，并且在模糊测试期间覆盖尽可能多的代码路径对于发现软件错误很重要。结果还表明，HTML错误率可用于确定良好的生成模型，从而增加选择过程。这尤其有用，因为仅平均验证损失和标准偏差可能表明两个模型之间的差异较小，例如参见清单1.2和1.3。这些模型之间的最高平均验证损失差异≤0.02，但HTML错误率的差异为0.3。这意味着性能最差的单层LSTM模型每个标签的误差是最佳性能的3层LSTM模型的两倍。</p>\n<p>总体而言，表现最佳的模型比其他模型生成更有效的HTML标签，从而导致使用现有的HTML标签。那些生成的和通常有效的HTML标签并不总是用正确的相应HTML标签关闭。这导致性能最佳的模型偶然构建嵌套的有效HTML标记，因为这些模型使用有效的开始HTML标记，但不生成相应的结束HTML标记。但是，这可能仍会在文件的后续阶段生成。假定的呈现行为和嵌套HTML标记的创建会触发基线集未触发的代码路径，因为在基线集中，每个打开的标记都会被关闭，每行中都有相应的结束标记。</p>\n<p>LSTM模型与基线集之间的重叠基本块（参见图7a）的相似性低于128个HTML标签情况下与突变集和彼此之间的模型的重叠。这可能表明模型无法完全复制给定的输入结构，因此另一个模型选择更适合学习此结构，或者所提供的训练集太小而无法使用所选的模型体系结构捕获输入结构。对于GRU模型，表现最佳的模型还显示与数据集的重叠高于具有变异集的重叠（参见图7b）。这进一步加强了这样的假设，即模型必须达到一定的质量才能表现良好。</p>\n<p>总的来说，我们能够证明特别是基于GRU的RNN能够创建HTML标签，然后可以在浏览器的模糊测试中使用。至关重要的是，生成的HTML测试用例还能够触发大量独特的基本块，而数据集的基线和简单突变方法无法实现这些基本块。</p>\n<p><img src=\"/2019/04/15/Recurrent-Neural-Networks-for-Fuzz-Testing-Web-Browsers/11.jpg\" alt=\"\"></p>\n<h1 id=\"6-相关工作\"><a href=\"#6-相关工作\" class=\"headerlink\" title=\"6 相关工作\"></a>6 相关工作</h1><p>最接近的相关工作由Godefroid等人完成 [11]。他们使用两层堆叠RNN来研究可实现的代码覆盖率，以对PDF对象进行采样，并重点关注训练持续时间对此的影响。将他们实现的代码覆盖率结果与基线进行比较，该基线是从训练集中随机选择的。与此相反，我们使用模型在训练阶段未见的数据来建立我们的比较基线。此外，他们分析了创建测试用例的不同方法并对其进行了比较。他们还强调了学习和模糊测试之间观察到的紧张关系，并提出了一种名为SampleFuzz的算法。如果模型的最高预测概率高于某个阈值并且随机抛硬币成功，则该算法使用最低预测概率。虽然我们的工作研究了不同的输入格式，即HTML，与PDF对象相比，它是一种结构更依赖的输入格式。我们还研究了模型深度对结果代码覆盖率的影响。我们无法观察到前面描述的学习和模糊测试之间的紧张关系。这可能与我们训练集的相对较大的大小有关，或者表明他们的模型开始过度拟合训练样本，因此需要额外的随机性来产生新的测试用例。无论如何，我们没有确定是否需要引入额外的随机值（例如，通过使用SampleFuzz）。</p>\n<p>其他相关工作在执行期间利用控制和数据流来生成新的测试用例。 Rawat等人[23]利用所谓的进化算法来推导新的测试用例。而Hochele等人[15]从收集的执行信息中导出输入语法。这两种方法都需要直接访问被测程序以对其进行检测并收集必要的数据。相反，我们的方法能够直接从输入示例中学习输入结构，这缩短了设计和学习过程。</p>\n<p>Bohme等人提出了一种利用代码覆盖和基于突变的模糊测试的不同方法 [5]。他们在突变过程中用马尔可夫链增强了AFL。他们的AFLFast调用方法使用Markov链来确定状态转换为新的测试输入。他们已经证明，他们缩短了在一组经过测试的软件中发现错误所需的时间。但是，它们没有提供任何有关高度依赖结构的输入格式的信息，如HTML，这被描述为一般AFL方法的不足之处。</p>\n<p>Pradel等人评估了另一种结合深度学习以便在软件中发现错误的方法 [22]。他们使用训练有素的模型来分类潜在的错误源代码。因此，他们将他们的模型训练为特定错误类别的单独分类器。与之相反，我们训练模型生成输入，然后可以用来触发和观察软件中的错误。此外，他们的方法需要直接访问源代码，而我们需要访问足够的输入示例来训练RNN模型。</p>\n<h1 id=\"7-结论和未来工作\"><a href=\"#7-结论和未来工作\" class=\"headerlink\" title=\"7 结论和未来工作\"></a>7 结论和未来工作</h1><p>我们的工作提供了证据，证明可以使用堆叠的RNN生成HTML标签，以便为浏览器的渲染引擎进行模糊测试生成新的测试用例。结果还清楚地表明，即使训练参数较少，基于GRU的模型也能够胜过LSTM模型。此外，所提出的评估程序和基于相似性的分析表明，数据集与模型生成的测试用例之间的基本块的重叠平均非常低。此外，与简单突变组的重叠平均约为70％，这表明训练的网络能够发现以前未通过具有不同突变机会的幼稚突变方法发现的新代码路径。这提供了一个明确的证据，即只要应用合适的模型选择和分析程序，RNN就可以被训练并用作有效的HTML模糊器。</p>\n<p>我们目前正在寻求以至少三种方式扩展目前的工作：首先，研究更复杂/更合适的神经网络模型对于提高生成的HTML的整体质量是必要的，因为其他流行的Web技术（如JavaScript）不能用于破坏的HTML标签都有效。其次，重要的是验证当前关于真实HTML示例的工作的概括，与此处考虑的模糊器生成的训练数据形成对比。最后，我们正在探索在训练过程中利用收集的代码覆盖率数据的方法，并在发现意外行为或新代码路径时奖励学习算法。我们推测这可以通过强化学习来实现，以系统地权衡模型拟合与探索。</p>\n","categories":[{"name":"论文","slug":"论文","permalink":"http://yama0xff.com/categories/论文/"},{"name":"fuzzing","slug":"论文/fuzzing","permalink":"http://yama0xff.com/categories/论文/fuzzing/"},{"name":"机器学习","slug":"论文/fuzzing/机器学习","permalink":"http://yama0xff.com/categories/论文/fuzzing/机器学习/"}],"tags":[{"name":"fuzzing","slug":"fuzzing","permalink":"http://yama0xff.com/tags/fuzzing/"},{"name":"堆叠RNN","slug":"堆叠RNN","permalink":"http://yama0xff.com/tags/堆叠RNN/"},{"name":"2019","slug":"2019","permalink":"http://yama0xff.com/tags/2019/"}]},{"title":"NEUZZ: Efficient Fuzzing with Neural Program Smoothing","date":"2019-04-11T13:05:03.000Z","path":"2019/04/11/NEUZZ-Efficient-Fuzzing-with-Neural-Program-Smoothing/","text":"AbstractFuzzing已经成为发现软件漏洞的事实上的标准技术。然而，即使是最先进的模糊器也不能很有效地找到难以触发的软件错误。最流行的模糊器使用进化指导来生成可以触发不同错误的输入。这种进化算法虽然快速且易于实现，但常常陷入无效的随机突变序列中。梯度引导优化是进化指导的有前途的替代方案。梯度引导技术已经被证明通过有效利用基础函数的梯度或高阶导数来解决机器学习等领域中的高维结构优化问题，从而显着优于进化算法。然而，梯度引导方法不能直接应用于模糊测试，因为真实世界的程序行为包含许多不连续性，平台和脊，其中基于梯度的方法经常被卡住。我们观察到这个问题可以通过创建一个近似于目标程序的离散分支行为的平滑代理函数来解决。在本文中，我们提出了一种新的程序平滑技术，使用替代神经网络模型，可以逐步学习复杂的，真实世界的程序的分支行为的平滑近似。我们进一步证明，这种神经网络模型可以与梯度引导输入生成方案一起使用，以显着提高模糊测试过程的效率。我们的广泛评估表明，NEUZZ在发现新漏洞和实现更高边缘覆盖率方面，在10个流行的真实世界节目中明显优于10个最先进的灰盒模糊器。 NEUZZ发现31个先前未知的错误（包括两个CVE），其他模糊测试器在10个真实世界的程序中找不到，并且比24小时运行的所有测试的灰盒模糊器实现了3倍的边缘覆盖。此外，NEUZZ在LAVA-M和DARPA CGC bug数据集上也优于现有的模糊器。 relevant information 作者 Dongdong She, Kexin Pei, Dave Epstein, Junfeng Yang, Baishakhi Ray, and Suman Jana 单位 Columbia University 出处 IEEE S&amp;P 原文地址 https://arxiv.org/abs/1807.05620 源码地址 https://github.com/Dongdongshe/neuzz 发表时间 2019 1. 简介模糊测试已成为发现软件漏洞的事实上的标准技术[88]，[25]。模糊测试过程涉及生成随机测试输入并使用这些输入执行目标程序以触发潜在的安全漏洞[59]。由于其简单性和低性能开销，在许多真实世界的程序中，模糊测试在寻找不同类型的安全漏洞方面非常成功[3]，[1]，[30]，[70]，[11]，[78] 。尽管它们有巨大的希望，但流行的模糊测试器，特别是对于大型程序，往往会在尝试冗余测试输入时遇到困难，并且很难找到隐藏在程序逻辑深处的安全漏洞[82]，[36]，[68]。 从概念上讲，模糊测试是一个优化问题，其目标是找到程序输入，以最大化在给定量的测试时间内发现的漏洞数量[60]。然而，由于安全漏洞往往是稀疏且不规律地分布在程序中，因此大多数模糊测试器旨在通过最大化某种形式的代码覆盖（例如，边缘覆盖）来测试尽可能多的程序代码，以增加其发现安全漏洞的机会。最流行的模糊器使用进化算法来解决潜在的优化问题 - 生成最大化代码覆盖的新输入[88]，[11]，[78]，[45]。进化优化从一组种子输入开始，将随机突变应用于种子以生成新的测试输入，执行这些输入的目标程序，并且仅保留有希望的新输入（例如，那些实现新代码覆盖的输入）作为进一步突变的语料库。然而，随着输入语料库变大，进化过程在到达新代码位置时变得越来越低效。 进化优化算法的主要限制之一是它们不能利用底层优化问题的结构（即梯度或其他高阶导数）。梯度引导优化（例如，梯度下降）是一种很有前途的替代方法，已被证明在解决包括空气动力学计算和机器学习在内的各种领域中的高维结构优化问题时显着优于进化算法[89]，[46]，[ 38。 然而，梯度引导优化算法不能直接应用于模糊现实世界的程序，因为它们通常包含大量不连续行为（不能精确计算梯度的情况），因为不同程序分支的行为差别很大[67]，[ 21]，[43]，[20]，[22]。我们观察到可以通过创建近似于目标程序关于程序输入的分支行为的平滑（即，可微分）代理函数来克服该问题。不幸的是，现有的程序平滑技术[21]，[20]会产生令人望而却步的性能开销，因为它们严重依赖于符号分析，但是由于路径爆炸，不完整的环境建模和符号内存建模的大量开销等几个基本限制而无法扩展到大型程序50]，[77]，[14]，[16]，[15]，[35]，[49]。 在本文中，我们介绍了一种新颖，高效，可扩展的程序平滑技术，该技术使用前馈神经网络（NN），可以逐步学习复杂的，真实世界的程序分支行为的平滑近似，即预测控制流边缘。目标程序由特定的输入执行。我们进一步提出梯度引导搜索策略，其计算并利用平滑近似的梯度（即，NN模型）来识别目标突变位置，其可以最大化目标程序中检测到的错误的数量。我们演示了如何通过在错误预测的程序行为上逐步重新训练模型来改进NN模型。我们发现前馈神经网络是我们任务的自然拟合，因为（i）它们证明了近似复杂非线性函数的能力，如通用逼近定理[33]所暗示的，以及（ii）它们对有效和精确计算梯度/高阶导数[38]。 我们设计并实施了我们的技术，作为NEUZZ的一部分，NEUZZ是一种新的学习型模糊器。我们将NEUZZ与10个最先进的模糊器进行比较，包括6种不同的文件格式（例如，ELF，PDF，XML，ZIP，TTF和JPEG），平均为47.546行代码，LAVA-M bug数据集[28]和CGC数据集[26]。我们的结果表明，NEUZZ在检测到的错误和实现的边缘覆盖方面始终优于所有其他模糊器。 NEUZZ在其他模糊测试仪未能找到的测试程序中发现了31个以前未知的错误（包括CVE-2018-19931和CVE-2018-19932）。我们对DARPA CGC数据集的测试也证实，NEUZZ在发现不同的错误时可以胜过最先进的模糊器，如Driller [82]。 我们在本文中的主要贡献如下： 我们是第一个确定程序平滑的重要性，采用有效的梯度引导技术进行模糊测试。 我们引入了第一个使用替代神经网络的高效且可扩展的程序平滑技术，以有效地模拟目标程序的分支行为。我们进一步提出了一种增量学习技术，以在更多训练数据可用时迭代地改进替代模型。 我们证明了替代神经网络模型的梯度可用于有效地生成程序输入，从而最大化目标程序中发现的错误数量。 我们作为NEUZZ的一部分设计，实施和评估我们的技术，并证明它在各种实际程序以及策划的bug数据集上明显优于10个最先进的模糊器。 本文的其余部分安排如下。第二部分总结了有关优化和梯度引导技术的必要背景信息。第三部分概述了我们的技术以及一个激励性的例子。第IV节和第V节详细描述了我们的方法和实施。我们在第VI节中介绍了我们的实验结果，并描述了NEUZZ在第VII节中发现的一些样本错误。第八节总结了相关工作，第九节总结了论文 II.优化基础在本节中，我们首先描述优化的基础知识以及梯度引导优化相对于平滑函数的进化指导的益处。最后，我们演示了如何将模糊测试作为优化问题。 优化问题通常由三个不同的组件组成：参数x的向量，要最小化或最大化的目标函数F（x），以及一组约束函数Ci（x），每个约束函数包括必须满足的不等式或相等性。优化过程的目标是找到参数向量x的具体值，其最大化/最小化F（x），同时满足所有约束函数Ci（x），如下所示。 这里R，N和Q分别表示实数集，不等式约束指数和等式约束指数 函数平滑和优化。优化算法通常在循环中操作，从对参数向量x的初始猜测开始，并逐渐迭代以找到更好的解。任何优化算法的关键组件是它用于从一个x值移动到下一个值的策略。大多数策略利用目标函数F，约束函数Ci以及梯度/高阶导数（如果可用）的值。 不同优化算法收敛到最优解的能力和效率在很大程度上取决于目标和约束函数F和Ci的性质。通常，可以比具有许多不连续性（例如，脊或平台）的函数更有效地优化更平滑的函数（即，具有明确定义和可计算的导数的函数）。直观地，目标/约束函数越平滑，优化算法就越容易准确地计算梯度或高阶导数，并使用它们系统地搜索整个参数空间。 对于本文的其余部分，我们特别关注不具有任何约束函数的无约束优化问题，即C =φ，因为它们非常模仿模糊化，即我们的目标域。对于无约束平滑优化问题，梯度引导方法在解决高维结构优化问题时可以明显优于进化策略[89]，[46]，[38]。这是因为梯度引导技术有效地利用梯度/高阶导数有效地收敛到最优解，如图1所示。 凸度和梯度引导优化。对于称为凸函数的常见函数类，梯度引导技术非常高效，并且总能收敛到全局最优解[86]。直观地，如果连接函数图上任意两点的直线完全位于图上方或上方，则函数是凸的。更正式地，如果在其域中的所有点x和y满足以下属性，则函数f被称为凸函数：f（tx +（1-t）y）≤ tf（x）+（1-t）f （y）,存在 t 属于[0; 1]。 然而，在非凸函数中，梯度引导方法可能会陷入局部最优解，其中目标函数（假设目标是最大化）比所有附近的可行点更大但是在整个其他地方存在其他更大的值可行参数值的范围。然而，即使对于这种情况，简单的启发式方法，例如从新的随机选择的起始点重新启动梯度引导方法，已经证明在实践中非常有效[38]，[86]。 模糊作为无约束的优化。模糊测试可以表示为无约束优化问题，其目标是最大化测试程序中针对固定数量的测试输入发现的错误/漏洞的数量。因此，目标函数可以被认为是Fp（x），如果输入x在使用输入x执行目标程序p时触发错误/漏洞，则返回1。然而，这种函数太不正常（即，主要包含平坦的平台和一些非常尖锐的过渡）以便有效地优化。 因此，大多数灰盒模糊器试图最大化测试代码的数量（例如，最大化边缘覆盖）作为替代代理度量[88]，[11]，[73]，[55]，[22]。这样的目标函数可以表示为F’p（x），其中F’返回程序P的输入x所覆盖的新控制流边缘的数量。注意，F比原始函数F相对更容易优化。所有可能的程序输入执行新的控制流边缘往往明显高于触发错误/安全漏洞的输入。 大多数现有的灰盒模糊器使用进化技术[88]，[11]，[73]，[55]，[22]以及其他特定领域的启发式算法作为其主要的优化策略。在梯度引导优化中选择此类算法的关键原因是大多数真实世界的程序由于沿着不同程序路径的显着不同的行为而包含许多不连续性[19]。这种不连续性可能导致梯度引导优化陷入非最优解。在本文中，我们提出了一种新技术，使用神经网络平滑目标程序，使其适用于梯度引导优化，并演示模糊器如何利用这些策略来显着提高其效率。 III.我们的方法概述图2展示了我们方法的高级概述。我们将在下面详细介绍关键组件 神经程序平滑。平滑地逼近程序的不连续分支行为对于精确计算梯度引导优化所必需的梯度或高阶导数至关重要。没有这种平滑，梯度引导的优化过程可能会卡在不同的不连续性/平台上。平滑过程的目标是创建一个平滑的函数，该函数可以模拟程序的分支行为而不会引入大的错误（即，它与原始程序行为的偏差最小）。为此，我们使用前馈神经网络（NN）。正如通用逼近定理[33]所暗示的那样，NN非常适合近似任意复杂（可能是非线性和非凸）的程序行为。此外，NN在设计上也支持对我们的目的至关重要的有效梯度计算。我们通过使用现有的测试输入或现有的进化模糊器生成的测试输入语料库来训练NN，如图2所示。 梯度引导优化。一旦经过训练，平滑NN模型可用于有效地计算梯度和高阶导数，然后可利用这些导数更快地收敛到最优解。梯度下降，牛顿方法或类牛顿方法（如L-BFGS算法）的梯度制导算法的不同变体使用梯度或高阶导数来实现更快的收敛[10]，[13]，[65]。平滑NN使得模糊输入生成过程可以使用所有这些技术。在本文中，我们设计，实现和评估了一种简单的梯度引导输入生成方案，该方案适用于基于覆盖的模糊测试，详见第IV-C节。 增量学习。任何类型的现有测试输入（只要它们暴露目标程序中的不同行为）都可以用于训练NN模型并引导模糊输入生成过程。在本文中，我们通过运行像AFL这样的进化模糊器来收集一组测试输入和相应的边缘覆盖信息来训练NN。 然而，由于用于训练NN模型的初始训练数据可能仅涵盖程序空间的一小部分，我们在模糊测试期间观察到新的程序行为时通过增量训练进一步细化模型。增量训练的关键挑战是，如果NN只接受新数据的训练，它可能会完全忘记从旧数据中学到的规则[57]。我们通过设计一种新的基于覆盖的过滤方案来避免这个问题，该方案创建了新旧数据的精简摘要，允许NN在其上进行有效的培训。 一个激励的例子。我们在图3中展示了一个简单的激励示例，以展示我们的方法背后的关键洞察力。图3中显示的简单C代码片段演示了许多真实世界程序中常见的类似switch的代码模式。特别地，示例代码计算输入的非线性指数函数（即，pow（3，a + b））。它根据计算函数的输出范围返回不同的值。让我们假设如果函数输出范围在（1,2）中，则执行有缺陷的代码块（标记为红色）。 考虑像AFL这样的进化模糊器已经设法探索第2行和第9行中的分支但是未能在第5行探索分支的情况。这里的关键挑战是找到将在第5行触发分支的a和b的值。进化模糊器通常会遇到这样的代码，因为通过随机变异找到解决方案的可能性非常低。例如，图3a显示了代码段所代表的原始函数。函数表面从a + b = 0到a + b- e = 0（e -&gt; +0）。为了在模糊测试期间最大化边缘覆盖，进化模糊器只能对输入采用随机突变，因为这种技术不考虑函数表面的形状。相比之下，我们的NN平滑和梯度引导突变旨在利用梯度测量的函数表面形状。 我们从其他两个分支 训练NN模型的程序行为。 NN模型平滑地近似于程序行为，如图3b和3c所示。然后，我们使用NN模型执行更有效的梯度引导优化，以找到a和b的期望值，并逐步细化模型，直到找到执行目标错误的所需分支。 IV.方法我们在下面详细描述我们方案的不同组成部分。 A.程序平滑程序平滑是使梯度引导优化技术适用于模糊具有离散行为的真实世界程序的重要步骤。没有平滑，梯度引导优化技术对于优化非平滑函数不是非常有效，因为它们往往会陷入不同的不连续性[67]。平滑过程使这种不规则性最小化，因此使梯度引导优化在不连续功能上显着更有效。 通常，不连续函数 f 的平滑可以被认为是 f 和平滑掩模函数g之间的卷积运算，以产生如下所示的新的平滑输出函数。流行的平滑掩模的一些示例包括不同的高斯和Sigmoid函数。$$f’(x) = \\int_{-\\infty}^{+\\infty}f(a)g(x − a)da$$然而，对于许多实际问题，不连续函数f可能不具有闭合形式的表示，因此不可能分析地计算上述积分。在这种情况下，使用离散版本$$f’（x）= \\sum_a f（a）g（x-a）$$并且数值地计算卷积。例如，在图像平滑中，通常使用固定大小的2-D卷积核来执行这种计算。但是，在我们的设置中，f是计算机程序，因此无法通过分析计算相应的卷积。 程序平滑技术可分为两大类：黑盒和白盒平滑。黑盒方法从f的输入空间中选取离散样本，并使用这些样本以数字方式计算卷积。相比之下，白盒方法会查看程序语句/指令，并尝试使用符号分析和抽象解释来总结它们的效果[21]，[20]。黑盒方法可能会引入大的近似误差，而白盒方法会产生令人望而却步的性能开销，这使得它们对于真实世界的程序来说是不可行的。 为了避免这些问题，我们使用NN以灰盒方式学习程序行为的平滑近似（例如，通过收集边缘覆盖数据），如下所述。 B.神经程序平滑在本文中，我们对程序平滑提出了一种新的方法，通过使用代理NN模型来基于观察到的程序行为来学习和迭代地改进目标程序的平滑近似。替代神经网络可以平滑地推广到观察到的程序行为，同时还准确地建模潜在的非线性和非凸行为。一旦经过训练，神经网络可用于有效地计算梯度和更高级别的导数，以指导模糊输入生成过程，如图3所示。 为何选择NN？正如通用逼近定理[33]所暗示的那样，NN非常适合近似复杂（可能是非线性和非凸）的程序行为。使用NN来学习平滑程序近似的优点如下：（i）NN可以精确地模拟复杂的非线性程序行为并且可以被有效地训练。基于模型的优化的先前工作使用简单的线性和二次模型[24]，[23]，[71]，[52]。然而，这些模型不适合用于建模具有高度非线性和非凸性行为的真实软件; （ii）NN支持有效计算其梯度和高阶导数。因此，梯度引导算法可以在模糊测试期间计算和使用这些信息，而无需任何额外开销; （iii）NN可以概括并学习根据类似输入的行为来预测程序对看不见的输入的行为。因此，NN可以基于其对少量输入样本的行为来潜在地学习整个程序的平滑近似。NN训练。虽然NN可用于模拟程序行为的不同方面，但在本文中，我们专门用它们来建模目标程序的分支行为（即，预测由给定程序输入执行的控制流边缘）。使用神经网络对分支行为进行建模的挑战之一是需要接受可变大小的输入。与现实世界的程序不同，前馈NN通常接受固定大小的输入。因此，我们设置最大输入大小阈值，并在训练期间使用空字节填充任何较小尺寸的输入。请注意，支持更大的输入不是主要问题，因为现代NN可以轻松扩展到数百万个参数。因此，对于较大的程序，我们可以根据需要简单地增加阈值大小。然而，我们凭经验发现相对适度的阈值产生最佳结果，而较大的输入不会显着提高建模精度。 形式上，让f：{0x00，0×01,…, 0xff}^m^ -&gt; {0, 1}^n^ 表示将程序输入作为具有大小为m的字节序列的NN，并输出大小为n的边缘位图。设θ表示 f 的可训练权重参数。给定一组训练样本（X, Y），其中X是一组输入字节，Y代表相应的边缘覆盖位图，参数函数f（x,θ）= y的训练任务是获得参数θ ^$$ \\overlineθ =arg min_θ\\sum_{x\\in X,y\\in Y} L（y, f（x,θ））$$其中L（y, f（x,θ））定义NN的输出与训练集中的真实标签y ∈ Y之间的损失函数。训练任务是找到NN f的权重参数θ以最小化损失，其使用距离度量来定义。特别是，我们使用二进制交叉熵来计算预测位图和真实覆盖位图之间的距离。特别是，让 y i 和fi（x,θ）分别表示真实数据和 f 预测的输出位图中的第i位。然后，这两者之间的二元交叉熵定义为：$$−\\frac{1}{n}\\sum_{i=1}^n[y_i · log(f_i(x, θ) + (1 − y_i) · log(1 − f_i(x, θ)]$$在本文中，我们使用前馈完全连接的NN来模拟目标程序的分支行为。前馈架构允许高效计算梯度和快速训练[53]。 我们的平滑技术对于训练数据的来源是不可知的，因此可以对从现有输入语料库收集的任何边缘覆盖数据训练NN。对于我们的原型实现，我们使用现有的进化模糊器（如AFL）生成的输入语料库来训练我们的初始模型。 训练数据预处理。由训练数据执行的边缘覆盖通常倾向于偏差，因为它仅包含程序中所有边缘的一小部分的标签。例如，一些边缘可能总是由训练数据中的所有输入一起运用。一组标签之间的这种类型的相关性在机器学习中被称为多重共线性，这通常会阻止模型收敛到一个小的损失值[34]。为了避免这种情况，我们通过将总是一起出现在训练数据中的边缘合并到一个边缘来遵循降维的常见机器学习实践。此外，我们仅考虑在训练数据中至少激活一次的边缘。这些步骤将标签数量平均从大约65536大幅减少到4000左右。请注意，我们在每次增量学习迭代时重新运行数据预处理步骤，因此一些合并标签可能会因为在模糊测试期间发现新边缘数据时相关性降低而分裂。 C.梯度引导优化不同的梯度引导优化技术，如梯度下降，牛顿法或准牛顿法，如L-BFGS，可以使用梯度或更高阶导数来实现更快的收敛[10]，[13]，[65] 。平滑NN使得模糊输入生成过程可以通过支持梯度和高阶导数的有效计算来潜在地使用这些技术中的任何一种。在本文中，我们专门设计了一个简单的梯度引导搜索方案，该方案对于较小的预测误差具有鲁棒性，以证明我们的方法的有效性。我们将更复杂的技术探索作为未来的工作。 在描述基于NN梯度的变异策略之前，我们首先提供梯度的形式定义，指示每个输入字节应该改变多少以影响NN f 中最终层神经元的输出（指示改变的边缘覆盖范围在程序中）[80]。这里，每个输出神经元对应于特定边缘，并计算0和1之间的值，总结给定输入字节对特定边缘的影响。 NN f w.r.t.输出神经元的梯度。输入已广泛用于对抗性输入生成[39]，[66]和可视化/理解DNN [87]，[80]，[56]。直观地，在我们的设置中，基于梯度的指导的目标是找到将改变对应于从0到1的不同边缘的最终层神经元的输出的输入。 给定如IV-B部分中定义的参数NN y = f（θ,x），令 yi 表示 f 的最后一层中的第i个神经元的输出，其也可以写为fi（θ,x）。 fi（θ,x）相对于输入x的梯度G可以定义为G = ▽xfi（θ, x）= δyi / δx。注意，可以容易地计算 f 的梯度w.r.t到θ，因为NN训练过程需要迭代地计算该值以更新θ。因此，通过简单地将θ的梯度的计算替换为x的梯度，也可以容易地计算G.注意，梯度G的维数与输入x的维度相同，在我们的例子中，它是一个字节序列。 梯度引导优化。算法1显示了梯度引导输入生成过程的概要。关键思想是识别具有最高梯度值的输入字节并对其进行改变，因为它们表明对NN具有更高的重要性，因此具有更高的机会导致程序行为发生重大变化的机会（例如，翻转分支）。 从种子开始，我们迭代地生成新的测试输入。如算法1所示，在每次迭代时，我们首先利用梯度的绝对值来识别输入字节，该输入字节将导致对应于未捕获边缘的输出神经元的最大变化。接下来，我们检查每个字节的梯度符号以确定突变的方向（例如，递增或递减它们的值）以最大化/最小化目标函数。从概念上讲，我们对梯度符号的使用类似于[39]中介绍的对抗性输入生成方法。我们还将每个字节的变异限制在其合法范围内（0-255）。第6行和第10行表示使用剪辑功能来实现这种边界。 我们用一个小的变异目标（算法1中的k）开始输入生成过程，并指数增加要变异的目标字节数，以有效地覆盖大的输入空间。 D.通过增量学习进行细化梯度引导输入生成过程的效率在很大程度上取决于代理NN对目标程序的分支行为进行建模的准确程度。为了获得更高的准确度，当在模糊测试过程中观察到不同的程序行为时（即，当目标程序的行为与预测的行为不匹配时），我们逐步细化NN模型。我们使用增量学习技术通过在触发新边缘时学习新数据来更新NN模型。 NN改进背后的主要挑战是阻止NN模型在训练新数据时突然忘记先前从旧数据中学到的信息。这种遗忘是深度学习文献中众所周知的现象，并被认为是稳定性 - 可塑性困境的结果[58]，[8]。为了避免这种遗忘问题，NN必须足够改变权重以学习新任务，但不能过多地使其忘记以前学过的表示。 细化NN的最简单方法是将新训练数据（即程序分支行为）与旧数据一起添加，并再次从头开始训练模型。但是，随着数据点数量的增加，这种再训练变得更难以扩展。先前的研究试图主要使用两种广泛的方法来解决这个问题[44]，[51]，[31]，[75]，[29]，[40]，[76]。第一个尝试为新旧模型保留单独的表示，以最大限度地减少使用分布式模型，正则化或从多个模型中创建集合的遗忘。第二种方法维护旧数据的摘要，并在新数据上重新训练模型以及汇总的旧数据，因此比完全再训练更有效。我们将感兴趣的读者引用到Kemker等人的调查中。 [48]了解更多详情。 在本文中，我们使用基于边缘覆盖的过滤来仅保留触发新分支的旧数据以进行重新训练。随着新的训练数据变得可用，我们确定实现新边缘覆盖的数据，将它们与过滤的旧训练数据放在一起，并重新训练NN。这种方法有效地防止训练数据样本的数量在重新训练迭代次数上急剧增加。我们发现我们的过滤方案可以轻松支持多达50次重新训练，同时仍将训练时间保持在几分钟之内。 V.实现在本节中，我们将讨论我们的实现以及如何微调NEUZZ以实现最佳性能。我们已经通过GitHub在http://github.com/dongdongshe/neuzz发布了我们的实现。我们所有的测量都是在运行Arch Linux 4.9.48并使用Nvidia GTX 1080 Ti GPU的系统上进行的。 NN架构。我们的NN模型在Keras2.1.3 [5]中实现，Tensorflow-1.4.1 [6]作为后端。 NN模型由三个完全连接的层组成。隐藏层使用ReLU作为其激活功能。我们使用sigmoid作为输出层的激活函数来预测控制流边缘是否被覆盖。 NN模型被训练50个时期（即，整个数据集的50次完整通过）以实现高测试准确度（平均约95％）。由于我们使用简单的前馈网络，所有10个程序的训练时间不到2分钟。即使在运行频率为3.6GHz的Intel i7-7700上进行纯CPU计算，训练时间也不到20分钟。 训练数据收集。对于每个测试的程序，我们在单个核心机器上运行AFL-2.5.2 [88]一小时，以收集NN模型的训练数据。为10个项目收集的平均训练输入数量约为2K。得到的语料库进一步分为训练和测试数据，比例为5：1，其中测试数据用于确保模型不会过度拟合。我们使用10KB作为阈值文件大小，用于从AFL输入语料库中选择我们的训练数据（平均90％的AFL生成的文件低于阈值）。 突变和再培训。如图2所示，NEUZZ迭代运行以生成1M突变并逐步重新训练NN模型。我们首先使用算法1中描述的变异算法来生成1M突变。我们将参数 i 设置为10，为种子输入生成5,120个突变输入。接下来，我们在目标程序中随机选择代表100个未探测边缘的100个输出神经元，并从两个种子生成10,240个突变输入。最后，我们使用AFL的fork服务器技术[54]执行具有1M突变输入的目标程序，并使用覆盖新边缘的任何输入进行增量重新训练。 模型参数选择。 NEUZZ的成功取决于训练模型和产生突变的不同参数的选择。在这里，我们通过经验探索确保最佳边缘覆盖四个程序的最佳参数：readelf，libjpeg，libxml和mupdf。结果总结在表I中。 首先，我们评估每个初始种子需要突变的关键字节数（算法1的第1行中的参数ki）。我们选择k = 2，如第IV-C节所述，并显示通过三次迭代（i = 7,10,11算法1第1行中的）实现的覆盖率，每次迭代有1M个突变。对于所有四个程序，较小的突变（每个突变更改的字节更少）可能导致更高的代码覆盖率，如表1a所示。 i = 11的最大值实现了所有四个程序的最小代码覆盖率。这个结果可能是由于算法1中的第4和第8行 - 在单个种子上浪费了太多突变（超出1M突变预算），而没有尝试其他种子。但是，最佳突变字节数在四个程序中有所不同。对于readelf和libxml，i的最佳值为10，而libjpeg和mupdf的最佳值为7。由于在i = 7和i = 10之间实现的代码覆盖率的差异不大，我们选择i = 10用于剩余的实验。 接下来，我们通过改变每个隐藏层中的层数和神经元数来评估NN模型中超参数的选择。特别地，我们将NN架构分别与每层的1和3个隐藏层以及4096和8192个神经元进行比较。对于每个目标计划，我们使用相同的训练数据来训练四种不同的NN模型并生成1M突变以测试所实现的边缘覆盖。对于所有四个程序，我们发现具有1个隐藏层的模型比具有3个隐藏层的模型执行得更好。我们认为这是因为1隐藏层模型足够复杂以模拟目标程序的分支行为，而较大的模型（即具有3个隐藏层）相对较难训练并且还倾向于过度拟合。 VI.评估在本节中，我们评估NEUZZ的错误发现性能，并获得与其他最先进的模糊器相关的边缘覆盖率。具体来说，我们回答以下四个研究问题： RQ1. NEUZZ可以找到比现有模糊器更多的错误吗？ RQ2. NEUZZ能否实现比现有模糊器更高的边缘覆盖？ RQ3. NEUZZ能否比现有的基于RNN的模糊器表现更好？ RQ4.不同的模型选择如何影响NEUZZ的性能？ 我们首先描述我们的研究对象和实验设置。 A.研究对象我们在三种不同类型的数据集上评估NEUZZ：（i）10个真实世界的程序，如表IIb所示，（ii）LAVA-M [28]，以及（iii）DARPA CGC数据集[26] 。为了演示NEUZZ的性能，我们将NEUZZ检测到的边缘覆盖范围和缺陷数量与10个最先进的模糊器进行比较，如表IIa所示。 B.实验设置我们的实验设置包括以下两个步骤：首先，我们运行AFL一小时以生成初始种子语料库。然后，我们使用相同的初始种子语料库运行每个模糊器一个固定的时间预算，并比较它们实现的边缘覆盖率和发现的错误数量。具体而言，10个真实世界程序，LAVA-M数据集和CGC数据集的时间预算分别为24小时，5小时和6小时。对于进化模糊器，种子语料库用于初始化模糊过程。对于基于学习的模糊器（即，基于NEUZZ和RNN的模糊器），使用相同的种子语料库来生成训练数据集。对于KleeFL，一种由Klee和AFL组成的混合工具，我们运行Klee一小时以生成额外的种子，然后将它们添加到原始种子语料库中，用于随后的24小时模糊测试过程。请注意，我们仅报告每个模糊器的变异输入所涵盖的附加代码，而不包括初始种子语料库中的覆盖信息。 在RQ3中，我们评估和比较NEUZZ与基于RNN的模糊器的性能。基于RNN的模糊器比NEUZZ的训练时间长20倍。然而，为了关注这两种突变算法的功效，我们评估固定数量突变的边缘覆盖率，以排除这些不同的训练时间的影响。我们还进行了独立评估，比较了这两种模型的训练时间成本。在RQ4中，我们还评估了固定数量突变的边缘覆盖率，以排除不同模型中不同训练时间成本的影响。 C.结果RQ1. NEUZZ可以找到比现有模糊器更多的错误吗？为了回答这个RQ，我们评估了NEUZZ w.r.t.三种设置中的其他模糊器：（i）检测现实世界中的错误。 （ii）检测LAVA-M数据集中注入的错误[28]。 （iii）检测CGC错误。我们详细描述结果。 （i）检测现实世界的错误。我们比较了NEUZZ和其他模糊器在24小时运行时发现的错误和崩溃的总数，给出相同的种子语料库。 NEUZZ和其他模糊器发现了五种不同类型的错误：内存不足，内存泄漏，断言崩溃，整数溢出和堆溢出。为了检测不一定会导致崩溃的内存错误，我们使用AddressSanitizer [4]编译程序二进制文件。我们通过比较AddressSanitizer报告的堆栈跟踪来测量发现的唯一内存错误。对于不会导致AddressSanitizer生成错误报告的崩溃，我们会检查执行跟踪。通过手动分析触发无限循环的输入找到整数溢出错误。我们使用未定义的行为清理程序进一步验证整数溢出错误[7]。结果总结在表III中。 NEUZZ在6个程序中查找所有5种类型的错误。 AFL，AFLFast和AFL-laf-intel发现了3种类型的错误 - 它们没有找到任何整数溢出错误。其他模糊器只发现2种类型的错误（即内存泄漏和断言崩溃）。 AFL可以在程序size上出现堆溢出错误，而NEUZZ可以在程序nm上找到相同的错误和另一个堆溢出错误。总的来说，NEUZZ发现的错误比第二个最好的模糊器多2倍。此外，strip中的整数溢出错误和nm中的堆溢出错误（仅由NEUZZ发现）已经分配了CVE-2018-19932和CVE-2018-19931，后来由开发人员修复。 （ii）检测LAVA-M数据集中注入的错误。创建LAVA数据集是为了通过提供一组注入大量错误的真实程序来评估模糊器的有效性[28]。 LAVA-M是LAVA数据集的子集，由4个GNU coreutil程序base64，md5sum，uniq和who分别注入44,57,28和2136个错误组成。所有的错误都受到四字节magic比较的保护。只有满足条件时才会触发错误。我们将NEUZZ在发现这些缺陷方面的性能与其他最先进的模糊器进行比较，如表IV所示。按照传统做法[22]，[28]，我们使用5小时的时间预算来完成模糊器的运行时间。 触发LAVA数据集中的magiv条件对于覆盖引导的模糊器来说是一项艰巨的任务，因为模糊器必须在256^4^种可能情况下生成4个连续字节的精确组合。为了解决这个问题，我们使用了一个定制的LLVM传递来检测magic字节检查，如Steelix [55]。但与Steelix不同，我们利用NN的渐变来指导输入生成过程，以找到满足magic检查的输入。我们运行AFL一小时来生成训练数据并用它来训练NN，其梯度识别触发magic字节条件的第一个字节比较的可能关键字节。接下来，我们对与第一个关键字节相邻的每个字节执行局部穷举搜索，以便通过256次尝试解决剩余的三个字节比较中的每一个。因此，我们需要一个NN梯度计算来查找影响魔法检查的字节位置，并且需要4×256 = 1024个试验来触发每个bug。对于程序md5sum，根据LAVA-M作者的最新建议[27]，我们进一步将种子减少到单行，这显着提高了模糊性能。 如表IV所示，NEUZZ查找程序base64，md5sum和uniq中的所有错误，以及程序的错误数量最多。请注意，LAVA-M作者在所有4个程序中都留下了一些未列出的错误，因此NEUZZ发现的错误总数实际上高于列出的错误数，如结果所示。 与其他模糊器相比，NEUZZ具有两个关键优势。首先，NEUZZ将搜索空间分成多个可管理的步骤：NEUZZ在AFL生成的数据上训练底层NN，使用计算的梯度到达第一个关键字节，并在找到的关键区域周围执行本地搜索。其次，与VUzzer相反，VUzzer利用目标二进制中硬编码的magic来构建程序输入，NEUZZ的基于梯度的搜索策略不依赖于任何硬编码的magic。因此，它可以找到程序md5sum中的所有错误，它在magic检查之前对输入字节执行一些计算，导致VUzzer失败。Angora（LAVA-M数据集当前最先进的模糊器）相比，NEUZZ在md5sum中发现了3个更多的错误。与Angora不同，NEUZZ使用NN渐变来更有效地触发复杂的magic条件 （iii）检测CGC错误。 DARPA CGC数据集[2]由DARPA网络大挑战中使用的易受攻击的程序组成。这些程序实现为执行各种任务的网络服务，旨在镜像具有已知漏洞的实际应用程序。程序中的每个错误都受到输入上的一些健全性检查的保护。 数据集附带一组输入作为漏洞的证据。 我们在50个随机选择的CGC二进制文件中评估NEUZZ，Driller和AFL。由于为每个模糊器运行每个测试二进制文件需要6个小时才能在CPU / GPU上运行，并且我们有限的GPU资源不允许我们并行执行多个实例，我们随机选择50个程序以将总实验时间保持在合理的范围内。与LAVA-M类似，这里我们也运行AFL一小时来生成训练数据并用它来训练NN。我们为所有三个模糊器提供相同的随机种子，让它们运行六个小时。 NEUZZ使用与LAVA-M数据集相同的自定义LLVM传递来检测CGC二进制文件中的magic检查。 结果（表五）显示，NEUZZ在50个二进制文件中发现31个错误的二进制文件，而AFL和Driller分别找到21个和25个。 NEUZZ发现的有缺陷的二进制文件包括Driller和AFL发现的所有文件。 NEUZZ进一步发现6个新的二进制文件中的错误，AFL和Driller都无法检测到这些错误。 我们分析了一个示例程序CROMU_00027（如清单1所示）。这是一个ASCII内容服务器，它从客户端获取查询并提供相应的ASCII代码。在用户尝试将命令设置为VISUALIZE后，将触发空指针解除引用错误。 AFL未能在6小时的时间预算内检测到这个错误，因为它在猜测magic字符串方面效率低下。虽然Driller试图通过concolic执行来满足这种复杂的魔术字符串检查，但在这种情况下，它无法找到满足检查的输入。相比之下，NEUZZ可以轻松使用NN渐变来定位程序输入中影响magic比较的关键字节，并找到满足magic检查的输入。 结果1：NEUZZ在6个不同的程序中找到了31个以前未知的错误，其他模糊器找不到。NEUZZ在寻找LAVA-M和CGC漏洞方面也优于最先进的模糊器 RQ2. NEUZZ能否实现比现有模糊器更高的边缘覆盖？为了研究这个问题，我们比较了24小时固定运行时预算的模糊器。此评估不仅显示模糊器发现的新边缘总数，还显示新边缘覆盖的速度与时间的关系。 我们从AFL的边缘覆盖率报告中收集边缘覆盖率信息。结果总结在表VI中。对于所有10个真实世界的节目，NEUZZ在边缘覆盖方面明显优于其他模糊器。如图4所示，NEUZZ在第一个小时内可以比其他模糊器获得更多的新边缘覆盖。在程序strip，harfbuz和readelf，NEUZZ在一小时内可以达到1000以上新的边缘覆盖。对于程序readelf和objdump，NEUZZ运行1小时的新边缘覆盖数量甚至超过所有其他模糊器24小时运行的新边缘覆盖数量。这表明NEUZZ具有优越的边缘覆盖能力。对于所有10个节目中的9个，NEUZZ分别实现了比基线AFL 6×，1.5×，9×，1.8×，3.7×，1.9×，10×，1.3×和3×边缘覆盖，以及4.2×，1.3× ，7×，1.2×，2.5×，1.5×，1.5×，1.3×和3×边缘覆盖率均高于所有6个模糊器中的第二高数量。对于代码小于2k的最小程序zlib，NEUZZ与其他模糊器实现了类似的边缘覆盖。我们相信它会在24小时模糊测试后发现这样一个小程序的大部分可能边缘时达到饱和点。显着的优异性能显示了NEUZZ使用渐变覆盖新边缘有效定位和突变关键字节的有效性。 NEUZZ在大型系统中也可以很好地扩展。实际上，对于超过10K行的程序（例如，readelf，harfbuzz，mupdf和libxml），NEUZZ实现了最高的边缘覆盖，其中采用污点辅助的fuzzer（即VUzzer）和符号执行辅助fuzzer（即KleeFL）执行较差或并不能扩展。 梯度引导变异策略允许NEUZZ探索不同的边缘，而其他基于进化的模糊器经常卡住并重复检查相同的分支条件。此外，NN平滑技术的最小执行开销有助于NEUZZ在较大程序中很好地扩展，而其他高级进化模糊器由于使用了重量级程序分析技术（如污点跟踪或符号执行）而导致高执行开销。 在进化模糊器中，AFLFast使用优化的种子选择策略，更多地关注稀有边缘，因此在8个程序中实现比AFL更高的覆盖率，特别是在libjpeg，size和harfbuzz中。另一方面，VUzzer在小程序（例如，zlib，nm，objdump，size和strip）的第一个小时内实现了比AFL，AFLFast和AFL-laf-intel更高的覆盖率，但它的导致很快停止并且最终是超过其他模糊器。同时，VUzzer的性能会因readelf，harfbuzz，libxml和mupdf等大型程序而降低。我们怀疑VUzzer的污点跟踪器引入的不精确会导致它在大型程序上表现不佳。 KleeFL使用符号执行引擎Klee生成的其他种子来指导AFL的探索。与VUzzer类似，对于小程序（nm，objdump和strip），KleeFL在开始时具有良好的性能，但其在Klee的额外种子的优势在几小时后逐渐消失。此外，KleeFL基于Klee，无法扩展到具有复杂库代码的大型程序，这是众所周知的符号执行限制。因此，KleeFL在程序libxml，mupdf和harfbuzz上没有结果。与VUzzer和KleeFL不同，NEUZZ不依赖任何繁重的程序分析技术; NEUZZ使用从NN计算的梯度来生成有希望的突变，即使对于较大的程序也是如此。有效的NN梯度计算过程允许NEUZZ在识别影响不同看不见的程序分支的关键字节时比VUzzer和KleeFL更好地扩展，从而实现更多的边缘覆盖。 AFL-laf-intel使用LLVM传递将复杂的magic比较转换为嵌套的字节比较，然后在转换的二进制文件上运行AFL。它在程序strip上实现了第二高的新边缘覆盖率。但是，比较转换会为常见的比较操作添加额外的指令，从而导致潜在的边缘爆炸问题。边缘爆炸大大增加了边缘冲突的速度，并且损害了进化模糊的表现。此外，这些附加指令会导致额外的执行开销。结果，像频繁比较操作的libjpeg这样的程序遭受显着的减速（例如，libjpeg），并且AFL-laf-intel努力触发新的边缘。 结果2：与其他灰盒式模糊器相比，NEUZZ可以实现更高的边缘覆盖率（比AFL高4倍，比24小时运行的第二好的高出2.5倍） RQ3.NEUZZ能否比现有的基于RNN的模糊器表现更好？现有的基于递归神经网络（RNN）的模糊器从过去的模糊测试经验中学习突变模式，以指导未来的突变[72]。这些模型首先从AFL生成的大量突变输入中学习突变模式（由关键字节组成）。接下来，他们使用突变模式为AFL构建一个过滤器，它只允许关键字节上的突变通过，否决所有其他非关键字节突变。我们选择了之前研究的4个项目来评估NEUZZ与基于RNN的模糊器相比100万个突变的性能。我们使用相同的训练数据训练两个NN模型，然后让两个基于NN的模糊器运行产生100万个突变，并比较两种方法实现的新代码覆盖率。我们报告了实现的边缘覆盖率和训练时间，如表VII所示。 对于所有四个程序，NEUZZ在1M突变方面明显优于基于RNN的模糊器。 NEUZZ比四个程序中基于RNN的模糊器达分别达到8.4×， 4.2×，6.7×和3.7×更多的边缘覆盖。此外，基于RNN的模糊器平均比NEUZZ多20倍的训练开销，因为RNN模型比前馈网络模型复杂得多。 基于RNN的模糊器与AFL的另外比较表明，使用1小时语料库，前者在libxml和mupdf上的平均边缘覆盖率比AFL高2倍。我们还观察到基于RNN的模糊器否决了AFL产生的大约50％的突变。因此，来自基于RNN的模糊器的1M突变的新边缘覆盖可以实现普通AFL中2M突变的边缘覆盖。这就解释了为什么基于RNN的模糊器在一些程序中发现AFL的新边缘增加了2倍左右。如果AFL在2M突变后卡住，基于RNN的模糊器也会在1M过滤突变后卡住。 NEUZZ相对于基于RNN的模糊器的关键优势在于，NEUZZ使用基于神经网络的梯度引导搜索获得关键位置，而RNN模糊器尝试以端到端方式对任务进行建模。我们的模型可以区分RNN模型可能遗漏的关键字节的不同影响因素，如我们的实验结果所示。对于突变生成，我们对由相应的贡献因子确定的关键字节进行穷举搜索，而基于RNN的模糊器仍然依赖于AFL的均匀随机突变。 结果3：NEUZZ，一个基于简单前馈网络的模糊器，通过在不同项目中实现3.7倍到8.4倍的边缘覆盖率，明显优于基于RNN的模糊器 RQ4.不同的型号选择如何影响NEUZZ的性能？NEUZZ的模糊测试性能在很大程度上取决于训练有素的NN的准确性。如第五部分所述，我们凭经验发现具有1个隐藏层的NN模型足以表达真实世界程序的复杂分支行为。在本节中，我们通过探索1个隐藏层架构的不同模型设置来进行消融研究，即，线性模型，没有细化的NN模型，以及具有渐进细化的NN模型。我们评估这些模型对NEUZZ性能的影响。 为了比较模糊测试性能，我们在4个程序中为每个版本的NEUZZ生成1M突变。我们通过去除隐藏层中使用的非线性激活函数来实现线性模型，从而使整个前馈网络完全线性化。 NN模型由AFL训练相同的种子语料库。接下来，我们从被动学习模型中生成1M突变，并测量这些1M突变所实现的边缘覆盖。最后，我们筛选出突变的输入，这些输入在100万个突变中运行看不见的边缘，并将这些选择的输入添加到原始种子语料库中，以递增地重新训练另一个NN模型并使用它来产生进一步的突变。结果总结在表VIII中。我们可以看到，两个NN模型（有或没有增量学习）都优于所有4个测试程序的线性模型。这表明非线性NN模型可以比简单的线性模型更好地逼近程序行为。我们还观察到增量学习有助于NN实现更高的准确度，从而提高边缘覆盖率。 结果4：NN模型优于线性模型，增量学习使NN随着时间的推移更加准确。 VII. BUGS的案例研究在本节中，我们提供和分析NEUZZ发现的三种不同类型的错误的样本：整数溢出，内存不足和崩溃诱发错误。我们注意到，由于对极值变量的错误处理导致了大量的程序错误。由于NEUZZ可以枚举从0x00到0xff的所有关键字节（参见算法1第3行），我们设法找到由错误处理的极值引起的大量错误。例如，通过将影响内存分配大小的输入字节设置为极大值，NEUZZ能够在libjpeg，objdump，nm和strip中找到许多内存不足的错误。 strip的整数溢出。 NEUZZ发现了一个整数溢出错误，可以在strip上产生无限循环。清单2显示了strip程序中的一个函数，它解析输入ELF文件的程序头表中的每个部分，并将所有部分分配给输出ELF文件中的新程序头表。整数溢出发生在清单2的第11行的if条件中，因为NEUZZ将segment_size设置为一个非常大的值。因此，程序陷入无限循环。我们发现在最新版本的Binutils 2.30和旧版本2.26和2.29中都存在此错误。 libjpeg的内存不足。在JPEG压缩过程中，每个颜色空间的数据通过相应的采样因子进行下采样，以减小文件大小。根据JPEG标准，采样因子必须是1到4之间的整数。在解压缩过程中使用此值来确定需要分配多少内存，如清单4所示.NEUZZ设置一个较大的值，导致过多要为图像数据分配的内存，导致内存不足错误。利用libjpeg显示图像，可能会利用此类错误在服务器上启动拒绝服务攻击。 readelf的崩溃。 ELF文件由文件头，程序头，节头和节数据组成。根据ELF规范，ELF头包含位于第60个字节的字段e_shnum，用于64位二进制，它指定ELF文件中的节数。 NEUZZ将输入文件的节数设置为0.如清单3所示，如果节的数量等于0，则实现返回一个NULL指针，该指针被后续代码取消引用，触发崩溃 VIII .相关工作程序平滑。 Parnas等 [67]观察到不连续性是开发安全可靠软件背后的基本挑战之一。 Chaudhury等人 [21]，[18]，[19]提出了程序平滑的想法，以促进程序分析，并使用抽象解释和符号执行提出了严格的平滑算法。不幸的是，这种算法会产生过高的性能开销，特别是对于大型程序。相比之下，我们的平滑技术利用NN的学习能力来实现更好的可扩展性。 基于学习的模糊测试。最近，人们越来越关注使用机器学习技术来改进模糊器[37]，[72]，[84]，[9]，[81]，[12]，[64]。然而，现有的基于学习的模糊器将模糊测试模型化为端到端ML问题，即，他们学习ML模型以直接预测可以实现更高代码覆盖的输入模式。相比之下，我们首先使用NN平滑地逼近程序分支行为，然后利用梯度引导输入生成技术来实现更高的覆盖范围。因此，我们的方法比ML模型更容忍学习错误而不是端到端方法。在本文中，我们凭经验证明我们的策略在发现错误和实现更高边缘覆盖方面优于端到端建模[72]。 基于污点的模糊测试。几个进化模糊器试图使用污点信息来识别有希望的变异位置[85]，[42]，[63]，[73]，[55]，[22]。例如，TaintScope [85]旨在识别影响系统/库调用的输入字节，并专注于改变这些字节。同样，Dowser [42]和BORG [63]专门使用污点信息来分别检测缓冲区边界违规和缓冲区过度读取漏洞。相比之下，Vuzzer [73]通过静态分析捕获magic常数，并将现有值变为这些常数。 Steelix [55]使用二进制文件来收集有关比较指令的其他污点信息。最后，Angora [22]使用动态污点跟踪来识别有希望的突变位置并执行坐标下降以指导这些位置上的突变。 然而，所有这些基于污点追踪的方法基本上受限于动态污点分析导致非常高的开销而静态污点分析遭受高误报率的事实。我们的实验结果表明，NEUZZ通过使用神经网络识别有希望的突变位置，轻松胜过现有的基于污点的现有模糊器。 一些模糊测试器和测试输入发生器[43]，[83]，[22]试图直接在目标程序上使用不同形式的梯度引导优化算法。然而，如果没有程序平滑，这种技术往往会挣扎并陷入不连续性。 符号/执行的执行。符号和执行执行[50]，[14]，[77]，[61]，[36]使用可满足模数理论（SMT）求解器来解决路径约束并找到有趣的测试输入。一些项目也尝试将模糊测试与这些方法相结合[17]，[32]，[82]。不幸的是，由于符号分析的几个基本限制，包括路径爆炸，不完整的环境建模，符号记忆建模的大量开销等，这些方法在实践中难以扩展[16]。 与我们的工作同时，NEUEX [79]通过使用NN学习程序的中间变量之间的依赖关系以及使用梯度引导神经约束求解在结合传统的SMT求解器，使符号执行更有效。相比之下，在本文中，我们专注于使用NN来提高模糊效率，因为它是迄今为止在大型真实世界程序中发现安全关键错误的最流行的技术。 神经程序。神经程序本质上是一个神经网络，它学习目标程序逻辑的潜在表示。最近的一些工作已经从程序的输入输出样本中合成了这样的神经程序，以准确地预测程序的新输入输出[41]，[74]，[62]。相比之下，我们使用NN来学习程序分支行为的平滑近似。 IX 结论我们提出了NEUZZ，一种有效的学习型模糊器，它使用代理神经网络来平滑地逼近目标程序的分支行为。我们进一步演示了梯度引导技术如何用于生成新的测试输入，可以发现目标程序中的不同错误。我们的广泛评估表明，NEUZZ在检测到的错误数量和边缘覆盖率方面明显优于其他10个最先进的模糊器。我们的研究结果表明，利用不同的梯度引导输入生成技术和神经平滑技术可以显着提高模糊过程的有效性。","content":"<h1 id=\"Abstract\"><a href=\"#Abstract\" class=\"headerlink\" title=\"Abstract\"></a>Abstract</h1><p>Fuzzing已经成为发现软件漏洞的事实上的标准技术。然而，即使是最先进的模糊器也不能很有效地找到难以触发的软件错误。最流行的模糊器使用进化指导来生成可以触发不同错误的输入。这种进化算法虽然快速且易于实现，但常常陷入无效的随机突变序列中。梯度引导优化是进化指导的有前途的替代方案。梯度引导技术已经被证明通过有效利用基础函数的梯度或高阶导数来解决机器学习等领域中的高维结构优化问题，从而显着优于进化算法。然而，梯度引导方法不能直接应用于模糊测试，因为真实世界的程序行为包含许多不连续性，平台和脊，其中基于梯度的方法经常被卡住。我们观察到这个问题可以通过创建一个近似于目标程序的离散分支行为的平滑代理函数来解决。在本文中，我们提出了一种新的程序平滑技术，使用替代神经网络模型，可以逐步学习复杂的，真实世界的程序的分支行为的平滑近似。我们进一步证明，这种神经网络模型可以与梯度引导输入生成方案一起使用，以显着提高模糊测试过程的效率。我们的广泛评估表明，NEUZZ在发现新漏洞和实现更高边缘覆盖率方面，在10个流行的真实世界节目中明显优于10个最先进的灰盒模糊器。 NEUZZ发现31个先前未知的错误（包括两个CVE），其他模糊测试器在10个真实世界的程序中找不到，并且比24小时运行的所有测试的灰盒模糊器实现了3倍的边缘覆盖。此外，NEUZZ在LAVA-M和DARPA CGC bug数据集上也优于现有的模糊器。</p>\n<table>\n<thead>\n<tr>\n<th>relevant information</th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><em>作者</em></td>\n<td>Dongdong She, Kexin Pei, Dave Epstein, Junfeng Yang, Baishakhi Ray, and Suman Jana</td>\n</tr>\n<tr>\n<td><em>单位</em></td>\n<td>Columbia University</td>\n</tr>\n<tr>\n<td><em>出处</em></td>\n<td>IEEE S&amp;P</td>\n</tr>\n<tr>\n<td><em>原文地址</em></td>\n<td><a href=\"https://arxiv.org/abs/1807.05620\" target=\"_blank\" rel=\"noopener\">https://arxiv.org/abs/1807.05620</a></td>\n</tr>\n<tr>\n<td><em>源码地址</em></td>\n<td><a href=\"https://github.com/Dongdongshe/neuzz\" target=\"_blank\" rel=\"noopener\">https://github.com/Dongdongshe/neuzz</a></td>\n</tr>\n<tr>\n<td><em>发表时间</em></td>\n<td>2019</td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"1-简介\"><a href=\"#1-简介\" class=\"headerlink\" title=\"1. 简介\"></a>1. 简介</h1><p>模糊测试已成为发现软件漏洞的事实上的标准技术[88]，[25]。模糊测试过程涉及生成随机测试输入并使用这些输入执行目标程序以触发潜在的安全漏洞[59]。由于其简单性和低性能开销，在许多真实世界的程序中，模糊测试在寻找不同类型的安全漏洞方面非常成功[3]，[1]，[30]，[70]，[11]，[78] 。尽管它们有巨大的希望，但流行的模糊测试器，特别是对于大型程序，往往会在尝试冗余测试输入时遇到困难，并且很难找到隐藏在程序逻辑深处的安全漏洞[82]，[36]，[68]。</p>\n<p>从概念上讲，模糊测试是一个优化问题，其目标是找到程序输入，以最大化在给定量的测试时间内发现的漏洞数量[60]。然而，由于安全漏洞往往是稀疏且不规律地分布在程序中，因此大多数模糊测试器旨在通过最大化某种形式的代码覆盖（例如，边缘覆盖）来测试尽可能多的程序代码，以增加其发现安全漏洞的机会。最流行的模糊器使用进化算法来解决潜在的优化问题 - 生成最大化代码覆盖的新输入[88]，[11]，[78]，[45]。进化优化从一组种子输入开始，将随机突变应用于种子以生成新的测试输入，执行这些输入的目标程序，并且仅保留有希望的新输入（例如，那些实现新代码覆盖的输入）作为进一步突变的语料库。然而，随着输入语料库变大，进化过程在到达新代码位置时变得越来越低效。</p>\n<p>进化优化算法的主要限制之一是它们不能利用底层优化问题的结构（即梯度或其他高阶导数）。梯度引导优化（例如，梯度下降）是一种很有前途的替代方法，已被证明在解决包括空气动力学计算和机器学习在内的各种领域中的高维结构优化问题时显着优于进化算法[89]，[46]，[ 38。</p>\n<p>然而，梯度引导优化算法不能直接应用于模糊现实世界的程序，因为它们通常包含大量不连续行为（不能精确计算梯度的情况），因为不同程序分支的行为差别很大[67]，[ 21]，[43]，[20]，[22]。我们观察到可以通过创建近似于目标程序关于程序输入的分支行为的平滑（即，可微分）代理函数来克服该问题。不幸的是，现有的程序平滑技术[21]，[20]会产生令人望而却步的性能开销，因为它们严重依赖于符号分析，但是由于路径爆炸，不完整的环境建模和符号内存建模的大量开销等几个基本限制而无法扩展到大型程序50]，[77]，[14]，[16]，[15]，[35]，[49]。</p>\n<p>在本文中，我们介绍了一种新颖，高效，可扩展的程序平滑技术，该技术使用前馈神经网络（NN），可以逐步学习复杂的，真实世界的程序分支行为的平滑近似，即预测控制流边缘。目标程序由特定的输入执行。我们进一步提出梯度引导搜索策略，其计算并利用平滑近似的梯度（即，NN模型）来识别目标突变位置，其可以最大化目标程序中检测到的错误的数量。我们演示了如何通过在错误预测的程序行为上逐步重新训练模型来改进NN模型。我们发现前馈神经网络是我们任务的自然拟合，因为（i）它们证明了近似复杂非线性函数的能力，如通用逼近定理[33]所暗示的，以及（ii）它们对有效和精确计算梯度/高阶导数[38]。</p>\n<p>我们设计并实施了我们的技术，作为NEUZZ的一部分，NEUZZ是一种新的学习型模糊器。我们将NEUZZ与10个最先进的模糊器进行比较，包括6种不同的文件格式（例如，ELF，PDF，XML，ZIP，TTF和JPEG），平均为47.546行代码，LAVA-M bug数据集[28]和CGC数据集[26]。我们的结果表明，NEUZZ在检测到的错误和实现的边缘覆盖方面始终优于所有其他模糊器。 NEUZZ在其他模糊测试仪未能找到的测试程序中发现了31个以前未知的错误（包括CVE-2018-19931和CVE-2018-19932）。我们对DARPA CGC数据集的测试也证实，NEUZZ在发现不同的错误时可以胜过最先进的模糊器，如Driller [82]。</p>\n<p>我们在本文中的主要贡献如下：</p>\n<ul>\n<li>我们是第一个确定程序平滑的重要性，采用有效的梯度引导技术进行模糊测试。</li>\n<li>我们引入了第一个使用替代神经网络的高效且可扩展的程序平滑技术，以有效地模拟目标程序的分支行为。我们进一步提出了一种增量学习技术，以在更多训练数据可用时迭代地改进替代模型。</li>\n<li>我们证明了替代神经网络模型的梯度可用于有效地生成程序输入，从而最大化目标程序中发现的错误数量。</li>\n<li>我们作为NEUZZ的一部分设计，实施和评估我们的技术，并证明它在各种实际程序以及策划的bug数据集上明显优于10个最先进的模糊器。</li>\n</ul>\n<p>本文的其余部分安排如下。第二部分总结了有关优化和梯度引导技术的必要背景信息。第三部分概述了我们的技术以及一个激励性的例子。第IV节和第V节详细描述了我们的方法和实施。我们在第VI节中介绍了我们的实验结果，并描述了NEUZZ在第VII节中发现的一些样本错误。第八节总结了相关工作，第九节总结了论文</p>\n<h1 id=\"II-优化基础\"><a href=\"#II-优化基础\" class=\"headerlink\" title=\"II.优化基础\"></a>II.优化基础</h1><p>在本节中，我们首先描述优化的基础知识以及梯度引导优化相对于平滑函数的进化指导的益处。最后，我们演示了如何将模糊测试作为优化问题。</p>\n<p>优化问题通常由三个不同的组件组成：参数x的向量，要最小化或最大化的目标函数F（x），以及一组约束函数Ci（x），每个约束函数包括必须满足的不等式或相等性。优化过程的目标是找到参数向量x的具体值，其最大化/最小化F（x），同时满足所有约束函数Ci（x），如下所示。</p>\n<p><img src=\"/2019/04/11/NEUZZ-Efficient-Fuzzing-with-Neural-Program-Smoothing/1.jpg\" alt=\"\"></p>\n<p>这里R，N和Q分别表示实数集，不等式约束指数和等式约束指数</p>\n<p><strong>函数平滑和优化。</strong>优化算法通常在循环中操作，从对参数向量x的初始猜测开始，并逐渐迭代以找到更好的解。任何优化算法的关键组件是它用于从一个x值移动到下一个值的策略。大多数策略利用目标函数F，约束函数Ci以及梯度/高阶导数（如果可用）的值。</p>\n<p>不同优化算法收敛到最优解的能力和效率在很大程度上取决于目标和约束函数F和Ci的性质。通常，可以比具有许多不连续性（例如，脊或平台）的函数更有效地优化更平滑的函数（即，具有明确定义和可计算的导数的函数）。直观地，目标/约束函数越平滑，优化算法就越容易准确地计算梯度或高阶导数，并使用它们系统地搜索整个参数空间。</p>\n<p>对于本文的其余部分，我们特别关注不具有任何约束函数的无约束优化问题，即C =φ，因为它们非常模仿模糊化，即我们的目标域。对于无约束平滑优化问题，梯度引导方法在解决高维结构优化问题时可以明显优于进化策略[89]，[46]，[38]。这是因为梯度引导技术有效地利用梯度/高阶导数有效地收敛到最优解，如图1所示。</p>\n<p><img src=\"/2019/04/11/NEUZZ-Efficient-Fuzzing-with-Neural-Program-Smoothing/2.jpg\" alt=\"\"></p>\n<p><strong>凸度和梯度引导优化。</strong>对于称为凸函数的常见函数类，梯度引导技术非常高效，并且总能收敛到全局最优解[86]。直观地，如果连接函数图上任意两点的直线完全位于图上方或上方，则函数是凸的。<br>更正式地，如果在其域中的所有点x和y满足以下属性，则函数f被称为凸函数：f（tx +（1-t）y）≤ tf（x）+（1-t）f （y）,存在 t 属于[0; 1]。</p>\n<p>然而，在非凸函数中，梯度引导方法可能会陷入局部最优解，其中目标函数（假设目标是最大化）比所有附近的可行点更大但是在整个其他地方存在其他更大的值可行参数值的范围。然而，即使对于这种情况，简单的启发式方法，例如从新的随机选择的起始点重新启动梯度引导方法，已经证明在实践中非常有效[38]，[86]。</p>\n<p><strong>模糊作为无约束的优化。</strong>模糊测试可以表示为无约束优化问题，其目标是最大化测试程序中针对固定数量的测试输入发现的错误/漏洞的数量。因此，目标函数可以被认为是F<sub>p</sub>（x），如果输入x在使用输入x执行目标程序p时触发错误/漏洞，则返回1。然而，这种函数太不正常（即，主要包含平坦的平台和一些非常尖锐的过渡）以便有效地优化。</p>\n<p>因此，大多数灰盒模糊器试图最大化测试代码的数量（例如，最大化边缘覆盖）作为替代代理度量[88]，[11]，[73]，[55]，[22]。这样的目标函数可以表示为F’<sub>p</sub>（x），其中F’返回程序P的输入x所覆盖的新控制流边缘的数量。注意，F比原始函数F相对更容易优化。所有可能的程序输入执行新的控制流边缘往往明显高于触发错误/安全漏洞的输入。</p>\n<p>大多数现有的灰盒模糊器使用进化技术[88]，[11]，[73]，[55]，[22]以及其他特定领域的启发式算法作为其主要的优化策略。在梯度引导优化中选择此类算法的关键原因是大多数真实世界的程序由于沿着不同程序路径的显着不同的行为而包含许多不连续性[19]。这种不连续性可能导致梯度引导优化陷入非最优解。在本文中，我们提出了一种新技术，使用神经网络平滑目标程序，使其适用于梯度引导优化，并演示模糊器如何利用这些策略来显着提高其效率。</p>\n<h1 id=\"III-我们的方法概述\"><a href=\"#III-我们的方法概述\" class=\"headerlink\" title=\"III.我们的方法概述\"></a>III.我们的方法概述</h1><p>图2展示了我们方法的高级概述。我们将在下面详细介绍关键组件</p>\n<p><img src=\"/2019/04/11/NEUZZ-Efficient-Fuzzing-with-Neural-Program-Smoothing/3.jpg\" alt=\"\"></p>\n<p><strong>神经程序平滑。</strong>平滑地逼近程序的不连续分支行为对于精确计算梯度引导优化所必需的梯度或高阶导数至关重要。没有这种平滑，梯度引导的优化过程可能会卡在不同的不连续性/平台上。平滑过程的目标是创建一个平滑的函数，该函数可以模拟程序的分支行为而不会引入大的错误（即，它与原始程序行为的偏差最小）。为此，我们使用前馈神经网络（NN）。<br>正如通用逼近定理[33]所暗示的那样，NN非常适合近似任意复杂（可能是非线性和非凸）的程序行为。此外，NN在设计上也支持对我们的目的至关重要的有效梯度计算。我们通过使用现有的测试输入或现有的进化模糊器生成的测试输入语料库来训练NN，如图2所示。</p>\n<p><strong>梯度引导优化。</strong>一旦经过训练，平滑NN模型可用于有效地计算梯度和高阶导数，然后可利用这些导数更快地收敛到最优解。梯度下降，牛顿方法或类牛顿方法（如L-BFGS算法）的梯度制导算法的不同变体使用梯度或高阶导数来实现更快的收敛[10]，[13]，[65]。平滑NN使得模糊输入生成过程可以使用所有这些技术。在本文中，我们设计，实现和评估了一种简单的梯度引导输入生成方案，该方案适用于基于覆盖的模糊测试，详见第IV-C节。</p>\n<p><strong>增量学习。</strong>任何类型的现有测试输入（只要它们暴露目标程序中的不同行为）都可以用于训练NN模型并引导模糊输入生成过程。在本文中，我们通过运行像AFL这样的进化模糊器来收集一组测试输入和相应的边缘覆盖信息来训练NN。</p>\n<p>然而，由于用于训练NN模型的初始训练数据可能仅涵盖程序空间的一小部分，我们在模糊测试期间观察到新的程序行为时通过增量训练进一步细化模型。增量训练的关键挑战是，如果NN只接受新数据的训练，它可能会完全忘记从旧数据中学到的规则[57]。我们通过设计一种新的基于覆盖的过滤方案来避免这个问题，该方案创建了新旧数据的精简摘要，允许NN在其上进行有效的培训。</p>\n<p><strong>一个激励的例子。</strong>我们在图3中展示了一个简单的激励示例，以展示我们的方法背后的关键洞察力。图3中显示的简单C代码片段演示了许多真实世界程序中常见的类似switch的代码模式。特别地，示例代码计算输入的非线性指数函数（即，pow（3，a + b））。它根据计算函数的输出范围返回不同的值。让我们假设如果函数输出范围在（1,2）中，则执行有缺陷的代码块（标记为红色）。</p>\n<p>考虑像AFL这样的进化模糊器已经设法探索第2行和第9行中的分支但是未能在第5行探索分支的情况。这里的关键挑战是找到将在第5行触发分支的a和b的值。进化模糊器通常会遇到这样的代码，因为通过随机变异找到解决方案的可能性非常低。例如，图3a显示了代码段所代表的原始函数。函数表面从a + b = 0到a + b- e = 0（e -&gt; +0）。为了在模糊测试期间最大化边缘覆盖，进化模糊器只能对输入采用随机突变，因为这种技术不考虑函数表面的形状。相比之下，我们的NN平滑和梯度引导突变旨在利用梯度测量的函数表面形状。</p>\n<p>我们从其他两个分支 训练NN模型的程序行为。 NN模型平滑地近似于程序行为，如图3b和3c所示。然后，我们使用NN模型执行更有效的梯度引导优化，以找到a和b的期望值，并逐步细化模型，直到找到执行目标错误的所需分支。</p>\n<p><img src=\"/2019/04/11/NEUZZ-Efficient-Fuzzing-with-Neural-Program-Smoothing/4.jpg\" alt=\"\"></p>\n<h1 id=\"IV-方法\"><a href=\"#IV-方法\" class=\"headerlink\" title=\"IV.方法\"></a>IV.方法</h1><p>我们在下面详细描述我们方案的不同组成部分。</p>\n<h2 id=\"A-程序平滑\"><a href=\"#A-程序平滑\" class=\"headerlink\" title=\"A.程序平滑\"></a>A.程序平滑</h2><p>程序平滑是使梯度引导优化技术适用于模糊具有离散行为的真实世界程序的重要步骤。没有平滑，梯度引导优化技术对于优化非平滑函数不是非常有效，因为它们往往会陷入不同的不连续性[67]。平滑过程使这种不规则性最小化，因此使梯度引导优化在不连续功能上显着更有效。</p>\n<p>通常，不连续函数 f 的平滑可以被认为是 f 和平滑掩模函数g之间的卷积运算，以产生如下所示的新的平滑输出函数。流行的平滑掩模的一些示例包括不同的高斯和Sigmoid函数。<br>$$<br>f’(x) = \\int_{-\\infty}^{+\\infty}f(a)g(x − a)da<br>$$<br>然而，对于许多实际问题，不连续函数f可能不具有闭合形式的表示，因此不可能分析地计算上述积分。在这种情况下，使用离散版本<br>$$<br>f’（x）= \\sum_a f（a）g（x-a）<br>$$<br>并且数值地计算卷积。例如，在图像平滑中，通常使用固定大小的2-D卷积核来执行这种计算。但是，在我们的设置中，f是计算机程序，因此无法通过分析计算相应的卷积。</p>\n<p>程序平滑技术可分为两大类：黑盒和白盒平滑。黑盒方法从f的输入空间中选取离散样本，并使用这些样本以数字方式计算卷积。相比之下，白盒方法会查看程序语句/指令，并尝试使用符号分析和抽象解释来总结它们的效果[21]，[20]。黑盒方法可能会引入大的近似误差，而白盒方法会产生令人望而却步的性能开销，这使得它们对于真实世界的程序来说是不可行的。</p>\n<p>为了避免这些问题，我们使用NN以灰盒方式学习程序行为的平滑近似（例如，通过收集边缘覆盖数据），如下所述。</p>\n<h2 id=\"B-神经程序平滑\"><a href=\"#B-神经程序平滑\" class=\"headerlink\" title=\"B.神经程序平滑\"></a>B.神经程序平滑</h2><p>在本文中，我们对程序平滑提出了一种新的方法，通过使用代理NN模型来基于观察到的程序行为来学习和迭代地改进目标程序的平滑近似。替代神经网络可以平滑地推广到观察到的程序行为，同时还准确地建模潜在的非线性和非凸行为。一旦经过训练，神经网络可用于有效地计算梯度和更高级别的导数，以指导模糊输入生成过程，如图3所示。</p>\n<p><strong>为何选择NN？</strong>正如通用逼近定理[33]所暗示的那样，NN非常适合近似复杂（可能是非线性和非凸）的程序行为。使用NN来学习平滑程序近似的优点如下：（i）NN可以精确地模拟复杂的非线性程序行为并且可以被有效地训练。基于模型的优化的先前工作使用简单的线性和二次模型[24]，[23]，[71]，[52]。然而，这些模型不适合用于建模具有高度非线性和非凸性行为的真实软件; （ii）NN支持有效计算其梯度和高阶导数。因此，梯度引导算法可以在模糊测试期间计算和使用这些信息，而无需任何额外开销; （iii）NN可以概括并学习根据类似输入的行为来预测程序对看不见的输入的行为。因此，NN可以基于其对少量输入样本的行为来潜在地学习整个程序的平滑近似。<br><strong>NN训练。</strong>虽然NN可用于模拟程序行为的不同方面，但在本文中，我们专门用它们来建模目标程序的分支行为（即，预测由给定程序输入执行的控制流边缘）。使用神经网络对分支行为进行建模的挑战之一是需要接受可变大小的输入。与现实世界的程序不同，前馈NN通常接受固定大小的输入。因此，我们设置最大输入大小阈值，并在训练期间使用空字节填充任何较小尺寸的输入。请注意，支持更大的输入不是主要问题，因为现代NN可以轻松扩展到数百万个参数。因此，对于较大的程序，我们可以根据需要简单地增加阈值大小。然而，我们凭经验发现相对适度的阈值产生最佳结果，而较大的输入不会显着提高建模精度。</p>\n<p>形式上，让f：{0x00，0×01,…, 0xff}^m^ -&gt; {0, 1}^n^ 表示将程序输入作为具有大小为m的字节序列的NN，并输出大小为n的边缘位图。设θ表示 f 的可训练权重参数。给定一组训练样本（X, Y），其中X是一组输入字节，Y代表相应的边缘覆盖位图，参数函数f（x,θ）= y的训练任务是获得参数θ ^<br>$$<br> \\overlineθ =arg min_θ\\sum_{x\\in X,y\\in Y} L（y, f（x,θ））<br>$$<br>其中L（y, f（x,θ））定义NN的输出与训练集中的真实标签y ∈ Y之间的损失函数。训练任务是找到NN f的权重参数θ以最小化损失，其使用距离度量来定义。特别是，我们使用二进制交叉熵来计算预测位图和真实覆盖位图之间的距离。特别是，让 y <sub>i</sub> 和f<sub>i</sub>（x,θ）分别表示真实数据和 f 预测的输出位图中的第i位。然后，这两者之间的二元交叉熵定义为：<br>$$<br>−\\frac{1}{n}\\sum_{i=1}^n<br>[y_i · log(f_i(x, θ) + (1 − y_i) · log(1 − f_i(x, θ)]<br>$$<br>在本文中，我们使用前馈完全连接的NN来模拟目标程序的分支行为。前馈架构允许高效计算梯度和快速训练[53]。</p>\n<p>我们的平滑技术对于训练数据的来源是不可知的，因此可以对从现有输入语料库收集的任何边缘覆盖数据训练NN。对于我们的原型实现，我们使用现有的进化模糊器（如AFL）生成的输入语料库来训练我们的初始模型。</p>\n<p><strong>训练数据预处理。</strong>由训练数据执行的边缘覆盖通常倾向于偏差，因为它仅包含程序中所有边缘的一小部分的标签。例如，一些边缘可能总是由训练数据中的所有输入一起运用。一组标签之间的这种类型的相关性在机器学习中被称为多重共线性，这通常会阻止模型收敛到一个小的损失值[34]。为了避免这种情况，我们通过将总是一起出现在训练数据中的边缘合并到一个边缘来遵循降维的常见机器学习实践。此外，我们仅考虑在训练数据中至少激活一次的边缘。这些步骤将标签数量平均从大约65536大幅减少到4000左右。请注意，我们在每次增量学习迭代时重新运行数据预处理步骤，因此一些合并标签可能会因为在模糊测试期间发现新边缘数据时相关性降低而分裂。</p>\n<h2 id=\"C-梯度引导优化\"><a href=\"#C-梯度引导优化\" class=\"headerlink\" title=\"C.梯度引导优化\"></a>C.梯度引导优化</h2><p>不同的梯度引导优化技术，如梯度下降，牛顿法或准牛顿法，如L-BFGS，可以使用梯度或更高阶导数来实现更快的收敛[10]，[13]，[65] 。平滑NN使得模糊输入生成过程可以通过支持梯度和高阶导数的有效计算来潜在地使用这些技术中的任何一种。在本文中，我们专门设计了一个简单的梯度引导搜索方案，该方案对于较小的预测误差具有鲁棒性，以证明我们的方法的有效性。我们将更复杂的技术探索作为未来的工作。</p>\n<p>在描述基于NN梯度的变异策略之前，我们首先提供梯度的形式定义，指示每个输入字节应该改变多少以影响NN f 中最终层神经元的输出（指示改变的边缘覆盖范围在程序中）[80]。这里，每个输出神经元对应于特定边缘，并计算0和1之间的值，总结给定输入字节对特定边缘的影响。 NN f w.r.t.输出神经元的梯度。输入已广泛用于对抗性输入生成[39]，[66]和可视化/理解DNN [87]，[80]，[56]。直观地，在我们的设置中，基于梯度的指导的目标是找到将改变对应于从0到1的不同边缘的最终层神经元的输出的输入。</p>\n<p>给定如IV-B部分中定义的参数NN y = f（θ,x），令 y<sub>i</sub> 表示 f 的最后一层中的第i个神经元的输出，其也可以写为f<sub>i</sub>（θ,x）。 f<sub>i</sub>（θ,x）相对于输入x的梯度G可以定义为G = ▽<sub>x</sub>f<sub>i</sub>（θ, x）= δy<sub>i</sub> / δx。注意，可以容易地计算 f 的梯度w.r.t到θ，因为NN训练过程需要迭代地计算该值以更新θ。因此，通过简单地将θ的梯度的计算替换为x的梯度，也可以容易地计算G.注意，梯度G的维数与输入x的维度相同，在我们的例子中，它是一个字节序列。</p>\n<p><img src=\"/2019/04/11/NEUZZ-Efficient-Fuzzing-with-Neural-Program-Smoothing/5.jpg\" alt=\"\"></p>\n<p>梯度引导优化。算法1显示了梯度引导输入生成过程的概要。关键思想是识别具有最高梯度值的输入字节并对其进行改变，因为它们表明对NN具有更高的重要性，因此具有更高的机会导致程序行为发生重大变化的机会（例如，翻转分支）。</p>\n<p>从种子开始，我们迭代地生成新的测试输入。如算法1所示，在每次迭代时，我们首先利用梯度的绝对值来识别输入字节，该输入字节将导致对应于未捕获边缘的输出神经元的最大变化。接下来，我们检查每个字节的梯度符号以确定突变的方向（例如，递增或递减它们的值）以最大化/最小化目标函数。从概念上讲，我们对梯度符号的使用类似于[39]中介绍的对抗性输入生成方法。我们还将每个字节的变异限制在其合法范围内（0-255）。第6行和第10行表示使用剪辑功能来实现这种边界。</p>\n<p>我们用一个小的变异目标（算法1中的k）开始输入生成过程，并指数增加要变异的目标字节数，以有效地覆盖大的输入空间。</p>\n<h2 id=\"D-通过增量学习进行细化\"><a href=\"#D-通过增量学习进行细化\" class=\"headerlink\" title=\"D.通过增量学习进行细化\"></a>D.通过增量学习进行细化</h2><p>梯度引导输入生成过程的效率在很大程度上取决于代理NN对目标程序的分支行为进行建模的准确程度。为了获得更高的准确度，当在模糊测试过程中观察到不同的程序行为时（即，当目标程序的行为与预测的行为不匹配时），我们逐步细化NN模型。我们使用增量学习技术通过在触发新边缘时学习新数据来更新NN模型。</p>\n<p>NN改进背后的主要挑战是阻止NN模型在训练新数据时突然忘记先前从旧数据中学到的信息。这种遗忘是深度学习文献中众所周知的现象，并被认为是稳定性 - 可塑性困境的结果[58]，[8]。为了避免这种遗忘问题，NN必须足够改变权重以学习新任务，但不能过多地使其忘记以前学过的表示。</p>\n<p>细化NN的最简单方法是将新训练数据（即程序分支行为）与旧数据一起添加，并再次从头开始训练模型。但是，随着数据点数量的增加，这种再训练变得更难以扩展。先前的研究试图主要使用两种广泛的方法来解决这个问题[44]，[51]，[31]，[75]，[29]，[40]，[76]。第一个尝试为新旧模型保留单独的表示，以最大限度地减少使用分布式模型，正则化或从多个模型中创建集合的遗忘。第二种方法维护旧数据的摘要，并在新数据上重新训练模型以及汇总的旧数据，因此比完全再训练更有效。我们将感兴趣的读者引用到Kemker等人的调查中。 [48]了解更多详情。</p>\n<p>在本文中，我们使用基于边缘覆盖的过滤来仅保留触发新分支的旧数据以进行重新训练。随着新的训练数据变得可用，我们确定实现新边缘覆盖的数据，将它们与过滤的旧训练数据放在一起，并重新训练NN。这种方法有效地防止训练数据样本的数量在重新训练迭代次数上急剧增加。我们发现我们的过滤方案可以轻松支持多达50次重新训练，同时仍将训练时间保持在几分钟之内。</p>\n<h1 id=\"V-实现\"><a href=\"#V-实现\" class=\"headerlink\" title=\"V.实现\"></a>V.实现</h1><p>在本节中，我们将讨论我们的实现以及如何微调NEUZZ以实现最佳性能。我们已经通过GitHub在<a href=\"http://github.com/dongdongshe/neuzz发布了我们的实现。我们所有的测量都是在运行Arch\" target=\"_blank\" rel=\"noopener\">http://github.com/dongdongshe/neuzz发布了我们的实现。我们所有的测量都是在运行Arch</a> Linux 4.9.48并使用Nvidia GTX 1080 Ti GPU的系统上进行的。</p>\n<p><strong>NN架构。</strong>我们的NN模型在Keras2.1.3 [5]中实现，Tensorflow-1.4.1 [6]作为后端。 NN模型由三个完全连接的层组成。隐藏层使用ReLU作为其激活功能。我们使用sigmoid作为输出层的激活函数来预测控制流边缘是否被覆盖。 NN模型被训练50个时期（即，整个数据集的50次完整通过）以实现高测试准确度（平均约95％）。由于我们使用简单的前馈网络，所有10个程序的训练时间不到2分钟。即使在运行频率为3.6GHz的Intel i7-7700上进行纯CPU计算，训练时间也不到20分钟。</p>\n<p><strong>训练数据收集。</strong>对于每个测试的程序，我们在单个核心机器上运行AFL-2.5.2 [88]一小时，以收集NN模型的训练数据。为10个项目收集的平均训练输入数量约为2K。得到的语料库进一步分为训练和测试数据，比例为5：1，其中测试数据用于确保模型不会过度拟合。我们使用10KB作为阈值文件大小，用于从AFL输入语料库中选择我们的训练数据（平均90％的AFL生成的文件低于阈值）。</p>\n<p><img src=\"/2019/04/11/NEUZZ-Efficient-Fuzzing-with-Neural-Program-Smoothing/6.jpg\" alt=\"\"></p>\n<p><strong>突变和再培训。</strong>如图2所示，NEUZZ迭代运行以生成1M突变并逐步重新训练NN模型。我们首先使用算法1中描述的变异算法来生成1M突变。我们将参数 i 设置为10，为种子输入生成5,120个突变输入。接下来，我们在目标程序中随机选择代表100个未探测边缘的100个输出神经元，并从两个种子生成10,240个突变输入。最后，我们使用AFL的fork服务器技术[54]执行具有1M突变输入的目标程序，并使用覆盖新边缘的任何输入进行增量重新训练。</p>\n<p><strong>模型参数选择。</strong> NEUZZ的成功取决于训练模型和产生突变的不同参数的选择。在这里，我们通过经验探索确保最佳边缘覆盖四个程序的最佳参数：readelf，libjpeg，libxml和mupdf。结果总结在表I中。</p>\n<p>首先，我们评估每个初始种子需要突变的关键字节数（算法1的第1行中的参数ki）。我们选择k = 2，如第IV-C节所述，并显示通过三次迭代（i = 7,10,11算法1第1行中的）实现的覆盖率，每次迭代有1M个突变。对于所有四个程序，较小的突变（每个突变更改的字节更少）可能导致更高的代码覆盖率，如表1a所示。 i = 11的最大值实现了所有四个程序的最小代码覆盖率。这个结果可能是由于算法1中的第4和第8行 - 在单个种子上浪费了太多突变（超出1M突变预算），而没有尝试其他种子。但是，最佳突变字节数在四个程序中有所不同。对于readelf和libxml，i的最佳值为10，而libjpeg和mupdf的最佳值为7。由于在i = 7和i = 10之间实现的代码覆盖率的差异不大，我们选择i = 10用于剩余的实验。</p>\n<p>接下来，我们通过改变每个隐藏层中的层数和神经元数来评估NN模型中超参数的选择。特别地，我们将NN架构分别与每层的1和3个隐藏层以及4096和8192个神经元进行比较。对于每个目标计划，我们使用相同的训练数据来训练四种不同的NN模型并生成1M突变以测试所实现的边缘覆盖。对于所有四个程序，我们发现具有1个隐藏层的模型比具有3个隐藏层的模型执行得更好。我们认为这是因为1隐藏层模型足够复杂以模拟目标程序的分支行为，而较大的模型（即具有3个隐藏层）相对较难训练并且还倾向于过度拟合。</p>\n<h1 id=\"VI-评估\"><a href=\"#VI-评估\" class=\"headerlink\" title=\"VI.评估\"></a>VI.评估</h1><p>在本节中，我们评估NEUZZ的错误发现性能，并获得与其他最先进的模糊器相关的边缘覆盖率。具体来说，我们回答以下四个研究问题：</p>\n<ul>\n<li>RQ1. NEUZZ可以找到比现有模糊器更多的错误吗？</li>\n<li>RQ2. NEUZZ能否实现比现有模糊器更高的边缘覆盖？</li>\n<li>RQ3. NEUZZ能否比现有的基于RNN的模糊器表现更好？</li>\n<li>RQ4.不同的模型选择如何影响NEUZZ的性能？</li>\n</ul>\n<p>我们首先描述我们的研究对象和实验设置。</p>\n<h2 id=\"A-研究对象\"><a href=\"#A-研究对象\" class=\"headerlink\" title=\"A.研究对象\"></a>A.研究对象</h2><p>我们在三种不同类型的数据集上评估NEUZZ：（i）10个真实世界的程序，如表IIb所示，（ii）LAVA-M [28]，以及（iii）DARPA CGC数据集[26] 。为了演示NEUZZ的性能，我们将NEUZZ检测到的边缘覆盖范围和缺陷数量与10个最先进的模糊器进行比较，如表IIa所示。</p>\n<p><img src=\"/2019/04/11/NEUZZ-Efficient-Fuzzing-with-Neural-Program-Smoothing/7.jpg\" alt=\"\"></p>\n<h2 id=\"B-实验设置\"><a href=\"#B-实验设置\" class=\"headerlink\" title=\"B.实验设置\"></a>B.实验设置</h2><p>我们的实验设置包括以下两个步骤：首先，我们运行AFL一小时以生成初始种子语料库。然后，我们使用相同的初始种子语料库运行每个模糊器一个固定的时间预算，并比较它们实现的边缘覆盖率和发现的错误数量。具体而言，10个真实世界程序，LAVA-M数据集和CGC数据集的时间预算分别为24小时，5小时和6小时。对于进化模糊器，种子语料库用于初始化模糊过程。对于基于学习的模糊器（即，基于NEUZZ和RNN的模糊器），使用相同的种子语料库来生成训练数据集。对于KleeFL，一种由Klee和AFL组成的混合工具，我们运行Klee一小时以生成额外的种子，然后将它们添加到原始种子语料库中，用于随后的24小时模糊测试过程。请注意，我们仅报告每个模糊器的变异输入所涵盖的附加代码，而不包括初始种子语料库中的覆盖信息。</p>\n<p>在RQ3中，我们评估和比较NEUZZ与基于RNN的模糊器的性能。基于RNN的模糊器比NEUZZ的训练时间长20倍。然而，为了关注这两种突变算法的功效，我们评估固定数量突变的边缘覆盖率，以排除这些不同的训练时间的影响。我们还进行了独立评估，比较了这两种模型的训练时间成本。在RQ4中，我们还评估了固定数量突变的边缘覆盖率，以排除不同模型中不同训练时间成本的影响。</p>\n<h2 id=\"C-结果\"><a href=\"#C-结果\" class=\"headerlink\" title=\"C.结果\"></a>C.结果</h2><h3 id=\"RQ1-NEUZZ可以找到比现有模糊器更多的错误吗？\"><a href=\"#RQ1-NEUZZ可以找到比现有模糊器更多的错误吗？\" class=\"headerlink\" title=\"RQ1. NEUZZ可以找到比现有模糊器更多的错误吗？\"></a>RQ1. NEUZZ可以找到比现有模糊器更多的错误吗？</h3><p>为了回答这个RQ，我们评估了NEUZZ w.r.t.三种设置中的其他模糊器：（i）检测现实世界中的错误。 （ii）检测LAVA-M数据集中注入的错误[28]。 （iii）检测CGC错误。我们详细描述结果。</p>\n<p><strong>（i）检测现实世界的错误。</strong>我们比较了NEUZZ和其他模糊器在24小时运行时发现的错误和崩溃的总数，给出相同的种子语料库。 NEUZZ和其他模糊器发现了五种不同类型的错误：内存不足，内存泄漏，断言崩溃，整数溢出和堆溢出。为了检测不一定会导致崩溃的内存错误，我们使用AddressSanitizer [4]编译程序二进制文件。我们通过比较AddressSanitizer报告的堆栈跟踪来测量发现的唯一内存错误。对于不会导致AddressSanitizer生成错误报告的崩溃，我们会检查执行跟踪。通过手动分析触发无限循环的输入找到整数溢出错误。我们使用未定义的行为清理程序进一步验证整数溢出错误[7]。结果总结在表III中。</p>\n<p><img src=\"/2019/04/11/NEUZZ-Efficient-Fuzzing-with-Neural-Program-Smoothing/8.jpg\" alt=\"\"></p>\n<p>NEUZZ在6个程序中查找所有5种类型的错误。 AFL，AFLFast和AFL-laf-intel发现了3种类型的错误 - 它们没有找到任何整数溢出错误。其他模糊器只发现2种类型的错误（即内存泄漏和断言崩溃）。 AFL可以在程序size上出现堆溢出错误，而NEUZZ可以在程序nm上找到相同的错误和另一个堆溢出错误。总的来说，NEUZZ发现的错误比第二个最好的模糊器多2倍。此外，strip中的整数溢出错误和nm中的堆溢出错误（仅由NEUZZ发现）已经分配了CVE-2018-19932和CVE-2018-19931，后来由开发人员修复。</p>\n<p><strong>（ii）检测LAVA-M数据集中注入的错误。</strong>创建LAVA数据集是为了通过提供一组注入大量错误的真实程序来评估模糊器的有效性[28]。 LAVA-M是LAVA数据集的子集，由4个GNU coreutil程序base64，md5sum，uniq和who分别注入44,57,28和2136个错误组成。所有的错误都受到四字节magic比较的保护。只有满足条件时才会触发错误。我们将NEUZZ在发现这些缺陷方面的性能与其他最先进的模糊器进行比较，如表IV所示。按照传统做法[22]，[28]，我们使用5小时的时间预算来完成模糊器的运行时间。</p>\n<p><img src=\"/2019/04/11/NEUZZ-Efficient-Fuzzing-with-Neural-Program-Smoothing/9.jpg\" alt=\"\"></p>\n<p>触发LAVA数据集中的magiv条件对于覆盖引导的模糊器来说是一项艰巨的任务，因为模糊器必须在256^4^种可能情况下生成4个连续字节的精确组合。为了解决这个问题，我们使用了一个定制的LLVM传递来检测magic字节检查，如Steelix [55]。但与Steelix不同，我们利用NN的渐变来指导输入生成过程，以找到满足magic检查的输入。我们运行AFL一小时来生成训练数据并用它来训练NN，其梯度识别触发magic字节条件的第一个字节比较的可能关键字节。接下来，我们对与第一个关键字节相邻的每个字节执行局部穷举搜索，以便通过256次尝试解决剩余的三个字节比较中的每一个。因此，我们需要一个NN梯度计算来查找影响魔法检查的字节位置，并且需要4×256 = 1024个试验来触发每个bug。对于程序md5sum，根据LAVA-M作者的最新建议[27]，我们进一步将种子减少到单行，这显着提高了模糊性能。</p>\n<p>如表IV所示，NEUZZ查找程序base64，md5sum和uniq中的所有错误，以及程序的错误数量最多。请注意，LAVA-M作者在所有4个程序中都留下了一些未列出的错误，因此NEUZZ发现的错误总数实际上高于列出的错误数，如结果所示。</p>\n<p>与其他模糊器相比，NEUZZ具有两个关键优势。首先，NEUZZ将搜索空间分成多个可管理的步骤：NEUZZ在AFL生成的数据上训练底层NN，使用计算的梯度到达第一个关键字节，并在找到的关键区域周围执行本地搜索。其次，与VUzzer相反，VUzzer利用目标二进制中硬编码的magic来构建程序输入，NEUZZ的基于梯度的搜索策略不依赖于任何硬编码的magic。因此，它可以找到程序md5sum中的所有错误，它在magic检查之前对输入字节执行一些计算，导致VUzzer失败。Angora（LAVA-M数据集当前最先进的模糊器）相比，NEUZZ在md5sum中发现了3个更多的错误。与Angora不同，NEUZZ使用NN渐变来更有效地触发复杂的magic条件</p>\n<p><strong>（iii）检测CGC错误。</strong> DARPA CGC数据集[2]由DARPA网络大挑战中使用的易受攻击的程序组成。这些程序实现为执行各种任务的网络服务，旨在镜像具有已知漏洞的实际应用程序。程序中的每个错误都受到输入上的一些健全性检查的保护。 数据集附带一组输入作为漏洞的证据。</p>\n<p>我们在50个随机选择的CGC二进制文件中评估NEUZZ，Driller和AFL。由于为每个模糊器运行每个测试二进制文件需要6个小时才能在CPU / GPU上运行，并且我们有限的GPU资源不允许我们并行执行多个实例，我们随机选择50个程序以将总实验时间保持在合理的范围内。与LAVA-M类似，这里我们也运行AFL一小时来生成训练数据并用它来训练NN。我们为所有三个模糊器提供相同的随机种子，让它们运行六个小时。 NEUZZ使用与LAVA-M数据集相同的自定义LLVM传递来检测CGC二进制文件中的magic检查。</p>\n<p>结果（表五）显示，NEUZZ在50个二进制文件中发现31个错误的二进制文件，而AFL和Driller分别找到21个和25个。 NEUZZ发现的有缺陷的二进制文件包括Driller和AFL发现的所有文件。 NEUZZ进一步发现6个新的二进制文件中的错误，AFL和Driller都无法检测到这些错误。</p>\n<p><img src=\"/2019/04/11/NEUZZ-Efficient-Fuzzing-with-Neural-Program-Smoothing/10.jpg\" alt=\"\"></p>\n<p>我们分析了一个示例程序CROMU_00027（如清单1所示）。这是一个ASCII内容服务器，它从客户端获取查询并提供相应的ASCII代码。在用户尝试将命令设置为VISUALIZE后，将触发空指针解除引用错误。 AFL未能在6小时的时间预算内检测到这个错误，因为它在猜测magic字符串方面效率低下。虽然Driller试图通过concolic执行来满足这种复杂的魔术字符串检查，但在这种情况下，它无法找到满足检查的输入。相比之下，NEUZZ可以轻松使用NN渐变来定位程序输入中影响magic比较的关键字节，并找到满足magic检查的输入。</p>\n<p><strong>结果1：NEUZZ在6个不同的程序中找到了31个以前未知的错误，其他模糊器找不到。NEUZZ在寻找LAVA-M和CGC漏洞方面也优于最先进的模糊器</strong></p>\n<h3 id=\"RQ2-NEUZZ能否实现比现有模糊器更高的边缘覆盖？\"><a href=\"#RQ2-NEUZZ能否实现比现有模糊器更高的边缘覆盖？\" class=\"headerlink\" title=\"RQ2. NEUZZ能否实现比现有模糊器更高的边缘覆盖？\"></a>RQ2. NEUZZ能否实现比现有模糊器更高的边缘覆盖？</h3><p>为了研究这个问题，我们比较了24小时固定运行时预算的模糊器。此评估不仅显示模糊器发现的新边缘总数，还显示新边缘覆盖的速度与时间的关系。</p>\n<p><img src=\"/2019/04/11/NEUZZ-Efficient-Fuzzing-with-Neural-Program-Smoothing/11.jpg\" alt=\"\"></p>\n<p><img src=\"/2019/04/11/NEUZZ-Efficient-Fuzzing-with-Neural-Program-Smoothing/12.jpg\" alt=\"\"></p>\n<p>我们从AFL的边缘覆盖率报告中收集边缘覆盖率信息。结果总结在表VI中。对于所有10个真实世界的节目，NEUZZ在边缘覆盖方面明显优于其他模糊器。如图4所示，NEUZZ在第一个小时内可以比其他模糊器获得更多的新边缘覆盖。在程序strip，harfbuz和readelf，NEUZZ在一小时内可以达到1000以上新的边缘覆盖。对于程序readelf和objdump，NEUZZ运行1小时的新边缘覆盖数量甚至超过所有其他模糊器24小时运行的新边缘覆盖数量。这表明NEUZZ具有优越的边缘覆盖能力。对于所有10个节目中的9个，NEUZZ分别实现了比基线AFL 6×，1.5×，9×，1.8×，3.7×，1.9×，10×，1.3×和3×边缘覆盖，以及4.2×，1.3× ，7×，1.2×，2.5×，1.5×，1.5×，1.3×和3×边缘覆盖率均高于所有6个模糊器中的第二高数量。对于代码小于2k的最小程序zlib，NEUZZ与其他模糊器实现了类似的边缘覆盖。我们相信它会在24小时模糊测试后发现这样一个小程序的大部分可能边缘时达到饱和点。显着的优异性能显示了NEUZZ使用渐变覆盖新边缘有效定位和突变关键字节的有效性。 NEUZZ在大型系统中也可以很好地扩展。实际上，对于超过10K行的程序（例如，readelf，harfbuzz，mupdf和libxml），NEUZZ实现了最高的边缘覆盖，其中采用污点辅助的fuzzer（即VUzzer）和符号执行辅助fuzzer（即KleeFL）执行较差或并不能扩展。</p>\n<p>梯度引导变异策略允许NEUZZ探索不同的边缘，而其他基于进化的模糊器经常卡住并重复检查相同的分支条件。此外，NN平滑技术的最小执行开销有助于NEUZZ在较大程序中很好地扩展，而其他高级进化模糊器由于使用了重量级程序分析技术（如污点跟踪或符号执行）而导致高执行开销。</p>\n<p>在进化模糊器中，AFLFast使用优化的种子选择策略，更多地关注稀有边缘，因此在8个程序中实现比AFL更高的覆盖率，特别是在libjpeg，size和harfbuzz中。另一方面，VUzzer在小程序（例如，zlib，nm，objdump，size和strip）的第一个小时内实现了比AFL，AFLFast和AFL-laf-intel更高的覆盖率，但它的导致很快停止并且最终是超过其他模糊器。同时，VUzzer的性能会因readelf，harfbuzz，libxml和mupdf等大型程序而降低。我们怀疑VUzzer的污点跟踪器引入的不精确会导致它在大型程序上表现不佳。 KleeFL使用符号执行引擎Klee生成的其他种子来指导AFL的探索。与VUzzer类似，对于小程序（nm，objdump和strip），KleeFL在开始时具有良好的性能，但其在Klee的额外种子的优势在几小时后逐渐消失。<br>此外，KleeFL基于Klee，无法扩展到具有复杂库代码的大型程序，这是众所周知的符号执行限制。因此，KleeFL在程序libxml，mupdf和harfbuzz上没有结果。与VUzzer和KleeFL不同，NEUZZ不依赖任何繁重的程序分析技术; NEUZZ使用从NN计算的梯度来生成有希望的突变，即使对于较大的程序也是如此。有效的NN梯度计算过程允许NEUZZ在识别影响不同看不见的程序分支的关键字节时比VUzzer和KleeFL更好地扩展，从而实现更多的边缘覆盖。</p>\n<p>AFL-laf-intel使用LLVM传递将复杂的magic比较转换为嵌套的字节比较，然后在转换的二进制文件上运行AFL。它在程序strip上实现了第二高的新边缘覆盖率。但是，比较转换会为常见的比较操作添加额外的指令，从而导致潜在的边缘爆炸问题。边缘爆炸大大增加了边缘冲突的速度，并且损害了进化模糊的表现。此外，这些附加指令会导致额外的执行开销。<br>结果，像频繁比较操作的libjpeg这样的程序遭受显着的减速（例如，libjpeg），并且AFL-laf-intel努力触发新的边缘。</p>\n<p><strong>结果2：与其他灰盒式模糊器相比，NEUZZ可以实现更高的边缘覆盖率（比AFL高4倍，比24小时运行的第二好的高出2.5倍）</strong></p>\n<h3 id=\"RQ3-NEUZZ能否比现有的基于RNN的模糊器表现更好？\"><a href=\"#RQ3-NEUZZ能否比现有的基于RNN的模糊器表现更好？\" class=\"headerlink\" title=\"RQ3.NEUZZ能否比现有的基于RNN的模糊器表现更好？\"></a>RQ3.NEUZZ能否比现有的基于RNN的模糊器表现更好？</h3><p>现有的基于递归神经网络（RNN）的模糊器从过去的模糊测试经验中学习突变模式，以指导未来的突变[72]。这些模型首先从AFL生成的大量突变输入中学习突变模式（由关键字节组成）。接下来，他们使用突变模式为AFL构建一个过滤器，它只允许关键字节上的突变通过，否决所有其他非关键字节突变。我们选择了之前研究的4个项目来评估NEUZZ与基于RNN的模糊器相比100万个突变的性能。我们使用相同的训练数据训练两个NN模型，然后让两个基于NN的模糊器运行产生100万个突变，并比较两种方法实现的新代码覆盖率。我们报告了实现的边缘覆盖率和训练时间，如表VII所示。</p>\n<p><img src=\"/2019/04/11/NEUZZ-Efficient-Fuzzing-with-Neural-Program-Smoothing/13.jpg\" alt=\"\"></p>\n<p>对于所有四个程序，NEUZZ在1M突变方面明显优于基于RNN的模糊器。 NEUZZ比四个程序中基于RNN的模糊器达分别达到8.4×， 4.2×，6.7×和3.7×更多的边缘覆盖。此外，基于RNN的模糊器平均比NEUZZ多20倍的训练开销，因为RNN模型比前馈网络模型复杂得多。</p>\n<p>基于RNN的模糊器与AFL的另外比较表明，使用1小时语料库，前者在libxml和mupdf上的平均边缘覆盖率比AFL高2倍。我们还观察到基于RNN的模糊器否决了AFL产生的大约50％的突变。因此，来自基于RNN的模糊器的1M突变的新边缘覆盖可以实现普通AFL中2M突变的边缘覆盖。这就解释了为什么基于RNN的模糊器在一些程序中发现AFL的新边缘增加了2倍左右。如果AFL在2M突变后卡住，基于RNN的模糊器也会在1M过滤突变后卡住。 <strong>NEUZZ相对于基于RNN的模糊器的关键优势在于，NEUZZ使用基于神经网络的梯度引导搜索获得关键位置，而RNN模糊器尝试以端到端方式对任务进行建模。</strong><br>我们的模型可以区分RNN模型可能遗漏的关键字节的不同影响因素，如我们的实验结果所示。对于突变生成，我们对由相应的贡献因子确定的关键字节进行穷举搜索，而基于RNN的模糊器仍然依赖于AFL的均匀随机突变。</p>\n<p><strong>结果3：NEUZZ，一个基于简单前馈网络的模糊器，通过在不同项目中实现3.7倍到8.4倍的边缘覆盖率，明显优于基于RNN的模糊器</strong></p>\n<h3 id=\"RQ4-不同的型号选择如何影响NEUZZ的性能？\"><a href=\"#RQ4-不同的型号选择如何影响NEUZZ的性能？\" class=\"headerlink\" title=\"RQ4.不同的型号选择如何影响NEUZZ的性能？\"></a>RQ4.不同的型号选择如何影响NEUZZ的性能？</h3><p>NEUZZ的模糊测试性能在很大程度上取决于训练有素的NN的准确性。如第五部分所述，我们凭经验发现具有1个隐藏层的NN模型足以表达真实世界程序的复杂分支行为。在本节中，我们通过探索1个隐藏层架构的不同模型设置来进行消融研究，即，线性模型，没有细化的NN模型，以及具有渐进细化的NN模型。我们评估这些模型对NEUZZ性能的影响。</p>\n<p>为了比较模糊测试性能，我们在4个程序中为每个版本的NEUZZ生成1M突变。我们通过去除隐藏层中使用的非线性激活函数来实现线性模型，从而使整个前馈网络完全线性化。 NN模型由AFL训练相同的种子语料库。接下来，我们从被动学习模型中生成1M突变，并测量这些1M突变所实现的边缘覆盖。最后，我们筛选出突变的输入，这些输入在100万个突变中运行看不见的边缘，并将这些选择的输入添加到原始种子语料库中，以递增地重新训练另一个NN模型并使用它来产生进一步的突变。结果总结在表VIII中。我们可以看到，两个NN模型（有或没有增量学习）都优于所有4个测试程序的线性模型。这表明非线性NN模型可以比简单的线性模型更好地逼近程序行为。我们还观察到增量学习有助于NN实现更高的准确度，从而提高边缘覆盖率。</p>\n<p><img src=\"/2019/04/11/NEUZZ-Efficient-Fuzzing-with-Neural-Program-Smoothing/14.jpg\" alt=\"\"></p>\n<p><strong>结果4：NN模型优于线性模型，增量学习使NN随着时间的推移更加准确。</strong></p>\n<h1 id=\"VII-BUGS的案例研究\"><a href=\"#VII-BUGS的案例研究\" class=\"headerlink\" title=\"VII. BUGS的案例研究\"></a>VII. BUGS的案例研究</h1><p>在本节中，我们提供和分析NEUZZ发现的三种不同类型的错误的样本：整数溢出，内存不足和崩溃诱发错误。<br>我们注意到，由于对极值变量的错误处理导致了大量的程序错误。由于NEUZZ可以枚举从0x00到0xff的所有关键字节（参见算法1第3行），我们设法找到由错误处理的极值引起的大量错误。例如，通过将影响内存分配大小的输入字节设置为极大值，NEUZZ能够在libjpeg，objdump，nm和strip中找到许多内存不足的错误。</p>\n<p><strong>strip的整数溢出。</strong> NEUZZ发现了一个整数溢出错误，可以在strip上产生无限循环。清单2显示了strip程序中的一个函数，它解析输入ELF文件的程序头表中的每个部分，并将所有部分分配给输出ELF文件中的新程序头表。整数溢出发生在清单2的第11行的if条件中，因为NEUZZ将segment_size设置为一个非常大的值。因此，程序陷入无限循环。我们发现在最新版本的Binutils 2.30和旧版本2.26和2.29中都存在此错误。</p>\n<p><strong>libjpeg的内存不足。</strong>在JPEG压缩过程中，每个颜色空间的数据通过相应的采样因子进行下采样，以减小文件大小。<br>根据JPEG标准，采样因子必须是1到4之间的整数。在解压缩过程中使用此值来确定需要分配多少内存，如清单4所示.NEUZZ设置一个较大的值，导致过多要为图像数据分配的内存，导致内存不足错误。利用libjpeg显示图像，可能会利用此类错误在服务器上启动拒绝服务攻击。</p>\n<p><img src=\"/2019/04/11/NEUZZ-Efficient-Fuzzing-with-Neural-Program-Smoothing/15.jpg\" alt=\"\"></p>\n<p><strong>readelf的崩溃。</strong> ELF文件由文件头，程序头，节头和节数据组成。根据ELF规范，ELF头包含位于第60个字节的字段e_shnum，用于64位二进制，它指定ELF文件中的节数。 NEUZZ将输入文件的节数设置为0.如清单3所示，如果节的数量等于0，则实现返回一个NULL指针，该指针被后续代码取消引用，触发崩溃</p>\n<h1 id=\"VIII-相关工作\"><a href=\"#VIII-相关工作\" class=\"headerlink\" title=\"VIII .相关工作\"></a>VIII .相关工作</h1><p><strong>程序平滑。</strong> Parnas等 [67]观察到不连续性是开发安全可靠软件背后的基本挑战之一。 Chaudhury等人 [21]，[18]，[19]提出了程序平滑的想法，以促进程序分析，并使用抽象解释和符号执行提出了严格的平滑算法。不幸的是，这种算法会产生过高的性能开销，特别是对于大型程序。相比之下，我们的平滑技术利用NN的学习能力来实现更好的可扩展性。</p>\n<p><strong>基于学习的模糊测试。</strong>最近，人们越来越关注使用机器学习技术来改进模糊器[37]，[72]，[84]，[9]，[81]，[12]，[64]。然而，现有的基于学习的模糊器将模糊测试模型化为端到端ML问题，即，他们学习ML模型以直接预测可以实现更高代码覆盖的输入模式。相比之下，我们首先使用NN平滑地逼近程序分支行为，然后利用梯度引导输入生成技术来实现更高的覆盖范围。因此，我们的方法比ML模型更容忍学习错误而不是端到端方法。在本文中，我们凭经验证明我们的策略在发现错误和实现更高边缘覆盖方面优于端到端建模[72]。</p>\n<p><strong>基于污点的模糊测试。</strong>几个进化模糊器试图使用污点信息来识别有希望的变异位置[85]，[42]，[63]，[73]，[55]，[22]。例如，TaintScope [85]旨在识别影响系统/库调用的输入字节，并专注于改变这些字节。同样，Dowser [42]和BORG [63]专门使用污点信息来分别检测缓冲区边界违规和缓冲区过度读取漏洞。相比之下，Vuzzer [73]通过静态分析捕获magic常数，并将现有值变为这些常数。 Steelix [55]使用二进制文件来收集有关比较指令的其他污点信息。最后，Angora [22]使用动态污点跟踪来识别有希望的突变位置并执行坐标下降以指导这些位置上的突变。</p>\n<p>然而，所有这些基于污点追踪的方法基本上受限于动态污点分析导致非常高的开销而静态污点分析遭受高误报率的事实。我们的实验结果表明，NEUZZ通过使用神经网络识别有希望的突变位置，轻松胜过现有的基于污点的现有模糊器。</p>\n<p>一些模糊测试器和测试输入发生器[43]，[83]，[22]试图直接在目标程序上使用不同形式的梯度引导优化算法。然而，如果没有程序平滑，这种技术往往会挣扎并陷入不连续性。</p>\n<p><strong>符号/执行的执行。</strong>符号和执行执行[50]，[14]，[77]，[61]，[36]使用可满足模数理论（SMT）求解器来解决路径约束并找到有趣的测试输入。一些项目也尝试将模糊测试与这些方法相结合[17]，[32]，[82]。不幸的是，由于符号分析的几个基本限制，包括路径爆炸，不完整的环境建模，符号记忆建模的大量开销等，这些方法在实践中难以扩展[16]。</p>\n<p>与我们的工作同时，NEUEX [79]通过使用NN学习程序的中间变量之间的依赖关系以及使用梯度引导神经约束求解在结合传统的SMT求解器，使符号执行更有效。相比之下，在本文中，我们专注于使用NN来提高模糊效率，因为它是迄今为止在大型真实世界程序中发现安全关键错误的最流行的技术。</p>\n<p><strong>神经程序。</strong>神经程序本质上是一个神经网络，它学习目标程序逻辑的潜在表示。最近的一些工作已经从程序的输入输出样本中合成了这样的神经程序，以准确地预测程序的新输入输出[41]，[74]，[62]。相比之下，我们使用NN来学习程序分支行为的平滑近似。</p>\n<h1 id=\"IX-结论\"><a href=\"#IX-结论\" class=\"headerlink\" title=\"IX 结论\"></a>IX 结论</h1><p>我们提出了NEUZZ，一种有效的学习型模糊器，它使用代理神经网络来平滑地逼近目标程序的分支行为。我们进一步演示了梯度引导技术如何用于生成新的测试输入，可以发现目标程序中的不同错误。我们的广泛评估表明，NEUZZ在检测到的错误数量和边缘覆盖率方面明显优于其他10个最先进的模糊器。我们的研究结果表明，利用不同的梯度引导输入生成技术和神经平滑技术可以显着提高模糊过程的有效性。</p>\n","categories":[{"name":"论文","slug":"论文","permalink":"http://yama0xff.com/categories/论文/"},{"name":"fuzzing","slug":"论文/fuzzing","permalink":"http://yama0xff.com/categories/论文/fuzzing/"},{"name":"机器学习","slug":"论文/fuzzing/机器学习","permalink":"http://yama0xff.com/categories/论文/fuzzing/机器学习/"}],"tags":[{"name":"fuzzing","slug":"fuzzing","permalink":"http://yama0xff.com/tags/fuzzing/"},{"name":"S&P'19","slug":"S-P-19","permalink":"http://yama0xff.com/tags/S-P-19/"},{"name":"神经网络","slug":"神经网络","permalink":"http://yama0xff.com/tags/神经网络/"}]},{"title":" HVLearn: Automated Black-box Analysis of Hostname Verification in SSL/TLS Implementations","date":"2019-04-11T07:30:56.000Z","path":"2019/04/11/HVLearn-Automated-Black-box-Analysis-of-Hostname-Verification-in-SSL-TLS-Implementations/","text":"AbstractSSL / TLS是用于保护网络通信的最常用的协议系列。 SSL / TLS的安全保证严重依赖于在SSL / TLS协议的握手阶段期间提供的X.509服务器证书的正确验证。主机名验证是证书验证过程的关键组件，它通过检查服务器的主机名是否与X.509证书中存在的任何名称相匹配来验证远程服务器的标识。主机名验证是一个非常复杂的过程，因为存在许多功能和角落情况，例如通配符，IP地址，国际域名等。因此，测试主机名验证实现是一项具有挑战性的任务。在本文中，我们介绍了HVLearn，一种用于分析SSL / TLS主机名验证实现的新型黑盒测试框架，它基于自动机学习算法。 HVLearn使用许多证书模板，即具有设置为特定模式的公用名（CN）的证书，以便测试来自相应规范的不同规则。对于每个证书模板，HVLearn使用自动机学习算法来推断确定性有限自动机（DFA），该自适应有限自动机描述与给定证书的CN匹配的所有主机名的集合。一旦为证书模板推断出模型，HVLearn就会通过查找来自其他实现的推断模型的差异或通过检查从规范派生的基于正则表达式的规则来检查模型中的错误。我们的方法背后的关键见解是，给定证书模板的可接受主机名形成了常规语言。因此，我们可以利用自动机学习技术来有效地推断接受相应常规语言的DFA模型。我们使用HVLearn来分析许多流行的SSL / TLS库中的主机名验证实现，以及用C，Python和Java等多种语言编写的应用程序。我们证明HVLearn可以比现有的黑/灰盒模糊技术实现更高的代码覆盖率11.21％。通过比较HVLearn推断的DFA模型，我们在测试的主机名验证实现中发现了8个唯一违反RFC规范的行为。其中一些违规行为至关重要，可能会使受影响的实施容易受到主动的中间人攻击。 relevant information 作者 Suphannee Sivakorn, George Argyros, Kexin Pei, Angelos D. Keromytis, and Suman Jana 单位 Department of Computer Science Columbia University, New York, USA 出处 2017 IEEE S&amp;P 原文地址 http://www.cs.columbia.edu/~suman/docs/hvlearn.pdf 源码地址 https://github.com/HVLearn 发表时间 2017年 1 简介SSL / TLS协议族是最常用的机制，用于保护网络通信的安全性和隐私免受中间人攻击。SSL / TLS协议的安全保证严重依赖于SSL / TLS握手阶段服务器提供的X.509数字证书的正确验证。反过来，证书验证依赖于主机名验证，以验证服务器的主机名（即完全限定的域名，IP地址等）是否与“SubjectAltName”扩展名或“公用名”中的标识符之一匹配“（CN）属性的呈现叶证书。因此，实施主机名验证时的任何错误都可能完全破坏SSL / TLS的安全性和隐私保护。 由于存在许多特殊情况（例如，通配符，IP地址，国际域名等），主机名验证是一个复杂的过程。例如，通配符（’*’）仅允许在主机名的最左侧部分（由’.’分隔）中。为了了解主机名验证过程中涉及的复杂性，请考虑在五个不同的RFC [18]，[20]，[21]，[24]，[25]中描述其规范的不同部分的事实。鉴于主机名验证过程的复杂性和安全性至关重要性，对实现进行自动分析以发现与规范的任何偏差至关重要。 然而，尽管主机名验证过程具有关键性质，但以前没有涉及SSL / TLS证书验证的对抗性测试的研究项目[36]，[38]，[45]，[50]，都不支持详细的主机名自动测试验证实施。先前的项目要么完全忽略对主机名验证过程的测试，要么只是检查是否启用了主机名验证过程。因此，他们无法检测到启用主机名验证实现的任何微妙错误，但会略微偏离规范。主机名验证实现的自动对抗性测试背后的关键问题是输入（即主机名和证书标识符，如常用名称）是高度结构化的稀疏字符串，因此使现有的黑/灰盒模糊测试技术难以实现高测试覆盖率或生成触发极端情况的输入。由于SSL / TLS实现的语言/平台多样性，严重的语言/平台相关的白盒测试技术也难以应用于测试主机名验证实现。 在本文中，我们设计，实现和评估HVLearn，一种基于自动机学习的黑盒差分测试框架，可以自动推断主机名验证实现的确定性有限自动机（DFA）模型。 HVLearn背后的关键见解是主机名验证，即使非常复杂，在概念上与许多方面的正则表达式匹配过程非常相似（例如，通配符）。对证书标识符格式结构的这种了解表明，如规范所建议的，给定证书标识符的可接受主机名形成常规语言。因此，我们可以使用黑盒自动机学习技术来有效地推断接受与给定主机名验证实现相对应的常规语言的确定性有限自动机（DFA）模型。 Angluin等人的先前结果。已经证明，在多个状态的多项式时间内，通过黑盒查询可以有效地学习DFA [31]。 HVLearn推断的DFA模型可用于有效执行现有测试技术无法做得好的两个主要任务：（i）查找和枚举多个不同实现之间的独特差异; （ii）通过计算来自不同实现的推断DFA模型的交集DFA，为主机名验证过程提取正式的，向后兼容的参考规范。 我们应用HVLearn来分析许多流行的SSL / TLS库，如OpenSSL，GnuTLS，MbedTLS，MatrixSSL，CPython SSL以及使用C，Python和Java等多种语言编写的Java HttpClient和cURL等应用程序。我们发现了8种不同的规范违规，例如国际化域名中的通配符处理不正确，域名与IP地址混淆，NULL字符处理不正确等等。其中一些违规行为允许网络攻击者通过允许攻击者读取/修改通过使用受影响的实现设置的SSL / TLS连接传输的任何数据来完全破坏SSL / TLS协议的安全保障。 HVLearn在任何两对测试应用程序/库之间平均发现了121个独特的差异。 本文的主要贡献如下。 据我们所知，HVLearn是第一个可以学习DFA模型以实现主机名验证的测试工具，这是SSL / TLS实施的关键部分。推断的DFA模型可用于有效的差分测试或提取与多个现有实现兼容的正式参考规范。 我们在HVLearn中设计并实现了几个特定于域的优化，如等价查询设计，字母表选择等，以便从主机名验证实现中有效地学习DFA模型。 我们在6个流行的库和2个应用程序上评估HVLearn。 HVLearn实现了比现有黑/灰盒模糊技术更高的代码覆盖率（平均11.21％），并发现了8个独特的先前未知的RFC违规，如表II所示，其中一些使得受影响的SSL / TLS实现对于man-in完全不安全 - 中间攻击。 本文的其余部分组织如下：第II部分介绍了SSL / TLS主机名验证过程。我们将在第III节讨论测试主机名验证和测试方法的挑战。第四节描述了HVLearn的设计和实现细节。我们在第V节中介绍了使用HVLearn测试SSL / TLS实现的评估结果。第六节介绍了HVLearn发现的几个安全关键错误的详细案例研究。第七节讨论了相关工作，第八节总结了论文。有关HVLearn发现的错误的详细开发人员回复，我们将感兴趣的读者引用到附录X-B。 2 主机名校验概述作为主机名验证过程的一部分，SSL / TLS客户端必须检查服务器的主机名是否与证书中的“公共名称”属性或证书中“subjectAltName”扩展名中的一个名称相匹配[21] 。请注意，即使该过程称为主机名验证，它也支持验证IP地址或电子邮件地址。 在本节中，我们首先简要介绍主机名格式和规范，这些格式和规范描述了X.509证书中的公共名称属性和subjectAltName扩展格式的格式。图1提供了X.509证书相关部分的高级摘要。接下来，我们将详细描述主机名验证过程的不同部分（例如，域名限制，通配符等）。 A.主机名验证输入主机名格式。主机名通常是完全限定的域名或没有任何 “.” 字符的单个字符串。若干SSL / TLS实现（即，OpenSSL）还支持将IP地址和电子邮件地址作为主机名传递到相应的主机名验证实现。 域名由多个“标签”组成，每个“标签”用 “.” 字符分隔。域名标签只能包含字母a-z或A-Z（不区分大小写），数字0-9和连字符’ - ‘[16]。每个标签最长可达63个字符。域名的总长度最多为255个字符。早期的规范要求标签必须以字母开头[21]。但是，随后的修订允许以数字[17]开头的标签。 X.509证书中的通用名称。公共名称（CN）是X.509证书中“主题可分辨名称”字段的属性。服务器证书中的公用名用于验证服务器的主机名，作为证书验证过程的一部分。通用名称通常包含完全限定的域名，但它也可以包含具有描述服务的任意ASCII和UTF-8字符的字符串（例如，CN =’Sample Service’）。对公共名称字符串的唯一限制是它应遵循X520CommonName标准（例如，不应重复子字符串’CN =’）[21]。请注意，这与非常严格定义的主机名规范不同，并且仅允许如上所述的某些字符和数字。 X.509证书中的SubjectAltName。主题备用名称（subjectAltName）是X.509扩展，可用于存储不同类型的身份信息，如完全限定的域名，IP地址，URI字符串，电子邮件地址等。每种类型对允许的格式都有不同的限制。例如，dNSName（DNS）和uniformResourceIdentifier（URI）必须是有效的IA5String字符串，是ASCII字符串的子集[21]。我们将感兴趣的读者引用到RFC 5280的4.1.2.6节以供进一步阅读。 B.主机名验证规则匹配顺序。 RFC 6125建议SSL / TLS实现使用subjectAltName扩展（如果存在于证书中），而不是通用名称，因为公共名称与标识没有很强的联系，并且可以是前面提到的任意字符串[24]。如果subjectAltName中存在多个标识符，则SSL / TLS实现应尝试匹配DNS，SRV，URI或实现支持的任何其他标识符类型，并且不得将主机名与证书的公用名匹配[24]。证书颁发机构（CA）也应该在颁发证书时使用dNSName而不是通用名称来存储身份信息[18]。 通用名称/ subjectAltName中的通配符。如果服务器证书包含通配符’*’，则SSL / TLS实现应使用RFC 6125 [24]中描述的规则将主机名与它们匹配。我们提供以下规则的摘要。 通配符仅允许在最左侧的标签中。如果所呈现的标识符在除最左侧标签之外的任何标签中包含通配符（例如，www.x.example.com和www.foo .example.com），则SSL / TLS实现应拒绝该证书。允许通配符出现在最左侧标签的任何位置，即通配符不必是最左侧标签中的唯一字符。例如，bar .example.com， bar.example.com或f bar.example.com等标识符有效。 在将主机名与证书中存在的标识符进行匹配时，标识符中的通配符应仅应用于一个子域，并且SSL / TLS实现不应与除主机名最左侧标签之外的任何内容进行比较（例如，* .example。 com应匹配foo.example.com但不匹配bar.foo.example.com 或 example.com）。 RFC 6125中允许涉及通配符的几个特殊情况仅用于向后兼容现有的SSL / TLS实现，因为它们往往与这些情况下的规范不同。 RFC 6125明确指出，这些情况通常会导致过于复杂的主机名验证代码，并可能导致潜在的可利用漏洞。因此，不鼓励新的SSL / TLS实现支持这种情况。我们总结了其中一些：（i）通配符是标识公共后缀的标签的全部或一部分（例如， .com和 .info），（ii）标签中存在多个通配符（例如，f b r.example.com），以及（iii）包含通配符作为多个标签的全部或部分（例如， . .example.com）。 国际域名（IDN）。 IDN可以包含特定语言字母表中的字符，如阿拉伯语或中文。IDN被编码为一串unicode字符。如果域名标签包含至少一个非ASCII字符（例如，UTF-8），则将其分类为U标签。 RFC 6125规定，在执行主机名验证之前，必须将IDN中的任何U标签转换为A标签域[24]。通过添加前缀’xn–’并将应用于相应Ulabel字符串的Punycode变换的输出附加到RFC 3492 [19]中所述，将U标签字符串转换为A标签（ASCII兼容编码）。 U标签和A标签仍然必须满足域名上的标准长度限制（即最多255个字节）。 subjectAltName中的IDN。如RFC 5280所示，X.509 subjectAltName扩展中的任何IDN必须定义为IA5String类型，它仅限于ASCII字符的子集[21]。在将IDN中的任何U标签添加到subjectAltName之前，必须将其转换为A标签。涉及IDN的电子邮件地址也必须先转换为A标签。 通用名称的IDN。与subjectAltName中的IDN不同，通用名称中的IDN允许包含PrintableString（AZ，az，0-9，特殊字符’=（）+， - ./：？和空格）以及UTF-8字符[21] ]。 通配符和IDN。没有规范定义如何将通配符嵌入IDN的A标签或U标签中[23]。因此，RFC 6125 [24]建议SSL / TLS实现不应与证书中的呈现标识符匹配，其中通配符嵌入在IDN的A标签或U标签内（例如，xn-kcry6tjko .example .COM）。但是，只要通配符占用IDN的最左侧标签（例如 .xn - kcry6tjko.example.com），SSL / TLS实现应匹配IDN中的通配符。 IP地址。 IP地址可以是证书中的公共名称属性或subjectAltName扩展名（带有“IP：”前缀）的一部分。 RFC 6125的3.1.3.2节规定在执行证书验证之前必须将IP地址转换为网络字节顺序八位字符串[24]。SSL / TLS实现应将此八位字节字符串与公用名称或subjectAltName标识符进行比较。对于IPv4和IPv6，八位字节串的长度必须分别为4个字节和18个字节。仅当两个八位字节字符串相同时，主机名验证才会成功。因此，IP地址标识符中不允许使用通配符，并且SSL / TLS实现不应尝试匹配通配符。 电子邮件。电子邮件可以作为旧版SSL / TLS实现中的emailAddress属性嵌入通用名称中。该属性不区分大小写。但是，新实现必须以rfc822Name格式添加电子邮件地址以使用替代名称扩展名而不是公共名称属性[21]。 际化电子邮件。与subjectAltName扩展中的IDN类似，在验证之前必须将国际化电子邮件转换为ASCII表示。 RFC 5321还指定网络管理员不得使用非ASCII字符和ASCII控制字符定义邮箱（local-part @ domain / address-literal）。如果本地部分和主机部分分别使用区分大小写和不区分大小写的ASCII比较，则认为电子邮件地址匹配（例如，MYEMAIL @ example.com与myemail@example.com不匹配但匹配MYEMAIL @ EXAMPLE.COM）[21]。请注意，此规范与嵌入在公共名称中的电子邮件地址相矛盾，该电子邮件地址应该完全不区分大小写。 主机部分中带有IP地址的电子邮件。 RFC 5280和6125未在电子邮件的主机部分中指定对IP地址的任何特殊处理，并且仅允许以rfc822Name格式的电子邮件。 rfc822Name格式支持主机部分中的IPv4和IPv6地址。因此，允许在主机部分中具有IP地址的电子邮件出现在证书[22]中。 电子邮件中的通配符。没有规范应该解释通配符并尝试匹配它们是证书中电子邮件地址的一部分。 subjectAltName中的其他标识符。还有其他标识符可用于执行身份检查，例如UniformResourceIdentifier（URI），SRVName和otherName。但是，大多数流行的SSL / TLS库不支持检查这些标识符并将其留给应用程序。 3 方法在本节中，我们将介绍主机名验证实现的自动化测试背后的挑战。尽管规模较小，但这些实现的多样性以及主机名验证过程中的细微之处使得这些实现难以测试。然后，我们继续描述使用自动机学习算法测试主机名验证实现的方法的概述。我们还简要介绍了自动机学习算法运行的基本设置。 A.主机名验证分析中的挑战我们认为，任何自动分析主机名验证功能的方法都应解决以下挑战： 1. 定义不明确的非正式规范。 如第II部分所述，尽管相关RFC提供了一些定义主机名验证过程的示例/规则，但许多极端情况未指定。因此，任何主机名验证实现分析都必须考虑其他流行实现的行为，以发现可能导致安全性/兼容性缺陷的差异。 2.名称检查功能的复杂性。 由于存在大量的角落案例和特殊字符，因此主机名验证比简单的字符串比较要复杂得多。因此，任何自动分析都必须能够探索这些极端情况。我们观察到证书标识符的格式以及匹配规则非常类似于正则表达式匹配问题。实际上，我们发现每个给定证书标识符的已接受主机名集合形成常规语言。 3.实施的多样性。 SSL / TLS协议的重要性和普及性导致了大量不同的SSL / TLS实现。因此，主机名验证逻辑通常以许多不同的编程语言实现，例如C / C ++，Java，Python等。此外，其中一些实现可能只能远程访问而无需访问其源代码。因此，我们认为黑盒分析算法是测试各种不同主机名验证实现的最合适的技术。 B. HVLearn的主机名验证分析方法受上述挑战的影响，我们现在提出了分析SSL / TLS库和应用程序中主机名验证例程的方法。 我们的HVLearn系统背后的主要思想如下：对于RFC中的不同规则以及RFC中未明确定义的模糊规则，我们生成具有通用名称的“模板证书”，这些名称是专门为检查具体规则。之后，我们使用自动机学习算法来提取DFA，该DFA描述与模板证书中的公用名匹配的所有主机名字符串的集合。例如，来自标识符模板“aaa。* .aaa.com”的实现的推断DFA可用于测试与RFC 6125中的规则的一致性，禁止将通配符出现在除最常见标签之外的任何其他标签中名称。 一旦学习算法生成DFA模型，我们就会检查模型是否违反任何RFC规则或其他可疑行为。 HVLearn提供了两种检查推断 DFA模型的方法：基于正则表达式的规则。第一个选项允许用户提供指定一组无效字符串的正则表达式。 HVLearn可以确保推断的DFA不接受任何这些字符串。例如，RFC 1035规定只应在主机名标识符中使用集[A-Za-z0-9]中的字符以及字符’’和’。’。因此，用户可以构造一个简单的正则表达式，HVLearn可以使用它来检查任何经过测试的实现是否接受具有给定集合之外的字符的主机名。 差分测试。 HVLearn提供的第二个选项是在推断的模型和从相同证书模板的其他实现推断的模型之间执行差异测试。给定两个推断的DFA模型，HVLearn使用我们在第IV-E节中讨论的算法在两个模型之间生成一组独特的差异。此选项对于查找在RFC中未明确定义的极端情况中的错误特别有用。 我们总结了我们方法的优势如下所示： 采用黑盒学习方法确保我们的分析方法独立于语言，我们可以轻松测试各种不同的实现。我们唯一的要求是能够使用我们选择的证书和主机名查询目标库/应用程序，并查找主机名是否与证书中的给定标识符匹配。 如上一节所述，主机名验证类似于正则表达式匹配。鉴于正则表达式可以表示为DFA，采用基于自动机的学习算法来表示每个证书模板的推断模型是一种自然而有效的选择。 最后，拥有DFA模型的另一个好处是我们可以有效地比较两个推断模型并枚举它们之间的所有差异。此属性对于差分测试非常重要，因为它有助于我们分析规范中的模糊规则。 限制。选择将我们的系统作为黑盒分析方法实现的自然权衡是我们无法保证模型的完整性或稳健性。但是，HVLearn推断出的每个差异都可以通过查询相应的实现来轻松验证。此外，由于我们的系统会发现实现之间的所有差异，因此除非明确指定规则，否则它不会报告所有实现中常见的错误，如上所述。最后，我们指出，并非所有系统之间的差异都必然是安全漏洞;对于模糊的RFC部分，它们可能代表同样可接受的设计选择。 C.自动机学习算法我们现在将描述自动机学习算法，它们允许我们实现基于自动机的分析框架。 学习模式。我们利用工作在主动学习模型中的学习算法，这种模型称为从查询中精确学习。传统的监督学习算法，例如用于训练深度神经网络的算法，在一组给定的标记示例上工作。相比之下，我们模型中的主动学习算法通过自适应地选择用于查询目标系统并获得正确标签的输入来工作。 图2展示了我们的学习模型。学习算法试图通过用其选择的输入查询目标系统来学习目标系统的模型。最后，通过多次查询目标系统，学习算法推断出目标系统的模型。然后通过等价oracle检查此模型的正确性，oracle检查推断模型是否正确地总结了目标系统行为。如果模型是正确的，即它与所有输入上的目标系统一致，则学习算法将输出生成的模型并终止。另一方面，如果模型不正确，等价oracle将产生一个反例，即目标系统和模型产生不同输出的输入。然后，学习算法使用反例来细化推断的模型。该过程重复进行，直到学习算法产生正确的模型。 总而言之，精确学习模型中的学习算法能够使用两种类型的查询与目标系统进行交互： 成员资格查询：此类查询的输入是字符串s，输出是接受还是拒绝，具体取决于字符串s是否被目标系统接受。 等价查询：等价查询的输入是模型M，如果模型M等于所有输入上的目标系统，则查询的输出为True，或者模型和目标系统下的反例输入产生不同的产出。 在实践中的自动化学习。第一个用于从查询模型中精确学习DFA模型的算法是由Angluin [31]开发的，随后在接下来的几年中进行了大量的优化和变化。在我们的系统中，我们使用Kearns-Vazirani（KV）算法[54]。 KV算法利用称为区分树的数据结构，并且在推断DFA模型所需的查询量方面实际上更有效。 为了在实践中使用KV算法和其他自动机学习算法，应该解决的最重要的挑战是如何实现高效且准确的等价oracle以模拟由学习算法执行的等价查询。由于我们只对目标系统进行黑盒访问，因此任何实现等价查询的方法都必然是不完整的。 在HVLearn中，我们使用Wp-method[49]来实现等价查询。 Wp-method仅使用对目标系统的黑盒查询来检查推断的DFA与目标系统之间的等效性。本质上，Wp-method通过使用多个成员资格查询来近似等价oracle。该算法作为输入给出了要检查的DFA和目标系统中状态数量的上限，当建模为DFA时，我们称之为深度的参数。然后，算法创建一组测试输入S，然后将其提交给目标系统。如果目标系统与测试集S中所有输入的DFA模型一致，则在假设目标系统的状态数的上限正确的情况下，DFA和目标系统被证明是等效的。 从理论上讲，可以将Wp-method的深度参数设置为一个非常大的值，以便设计一个在实践中完整的等价oracle。但是，Wp-method产生的测试输入集的大小是O（n2 |Σ|^( m-n + 1)），其中Σ是DFA的输入字母，m是目标系统的状态数的上限，n是输入DFA中的状态数。因此，使用具有大深度的Wp-method（即，目标系统的状态数量的上限）是不切实际的。注意，Wp-method产生的测试输入数量的界限不是最坏的情况;相反，产生的测试输入数量通常是该顺序。 因此，我们的系统的效率必须为我们的DFA维护一个小字母表，并在使用Wp-method时设置目标系统状态数的小上限（深度）。我们将在下一节中解决这两个问题。 IV . HVLEARN的体系结构在本节中，我们将基于自动机学习技术描述我们的系统HVLearn的设计和实现。具体来说，我们描述了当我们尝试在实践中使用自动机学习算法时出现的技术挑战。我们还总结了HVLearn为解决这些挑战而实施的优化，并有效地学习了主机名验证实现的DFA模型。 A.系统概述图3概述了如何使用HVLearn分析SSL / TLS库的主机名验证功能。要使用HVLearn，用户提供对主机名验证功能的HVLearn访问权限，该功能将X.509证书和主机名作为输入，并根据提供的主机名是否与证书中的标识符匹配来返回接受/拒绝。我们将在第IV-C节中描述如何实现此接口。我们的系统包括许多证书模板，这些证书模板是用于根据第IV-B节中描述的许多不同规则测试SSL / TLS实现的证书。对于每个此类模板，HVLearn将学习一个DFA模型，该模型描述给定证书模板的给定实现所接受的主机名集。为了生成DFA模型，HVLearn使用LearnLib [59]库，该库包含KV算法和Wp-method的实现。为了避免将Wp-method的最大深度设置为不切实际的高值，我们按照第IV-D节中的描述优化等效oracle。 生成模型后，我们的系统将继续按照第IV-E节中的描述分析模型。然后保存我们的分析结果，推断模型和模型之间的差异以供重复使用。可选地，HVLearn还可以利用证书模板的推断模型来提取相应证书模板的正式规范，如第V-F部分所述。 B.生成证书模板为了涵盖主机名验证中的所有不同规则和模糊实践，我们创建了一组具有不同标识符模板的23个证书，其中每个证书用于测试规范中的特定规则。选择这些证书是为了涵盖我们在第II节中描述的所有规则。例如，具有通用名称“xn - a * .aaa”的证书将测试实现是否允许通配符作为IDN中A标签的一部分，这是RFC 6125明确禁止的。我们的模板证书是自我使用GnuTLS库生成的签名X.509 v3证书。我们选择使用GnuTLS进行证书生成，因为它允许在主题公用名和SAN中使用嵌入的NULL字符的标识符。要测试的模板标识符放在Subject CN和/或SAN中（如dNSName，iPAddress或email）。 C.执行成员资格查询为了利用LearnLib中的学习算法（包括Wp-method），我们实现了一个成员资格查询功能，可以对目标系统执行所有查询。此函数接受像字符串的输入并返回二进制值。在我们的系统中，我们使用目标SSL / TLS实现中的主机名验证功能。我们在此注意到，由于LearnLib是用Java编写的，而我们测试的许多SSL / TLS实现都是用C / C ++ / Python编写的，在这种情况下m我们利用Java Native Interface（JNI）[10]有效地对目标进行成员资格查询。 D.自动学习参数和优化在本节中，我们将描述我们实现的体系结构决策和优化，以有效地扩展KV算法，以测试复杂的实际SSL / TLS主机名验证实现。 字母大小。我们要利用KV算法做出的第一个重要决定是选择算法将使用的字母表。字母表是指学习算法将测试的符号集。 一种简单的方法是使用一组非常通用的字符，例如ASCII字符集。然而，这会对我们系统的性能造成不必要的开销，因为KV算法和Wp-method的性能在很大程度上依赖于底层字母大小。我们的主要观点是，我们可以将字母表缩减为一小组代表性字符，这些字符将彻底测试主机名验证的所有不同方面。特别地，我们在实验中选择集合Σ= {a，1，dot，\\ s，@，A，=，*，x，n，\\ u4F60，NULL}作为输入字母表。在所呈现的字母表中，’dot’表示 ‘.’ 字符，\\ s表示空格字符（ASCII值32），NULL表示零字节字符，\\ u4F60表示具有十六进制值4F60的unicode字符。请注意，这组符号足以分析主机名验证实现，因为它包含来自所有不同类别的字符，如小写，大写，数字，unicode等，以及特殊字符，如NULL字符。为了编码IDN主机名，必须使用小写字符’x’，’n’和’ - ‘字符。最后，包含一些非字母数字字符（如“=”字符）允许我们检测实现接受无效主机名的违规行为。 请注意，即使使用此字母集生成的主机名在处理为DNS名称时通常也无法解析为真实IP地址，但它不会以任何方式影响我们的分析的准确性。这是一个副作用，即主机名验证例程不负责将提供的DNS名称解析为IP地址。它只是检查给定的主机名是否与提供的证书中的标识符匹配。 缓存成员资格查询。为避免使用相同输入重复查询SSL / TLS实现的通信成本，我们利用LearnLib的DFALearningCache类来缓存成员资格查询的结果。在每个新查询上检查缓存，并在找到时使用缓存结果。此优化对于减少Wp-method在多个等价查询中生成的重复查询的开销特别有用。 优化等价查询。实际上，学习算法生成的第一个模型通常只是单个状态DFA，它拒绝所有主机名。原因是学习算法不能生成任何接受主机名，因此无法区分目标系统中的初始状态和任何其他状态。有时，为了强制KV算法使用Wp-method生成接受主机名，需要非常大的深度。这可能会导致系统中的效率问题。但是，如果我们为模型提供接受主机名，那么无需在Wp方法中使用过多的深度参数即可快速改进平凡模型。 回想一下，Wp-method中的指数项取决于模型中状态数与提供的深度之间的差异。因此，一旦我们在目标系统中发现接受状态，具有小得多的深度的Wp-methods仍将能够探索主机名验证实现的许多不同方面。 为了生成接受主机名，我们在等价查询期间和调用Wp方法之前执行以下测试。首先，我们在提供的通用名称中搜索任何通配符（*），并用字母表中的随机字符替换它们以获得具体的主机名。接下来，我们检查生成的模型和目标主机名验证实现是否同意使用此方法生成的一组主机名。如果没有，我们将返回它们不同的主机名作为反例。这种启发式的主要优点是它允许我们快速生成接受主机名，这些主机名在目标系统中发现新状态，而无需调用具有非常大深度值的Wp-method。一旦发现这些状态，并且推断模型的质量提高，则利用具有小深度参数的Wp-method来发现目标系统中的其他状态。 E.推断的DFA模型的分析和比较在HVLearn输出模型之后，我们系统的下一个任务是分析生成的RFC违规模型或RFC中的混淆/模糊规则，比较不同的推断模型并分析发现的任何差异不同的实现之间。 分析单个DFA模型。对于单个模型，我们希望确定模型是否接受RFC规范禁止的无效主机名。如果规范不清楚，除了下面描述的差异分析之外，我们的分析仍然可以用于手动检查特定证书模板上的实现行为。 我们的系统提供两种选择来执行单个模型的分析。首先，我们的系统生成输入，这些输入将在推断的模型中运用导致接受状态的所有简单路径（即，没有循环的路径）。直观地说，这些输入是一小组输入，描述了给定证书模板可接受的所有不同主机名。通过检查这些证书，我们可以确定实现是否接受无效的主机名。其次，HVLearn允许用户指定要针对推断模型检查的正则表达式规则。在这种情况下，用户指定正则表达式，HVLearn验证正则表达式和推断模型不共享任何公共字符串。此选项允许使用简单的正则表达式规则轻松检查某些RFC违规。例如，请考虑规则，指定不应将非字母数字字符作为匹配主机名的一部分。通过指定正则表达式规则“（.） =（.）”，我们可以检查在推断模型中是否存在包含“=”字符的任何匹配主机名。 比较DFA模型之间的独特差异。为了分析RFC中未指定的某些极端情况，测试单个模型可能还不够。相反，我们比较不同SSL / TLS实现的推断模型，并找到实现行为不同的输入。为了执行此分析，我们使用[33]中的差异枚举算法。简而言之，该算法计算两个或更多给定模型之间的乘积DFA，然后找到所有简单路径到达DFA产生不同输出的状态。 F.规范提取正如我们已经讨论的那样，RFC规范通过在所有情况下都没有指定正确的行为，将主机名验证的某些方面留给了实现。在这些情况下，在实现中强加特定限制是具有挑战性的，因为我们必须小心避免破坏与现有实现和有效证书的兼容性。在本节中，我们将描述对于RFC规范含糊不清的情况，如何使用不同证书模板的推断DFA模型来推断与现有实现兼容的正式规范。我们的主要见解如下：对于每个证书模板，我们可以使用DFA接受所有SSL / TLS实现接受的主机名集作为相应规则模板的正式规范。这种选择背后的直觉是，该规范避免了每个库的小特性，因此非常紧凑。另一方面，如果此规范中存在漏洞，则此漏洞也必须存在于所有经过测试的实现中。由于每个实现都是独立审计的，因此我们的选择使我们相信我们的规范可以抵御简单的漏洞，同时保持与测试实现的向后兼容性。 计算规范。为了计算每个证书模板的相应规范，我们按如下方式进行：首先，我们使用HVLearn获取所有正在测试的主机名验证实现的DFA模型。接下来，我们计算所有推断模型产生的DFA。产生 的DFA接受每个DFA的常规语言的交集。我们使用标准自动机算法计算产生的DFA [60]。我们的实现集的推断形式规范由每个DFA模型的产品DFA表示。然后可以将此产品DFA转换回正则表达式以提高可读性。 最后，我们想指出，计算k个DFA的交集具有最差的O（nk）时间复杂度，其中n是每个DFA中的状态数[55]。但是，在我们的例子中，推断的DFA大多数是相似的，因此产品结构非常有效，因为相交两个DFA并不会在最终产品DFA中添加大量状态。我们在第五节提供了更多证据支持这一假设。 V.评估我们评估HVLearn的主要目标是回答以下问题：（i）HVLearn在实际主机名验证实施中发现RFC违规的效果如何？ （ii）我们的优化对提高HVLearn的性能有多大帮助？ （iii）HVLearn相比现有的黑盒或覆盖范围的灰盒技术如何（iv）进行比较，HVLearn可以从推断的实际主机名验证实现的DFA推断出后向兼容的规范。 A.主机名验证测试主题我们使用HVLearn测试六种流行的开源SSL / TLS实现中的主机名验证实现，即OpenSSL，GnuTLS，MbedTLS（PolarSSL），MatrixSSL，JSSE和CPython SSL，以及两种流行的SSL / TLS应用程序：cURL和HttpClient。请注意，像1.0.1之前的OpenSSL版本这样的几个库不提供对主机名验证的支持，而是由应用程序开发人员实现它。因此，支持不同库的cURL / HttpClient等应用程序通常被迫编写自己的主机名验证实现。 在支持主机名验证的库中，有些像OpenSSL提供了单独的API函数，用于匹配每种类型的标识符（即域名，IP地址，电子邮件等），并根据设置将其留给应用程序选择合适的一个。 相比之下，像MatrixSSL这样的其他人将所有支持的标识符类型组合在一个函数中，并通过检查输入字符串找出合适的标识符。表I显示了我们测试的所有实现的主机名验证函数/类名称以及它们各自支持的标识符类型。最后一列显示了SLOCCount [14]工具报告的每个主机匹配函数/类的物理源代码行（SLOC）。请注意，显示的SLOC仅计算执行主机名匹配的代码部分。 B.使用HVLearn查找RFC违规我们使用HVLearn为每个不同的证书模板生成DFA模型，这些模板对应于来自RFC的不同模式。之后，我们通过执行输出DFA的差异测试以及检查单个DFA是否违反基于规则表达式的规则来检测潜在的错误行为，这些规则是我们手动创建的，如第IV-E节所述。 表II列出了我们的实验结果。我们评估了来自四个不同RFC的各种规则[16]，[17]，[21]，[24]。我们发现，我们测试的每个规则都被至少一个实现违反，而平均每个实现都违反了三个RFC规则。其中一些违规行为具有严重的安全隐患（例如，错误处理国际域名中的通配符，将IP地址混淆为域名等）。我们将在第VI节中详细描述这些案例及其安全隐患。 请注意，违规次数最多的库是JSSE（四次违规），而HttpClient是违规次数最多的应用程序（五次违规）。 OpenSSL，MbedTLS和CPython SSL每个只有两个违规，共同违反匹配的无效主机名。感兴趣的读者可以在附录中找到我们结果的扩展描述（表VIII）。 C.比较DFA模型之间的唯一差异为了评估所有不同主机名验证实现之间的差异，我们计算了测试集中每对主机名验证实现的差异数。回想一下，对于两个给定的DFA模型，我们将差异的数量定义为产品DFA中的简单路径的数量，这导致两个模型产生不同的输出[33]。 表III列出了我们实验的结果。例如，OpenSSL和GnuTLS总共有95个差异。这是通过总结表VIII中每个通用名称的推断的DFA之间不同的唯一路径的数量而获得的。请注意，所有实现对都包含大量唯一的情况，在这些情况下它们会产生不同的输出。如表III所示，每对测试的实现在它们之间平均有127个独特的差异。我们注意到一些差异仅仅意味着不明确的RFC规则，而一些差异则揭示了潜在的无效主机名或RFC违规错误。感兴趣的读者可以在附录中的表VIII中找到每个实现所接受的唯一字符串的更详细列表。在任何情况下，我们发现SSL / TLS协议的这种安全关键组件的所有实现都存在如此大量的差异，这是一个令人担忧的问题，因为它表示规范实施不当或规范模糊不清本身。我们的分析表明这两种情况都存在于实践中。 D.比较HVLearn和黑/灰盒模糊的代码覆盖率为了比较HVLearn在查找错误和黑/灰盒模糊测试中的有效性，我们研究了以下研究问题： RQ.1：HVLearn的代码覆盖率与黑/灰盒模糊技术的不同？ 我们比较了HVLearn和其他两种技术（黑盒模糊测试和覆盖引导灰盒模糊测试）所测试的主机名验证实现的代码覆盖率。我们在下面简要描述我们的测试设置 HVLearn：HVLearn利用自动机学习，通过预定义的证书模板和字母集调用主机名验证匹配例程。 HVLearn通过使用新的主机名字符串查询实现，自适应地优化与测试主机名验证实现相对应的DFA。我们测量在学习过程中实现的代码覆盖率，直到完成为止。我们还监视NQ的查询总数，它来自成员资格和等价查询。 黑盒模糊测试：使用HVLearn使用的相同字母和证书模板，我们随机生成NQ字符串并使用相同的证书模板查询目标SSL / TLS主机名验证功能。请注意，黑盒模糊器生成独立的随机字符串，没有任何指导。 覆盖引导的灰盒模糊测试：与黑盒模糊测试不同，覆盖引导的灰盒模糊测试通过使用进化技术在输入生成过程中尝试生成更有趣的输入。在每一代中，通过突变/交叉从上一代生成新的一批输入，并且仅保留增加代码覆盖的输入以进行进一步的改变。覆盖引导的灰盒模糊测试是一种在大型真实世界程序中查找错误的流行技术[6]，[11]。 为了与HVLearn进行公平的比较，我们实现了我们自己的覆盖引导灰盒模糊器，因为像AFL这样的现有工具不能提供限制给定字母表中的突变输出的简单方法。使用相同的字母集，我们用一组不同长度的字符串初始化模糊器，因为种子在队列Q中保存。然后，模糊器使用种子来查询目标主机名验证实现。完成查询后，使用种子，模糊器获得字符串S =dequeue（Q）。它随机改变S中的一个字符并获得 S’。然后它使用变异的 S‘ 查询目标。如果变异的字符串 S’ 增加代码覆盖率，我们将其存储在队列中以进一步突变，即enqueue（S‘，Q）。否则，我们扔掉它。因此引导模糊器总是在具有更好代码覆盖的字符串上变异。模糊器迭代地执行NQ轮次的这种入队/出队操作，并且我们获得每个功能SSL / TLS实现的最终代码覆盖COV_randmu。请注意，我们在整个测试期间保持测试证书模板的固定。 我们使用由Gcov [51]提取的行的百分比作为代码覆盖率的指标。考虑到主机名验证只是SSL / TLS实现的一小部分，我们不计算相对于总行数的行百分比。相反，我们计算仅考虑与主机名验证相关的函数中行覆盖率的百分比。 结果1：与黑/灰盒模糊测试技术相比，HVLearn平均增加了11.21％的代码覆盖率。 因此，令LE（f）为SI中函数f执行的行数，L（f）为f的总行数，代码覆盖率可在以下公式中定义：$$coverage = \\frac {\\sum_{i = 1}^m LE（f_i）}{\\sum_{i=1}^m L（f_i）}$$其中f1，f2，…，fm是与主机名验证相关的函数。图4显示了代码覆盖率比较，它表明与黑/灰盒模糊测试技术相比，HVLearn实现了明显更好的代码覆盖率。 E.自动学习性能HVLearn主要基于KV算法和Wp-method来执行其分析。因此，彻底评估这些算法的不同参数及其对HVLearn性能的影响至关重要。我们现在将评估学习算法的每个不同参数对HVLearn整体性能的影响。 RQ.2：字母大小如何影响HVLearn在实践中的表现？ 如第III-C部分所述，字母表大小会影响我们系统的性能。理论上，KV算法和Wp-method的性能取决于输入字母表的大小。我们进行了两个实验，用于评估字母大小在实践中影响学习算法组件性能的程度。在第一个实验中，我们评估了在真实世界的DNS名称中增加字母表大小的效果。对于本实验，我们在默认配置中使用了我们的系统，并启用了所有优化（例如，查询缓存和EQ优化），并将Wp-method深度设置为1.我们使用CPython的SSL实现作为这些实验的主机名验证功能。 图5显示了我们实验的结果。请注意，从字母大小9开始，我们在字母表中包含的每个附加字符将使学习算法执行至少10％以上的查询，以便为两个DNS名称生成模型，而此百分比仅增加当更大的字母大小。 我们还测量了增加字母大小对我们系统整体运行时间的影响。为了执行此实验，我们使用与之前实验相同的设置，并使用包含通用名称“* .aaa.aaa”的证书评估HVLearn的性能。表IV显示了该实验的结果。我们注意到，成员资格查询的增加直接转化为增加的运行时间。具体来说，通过在字母表中添加5个附加字符（从2到5），我们注意到运行时间增加了7倍。当我们在字母表集中添加更多字符时，可以观察到类似的结果。 结果2：在字母表集中仅添加一个符号会导致查询数量增加至少10％。因此，HVLearn使用的简洁字母集对系统的性能至关重要。 RQ.3：会员缓存会提高HVLearn的性能吗？ 表IV列出了使用和不使用不同字母大小的成员资格查询缓存来推断具有公共名称“* .aaa.aaa”的证书模板的模型所需的查询数。我们注意到缓存始终有助于减少推断模型所需的成员资格查询数量。总的来说，缓存将查询数量减少了42％，从而显着提高了系统的效率。因此，对于本节中的其余实验，我们利用启用了成员资格查询缓存的系统。 结果3：成员缓存平均提供学习算法所产生的成员资格查询数量减少42％。 RQ.4：Wp-method的深度参数如何影响HVLearn的性能和准确度？** 如第IV-D节中所讨论的，Wp-method执行的查询数量是可自定义深度参数的指数。我们评估了这个指数项在实践中如何影响查询的数量，此外，深度参数的不同值对HVLearn推断的模型的正确性有何影响。 对于我们的第一个实验，我们探索了成员查询总数与相应深度参数之间的相关性。该实验的结果显示在图6和表V中。为了确保实验在合理的时间内完成，我们进一步将字母大小减小到仅两个符号。结果清楚地表明，深度参数与学习算法执行的查询总数之间的依赖关系是明确的指数，实际上与O（|Σ| ^d）界限完全匹配，其中d是深度参数，如章节中所讨论的IV-d。请注意，当Wp-method的深度参数设置为小于8的值时，HVLearn无法推断目标实现的任何方面，并输出拒绝所有主机名的单个状态DFA模型，如表V所示 结果4：Wp-method深度参数的较大值导致不切实际的运行时间，而较小的值导致不完整的模型。 RQ.5：HVLearn中的等价查询优化提供了多少改进？ 之前的实验清楚地表明单独使用Wp-method不足以使用HVLearn准确分析各种不同的模板。使用我们的完整字母表，推断出通用名称“* .aaa.aaa”的完整模型需要深度参数≥8，如表V所示。使用13个符号的完整字母表，这将需要大约230个基于查询算法的复杂性。我们发现即使运行深度为6的算法，仍然无法推断出完整的模型，也会导致超过6800万个查询。因此，我们的等价查询优化是HVLearn的一个重要组成部分，它允许它生成准确的DFA模型，可用于评估实现的安全性和正确性。从表V可以看出，使用我们的等价查询优化和深度参数仅为1，我们的系统能够为给定的证书模板生成完整的模型。运行相同的实验，字母大小为15，我们发现HVLearn仅使用14,812个查询推断出正确的模型，如表IV所示 结果5：在某些情况下，EQ优化提供了推断完整DFA模型所需的查询数量超过一个数量级的改进。 F.规范提取现在让我们来研究如何利用HVLearn的规范提取功能来推断对应于通用名称“* .a.a”的规则的实际规范。此规则对应于基本通配符证书情况，其中在标识符的最左侧标签中找到通配符。尽管如此，图7表明即使对于这个简单的规则，不同实现的相应DFA模型也存在明显的差异。例如，DFA模型（a）接受主机名“.a”，模型（b）接受主机名“.a.a”，而模型（d）接受主机名“a.a.a.”。只有模型（c）通过仅接受与正则表达式“a + .a.a”匹配的主机名来执行最直观的匹配（这里’+’表示字符’a’的一个或多个重复）。 通过计算所有DFA模型之间的交集，我们获得了交叉点DFA模型（e）。我们的第一个观察是交叉点DFA只有6个状态，因此它非常紧凑，如第V-F节所述。此外，我们注意到交叉点DFA与DFA（c）相同，它对应于相应规则的最自然的实现。更重要的是，即使我们计算交叉点而不包括模型（c），我们仍然会推断出相同的规范。因此，我们得出结论，计算DFA模型的交集，即使是以不同方式失败的实现，通常也可以生成紧凑和自然的规范。 推断模型的大小。通常，推断模型的实际大小在很大程度上取决于测试系统的实现细节。但是，我们希望系统推断的DFA模型将具有大约l + 2个状态，其中l是证书模板中公共名称的长度。实际上，如果我们考虑图7中推断的DFA，我们可以注意到，对于长度为l = 5的通用名称“* .a.a”，平均状态数为6.9，这非常接近预期的7个状态。直观地说，这个大小背后的推理是，用于匹配长度为l的字符串的DFA通常具有l + 2个状态，其中l个状态将DFA向前移向接受状态，而另外2个状态包括初始状态和当找不到匹配时DFA进入的接收器状态 VI. bugs案例研究 我们的研究目标旨在通过证书验证中不正确或不明确的主机名检查来了解潜在利用的严重性。我们也有兴趣发现SSL / TLS实现的主机名检查与RFC指定的不一致。在本节中，我们将介绍我们从实验结果或我们发现的拐角案例中获得的一些有趣案例。 A. IDN标识符中的A-labels内的通配符RFC 6125严格禁止将证书与包含嵌入在IDN的A-labels内的通配符的标识符进行匹配。对于具有“xn-aa *”形式的标识符的证书，由于转换过程的复杂性，很难预测将它们转换为punycode格式后将匹配的unicode字符串集合。无法轻松预测与A标签匹配的主机名集与嵌入式通配符通常会为中间人攻击提供途径。 最近在Ruby OpenSSL扩展[28]和Mozilla Firefox [27]使用的NSS库中发现了将标识符与嵌入在A-labels中的通配符匹配的主机名验证实现。这些问题被相应产品的开发人员识别为安全漏洞。 使用HVLearn，我们发现JSSE和HttpClient（在构造函数中不使用PublicSuffixMatcher）也容易受到此问题的影响。我们的工具还报告其他测试的库/应用程序没有受到影响。 B.混淆CN和SAN标识符之间的检查顺序RFC 6125明确指定当存在任何subjectAltName标识符时，应用程序不应尝试将主机名与主题CN匹配，而不管subjectAltName中是否存在匹配，如第II部分所示。我们使用HVLearn发现了一些违反该规则的行为，如表II所述。我们还发现MatrixSSL在这种情况下表现出一种有趣的行为。 更具体地说，MatrixSSL在尝试匹配SAN中的任何标识符之前匹配CN标识符，即使它们存在于证书中。请注意，CN对其内容没有任何强烈限制，甚至可能包含非FQDN字符（例如，UTF-8）。因此，某些证书颁发机构可能会遵循RFC 6125中的说明，在存在SAN标识符的情况下不会检查CN，并且只要用户被成功识别为CN，就会发出证书而不管CN中的值。 SAN标识符中域的所有者。虽然很自然，但这种选择会使使用MatrixSSL的应用程序容易受到简单的中间人攻击。 具体而言，攻击者可以为攻击者拥有的域生成带有SAN标识符的签名证书，例如“www.attacker.com”，并将CN字段设置为受害域，例如“www.bank.com”。 MatrixSSL将首先检查CN并省略检查SAN标识符。因此，MatrixSSL将允许攻击者劫持CN字段中存在的任何域（例如，www.bank.com）。 C.劫持基于IP的证书RFC [16]中域名实现和规范的第2.3.1节规定，首选名称（标签）应仅以字母字符开头。但是，RFC [17]更改了此限制，以允许第一个字符为字母或数字。此更改引入了与IP地址相同的有效DNS名称。 不幸的是，IP地址也是有效的DNS名称这一事实可能为攻击开辟了一条新的途径，如下所述。请注意，要使此攻击变得切实可行，必须存在0-255范围内的数字顶级域（TLD），这是当前不可用的。尽管如此，我们的描述应作为新TLD的预防性说明。 该攻击基于以下事实：某些实现首先检查给定主机名是否与证书的CN / SAN匹配为域名，然后是IP地址。因此，请考虑攻击者控制IP地址，例如80.50.12.33并持有具有该IP地址的基于IP的证书。然后，假设“33”是有效的TLD，同一实体将自动拥有域名“80.50.12.33”的证书，并可以对该域执行中间人攻击！ 我们评估了此攻击在当前的SSL / TLS实现中是否可行。表VI显示了我们的评估结果。在主题CN或subjectAltName DNS列中标记为accept的所有库/应用程序都容易受到此攻击。尽管此问题目前尚未被利用，但如果将来引入数字TLD，则会给这些库带来安全风险 D. CN / SAN标识符中的嵌入NULL字节2008年，Kaminsky等人 [53]演示了流行的SSL / TLS库的主机名验证实现中的漏洞，其中X.509 CN中的早期NULL字节（\\ 0）终止导致某些库识别不同的CN值。简而言之，客户端在尝试连接到“www.bank.com”时接受来自攻击者子域“www.bank.com \\ 0.attacker.com”的证书，因此允许攻击者劫持连接。 为了防御这次袭击，接下来是两道防线。第一种选择是拒绝任何包含嵌入在任何CN / SAN标识符中的NULL字节的证书。第二种是简单地修补从函数中检索CN / SAN标识符的API函数，以便即使存在嵌入的NULL字节也可以恢复整个标识符。我们彻底评估了每个SSL / TLS库中实施的防御。表七列出了我们的评估结果。第二列描述SSL / TLS库是否允许嵌入的NULL字节，第三列显示用于检索CN / SAN标识符的相应API函数，第四列描述API调用是否也返回相应的长度CN / SAN标识符。请注意，这是一个非常重要的功能，否则，使用SSL / TLS库的应用程序无法知道标识符字符串的终止位置。我们注意到除了JSSE之外，所有库都实现了这个重要的特性。请注意，即使JSSE没有返回相应标识符的长度，因为JSSE是用Java编写的，所以它不容易受到嵌入式NULL字节攻击，因为Java字符串不是NULL终止的。 尽管SSL / TLS实现采取预防措施来防止嵌入式NULL字节攻击，但这并不意味着使用这些库的应用程序也是安全的。实际上，实现主机名验证功能的应用程序必须确保它们不使用易受攻击的函数，例如来自libc的标准字符串比较函数（例如，strcmp，strcasecmp，fnmatch），因为它们匹配NULL终止样式的字符串。 为了评估使用SSL / TLS库抵御嵌入式NULL字节攻击的应用程序的安全性，我们对几个应用程序进行了手动审计。不幸的是，我们发现几个流行的应用程序容易受到使用嵌入NULL字节证书的中间人攻击。一些例子包括FreeRadius服务器[8]，它是部署最广泛的RADIUS（远程认证拨入用户服务）服务器之一，OpenSIPS [12]是一种流行的开源SIP服务器，Proxytunnel [13]是一种隐身隧道代理和Telex Anticensorship系统[15]，它是一个开源的审查制度绕过软件。 本节的一个重要内容是嵌入NULL字节攻击，即使在SSL / TLS库级别处理，仍然对使用这些库的应用程序提出了非常现实和被忽视的威胁。 VII. 相关工作A.保护SSL / TLS实现 已经在大量项目中检查了SSL / TLS实现的不同组件的安全性分析。我们提供以下最相关项目的摘要。这些项目与我们的项目之间的主要区别在于，这些项目都没有专注于自动分析SSL / TLS证书验证实现的主机名验证部分的正确性。先前的工作不包括详细分析主机名验证，主要是准确建模实施的硬度。在本文中，我们通过使用自动机学习技术并证明它们能够以黑盒方式准确有效地推断主机名验证实现的DFA模型来解决这个问题。 自动分析SSL / TLS实施。布鲁贝克等人 [36]随后陈等人 [39]使用基于突变的差异测试来查找证书验证问题。但是，在他们的情况下，被禁用的主机名验证功能被禁用，以便发现其他证书验证问题，因此，他们无法发现我们的工作发现的错误。He等人 [52]使用静态分析来检测SSL / TLS库API的错误使用。 Somorovsky [61]创建了TLS-Attacker系统地模糊TLS实现的工具。但是，TLS-Attacker专注于查找协议级别的错误，并且没有分析SSL / TLS实现的主机名验证功能。最后，de Ruiter和Poll [41]使用自动机学习算法来推断TLS协议的模型，并手动检查机器以发现错误。与我们的方法相反，我们专注于分析主机名验证实现，他们的工作集中在由TLS握手期间交换的不同消息引起的TLS状态机。 证书验证。 Georgiev等人 [50]研究了SSL / TLS API在非浏览器软件中被滥用的不同方式。他们在关键软件所依赖的不同SSL / TLS实现中手动识别普遍存在的错误证书验证。 Fahl等人。 [45]调查了Android应用中SSL / TLS API的错误使用情况。但是，与HVLearn不同，这些项目都没有考虑API函数的实现。 解析具有嵌入式NULL字符的X.509证书。Kaminsky等人 [53]证明了几个主机名验证实现在X.509证书中错误处理了嵌入的NULL字符，并且可以用来欺骗CA发布具有错误主题名称的有效叶证书。但是，他们手动发现了这个问题，并且没有任何自动分析主机名验证实现的技术。此外，这些问题应该由SSL / TLS实现修复，但我们发现使用不正确的API从证书中提取标识符字符串的几个应用程序仍然存在这些漏洞，如第VI节所述。 加密攻击和实施错误。关于SSL / TLS协议实现的各种加密攻击有大量工作。感兴趣的读者可以参考[40]进行调查。这些攻击包括各种基于协议的攻击[35]，[43]，[44]，[46]以及定时攻击[37]和伪随机数生成器[57]中的缺陷。除了加密攻击之外，实施错误可能会导致严重的安全漏洞，正如最近发现的攻击[26]，[56]所证明的那样。 B.自动推理和应用Angluin [31]发明了L *算法，用于从成员资格和等价查询中学习确定性有限自动机（DFA）。在接下来的几年中，开发了许多变化和优化，包括HVLearn [54]中使用的Kearns-Vazirani算法。感兴趣的读者可以阅读Balcazzar等人的论文 [34]用于流行算法的统一表示。自动机学习算法已被应用于推断各种协议的模型，如EMV银行卡[29]，电子护照[30]，TLS协议[41]和TCP / IP实现[47]，[48]。 Argyros等[33]利用符号有限自动机学习算法创建差异测试框架，并利用它来发现Web应用程序防火墙中的错误。虽然我们的方法本质上是相似的，但我们通过仅使用必要的符号进行分析来解决大字母的问题。此外，我们的方法不是使用差分测试来模拟等价查询，而是使用Wp-method的优化版本，它提供了更强的正确性保证。 八.结论我们设计，实现并广泛评估了HVLearn，一种用于分析不同主机名验证实现的自动化黑盒自动机学习框架。 HVLearn支持从多种不同的实现中自动提取DFA模型，以及对推断的DFA模型进行有效的差分测试。我们对广泛的主机名验证实施进行了广泛的评估，发现8个RFC违规，具有严重的安全隐患。其中一些RFC违规可以实现主动的中间人攻击。我们还发现每对推断的DFA模型之间平均有121个独特的差异。此外，鉴于RFC规范通常对极端情况不明确，我们希望HVLearn推断的模型对于开发人员根据RFC规范检查其主机名验证实现非常有用，因此可以帮助减少未检测到安全漏洞的机会。我们已经将HVLearn开源，以便社区可以继续以此为基础。可以通过https://github.com/HVLearn访问该框架。","content":"<h1 id=\"Abstract\"><a href=\"#Abstract\" class=\"headerlink\" title=\"Abstract\"></a>Abstract</h1><p>SSL / TLS是用于保护网络通信的最常用的协议系列。 SSL / TLS的安全保证严重依赖于在SSL / TLS协议的握手阶段期间提供的X.509服务器证书的正确验证。主机名验证是证书验证过程的关键组件，它通过检查服务器的主机名是否与X.509证书中存在的任何名称相匹配来验证远程服务器的标识。主机名验证是一个非常复杂的过程，因为存在许多功能和角落情况，例如通配符，IP地址，国际域名等。因此，测试主机名验证实现是一项具有挑战性的任务。在本文中，我们介绍了HVLearn，一种用于分析SSL / TLS主机名验证实现的新型黑盒测试框架，它基于自动机学习算法。 HVLearn使用许多证书模板，即具有设置为特定模式的公用名（CN）的证书，以便测试来自相应规范的不同规则。对于每个证书模板，HVLearn使用自动机学习算法来推断确定性有限自动机（DFA），该自适应有限自动机描述与给定证书的CN匹配的所有主机名的集合。一旦为证书模板推断出模型，HVLearn就会通过查找来自其他实现的推断模型的差异或通过检查从规范派生的基于正则表达式的规则来检查模型中的错误。我们的方法背后的关键见解是，给定证书模板的可接受主机名形成了常规语言。因此，我们可以利用自动机学习技术来有效地推断接受相应常规语言的DFA模型。我们使用HVLearn来分析许多流行的SSL / TLS库中的主机名验证实现，以及用C，Python和Java等多种语言编写的应用程序。我们证明HVLearn可以比现有的黑/灰盒模糊技术实现更高的代码覆盖率11.21％。通过比较HVLearn推断的DFA模型，我们在测试的主机名验证实现中发现了8个唯一违反RFC规范的行为。其中一些违规行为至关重要，可能会使受影响的实施容易受到主动的中间人攻击。</p>\n<table>\n<thead>\n<tr>\n<th>relevant information</th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><em>作者</em></td>\n<td>Suphannee Sivakorn, George Argyros, Kexin Pei, Angelos D. Keromytis, and Suman Jana</td>\n</tr>\n<tr>\n<td><em>单位</em></td>\n<td>Department of Computer Science Columbia University, New York, USA</td>\n</tr>\n<tr>\n<td><em>出处</em></td>\n<td>2017 IEEE S&amp;P</td>\n</tr>\n<tr>\n<td><em>原文地址</em></td>\n<td><a href=\"http://www.cs.columbia.edu/~suman/docs/hvlearn.pdf\" target=\"_blank\" rel=\"noopener\">http://www.cs.columbia.edu/~suman/docs/hvlearn.pdf</a></td>\n</tr>\n<tr>\n<td><em>源码地址</em></td>\n<td><a href=\"https://github.com/HVLearn\" target=\"_blank\" rel=\"noopener\">https://github.com/HVLearn</a></td>\n</tr>\n<tr>\n<td><em>发表时间</em></td>\n<td>2017年</td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"1-简介\"><a href=\"#1-简介\" class=\"headerlink\" title=\"1 简介\"></a>1 简介</h1><p>SSL / TLS协议族是最常用的机制，用于保护网络通信的安全性和隐私免受中间人攻击。SSL / TLS协议的安全保证严重依赖于SSL / TLS握手阶段服务器提供的X.509数字证书的正确验证。反过来，证书验证依赖于主机名验证，以验证服务器的主机名（即完全限定的域名，IP地址等）是否与“SubjectAltName”扩展名或“公用名”中的标识符之一匹配“（CN）属性的呈现叶证书。因此，实施主机名验证时的任何错误都可能完全破坏SSL / TLS的安全性和隐私保护。</p>\n<p>由于存在许多特殊情况（例如，通配符，IP地址，国际域名等），主机名验证是一个复杂的过程。例如，通配符（’*’）仅允许在主机名的最左侧部分（由’.’分隔）中。为了了解主机名验证过程中涉及的复杂性，请考虑在五个不同的RFC [18]，[20]，[21]，[24]，[25]中描述其规范的不同部分的事实。鉴于主机名验证过程的复杂性和安全性至关重要性，对实现进行自动分析以发现与规范的任何偏差至关重要。</p>\n<p>然而，尽管主机名验证过程具有关键性质，但以前没有涉及SSL / TLS证书验证的对抗性测试的研究项目[36]，[38]，[45]，[50]，都不支持详细的主机名自动测试验证实施。先前的项目要么完全忽略对主机名验证过程的测试，要么只是检查是否启用了主机名验证过程。因此，他们无法检测到启用主机名验证实现的任何微妙错误，但会略微偏离规范。主机名验证实现的自动对抗性测试背后的关键问题是输入（即主机名和证书标识符，如常用名称）是高度结构化的稀疏字符串，因此使现有的黑/灰盒模糊测试技术难以实现高测试覆盖率或生成触发极端情况的输入。由于SSL / TLS实现的语言/平台多样性，严重的语言/平台相关的白盒测试技术也难以应用于测试主机名验证实现。</p>\n<p>在本文中，我们设计，实现和评估HVLearn，一种基于自动机学习的黑盒差分测试框架，可以自动推断主机名验证实现的确定性有限自动机（DFA）模型。 HVLearn背后的关键见解是主机名验证，即使非常复杂，在概念上与许多方面的正则表达式匹配过程非常相似（例如，通配符）。对证书标识符格式结构的这种了解表明，如规范所建议的，给定证书标识符的可接受主机名形成常规语言。因此，我们可以使用黑盒自动机学习技术来有效地推断接受与给定主机名验证实现相对应的常规语言的确定性有限自动机（DFA）模型。 Angluin等人的先前结果。已经证明，在多个状态的多项式时间内，通过黑盒查询可以有效地学习DFA [31]。 HVLearn推断的DFA模型可用于有效执行现有测试技术无法做得好的两个主要任务：（i）查找和枚举多个不同实现之间的独特差异; （ii）通过计算来自不同实现的推断DFA模型的交集DFA，为主机名验证过程提取正式的，向后兼容的参考规范。</p>\n<p>我们应用HVLearn来分析许多流行的SSL / TLS库，如OpenSSL，GnuTLS，MbedTLS，MatrixSSL，CPython SSL以及使用C，Python和Java等多种语言编写的Java HttpClient和cURL等应用程序。我们发现了8种不同的规范违规，例如国际化域名中的通配符处理不正确，域名与IP地址混淆，NULL字符处理不正确等等。其中一些违规行为允许网络攻击者通过允许攻击者读取/修改通过使用受影响的实现设置的SSL / TLS连接传输的任何数据来完全破坏SSL / TLS协议的安全保障。 HVLearn在任何两对测试应用程序/库之间平均发现了121个独特的差异。</p>\n<p>本文的主要贡献如下。</p>\n<ul>\n<li>据我们所知，HVLearn是第一个可以学习DFA模型以实现主机名验证的测试工具，这是SSL / TLS实施的关键部分。推断的DFA模型可用于有效的差分测试或提取与多个现有实现兼容的正式参考规范。</li>\n<li>我们在HVLearn中设计并实现了几个特定于域的优化，如等价查询设计，字母表选择等，以便从主机名验证实现中有效地学习DFA模型。</li>\n<li>我们在6个流行的库和2个应用程序上评估HVLearn。 HVLearn实现了比现有黑/灰盒模糊技术更高的代码覆盖率（平均11.21％），并发现了8个独特的先前未知的RFC违规，如表II所示，其中一些使得受影响的SSL / TLS实现对于man-in完全不安全 - 中间攻击。</li>\n</ul>\n<p>本文的其余部分组织如下：第II部分介绍了SSL / TLS主机名验证过程。我们将在第III节讨论测试主机名验证和测试方法的挑战。第四节描述了HVLearn的设计和实现细节。我们在第V节中介绍了使用HVLearn测试SSL / TLS实现的评估结果。第六节介绍了HVLearn发现的几个安全关键错误的详细案例研究。第七节讨论了相关工作，第八节总结了论文。有关HVLearn发现的错误的详细开发人员回复，我们将感兴趣的读者引用到附录X-B。</p>\n<h1 id=\"2-主机名校验概述\"><a href=\"#2-主机名校验概述\" class=\"headerlink\" title=\"2 主机名校验概述\"></a>2 主机名校验概述</h1><p>作为主机名验证过程的一部分，SSL / TLS客户端必须检查服务器的主机名是否与证书中的“公共名称”属性或证书中“subjectAltName”扩展名中的一个名称相匹配[21] 。请注意，即使该过程称为主机名验证，它也支持验证IP地址或电子邮件地址。</p>\n<p>在本节中，我们首先简要介绍主机名格式和规范，这些格式和规范描述了X.509证书中的公共名称属性和subjectAltName扩展格式的格式。图1提供了X.509证书相关部分的高级摘要。接下来，我们将详细描述主机名验证过程的不同部分（例如，域名限制，通配符等）。</p>\n<p><img src=\"/2019/04/11/HVLearn-Automated-Black-box-Analysis-of-Hostname-Verification-in-SSL-TLS-Implementations/2.jpg\" alt=\"\"></p>\n<h2 id=\"A-主机名验证输入\"><a href=\"#A-主机名验证输入\" class=\"headerlink\" title=\"A.主机名验证输入\"></a>A.主机名验证输入</h2><p><strong>主机名格式。</strong>主机名通常是完全限定的域名或没有任何 “.” 字符的单个字符串。若干SSL / TLS实现（即，OpenSSL）还支持将IP地址和电子邮件地址作为主机名传递到相应的主机名验证实现。</p>\n<p>域名由多个“标签”组成，每个“标签”用 “.” 字符分隔。域名标签只能包含字母a-z或A-Z（不区分大小写），数字0-9和连字符’ - ‘[16]。每个标签最长可达63个字符。域名的总长度最多为255个字符。早期的规范要求标签必须以字母开头[21]。但是，随后的修订允许以数字[17]开头的标签。</p>\n<p><strong>X.509证书中的通用名称。</strong>公共名称（CN）是X.509证书中“主题可分辨名称”字段的属性。服务器证书中的公用名用于验证服务器的主机名，作为证书验证过程的一部分。通用名称通常包含完全限定的域名，但它也可以包含具有描述服务的任意ASCII和UTF-8字符的字符串（例如，CN =’Sample Service’）。对公共名称字符串的唯一限制是它应遵循X520CommonName标准（例如，不应重复子字符串’CN =’）[21]。请注意，这与非常严格定义的主机名规范不同，并且仅允许如上所述的某些字符和数字。</p>\n<p><strong>X.509证书中的SubjectAltName。</strong>主题备用名称（subjectAltName）是X.509扩展，可用于存储不同类型的身份信息，如完全限定的域名，IP地址，URI字符串，电子邮件地址等。每种类型对允许的格式都有不同的限制。例如，dNSName（DNS）和uniformResourceIdentifier（URI）必须是有效的IA5String字符串，是ASCII字符串的子集[21]。我们将感兴趣的读者引用到RFC 5280的4.1.2.6节以供进一步阅读。</p>\n<h2 id=\"B-主机名验证规则\"><a href=\"#B-主机名验证规则\" class=\"headerlink\" title=\"B.主机名验证规则\"></a>B.主机名验证规则</h2><p><strong>匹配顺序。</strong> RFC 6125建议SSL / TLS实现使用subjectAltName扩展（如果存在于证书中），而不是通用名称，因为公共名称与标识没有很强的联系，并且可以是前面提到的任意字符串[24]。如果subjectAltName中存在多个标识符，则SSL / TLS实现应尝试匹配DNS，SRV，URI或实现支持的任何其他标识符类型，并且不得将主机名与证书的公用名匹配[24]。<br>证书颁发机构（CA）也应该在颁发证书时使用dNSName而不是通用名称来存储身份信息[18]。</p>\n<p><strong>通用名称/ subjectAltName中的通配符。</strong>如果服务器证书包含通配符’*’，则SSL / TLS实现应使用RFC 6125 [24]中描述的规则将主机名与它们匹配。我们提供以下规则的摘要。</p>\n<p>通配符仅允许在最左侧的标签中。如果所呈现的标识符在除最左侧标签之外的任何标签中包含通配符（例如，<a href=\"http://www.x.example.com和www.foo\" target=\"_blank\" rel=\"noopener\">www.x.example.com和www.foo</a> <em> .example.com），则SSL / TLS实现应拒绝该证书。允许通配符出现在最左侧标签的任何位置，即通配符不必是最左侧标签中的唯一字符。例如，bar </em> .example.com，<em> bar.example.com或f </em> bar.example.com等标识符有效。</p>\n<p>在将主机名与证书中存在的标识符进行匹配时，标识符中的通配符应仅应用于一个子域，并且SSL / TLS实现不应与除主机名最左侧标签之外的任何内容进行比较（例如，* .example。 com应匹配foo.example.com但不匹配bar.foo.example.com 或 example.com）。</p>\n<p>RFC 6125中允许涉及通配符的几个特殊情况仅用于向后兼容现有的SSL / TLS实现，因为它们往往与这些情况下的规范不同。 RFC 6125明确指出，这些情况通常会导致过于复杂的主机名验证代码，并可能导致潜在的可利用漏洞。因此，不鼓励新的SSL / TLS实现支持这种情况。我们总结了其中一些：（i）通配符是标识公共后缀的标签的全部或一部分（例如，<em> .com和</em> .info），（ii）标签中存在多个通配符（例如，f <em> b </em> r.example.com），以及（iii）包含通配符作为多个标签的全部或部分（例如，<em> . </em>.example.com）。</p>\n<p><strong>国际域名（IDN）。</strong> IDN可以包含特定语言字母表中的字符，如阿拉伯语或中文。IDN被编码为一串unicode字符。如果域名标签包含至少一个非ASCII字符（例如，UTF-8），则将其分类为U标签。 RFC 6125规定，在执行主机名验证之前，必须将IDN中的任何U标签转换为A标签域[24]。通过添加前缀’xn–’并将应用于相应Ulabel字符串的Punycode变换的输出附加到RFC 3492 [19]中所述，将U标签字符串转换为A标签（ASCII兼容编码）。 U标签和A标签仍然必须满足域名上的标准长度限制（即最多255个字节）。</p>\n<p><strong>subjectAltName中的IDN。</strong>如RFC 5280所示，X.509 subjectAltName扩展中的任何IDN必须定义为IA5String类型，它仅限于ASCII字符的子集[21]。在将IDN中的任何U标签添加到subjectAltName之前，必须将其转换为A标签。涉及IDN的电子邮件地址也必须先转换为A标签。</p>\n<p><strong>通用名称的IDN。</strong>与subjectAltName中的IDN不同，通用名称中的IDN允许包含PrintableString（AZ，az，0-9，特殊字符’=（）+， -  ./：？和空格）以及UTF-8字符[21] ]。</p>\n<p><strong>通配符和IDN。</strong>没有规范定义如何将通配符嵌入IDN的A标签或U标签中[23]。因此，RFC 6125 [24]建议SSL / TLS实现不应与证书中的呈现标识符匹配，其中通配符嵌入在IDN的A标签或U标签内（例如，xn-kcry6tjko <em> .example .COM）。但是，只要通配符占用IDN的最左侧标签（例如</em> .xn  -  kcry6tjko.example.com），SSL / TLS实现应匹配IDN中的通配符。</p>\n<p><strong>IP地址。</strong> IP地址可以是证书中的公共名称属性或subjectAltName扩展名（带有“IP：”前缀）的一部分。 RFC 6125的3.1.3.2节规定在执行证书验证之前必须将IP地址转换为网络字节顺序八位字符串[24]。SSL / TLS实现应将此八位字节字符串与公用名称或subjectAltName标识符进行比较。对于IPv4和IPv6，八位字节串的长度必须分别为4个字节和18个字节。仅当两个八位字节字符串相同时，主机名验证才会成功。因此，IP地址标识符中不允许使用通配符，并且SSL / TLS实现不应尝试匹配通配符。</p>\n<p><strong>电子邮件。</strong>电子邮件可以作为旧版SSL / TLS实现中的emailAddress属性嵌入通用名称中。该属性不区分大小写。但是，新实现必须以rfc822Name格式添加电子邮件地址以使用替代名称扩展名而不是公共名称属性[21]。</p>\n<p><strong>际化电子邮件。</strong>与subjectAltName扩展中的IDN类似，在验证之前必须将国际化电子邮件转换为ASCII表示。 RFC 5321还指定网络管理员不得使用非ASCII字符和ASCII控制字符定义邮箱（local-part @ domain / address-literal）。如果本地部分和主机部分分别使用区分大小写和不区分大小写的ASCII比较，则认为电子邮件地址匹配（例如，MYEMAIL @ example.com与<a href=\"mailto:myemail@example.com\" target=\"_blank\" rel=\"noopener\">myemail@example.com</a>不匹配但匹配MYEMAIL @ EXAMPLE.COM）[21]。请注意，此规范与嵌入在公共名称中的电子邮件地址相矛盾，该电子邮件地址应该完全不区分大小写。</p>\n<p><strong>主机部分中带有IP地址的电子邮件。</strong> RFC 5280和6125未在电子邮件的主机部分中指定对IP地址的任何特殊处理，并且仅允许以rfc822Name格式的电子邮件。 rfc822Name格式支持主机部分中的IPv4和IPv6地址。因此，允许在主机部分中具有IP地址的电子邮件出现在证书[22]中。</p>\n<p><strong>电子邮件中的通配符。</strong>没有规范应该解释通配符并尝试匹配它们是证书中电子邮件地址的一部分。</p>\n<p><strong>subjectAltName中的其他标识符。</strong>还有其他标识符可用于执行身份检查，例如UniformResourceIdentifier（URI），SRVName和otherName。但是，大多数流行的SSL / TLS库不支持检查这些标识符并将其留给应用程序。</p>\n<h1 id=\"3-方法\"><a href=\"#3-方法\" class=\"headerlink\" title=\"3 方法\"></a>3 方法</h1><p>在本节中，我们将介绍主机名验证实现的自动化测试背后的挑战。尽管规模较小，但这些实现的多样性以及主机名验证过程中的细微之处使得这些实现难以测试。然后，我们继续描述使用自动机学习算法测试主机名验证实现的方法的概述。我们还简要介绍了自动机学习算法运行的基本设置。</p>\n<h2 id=\"A-主机名验证分析中的挑战\"><a href=\"#A-主机名验证分析中的挑战\" class=\"headerlink\" title=\"A.主机名验证分析中的挑战\"></a>A.主机名验证分析中的挑战</h2><p>我们认为，任何自动分析主机名验证功能的方法都应解决以下挑战：</p>\n<ul>\n<li><strong>1. 定义不明确的非正式规范。</strong></li>\n</ul>\n<p>如第II部分所述，尽管相关RFC提供了一些定义主机名验证过程的示例/规则，但许多极端情况未指定。因此，任何主机名验证实现分析都必须考虑其他流行实现的行为，以发现可能导致安全性/兼容性缺陷的差异。</p>\n<ul>\n<li><strong>2.名称检查功能的复杂性。</strong></li>\n</ul>\n<p>由于存在大量的角落案例和特殊字符，因此主机名验证比简单的字符串比较要复杂得多。因此，任何自动分析都必须能够探索这些极端情况。我们观察到证书标识符的格式以及匹配规则非常类似于正则表达式匹配问题。<br>实际上，我们发现每个给定证书标识符的已接受主机名集合形成常规语言。</p>\n<ul>\n<li><p><strong>3.实施的多样性。</strong></p>\n<p>SSL / TLS协议的重要性和普及性导致了大量不同的SSL / TLS实现。因此，主机名验证逻辑通常以许多不同的编程语言实现，例如C / C ++，Java，Python等。此外，其中一些实现可能只能远程访问而无需访问其源代码。因此，我们认为黑盒分析算法是测试各种不同主机名验证实现的最合适的技术。</p>\n</li>\n</ul>\n<h2 id=\"B-HVLearn的主机名验证分析方法\"><a href=\"#B-HVLearn的主机名验证分析方法\" class=\"headerlink\" title=\"B. HVLearn的主机名验证分析方法\"></a>B. HVLearn的主机名验证分析方法</h2><p>受上述挑战的影响，我们现在提出了分析SSL / TLS库和应用程序中主机名验证例程的方法。</p>\n<p>我们的HVLearn系统背后的主要思想如下：对于RFC中的不同规则以及RFC中未明确定义的模糊规则，我们生成具有通用名称的“模板证书”，这些名称是专门为检查具体规则。之后，我们使用自动机学习算法来提取DFA，该DFA描述与模板证书中的公用名匹配的所有主机名字符串的集合。例如，来自标识符模板“aaa。* .aaa.com”的实现的推断DFA可用于测试与RFC 6125中的规则的一致性，禁止将通配符出现在除最常见标签之外的任何其他标签中名称。</p>\n<p>一旦学习算法生成DFA模型，我们就会检查模型是否违反任何RFC规则或其他可疑行为。 HVLearn提供了两种检查推断</p>\n<p><strong>DFA模型的方法</strong>：基于正则表达式的规则。第一个选项允许用户提供指定一组无效字符串的正则表达式。 HVLearn可以确保推断的DFA不接受任何这些字符串。例如，RFC 1035规定只应在主机名标识符中使用集[A-Za-z0-9]中的字符以及字符’’和’。’。因此，用户可以构造一个简单的正则表达式，HVLearn可以使用它来检查任何经过测试的实现是否接受具有给定集合之外的字符的主机名。</p>\n<p><strong>差分测试</strong>。 HVLearn提供的第二个选项是在推断的模型和从相同证书模板的其他实现推断的模型之间执行差异测试。给定两个推断的DFA模型，HVLearn使用我们在第IV-E节中讨论的算法在两个模型之间生成一组独特的差异。此选项对于查找在RFC中未明确定义的极端情况中的错误特别有用。</p>\n<p>我们总结了我们方法的优势如下所示：</p>\n<ul>\n<li>采用黑盒学习方法确保我们的分析方法独立于语言，我们可以轻松测试各种不同的实现。我们唯一的要求是能够使用我们选择的证书和主机名查询目标库/应用程序，并查找主机名是否与证书中的给定标识符匹配。</li>\n<li>如上一节所述，主机名验证类似于正则表达式匹配。鉴于正则表达式可以表示为DFA，采用基于自动机的学习算法来表示每个证书模板的推断模型是一种自然而有效的选择。</li>\n<li>最后，拥有DFA模型的另一个好处是我们可以有效地比较两个推断模型并枚举它们之间的所有差异。此属性对于差分测试非常重要，因为它有助于我们分析规范中的模糊规则。</li>\n</ul>\n<p><strong>限制</strong>。选择将我们的系统作为黑盒分析方法实现的自然权衡是我们无法保证模型的完整性或稳健性。但是，HVLearn推断出的每个差异都可以通过查询相应的实现来轻松验证。此外，由于我们的系统会发现实现之间的所有差异，因此除非明确指定规则，否则它不会报告所有实现中常见的错误，如上所述。最后，我们指出，并非所有系统之间的差异都必然是安全漏洞;对于模糊的RFC部分，它们可能代表同样可接受的设计选择。</p>\n<h2 id=\"C-自动机学习算法\"><a href=\"#C-自动机学习算法\" class=\"headerlink\" title=\"C.自动机学习算法\"></a>C.自动机学习算法</h2><p>我们现在将描述自动机学习算法，它们允许我们实现基于自动机的分析框架。</p>\n<p><strong>学习模式</strong>。我们利用工作在主动学习模型中的学习算法，这种模型称为从查询中精确学习。传统的监督学习算法，例如用于训练深度神经网络的算法，在一组给定的标记示例上工作。相比之下，我们模型中的主动学习算法通过自适应地选择用于查询目标系统并获得正确标签的输入来工作。</p>\n<p><img src=\"/2019/04/11/HVLearn-Automated-Black-box-Analysis-of-Hostname-Verification-in-SSL-TLS-Implementations/1.jpg\" alt=\"\"></p>\n<p>图2展示了我们的学习模型。学习算法试图通过用其选择的输入查询目标系统来学习目标系统的模型。最后，通过多次查询目标系统，学习算法推断出目标系统的模型。然后通过等价oracle检查此模型的正确性，oracle检查推断模型是否正确地总结了目标系统行为。如果模型是正确的，即它与所有输入上的目标系统一致，则学习算法将输出生成的模型并终止。另一方面，如果模型不正确，等价oracle将产生一个反例，即目标系统和模型产生不同输出的输入。然后，学习算法使用反例来细化推断的模型。该过程重复进行，直到学习算法产生正确的模型。</p>\n<p>总而言之，精确学习模型中的学习算法能够使用两种类型的查询与目标系统进行交互：</p>\n<ul>\n<li>成员资格查询：此类查询的输入是字符串s，输出是接受还是拒绝，具体取决于字符串s是否被目标系统接受。</li>\n<li>等价查询：等价查询的输入是模型M，如果模型M等于所有输入上的目标系统，则查询的输出为True，或者模型和目标系统下的反例输入产生不同的产出。</li>\n</ul>\n<p><strong>在实践中的自动化学习</strong>。第一个用于从查询模型中精确学习DFA模型的算法是由Angluin [31]开发的，随后在接下来的几年中进行了大量的优化和变化。在我们的系统中，我们使用Kearns-Vazirani（KV）算法[54]。 KV算法利用称为区分树的数据结构，并且在推断DFA模型所需的查询量方面实际上更有效。</p>\n<p>为了在实践中使用KV算法和其他自动机学习算法，应该解决的最重要的挑战是如何实现高效且准确的等价oracle以模拟由学习算法执行的等价查询。由于我们只对目标系统进行黑盒访问，因此任何实现等价查询的方法都必然是不完整的。</p>\n<p>在HVLearn中，我们使用Wp-method[49]来实现等价查询。 Wp-method仅使用对目标系统的黑盒查询来检查推断的DFA与目标系统之间的等效性。本质上，Wp-method通过使用多个成员资格查询来近似等价oracle。该算法作为输入给出了要检查的DFA和目标系统中状态数量的上限，当建模为DFA时，我们称之为深度的参数。然后，算法创建一组测试输入S，然后将其提交给目标系统。如果目标系统与测试集S中所有输入的DFA模型一致，则在假设目标系统的状态数的上限正确的情况下，DFA和目标系统被证明是等效的。</p>\n<p>从理论上讲，可以将Wp-method的深度参数设置为一个非常大的值，以便设计一个在实践中完整的等价oracle。但是，Wp-method产生的测试输入集的大小是O（n2 |Σ|^( m-n + 1)），其中Σ是DFA的输入字母，m是目标系统的状态数的上限，n是输入DFA中的状态数。因此，使用具有大深度的Wp-method（即，目标系统的状态数量的上限）是不切实际的。注意，Wp-method产生的测试输入数量的界限不是最坏的情况;相反，产生的测试输入数量通常是该顺序。</p>\n<p>因此，我们的系统的效率必须为我们的DFA维护一个小字母表，并在使用Wp-method时设置目标系统状态数的小上限（深度）。我们将在下一节中解决这两个问题。</p>\n<h1 id=\"IV-HVLEARN的体系结构\"><a href=\"#IV-HVLEARN的体系结构\" class=\"headerlink\" title=\"IV . HVLEARN的体系结构\"></a>IV . HVLEARN的体系结构</h1><p>在本节中，我们将基于自动机学习技术描述我们的系统HVLearn的设计和实现。具体来说，我们描述了当我们尝试在实践中使用自动机学习算法时出现的技术挑战。我们还总结了HVLearn为解决这些挑战而实施的优化，并有效地学习了主机名验证实现的DFA模型。</p>\n<h2 id=\"A-系统概述\"><a href=\"#A-系统概述\" class=\"headerlink\" title=\"A.系统概述\"></a>A.系统概述</h2><p>图3概述了如何使用HVLearn分析SSL / TLS库的主机名验证功能。要使用HVLearn，用户提供对主机名验证功能的HVLearn访问权限，该功能将X.509证书和主机名作为输入，并根据提供的主机名是否与证书中的标识符匹配来返回接受/拒绝。我们将在第IV-C节中描述如何实现此接口。我们的系统包括许多证书模板，这些证书模板是用于根据第IV-B节中描述的许多不同规则测试SSL / TLS实现的证书。对于每个此类模板，HVLearn将学习一个DFA模型，该模型描述给定证书模板的给定实现所接受的主机名集。为了生成DFA模型，HVLearn使用LearnLib [59]库，该库包含KV算法和Wp-method的实现。为了避免将Wp-method的最大深度设置为不切实际的高值，我们按照第IV-D节中的描述优化等效oracle。</p>\n<p><img src=\"/2019/04/11/HVLearn-Automated-Black-box-Analysis-of-Hostname-Verification-in-SSL-TLS-Implementations/10.jpg\" alt=\"\"></p>\n<p>生成模型后，我们的系统将继续按照第IV-E节中的描述分析模型。然后保存我们的分析结果，推断模型和模型之间的差异以供重复使用。可选地，HVLearn还可以利用证书模板的推断模型来提取相应证书模板的正式规范，如第V-F部分所述。</p>\n<h2 id=\"B-生成证书模板\"><a href=\"#B-生成证书模板\" class=\"headerlink\" title=\"B.生成证书模板\"></a>B.生成证书模板</h2><p>为了涵盖主机名验证中的所有不同规则和模糊实践，我们创建了一组具有不同标识符模板的23个证书，其中每个证书用于测试规范中的特定规则。选择这些证书是为了涵盖我们在第II节中描述的所有规则。例如，具有通用名称“xn  -  a * .aaa”的证书将测试实现是否允许通配符作为IDN中A标签的一部分，这是RFC 6125明确禁止的。我们的模板证书是自我使用GnuTLS库生成的签名X.509 v3证书。我们选择使用GnuTLS进行证书生成，因为它允许在主题公用名和SAN中使用嵌入的NULL字符的标识符。要测试的模板标识符放在Subject CN和/或SAN中（如dNSName，iPAddress或email）。</p>\n<h2 id=\"C-执行成员资格查询\"><a href=\"#C-执行成员资格查询\" class=\"headerlink\" title=\"C.执行成员资格查询\"></a>C.执行成员资格查询</h2><p>为了利用LearnLib中的学习算法（包括Wp-method），我们实现了一个成员资格查询功能，可以对目标系统执行所有查询。此函数接受像字符串的输入并返回二进制值。在我们的系统中，我们使用目标SSL / TLS实现中的主机名验证功能。我们在此注意到，由于LearnLib是用Java编写的，而我们测试的许多SSL / TLS实现都是用C / C ++ / Python编写的，在这种情况下m我们利用Java Native Interface（JNI）[10]有效地对目标进行成员资格查询。</p>\n<h2 id=\"D-自动学习参数和优化\"><a href=\"#D-自动学习参数和优化\" class=\"headerlink\" title=\"D.自动学习参数和优化\"></a>D.自动学习参数和优化</h2><p>在本节中，我们将描述我们实现的体系结构决策和优化，以有效地扩展KV算法，以测试复杂的实际SSL / TLS主机名验证实现。</p>\n<p><strong>字母大小</strong>。我们要利用KV算法做出的第一个重要决定是选择算法将使用的字母表。字母表是指学习算法将测试的符号集。</p>\n<p>一种简单的方法是使用一组非常通用的字符，例如ASCII字符集。然而，这会对我们系统的性能造成不必要的开销，因为KV算法和Wp-method的性能在很大程度上依赖于底层字母大小。我们的主要观点是，我们可以将字母表缩减为一小组代表性字符，这些字符将彻底测试主机名验证的所有不同方面。特别地，我们在实验中选择集合Σ= {a，1，dot，\\ s，@，A，=，*，x，n，\\ u4F60，NULL}作为输入字母表。在所呈现的字母表中，’dot’表示 ‘.’ 字符，\\ s表示空格字符（ASCII值32），NULL表示零字节字符，\\ u4F60表示具有十六进制值4F60的unicode字符。<br>请注意，这组符号足以分析主机名验证实现，因为它包含来自所有不同类别的字符，如小写，大写，数字，unicode等，以及特殊字符，如NULL字符。为了编码IDN主机名，必须使用小写字符’x’，’n’和’ - ‘字符。最后，包含一些非字母数字字符（如“=”字符）允许我们检测实现接受无效主机名的违规行为。</p>\n<p>请注意，即使使用此字母集生成的主机名在处理为DNS名称时通常也无法解析为真实IP地址，但它不会以任何方式影响我们的分析的准确性。这是一个副作用，即主机名验证例程不负责将提供的DNS名称解析为IP地址。它只是检查给定的主机名是否与提供的证书中的标识符匹配。</p>\n<p><strong>缓存成员资格查询</strong>。为避免使用相同输入重复查询SSL / TLS实现的通信成本，我们利用LearnLib的DFALearningCache类来缓存成员资格查询的结果。在每个新查询上检查缓存，并在找到时使用缓存结果。此优化对于减少Wp-method在多个等价查询中生成的重复查询的开销特别有用。</p>\n<p><strong>优化等价查询。</strong>实际上，学习算法生成的第一个模型通常只是单个状态DFA，它拒绝所有主机名。原因是学习算法不能生成任何接受主机名，因此无法区分目标系统中的初始状态和任何其他状态。有时，为了强制KV算法使用Wp-method生成接受主机名，需要非常大的深度。这可能会导致系统中的效率问题。但是，如果我们为模型提供接受主机名，那么无需在Wp方法中使用过多的深度参数即可快速改进平凡模型。</p>\n<p>回想一下，Wp-method中的指数项取决于模型中状态数与提供的深度之间的差异。因此，一旦我们在目标系统中发现接受状态，具有小得多的深度的Wp-methods仍将能够探索主机名验证实现的许多不同方面。</p>\n<p>为了生成接受主机名，我们在等价查询期间和调用Wp方法之前执行以下测试。首先，我们在提供的通用名称中搜索任何通配符（*），并用字母表中的随机字符替换它们以获得具体的主机名。接下来，我们检查生成的模型和目标主机名验证实现是否同意使用此方法生成的一组主机名。如果没有，我们将返回它们不同的主机名作为反例。这种启发式的主要优点是它允许我们快速生成接受主机名，这些主机名在目标系统中发现新状态，而无需调用具有非常大深度值的Wp-method。一旦发现这些状态，并且推断模型的质量提高，则利用具有小深度参数的Wp-method来发现目标系统中的其他状态。</p>\n<h2 id=\"E-推断的DFA模型的分析和比较\"><a href=\"#E-推断的DFA模型的分析和比较\" class=\"headerlink\" title=\"E.推断的DFA模型的分析和比较\"></a>E.推断的DFA模型的分析和比较</h2><p>在HVLearn输出模型之后，我们系统的下一个任务是分析生成的RFC违规模型或RFC中的混淆/模糊规则，比较不同的推断模型并分析发现的任何差异不同的实现之间。</p>\n<p><strong>分析单个DFA模型。</strong>对于单个模型，我们希望确定模型是否接受RFC规范禁止的无效主机名。如果规范不清楚，除了下面描述的差异分析之外，我们的分析仍然可以用于手动检查特定证书模板上的实现行为。</p>\n<p>我们的系统提供两种选择来执行单个模型的分析。首先，我们的系统生成输入，这些输入将在推断的模型中运用导致接受状态的所有简单路径（即，没有循环的路径）。直观地说，这些输入是一小组输入，描述了给定证书模板可接受的所有不同主机名。通过检查这些证书，我们可以确定实现是否接受无效的主机名。其次，HVLearn允许用户指定要针对推断模型检查的正则表达式规则。在这种情况下，用户指定正则表达式，HVLearn验证正则表达式和推断模型不共享任何公共字符串。此选项允许使用简单的正则表达式规则轻松检查某些RFC违规。例如，请考虑规则，指定不应将非字母数字字符作为匹配主机名的一部分。通过指定正则表达式规则“（.）<em> =（.）</em>”，我们可以检查在推断模型中是否存在包含“=”字符的任何匹配主机名。</p>\n<p><strong>比较DFA模型之间的独特差异</strong>。为了分析RFC中未指定的某些极端情况，测试单个模型可能还不够。相反，我们比较不同SSL / TLS实现的推断模型，并找到实现行为不同的输入。为了执行此分析，我们使用[33]中的差异枚举算法。简而言之，该算法计算两个或更多给定模型之间的乘积DFA，然后找到所有简单路径到达DFA产生不同输出的状态。</p>\n<h2 id=\"F-规范提取\"><a href=\"#F-规范提取\" class=\"headerlink\" title=\"F.规范提取\"></a>F.规范提取</h2><p>正如我们已经讨论的那样，RFC规范通过在所有情况下都没有指定正确的行为，将主机名验证的某些方面留给了实现。在这些情况下，在实现中强加特定限制是具有挑战性的，因为我们必须小心避免破坏与现有实现和有效证书的兼容性。在本节中，我们将描述对于RFC规范含糊不清的情况，如何使用不同证书模板的推断DFA模型来推断与现有实现兼容的正式规范。<br>我们的主要见解如下：对于每个证书模板，我们可以使用DFA接受所有SSL / TLS实现接受的主机名集作为相应规则模板的正式规范。这种选择背后的直觉是，该规范避免了每个库的小特性，因此非常紧凑。另一方面，如果此规范中存在漏洞，则此漏洞也必须存在于所有经过测试的实现中。由于每个实现都是独立审计的，因此我们的选择使我们相信我们的规范可以抵御简单的漏洞，同时保持与测试实现的向后兼容性。</p>\n<p><strong>计算规范。</strong>为了计算每个证书模板的相应规范，我们按如下方式进行：首先，我们使用HVLearn获取所有正在测试的主机名验证实现的DFA模型。接下来，我们计算所有推断模型产生的DFA。产生 的DFA接受每个DFA的常规语言的交集。我们使用标准自动机算法计算产生的DFA [60]。我们的实现集的推断形式规范由每个DFA模型的产品DFA表示。然后可以将此产品DFA转换回正则表达式以提高可读性。</p>\n<p>最后，我们想指出，计算k个DFA的交集具有最差的O（nk）时间复杂度，其中n是每个DFA中的状态数[55]。但是，在我们的例子中，推断的DFA大多数是相似的，因此产品结构非常有效，因为相交两个DFA并不会在最终产品DFA中添加大量状态。我们在第五节提供了更多证据支持这一假设。</p>\n<h1 id=\"V-评估\"><a href=\"#V-评估\" class=\"headerlink\" title=\"V.评估\"></a>V.评估</h1><p>我们评估HVLearn的主要目标是回答以下问题：（i）HVLearn在实际主机名验证实施中发现RFC违规的效果如何？ （ii）我们的优化对提高HVLearn的性能有多大帮助？ （iii）HVLearn相比现有的黑盒或覆盖范围的灰盒技术如何（iv）进行比较，HVLearn可以从推断的实际主机名验证实现的DFA推断出后向兼容的规范。</p>\n<h2 id=\"A-主机名验证测试主题\"><a href=\"#A-主机名验证测试主题\" class=\"headerlink\" title=\"A.主机名验证测试主题\"></a>A.主机名验证测试主题</h2><p>我们使用HVLearn测试六种流行的开源SSL / TLS实现中的主机名验证实现，即OpenSSL，GnuTLS，MbedTLS（PolarSSL），MatrixSSL，JSSE和CPython SSL，以及两种流行的SSL / TLS应用程序：cURL和HttpClient。请注意，像1.0.1之前的OpenSSL版本这样的几个库不提供对主机名验证的支持，而是由应用程序开发人员实现它。因此，支持不同库的cURL / HttpClient等应用程序通常被迫编写自己的主机名验证实现。</p>\n<p>在支持主机名验证的库中，有些像OpenSSL提供了单独的API函数，用于匹配每种类型的标识符（即域名，IP地址，电子邮件等），并根据设置将其留给应用程序选择合适的一个。 相比之下，像MatrixSSL这样的其他人将所有支持的标识符类型组合在一个函数中，并通过检查输入字符串找出合适的标识符。表I显示了我们测试的所有实现的主机名验证函数/类名称以及它们各自支持的标识符类型。最后一列显示了SLOCCount [14]工具报告的每个主机匹配函数/类的物理源代码行（SLOC）。请注意，显示的SLOC仅计算执行主机名匹配的代码部分。</p>\n<p><img src=\"/2019/04/11/HVLearn-Automated-Black-box-Analysis-of-Hostname-Verification-in-SSL-TLS-Implementations/3.jpg\" alt=\"\"></p>\n<h2 id=\"B-使用HVLearn查找RFC违规\"><a href=\"#B-使用HVLearn查找RFC违规\" class=\"headerlink\" title=\"B.使用HVLearn查找RFC违规\"></a>B.使用HVLearn查找RFC违规</h2><p>我们使用HVLearn为每个不同的证书模板生成DFA模型，这些模板对应于来自RFC的不同模式。之后，我们通过执行输出DFA的差异测试以及检查单个DFA是否违反基于规则表达式的规则来检测潜在的错误行为，这些规则是我们手动创建的，如第IV-E节所述。</p>\n<p>表II列出了我们的实验结果。我们评估了来自四个不同RFC的各种规则[16]，[17]，[21]，[24]。我们发现，我们测试的每个规则都被至少一个实现违反，而平均每个实现都违反了三个RFC规则。其中一些违规行为具有严重的安全隐患（例如，错误处理国际域名中的通配符，将IP地址混淆为域名等）。我们将在第VI节中详细描述这些案例及其安全隐患。</p>\n<p>请注意，违规次数最多的库是JSSE（四次违规），而HttpClient是违规次数最多的应用程序（五次违规）。 OpenSSL，MbedTLS和CPython SSL每个只有两个违规，共同违反匹配的无效主机名。感兴趣的读者可以在附录中找到我们结果的扩展描述（表VIII）。</p>\n<p><img src=\"/2019/04/11/HVLearn-Automated-Black-box-Analysis-of-Hostname-Verification-in-SSL-TLS-Implementations/4.jpg\" alt=\"table 2\"></p>\n<h2 id=\"C-比较DFA模型之间的唯一差异\"><a href=\"#C-比较DFA模型之间的唯一差异\" class=\"headerlink\" title=\"C.比较DFA模型之间的唯一差异\"></a>C.比较DFA模型之间的唯一差异</h2><p>为了评估所有不同主机名验证实现之间的差异，我们计算了测试集中每对主机名验证实现的差异数。回想一下，对于两个给定的DFA模型，我们将差异的数量定义为产品DFA中的简单路径的数量，这导致两个模型产生不同的输出[33]。</p>\n<p>表III列出了我们实验的结果。例如，OpenSSL和GnuTLS总共有95个差异。这是通过总结表VIII中每个通用名称的推断的DFA之间不同的唯一路径的数量而获得的。请注意，所有实现对都包含大量唯一的情况，在这些情况下它们会产生不同的输出。如表III所示，每对测试的实现在它们之间平均有127个独特的差异。我们注意到一些差异仅仅意味着不明确的RFC规则，而一些差异则揭示了潜在的无效主机名或RFC违规错误。感兴趣的读者可以在附录中的表VIII中找到每个实现所接受的唯一字符串的更详细列表。在任何情况下，我们发现SSL / TLS协议的这种安全关键组件的所有实现都存在如此大量的差异，这是一个令人担忧的问题，因为它表示规范实施不当或规范模糊不清本身。我们的分析表明这两种情况都存在于实践中。</p>\n<h2 id=\"D-比较HVLearn和黑-灰盒模糊的代码覆盖率\"><a href=\"#D-比较HVLearn和黑-灰盒模糊的代码覆盖率\" class=\"headerlink\" title=\"D.比较HVLearn和黑/灰盒模糊的代码覆盖率\"></a>D.比较HVLearn和黑/灰盒模糊的代码覆盖率</h2><p>为了比较HVLearn在查找错误和黑/灰盒模糊测试中的有效性，我们研究了以下研究问题：</p>\n<p><strong>RQ.1：HVLearn的代码覆盖率与黑/灰盒模糊技术的不同？</strong></p>\n<p>我们比较了HVLearn和其他两种技术（黑盒模糊测试和覆盖引导灰盒模糊测试）所测试的主机名验证实现的代码覆盖率。我们在下面简要描述我们的测试设置</p>\n<p><strong>HVLearn</strong>：HVLearn利用自动机学习，通过预定义的证书模板和字母集调用主机名验证匹配例程。 HVLearn通过使用新的主机名字符串查询实现，自适应地优化与测试主机名验证实现相对应的DFA。我们测量在学习过程中实现的代码覆盖率，直到完成为止。我们还监视NQ的查询总数，它来自成员资格和等价查询。</p>\n<p><strong>黑盒模糊测试</strong>：使用HVLearn使用的相同字母和证书模板，我们随机生成NQ字符串并使用相同的证书模板查询目标SSL / TLS主机名验证功能。请注意，黑盒模糊器生成独立的随机字符串，没有任何指导。</p>\n<p><strong>覆盖引导的灰盒模糊测试</strong>：与黑盒模糊测试不同，覆盖引导的灰盒模糊测试通过使用进化技术在输入生成过程中尝试生成更有趣的输入。在每一代中，通过突变/交叉从上一代生成新的一批输入，并且仅保留增加代码覆盖的输入以进行进一步的改变。覆盖引导的灰盒模糊测试是一种在大型真实世界程序中查找错误的流行技术[6]，[11]。</p>\n<p>为了与HVLearn进行公平的比较，我们实现了我们自己的覆盖引导灰盒模糊器，因为像AFL这样的现有工具不能提供限制给定字母表中的突变输出的简单方法。使用相同的字母集，我们用一组不同长度的字符串初始化模糊器，因为种子在队列Q中保存。然后，模糊器使用种子来查询目标主机名验证实现。完成查询后，使用种子，模糊器获得字符串S =dequeue（Q）。它随机改变S中的一个字符并获得 S’。然后它使用变异的 S‘ 查询目标。如果变异的字符串 S’ 增加代码覆盖率，我们将其存储在队列中以进一步突变，即enqueue（S‘，Q）。否则，我们扔掉它。因此引导模糊器总是在具有更好代码覆盖的字符串上变异。模糊器迭代地执行NQ轮次的这种入队/出队操作，并且我们获得每个功能SSL / TLS实现的最终代码覆盖COV_randmu。请注意，我们在整个测试期间保持测试证书模板的固定。</p>\n<p>我们使用由Gcov [51]提取的行的百分比作为代码覆盖率的指标。考虑到主机名验证只是SSL / TLS实现的一小部分，我们不计算相对于总行数的行百分比。相反，我们计算仅考虑与主机名验证相关的函数中行覆盖率的百分比。</p>\n<p><img src=\"/2019/04/11/HVLearn-Automated-Black-box-Analysis-of-Hostname-Verification-in-SSL-TLS-Implementations/5.jpg\" alt=\"\"></p>\n<p><strong>结果1：与黑/灰盒模糊测试技术相比，HVLearn平均增加了11.21％的代码覆盖率。</strong></p>\n<p>因此，令LE（f）为SI中函数f执行的行数，L（f）为f的总行数，代码覆盖率可在以下公式中定义：<br>$$<br>coverage = \\frac {\\sum_{i = 1}^m LE（f_i）}{\\sum_{i=1}^m L（f_i）}<br>$$<br>其中f1，f2，…，fm是与主机名验证相关的函数。图4显示了代码覆盖率比较，它表明与黑/灰盒模糊测试技术相比，HVLearn实现了明显更好的代码覆盖率。</p>\n<h2 id=\"E-自动学习性能\"><a href=\"#E-自动学习性能\" class=\"headerlink\" title=\"E.自动学习性能\"></a>E.自动学习性能</h2><p>HVLearn主要基于KV算法和Wp-method来执行其分析。因此，彻底评估这些算法的不同参数及其对HVLearn性能的影响至关重要。我们现在将评估学习算法的每个不同参数对HVLearn整体性能的影响。</p>\n<ul>\n<li><strong>RQ.2：字母大小如何影响HVLearn在实践中的表现？</strong></li>\n</ul>\n<p>如第III-C部分所述，字母表大小会影响我们系统的性能。理论上，KV算法和Wp-method的性能取决于输入字母表的大小。我们进行了两个实验，用于评估字母大小在实践中影响学习算法组件性能的程度。在第一个实验中，我们评估了在真实世界的DNS名称中增加字母表大小的效果。对于本实验，我们在默认配置中使用了我们的系统，并启用了所有优化（例如，查询缓存和EQ优化），并将Wp-method深度设置为1.我们使用CPython的SSL实现作为这些实验的主机名验证功能。</p>\n<p> 图5显示了我们实验的结果。请注意，从字母大小9开始，我们在字母表中包含的每个附加字符将使学习算法执行至少10％以上的查询，以便为两个DNS名称生成模型，而此百分比仅增加当更大的字母大小。</p>\n<p>我们还测量了增加字母大小对我们系统整体运行时间的影响。为了执行此实验，我们使用与之前实验相同的设置，并使用包含通用名称“* .aaa.aaa”的证书评估HVLearn的性能。表IV显示了该实验的结果。我们注意到，成员资格查询的增加直接转化为增加的运行时间。具体来说，通过在字母表中添加5个附加字符（从2到5），我们注意到运行时间增加了7倍。当我们在字母表集中添加更多字符时，可以观察到类似的结果。</p>\n<p><img src=\"/2019/04/11/HVLearn-Automated-Black-box-Analysis-of-Hostname-Verification-in-SSL-TLS-Implementations/6.jpg\" alt=\"\"></p>\n<p><strong>结果2：在字母表集中仅添加一个符号会导致查询数量增加至少10％。因此，HVLearn使用的简洁字母集对系统的性能至关重要。</strong></p>\n<ul>\n<li><strong>RQ.3：会员缓存会提高HVLearn的性能吗？</strong></li>\n</ul>\n<p>表IV列出了使用和不使用不同字母大小的成员资格查询缓存来推断具有公共名称“* .aaa.aaa”的证书模板的模型所需的查询数。我们注意到缓存始终有助于减少推断模型所需的成员资格查询数量。总的来说，缓存将查询数量减少了42％，从而显着提高了系统的效率。因此，对于本节中的其余实验，我们利用启用了成员资格查询缓存的系统。</p>\n<p><strong>结果3：成员缓存平均提供学习算法所产生的成员资格查询数量减少42％。</strong></p>\n<ul>\n<li><strong>RQ.4：Wp-method的深度参数如何影响HVLearn的性能和准确度？**</strong></li>\n</ul>\n<p>如第IV-D节中所讨论的，Wp-method执行的查询数量是可自定义深度参数的指数。我们评估了这个指数项在实践中如何影响查询的数量，此外，深度参数的不同值对HVLearn推断的模型的正确性有何影响。</p>\n<p>对于我们的第一个实验，我们探索了成员查询总数与相应深度参数之间的相关性。该实验的结果显示在图6和表V中。为了确保实验在合理的时间内完成，我们进一步将字母大小减小到仅两个符号。结果清楚地表明，深度参数与学习算法执行的查询总数之间的依赖关系是明确的指数，实际上与O（|Σ| ^d）界限完全匹配，其中d是深度参数，如章节中所讨论的IV-d。请注意，当Wp-method的深度参数设置为小于8的值时，HVLearn无法推断目标实现的任何方面，并输出拒绝所有主机名的单个状态DFA模型，如表V所示</p>\n<p><img src=\"/2019/04/11/HVLearn-Automated-Black-box-Analysis-of-Hostname-Verification-in-SSL-TLS-Implementations/7.jpg\" alt=\"\"></p>\n<p><strong>结果4：Wp-method深度参数的较大值导致不切实际的运行时间，而较小的值导致不完整的模型。</strong></p>\n<ul>\n<li><strong>RQ.5：HVLearn中的等价查询优化提供了多少改进？</strong></li>\n</ul>\n<p>之前的实验清楚地表明单独使用Wp-method不足以使用HVLearn准确分析各种不同的模板。使用我们的完整字母表，推断出通用名称“* .aaa.aaa”的完整模型需要深度参数≥8，如表V所示。使用13个符号的完整字母表，这将需要大约230个基于查询算法的复杂性。我们发现即使运行深度为6的算法，仍然无法推断出完整的模型，也会导致超过6800万个查询。<br>因此，我们的等价查询优化是HVLearn的一个重要组成部分，它允许它生成准确的DFA模型，可用于评估实现的安全性和正确性。从表V可以看出，使用我们的等价查询优化和深度参数仅为1，我们的系统能够为给定的证书模板生成完整的模型。运行相同的实验，字母大小为15，我们发现HVLearn仅使用14,812个查询推断出正确的模型，如表IV所示</p>\n<p><strong>结果5：在某些情况下，EQ优化提供了推断完整DFA模型所需的查询数量超过一个数量级的改进。</strong></p>\n<h2 id=\"F-规范提取-1\"><a href=\"#F-规范提取-1\" class=\"headerlink\" title=\"F.规范提取\"></a>F.规范提取</h2><p>现在让我们来研究如何利用HVLearn的规范提取功能来推断对应于通用名称“* .a.a”的规则的实际规范。此规则对应于基本通配符证书情况，其中在标识符的最左侧标签中找到通配符。尽管如此，图7表明即使对于这个简单的规则，不同实现的相应DFA模型也存在明显的差异。例如，DFA模型（a）接受主机名“.a”，模型（b）接受主机名“.a.a”，而模型（d）接受主机名“a.a.a.”。只有模型（c）通过仅接受与正则表达式“a + .a.a”匹配的主机名来执行最直观的匹配（这里’+’表示字符’a’的一个或多个重复）。</p>\n<p>通过计算所有DFA模型之间的交集，我们获得了交叉点DFA模型（e）。我们的第一个观察是交叉点DFA只有6个状态，因此它非常紧凑，如第V-F节所述。此外，我们注意到交叉点DFA与DFA（c）相同，它对应于相应规则的最自然的实现。更重要的是，即使我们计算交叉点而不包括模型（c），我们仍然会推断出相同的规范。因此，我们得出结论，计算DFA模型的交集，即使是以不同方式失败的实现，通常也可以生成紧凑和自然的规范。</p>\n<p><strong>推断模型的大小。</strong>通常，推断模型的实际大小在很大程度上取决于测试系统的实现细节。但是，我们希望系统推断的DFA模型将具有大约l + 2个状态，其中l是证书模板中公共名称的长度。实际上，如果我们考虑图7中推断的DFA，我们可以注意到，对于长度为l = 5的通用名称“* .a.a”，平均状态数为6.9，这非常接近预期的7个状态。直观地说，这个大小背后的推理是，用于匹配长度为l的字符串的DFA通常具有l + 2个状态，其中l个状态将DFA向前移向接受状态，而另外2个状态包括初始状态和当找不到匹配时DFA进入的接收器状态</p>\n<h1 id=\"VI-bugs案例研究\"><a href=\"#VI-bugs案例研究\" class=\"headerlink\" title=\"VI.  bugs案例研究\"></a>VI.  bugs案例研究</h1><p> 我们的研究目标旨在通过证书验证中不正确或不明确的主机名检查来了解潜在利用的严重性。我们也有兴趣发现SSL / TLS实现的主机名检查与RFC指定的不一致。在本节中，我们将介绍我们从实验结果或我们发现的拐角案例中获得的一些有趣案例。</p>\n<h2 id=\"A-IDN标识符中的A-labels内的通配符\"><a href=\"#A-IDN标识符中的A-labels内的通配符\" class=\"headerlink\" title=\"A. IDN标识符中的A-labels内的通配符\"></a>A. IDN标识符中的A-labels内的通配符</h2><p>RFC 6125严格禁止将证书与包含嵌入在IDN的A-labels内的通配符的标识符进行匹配。对于具有“xn-aa *”形式的标识符的证书，由于转换过程的复杂性，很难预测将它们转换为punycode格式后将匹配的unicode字符串集合。无法轻松预测与A标签匹配的主机名集与嵌入式通配符通常会为中间人攻击提供途径。</p>\n<p>最近在Ruby OpenSSL扩展[28]和Mozilla Firefox [27]使用的NSS库中发现了将标识符与嵌入在A-labels中的通配符匹配的主机名验证实现。这些问题被相应产品的开发人员识别为安全漏洞。</p>\n<p>使用HVLearn，我们发现JSSE和HttpClient（在构造函数中不使用PublicSuffixMatcher）也容易受到此问题的影响。我们的工具还报告其他测试的库/应用程序没有受到影响。</p>\n<h2 id=\"B-混淆CN和SAN标识符之间的检查顺序\"><a href=\"#B-混淆CN和SAN标识符之间的检查顺序\" class=\"headerlink\" title=\"B.混淆CN和SAN标识符之间的检查顺序\"></a>B.混淆CN和SAN标识符之间的检查顺序</h2><p>RFC 6125明确指定当存在任何subjectAltName标识符时，应用程序不应尝试将主机名与主题CN匹配，而不管subjectAltName中是否存在匹配，如第II部分所示。我们使用HVLearn发现了一些违反该规则的行为，如表II所述。我们还发现MatrixSSL在这种情况下表现出一种有趣的行为。</p>\n<p>更具体地说，MatrixSSL在尝试匹配SAN中的任何标识符之前匹配CN标识符，即使它们存在于证书中。请注意，CN对其内容没有任何强烈限制，甚至可能包含非FQDN字符（例如，UTF-8）。因此，某些证书颁发机构可能会遵循RFC 6125中的说明，在存在SAN标识符的情况下不会检查CN，并且只要用户被成功识别为CN，就会发出证书而不管CN中的值。 SAN标识符中域的所有者。虽然很自然，但这种选择会使使用MatrixSSL的应用程序容易受到简单的中间人攻击。</p>\n<p>具体而言，攻击者可以为攻击者拥有的域生成带有SAN标识符的签名证书，例如“<a href=\"http://www.attacker.com”，并将CN字段设置为受害域，例如“www.bank.com”。\" target=\"_blank\" rel=\"noopener\">www.attacker.com”，并将CN字段设置为受害域，例如“www.bank.com”。</a> MatrixSSL将首先检查CN并省略检查SAN标识符。因此，MatrixSSL将允许攻击者劫持CN字段中存在的任何域（例如，<a href=\"http://www.bank.com）。\" target=\"_blank\" rel=\"noopener\">www.bank.com）。</a></p>\n<h2 id=\"C-劫持基于IP的证书\"><a href=\"#C-劫持基于IP的证书\" class=\"headerlink\" title=\"C.劫持基于IP的证书\"></a>C.劫持基于IP的证书</h2><p>RFC [16]中域名实现和规范的第2.3.1节规定，首选名称（标签）应仅以字母字符开头。但是，RFC [17]更改了此限制，以允许第一个字符为字母或数字。此更改引入了与IP地址相同的有效DNS名称。</p>\n<p>不幸的是，IP地址也是有效的DNS名称这一事实可能为攻击开辟了一条新的途径，如下所述。请注意，要使此攻击变得切实可行，必须存在0-255范围内的数字顶级域（TLD），这是当前不可用的。尽管如此，我们的描述应作为新TLD的预防性说明。</p>\n<p>该攻击基于以下事实：某些实现首先检查给定主机名是否与证书的CN / SAN匹配为域名，然后是IP地址。因此，请考虑攻击者控制IP地址，例如80.50.12.33并持有具有该IP地址的基于IP的证书。然后，假设“33”是有效的TLD，同一实体将自动拥有域名“80.50.12.33”的证书，并可以对该域执行中间人攻击！</p>\n<p>我们评估了此攻击在当前的SSL / TLS实现中是否可行。表VI显示了我们的评估结果。在主题CN或subjectAltName DNS列中标记为accept的所有库/应用程序都容易受到此攻击。尽管此问题目前尚未被利用，但如果将来引入数字TLD，则会给这些库带来安全风险</p>\n<p><img src=\"/2019/04/11/HVLearn-Automated-Black-box-Analysis-of-Hostname-Verification-in-SSL-TLS-Implementations/8.jpg\" alt=\"\"></p>\n<h2 id=\"D-CN-SAN标识符中的嵌入NULL字节\"><a href=\"#D-CN-SAN标识符中的嵌入NULL字节\" class=\"headerlink\" title=\"D. CN / SAN标识符中的嵌入NULL字节\"></a>D. CN / SAN标识符中的嵌入NULL字节</h2><p>2008年，Kaminsky等人 [53]演示了流行的SSL / TLS库的主机名验证实现中的漏洞，其中X.509 CN中的早期NULL字节（\\ 0）终止导致某些库识别不同的CN值。简而言之，客户端在尝试连接到“<a href=\"http://www.bank.com”时接受来自攻击者子域“www.bank.com\" target=\"_blank\" rel=\"noopener\">www.bank.com”时接受来自攻击者子域“www.bank.com</a> \\ 0.attacker.com”的证书，因此允许攻击者劫持连接。</p>\n<p>为了防御这次袭击，接下来是两道防线。第一种选择是拒绝任何包含嵌入在任何CN / SAN标识符中的NULL字节的证书。第二种是简单地修补从函数中检索CN / SAN标识符的API函数，以便即使存在嵌入的NULL字节也可以恢复整个标识符。<br>我们彻底评估了每个SSL / TLS库中实施的防御。表七列出了我们的评估结果。第二列描述SSL / TLS库是否允许嵌入的NULL字节，第三列显示用于检索CN / SAN标识符的相应API函数，第四列描述API调用是否也返回相应的长度CN / SAN标识符。请注意，这是一个非常重要的功能，否则，使用SSL / TLS库的应用程序无法知道标识符字符串的终止位置。我们注意到除了JSSE之外，所有库都实现了这个重要的特性。请注意，即使JSSE没有返回相应标识符的长度，因为JSSE是用Java编写的，所以它不容易受到嵌入式NULL字节攻击，因为Java字符串不是NULL终止的。</p>\n<p><img src=\"/2019/04/11/HVLearn-Automated-Black-box-Analysis-of-Hostname-Verification-in-SSL-TLS-Implementations/9.jpg\" alt=\"\"></p>\n<p>尽管SSL / TLS实现采取预防措施来防止嵌入式NULL字节攻击，但这并不意味着使用这些库的应用程序也是安全的。<br>实际上，实现主机名验证功能的应用程序必须确保它们不使用易受攻击的函数，例如来自libc的标准字符串比较函数（例如，strcmp，strcasecmp，fnmatch），因为它们匹配NULL终止样式的字符串。</p>\n<p>为了评估使用SSL / TLS库抵御嵌入式NULL字节攻击的应用程序的安全性，我们对几个应用程序进行了手动审计。不幸的是，我们发现几个流行的应用程序容易受到使用嵌入NULL字节证书的中间人攻击。一些例子包括FreeRadius服务器[8]，它是部署最广泛的RADIUS（远程认证拨入用户服务）服务器之一，OpenSIPS [12]是一种流行的开源SIP服务器，Proxytunnel [13]是一种隐身隧道代理和Telex Anticensorship系统[15]，它是一个开源的审查制度绕过软件。</p>\n<p>本节的一个重要内容是嵌入NULL字节攻击，即使在SSL / TLS库级别处理，仍然对使用这些库的应用程序提出了非常现实和被忽视的威胁。</p>\n<h1 id=\"VII-相关工作\"><a href=\"#VII-相关工作\" class=\"headerlink\" title=\"VII. 相关工作\"></a>VII. 相关工作</h1><p>A.保护SSL / TLS实现</p>\n<p>已经在大量项目中检查了SSL / TLS实现的不同组件的安全性分析。我们提供以下最相关项目的摘要。这些项目与我们的项目之间的主要区别在于，这些项目都没有专注于自动分析SSL / TLS证书验证实现的主机名验证部分的正确性。先前的工作不包括详细分析主机名验证，主要是准确建模实施的硬度。在本文中，我们通过使用自动机学习技术并证明它们能够以黑盒方式准确有效地推断主机名验证实现的DFA模型来解决这个问题。</p>\n<p><strong>自动分析SSL / TLS实施</strong>。布鲁贝克等人 [36]随后陈等人 [39]使用基于突变的差异测试来查找证书验证问题。但是，在他们的情况下，被禁用的主机名验证功能被禁用，以便发现其他证书验证问题，因此，他们无法发现我们的工作发现的错误。He等人 [52]使用静态分析来检测SSL / TLS库API的错误使用。 Somorovsky [61]创建了TLS-Attacker系统地模糊TLS实现的工具。但是，TLS-Attacker专注于查找协议级别的错误，并且没有分析SSL / TLS实现的主机名验证功能。最后，de Ruiter和Poll [41]使用自动机学习算法来推断TLS协议的模型，并手动检查机器以发现错误。与我们的方法相反，我们专注于分析主机名验证实现，他们的工作集中在由TLS握手期间交换的不同消息引起的TLS状态机。</p>\n<p><strong>证书验证</strong>。 Georgiev等人 [50]研究了SSL / TLS API在非浏览器软件中被滥用的不同方式。他们在关键软件所依赖的不同SSL / TLS实现中手动识别普遍存在的错误证书验证。 Fahl等人。 [45]调查了Android应用中SSL / TLS API的错误使用情况。但是，与HVLearn不同，这些项目都没有考虑API函数的实现。</p>\n<p><strong>解析具有嵌入式NULL字符的X.509证书。</strong>Kaminsky等人 [53]证明了几个主机名验证实现在X.509证书中错误处理了嵌入的NULL字符，并且可以用来欺骗CA发布具有错误主题名称的有效叶证书。但是，他们手动发现了这个问题，并且没有任何自动分析主机名验证实现的技术。此外，这些问题应该由SSL / TLS实现修复，但我们发现使用不正确的API从证书中提取标识符字符串的几个应用程序仍然存在这些漏洞，如第VI节所述。</p>\n<p><strong>加密攻击和实施错误。</strong>关于SSL / TLS协议实现的各种加密攻击有大量工作。感兴趣的读者可以参考[40]进行调查。这些攻击包括各种基于协议的攻击[35]，[43]，[44]，[46]以及定时攻击[37]和伪随机数生成器[57]中的缺陷。除了加密攻击之外，实施错误可能会导致严重的安全漏洞，正如最近发现的攻击[26]，[56]所证明的那样。</p>\n<h2 id=\"B-自动推理和应用\"><a href=\"#B-自动推理和应用\" class=\"headerlink\" title=\"B.自动推理和应用\"></a>B.自动推理和应用</h2><p>Angluin [31]发明了L *算法，用于从成员资格和等价查询中学习确定性有限自动机（DFA）。在接下来的几年中，开发了许多变化和优化，包括HVLearn [54]中使用的Kearns-Vazirani算法。感兴趣的读者可以阅读Balcazzar等人的论文 [34]用于流行算法的统一表示。自动机学习算法已被应用于推断各种协议的模型，如EMV银行卡[29]，电子护照[30]，TLS协议[41]和TCP / IP实现[47]，[48]。</p>\n<p>Argyros等[33]利用符号有限自动机学习算法创建差异测试框架，并利用它来发现Web应用程序防火墙中的错误。虽然我们的方法本质上是相似的，但我们通过仅使用必要的符号进行分析来解决大字母的问题。此外，我们的方法不是使用差分测试来模拟等价查询，而是使用Wp-method的优化版本，它提供了更强的正确性保证。</p>\n<h1 id=\"八-结论\"><a href=\"#八-结论\" class=\"headerlink\" title=\"八.结论\"></a>八.结论</h1><p>我们设计，实现并广泛评估了HVLearn，一种用于分析不同主机名验证实现的自动化黑盒自动机学习框架。 HVLearn支持从多种不同的实现中自动提取DFA模型，以及对推断的DFA模型进行有效的差分测试。我们对广泛的主机名验证实施进行了广泛的评估，发现8个RFC违规，具有严重的安全隐患。其中一些RFC违规可以实现主动的中间人攻击。我们还发现每对推断的DFA模型之间平均有121个独特的差异。此外，鉴于RFC规范通常对极端情况不明确，我们希望HVLearn推断的模型对于开发人员根据RFC规范检查其主机名验证实现非常有用，因此可以帮助减少未检测到安全漏洞的机会。<br>我们已经将HVLearn开源，以便社区可以继续以此为基础。可以通过<a href=\"https://github.com/HVLearn访问该框架。\" target=\"_blank\" rel=\"noopener\">https://github.com/HVLearn访问该框架。</a></p>\n","categories":[{"name":"论文","slug":"论文","permalink":"http://yama0xff.com/categories/论文/"},{"name":"fuzzing","slug":"论文/fuzzing","permalink":"http://yama0xff.com/categories/论文/fuzzing/"},{"name":"协议","slug":"论文/fuzzing/协议","permalink":"http://yama0xff.com/categories/论文/fuzzing/协议/"}],"tags":[{"name":"S&P‘17","slug":"S-P‘17","permalink":"http://yama0xff.com/tags/S-P‘17/"},{"name":"SSL/TLS","slug":"SSL-TLS","permalink":"http://yama0xff.com/tags/SSL-TLS/"},{"name":"主动学习","slug":"主动学习","permalink":"http://yama0xff.com/tags/主动学习/"}]},{"title":"A Reinforcement Learning Based Approach to Automated Testing of Android Applications","date":"2019-04-10T13:31:37.000Z","path":"2019/04/10/A-Reinforcement-Learning-Based-Approach-to-Automated-Testing-of-Android-Applications/","text":"Abstract近年来，研究人员积极提出了自动化Android应用程序测试的工具。然而，他们的技术仍然遇到重大困难。首先是实现高代码覆盖率的困难，因为应用程序通常有大量的业务和转换的可能的组合，这使得在测试大型系统场景时会非常的耗时和无效。其次是实现广泛的应用功能的困难，因为某些功能只能通过特定的事件序列来实现。因此，在随机测试中，它们的测试频率较低。面对这些问题，我们应用称为Q学习的强化学习算法，以利用随机和基于模型的测试。 Q-learning代理与Android应用程序交互，逐步构建行为模型并基于模型生成测试用例。代理以最佳方式探索应用程序，尽可能多地显示应用程序的功能。与随机和基于模型的测试相比，使用Q学习的探索提高了代码覆盖率，并且能够检测被测应用程序中的故障 KEYWORDS：Android, Test Input Generation, Reinforcement Learning, Q-Learning relevant information 作者 Thi Anh Tuyet Vuong，Shingo Takada 单位 Grad. School of Science and Technology, Keio University Yokohama, JapanGrad. School of Science and Technology, Keio University Yokohama, Japan 出处 A-TEST ’18 原文地址 https://dl.acm.org/citation.cfm?id=3278191 源码地址 发表时间 2018年 1. 引言近年来，全球范围内移动软件的经济增长导致了开发人员对有效测试工具的持续需求。作为对这种需求的回应，研究人员提出了一种不同的工具，可以用尽可能少的人力来自动测试移动应用程序。大多数研究人员选择Android平台来开发他们的工具，因为Android手机的市场份额很大，Android测试工具无疑是有用的，并且与许多开发人员相关。此外，Android平台的开源特性使研究人员更容易访问应用程序和底层操作系统[11]。我们针对Android平台并针对Android应用程序开发测试工具的原因相同。 Android应用程序由一个或多个activities`组成，这些activities是负责应用程序用户界面（UI）的组件。每个activities都包含各种UI组件，如按钮，文本，复选框等。Android应用程序是基于事件的，这意味着它的行为基于对用户输入事件（UI事件）的响应，如单击，滚动，文本输入它还对来自手机操作系统的系统事件做出反应，如电话呼叫或短信信号等。由于Android应用程序基于事件的特性，相当多的研究都集中在自动生成输入事件以进行测试。无论采用何种技术，目标都是生成相关输入，以尽可能多地显示应用程序的功能。然而，这个领域的研究人员仍面临两个主要挑战： 移动应用程序通常包含大量组件和可执行的事件。因此，测试组件和事件的所有可能组合是耗时的，并且难以扩展到大型系统。自动测试工具应仅测试与应用程序相关的事件序列，即导致测试应用程序功能的序列。 •应用程序的某些功能只能通过特定的事件序列（难以到达的功能）来实现，这使得自动随机测试难以显示和测试它们。 本文的主要贡献是提出强化学习的应用，特别是Q学习，以自动生成Android应用程序的测试输入。使用强化学习，我们构建了一个测试工具，以试错法的方式交互和探索应用程序的功能。在此探索过程中，该工具动态构建应用程序的行为模型，并生成遵循最有可能揭示应用程序功能的事件序列的测试用例。本文还展示了与最先进的自动化测试工具相比较的工具评估。 本文的结构如下：第2节回顾了Android测试技术的相关工作;第3节介绍Q学习，然后第4节解释了Q-Learning工具的提议方法和实现细节;第5节讨论了对拟议工具的评估，最后第6节总结了论文以及对未来工作的建议。 2 相关工作在本节中，我们将研究Android应用程序的自动测试输入生成中的现有技术。 我们可以基于探索策略对测试输入生成技术进行分类[11]。第一种技术是Random Exploration，其中测试工具生成随机事件并将它们发送到应用程序。虽然这种技术快速而简单，但生成的事件通常是不充分的。这是因为应用程序只能响应每个应用程序状态下的许多不同类型的事件中的一些。此外，所产生的事件通常是多余的，并且很难揭示难以触及的功能。 Android Monkey [2]是一个使用随机测试策略的黑盒测试工具，因其简单性而在开发人员中广泛使用。它在生成事件（仅UI事件）方面特别有效，能够每秒向应用程序发送数千个事件。 Monkey通常在测试工具中获得最高的代码覆盖率。然而，从人类与应用程序交互的角度来看，它发现的崩溃很难再现和不切实际。可能更好的说法使用Monkey测试比功能测试更接近压力测试。 Dynodroid [18]也是一种使用随机探索策略的黑盒测试工具，但与Monkey相比它有一些改进。它不是选择随机事件，而是选择与应用程序当前上下文最相关的事件（BiasedRandom策略）。开发人员提供无法自动生成的输入，例如测试前对工具的身份验证信息。 Dynodroid还通过分析应用程序的侦听器来生成相关的系统事件。属于此类别的另一组工具是模糊测试器：DroidFuzzer [29]，Intent Fuzzer [25]，Null Intent Fuzzer [5]等。它们主要旨在生成无效输入，导致被测应用程序崩溃 第二种技术是基于模型的探索策略，其中测试工具静态或动态地构建测试中的应用程序的GUI模型，然后使用该模型来探索应用程序并生成事件。 A3E [10]提出了一种基于动态模型的动态深度探索，该动态模型将每个活动视为应用的状态。这种状态表示的简化导致测试不完整，因为A3E侧重于测试活动之间的转换，而不是每个活动内部的行为。 PUMA [14]是一个动态分析框架。它包含一个通用UI自动化功能（Monkey），可以公开用户可以定义处理程序的高级事件。这些处理程序指导Monkey的探索，并指定应用程序检测以收集动态状态信息或在应用程序执行期间触发环境中的更改。AndroidRipper [3]（也称为GUIRipper [8]或MobiGUITAR [7]）通过爬行构建应用程序模型。在每个活动中，它会注册当前状态下的所有可用事件。然后使用深度优先搜索策略系统地执行所有这些操作。AndroidRipper仅生成UI事件。 最后一类技术是系统探索战略，它使用符号执行和进化算法等算法来指导探索。这种技术被EvoDroid [19]和Acteve [9]等工具使用。 EvoDroid为Android应用程序的系统测试提出了一种演化方法。进化测试将每个测试用例视为个体。根据某些启发式方法演变由许多个体组成的群体，以最大化代码覆盖并减少测试数量。 EvoDroid静态分析测试中的应用程序以构建其行为模型。这个模型允许进化搜索确定如何跨越个体将遗传构成传递给后代[19]。另一方面，Acteve系统地生成基于concolic测试的测试输入。它通过在事件序列之间提出包含的概念来处理类型测试的路径爆炸问题，以避免冗余事件执行。 虽然与产生相同数量的事件的随机策略相比，基于模型的策略似乎更有效，但它仍然面临着许多挑战。基于黑盒模型的测试通常通过在测试之前静态构建应用程序模型或在测试期间动态地通过记录来自正在运行的应用程序的所有可能事件序列来进行。然后它生成测试用例以覆盖模型中的序列[21] [30]。因此，生成的测试用例的有效性很大程度上取决于记录模型的完整性以及应用程序状态的表示方式。一种广泛使用的技术是随机遍历被测应用程序的GUI以构建模型，但这种技术在处理复杂的GUI时是多余的和有限的。原因是某些状态比其他状态更容易到达，因此它们将在随机策略下更频繁地执行;而一些难以触及的国家可能根本不会被执行。停止条件也很难确定，有多少随机探索足以获得完整的模型？ 面对难以触及的GUI测试问题，Mariani等人[20]提出了一种用于通用Java桌面软件的黑盒GUI测试工具，它能够向前看并执行某些操作，以便进入难以触及的GUI。他们特别使用Q-learning，一种强化学习技术来实现这一目标。他们的工具（称为AutoBlackTest）动态构建行为模型，并在与被测软件交互时逐步生成测试用例。 AutoBlackTest将被测软件的行为模型表示构建为多方向图。节点表示状态（GUI），而边表示可执行操作。连接节点对应于状态之间的转换。在Q学习算法探索应用程序并观察新状态或执行新操作的每个步骤中，它都扩展了行为模型。当该工具提供初始测试套件时，性能得到改善，该测试套件指示如何测试软件的最相关功能。 TESTAR [13]是一种测试工具，它还使用Q-learning来基于GUI信息生成测试序列，而无需访问源代码。来自TESTAR结果的统计分析指出，Q学习行动选择策略仅在适当选择参数时才有效。 TESTAR可以测试一般桌面软件和基于Web的软件。通过AutoBlackTest和TESTAR，强化学习技术已被证明在独立Java应用程序的GUI测试中非常有用。然而，由于Android平台以及Android应用程序本身的特殊性，这样的工具不能直接用于测试Android应用程序。强化学习需要适应Android环境，需要证明它在Android测试中很有用，因此本研究的目的是：在Android应用程序测试中应用强化学习。 以下部分介绍了强化学习和Q-Learning，提供了必要的背景知识，以便理解论文的其余部分。 3 Q-LEARNINGQ-Learning [26]是一种着名的强化学习技术，受行为主义心理学的启发，软件代理试图以反复试验的方式与环境互动。在每次交互时，代理执行一个动作，然后根据环境的当前状态，它根据其立即奖励并最终转移到环境返回的新状态来评估该动作的后果。总体目标是让代理学习如何以最佳方式行动以最大化累积奖励，这是在执行整个动作序列时收集的奖励。强化学习问题的数学公式是马尔可夫决策过程。它由[26]定义： S：可能状态的集合 A：可能的行动的集合 R：给予的奖励的分布（状态，行动）对 P：转移概率，即给定的下一个状态的分布（状态，动作）对 γ：折扣因子图1总结了强化学习机制以及环境与代理之间的相互作用。 Q学习代理在一系列离散时间步骤t = 0,1,2,3 ……中的每一个与环境交互[26]。在时间t = 0，环境从初始状态s0∈S开始。然后在从t = 0到完成的每个时间步骤： 代理选择在∈A（st）处的动作，其中A（st）是一组状态st中可用的动作 环境采样并基于奖励R（.| st，at）的分布返回数值奖励rt 环境采样并基于转移概率P返回下一状态st + 1（.| st，at） 代理接收奖励rt并在新状态st + 1中结束自身。 在每个步骤t，代理观察环境的当前状态st并基于策略π选择动作。此策略表示代理对环境的行为。因为我们希望代理以最佳方式行事以最大化累积奖励，强化学习的目标是使政策π最大化累积折扣奖励$$\\sum_{t&gt;0}γ^tr_t$$给定规则π，在Q学习中，我们定义一个称为Qvalue函数（或Q函数）的函数，它告诉一个（状态，动作）对有多好。对于状态s和动作a的任何组合，该函数返回可以通过执行以在a状态以s开始然后遵循规则π的一系列动作可以实现的预期累积奖励。最佳Q值函数Q 是对于所有可能的规则，从给定（状态，动作）对可实现的最大预期累积奖励。$$Q^π (s_t , a_t ) = max_π \\sum_{t &gt;0}(γ^tr_t |s = s_0, a = a_t,π)$$如果已知下一步Q s_{t + 1}，a_{t + 1}）的最佳状态 - 动作值，则最优策略是采取最大化r +γQ的预期回报的动作（s_{t + 1}，a_{t + 1}）其中r是当前步骤的直接奖励。 Q *满足Bellman方程： $$Q^∗(s_t , a_t ) = R(s_t , a_t ) + γ max_{a_t+1}Q(s_{t+1}, a_{t+1})$$其中γ是介于0和1之间的折扣率参数。它平衡了即时奖励和累积奖励的相关性：γ越接近0值越立即奖励，γ越接近1值越累积奖励。因此，最优策略π对应于采用由Q 指定的具有最高Q值的动作.Q学习算法基于等式（3）以迭代地估计Q函数的值。 Q函数使用默认值初始化。每当代理从状态st执行动作以达到状态st + 1并且接收奖励rt时，Q-function被更新为：$$Q(s_t , a_t ) ← Q(s_t , a_t ) + α(r_t + γ max_aQ(s_{t+1}, a) − Q(s_t , a_t ))$$在该公式中，α是学习率（0≤α≤1）。 α表示新观察对Q函数估计值的影响。 如果应用于马尔可夫环境，Q学习算法保证收敛到真正的Q函数，具有有限的立即奖励和状态 - 动作对不断更新[28]。 4 提议的方法：在Android应用程序测试中进行Q-LEARNING因为Q-Learning算法具有结合达到某种环境状态的最佳方式的能力，所以它可以用于指导探索到达揭示应用程序功能或难以到达状态的状态。在本文中，Q学习代理探索Android应用程序，可以将其建模为GUI状态的集合，并在每次迭代时生成诸如点击，类型，滑动，滚 动等事件。代理逐渐学习如何以揭示应用程序功能的方式遍历应用程序，然后生成涵盖尽可能多的代码的测试用例。 在本文中，Markov模型的设计目的是为Android应用程序生成测试输入，如下所示： S：应用程序状态集。状态由活动名称和相应屏幕上可用的UI事件集确定。通过在每次访问一个状态时添加新状态，在每个Q学习迭代处更新该组访问状态。 A：可能的GUI事件集。事件对应于可以在GUI组件上执行的动作（例如，按钮点击）。它由元组（GUI组件类名，事件类型，GUI组件唯一资源ID，屏幕上GUI组件的位置）定义。 R：在给定转换（状态，事件，新状态）时返回数值的奖励函数 P：在当前状态下执行事件时，转换到新状态由被测应用程序的响应确定 γ：折扣因子 我们的Q学习测试工具由两个主要角色组成：环境和代理。 Environment表示Android设备和正在测试的应用程序。它有三个辅助模块：Observer，Executor和Reward Function。代理了解被测应用程序的最相关行为模型，并根据此模型生成测试用例。行为模型结合了Q学习的结果。它包含状态空间S，可以在每个状态上执行的事件集以及每个（状态，事件）对的估计Q函数。 为了创建测试用例，代理执行一系列固定数量的事件，也称为episode 。在完成一集之后，代理从已经访问过的那些中选择随机状态并从那里开始新的episode 。一集的长度是影响代理的有效性的一个重要参数，因为它可以为每个测试用例确定搜索空间的大小。该参数在很大程度上取决于应用程序的设计，例如活动的复杂性以及不同活动之间的交互频率。每集的迭代过程如下： 从t = 0到episode 结束，重复： 步骤1：环境 - 观察者观察正在测试的应用程序并构建当前的抽象状态。 步骤2：代理确认当前状态，并根据策略及其当前行为模型选择要执行的下一个事件。 步骤3：环境 - 执行程序执行所选事件。 步骤4：环境 - 观察者观察应用程序的新GUI状态 步骤5：环境 - 奖励功能计算后续奖励。 步骤6：代理更新Q功能。 下面给出每个步骤的细节。 4.1观察环境（步骤1和4）Observer是环境的一个模块，其功能是观察环境的当前状态。 Observer的任务是在每次迭代时创建当前GUI树的抽象表示，简称为状态。 GUI树是GUI组件的层次结构，我们可以在运行时使用Android UI Automator从测试中的应用程序中提取。抽象GUI状态由当前活动的名称和当前GUI树中所有UI事件的元组组成。观察者仅在抽象状态中包括属于当前被测试应用程序的GUI元素（通过检查GUI元素属于哪个包）。在本文中，只考虑事件类型的点击，长按，检查（复选框），文本输入和滚动。即使Android平台支持更多的事件类型，我们目前仅支持这5种，因为它们是最广泛使用的，并将其他部分视为未来工作的一部分。除了正在测试的应用程序的UI事件之外，观察者还将菜单按钮单击和设备的后退按钮单击作为可用的UI事件。 4.2选择要在当前状态下执行的事件（步骤2）在每个时间步，代理选择要在当前状态下执行的事件。基于策略π选择该事件。选择良好政策的挑战是平衡exploration and exploitation 之间的贸易往来[26]。为了获得巨大的回报，代理必须更喜欢过去曾经尝试过的事件，并且发现它们在产生奖励方面是有效的。它应该利用它对应用程序的了解并选择具有最高Q值的事件。但是要选择此类事件，代理商还必须探索新事件，以便在将来做出更好的选择。因此，通常考虑概率方法。在这项研究中，我们使用了一种名为ε-greedy的流行政策。代理选择当前状态中可用的随机事件，具有概率ε，或根据当前行为模型选择具有最高Q值的事件，概率为1-ε。 在测试过程开始时，我们希望代理能够探索尽可能多的状态，以便构建最接近应用程序的完整模型，因此，应使用大的ε值。然而，一旦模型构建得很好，我们希望代理遵循Q值函数来快速达到应用程序的功能并测试它们，因此预期ε值较小。在本文中，我们从ε= 1开始以实现最大探索，然后我们在第一次100集期间均匀地减小其值，直到最终的最小值（在评估期间的实证研究之后为0.5）以改变代理的行为exploitation 。 4.3在环境中执行事件（步骤3）Executor模块通过UI Automator [15]和Android Debug Bridge [1]在实际的Android设备或模拟器上执行事件。 Executor可以执行观察者可观察到的所有事件类型：单击，长按，检查，文本输入，滚动。对于文本输入，文本在执行期间随机生成。 4.4计算奖励（步骤5）通过奖励函数R在环境中计算奖励，奖励函数R基本上告诉代理哪个事件是好的以及哪个是坏的。在确定奖励函数时，需要考虑两个方面：GUI更改和执行频率。 为了启发式地识别触发新功能的事件，奖励函数支持导致抽象GUI状态的许多变化并给予他们更高奖励的事件。这种推理类似于AutoBlackTest [20]中使用的推理。给定两个状态s1和s2，奖励函数通过比较和识别s2中但不在s1中的GUI事件的数量来计算从s1到s2的变化程度，描述为| s2 \\ s1 |。然后通过比率| s2 \\ s1 | / | s2 |来确定相对变化其中| s2 |是| s2 |中的GUI事件数。此公式考虑新出现在s2中的组件，但不考虑从s1中消失的组件。这样可以避免为触发应用程序活动之间跳转的事件提供过大的值。它适度地增加了Q值，因此我们可以测试每个活动中活动和功能之间的转换。 添加了另一个因素来帮助代理平衡the exploration and exploitation ：执行频率。我们计算每个事件执行的次数，并随着执行频率的增加而减少奖励。与一定次数的迭代之后的GUI改变奖励相比，该奖励值变得相对较小。但它有助于Q-agent在测试开始时更快地探索新状态，从而提高其状态空间的完整性。总之，奖励函数的定义由以下公式给出：$$r_t = R(s_t ,a_t ,s_{t+1}) = \\frac{|s_{t+1} \\ s_t |}{|s_{t+1}|} \\frac{1}{f(s_t,a_t )}$$其中f（st，at）是处于状态 st 直到时间 t 的事件 at 的执行频率。 4.5 更新Q值函数（步骤6）代理根据当前迭代期间发生的转换构建和更新Q值函数，即行为模型。 代理在每次迭代之后使用等式（4）更新Q值函数，学习率α= 1并且折扣率γ= 0.9。学习率α接近1会对新模型的新观察产生更大的影响。我们选择值α= 1，以便代理快速了解应用程序的行为方式。折扣因子平衡了即时奖励与未来事件的相关性，值0.9最大化了整个episode 期间收集的奖励，而不是最大化直接奖励。因此，等式（4）变为$$Q（s_t，a_t）←r_t + 0.9 max_a Q（s_{t + 1}，a）$$当动作到达未被访问的状态时，公式的第二项是因为我们没有对该状态的Q值进行任何估计。在这种情况下，Q值只是即时奖励。否则，根据目标状态中的事件的奖励值和Q值来计算Q值。 特殊功能用于处理转换导致退出被测应用程序的情况。在这种情况下，测试工具随机执行最多数量的事件，这些事件不属于被测应用程序。这个最大数量是两个事件。每次执行后，我们都会检查该工具是否返回到测试中的应用程序。如果是，我们正常进行测试;如果没有，我们强制该工具返回应用程序的启动器活动。触发退出应用程序的事件被给予0奖励，因为我们避免执行它。这是必要的，因为我们无法在正常的应用程序退出和应用程序崩溃（我们认为存在故障）之间进行区分。 4.6实现该工具是用Python 2.7编写的。该工具的架构和工作流程如图2所示。为了与Android设备和被测应用程序进行交互，我们使用Android UI Automator [15]的python库以及Android Debug Bridge [1] 5评估5.1评估指标衡量工具有效性的指标是代码覆盖率，这是评估测试工具的通用指标。具体而言，我们使用行覆盖来评估Q-Learning工具并与其他测试工具进行比较，因为它是最小的覆盖单位。 该工具的评估旨在回答以下研究问题： RQ1：与最先进的测试工具相比，该工具是否能提高代码覆盖率？ RQ2：该工具是否能够检测故障？ 该工具与最先进的测试工具进行了比较：Android Monkey，Dynodroid和PUMA。 5.2目标应用我们在七个开源Android应用程序上评估了我们的工具：AnyMemo [22]，Battery Dog [16]，Learn Music Notes [24]，Munch Life [23]，My Expenses [27]，Tippy Tipper [12和 Who has mystuﬀ [6]。它们具有各种大小和复杂性，具有静态和动态内容。表1提供了每种应用的简短描述。 5.3评估设置每个工具都在AndroTest [11]提供的单独虚拟机上运行。 AndroTest为各种应用程序的集合评估不同的测试工具提供了一个很好的基准。所有虚拟机都运行Ubuntu 32位，带有6114 MB基本内存和2个处理器。对于每个测试会话，应用程序仅在默认设置的模拟器上安装。为了防止先前会话的寄生数据，在开始新测试之前，已删除模拟器上的所有数据并重新启动模拟器。每个测试工具在每个应用程序上运行四次，然后将平均值作为最终结果。 5.4获得结果5.4.1代码覆盖率代码覆盖率是使用Emma [4]获得的，这是一个帮助程序类，它在运行测试之前嵌入在被测应用程序中。自定义脚本用于从设备中提取代码覆盖率，并且每隔五分钟将其转换为人类可读的报告。该报告提供有关包，类，块和行覆盖的详细信息。 Emma返回的覆盖范围考虑了检测类的代码行。我们根据Emma的结果计算实际覆盖率（仅计算应用程序的代码行数）并在评估中使用它。 5.4.2应用程序故障当应用程序意外崩溃时，在运行该工具时会发现应用程序故障。错误的堆栈跟踪由logcat记录，logcat是一个转储系统消息的命令行工具。通过Android Debug Bridge（adb）从手机或模拟器中检索错误跟踪。 5.5评估结果我们的工具获得的代码覆盖率与Android Monkey，Dynodroid和Puma的结果进行了比较。我们执行每个工具一小时，然后我们停止它，即我们比较执行一小时后的结果 5.5.1 RQ1：与最先进的测试工具相比，该工具是否提高了代码覆盖率？表2比较了七个目标应用程序的代码覆盖率，图3显示了Q学习工具实现的代码覆盖率的变化。 除了Battery Dog，我们的工具获得的代码覆盖率略低于Dynodroid，所提议的方法在7个应用程序中有6个优于DynoDroid和Puma。这种差异可以解释为Dynodroid可以生成系统事件和UI事件，而我们的工具只能生成UI事件。在Battery Dog的情况下，应用程序监视手机的电池电量，它响应系统事件，我们的工具无法处理。 对于大多数应用程序，Android Monkey获得了更高的代码覆盖率，因为它能够每秒有效地生成大量事件，远远超过我们的工具。 5.5.2 RQ2：工具是否能够检测到应用程序中的故障？尽管代码覆盖率是测试工具有效性的良好指标，但测试的最终目标是发现应用程序中的错误。因此，我们需要根据检测到的故障来评估该工具。在每次测试期间，通过Android Debug Bridge记录设备的日志，然后进行分析以发现与应用程序相关的故障。对于每个应用程序，我们计算在测试期间由应用程序引起的错误（或崩溃）的数量以及不同故障的数量。表3总结了实验结果。我们的工具能够在大多数应用程序中触发崩溃并发现故障。在一些应用中，多次崩溃是由同一故障引起的 6 对有效性的威胁有效性的两个主要威胁是内部和外部有效性。外部有效性的一个威胁是用于评估的应用程序数量。虽然我们只有七个应用程序，但我们尝试通过选择不同类别和不同大小的应用程序来最小化这种威胁。对内部有效性的威胁是我们方法的非确定性，这可能导致每次运行获得不同的代码覆盖率。因此，我们执行了多次运行以减少此威胁。 7结论本文提出了一种使用Q学习算法的Android应用程序测试强化学习方法。所提出的工具基于Q学习代理，并通过让代理以试错方式与应用程序交互来逐步构建应用程序的行为模型。 Q-learning代理以最佳方式探索应用程序，达到应用程序最相关的功能，从而生成测试用例。对该工具的评估已经证明，与现有测试工具相比，该工具在代码覆盖率方面有显着改进，并且能够发现故障。 未来改进我们的工具包括详细调查Q学习算法的奖励函数，支持更多类型的事件，如系统和上下文事件，以及处理非确定性。","content":"<h1 id=\"Abstract\"><a href=\"#Abstract\" class=\"headerlink\" title=\"Abstract\"></a>Abstract</h1><p>近年来，研究人员积极提出了自动化Android应用程序测试的工具。然而，他们的技术仍然遇到重大困难。首先是实现高代码覆盖率的困难，因为应用程序通常有大量的业务和转换的可能的组合，这使得在测试大型系统场景时会非常的耗时和无效。其次是实现广泛的应用功能的困难，因为某些功能只能通过特定的事件序列来实现。因此，在随机测试中，它们的测试频率较低。面对这些问题，我们应用称为Q学习的强化学习算法，以利用随机和基于模型的测试。 Q-learning代理与Android应用程序交互，逐步构建行为模型并基于模型生成测试用例。代理以最佳方式探索应用程序，尽可能多地显示应用程序的功能。与随机和基于模型的测试相比，使用Q学习的探索提高了代码覆盖率，并且能够检测被测应用程序中的故障</p>\n<p>KEYWORDS：Android, Test Input Generation, Reinforcement Learning, Q-Learning </p>\n<table>\n<thead>\n<tr>\n<th>relevant information</th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><em>作者</em></td>\n<td>Thi Anh Tuyet Vuong，<br>Shingo Takada</td>\n</tr>\n<tr>\n<td><em>单位</em></td>\n<td>Grad. School of Science and Technology, Keio University Yokohama, Japan<br>Grad. School of Science and Technology, Keio University Yokohama, Japan</td>\n</tr>\n<tr>\n<td><em>出处</em></td>\n<td>A-TEST ’18</td>\n</tr>\n<tr>\n<td><em>原文地址</em></td>\n<td><a href=\"https://dl.acm.org/citation.cfm?id=3278191\" target=\"_blank\" rel=\"noopener\">https://dl.acm.org/citation.cfm?id=3278191</a></td>\n</tr>\n<tr>\n<td><em>源码地址</em></td>\n<td></td>\n</tr>\n<tr>\n<td><em>发表时间</em></td>\n<td>2018年</td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"1-引言\"><a href=\"#1-引言\" class=\"headerlink\" title=\"1. 引言\"></a>1. 引言</h1><p>近年来，全球范围内移动软件的经济增长导致了开发人员对有效测试工具的持续需求。作为对这种需求的回应，研究人员提出了一种不同的工具，可以用尽可能少的人力来自动测试移动应用程序。大多数研究人员选择Android平台来开发他们的工具，因为Android手机的市场份额很大，Android测试工具无疑是有用的，并且与许多开发人员相关。此外，Android平台的开源特性使研究人员更容易访问应用程序和底层操作系统[11]。我们针对Android平台并针对Android应用程序开发测试工具的原因相同。</p>\n<p>Android应用程序由一个或多个<code></code>activities`组成，这些activities是负责应用程序用户界面（UI）的组件。每个activities都包含各种UI组件，如按钮，文本，复选框等。Android应用程序是基于事件的，这意味着它的行为基于对用户输入事件（UI事件）的响应，如单击，滚动，文本输入它还对来自手机操作系统的系统事件做出反应，如电话呼叫或短信信号等。由于Android应用程序基于事件的特性，相当多的研究都集中在自动生成输入事件以进行测试。无论采用何种技术，目标都是生成相关输入，以尽可能多地显示应用程序的功能。然而，这个领域的研究人员仍面临两个主要挑战：</p>\n<ul>\n<li>移动应用程序通常包含大量组件和可执行的事件。因此，测试组件和事件的所有可能组合是耗时的，并且难以扩展到大型系统。自动测试工具应仅测试与应用程序相关的事件序列，即导致测试应用程序功能的序列。</li>\n<li>•应用程序的某些功能只能通过特定的事件序列（难以到达的功能）来实现，这使得自动随机测试难以显示和测试它们。</li>\n</ul>\n<p>本文的主要贡献是提出强化学习的应用，特别是Q学习，以自动生成Android应用程序的测试输入。使用强化学习，我们构建了一个测试工具，以试错法的方式交互和探索应用程序的功能。在此探索过程中，该工具动态构建应用程序的行为模型，并生成遵循最有可能揭示应用程序功能的事件序列的测试用例。本文还展示了与最先进的自动化测试工具相比较的工具评估。</p>\n<p>本文的结构如下：第2节回顾了Android测试技术的相关工作;第3节介绍Q学习，然后第4节解释了Q-Learning工具的提议方法和实现细节;第5节讨论了对拟议工具的评估，最后第6节总结了论文以及对未来工作的建议。</p>\n<h1 id=\"2-相关工作\"><a href=\"#2-相关工作\" class=\"headerlink\" title=\"2 相关工作\"></a>2 相关工作</h1><p>在本节中，我们将研究Android应用程序的自动测试输入生成中的现有技术。</p>\n<p>我们可以基于探索策略对测试输入生成技术进行分类[11]。第一种技术是Random Exploration，其中测试工具生成随机事件并将它们发送到应用程序。虽然这种技术快速而简单，但生成的事件通常是不充分的。这是因为应用程序只能响应每个应用程序状态下的许多不同类型的事件中的一些。此外，所产生的事件通常是多余的，并且很难揭示难以触及的功能。 Android Monkey [2]是一个使用随机测试策略的黑盒测试工具，因其简单性而在开发人员中广泛使用。它在生成事件（仅UI事件）方面特别有效，能够每秒向应用程序发送数千个事件。 Monkey通常在测试工具中获得最高的代码覆盖率。然而，从人类与应用程序交互的角度来看，它发现的崩溃很难再现和不切实际。可能更好的说法使用Monkey测试比功能测试更接近压力测试。 Dynodroid [18]也是一种使用随机探索策略的黑盒测试工具，但与Monkey相比它有一些改进。它不是选择随机事件，而是选择与应用程序当前上下文最相关的事件（BiasedRandom策略）。开发人员提供无法自动生成的输入，例如测试前对工具的身份验证信息。 Dynodroid还通过分析应用程序的侦听器来生成相关的系统事件。属于此类别的另一组工具是模糊测试器：DroidFuzzer [29]，Intent Fuzzer [25]，Null Intent Fuzzer [5]等。它们主要旨在生成无效输入，导致被测应用程序崩溃</p>\n<p>第二种技术是基于模型的探索策略，其中测试工具静态或动态地构建测试中的应用程序的GUI模型，然后使用该模型来探索应用程序并生成事件。 A3E [10]提出了一种基于动态模型的动态深度探索，该动态模型将每个活动视为应用的状态。这种状态表示的简化导致测试不完整，因为A3E侧重于测试活动之间的转换，而不是每个活动内部的行为。 PUMA [14]是一个动态分析框架。它包含一个通用UI自动化功能（Monkey），可以公开用户可以定义处理程序的高级事件。这些处理程序指导Monkey的探索，并指定应用程序检测以收集动态状态信息或在应用程序执行期间触发环境中的更改。AndroidRipper [3]（也称为GUIRipper [8]或MobiGUITAR [7]）通过爬行构建应用程序模型。在每个活动中，它会注册当前状态下的所有可用事件。然后使用深度优先搜索策略系统地执行所有这些操作。AndroidRipper仅生成UI事件。</p>\n<p>最后一类技术是系统探索战略，它使用符号执行和进化算法等算法来指导探索。这种技术被EvoDroid [19]和Acteve [9]等工具使用。 EvoDroid为Android应用程序的系统测试提出了一种演化方法。进化测试将每个测试用例视为个体。根据某些启发式方法演变由许多个体组成的群体，以最大化代码覆盖并减少测试数量。 EvoDroid静态分析测试中的应用程序以构建其行为模型。这个模型允许进化搜索确定如何跨越个体将遗传构成传递给后代[19]。另一方面，Acteve系统地生成基于concolic测试的测试输入。它通过在事件序列之间提出包含的概念来处理类型测试的路径爆炸问题，以避免冗余事件执行。</p>\n<p>虽然与产生相同数量的事件的随机策略相比，基于模型的策略似乎更有效，但它仍然面临着许多挑战。基于黑盒模型的测试通常通过在测试之前静态构建应用程序模型或在测试期间动态地通过记录来自正在运行的应用程序的所有可能事件序列来进行。然后它生成测试用例以覆盖模型中的序列[21] [30]。因此，生成的测试用例的有效性很大程度上取决于记录模型的完整性以及应用程序状态的表示方式。一种广泛使用的技术是随机遍历被测应用程序的GUI以构建模型，但这种技术在处理复杂的GUI时是多余的和有限的。原因是某些状态比其他状态更容易到达，因此它们将在随机策略下更频繁地执行;而一些难以触及的国家可能根本不会被执行。停止条件也很难确定，有多少随机探索足以获得完整的模型？</p>\n<p>面对难以触及的GUI测试问题，Mariani等人[20]提出了一种用于通用Java桌面软件的黑盒GUI测试工具，它能够向前看并执行某些操作，以便进入难以触及的GUI。他们特别使用Q-learning，一种强化学习技术来实现这一目标。他们的工具（称为AutoBlackTest）动态构建行为模型，并在与被测软件交互时逐步生成测试用例。 AutoBlackTest将被测软件的行为模型表示构建为多方向图。节点表示状态（GUI），而边表示可执行操作。连接节点对应于状态之间的转换。在Q学习算法探索应用程序并观察新状态或执行新操作的每个步骤中，它都扩展了行为模型。当该工具提供初始测试套件时，性能得到改善，该测试套件指示如何测试软件的最相关功能。</p>\n<p>TESTAR [13]是一种测试工具，它还使用Q-learning来基于GUI信息生成测试序列，而无需访问源代码。来自TESTAR结果的统计分析指出，Q学习行动选择策略仅在适当选择参数时才有效。 TESTAR可以测试一般桌面软件和基于Web的软件。通过AutoBlackTest和TESTAR，强化学习技术已被证明在独立Java应用程序的GUI测试中非常有用。然而，由于Android平台以及Android应用程序本身的特殊性，这样的工具不能直接用于测试Android应用程序。强化学习需要适应Android环境，需要证明它在Android测试中很有用，因此本研究的目的是：在Android应用程序测试中应用强化学习。</p>\n<p>以下部分介绍了强化学习和Q-Learning，提供了必要的背景知识，以便理解论文的其余部分。</p>\n<h1 id=\"3-Q-LEARNING\"><a href=\"#3-Q-LEARNING\" class=\"headerlink\" title=\"3 Q-LEARNING\"></a>3 Q-LEARNING</h1><p>Q-Learning [26]是一种着名的强化学习技术，受行为主义心理学的启发，软件代理试图以反复试验的方式与环境互动。在每次交互时，代理执行一个动作，然后根据环境的当前状态，它根据其立即奖励并最终转移到环境返回的新状态来评估该动作的后果。总体目标是让代理学习如何以最佳方式行动以最大化累积奖励，这是在执行整个动作序列时收集的奖励。<br>强化学习问题的数学公式是马尔可夫决策过程。它由[26]定义：</p>\n<ul>\n<li>S：可能状态的集合</li>\n<li>A：可能的行动的集合</li>\n<li>R：给予的奖励的分布（状态，行动）对</li>\n<li>P：转移概率，即给定的下一个状态的分布（状态，动作）对</li>\n<li>γ：折扣因子图1总结了强化学习机制以及环境与代理之间的相互作用。</li>\n</ul>\n<p><img src=\"/2019/04/10/A-Reinforcement-Learning-Based-Approach-to-Automated-Testing-of-Android-Applications/1.jpg\" alt=\"\"></p>\n<p>Q学习代理在一系列离散时间步骤t = 0,1,2,3 ……中的每一个与环境交互[26]。在时间t = 0，环境从初始状态s0∈S开始。然后在从t = 0到完成的每个时间步骤：</p>\n<ul>\n<li><p>代理选择在∈A（st）处的动作，其中A（st）是一组状态st中可用的动作</p>\n</li>\n<li><p>环境采样并基于奖励R（.| st，at）的分布返回数值奖励rt</p>\n</li>\n<li><p>环境采样并基于转移概率P返回下一状态st + 1（.| st，at）</p>\n</li>\n<li><p>代理接收奖励rt并在新状态st + 1中结束自身。</p>\n</li>\n</ul>\n<p>在每个步骤t，代理观察环境的当前状态st并基于策略π选择动作。此策略表示代理对环境的行为。因为我们希望代理以最佳方式行事以最大化累积奖励，强化学习的目标是使政策π<em>最大化累积折扣奖励<br>$$<br>\\sum_{t&gt;0}γ^tr_t<br>$$<br>给定规则π，在Q学习中，我们定义一个称为Qvalue函数（或Q函数）的函数，它告诉一个（状态，动作）对有多好。对于状态s和动作a的任何组合，该函数返回可以通过执行以在a状态以s开始然后遵循规则π的一系列动作可以实现的预期累积奖励。最佳Q值函数Q </em>是对于所有可能的规则，从给定（状态，动作）对可实现的最大预期累积奖励。<br>$$<br>Q^π (s_t , a_t ) = max_π \\sum_{t &gt;0}<br>(γ^tr_t |s = s_0, a = a_t,π)<br>$$<br>如果已知下一步Q<em> s_{t + 1}，a_{t + 1}）的最佳状态 - 动作值，则最优策略是采取最大化r +γQ</em>的预期回报的动作（s_{t + 1}，a_{t + 1}）其中r是当前步骤的直接奖励。 Q *满足Bellman方程：</p>\n<p>$$<br>Q^∗(s_t , a_t ) = R(s_t , a_t ) + γ max_{a_t+1}<br>Q(s_{t+1}, a_{t+1})<br>$$<br>其中γ是介于0和1之间的折扣率参数。它平衡了即时奖励和累积奖励的相关性：γ越接近0值越立即奖励，γ越接近1值越累积奖励。因此，最优策略π<em>对应于采用由Q </em>指定的具有最高Q值的动作.Q学习算法基于等式（3）以迭代地估计Q函数的值。 Q函数使用默认值初始化。每当代理从状态st执行动作以达到状态st + 1并且接收奖励rt时，Q-function被更新为：<br>$$<br>Q(s_t , a_t ) ← Q(s_t , a_t ) + α(r_t + γ max_a<br>Q(s_{t+1}, a) − Q(s_t , a_t ))<br>$$<br>在该公式中，α是学习率（0≤α≤1）。 α表示新观察对Q函数估计值的影响。</p>\n<p>如果应用于马尔可夫环境，Q学习算法保证收敛到真正的Q函数，具有有限的立即奖励和状态 - 动作对不断更新[28]。</p>\n<h1 id=\"4-提议的方法：在Android应用程序测试中进行Q-LEARNING\"><a href=\"#4-提议的方法：在Android应用程序测试中进行Q-LEARNING\" class=\"headerlink\" title=\"4 提议的方法：在Android应用程序测试中进行Q-LEARNING\"></a>4 提议的方法：在Android应用程序测试中进行Q-LEARNING</h1><p>因为Q-Learning算法具有结合达到某种环境状态的最佳方式的能力，所以它可以用于指导探索到达揭示应用程序功能或难以到达状态的状态。在本文中，Q学习代理探索Android应用程序，可以将其建模为GUI状态的集合，并在每次迭代时生成诸如点击，类型，滑动，滚 动等事件。代理逐渐学习如何以揭示应用程序功能的方式遍历应用程序，然后生成涵盖尽可能多的代码的测试用例。</p>\n<p>在本文中，Markov模型的设计目的是为Android应用程序生成测试输入，如下所示：</p>\n<ul>\n<li>S：应用程序状态集。状态由活动名称和相应屏幕上可用的UI事件集确定。通过在每次访问一个状态时添加新状态，在每个Q学习迭代处更新该组访问状态。</li>\n<li>A：可能的GUI事件集。事件对应于可以在GUI组件上执行的动作（例如，按钮点击）。它由元组（GUI组件类名，事件类型，GUI组件唯一资源ID，屏幕上GUI组件的位置）定义。</li>\n<li>R：在给定转换（状态，事件，新状态）时返回数值的奖励函数</li>\n<li>P：在当前状态下执行事件时，转换到新状态由被测应用程序的响应确定</li>\n<li>γ：折扣因子</li>\n</ul>\n<p>我们的Q学习测试工具由两个主要角色组成：环境和代理。 Environment表示Android设备和正在测试的应用程序。它有三个辅助模块：Observer，Executor和Reward Function。代理了解被测应用程序的最相关行为模型，并根据此模型生成测试用例。行为模型结合了Q学习的结果。它包含状态空间S，可以在每个状态上执行的事件集以及每个（状态，事件）对的估计Q函数。</p>\n<p>为了创建测试用例，代理执行一系列固定数量的事件，也称为episode 。在完成一集之后，代理从已经访问过的那些中选择随机状态并从那里开始新的episode 。一集的长度是影响代理的有效性的一个重要参数，因为它可以为每个测试用例确定搜索空间的大小。该参数在很大程度上取决于应用程序的设计，例如活动的复杂性以及不同活动之间的交互频率。每集的迭代过程如下：</p>\n<p>从t = 0到episode 结束，重复：</p>\n<ul>\n<li>步骤1：环境 - 观察者观察正在测试的应用程序并构建当前的抽象状态。</li>\n<li>步骤2：代理确认当前状态，并根据策略及其当前行为模型选择要执行的下一个事件。</li>\n<li>步骤3：环境 - 执行程序执行所选事件。</li>\n<li>步骤4：环境 - 观察者观察应用程序的新GUI状态</li>\n<li>步骤5：环境 - 奖励功能计算后续奖励。</li>\n<li>步骤6：代理更新Q功能。</li>\n</ul>\n<p>下面给出每个步骤的细节。</p>\n<h2 id=\"4-1观察环境（步骤1和4）\"><a href=\"#4-1观察环境（步骤1和4）\" class=\"headerlink\" title=\"4.1观察环境（步骤1和4）\"></a>4.1观察环境（步骤1和4）</h2><p>Observer是环境的一个模块，其功能是观察环境的当前状态。 Observer的任务是在每次迭代时创建当前GUI树的抽象表示，简称为状态。 GUI树是GUI组件的层次结构，我们可以在运行时使用Android UI Automator从测试中的应用程序中提取。抽象GUI状态由当前活动的名称和当前GUI树中所有UI事件的元组组成。观察者仅在抽象状态中包括属于当前被测试应用程序的GUI元素（通过检查GUI元素属于哪个包）。在本文中，只考虑事件类型的点击，长按，检查（复选框），文本输入和滚动。即使Android平台支持更多的事件类型，我们目前仅支持这5种，因为它们是最广泛使用的，并将其他部分视为未来工作的一部分。除了正在测试的应用程序的UI事件之外，观察者还将菜单按钮单击和设备的后退按钮单击作为可用的UI事件。</p>\n<h2 id=\"4-2选择要在当前状态下执行的事件（步骤2）\"><a href=\"#4-2选择要在当前状态下执行的事件（步骤2）\" class=\"headerlink\" title=\"4.2选择要在当前状态下执行的事件（步骤2）\"></a>4.2选择要在当前状态下执行的事件（步骤2）</h2><p>在每个时间步，代理选择要在当前状态下执行的事件。基于策略π选择该事件。选择良好政策的挑战是平衡exploration and exploitation 之间的贸易往来[26]。为了获得巨大的回报，代理必须更喜欢过去曾经尝试过的事件，并且发现它们在产生奖励方面是有效的。它应该利用它对应用程序的了解并选择具有最高Q值的事件。但是要选择此类事件，代理商还必须探索新事件，以便在将来做出更好的选择。因此，通常考虑概率方法。在这项研究中，我们使用了一种名为ε-greedy的流行政策。代理选择当前状态中可用的随机事件，具有概率ε，或根据当前行为模型选择具有最高Q值的事件，概率为1-ε。</p>\n<p>在测试过程开始时，我们希望代理能够探索尽可能多的状态，以便构建最接近应用程序的完整模型，因此，应使用大的ε值。然而，一旦模型构建得很好，我们希望代理遵循Q值函数来快速达到应用程序的功能并测试它们，因此预期ε值较小。在本文中，我们从ε= 1开始以实现最大探索，然后我们在第一次100集期间均匀地减小其值，直到最终的最小值（在评估期间的实证研究之后为0.5）以改变代理的行为exploitation 。</p>\n<h2 id=\"4-3在环境中执行事件（步骤3）\"><a href=\"#4-3在环境中执行事件（步骤3）\" class=\"headerlink\" title=\"4.3在环境中执行事件（步骤3）\"></a>4.3在环境中执行事件（步骤3）</h2><p>Executor模块通过UI Automator [15]和Android Debug Bridge [1]在实际的Android设备或模拟器上执行事件。 Executor可以执行观察者可观察到的所有事件类型：单击，长按，检查，文本输入，滚动。对于文本输入，文本在执行期间随机生成。</p>\n<h2 id=\"4-4计算奖励（步骤5）\"><a href=\"#4-4计算奖励（步骤5）\" class=\"headerlink\" title=\"4.4计算奖励（步骤5）\"></a>4.4计算奖励（步骤5）</h2><p>通过奖励函数R在环境中计算奖励，奖励函数R基本上告诉代理哪个事件是好的以及哪个是坏的。在确定奖励函数时，需要考虑两个方面：GUI更改和执行频率。</p>\n<p>为了启发式地识别触发新功能的事件，奖励函数支持导致抽象GUI状态的许多变化并给予他们更高奖励的事件。这种推理类似于AutoBlackTest [20]中使用的推理。给定两个状态s1和s2，奖励函数通过比较和识别s2中但不在s1中的GUI事件的数量来计算从s1到s2的变化程度，描述为| s2 \\ s1 |。然后通过比率| s2 \\ s1 | / | s2 |来确定相对变化其中| s2 |是| s2 |中的GUI事件数。此公式考虑新出现在s2中的组件，但不考虑从s1中消失的组件。这样可以避免为触发应用程序活动之间跳转的事件提供过大的值。它适度地增加了Q值，因此我们可以测试每个活动中活动和功能之间的转换。</p>\n<p>添加了另一个因素来帮助代理平衡the exploration and exploitation ：执行频率。我们计算每个事件执行的次数，并随着执行频率的增加而减少奖励。与一定次数的迭代之后的GUI改变奖励相比，该奖励值变得相对较小。但它有助于Q-agent在测试开始时更快地探索新状态，从而提高其状态空间的完整性。<br>总之，奖励函数的定义由以下公式给出：<br>$$<br>r_t = R(s_t ,a_t ,s_{t+1}) = \\frac{|s_{t+1} \\ s_t |}{|s_{t+1}|} </p>\n<ul>\n<li>\\frac{1}{f(s_t,a_t )}<br>$$<br>其中f（st，at）是处于状态 st 直到时间 t 的事件 at 的执行频率。</li>\n</ul>\n<h2 id=\"4-5-更新Q值函数（步骤6）\"><a href=\"#4-5-更新Q值函数（步骤6）\" class=\"headerlink\" title=\"4.5 更新Q值函数（步骤6）\"></a>4.5 更新Q值函数（步骤6）</h2><p>代理根据当前迭代期间发生的转换构建和更新Q值函数，即行为模型。</p>\n<p>代理在每次迭代之后使用等式（4）更新Q值函数，学习率α= 1并且折扣率γ= 0.9。学习率α接近1会对新模型的新观察产生更大的影响。我们选择值α= 1，以便代理快速了解应用程序的行为方式。折扣因子平衡了即时奖励与未来事件的相关性，值0.9最大化了整个episode 期间收集的奖励，而不是最大化直接奖励。因此，等式（4）变为<br>$$<br>Q（s_t，a_t）←r_t + 0.9 max_a Q（s_{t + 1}，a）<br>$$<br>当动作到达未被访问的状态时，公式的第二项是因为我们没有对该状态的Q值进行任何估计。在这种情况下，Q值只是即时奖励。否则，根据目标状态中的事件的奖励值和Q值来计算Q值。</p>\n<p>特殊功能用于处理转换导致退出被测应用程序的情况。在这种情况下，测试工具随机执行最多数量的事件，这些事件不属于被测应用程序。这个最大数量是两个事件。每次执行后，我们都会检查该工具是否返回到测试中的应用程序。如果是，我们正常进行测试;如果没有，我们强制该工具返回应用程序的启动器活动。触发退出应用程序的事件被给予0奖励，因为我们避免执行它。这是必要的，因为我们无法在正常的应用程序退出和应用程序崩溃（我们认为存在故障）之间进行区分。</p>\n<h2 id=\"4-6实现\"><a href=\"#4-6实现\" class=\"headerlink\" title=\"4.6实现\"></a>4.6实现</h2><p>该工具是用Python 2.7编写的。该工具的架构和工作流程如图2所示。为了与Android设备和被测应用程序进行交互，我们使用Android UI Automator [15]的python库以及Android Debug Bridge [1]</p>\n<p><img src=\"/2019/04/10/A-Reinforcement-Learning-Based-Approach-to-Automated-Testing-of-Android-Applications/2.jpg\" alt=\"\"></p>\n<h1 id=\"5评估\"><a href=\"#5评估\" class=\"headerlink\" title=\"5评估\"></a>5评估</h1><h2 id=\"5-1评估指标\"><a href=\"#5-1评估指标\" class=\"headerlink\" title=\"5.1评估指标\"></a>5.1评估指标</h2><p>衡量工具有效性的指标是代码覆盖率，这是评估测试工具的通用指标。具体而言，我们使用行覆盖来评估Q-Learning工具并与其他测试工具进行比较，因为它是最小的覆盖单位。</p>\n<p>该工具的评估旨在回答以下研究问题：</p>\n<ul>\n<li>RQ1：与最先进的测试工具相比，该工具是否能提高代码覆盖率？</li>\n<li>RQ2：该工具是否能够检测故障？</li>\n</ul>\n<p>该工具与最先进的测试工具进行了比较：Android Monkey，Dynodroid和PUMA。</p>\n<h2 id=\"5-2目标应用\"><a href=\"#5-2目标应用\" class=\"headerlink\" title=\"5.2目标应用\"></a>5.2目标应用</h2><p>我们在七个开源Android应用程序上评估了我们的工具：AnyMemo [22]，Battery Dog [16]，Learn Music Notes [24]，Munch Life [23]，My Expenses [27]，Tippy Tipper [12和 Who has mystuﬀ [6]。它们具有各种大小和复杂性，具有静态和动态内容。表1提供了每种应用的简短描述。</p>\n<p><img src=\"/2019/04/10/A-Reinforcement-Learning-Based-Approach-to-Automated-Testing-of-Android-Applications/3.jpg\" alt=\"\"></p>\n<h2 id=\"5-3评估设置\"><a href=\"#5-3评估设置\" class=\"headerlink\" title=\"5.3评估设置\"></a>5.3评估设置</h2><p>每个工具都在AndroTest [11]提供的单独虚拟机上运行。 AndroTest为各种应用程序的集合评估不同的测试工具提供了一个很好的基准。所有虚拟机都运行Ubuntu 32位，带有6114 MB基本内存和2个处理器。对于每个测试会话，应用程序仅在默认设置的模拟器上安装。为了防止先前会话的寄生数据，在开始新测试之前，已删除模拟器上的所有数据并重新启动模拟器。每个测试工具在每个应用程序上运行四次，然后将平均值作为最终结果。</p>\n<h2 id=\"5-4获得结果\"><a href=\"#5-4获得结果\" class=\"headerlink\" title=\"5.4获得结果\"></a>5.4获得结果</h2><h3 id=\"5-4-1代码覆盖率\"><a href=\"#5-4-1代码覆盖率\" class=\"headerlink\" title=\"5.4.1代码覆盖率\"></a>5.4.1代码覆盖率</h3><p>代码覆盖率是使用Emma [4]获得的，这是一个帮助程序类，它在运行测试之前嵌入在被测应用程序中。自定义脚本用于从设备中提取代码覆盖率，并且每隔五分钟将其转换为人类可读的报告。该报告提供有关包，类，块和行覆盖的详细信息。 Emma返回的覆盖范围考虑了检测类的代码行。我们根据Emma的结果计算实际覆盖率（仅计算应用程序的代码行数）并在评估中使用它。</p>\n<h3 id=\"5-4-2应用程序故障\"><a href=\"#5-4-2应用程序故障\" class=\"headerlink\" title=\"5.4.2应用程序故障\"></a>5.4.2应用程序故障</h3><p>当应用程序意外崩溃时，在运行该工具时会发现应用程序故障。错误的堆栈跟踪由logcat记录，logcat是一个转储系统消息的命令行工具。通过Android Debug Bridge（adb）从手机或模拟器中检索错误跟踪。</p>\n<h2 id=\"5-5评估结果\"><a href=\"#5-5评估结果\" class=\"headerlink\" title=\"5.5评估结果\"></a>5.5评估结果</h2><p>我们的工具获得的代码覆盖率与Android Monkey，Dynodroid和Puma的结果进行了比较。我们执行每个工具一小时，然后我们停止它，即我们比较执行一小时后的结果</p>\n<p><img src=\"/2019/04/10/A-Reinforcement-Learning-Based-Approach-to-Automated-Testing-of-Android-Applications/4.jpg\" alt=\"\"></p>\n<p><img src=\"/2019/04/10/A-Reinforcement-Learning-Based-Approach-to-Automated-Testing-of-Android-Applications/5.jpg\" alt=\"\"></p>\n<h3 id=\"5-5-1-RQ1：与最先进的测试工具相比，该工具是否提高了代码覆盖率？\"><a href=\"#5-5-1-RQ1：与最先进的测试工具相比，该工具是否提高了代码覆盖率？\" class=\"headerlink\" title=\"5.5.1 RQ1：与最先进的测试工具相比，该工具是否提高了代码覆盖率？\"></a>5.5.1 RQ1：与最先进的测试工具相比，该工具是否提高了代码覆盖率？</h3><p>表2比较了七个目标应用程序的代码覆盖率，图3显示了Q学习工具实现的代码覆盖率的变化。</p>\n<p>除了Battery Dog，我们的工具获得的代码覆盖率略低于Dynodroid，所提议的方法在7个应用程序中有6个优于DynoDroid和Puma。这种差异可以解释为Dynodroid可以生成系统事件和UI事件，而我们的工具只能生成UI事件。在Battery Dog的情况下，应用程序监视手机的电池电量，它响应系统事件，我们的工具无法处理。</p>\n<p>对于大多数应用程序，Android Monkey获得了更高的代码覆盖率，因为它能够每秒有效地生成大量事件，远远超过我们的工具。</p>\n<h3 id=\"5-5-2-RQ2：工具是否能够检测到应用程序中的故障？\"><a href=\"#5-5-2-RQ2：工具是否能够检测到应用程序中的故障？\" class=\"headerlink\" title=\"5.5.2 RQ2：工具是否能够检测到应用程序中的故障？\"></a>5.5.2 RQ2：工具是否能够检测到应用程序中的故障？</h3><p>尽管代码覆盖率是测试工具有效性的良好指标，但测试的最终目标是发现应用程序中的错误。因此，我们需要根据检测到的故障来评估该工具。在每次测试期间，通过Android Debug Bridge记录设备的日志，然后进行分析以发现与应用程序相关的故障。对于每个应用程序，我们计算在测试期间由应用程序引起的错误（或崩溃）的数量以及不同故障的数量。表3总结了实验结果。我们的工具能够在大多数应用程序中触发崩溃并发现故障。在一些应用中，多次崩溃是由同一故障引起的</p>\n<p><img src=\"/2019/04/10/A-Reinforcement-Learning-Based-Approach-to-Automated-Testing-of-Android-Applications/6.jpg\" alt=\"\"></p>\n<h1 id=\"6-对有效性的威胁\"><a href=\"#6-对有效性的威胁\" class=\"headerlink\" title=\"6 对有效性的威胁\"></a>6 对有效性的威胁</h1><p>有效性的两个主要威胁是内部和外部有效性。外部有效性的一个威胁是用于评估的应用程序数量。虽然我们只有七个应用程序，但我们尝试通过选择不同类别和不同大小的应用程序来最小化这种威胁。<br>对内部有效性的威胁是我们方法的非确定性，这可能导致每次运行获得不同的代码覆盖率。因此，我们执行了多次运行以减少此威胁。</p>\n<h1 id=\"7结论\"><a href=\"#7结论\" class=\"headerlink\" title=\"7结论\"></a>7结论</h1><p>本文提出了一种使用Q学习算法的Android应用程序测试强化学习方法。所提出的工具基于Q学习代理，并通过让代理以试错方式与应用程序交互来逐步构建应用程序的行为模型。 Q-learning代理以最佳方式探索应用程序，达到应用程序最相关的功能，从而生成测试用例。对该工具的评估已经证明，与现有测试工具相比，该工具在代码覆盖率方面有显着改进，并且能够发现故障。</p>\n<p>未来改进我们的工具包括详细调查Q学习算法的奖励函数，支持更多类型的事件，如系统和上下文事件，以及处理非确定性。</p>\n","categories":[{"name":"论文","slug":"论文","permalink":"http://yama0xff.com/categories/论文/"},{"name":"fuzzing","slug":"论文/fuzzing","permalink":"http://yama0xff.com/categories/论文/fuzzing/"},{"name":"测试样例生成","slug":"论文/fuzzing/测试样例生成","permalink":"http://yama0xff.com/categories/论文/fuzzing/测试样例生成/"}],"tags":[{"name":"reinforcement learning","slug":"reinforcement-learning","permalink":"http://yama0xff.com/tags/reinforcement-learning/"},{"name":"Android","slug":"Android","permalink":"http://yama0xff.com/tags/Android/"}]},{"title":"Skyfire: Data-Driven Seed Generation for Fuzzing","date":"2019-04-10T12:19:39.000Z","path":"2019/04/10/Skyfire-Data-Driven-Seed-Generation-for-Fuzzing/","text":"Abstract对于输入格式是高度结构化文件的程序来说，其处理流程一般是：语法解析–语义检查–程序执行。程序深层次的漏洞一般隐藏在程序执行阶段，而对于自动化的模糊测试（Fuzzing）来说很难触发该类漏洞。该论文提出了一种数据驱动的种子生成方法，叫做Skyfire。Skyfire通过从大量的已知样本中学习而生成覆盖良好的种子作为Fuzzing的输入对处理高度结构化输入的程序进行测试。Skyfire接收输入样本集合和文法，通过自动化学习PCSG（Probabilistic context-sensitive grammar，一种带概率的上下文有关文法，包含语义规则和语法特征），并利用其生成种子文件。本文利用收集的样本和Skyfire生成的种子作为AFL的seed对开源的XSLT、XML等引擎进行测试，证明skyfire生成的种子文件分布（提高了20%行覆 盖率和%15的函数覆盖率）和发现漏洞能力。同时也对闭源的IE11的JavaScript引擎测试。其发现了19个新的内存破坏型bug（其中16个新的漏洞）和32个拒绝服务bug。 relevant information 作者 Junjie Wang, Bihuan Chen†, Lei Wei, and Yang Liu 单位 Nanyang Technological University, Singapore 出处 IEEE S&amp;P 2017 原文地址 https://www.ieee-security.org/TC/SP2017/papers/42.pdf 源码地址 https://github.com/zhunki/skyfire 发表时间 2017年 1. 背景介绍Fuzzing是一种自动化的随机测试技术，其通过变异或者生成的方法生成大量的测试样本，并利用生成的测试样本对目标程序进行测试和监控，以发现程序异常和缺陷。 模糊测试的输入种子文件的质量是对测试效果的重要影响因素。如图1所示，基于变异的方法是通过随机或者启发式的方法对合法的输入种子文件进行变异生成测试用例，大部分的生成用例在早期的语法检查阶段就被拒绝而导致程序退出。然而，基于生成的方法是利用格式描述或文法描述来生成测试用例，可以快速的通过语法检查阶段，但是大部分程序在语义检查阶段也难以通过，这都限制了这些方法难以挖掘程序的深层次漏洞。一个高效的Fuzzer需要实现大部分的生成样本可以到达处理执行阶段（execution stage)。 基于生成的方法能够实现对语法规则的描述和生成，但是想要通过语义规则的检查却是非常困难的。一方面，对于不同的程序有不同的语义规则，编写的生成规则难以复用；另一方面，这样的手动描述方法是非常耗时费力的，而且有时候甚至是难以实现的。 本文使用一种扩展的上下文敏感的文法（包含语义信息和概率信息）来生成测试用例，并将其作为Fuzzer的输入进行测试。Skyfire面向的目标程序是接收高度结构化输入的程序，目的是生成覆盖良好的测试用例。 2 方法概述2.1 生成目标（1）生成正确的种子：能够通过程序的语法和语义检测； （2）生成多样性种子：能够多样化地覆盖语法和语义规则； （3）生成不常见种子：能够生成一般Fuzzer生成不了的种子。 2.2 处理过程Skyfire通过学习PCSG，可以生成覆盖良好的种子，供后续fuzzing，总体架构如图2所示。 输入：爬取的样本集合+程序的语法规则（github上ANTLR社区开源）； 输出：覆盖良好的种子。 包含以下主要步骤： (1) PCSG学习 根据输入自动化抽取带概率的上下文有关文法规则； （2）种子生成 初始种子生成：根据抽取的规则采用左推导方法进行初始种子生成； 种子选取：采用覆盖率作为衡量标准进行样本去重选取； 种子变异：利用随机替换原则对同种类型的叶子节点进行变异； 下面详细介绍下这些主要步骤： 2.2.1 PCSG学习这里是Skyfire的很重要的一点，为了更好理解这个过程，先介绍下CFG（Context-free grammar，上下文无关文法）、CSG（Context-sensitive grammar，上下文有关文法）。CFG的定义如图3，它是一个四元组，由一组有限的α→β1β2…βn形式的产生式规则组成。其中α∈N是有限的非终端符号集，βi属于一组有限的非终端符号和终端符号的并集。这套文法可以用来表示一个语言的语法规则。图4是XSL语言的上下文无关文法部分内容。 图3 CFG的定义 图4 XSL语言的上下文无关文法部分内容 根据上下文无关文法，可以将一个XSL文件解析为抽象语法树，图5就是一个XSL文件及其抽象语法树。上下文无关文法能很好地表达语法信息，但因为上下文无关，不能表达上下文相关的语义信息。 图5 一个XSL示例文件及其抽象语法树 因此，可以用上下文有关文法来加入语义信息。图6是作者定义的一种上下文有关文法，给产生式中增加了上下文信息。上下文包含四项信息，顺序依次为α的曾祖父母类型、祖父母类型、父类类型、第一兄弟姐妹的值或第一兄弟姐妹的类型（如果值为空的话）。 图6 CSG的定义 为了生成分布良好的种子，作者还将概率附加到每个产生规则的上下文中，来定义在一个上下文下，每种产生式规则的概率。这样，就有了本文的核心和一大创新点：带概率的上下文有关文法PCSG，可以将CFG、CSG和PCSG结合起来看，如图7所示。 图7 从CFG、CSG到PCSG的演进 PCSG的学习过程分为以下几步： （1）自动从样本解析出AST； （2）计算每种parent-children对（即产生式规则）在相应上下文下的次数； （3）计算在一种上下文下的每种产生式规则的概率，等于在上下文c下这个产生式规则“α→β1β2…βn”的次数除以所有树中“α”的次数，公式如下： $$q([c]α→β1β2…βn) = count([c]α→β1β2…βn)/count(α)$$ 例如图8所示，绿色的节点5和节点14是父子对，对应的是上下文&lt;null, document, prolog, &lt;?xml&gt;下的产生规则attribute Version=“1.0”，它对应的上下文为曾祖父为空，祖父母为文档，父为PROLOG，第一个兄弟为&lt;？xml。图9是XSL语言学习的产生规则的一部分，在上下文&lt;NULL、NULL、NULL、NULL&gt;下只有两个产生规则的左边是document，这与document是XSL语言的开始符号这一事实是一致的。 图8 PCSG学习过程示例 图9 XSL语言学习的产生规则的一部分 2.2.2 种子生成整个种子生成过程可以分为三步：初始种子生成、种子选择、种子变异。 （1）始种子生成 初始种子生成的算法 初始种子是根据学习出的PCGS，利用左推导方法生成种子输入产生的，算法也很清晰易懂，如图10所示。首先设置语法的起始符号t0，然后从 t 中获取最左边的非终结符 l 和上下文信息 c，再从Rl中随机选取产生式规则r，再在 t 中对 l 进行 r 推导替换，重复这个过程直到没有剩余的非终端符号。 这里使用了四个启发式规则来生成分布良好的样本，我用不同颜色在算法中标示了出来。第一条红色代表优先选取低概率的产生规则，这样可以生成网上爬取的样本很难覆盖的功能；第二条是限制相同一产生规则的使用次数，优先应用频率低的规则；第三条是优先使用低复杂度的产生规则；第四条是限制所有规则的应用次数。 图10 从PCSG中产生初始种子的算法 （2）种子选取 上面的步骤可以生成很多的初始种子，但并不是所有种子都是唯一和重要的，作者以覆盖率作为标准进行种子去冗余筛选，对于开源程序使用gcov获取代码和函数覆盖率，对于闭源程序使用PIN获取基本块覆盖率。 （3）种子变异 上面的步骤可以产生语法结构多样的种子，为了进一步确保语义的多样性，SkyFire会对生成的种子进行Big-Step变异。这种Big-step的变异可以产生一般Fuzzer的small-step变异难以生成的种子。方法是从AST中选取叶子节点，并利用同种类型的叶子节点对其进行随机替换，只用右边是终结符的推导规则。 3 实验实验利用爬取的种子文件对libxslt、libxml2、Sabotron进行测试，测试能够有效发现漏洞，并且漏洞持续发现能力比直接用爬取的种子文件进行测试效果更好。 此外，测试的覆盖率等得到明显的提升效果。目前该方法对JavaScript语言的测试效果不是特别理想，需要进一步的改进。 4 总结本文实现的数据驱动的种子生成方法利用文法和样本自动抽取语义信息，并利用语义信息和语法规则进行种子生成，能够保证生成种子文件通过语法解析和语义检查，能够执行到目标程序的更深的路径，从而更有效的发现深层次的漏洞。 Skyfire目前对于XML、XSL语言的应用效果很好，能够保证漏洞发现能力和覆盖率，但是对于JS这种较为复杂的语言应用不够理想。 5 未来工作 作者将继续应用和扩展这种种子生成方法，以便更好地支持更多不同的语言，如javascript、SQL、C和java。除了查找安全漏洞之外，作者还希望使用生成的种子输入来查找编译器错误。","content":"<h1 id=\"Abstract\"><a href=\"#Abstract\" class=\"headerlink\" title=\"Abstract\"></a>Abstract</h1><p>对于输入格式是高度结构化文件的程序来说，其处理流程一般是：语法解析–语义检查–程序执行。程序深层次的漏洞一般隐藏在程序执行阶段，而对于自动化的模糊测试（Fuzzing）来说很难触发该类漏洞。该论文提出了一种数据驱动的种子生成方法，叫做Skyfire。Skyfire通过从大量的已知样本中学习而生成覆盖良好的种子作为Fuzzing的输入对处理高度结构化输入的程序进行测试。Skyfire接收输入样本集合和文法，通过自动化学习PCSG（Probabilistic context-sensitive grammar，一种带概率的上下文有关文法，包含语义规则和语法特征），并利用其生成种子文件。本文利用收集的样本和Skyfire生成的种子作为AFL的seed对开源的XSLT、XML等引擎进行测试，证明skyfire生成的种子文件分布（提高了20%行覆 盖率和%15的函数覆盖率）和发现漏洞能力。同时也对闭源的IE11的JavaScript引擎测试。其发现了19个新的内存破坏型bug（其中16个新的漏洞）和32个拒绝服务bug。</p>\n<table>\n<thead>\n<tr>\n<th>relevant information</th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><em>作者</em></td>\n<td>Junjie Wang, Bihuan Chen†, Lei Wei, and Yang Liu</td>\n</tr>\n<tr>\n<td><em>单位</em></td>\n<td>Nanyang Technological University, Singapore</td>\n</tr>\n<tr>\n<td><em>出处</em></td>\n<td>IEEE S&amp;P 2017</td>\n</tr>\n<tr>\n<td><em>原文地址</em></td>\n<td><a href=\"https://www.ieee-security.org/TC/SP2017/papers/42.pdf\" target=\"_blank\" rel=\"noopener\">https://www.ieee-security.org/TC/SP2017/papers/42.pdf</a></td>\n</tr>\n<tr>\n<td><em>源码地址</em></td>\n<td><a href=\"https://github.com/zhunki/skyfire\" target=\"_blank\" rel=\"noopener\">https://github.com/zhunki/skyfire</a></td>\n</tr>\n<tr>\n<td><em>发表时间</em></td>\n<td>2017年</td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"1-背景介绍\"><a href=\"#1-背景介绍\" class=\"headerlink\" title=\"1. 背景介绍\"></a>1. 背景介绍</h1><p>Fuzzing是一种自动化的随机测试技术，其通过变异或者生成的方法生成大量的测试样本，并利用生成的测试样本对目标程序进行测试和监控，以发现程序异常和缺陷。</p>\n<p>模糊测试的输入种子文件的质量是对测试效果的重要影响因素。如图1所示，基于变异的方法是通过随机或者启发式的方法对合法的输入种子文件进行变异生成测试用例，大部分的生成用例在早期的语法检查阶段就被拒绝而导致程序退出。然而，基于生成的方法是利用格式描述或文法描述来生成测试用例，可以快速的通过语法检查阶段，但是大部分程序在语义检查阶段也难以通过，这都限制了这些方法难以挖掘程序的深层次漏洞。一个高效的Fuzzer需要实现大部分的生成样本可以到达处理执行阶段（execution stage)。</p>\n<p><img src=\"/2019/04/10/Skyfire-Data-Driven-Seed-Generation-for-Fuzzing/1.jpg\" alt=\"\"></p>\n<p>基于生成的方法能够实现对语法规则的描述和生成，但是想要通过语义规则的检查却是非常困难的。一方面，对于不同的程序有不同的语义规则，编写的生成规则难以复用；另一方面，这样的手动描述方法是非常耗时费力的，而且有时候甚至是难以实现的。</p>\n<p>本文使用一种扩展的上下文敏感的文法（包含语义信息和概率信息）来生成测试用例，并将其作为Fuzzer的输入进行测试。Skyfire面向的目标程序是接收高度结构化输入的程序，目的是生成覆盖良好的测试用例。</p>\n<h1 id=\"2-方法概述\"><a href=\"#2-方法概述\" class=\"headerlink\" title=\"2 方法概述\"></a>2 方法概述</h1><h2 id=\"2-1-生成目标\"><a href=\"#2-1-生成目标\" class=\"headerlink\" title=\"2.1 生成目标\"></a>2.1 生成目标</h2><p>（1）生成正确的种子：能够通过程序的语法和语义检测；</p>\n<p>（2）生成多样性种子：能够多样化地覆盖语法和语义规则；</p>\n<p>（3）生成不常见种子：能够生成一般Fuzzer生成不了的种子。</p>\n<h2 id=\"2-2-处理过程\"><a href=\"#2-2-处理过程\" class=\"headerlink\" title=\"2.2 处理过程\"></a>2.2 处理过程</h2><p>Skyfire通过学习PCSG，可以生成覆盖良好的种子，供后续fuzzing，总体架构如图2所示。</p>\n<p><strong>输入</strong>：爬取的样本集合+程序的语法规则（github上ANTLR社区开源）；</p>\n<p><strong>输出</strong>：覆盖良好的种子。</p>\n<p>包含以下主要步骤：</p>\n<ul>\n<li><strong>(1) PCSG学习</strong></li>\n</ul>\n<p>根据输入自动化抽取带概率的上下文有关文法规则；</p>\n<ul>\n<li><strong>（2）种子生成</strong></li>\n</ul>\n<p><strong>初始种子生成</strong>：根据抽取的规则采用左推导方法进行初始种子生成；</p>\n<p><strong>种子选取</strong>：采用覆盖率作为衡量标准进行样本去重选取；</p>\n<p><strong>种子变异</strong>：利用随机替换原则对同种类型的叶子节点进行变异；</p>\n<p><img src=\"/2019/04/10/Skyfire-Data-Driven-Seed-Generation-for-Fuzzing/2.jpg\" alt=\"\"></p>\n<p>下面详细介绍下这些主要步骤：</p>\n<h3 id=\"2-2-1-PCSG学习\"><a href=\"#2-2-1-PCSG学习\" class=\"headerlink\" title=\"2.2.1 PCSG学习\"></a>2.2.1 PCSG学习</h3><p>这里是Skyfire的很重要的一点，为了更好理解这个过程，先介绍下CFG（Context-free grammar，上下文无关文法）、CSG（Context-sensitive grammar，上下文有关文法）。CFG的定义如图3，它是一个四元组，由一组有限的α→β1β2…βn形式的产生式规则组成。其中α∈N是有限的非终端符号集，βi属于一组有限的非终端符号和终端符号的并集。这套文法可以用来表示一个语言的语法规则。图4是XSL语言的上下文无关文法部分内容。</p>\n<p><img src=\"/2019/04/10/Skyfire-Data-Driven-Seed-Generation-for-Fuzzing/3.jpg\" alt=\"3\"><br>图3 CFG的定义</p>\n<p><img src=\"/2019/04/10/Skyfire-Data-Driven-Seed-Generation-for-Fuzzing/4.jpg\" alt=\"4\"><br>图4 XSL语言的上下文无关文法部分内容</p>\n<p>根据上下文无关文法，可以将一个XSL文件解析为抽象语法树，图5就是一个XSL文件及其抽象语法树。上下文无关文法能很好地表达语法信息，但因为上下文无关，不能表达上下文相关的语义信息。</p>\n<p><img src=\"/2019/04/10/Skyfire-Data-Driven-Seed-Generation-for-Fuzzing/5.jpg\" alt=\"\"><br>图5 一个XSL示例文件及其抽象语法树</p>\n<p>因此，可以用上下文有关文法来加入语义信息。图6是作者定义的一种上下文有关文法，给产生式中增加了上下文信息。上下文包含四项信息，顺序依次为α的曾祖父母类型、祖父母类型、父类类型、第一兄弟姐妹的值或第一兄弟姐妹的类型（如果值为空的话）。</p>\n<p><img src=\"/2019/04/10/Skyfire-Data-Driven-Seed-Generation-for-Fuzzing/6.jpg\" alt=\"\"><br>图6 CSG的定义</p>\n<p>为了生成分布良好的种子，作者还将概率附加到每个产生规则的上下文中，来定义在一个上下文下，每种产生式规则的概率。这样，就有了本文的核心和一大创新点：带概率的上下文有关文法PCSG，可以将CFG、CSG和PCSG结合起来看，如图7所示。</p>\n<p><img src=\"/2019/04/10/Skyfire-Data-Driven-Seed-Generation-for-Fuzzing/7.jpg\" alt=\"\"><br>图7 从CFG、CSG到PCSG的演进</p>\n<p>PCSG的学习过程分为以下几步：</p>\n<ul>\n<li><p>（1）自动从样本解析出AST；</p>\n</li>\n<li><p>（2）计算每种parent-children对（即产生式规则）在相应上下文下的次数；</p>\n</li>\n<li><p>（3）计算在一种上下文下的每种产生式规则的概率，等于在上下文c下这个产生式规则“α→β1β2…βn”的次数除以所有树中“α”的次数，公式如下：</p>\n</li>\n</ul>\n<p>$$<br>q([c]α→β1β2…βn) = count([c]α→β1β2…βn)/count(α)<br>$$</p>\n<p>例如图8所示，绿色的节点5和节点14是父子对，对应的是上下文&lt;null, document, prolog, &lt;?xml&gt;下的产生规则attribute Version=“1.0”，它对应的上下文为曾祖父为空，祖父母为文档，父为PROLOG，第一个兄弟为&lt;？xml。图9是XSL语言学习的产生规则的一部分，在上下文&lt;NULL、NULL、NULL、NULL&gt;下只有两个产生规则的左边是document，这与document是XSL语言的开始符号这一事实是一致的。</p>\n<p><img src=\"/2019/04/10/Skyfire-Data-Driven-Seed-Generation-for-Fuzzing/8.png\" alt=\"\"><br>图8 PCSG学习过程示例</p>\n<p><img src=\"/2019/04/10/Skyfire-Data-Driven-Seed-Generation-for-Fuzzing/9.jpg\" alt=\"\"><br>图9 XSL语言学习的产生规则的一部分</p>\n<h3 id=\"2-2-2-种子生成\"><a href=\"#2-2-2-种子生成\" class=\"headerlink\" title=\"2.2.2 种子生成\"></a>2.2.2 种子生成</h3><p>整个种子生成过程可以分为三步：初始种子生成、种子选择、种子变异。</p>\n<ul>\n<li><strong>（1）始种子生成</strong></li>\n</ul>\n<p><strong>初始种子生成的算法</strong></p>\n<p>初始种子是根据学习出的PCGS，利用左推导方法生成种子输入产生的，算法也很清晰易懂，如图10所示。首先设置语法的起始符号t0，然后从 t 中获取最左边的非终结符 l 和上下文信息 c，再从Rl中随机选取产生式规则r，再在 t 中对 l 进行 r 推导替换，重复这个过程直到没有剩余的非终端符号。</p>\n<p>这里使用了四个启发式规则来生成分布良好的样本，我用不同颜色在算法中标示了出来。第一条红色代表优先选取低概率的产生规则，这样可以生成网上爬取的样本很难覆盖的功能；第二条是限制相同一产生规则的使用次数，优先应用频率低的规则；第三条是优先使用低复杂度的产生规则；第四条是限制所有规则的应用次数。</p>\n<p><img src=\"/2019/04/10/Skyfire-Data-Driven-Seed-Generation-for-Fuzzing/10.jpg\" alt=\"\"><br>图10 从PCSG中产生初始种子的算法</p>\n<ul>\n<li><strong>（2）种子选取</strong></li>\n</ul>\n<p>上面的步骤可以生成很多的初始种子，但并不是所有种子都是唯一和重要的，作者以覆盖率作为标准进行种子去冗余筛选，对于开源程序使用gcov获取代码和函数覆盖率，对于闭源程序使用PIN获取基本块覆盖率。</p>\n<ul>\n<li><strong>（3）种子变异</strong></li>\n</ul>\n<p>上面的步骤可以产生语法结构多样的种子，为了进一步确保语义的多样性，SkyFire会对生成的种子进行Big-Step变异。这种Big-step的变异可以产生一般Fuzzer的small-step变异难以生成的种子。方法是从AST中选取叶子节点，并利用同种类型的叶子节点对其进行随机替换，只用右边是终结符的推导规则。</p>\n<h1 id=\"3-实验\"><a href=\"#3-实验\" class=\"headerlink\" title=\"3 实验\"></a>3 实验</h1><p>实验利用爬取的种子文件对libxslt、libxml2、Sabotron进行测试，测试能够有效发现漏洞，并且漏洞持续发现能力比直接用爬取的种子文件进行测试效果更好。</p>\n<p>此外，测试的覆盖率等得到明显的提升效果。目前该方法对JavaScript语言的测试效果不是特别理想，需要进一步的改进。</p>\n<h1 id=\"4-总结\"><a href=\"#4-总结\" class=\"headerlink\" title=\"4 总结\"></a>4 总结</h1><p>本文实现的数据驱动的种子生成方法利用文法和样本自动抽取语义信息，并利用语义信息和语法规则进行种子生成，能够保证生成种子文件通过语法解析和语义检查，能够执行到目标程序的更深的路径，从而更有效的发现深层次的漏洞。</p>\n<p>Skyfire目前对于XML、XSL语言的应用效果很好，能够保证漏洞发现能力和覆盖率，但是对于JS这种较为复杂的语言应用不够理想。</p>\n<p><strong>5</strong> <strong>未来工作</strong></p>\n<p>作者将继续应用和扩展这种种子生成方法，以便更好地支持更多不同的语言，如javascript、SQL、C和java。除了查找安全漏洞之外，作者还希望使用生成的种子输入来查找编译器错误。</p>\n","categories":[{"name":"论文","slug":"论文","permalink":"http://yama0xff.com/categories/论文/"},{"name":"fuzzing","slug":"论文/fuzzing","permalink":"http://yama0xff.com/categories/论文/fuzzing/"},{"name":"测试输入生成","slug":"论文/fuzzing/测试输入生成","permalink":"http://yama0xff.com/categories/论文/fuzzing/测试输入生成/"}],"tags":[{"name":"fuzzing","slug":"fuzzing","permalink":"http://yama0xff.com/tags/fuzzing/"},{"name":"机器学习","slug":"机器学习","permalink":"http://yama0xff.com/tags/机器学习/"},{"name":"2017年","slug":"2017年","permalink":"http://yama0xff.com/tags/2017年/"},{"name":"测试输入生成","slug":"测试输入生成","permalink":"http://yama0xff.com/tags/测试输入生成/"}]},{"title":"Learn to Accelerate Identifying New Test Cases in Fuzzing","date":"2019-04-10T02:49:31.000Z","path":"2019/04/10/Learn-to-Accelerate-Identifying-New-Test-Cases-in-Fuzzing/","text":"Abstract模糊测试是一种有效的测试技术，可以在bug转变为漏洞之前及早发现漏洞。如果没有复杂的程序分析，它可以通过稍微改变输入并发现程序中的潜在错误来生成有趣的测试用例。然而，以前的模糊器要么无法探索更深层次的错误，要么其中一些受到严重时间复杂性的影响，因此我们不能在实际应用中依赖它们。在本文中，我们通过结合实用和轻量级的深度学习方法，专注于减少模糊测试的时间复杂度，从根本上加速识别新测试用例和发现错误的过程。为了实现预期的模糊覆盖，我们通过使用深度学习方法扩展最先进的模糊AFL来实现我们的方法，并在几个广泛使用的开源可执行程序上进行评估。在所有这些计划中，我们可以看到我们方法的效率，并产生明显更好的结果。 关键字：加速，新测试样例，Fuzzing，深度学习安全 relevant information 作者 Weiwei Gong(B), Gen Zhang, and Xu Zhou 单位 School of Computer, National University of Defense Technology, 出处 SpaCCS 2017 原文地址 https://link.springer.com/chapter/10.1007/978-3-319-72389-1_24 源码地址 发表时间 2017年 1. 简介如今，网络和软件的安全性正在引起越来越多的关注。尽管努力提高软件抵御安全漏洞的能力，但软件漏洞仍然普遍存在[1]。在过去的几十年中，安全专家和研究人员不遗余力地发现漏洞并修复漏洞。但是，如果不执行一段代码，很难找到许多类漏洞，例如函数正确性漏洞[2]。关于代码执行的问题，关于符号执行的效率与更轻量级的模糊器有很多争论[3]。符号执行工具，如KLEE，EXE和DART，能够自动生成测试，实现对各种复杂和环境密集型程序的高覆盖率[2,4,5]。模糊测试是通过使用修改或模糊输入反复测试解析器来查找输入解析代码中的安全漏洞的过程[6]。 符号执行非常有效，因为每个测试用例通常沿着某个路径执行目标程序[7]。然而，这种有效性是以花费大量时间进行程序分析和约束求解为代价的。它会触发目标程序中的大量路径，并导致路径爆炸[8]。然而，关于模糊测试，今天大多数漏洞都是由特别轻量级的模糊器暴露出来的，这些模糊器不利用任何程序分析[9]。事实证明，如果生成测试用例所花费的时间相对过长，即使是最有效的符号执行也不如模糊测试效率高[10]。基于以上原因，在本文中，我们放弃了经典的符号执行，并专注于扩展一个最先进的模糊器American FuzzingLop （AFL）[11]。 有三种主要类型的模糊测试技术在使用[12]：黑盒随机模糊测试[13]，基于白盒约束的[14]模糊测试和灰盒模糊测试[15]。黑盒模糊测试是一种软件测试技术，不需要了解目标程序的内部架构。它只考察了系统的基本方面，将软件视为黑匣子[16]。白盒模糊测试基于对目标程序内部结构的分析，在验证设计和假设方面非常有效和高效。基于对系统实现方式的了解，执行白盒模糊测试[17]。灰盒模糊测试程序对应用程序结构的了解有限。它提供了黑盒和白盒模糊测试技术的综合优势，测试人员可以设计出色的测试场景[15]。 然而，由于灰盒模糊测试对于现实世界程序及其组合的优点是有效的，因此它广泛应用于软件测试中。在greybox模糊测试的范围内，有几个着名的模糊器，如自动生成[18]，模糊[19]和语义模型[20]。虽然这些方法确实放弃了耗时的程序分析，但它们的测试精度很低：要么将非崩溃点作为崩溃，要么忽略真正的重大崩溃。此外，现有的灰盒模糊器主要用于发现靠近软件表面的表面缺陷，同时与更复杂的模型进行斗争[21,22]。除了所有这些原因，我们专注于扩展最先进的灰盒模糊器AFL，它采用进化算法来操作有效的输入生成和简单的反馈回路来评估输入的好坏[23]。在以前的工作中，AFL被证明具有高精度，能够揭示程序中更深层次的错误[3,23]。 AFL是一种蛮力模糊器，加上极其简单但是坚固的插桩引导的遗传算法。但是，使用AFL工具找到一个独特的崩溃需要数小时和数天。 AFL的主要缺点是它实际运行目标程序一次，输入决定天气状态转换或新状态：换句话说，识别新测试用例的过程。当目标程序很复杂并且包含数百万个解析或条件代码时，运行该程序一次将花费相当长的时间并且AFL的整个过程将花费数小时和数天才能找到一个独特的崩溃（我们将在Sect2 中详细讨论这一点）。为了解决这个问题，在本文中，我们将有效的深度学习方法（如神经网络）集成到AFL中，以加快识别新测试样例和发现bug的过程。在我们的所有实验中，我们看到了方法的效率，并产生了明显更好的结果。 本文的主要贡献如下：（1）采用灰盒模糊测试，效率高，易于实现; （2）我们使用深度学习方法扩展AFL，这显着加快了识别新测试样例和发现bug的过程。 2 . 背景2.1 American Fuzzy LopAmerican Fuzzy Lop（AFL）是一种蛮力模糊器，配有极其简单但坚如磐石的插桩引导遗传算法。它使用修改后的边缘覆盖形式，轻松地获取程序控制流程的细微局部变化[24]。 整个算法可以总结为： （1）将用户提供的初始测试用例加载到队列中， （2）从队列中获取下一个输入文件， （3）尝试将测试用例修剪为最小的大小改变程序的测量行为， （4）使用平衡且经过充分研究的各种传统模糊测试策略反复改变文件。 （5）如果任何生成的突变导致仪器记录的新状态转换，添加将输出变换为队列中的新条目， （6）转到2。 American Fuzzy Lop尽力不专注于任何单一的操作原理，也不是任何特定理论的概念验证。该工具可以被认为是在实践中经过测试的黑客集合，被发现具有惊人的效果，并且已经以人们当时可能想到的最简单，最强大的方式实现[9]。因此，AFL的扩展可以为我们提供一个高水平的平台。 更具体地说，当我们深入研究AFL的运行过程时，我们会发现有几个耗时的过程，我们实际上是为了改进。如上所述，AFL将初始测试用例放入队列，修剪它，进行突变，并实际运行目标程序一次，输入以确定weather ，此测试用例将导致状态转换或新状态。如果此测试用例确实导致状态转换或新状态，我们可以将其识别为新的测试用例。当目标程序很复杂并且包含数百万个解析或条件代码时，运行该程序一次将花费相当长的时间并且AFL的整个过程将花费数小时和数天才能找到唯一的崩溃。因此，我们使用深度学习技术扩展AFL，而不实际运行目标程序，以加速识别新测试用例和发现错误的整个过程，这是AFL原始版本的重大改进。 2.2 深度学习如今，机器学习和深度学习正在受到关注，吸引了成千上万的研究人员努力工作。深度和递归神经网络（分别是DNN和RNN）是强大的模型，可以在视觉和语音中的困难模式识别问题上实现高性能[25]。神经网络中的深度学习（NN）与监督学习（SL），无监督学习（UL）和强化学习（RL）相关[26]。深度学习允许由多个处理层组成的计算模型来学习具有多个抽象级别的数据表示[27]。 深度学习带来了许多全新的特征，软件测试和深度学习的结合是有意义的。在本文中，我们应用深度学习技术来提高AFL的性能，并加速新的测试用例识别和错误发现的过程，这是一个全新而有趣的研究领域（迄今为止我们所知）。 3 模型概述在本节中，我们将详细描述我们提出的模型，并将介绍我们方法的整个过程。 3.1使用深度学习方法训练AFL结果如Sect 2中所述。 当目标程序很复杂并且包含数百万个解析或条件代码时，运行该程序一次将花费相当多的时间并且AFL的整个过程将花费数小时和数天才能找到唯一的崩溃。因此，我们专注于使用深度学习技术消除或减少这些程序。 在AFL中，一个测试用例使用某些模糊技术进行变异，例如翻转某个位，添加某个整数，替换为某个数字等等。 AFL中总共有16种模糊测试技术：flip2，flip4，flip8，flip16，flip32，arith8，arith16，arith32，int8，int16，int32，ext-UO，ext-UI，ext-AO，havoc和拼接。 在通过上述技术之一改变一个测试用例之后，它将被抛入目标程序以运行一次，以查看是否存在新的程序或状态转换状态。如果有新内容，则将变异的测试用例标识为新的测试用例并保存以供以后使用。 更具体地说，一个测试用例的内容总是可以翻译成0和1的序列。同样，模糊测试技术也可以看作是4位二进制序列。例如，“0000”代表“flip2”，“1111”代表“拼接”。突变的位置和值可以用同样的方式翻译。最后，这是否是一个新的测试案例用1和0表示。表1说明了我们如何将AFL问题的原始输入转换为二进制序列。例如，我们有一个字符串测试用例“3”，模糊测试技术是“int8”，它将为测试用例添加一个8位整数。而且，8位整数是4，位置只是0位。这个变异的测试用例将导致AFL中的状态转换，因此它是一个新的测试用例。因此，我们可以将此情况转换为我们定义的二进制序列测试用例为“00 … 0011”，模糊技术为“1000”，突变位置为“00 … 000”，突变值为“00 … 00100”，新的为“1”。 在我们运行AFL一段时间后，我们从AFL过程中收集的数据将按照一定的比例分为训练数据和测试数据，这将在第4节中详细讨论。 将所有训练数据转换为二进制序列后，前一个78位可作为输入，最后一位可视为标记。这个二进制序列可以完美地融入神经网络模型，这是一种广泛使用的深度学习技术。神经网络模型将1和0的序列作为输入，并在网络中计算后简单地输出1或0。我们将使用此过程来预测是否变异测试用例是AFL中的新测试用例。更具体地说，为了训练网络，需要78 + 1比特作为训练数据，对于测试，78比特作为输入，而最后1比特是我们需要网络计算的比特。 3.2将学习成果整合到AFL中如上所述，我们将通过将学习结果整合到AFL中来消除或减少耗时的新测试案例识别AFL程序。原始版本将使用变异的测试用例运行程序，但是我们的新方法将简单地将已翻译的二进制序列抛入神经网络模型并预测此测试用例是否将导致新状态。更具体地说，当AFL拉出测试用例以对其进行突变时，此时我们手动停止在该测试用例上进一步执行。相反，我们将此测试用例放入表1中定义形式的神经网络中，并进行预测这是否是一个新的测试用例。结果将被发送回AFL以便进一步运行：如果此测试用例是新的并且将导致状态转换，它将被保存以供以后使用;如果没有，丢弃。需要声明的一件事是：虽然训练神经网络模型需要一些时间，但我们只需要为一个目标程序训练一次。在简单的神经网络中预测结果的时间复杂度仅为O（n1 n2 + n2 n3 + …）[28]。因此，当节点数量在一个较小的范围内时，例如在我们的模型中，预测过程所花费的时间比实际运行目标程序一次要少得多。因此，我们的方法可以加快识别新测试用例和查找原始版本AFL的错误的过程。 因此，我们扩展AFL的方法的整个过程如下： （1）运行AFL一段时间，以收集我们进一步训练所需的数据。 （有一点必须明确，与运行AFL数小时和数天相比，在此过程中花费的时间要少得多。） （2）训练我们在神经网络中收集的数据。 （3）使用训练结果返回AFL，对每个测试用例进行预测，最后找到程序中的潜在错误。 算法1还说明了我们的扩展AFL的过程： 4 实验在本节中，我们将介绍我们的方法的实验结果，并讨论对原始版本的AFL的改进。我们在配备64位4核Intel CPU和32 GB RAM的Ubuntu 14.04 LTS系统上进行了实验。对于我们的实验，我们选择了8个目标程序：bmp2tiff，pal2rgb，tiff2pdf，tiff2ps，gif2png，readelf，nm-new和cxxfix [29-31]，它们都在他们的领域中广泛使用，并且在之前的论文中已经过测试[3,23] 4.1神经网络的训练结果对于我们的每个目标程序，我们使用它运行AFL一段时间并收集超过500K的测试用例以供之后的训练过程使用。所有这些都以二进制顺序存储，如表1所示。我们应用的神经网络是sklearn.neural-network.MLPClassifier [32]，它是一种广泛使用的多层感知器分类器。隐藏图层大小为（5,2），解算器为“adam”。虽然有许多类型的网络算法，考虑到时间和其他因素，但本文中我们只引入一个神经网络来完成我们的实验。我们将训练数据作为神经网络的输入，并在可接受的短时间内计算结果。我们获得了培训结果，如表2所示。 第一列“目标”是我们试验的8个目标程序。下一列“总计”是我们为每个目标程序收集的测试用例数。然后我们将所有收集的测试用例划分为5倍的训练和测试数据，这意味着训练数据是总测试用例的4 /5，测试数据相应地为1/5。在将训练数据拟合到我们的神经网络之后，我们可以预测一个新的测试用例。第三列“错误”是错误预测的数量，最后一列是预测神经网络的准确性。如表2所示，我们的预测准确度在85％至90％之间。由于具有如此高的精度，我们提出的识别新测试用例的方法可以准确地预测变异的测试用例是否将导致状态转换并且在准确度上与原始版本执行几乎相同，并且在速度上表现更好。 4.2我们方法的时间性能如上所述，在用我们收集的数据训练我们的神经网络之后，是时候预测变异的测试用例是否将导致AFL过程中的状态转换。而且我们预测的高精度绝对是之后操作的坚实基础。同样，我们运行8个目标程序一段时间，与原始AFL相比唯一的区别是测试用例不必通过目标程序来决定它是否将被保存或丢弃。唯一需要做的就是将这个测试用例抛给我们已经训练过的神经网络进行预测。表3说明了与原始版本的AFL的比较。 第一列是如上所述的8个目标程序。第二列是崩溃和挂起AFL的数量，我们的方法在一定时间内找到。所以AFL和我们的方法之间的比较是关于找到给定数量的崩溃和挂起的时间。接下来的两列是时间AFL，我们的方法需要分别找到那些崩溃和挂起。 （我们所有的执行时间都与Bohme等人[3]和Rawat等人[23]的工作一致。）如表中所示，我们的方法确实引导了原始AFL的执行时间和开启时间。平均为5％。正如我们在上一节的理论分析中所详述的，我们的方法不必实际运行目标程序，它只依赖于我们的神经网络来预测测试用例是否将导致状态转换。因此，理论分析和实验表明，我们的方法在识别新测试用例和发现错误的过程中确实加速了AFL。 5 结论面对当今严峻的安全问题，在我们提出的方法中，我们首先选择对复杂的符号执行进行模糊测试。此外，在所有的模糊测试实施中，我们专注于最先进的AFL，以扩展其承诺的特性。为了加速AFL的过程并确定新的测试用例，本文通过结合实用和轻量级深度学习方法，着重降低模糊测试的时间复杂度。为了实现预期的模糊覆盖，我们通过使用深度学习方法扩展AFL并在8个广泛使用的开源目标程序上进行评估来实现我们的方法。在所有这些程序中，我们扩展AFL的方法显示出对原始版本的显着改进。但是，我们的方法并不专注于改进代码覆盖率以发现更多错误。因此，在以后的工作中，我们将尝试对这些领域进行研究。此外，虽然有许多类型的网络算法，考虑到时间和其他因素，但本文中我们只引入一个神经网络来完成我们的实验。在未来，我们将在不同情况下使用不同的神经网络来评估不同神经网络的性能","content":"<h1 id=\"Abstract\"><a href=\"#Abstract\" class=\"headerlink\" title=\"Abstract\"></a>Abstract</h1><p>模糊测试是一种有效的测试技术，可以在bug转变为漏洞之前及早发现漏洞。如果没有复杂的程序分析，它可以通过稍微改变输入并发现程序中的潜在错误来生成有趣的测试用例。然而，以前的模糊器要么无法探索更深层次的错误，要么其中一些受到严重时间复杂性的影响，因此我们不能在实际应用中依赖它们。在本文中，我们通过结合实用和轻量级的深度学习方法，专注于减少模糊测试的时间复杂度，从根本上加速识别新测试用例和发现错误的过程。为了实现预期的模糊覆盖，我们通过使用深度学习方法扩展最先进的模糊AFL来实现我们的方法，并在几个广泛使用的开源可执行程序上进行评估。在所有这些计划中，我们可以看到我们方法的效率，并产生明显更好的结果。</p>\n<p>关键字：加速，新测试样例，Fuzzing，深度学习安全</p>\n<table>\n<thead>\n<tr>\n<th>relevant information</th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><em>作者</em></td>\n<td>Weiwei Gong(B), Gen Zhang, and Xu Zhou</td>\n</tr>\n<tr>\n<td><em>单位</em></td>\n<td>School of Computer, National University of Defense Technology,</td>\n</tr>\n<tr>\n<td><em>出处</em></td>\n<td>SpaCCS 2017</td>\n</tr>\n<tr>\n<td><em>原文地址</em></td>\n<td><a href=\"https://link.springer.com/chapter/10.1007/978-3-319-72389-1_24\" target=\"_blank\" rel=\"noopener\">https://link.springer.com/chapter/10.1007/978-3-319-72389-1_24</a></td>\n</tr>\n<tr>\n<td><em>源码地址</em></td>\n<td></td>\n</tr>\n<tr>\n<td><em>发表时间</em></td>\n<td>2017年</td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"1-简介\"><a href=\"#1-简介\" class=\"headerlink\" title=\"1. 简介\"></a>1. 简介</h1><p>如今，网络和软件的安全性正在引起越来越多的关注。<br>尽管努力提高软件抵御安全漏洞的能力，但软件漏洞仍然普遍存在[1]。在过去的几十年中，安全专家和研究人员不遗余力地发现漏洞并修复漏洞。但是，如果不执行一段代码，很难找到许多类漏洞，例如函数正确性漏洞[2]。关于代码执行的问题，关于符号执行的效率与更轻量级的模糊器有很多争论[3]。符号执行工具，如KLEE，EXE和DART，能够自动生成测试，实现对各种复杂和环境密集型程序的高覆盖率[2,4,5]。模糊测试是通过使用修改或模糊输入反复测试解析器来查找输入解析代码中的安全漏洞的过程[6]。</p>\n<p>符号执行非常有效，因为每个测试用例通常沿着某个路径执行目标程序[7]。然而，这种有效性是以花费大量时间进行程序分析和约束求解为代价的。它会触发目标程序中的大量路径，并导致路径爆炸[8]。然而，关于模糊测试，今天大多数漏洞都是由特别轻量级的模糊器暴露出来的，这些模糊器不利用任何程序分析[9]。事实证明，如果生成测试用例所花费的时间相对过长，即使是最有效的符号执行也不如模糊测试效率高[10]。基于以上原因，在本文中，我们放弃了经典的符号执行，并专注于扩展一个最先进的模糊器American FuzzingLop （AFL）[11]。</p>\n<p>有三种主要类型的模糊测试技术在使用[12]：黑盒随机模糊测试[13]，基于白盒约束的[14]模糊测试和灰盒模糊测试[15]。黑盒模糊测试是一种软件测试技术，不需要了解目标程序的内部架构。它只考察了系统的基本方面，将软件视为黑匣子[16]。白盒模糊测试基于对目标程序内部结构的分析，在验证设计和假设方面非常有效和高效。基于对系统实现方式的了解，执行白盒模糊测试[17]。灰盒模糊测试程序对应用程序结构的了解有限。它提供了黑盒和白盒模糊测试技术的综合优势，测试人员可以设计出色的测试场景[15]。</p>\n<p>然而，由于灰盒模糊测试对于现实世界程序及其组合的优点是有效的，因此它广泛应用于软件测试中。在greybox模糊测试的范围内，有几个着名的模糊器，如自动生成[18]，模糊[19]和语义模型[20]。虽然这些方法确实放弃了耗时的程序分析，但它们的测试精度很低：要么将非崩溃点作为崩溃，要么忽略真正的重大崩溃。此外，现有的灰盒模糊器主要用于发现靠近软件表面的表面缺陷，同时与更复杂的模型进行斗争[21,22]。除了所有这些原因，我们专注于扩展最先进的灰盒模糊器AFL，它采用进化算法来操作有效的输入生成和简单的反馈回路来评估输入的好坏[23]。在以前的工作中，AFL被证明具有高精度，能够揭示程序中更深层次的错误[3,23]。</p>\n<p>AFL是一种蛮力模糊器，加上极其简单但是坚固的插桩引导的遗传算法。但是，使用AFL工具找到一个独特的崩溃需要数小时和数天。 AFL的主要缺点是它实际运行目标程序一次，输入决定天气状态转换或新状态：换句话说，识别新测试用例的过程。当目标程序很复杂并且包含数百万个解析或条件代码时，运行该程序一次将花费相当长的时间并且AFL的整个过程将花费数小时和数天才能找到一个独特的崩溃（我们将在Sect2 中详细讨论这一点）。为了解决这个问题，在本文中，我们将有效的深度学习方法（如神经网络）集成到AFL中，以加快识别新测试样例和发现bug的过程。在我们的所有实验中，我们看到了方法的效率，并产生了明显更好的结果。</p>\n<p>本文的主要贡献如下：（1）采用灰盒模糊测试，效率高，易于实现; （2）我们使用深度学习方法扩展AFL，这显着加快了识别新测试样例和发现bug的过程。</p>\n<h1 id=\"2-背景\"><a href=\"#2-背景\" class=\"headerlink\" title=\"2 . 背景\"></a>2 . 背景</h1><h2 id=\"2-1-American-Fuzzy-Lop\"><a href=\"#2-1-American-Fuzzy-Lop\" class=\"headerlink\" title=\"2.1 American Fuzzy Lop\"></a>2.1 American Fuzzy Lop</h2><p>American Fuzzy Lop（AFL）是一种蛮力模糊器，配有极其简单但坚如磐石的插桩引导遗传算法。它使用修改后的边缘覆盖形式，轻松地获取程序控制流程的细微局部变化[24]。</p>\n<p>整个算法可以总结为：</p>\n<ul>\n<li><p>（1）将用户提供的初始测试用例加载到队列中，</p>\n</li>\n<li><p>（2）从队列中获取下一个输入文件，</p>\n</li>\n<li><p>（3）尝试将测试用例修剪为最小的大小改变程序的测量行为，</p>\n</li>\n<li><p>（4）使用平衡且经过充分研究的各种传统模糊测试策略反复改变文件。</p>\n</li>\n<li><p>（5）如果任何生成的突变导致仪器记录的新状态转换，添加将输出变换为队列中的新条目，</p>\n</li>\n<li><p>（6）转到2。</p>\n</li>\n</ul>\n<p>American Fuzzy Lop尽力不专注于任何单一的操作原理，也不是任何特定理论的概念验证。该工具可以被认为是在实践中经过测试的黑客集合，被发现具有惊人的效果，并且已经以人们当时可能想到的最简单，最强大的方式实现[9]。因此，AFL的扩展可以为我们提供一个高水平的平台。</p>\n<p>更具体地说，当我们深入研究AFL的运行过程时，我们会发现有几个耗时的过程，我们实际上是为了改进。如上所述，AFL将初始测试用例放入队列，修剪它，进行突变，并实际运行目标程序一次，输入以确定weather ，此测试用例将导致状态转换或新状态。如果此测试用例确实导致状态转换或新状态，我们可以将其识别为新的测试用例。当目标程序很复杂并且包含数百万个解析或条件代码时，运行该程序一次将花费相当长的时间并且AFL的整个过程将花费数小时和数天才能找到唯一的崩溃。因此，我们使用深度学习技术扩展AFL，而不实际运行目标程序，以加速识别新测试用例和发现错误的整个过程，这是AFL原始版本的重大改进。</p>\n<h2 id=\"2-2-深度学习\"><a href=\"#2-2-深度学习\" class=\"headerlink\" title=\"2.2 深度学习\"></a>2.2 深度学习</h2><p>如今，机器学习和深度学习正在受到关注，吸引了成千上万的研究人员努力工作。深度和递归神经网络（分别是DNN和RNN）是强大的模型，可以在视觉和语音中的困难模式识别问题上实现高性能[25]。神经网络中的深度学习（NN）与监督学习（SL），无监督学习（UL）和强化学习（RL）相关[26]。深度学习允许由多个处理层组成的计算模型来学习具有多个抽象级别的数据表示[27]。</p>\n<p>深度学习带来了许多全新的特征，软件测试和深度学习的结合是有意义的。在本文中，我们应用深度学习技术来提高AFL的性能，并加速新的测试用例识别和错误发现的过程，这是一个全新而有趣的研究领域（迄今为止我们所知）。</p>\n<h1 id=\"3-模型概述\"><a href=\"#3-模型概述\" class=\"headerlink\" title=\"3 模型概述\"></a>3 模型概述</h1><p>在本节中，我们将详细描述我们提出的模型，并将介绍我们方法的整个过程。</p>\n<h2 id=\"3-1使用深度学习方法训练AFL结果\"><a href=\"#3-1使用深度学习方法训练AFL结果\" class=\"headerlink\" title=\"3.1使用深度学习方法训练AFL结果\"></a>3.1使用深度学习方法训练AFL结果</h2><p>如Sect 2中所述。 当目标程序很复杂并且包含数百万个解析或条件代码时，运行该程序一次将花费相当多的时间并且AFL的整个过程将花费数小时和数天才能找到唯一的崩溃。因此，我们专注于使用深度学习技术消除或减少这些程序。</p>\n<p>在AFL中，一个测试用例使用某些模糊技术进行变异，例如翻转某个位，添加某个整数，替换为某个数字等等。 AFL中总共有16种模糊测试技术：flip2，flip4，flip8，flip16，flip32，arith8，arith16，arith32，int8，int16，int32，ext-UO，ext-UI，ext-AO，havoc和拼接。 在通过上述技术之一改变一个测试用例之后，它将被抛入目标程序以运行一次，以查看是否存在新的程序或状态转换状态。如果有新内容，则将变异的测试用例标识为新的测试用例并保存以供以后使用。</p>\n<p>更具体地说，一个测试用例的内容总是可以翻译成0和1的序列。同样，模糊测试技术也可以看作是4位二进制序列。例如，“0000”代表“flip2”，“1111”代表“拼接”。突变的位置和值可以用同样的方式翻译。最后，这是否是一个新的测试案例用1和0表示。表1说明了我们如何将AFL问题的原始输入转换为二进制序列。例如，我们有一个字符串测试用例“3”，模糊测试技术是“int8”，它将为测试用例添加一个8位整数。而且，8位整数是4，位置只是0位。这个变异的测试用例将导致AFL中的状态转换，因此它是一个新的测试用例。因此，我们可以将此情况转换为我们定义的二进制序列测试用例为“00 … 0011”，模糊技术为“1000”，突变位置为“00 … 000”，突变值为“00 … 00100”，新的为“1”。</p>\n<p><img src=\"/2019/04/10/Learn-to-Accelerate-Identifying-New-Test-Cases-in-Fuzzing/1.jpg\" alt=\"\"></p>\n<p>在我们运行AFL一段时间后，我们从AFL过程中收集的数据将按照一定的比例分为训练数据和测试数据，这将在第4节中详细讨论。 将所有训练数据转换为二进制序列后，前一个78位可作为输入，最后一位可视为标记。这个二进制序列可以完美地融入神经网络模型，这是一种广泛使用的深度学习技术。神经网络模型将1和0的序列作为输入，并在网络中计算后简单地输出1或0。我们将使用此过程来预测是否变异测试用例是AFL中的新测试用例。更具体地说，为了训练网络，需要78 + 1比特作为训练数据，对于测试，78比特作为输入，而最后1比特是我们需要网络计算的比特。</p>\n<h2 id=\"3-2将学习成果整合到AFL中\"><a href=\"#3-2将学习成果整合到AFL中\" class=\"headerlink\" title=\"3.2将学习成果整合到AFL中\"></a>3.2将学习成果整合到AFL中</h2><p>如上所述，我们将通过将学习结果整合到AFL中来消除或减少耗时的新测试案例识别AFL程序。<br>原始版本将使用变异的测试用例运行程序，但是我们的新方法将简单地将已翻译的二进制序列抛入神经网络模型并预测此测试用例是否将导致新状态。更具体地说，当AFL拉出测试用例以对其进行突变时，此时我们手动停止在该测试用例上进一步执行。相反，我们将此测试用例放入表1中定义形式的神经网络中，并进行预测这是否是一个新的测试用例。结果将被发送回AFL以便进一步运行：如果此测试用例是新的并且将导致状态转换，它将被保存以供以后使用;如果没有，丢弃。需要声明的一件事是：虽然训练神经网络模型需要一些时间，但我们只需要为一个目标程序训练一次。在简单的神经网络中预测结果的时间复杂度仅为O（n1 <em> n2 + n2 </em> n3 + …）[28]。因此，当节点数量在一个较小的范围内时，例如在我们的模型中，预测过程所花费的时间比实际运行目标程序一次要少得多。因此，我们的方法可以加快识别新测试用例和查找原始版本AFL的错误的过程。</p>\n<p>因此，我们扩展AFL的方法的整个过程如下：</p>\n<ul>\n<li><p>（1）运行AFL一段时间，以收集我们进一步训练所需的数据。 （有一点必须明确，与运行AFL数小时和数天相比，在此过程中花费的时间要少得多。）</p>\n</li>\n<li><p>（2）训练我们在神经网络中收集的数据。</p>\n</li>\n<li><p>（3）使用训练结果返回AFL，对每个测试用例进行预测，最后找到程序中的潜在错误。</p>\n</li>\n<li>算法1还说明了我们的扩展AFL的过程：</li>\n</ul>\n<p><img src=\"/2019/04/10/Learn-to-Accelerate-Identifying-New-Test-Cases-in-Fuzzing/2.jpg\" alt=\"\"></p>\n<h1 id=\"4-实验\"><a href=\"#4-实验\" class=\"headerlink\" title=\"4 实验\"></a>4 实验</h1><p>在本节中，我们将介绍我们的方法的实验结果，并讨论对原始版本的AFL的改进。我们在配备64位4核Intel CPU和32 GB RAM的Ubuntu 14.04 LTS系统上进行了实验。对于我们的实验，我们选择了8个目标程序：bmp2tiff，pal2rgb，tiff2pdf，tiff2ps，gif2png，readelf，nm-new和cxxfix [29-31]，它们都在他们的领域中广泛使用，并且在之前的论文中已经过测试[3,23]</p>\n<h2 id=\"4-1神经网络的训练结果\"><a href=\"#4-1神经网络的训练结果\" class=\"headerlink\" title=\"4.1神经网络的训练结果\"></a>4.1神经网络的训练结果</h2><p>对于我们的每个目标程序，我们使用它运行AFL一段时间并收集超过500K的测试用例以供之后的训练过程使用。所有这些都以二进制顺序存储，如表1所示。我们应用的神经网络是sklearn.neural-network.MLPClassifier [32]，它是一种广泛使用的多层感知器分类器。隐藏图层大小为（5,2），解算器为“adam”。虽然有许多类型的网络算法，考虑到时间和其他因素，但本文中我们只引入一个神经网络来完成我们的实验。我们将训练数据作为神经网络的输入，并在可接受的短时间内计算结果。我们获得了培训结果，如表2所示。</p>\n<p>第一列“目标”是我们试验的8个目标程序。下一列“总计”是我们为每个目标程序收集的测试用例数。然后我们将所有收集的测试用例划分为5倍的训练和测试数据，这意味着训练数据是总测试用例的4 /5，测试数据相应地为1/5。在将训练数据拟合到我们的神经网络之后，我们可以预测一个新的测试用例。第三列“错误”是错误预测的数量，最后一列是预测神经网络的准确性。如表2所示，我们的预测准确度在85％至90％之间。由于具有如此高的精度，我们提出的识别新测试用例的方法可以准确地预测变异的测试用例是否将导致状态转换并且在准确度上与原始版本执行几乎相同，并且在速度上表现更好。</p>\n<p><img src=\"/2019/04/10/Learn-to-Accelerate-Identifying-New-Test-Cases-in-Fuzzing/3.jpg\" alt=\"\"></p>\n<h2 id=\"4-2我们方法的时间性能\"><a href=\"#4-2我们方法的时间性能\" class=\"headerlink\" title=\"4.2我们方法的时间性能\"></a>4.2我们方法的时间性能</h2><p>如上所述，在用我们收集的数据训练我们的神经网络之后，是时候预测变异的测试用例是否将导致AFL过程中的状态转换。而且我们预测的高精度绝对是之后操作的坚实基础。同样，我们运行8个目标程序一段时间，与原始AFL相比唯一的区别是测试用例不必通过目标程序来决定它是否将被保存或丢弃。唯一需要做的就是将这个测试用例抛给我们已经训练过的神经网络进行预测。表3说明了与原始版本的AFL的比较。</p>\n<p>第一列是如上所述的8个目标程序。第二列是崩溃和挂起AFL的数量，我们的方法在一定时间内找到。所以AFL和我们的方法之间的比较是关于找到给定数量的崩溃和挂起的时间。接下来的两列是时间AFL，我们的方法需要分别找到那些崩溃和挂起。 （我们所有的执行时间都与Bohme等人[3]和Rawat等人[23]的工作一致。）如表中所示，我们的方法确实引导了原始AFL的执行时间和开启时间。平均为5％。正如我们在上一节的理论分析中所详述的，我们的方法不必实际运行目标程序，它只依赖于我们的神经网络来预测测试用例是否将导致状态转换。因此，理论分析和实验表明，我们的方法在识别新测试用例和发现错误的过程中确实加速了AFL。</p>\n<p><img src=\"/2019/04/10/Learn-to-Accelerate-Identifying-New-Test-Cases-in-Fuzzing/4.jpg\" alt=\"\"></p>\n<h1 id=\"5-结论\"><a href=\"#5-结论\" class=\"headerlink\" title=\"5 结论\"></a>5 结论</h1><p>面对当今严峻的安全问题，在我们提出的方法中，我们首先选择对复杂的符号执行进行模糊测试。此外，在所有的模糊测试实施中，我们专注于最先进的AFL，以扩展其承诺的特性。为了加速AFL的过程并确定新的测试用例，本文通过结合实用和轻量级深度学习方法，着重降低模糊测试的时间复杂度。为了实现预期的模糊覆盖，我们通过使用深度学习方法扩展AFL并在8个广泛使用的开源目标程序上进行评估来实现我们的方法。在所有这些程序中，我们扩展AFL的方法显示出对原始版本的显着改进。但是，我们的方法并不专注于改进代码覆盖率以发现更多错误。因此，在以后的工作中，我们将尝试对这些领域进行研究。此外，虽然有许多类型的网络算法，考虑到时间和其他因素，但本文中我们只引入一个神经网络来完成我们的实验。在未来，我们将在不同情况下使用不同的神经网络来评估不同神经网络的性能</p>\n","categories":[{"name":"论文","slug":"论文","permalink":"http://yama0xff.com/categories/论文/"},{"name":"fuzzing","slug":"论文/fuzzing","permalink":"http://yama0xff.com/categories/论文/fuzzing/"},{"name":"测试输入筛选","slug":"论文/fuzzing/测试输入筛选","permalink":"http://yama0xff.com/categories/论文/fuzzing/测试输入筛选/"}],"tags":[{"name":"fuzzing","slug":"fuzzing","permalink":"http://yama0xff.com/tags/fuzzing/"},{"name":"2017年","slug":"2017年","permalink":"http://yama0xff.com/tags/2017年/"},{"name":"深度学习","slug":"深度学习","permalink":"http://yama0xff.com/tags/深度学习/"}]},{"title":"ExploitMeter: Combining Fuzzing with Machine Learning for Automated Evaluation of Software Exploitability","date":"2019-04-08T12:38:23.000Z","path":"2019/04/08/ExploitMeter-Combining-Fuzzing-with-Machine-Learning-for-Automated-Evaluation-of-Software-Exploitability/","text":"Abstract可利用的软件漏洞对其信息安全和隐私构成严重威胁。尽管已经投入大量精力来提高软件安全性，但量化软件可利用性的研究仍处于起步阶段。在这项工作中，我们提出了ExploitMeter，这是一个基于模糊的软件可利用性量化框架，可以促进软件保障和网络保险的决策。 ExploitMeter设计为动态，高效和严谨，它以贝叶斯方式集成了基于机器学习的预测和动态模糊测试。使用100个Linux应用程序，我们进行了大量实验，以评估ExploitMeter在动态环境中的性能。 relevant information 作者 Guanhua Yan Junchen Lu Zhan Shu Yunus Kucuk 单位 Department of Computer ScienceBinghamton University, State University of New York 出处 2017 IEEE Symposium on Privacy-Aware Computing 原文地址 源码地址 http：//www.cs.binghamton.edu/~ghyan/code/ExploitMeter/ 发表时间 2017年 1. 介绍软件安全在确保网络空间可信度方面发挥着关键作用。由于零日软件攻击的地下市场蓬勃发展，大部分网络犯罪都是通过利用易受攻击的软件系统来实现的。不幸的是，在可预见的未来，软件漏洞不太可能被消除，因为现代软件系统变得如此复杂，以至于只有有限认知能力的软件程序员几乎不可能测试他们所有的角落情况，更不用说那些不安全的语言了。 C仍在广泛使用。 在这项工作中，我们探讨了以下基本问题：鉴于软件系统中可能存在许多软件漏洞，我们能否量化其可利用性？软件可利用性的量化可以在两个重要的情况下找到它的应用：软件保障和网络保险。在国家信息保障术语表[30]中，软件保证被定义为“软件没有漏洞的信任程度，无论是故意设计到软件中还是在其生命周期的任何时间意外插入，以及软件在预期中运行“可量化的软件可利用性提供了对可利用软件漏洞不存在的这种信心的定量测量，从而促进了安全关键软件程序部署中的决策。另一方面，新兴的网络保险市场需要采用严格的方法，保险公司可以使用这些方法定量评估使用潜在易受攻击的软件系统与被保险人相关的风险。 正如[33]所述，由于运营网络安全的对抗性和动态性，很难实现可量化的安全措施。事实上，随着新开发技术的发展和部署的新的漏洞缓解功能，软件开发的格局不断变化。针对2006年至2012年期间针对Microsoft Windows平台的软件漏洞的调查显示，堆栈损坏漏洞利用率的百分比已经下降，但UAF漏洞的漏洞率却在上升[26]。 虽然已经做了许多致力于提高软件安全性的努力，但仍然缺乏一个统一的框架来量化软件可利用性在动态操作环境中，正如软件保障和网络保险所需要的那样。在行业中，CVSS（通用漏洞评分系统）[1]被广泛用于估计已知软件漏洞的严重性，包括基于其攻击向量，攻击复杂性，所需权限和用户交互计算的可利用性度量。除了CVSS之外，还提出了一些其他方法来评估软件安全性，例如攻击面度量[22]，漏洞密度度量[7]，[9]，具有危险系统调用的入口点的可达性[39]，以及基于机器学习的预测[12]，[19]。但是，这些方法都不允许我们量化动态执行环境中的软件可利用性。 在此背景下，我们在这项工作中提出了一个名为ExploitMeter的新框架，旨在定量和动态地评估软件可利用性，以促进软件保障和网络保险的决策。在ExploitMeter框架的核心是模仿人工评估人员的认知过程贝叶斯推理引擎：评价者首先基于静态特征采用机器学习今天初步的预测，然后与来自不同模糊器的多个动态模糊测试的新观察结果来更新自己对软件可利用性的判定。此外，评估者使用这些不同的模糊器的经验被用于更新他们的感知性能 - 也以贝叶斯方式 - 并且这些性能测量形成评估者量化软件可利用性的基础。因此，ExploitMeter的推理引擎可以被描述为动态非线性系统，其输入来自基于机器学习的预测和动态模糊测试。 在构建ExploitMeter框架的最后，我们在这项工作中的贡献总结如下： 我们从软件程序的静态分析中提取各种特征，我们从中训练分类模型以预测软件程序可能具有的漏洞类型（例如，堆栈溢出和use-after-free）。评估者使用这些分类器的分类性能来得出她对预测结果的初始置信水平。 对于每个受测试的软件，我们使用各种模糊器来生成崩溃，从中我们发现导致崩溃的软件漏洞类型。对于发现的每种类型的软件漏洞，我们使用贝叶斯方法来计算评估者对软件漏洞的后验信念。 基于概率论，我们将软件程序包含的不同类型软件漏洞的可利用性分数结合起来，以生成最终的可利用性分数。 我们在以下网址提供ExploitMeter的源代码：http：//www.cs.binghamton.edu/~ghyan/code/ExploitMeter/。为了证明其实用性，我们进行了大量实验，其中使用了两个不同的软件模糊器来模拟虚拟机中的100个标准Linux实用程序。我们在不同配置下使用ExploitMeter动态量化这些程序的可利用性，从而深入了解ExploitMeter如何促进软件保障和网络保险实践中的决策制定。 在本文的其余部分安排如下。第二节总结了相关工作。第三节提供了ExploitMeter的实际背景。 ExploitMeter采用的主要方法在第IV节中讨论。在第五节中，我们介绍了实验结果，并在第六节中得出结论性意见 II 相关工作许多努力致力于提高软件漏洞发现的效率。这些技术主要分为两类，静态分析（例如，[16]，[21]，[20]，[35]）和动态模糊测试（例如，[32]，[34]，[17]）。 ExploitMeter的当前实现依赖于动态模糊测试来发现软件漏洞，因为模糊测试工具可以轻松实现自动化，程序的崩溃状态允许我们推断导致崩溃的漏洞类型。但是，在ExploitMeter框架中，很容易合并其他软件漏洞发现工具，这仍然是我们未来的工作。 软件安全研究人员也一直在开发模型来预测软件漏洞。该领域的工作通常利用国家漏洞数据库中的大量软件漏洞数据，并通过改进历史漏洞数据来训练预测模型（例如[18]，[9]，[28]，[8]，[ 8]，[27]，[40]）。与我们的工作更相关的是那些应用机器学习来推断软件漏洞的可利用性的工作。例如，Bozorgi等人 [12]训练线性支持向量机，使用从两个公共漏洞数据源中的描述中提取的基于文本的特征，对易受攻击的软件程序是否可利用进行分类。 [12]中提出的预测模型不能用于预测日常漏洞的可利用性。在[19]中Grieco等人从静态分析和动态执行软件程序中提取C标准库调用序列，以分类它们是否容易受到内存损坏。虽然这项工作直接适用于可执行程序，但它并不像ExploitMeter那样提供可量化的软件可利用性度量。所有这些先前工作的共同点是，他们从历史数据中训练模型以预测未来威胁的特征。 ExploitMeter与这些作品不同，因为预测模型仅用于推导先验信念，但这些信念应该用新的测试结果动态更新。这有效地解决了在软件开发技术和威胁缓解功能之间存在军备竞争的动态环境中可预测性的下降。 ExploitMeter还涉及一些关于自动生成软件漏洞的最新工作，例如AEG [10]和Mayhem [14]尽管ExploitMeter的设计受到了这些工作的启发，但是没有必要针对易受攻击的程序找到可操作的漏洞来评估其可利用性。 ExploitMeter采用的方法类似于我们之前的工作[38]，它采用贝叶斯方法来量化软件可利用性。但是，这项工作主要是理论性的，没有具体说明如何推导出先前的信念以及应该使用哪些工具来测试软件漏洞。相比之下，ExploitMeter提供了量化软件可利用性的实用框架 III 背景可量化的软件可利用性有助于软件保障和网络保险的决策。为了解释这一动机，我们为这两个应用程序中的每一个提供了一个示例场景： 软件保障：考虑一个安全关键环境，其中运行的每个软件应该不受利用，即使软件可能包含已知或未知的漏洞。当要部署新软件时，系统管理员需要确保在其执行环境中可以利用它的可能性应低于某个阈值。可量化的软件可利用性允许系统管理员在决定是否运行软件程序时建立置信度。 网络保险：IT（信息技术）经理希望确保企业免受恶意网络威胁。为了计算溢价，网络保险公司需要评估被保险企业网络中安装的软件的安全性。软件可利用性的定量测量允许保险公司量化与在被保险人网络内使用软件相关的风险。一旦投保，可以通过可信计算模块的远程证明来确保软件的完整性。这有助于保险公司仅为已经评估过的软件制定保险单。 两个示例的共同点是必须量化在特定执行环境中运行的软件程序的可利用性。我们的目标是建立一个名为ExploitMeter的实用框架，系统管理员可以使用它来决定是否应该部署特定软件（软件保证），或者由保险公司用来评估软件程序的开发风险然后相应地计算保费（网络保险）。 利用软件的先决条件是它包含一些可以从其攻击面利用的软件漏洞。经典类型的软件漏洞包括堆栈缓冲区溢出，释放后使用引用，堆损坏，整数溢出，除零，解除引用空指针以及类型混淆。有许多工具可用于自动发现软件漏洞。由于软件的源代码可能无法在操作环境中使用，因此我们排除了依赖静态代码分析来查找软件漏洞的工具。并非所有软件漏洞都可以在相同程度上被利用。例如，虽然除零可能会有效地崩溃程序并因此启用拒绝服务攻击，但它不容易被利用用于更有趣的目的，例如权限提升。 IV 方法如图1所示，ExploitMeter是一个评估动态环境中软件可利用性的框架。在ExploitMeter中，计划按顺序测试软件S = {s0，s1，…，si，…}的列表。对于每个软件s∈S，假设其可利用性由假想的人类评估者测量，作为她对软件可被利用的可能性的主观信念。但是，软件可以通过各种低级软件漏洞利用，例如缓冲区溢出和整数溢出。此外，攻击者可以利用每种类型的这些安全漏洞的可能性可能会有所不同。因此，我们的模型使评估者能够推断每个软件漏洞类型的软件可利用性。设V = {v0，v1，…，v | V | -1}表示考虑的软件漏洞类型集。因此，软件通过漏洞类型v∈V的可利用性是评估者对通过漏洞类型v利用软件的可能性的主观信念。因此，我们的关键利益是评估零假设H0（s，v）的概率。这表明软件不易受类型v的攻击。我们让H1（s，v）表示相反的假设，即假设软件易受类型v攻击。 因此，由于类型v导致的软件的可利用性可以被表征为评估者的主观概率P（H0（s，v））。在贝叶斯推理[11]中，假设评估者保留P（H0（s，v））的先验概率，并且在看到证据E后，她的后验信念根据贝叶斯规则更新：$$P{H0(s, v)|E} = \\frac {P{E|H0(s, v)}* P{H0(s, v)}}{P{E}}$$为了应用贝叶斯推理[11]，我们需要解决如何推导先验概率P {H0（s，v）}以及如何获得证据E以支持软件可利用性的后验更新。 A.从机器学习模型中获得初始概率ExploitMeter允许评估人员使用预测分类模型快速评估软件可利用性。对于每种类型的软漏洞，对基于软件程序的静态分析提取的特征训练分类模型。我们使用f（s）来表示从软件程序中提取的一组特征。给定特征向量f∈F，其中F是特征空间，给出的漏洞类型v的分类模型cv，由cv：F→{positive，negative}从历史数据中训练以预测具有特征向量 f 的软件程序 是否包含v类型的漏洞。 受过训练的分类模型可能会对软件程序包含的漏洞类型做出错误的预测。错误预测的来源可以是从软件程序中提取的弱特征，不准确的预测模型（例如，具有不良泛化能力的训练数据过度拟合的模型），或者本质上缺乏可预测性的非静止数据。因此，当使用机器学习模型来预测软件可利用性时，有必要考虑它们的预测性能。 ExploitMeter使用四重（TP，FP，TN，F N）监控每个分类器的性能，其中包括过去预测中的真阳性，假阳性，真阴性和假阴性的数量。令p（cv）表示与分类器cv相关联的性能四元组，并且其第i个元素由p（cv）[i]给出。 为了应用贝叶斯推理，需要假设P {H0（s，v）}的先验概率。基于所评估的软件程序没有发现类型v的漏洞的分数来建立P {H0（s，v）}的先验概率的合理模型。因此，计数器n用于保持评估的软件程序的数量，并且对于每种漏洞类型，nv用于保持已发现包含类型v的漏洞的软件程序的数量。但是，我们可能不想要直接使用nv / n作为先验概率，因为如果nv = 0，则对P {H0（s，v）}的先验概率为0，这决定了方程（1）中后验概率的计算。 忽视了E的存在。为了解决这个问题，ExploitMeter用一些正数初始化nv和n。例如，n = 2且nv = 1最初假设P {H0（s，v）}的初始先验信念是0.5，并且计数器在评估的每个软件程序时更新。 当评估新的软件程序时，分类器cv的预测结果证明了E的存在。根据等式（1），如果cv预测s为正，我们有：$$P{H0(s, v)| classifier cv predicts s to be positive }=\\frac {\\frac {nv}{n}·\\frac{p(cv)[2]}{p(cv)[2]+p(cv)[3]}}{\\frac {nv}{n}·\\frac{p(cv)[2]}{p(cv)[2]+p(cv)[3]} + \\frac{n−nv}{n} · \\frac{p(cv)[1]}{p(cv)[1]+p(cv)[4]}}$$如果cv预测s为负数，我们有：$$P{H0(s, v)| classifier cv predicts s to be positive }=\\frac {\\frac {nv}{n}·\\frac{p(cv)[3]}{p(cv)[2]+p(cv)[3]}}{\\frac {nv}{n}·\\frac{p(cv)[3]}{p(cv)[2]+p(cv)[3]} + \\frac{n−nv}{n} · \\frac{p(cv)[4]}{p(cv)[1]+p(cv)[4]}}$$ B.基于模糊测试的软件可利用性后验更新从软件程序提取的特征数据可能具有低稳定性，因此对于预测其可利用性的能力有限。例如，用于开发这些软件的编程语言的分布可能会随着时间的推移而发生变化，即使对于相同的编程语言，它也可能随着用新的功能替换过时功能而发展。此外，由于网络安全的对抗性质，可以在具有悠久历史的软件中找到新的安全漏洞。例如，自1989年9月以来，2014年发现的ShellShock漏洞突然使所有版本的Bash变得脆弱[36]。对于关键的网络安全操作，我们因此不应仅依赖从历史数据训练的模型来预测软件可利用性。 ExploitMeter允许评估者通过向她提供的新证据更新她对软件可利用性的信念。为了获得新的证据，使用一组模糊器Z = {z0，z1，…，z | Z | -1}来查找被测软件中的漏洞。每个模糊器的工作原理是将格式错误的数据注入程序以创建崩溃。进一步分析这些崩溃以推断潜在的安全漏洞。模糊测试的输出要么软件成功终止，要么导致崩溃。对于每次崩溃，我们都可以推断导致崩溃的软件漏洞类型。在第IV-C节中，我们将详细说明如何在ExploitMeter框架中完成此操作。 在使用Z中的模糊器对软件进行模糊测试后，模糊测试结果将作为评估者更新其后验概率的证据。如果模糊器发现软件的漏洞类型为v，则将Esv定义为1，否则为0。然后我们有两个用fuzzer模糊软件的Esv案例： 案例A：Esv = 1.在这种情况下，模糊器在软件中成功找到v类型的漏洞。有了这样一个确凿的证据，评估者对软件免疫v的后验概率应该是0，而不管她从回归模型得出的初始概率。这可以通过贝叶斯规则得到证实：$$P(H0(s, v) | Esv = 1)=\\frac{P(Esv = 1 | H0(s, v)) · P(H0(s, v))}{P(Esv = 1)} = 0$$必须保持最终的相等性，就好像软件不易受类型v攻击一样，任何模糊器都不可能找到导致它因类型v而崩溃的软件输入。 案例B：Esv = 0.在这种情况下，模糊器在软件s中找不到类型v的漏洞。但是，软件仍然可能容易受到v攻击，因为模糊器可能由于其模糊测试策略而无法检测到漏洞。使用贝叶斯规则，我们有以下内容：$$P(H0(s, v) | Esv = 0)=\\frac{P(Esv = 0 | H0(s, v)) · P(H0(s, v))}{P(Esv = 0)}$$一些模糊测试者比其他模糊测试人员更能检测到特定类型的漏洞。例如，[25]中开发的SmartFuzz方法专注于检测整数错误。让模糊器z对漏洞类型v的检测率为q（v，z）。我们因此：$$P(Es,v = 0 | H1(s, v)) = 1 − q(v, z)$$如果假设H0（s，v）为真（即软件不易受类型v影响），则情况B必须保持。因此，我们有：$$P(Es,v = 0 | H0(s, v)) = 1$$结合方程（6）和（7），我们有：$$P(Es,v = 0) = \\sum_{i=0}^1 P(H_i(s,v))·P(Esv=0|H_i(s,v))= P(H0(s,v))+(1−P(H0(s,v)))·(1−q(v,z)$$最后，我们有以下内容：$$P(H0(s, v) | Es,v = 0) =\\frac{P(H0(s,v))}{P(H0(s,v))+(1−P(H0(s,v)))·(1−q(v,z)) }$$软件程序的可利用性取决于它包含的漏洞类型以及每种漏洞类型转化为软件漏洞的可能性。为了对这种依赖关系进行建模，我们假设评估者对于每个漏洞类型v∈V，都相信其被利用的可能性，用r（v）表示。假设V中的漏洞类型是独占且独立的，在看到模糊器的模糊测试结果后，软件的整体可利用性由下式给出：$$U(s) = 1−\\prod_{v∈V}[(1−r(v))·(1−P(H0(s,v)|Es,v))+P(H0(s,v)|Esv)]= 1 − \\prod_{v∈V}[1 − r(v) + r(v) · P(H0(s, v) | Esv)]$$其中P（H0（s，v）| Esv）是在看到证据Esv后，评估者对假设H0（s，v）的后验概率。方程式（9）RHS（右手侧）的第二个术语， 给出了软件不能通过V中任何类型的漏洞被利用的概率。 ExploitMeter在模糊器模糊后重新计算软件程序的可利用性分数。基于该可利用性得分，如果可利用性得分高于某个置信度阈值，则可以做出决定。否则，评估者需要更多证据来确定软件程序是否确实可以利用。 C.崩溃造成的漏洞干扰当程序崩溃或以其他方式异常终止时，现代OS通常允许将崩溃进程的存储器映像和程序寄存器转储到本地文件系统上。这些核心转储文件可以进一步加载到调试器中，例如GNU调试器或Microsoft WinDbg，以在崩溃发生时恢复进程的内部状态。这些核心转储文件可用于推断导致崩溃的漏洞类型。例如，可以检查崩溃进程的堆栈跟踪缓冲区溢出的可能性，这是一种典型的软件漏洞。Microsoft安全工程中心开发了一个名为！exploitable [4]的WinDbg扩展，根据其原因对崩溃进行分类，例如使用先前释放的堆缓冲区和堆栈缓冲区溢出。可以将每个原因视为漏洞类型，并且不同漏洞类型的可利用性不同。在！exploitable 的情况下，所有类型的软件漏洞都分为四类，具体取决于它们被开发的可能性，可利用，可能可利用 ，可泵不可利用和未知性。 Apple开发了一个名为CrashWrangler的类似工具来检查Mac OS平台上的软件崩溃[3]，并开发了CERT分类工具来评估Linux平台上的软件可利用性[5]。 ExploitMeter依靠这些工具来推断导致程序崩溃的软件漏洞类型。表1中给出了可由CERT分类工具推断出的漏洞类型列表。尽管这些工具是ExploitMeter框架的一个组成部分，但我们知道它们在评估软件崩溃时的安全性方面并不完美。 [31]这些工具背后的一个基本假设是攻击者可以完全控制导致崩溃的错误指令的输入操作数。如果无法从程序的攻击面更改这些输入操作，则这些工具往往会高估发现软件漏洞的风险。此外，这些工具还应用基于规则的启发式和轻量级污点分析，这些技术中固有的局限性可能导致错误的漏洞分类。 D.训练分类模型ExploitMeter目前旨在评估ELF（可执行和可链接格式）可执行文件的可利用性。它从ELF可执行文件中提取特征以训练分类模型，该模型预测它们是否包含特定类型的漏洞。可以从ELF可执行文件的静态分析中提取各种类型的功能。ExploitMeter目前使用以下类型的功能： Hexdump功能。我们使用hexdump实用程序从二进制程序中获取字节序列，然后计算软件程序中出现的每个n-gram字节序列的频率。有256个1-gram特征（即0x00到0xFF）和65536个2-gram特征（即0x0000到0xFFFF）。 Objdump功能。我们使用objdump来反汇编二进制可执行程序，并且对于每个指令，我们将其表示为操作码及其操作数类型的组合。例如，指令mov edi，0x600dc0被抽象为mov-register-immediate，而指令mov rax，QWORD PTR [rip + 0x981375]被抽象为mov-register-memory。使用操作数类型扩展操作码的直觉是ExploitMeter目前专注于评估与内存相关的软件漏洞，因此希望明确识别指令是否访问内存有助于提高分类性能。然后，我们计算出软件程序代码部分中出现的每个n-gram序列的频率。由于软件开发针对合法软件，我们希望大多数合法程序不会使用恶意软件中的大量混淆来混淆反汇编过程。 库功能。我们使用ldd实用程序来获取可执行程序所需的共享库列表。值得注意的是，严格来说，ldd实用程序不是静态分析工具，因为它使用动态加载程序来决定运行时需要哪些共享库，但它比静态分析工具（如objdump）提供了更准确的共享库覆盖。对于某些ELF可执行文件，例如mediainfo和pdftk，由于ld.so检测到不一致问题，在它们上运行ldd会崩溃。对于他们，我们使用objdump -p来查找所需的共享库。 搬迁功能。我们使用readelf实用程序（使用-rW选项）来发现重定位部分的内容，然后使用c ++ filt实用程序对重定位的符号进行解码。每个已解密的符号都被视为值为1的要素，如果在重定位部分中找不到，则为0。 在动态环境中，分类模型定期重新训练。我们按时间划分为几个时期，T = {T0，T1，…}。获得这些时期的选择可以是灵活的。例如，我们可以将时间划分为相等的长度（例如，三个月），或者让在不同时期测试的软件的数量大致相同，或者将模糊测试活动视为时期。让时期Ti中使用的分类模型cv被区分为c（vi），其中i = 0,1，……对于第一个时期T0，由于没有历史数据来训练每个漏洞类型的分类模型，我们可以使用领域知识来指定先前的概率。 在每个时期的开始，使用所有历史数据对每个漏洞类型重新训练分类模型。通过略微滥用符号S，我们定义Si，其中i = 0,1，…作为已在时期Ti中测试的软件集。当在i ≥ 1的时期Ti的开始建立漏洞类型v的分类模型时，我们如下导出训练数据集。对于每个软件s∈{Sk} 0≤k≤i-1，我们让Ys（v）∈{positive，negative}表示软件s是否被任何模糊器检测到包含v类型的漏洞;我们将元组（f（s），Ys（v））添加到训练数据集中，其中我们记得f（s）是软件s的特征向量。用于时期Ti的分类模型c（vi）通过从f（s）预测所有s∈{Sk}0≤k≤i-1的Ys（v）来训练。 ExploitMeter中分类模型的选择是灵活的，我们将在实验中根据经验评估各种分类模型的性能 E.贝叶斯参数估计回想一下，参数q（v，z）表示模糊器z对漏洞类型v的检测率。为了估计q（v，z），我们维护一个性能计数表，用C表示，大小为| V | x | Z |。表C的每个条目C [v，z]是保持模糊器z成功检测到具有漏洞类型v的软件的次数的计数器。除了表C之外，长度为| V |的向量D也保留，其中每个i在[0，| V | - 1]，D [v]给出已用漏洞类型v识别的软件数量。 表C和向量D更新如下。限定：$$V_s^{‘} = {v ∈ V : Esv = 1}.$$ 因此，设置Vs’包含至少一个fuzzer在软件中找到的所有漏洞类型。对于每个v∈Vs’,我们将D [v]增加1，因为在软件中已发现v类型的新漏洞。此外，对于每个v∈Vs‘,我们得到模糊器列表L（s，v）在软件中成功识别出这种类型的漏洞。即，L（s，v）= {z∈Z：Ts [v，z] = 0}。然后，对于每个z∈L（s，v），我们将C [v，z]增加1。 如果假设一个频率论者的观点，我们应该将表C和矢量D中的所有条目初始化为零，并且让q（v，z）简单地为C [v，z] / D [v]。但是，如果在漏洞类型v中找到的软件测试很少，则q（v，z）的估计值可能不稳定。这类似于这样一种情况，即一个先前相信硬币应该公平的人，即使在连续看到三个头之后也不会认为它应该始终产生头部。 因此，我们在估算时考虑了评估者对q（v，z）的先验概率。我们假设当在具有概率q（v，z）的软件中查找漏洞类型v时，每个模糊器z遵循二项式过程。由于二项式过程的共轭先验是Beta分布，我们假设参数q（v，z）的先验取一个$$Beta（c_0^{（v，z）}+ 1，d_0^{（v）} - c_0^{（v，z）}+ 1）$$分布，其中d0（v）≥c0( v，z）。使用MAP（Maximum A Posteriori）方法估计q（v，z），我们得到：$$q(v, z) = \\frac{c_0^{(v,z)} + C[v, z]}{d_0^{(v)}+ D[v]}$$其中表C和向量D被初始化为全0。简化等式（13），我们可以通过让C [v，z]为所有v∈V和z∈Z的c0（v，z）来初始化表C，并且对于所有v∈V，D [v]是d0（v） 。如果是这样等式（13）简单地变成： $$q(v, z) = \\frac{C[v, z]}{D[v]}$$注意：注意q（v，z）估计如公式(14)所示有偏见，因为D [v]不包括软件包含漏洞类型v的情况，但没有一个模糊检测器正确检测到它。因此等式（14）具有过高估计q（v，z）的真值的趋势。由于可能无法在复杂的软件程序中找到所有漏洞，因此可以通过在ExploitMeter中使用更大的互补模糊器来缓解此类系统错误。 类似地，我们以贝叶斯方式估计等式（11）中的参数r（v）。还假设r（v）遵循具有共轭先验Beta（a0（v）+ 1，b0（v）+1）的二项分布。我们使用两个向量A和B，每个向量的大小为| V |，分别存储每种类型的软件漏洞可被利用和不可利用的次数。对于每个漏洞类型v，A [v]和B [v]分别被初始化为a0（v）和b0（v）。最终分析每次崩溃以验证它是否确实可以被利用。对于每次独特的崩溃，如果发现可利用，A [h（d）]增加1;否则，B [h（d）]增加1。 MAP方法导致以下公式：$$r(v) = \\frac{A[v]}{A[v] + B[v]}$$因此，r（v）的先验估计由a0（v）/（a0（v）+ b0（v））给出，并且在分析由于模糊引起的崩溃之后r（v）的后验估计被连续更新手动。 五，实验结果目前，ExploitMeter已经实现了大约1300行Python代码（不包括模糊器代码）。出于评估目的，我们使用100个Linux应用程序，这些应用程序列在表IV中。所有实验都在以相同方式配置的KVM / QEMU虚拟机中执行：64位Ubuntu 14.04.1,8个逻辑主机CPU，8G RAM和16GB VirtIO磁盘。四个物理工作站专门用于实验，每个工作站有8个内核和32G RAM。在我们的实验中，每个应用程序在模糊测试中提供10个随机选择的种子文件，并且每个应用用这些种子模糊30小时。因此，完成所有模糊测试需要6000个CPU小时。由于有限的计算资源，我们仅使用10个种子来模糊每个应用程序，尽管可以理解，希望用更多种子模糊每个应用程序以实现更好的代码覆盖。对于每种漏洞类型v，ExploitMeter在评估每10个软件程序后重新训练其分类模型。 A. fuzzing 结果自从作为威斯康星大学麦迪逊分校[24]的课程项目引入的模糊概念开始以来，已经开发了许多开源模糊器。然而，许多这些模糊器不成熟，不稳定或支持不足[23]。在研究了许多开源模糊器的可用性之后，我们决定在ExploitMeter的当前实现中使用以下模糊器（尽管其他模糊器可以很容易地结合到ExploitMeter中）： BFF（基本模糊测试框架）[13]。 BFF是由CERT开发的用于查找Linux和Mac OS平台的软件安全漏洞的模糊测试框架。其核心是zzuf，一个流行的模糊测试软件，通过随机改变程序的输入来发现错误[6]。 OFuzz [2]。来自卡内基梅隆大学的研究产品OFuzz是一个突变的模糊测试框架，旨在促进对模糊测试结果的严格统计分析。它采用OCaml语言实现，其模块化设计使得开发新的模糊测试功能变得容易，例如优化模糊测试的种子选择[29]，在模糊测试活动中更改调度算法[37]，以及优化突变比率一个模糊的[15]。 表IV列出了BFF和OFuzz的模糊测试结果。这些结果的一些统计数据总结如下： BFF：在100个应用程序中，26个在模糊测试期间崩溃。对于这26个应用程序中的每一个，平均而言，它崩溃了21.6次，具有19.7个独特的堆栈哈希，归因于5.9种类型的软件漏洞。 OFuzz：在100个应用程序中，29个在模糊测试期间崩溃。对于这29个应用程序中的每一个，平均而言，它崩溃了108270.4次，具有17.3个独特的堆栈哈希，归因于4.9种类型的软件漏洞。 在被模糊器撞毁的35个应用程序中，其中20个被两个模糊器崩溃，这表明使用多个模糊器可以提高查找软件漏洞的效率。比较两个模糊器的模糊测试结果，虽然OFuzz比BFF崩溃的应用程序略多，但它平均崩溃的频率比BFF高5012.5倍。对于这些崩溃，我们使用CERT分类工具提供的堆栈哈希值，这些哈希值是在每次崩溃后对堆栈中前五个堆栈帧进行散列而得到的，以估算唯一崩溃的数量。显然，OFuzz往往比BFF更频繁地报告相同的崩溃，因为OFuzz报告的每个崩溃应用程序的平均堆栈哈希数小于BFF。使用CERT分类工具对每个崩溃的漏洞类型进行分类，我们发现对于每个崩溃的应用程序，BFF发现的软件漏洞类型比OFuzz更多。这与我们之前的观察结果一致，即BFF为每个崩溃的应用程序产生比OFuzz更多的独特崩溃。在图2中，我们针对每个漏洞类型显示了基于两个模糊器的模糊测试结果而导致崩溃的不同应用程序的数量。结果发现，漏洞类型16（SourceAV）导致所有22种漏洞类型中的大多数应用程序崩溃。此外，大多数漏洞类型导致至少一个应用程序崩溃，但类型1（ReturnAv），类型2（UseAfterFree），类型5（StackCodeExecution）和类型14（BlockMoveAv）除外。 B.软件漏洞的可预测性接下来，我们评估软件程序可能具有四个函数名称的不同类型软件漏洞的可预测性。图4（1）显示了在从每个类型的软件漏洞的核心转储中恢复的堆栈上可以找到哪些共享库。结果发现，422个共享库中只有28个或6.6％出现在从核心转储中恢复的堆栈中至少一次。可以经常使用这些共享库。例如，由于漏洞类型4（BrachAv）和7（PossibleStackCorruption）以及库libX11.so.6和libpcre.so.3，32个应用程序使用的库libstdc ++.so.6被发现涉及核心转储。由于漏洞类型7，每个应用程序使用31个应用程序，都涉及核心转储。某些库与许多类型的软件漏洞相关联。例如，由于12种不同类型的软件漏洞，仅由应用程序abiword使用的库libabiword-3.0.so已出现在核心转储堆栈上。图4（2）分别显示了每个漏洞类型在核心转储堆栈上具有相关共享库名称的唯一崩溃的比例。显然，对于除18（BenignSignal）之外的任何漏洞类型，超过一半的独特崩溃涉及共享库。此外，图4（3）显示了可以在核心转储堆栈上找到其共享库名称的易受攻击应用程序的比例。我们发现，对于五种漏洞类型，所有易受攻击的应用程序在执行时都会在核心转储堆栈上留下共享库名称的痕迹。这些观察结果表明，ELF可执行文件使用的共享库列表提供了有价值的信息，用于预测它可能包含的软件漏洞类型。 与库功能相比，重定位功能在函数级别提供了更细粒度的信息，因为它们包括在修补代码时需要解析的功能名称。对于在核心转储堆栈上找到的函数名称，我们检查ELF可执行文件的重定位部分，以查看它们是否出现在重定位功能中。由于相同的函数名称可能出现在两个不同的共享库中，因此我们也需要匹配库名称。但是，重定位部分不提供确切的库名称。例如，应用程序mpv和mplayer在其重定位部分中都有函数pa_context_new @ PULSE_0，其中相应的库是libpulse.so.0。因此，我们从重定位部分中的每个函数名称中搜索库密钥，然后查找是否可以在核心转储堆栈上找到的库名中找到不区分大小写的密钥。按照前面的示例，不区分大小写的键是pulse，我们可以从库名libpulse.so.0中找到它。此外，还添加了两个异常情况：如果密钥是GLIBC或CXXABI，我们将分别在库名称中搜索libc.so和libstdc ++。图4（2）给出了唯一崩溃的部分，其中堆栈上的函数名称可以在ELF可执行文件的重定位部分中找到，类似地，图4（3）显示了某些函数名称上的易受攻击的应用程序的分数核心转储堆栈可以在其重定位部分中找到。据观察，这些分数是显着的，表明从重定位部分提取的特征确实可用于预测软件漏洞。虽然这些数字似乎低于库功能中的数字，但是知道应用程序调用易受攻击的函数显然提供了有关其漏洞的更多信息，而不是知道它链接了易受攻击的共享库。 C.为什么选择贝叶斯？我们接下来解释在ExploitMeter中使用贝叶斯推理的好处。为了便于解释，我们仅考虑漏洞类型16的预测结果。由于只考虑了一种漏洞类型，我们假设评估者有一个置信度阈值来确定软件程序在评估的不同阶段是否存在16类漏洞： prior:先验概率计算为nv / n，其中我们记得nv是先前看到的包含漏洞类型v和n已经评估的样本数的样本的数量。 Prior+ ML：后验概率来自等式（2）和（3）使用分类模型预测软件程序是否包含漏洞类型16.在分类模型中，我们使用所有重定位，库和objdump 2-gram特征。 Prior + ML + BFF：在看到模糊器BFF的模糊测试结果后得出后验概率，模糊器BFF总是在模糊器Ofuzz之前使用。 决策规则很简单：如果概率得分高于给定的置信度阈值，则被评估的软件被认为不易受攻击（对于类型16）。图6显示了在不同评估阶段应用决策规则的精确度和召回分数。为了比较，我们还显示了单独使用BFF和Ofuzz的精确度和召回分数。由于模糊测试结果没有误报，我们可以看到单个模糊器在图6（1）中的精度得分始终为1。 从图6中，我们发现现有方法的性能对置信度阈值敏感。当阈值较低时，该方法始终将新应用程序分类为负数，这会导致调用0和未定义的精度。当阈值超过阳性样本的分数时，该方法倾向于将新应用分类为正，这导致精度降低和具有置信度阈值的召回增加。先前的+ ML方法在看到机器学习的预测结果后，基于后验概率做出决定。该方法的精确度随置信度阈值降低，并且该方法的召回随置信度阈值增加，因为较高置信度阈值导致更多应用被归类为具有相同分类模型的正数。先前的+ ML + BFF方法在看到BFF的模糊测试结果后更新后验概率后作出决定。使用该方法的精度和召回曲线的趋势类似于先前的+ ML方法的趋势。贝叶斯方法有助于在不同的操作环境下进行决策。例如，在军事网络等安全严密的环境中，在应用程序实际部署之前建立对应用程序安全性的高度信任至关重要。在这种情况下，操作员可以使用具有高置信度阈值的先前+ ML方法来查找具有高召回率的易受攻击的应用程序;然而，高置信度阈值也导致高误报率（即，低精度），并且操作员需要对机器学习模型检测到为正的那些应用执行更多模糊测试以确保它们不易受攻击。另一方面，具有低误报率容限的普通用户可以使用具有低置信度阈值的先前+ ML方法;但是，用户必须承担使用未被检测到的易受攻击程序的风险。 D.可利用性评分的评估ExploitMeter提供了一个包含各种输入参数的丰富框架。在本节中，我们将评估ExploitMeter如何使用表II中汇总的参数设置评估可利用性分数。对于每个漏洞类型v和每个模糊器z，漏洞类型v的模糊器z的初始检测率被设置为10/12（即，大约83.3％）。此外，对于CERT分类工具分类为EXPLOITABLE，PROBABLY_EXPLOITABLE，PROBABLY_NOT_EXPLOITABLE或UNKNOWN的漏洞类型，其初始可利用性分别设置为80％，60％，10％或1％。在我们的实验中，这些可利用性分数未更新，因为验证发现的每个漏洞的可利用性是耗时的。 图7（1）显示了ExploitMeter在100个Linux应用程序上按顺序运行后每个应用程序的最终可利用性得分。图中的四条曲线表示每个应用程序在四个不同阶段的可利用性得分：计算先前的信念，从分类模型预测，使用BFF模糊测试，以及使用Ofuzz进行模糊测试。最终的可利用性分数（在使用fuzzer Ofuzz之后）有20个峰值，可利用性分数高于0.6。为了研究分数与表IV中显示的模糊测试结果之间的相关性，我们总结了表III中具有高可利用性分数的20个应用程序的列表，以及CERT分类工具中属于每个可利用性类别的漏洞类型的数量。在100个应用程序中，其中19个至少有一个漏洞类型属于EXPLOITABLE类别，只有它们的可利用性分数高于0.8。应用程序qpdfview有两种漏洞类型属于PROBABLY_EXPLOITABLE类别，也导致相对较高的可利用性得分为0.647。因此，最终的可利用性分数与其模糊测试结果高度相关。 图7（1）还揭示了从机器学习模型预测的可利用性分数与从模糊测试结果估计的最终值不一致。由于分类性能较差，预计会出现这种情况，如图3所示，这些漏洞属于EXPLOITABLE或PROBABLY_EXPLOITABLE类别。 图7（2）显示了每个应用程序的平均可利用性得分以及具有随机测试顺序的20个样本运行中的标准偏差。结果发现，对于具有高可利用性分数的20个应用程序，当测试顺序发生变化时，它们的可利用性分数差别很小。这是合理的，因为无论测试顺序如何，一旦发现一种易于利用的漏洞，它就会将评估者对该漏洞类型的后验信念降低为0，从而显着提高其可利用性评分。 相比之下，评估者基于机器学习模型的预测结果的初始信念更容易改变那些没有发现任何高度可利用漏洞的应用程序的可利用性分数。 VI 结论在这项工作中，我们开发了一个名为ExploitMeter的框架，它将模糊测试与机器学习相结合，以评估软件的可利用性。 ExploitMeter依赖于分类建模来估计基于从静态分析中提取的特征的软件可利用性的初始信念。 ExploitMeter进一步使用动态模糊测试来更新可利用性的信念。 ExploitMeter采用的贝叶斯方法以有机的方式集成了基于机器学习的预测和模糊测试结果。我们将ExploitMeter应用于100个Linux应用程序列表，以深入了解其性能。 在我们未来的工作中，我们计划提高ExploitMeter中使用的机器学习模型的预测准确性。我们将特别研究以下研究问题：更多的阳性样本是否有助于提高所用机器学习模型的预测准确度？是否有可能找到具有更好预测能力的其他类型的功能？或者，深度学习等新机器学习模型能否提升预测性能？","content":"<h1 id=\"Abstract\"><a href=\"#Abstract\" class=\"headerlink\" title=\"Abstract\"></a>Abstract</h1><p>可利用的软件漏洞对其信息安全和隐私构成严重威胁。尽管已经投入大量精力来提高软件安全性，但量化软件可利用性的研究仍处于起步阶段。在这项工作中，我们提出了ExploitMeter，这是一个基于模糊的软件可利用性量化框架，可以促进软件保障和网络保险的决策。 ExploitMeter设计为动态，高效和严谨，它以贝叶斯方式集成了基于机器学习的预测和动态模糊测试。使用100个Linux应用程序，我们进行了大量实验，以评估ExploitMeter在动态环境中的性能。</p>\n<table>\n<thead>\n<tr>\n<th>relevant information</th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><em>作者</em></td>\n<td>Guanhua Yan Junchen Lu Zhan Shu Yunus Kucuk</td>\n</tr>\n<tr>\n<td><em>单位</em></td>\n<td>Department of Computer Science<br>Binghamton University, State University of New York</td>\n</tr>\n<tr>\n<td><em>出处</em></td>\n<td>2017 IEEE Symposium on Privacy-Aware Computing</td>\n</tr>\n<tr>\n<td><em>原文地址</em></td>\n<td></td>\n</tr>\n<tr>\n<td><em>源码地址</em></td>\n<td>http：//<a href=\"http://www.cs.binghamton.edu/~ghyan/code/ExploitMeter/\" target=\"_blank\" rel=\"noopener\">www.cs.binghamton.edu/~ghyan/code/ExploitMeter/</a></td>\n</tr>\n<tr>\n<td><em>发表时间</em></td>\n<td>2017年</td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"1-介绍\"><a href=\"#1-介绍\" class=\"headerlink\" title=\"1. 介绍\"></a>1. 介绍</h1><p>软件安全在确保网络空间可信度方面发挥着关键作用。由于零日软件攻击的地下市场蓬勃发展，大部分网络犯罪都是通过利用易受攻击的软件系统来实现的。不幸的是，在可预见的未来，软件漏洞不太可能被消除，因为现代软件系统变得如此复杂，以至于只有有限认知能力的软件程序员几乎不可能测试他们所有的角落情况，更不用说那些不安全的语言了。 C仍在广泛使用。</p>\n<p>在这项工作中，我们探讨了以下基本问题：鉴于软件系统中可能存在许多软件漏洞，我们能否量化其可利用性？软件可利用性的量化可以在两个重要的情况下找到它的应用：软件保障和网络保险。在国家信息保障术语表[30]中，软件保证被定义为“软件没有漏洞的信任程度，无论是故意设计到软件中还是在其生命周期的任何时间意外插入，以及软件在预期中运行“可量化的软件可利用性提供了对可利用软件漏洞不存在的这种信心的定量测量，从而促进了安全关键软件程序部署中的决策。另一方面，新兴的网络保险市场需要采用严格的方法，保险公司可以使用这些方法定量评估使用潜在易受攻击的软件系统与被保险人相关的风险。</p>\n<p>正如[33]所述，由于运营网络安全的对抗性和动态性，很难实现可量化的安全措施。事实上，随着新开发技术的发展和部署的新的漏洞缓解功能，软件开发的格局不断变化。针对2006年至2012年期间针对Microsoft Windows平台的软件漏洞的调查显示，堆栈损坏漏洞利用率的百分比已经下降，但UAF漏洞的漏洞率却在上升[26]。</p>\n<p>虽然已经做了许多致力于提高软件安全性的努力，但仍然缺乏一个统一的框架来量化软件可利用性在动态操作环境中，正如软件保障和网络保险所需要的那样。在行业中，CVSS（通用漏洞评分系统）[1]被广泛用于估计已知软件漏洞的严重性，包括基于其攻击向量，攻击复杂性，所需权限和用户交互计算的可利用性度量。除了CVSS之外，还提出了一些其他方法来评估软件安全性，例如攻击面度量[22]，漏洞密度度量[7]，[9]，具有危险系统调用的入口点的可达性[39]，以及基于机器学习的预测[12]，[19]。但是，这些方法都不允许我们量化动态执行环境中的软件可利用性。</p>\n<p>在此背景下，我们在这项工作中提出了一个名为ExploitMeter的新框架，旨在定量和动态地评估软件可利用性，以促进软件保障和网络保险的决策。在ExploitMeter框架的核心是模仿人工评估人员的认知过程贝叶斯推理引擎：评价者首先基于静态特征采用机器学习今天初步的预测，然后与来自不同模糊器的多个动态模糊测试的新观察结果来更新自己对软件可利用性的判定。此外，评估者使用这些不同的模糊器的经验被用于更新他们的感知性能 - 也以贝叶斯方式 - 并且这些性能测量形成评估者量化软件可利用性的基础。因此，ExploitMeter的推理引擎可以被描述为动态非线性系统，其输入来自基于机器学习的预测和动态模糊测试。</p>\n<p>在构建ExploitMeter框架的最后，我们在这项工作中的贡献总结如下：</p>\n<ul>\n<li><p>我们从软件程序的静态分析中提取各种特征，我们从中训练分类模型以预测软件程序可能具有的漏洞类型（例如，堆栈溢出和use-after-free）。评估者使用这些分类器的分类性能来得出她对预测结果的初始置信水平。</p>\n</li>\n<li><p>对于每个受测试的软件，我们使用各种模糊器来生成崩溃，从中我们发现导致崩溃的软件漏洞类型。对于发现的每种类型的软件漏洞，我们使用贝叶斯方法来计算评估者对软件漏洞的后验信念。</p>\n</li>\n<li><p>基于概率论，我们将软件程序包含的不同类型软件漏洞的可利用性分数结合起来，以生成最终的可利用性分数。</p>\n</li>\n</ul>\n<p>我们在以下网址提供ExploitMeter的源代码：http：//<a href=\"http://www.cs.binghamton.edu/~ghyan/code/ExploitMeter/。为了证明其实用性，我们进行了大量实验，其中使用了两个不同的软件模糊器来模拟虚拟机中的100个标准Linux实用程序。我们在不同配置下使用ExploitMeter动态量化这些程序的可利用性，从而深入了解ExploitMeter如何促进软件保障和网络保险实践中的决策制定。\" target=\"_blank\" rel=\"noopener\">www.cs.binghamton.edu/~ghyan/code/ExploitMeter/。为了证明其实用性，我们进行了大量实验，其中使用了两个不同的软件模糊器来模拟虚拟机中的100个标准Linux实用程序。我们在不同配置下使用ExploitMeter动态量化这些程序的可利用性，从而深入了解ExploitMeter如何促进软件保障和网络保险实践中的决策制定。</a></p>\n<p>在本文的其余部分安排如下。第二节总结了相关工作。第三节提供了ExploitMeter的实际背景。 ExploitMeter采用的主要方法在第IV节中讨论。在第五节中，我们介绍了实验结果，并在第六节中得出结论性意见</p>\n<h1 id=\"II-相关工作\"><a href=\"#II-相关工作\" class=\"headerlink\" title=\"II 相关工作\"></a>II 相关工作</h1><p>许多努力致力于提高软件漏洞发现的效率。这些技术主要分为两类，静态分析（例如，[16]，[21]，[20]，[35]）和动态模糊测试（例如，[32]，[34]，[17]）。 ExploitMeter的当前实现依赖于动态模糊测试来发现软件漏洞，因为模糊测试工具可以轻松实现自动化，程序的崩溃状态允许我们推断导致崩溃的漏洞类型。但是，在ExploitMeter框架中，很容易合并其他软件漏洞发现工具，这仍然是我们未来的工作。</p>\n<p>软件安全研究人员也一直在开发模型来预测软件漏洞。该领域的工作通常利用国家漏洞数据库中的大量软件漏洞数据，并通过改进历史漏洞数据来训练预测模型（例如[18]，[9]，[28]，[8]，[ 8]，[27]，[40]）。与我们的工作更相关的是那些应用机器学习来推断软件漏洞的可利用性的工作。例如，Bozorgi等人 [12]训练线性支持向量机，使用从两个公共漏洞数据源中的描述中提取的基于文本的特征，对易受攻击的软件程序是否可利用进行分类。 [12]中提出的预测模型不能用于预测日常漏洞的可利用性。在[19]中Grieco等人从静态分析和动态执行软件程序中提取C标准库调用序列，以分类它们是否容易受到内存损坏。虽然这项工作直接适用于可执行程序，但它并不像ExploitMeter那样提供可量化的软件可利用性度量。所有这些先前工作的共同点是，他们从历史数据中训练模型以预测未来威胁的特征。 ExploitMeter与这些作品不同，因为预测模型仅用于推导先验信念，但这些信念应该用新的测试结果动态更新。这有效地解决了在软件开发技术和威胁缓解功能之间存在军备竞争的动态环境中可预测性的下降。</p>\n<p>ExploitMeter还涉及一些关于自动生成软件漏洞的最新工作，例如AEG [10]和Mayhem [14]尽管ExploitMeter的设计受到了这些工作的启发，但是没有必要针对易受攻击的程序找到可操作的漏洞来评估其可利用性。 ExploitMeter采用的方法类似于我们之前的工作[38]，它采用贝叶斯方法来量化软件可利用性。但是，这项工作主要是理论性的，没有具体说明如何推导出先前的信念以及应该使用哪些工具来测试软件漏洞。相比之下，ExploitMeter提供了量化软件可利用性的实用框架</p>\n<h1 id=\"III-背景\"><a href=\"#III-背景\" class=\"headerlink\" title=\"III 背景\"></a>III 背景</h1><p>可量化的软件可利用性有助于软件保障和网络保险的决策。为了解释这一动机，我们为这两个应用程序中的每一个提供了一个示例场景：</p>\n<ul>\n<li>软件保障：考虑一个安全关键环境，其中运行的每个软件应该不受利用，即使软件可能包含已知或未知的漏洞。当要部署新软件时，系统管理员需要确保在其执行环境中可以利用它的可能性应低于某个阈值。可量化的软件可利用性允许系统管理员在决定是否运行软件程序时建立置信度。</li>\n<li>网络保险：IT（信息技术）经理希望确保企业免受恶意网络威胁。为了计算溢价，网络保险公司需要评估被保险企业网络中安装的软件的安全性。软件可利用性的定量测量允许保险公司量化与在被保险人网络内使用软件相关的风险。一旦投保，可以通过可信计算模块的远程证明来确保软件的完整性。这有助于保险公司仅为已经评估过的软件制定保险单。</li>\n</ul>\n<p>两个示例的共同点是必须量化在特定执行环境中运行的软件程序的可利用性。我们的目标是建立一个名为ExploitMeter的实用框架，系统管理员可以使用它来决定是否应该部署特定软件（软件保证），或者由保险公司用来评估软件程序的开发风险然后相应地计算保费（网络保险）。</p>\n<p>利用软件的先决条件是它包含一些可以从其攻击面利用的软件漏洞。经典类型的软件漏洞包括堆栈缓冲区溢出，释放后使用引用，堆损坏，整数溢出，除零，解除引用空指针以及类型混淆。有许多工具可用于自动发现软件漏洞。由于软件的源代码可能无法在操作环境中使用，因此我们排除了依赖静态代码分析来查找软件漏洞的工具。并非所有软件漏洞都可以在相同程度上被利用。例如，虽然除零可能会有效地崩溃程序并因此启用拒绝服务攻击，但它不容易被利用用于更有趣的目的，例如权限提升。</p>\n<h1 id=\"IV-方法\"><a href=\"#IV-方法\" class=\"headerlink\" title=\"IV 方法\"></a>IV 方法</h1><p>如图1所示，ExploitMeter是一个评估动态环境中软件可利用性的框架。在ExploitMeter中，计划按顺序测试软件S = {s0，s1，…，si，…}的列表。对于每个软件s∈S，假设其可利用性由假想的人类评估者测量，作为她对软件可被利用的可能性的主观信念。但是，软件可以通过各种低级软件漏洞利用，例如缓冲区溢出和整数溢出。此外，攻击者可以利用每种类型的这些安全漏洞的可能性可能会有所不同。因此，我们的模型使评估者能够推断每个软件漏洞类型的软件可利用性。设V = {v0，v1，…，v | V | -1}表示考虑的软件漏洞类型集。因此，软件通过漏洞类型v∈V的可利用性是评估者对通过漏洞类型v利用软件的可能性的主观信念。因此，我们的关键利益是评估零假设H0（s，v）的概率。这表明软件不易受类型v的攻击。我们让H1（s，v）表示相反的假设，即假设软件易受类型v攻击。</p>\n<p><img src=\"/2019/04/08/ExploitMeter-Combining-Fuzzing-with-Machine-Learning-for-Automated-Evaluation-of-Software-Exploitability/1.jpg\" alt=\"\"></p>\n<p>因此，由于类型v导致的软件的可利用性可以被表征为评估者的主观概率P（H0（s，v））。在贝叶斯推理[11]中，假设评估者保留P（H0（s，v））的先验概率，并且在看到证据E后，她的后验信念根据贝叶斯规则更新：<br>$$<br>P{H0(s, v)|E} =  \\frac {P{E|H0(s, v)}* P{H0(s, v)}}{P{E}}<br>$$<br>为了应用贝叶斯推理[11]，我们需要解决如何推导先验概率P {H0（s，v）}以及如何获得证据E以支持软件可利用性的后验更新。</p>\n<h2 id=\"A-从机器学习模型中获得初始概率\"><a href=\"#A-从机器学习模型中获得初始概率\" class=\"headerlink\" title=\"A.从机器学习模型中获得初始概率\"></a>A.从机器学习模型中获得初始概率</h2><p>ExploitMeter允许评估人员使用预测分类模型快速评估软件可利用性。对于每种类型的软漏洞，对基于软件程序的静态分析提取的特征训练分类模型。我们使用f（s）来表示从软件程序中提取的一组特征。给定特征向量f∈F，其中F是特征空间，给出的漏洞类型v的分类模型cv，由<code>cv：F→{positive，negative}</code>从历史数据中训练以预测具有特征向量 f 的软件程序 是否包含v类型的漏洞。</p>\n<p>受过训练的分类模型可能会对软件程序包含的漏洞类型做出错误的预测。错误预测的来源可以是从软件程序中提取的弱特征，不准确的预测模型（例如，具有不良泛化能力的训练数据过度拟合的模型），或者本质上缺乏可预测性的非静止数据。因此，当使用机器学习模型来预测软件可利用性时，有必要考虑它们的预测性能。 ExploitMeter使用四重（TP，FP，TN，F N）监控每个分类器的性能，其中包括过去预测中的真阳性，假阳性，真阴性和假阴性的数量。令p（cv）表示与分类器cv相关联的性能四元组，并且其第i个元素由p（cv）[i]给出。</p>\n<p>为了应用贝叶斯推理，需要假设P {H0（s，v）}的先验概率。基于所评估的软件程序没有发现类型v的漏洞的分数来建立P {H0（s，v）}的先验概率的合理模型。因此，计数器n用于保持评估的软件程序的数量，并且对于每种漏洞类型，nv用于保持已发现包含类型v的漏洞的软件程序的数量。但是，我们可能不想要直接使用nv / n作为先验概率，因为如果nv = 0，则对P {H0（s，v）}的先验概率为0，这决定了方程（1）中后验概率的计算。 忽视了E的存在。为了解决这个问题，ExploitMeter用一些正数初始化nv和n。例如，n = 2且nv = 1最初假设P {H0（s，v）}的初始先验信念是0.5，并且计数器在评估的每个软件程序时更新。</p>\n<p>当评估新的软件程序时，分类器cv的预测结果证明了E的存在。根据等式（1），如果cv预测s为正，我们有：<br>$$<br>P{H0(s, v)| classifier cv predicts s to be positive }<br>=<br>\\frac {<br>\\frac {nv}{n}·\\frac{p(cv)[2]}<br>{p(cv)[2]+p(cv)[3]}}<br>{<br>\\frac {nv}{n}·\\frac{p(cv)[2]}<br>{p(cv)[2]+p(cv)[3]} + \\frac{n−nv}{n} · \\frac{p(cv)[1]}{p(cv)[1]+p(cv)[4]}<br>}<br>$$<br>如果cv预测s为负数，我们有：<br>$$<br>P{H0(s, v)| classifier cv predicts s to be positive }<br>=<br>\\frac {<br>\\frac {nv}{n}·\\frac{p(cv)[3]}<br>{p(cv)[2]+p(cv)[3]}}<br>{<br>\\frac {nv}{n}·\\frac{p(cv)[3]}<br>{p(cv)[2]+p(cv)[3]} + \\frac{n−nv}{n} · \\frac{p(cv)[4]}{p(cv)[1]+p(cv)[4]}<br>}<br>$$</p>\n<h2 id=\"B-基于模糊测试的软件可利用性后验更新\"><a href=\"#B-基于模糊测试的软件可利用性后验更新\" class=\"headerlink\" title=\"B.基于模糊测试的软件可利用性后验更新\"></a>B.基于模糊测试的软件可利用性后验更新</h2><p>从软件程序提取的特征数据可能具有低稳定性，因此对于预测其可利用性的能力有限。例如，用于开发这些软件的编程语言的分布可能会随着时间的推移而发生变化，即使对于相同的编程语言，它也可能随着用新的功能替换过时功能而发展。此外，由于网络安全的对抗性质，可以在具有悠久历史的软件中找到新的安全漏洞。例如，自1989年9月以来，2014年发现的ShellShock漏洞突然使所有版本的Bash变得脆弱[36]。对于关键的网络安全操作，我们因此不应仅依赖从历史数据训练的模型来预测软件可利用性。</p>\n<p>ExploitMeter允许评估者通过向她提供的新证据更新她对软件可利用性的信念。为了获得新的证据，使用一组模糊器Z = {z0，z1，…，z | Z | -1}来查找被测软件中的漏洞。每个模糊器的工作原理是将格式错误的数据注入程序以创建崩溃。进一步分析这些崩溃以推断潜在的安全漏洞。模糊测试的输出要么软件成功终止，要么导致崩溃。对于每次崩溃，我们都可以推断导致崩溃的软件漏洞类型。在第IV-C节中，我们将详细说明如何在ExploitMeter框架中完成此操作。</p>\n<p>在使用Z中的模糊器对软件进行模糊测试后，模糊测试结果将作为评估者更新其后验概率的证据。如果模糊器发现软件的漏洞类型为v，则将Esv定义为1，否则为0。然后我们有两个用fuzzer模糊软件的Esv案例：</p>\n<p>案例A：Esv = 1.在这种情况下，模糊器在软件中成功找到v类型的漏洞。有了这样一个确凿的证据，评估者对软件免疫v的后验概率应该是0，而不管她从回归模型得出的初始概率。这可以通过贝叶斯规则得到证实：<br>$$<br>P(H0(s, v) | Esv = 1)<br>=<br>\\frac{P(Esv = 1 | H0(s, v)) · P(H0(s, v))}<br>{P(Esv = 1)} = 0<br>$$<br>必须保持最终的相等性，就好像软件不易受类型v攻击一样，任何模糊器都不可能找到导致它因类型v而崩溃的软件输入。</p>\n<p>案例B：Esv = 0.在这种情况下，模糊器在软件s中找不到类型v的漏洞。但是，软件仍然可能容易受到v攻击，因为模糊器可能由于其模糊测试策略而无法检测到漏洞。使用贝叶斯规则，我们有以下内容：<br>$$<br>P(H0(s, v) | Esv = 0)<br>=<br>\\frac{P(Esv = 0 | H0(s, v)) · P(H0(s, v))}<br>{P(Esv = 0)}<br>$$<br>一些模糊测试者比其他模糊测试人员更能检测到特定类型的漏洞。例如，[25]中开发的SmartFuzz方法专注于检测整数错误。让模糊器z对漏洞类型v的检测率为q（v，z）。我们因此：<br>$$<br>P(Es,v = 0 | H1(s, v)) = 1 − q(v, z)<br>$$<br>如果假设H0（s，v）为真（即软件不易受类型v影响），则情况B必须保持。因此，我们有：<br>$$<br>P(Es,v = 0 | H0(s, v)) = 1<br>$$<br>结合方程（6）和（7），我们有：<br>$$<br>P(Es,v = 0) = \\sum_{i=0}^1 P(H_i(s,v))·P(Esv=0|H_i(s,v))<br>= P(H0(s,v))+(1−P(H0(s,v)))·(1−q(v,z)<br>$$<br>最后，我们有以下内容：<br>$$<br>P(H0(s, v) | Es,v = 0) =<br>\\frac{P(H0(s,v))}<br>{P(H0(s,v))+(1−P(H0(s,v)))·(1−q(v,z)) }<br>$$<br>软件程序的可利用性取决于它包含的漏洞类型以及每种漏洞类型转化为软件漏洞的可能性。为了对这种依赖关系进行建模，我们假设评估者对于每个漏洞类型v∈V，都相信其被利用的可能性，用r（v）表示。假设V中的漏洞类型是独占且独立的，在看到模糊器的模糊测试结果后，软件的整体可利用性由下式给出：<br>$$<br>U(s) = 1−<br>\\prod_{v∈V}[(1−r(v))·(1−P(H0(s,v)|Es,v))+P(H0(s,v)|Esv)]<br>= 1 − \\prod_{v∈V}[1 − r(v) + r(v) · P(H0(s, v) | Esv)]<br>$$<br>其中P（H0（s，v）| Esv）是在看到证据Esv后，评估者对假设H0（s，v）的后验概率。方程式（9）RHS（右手侧）的第二个术语， 给出了软件不能通过V中任何类型的漏洞被利用的概率。</p>\n<p>ExploitMeter在模糊器模糊后重新计算软件程序的可利用性分数。基于该可利用性得分，如果可利用性得分高于某个置信度阈值，则可以做出决定。否则，评估者需要更多证据来确定软件程序是否确实可以利用。</p>\n<h2 id=\"C-崩溃造成的漏洞干扰\"><a href=\"#C-崩溃造成的漏洞干扰\" class=\"headerlink\" title=\"C.崩溃造成的漏洞干扰\"></a>C.崩溃造成的漏洞干扰</h2><p>当程序崩溃或以其他方式异常终止时，现代OS通常允许将崩溃进程的存储器映像和程序寄存器转储到本地文件系统上。这些核心转储文件可以进一步加载到调试器中，例如GNU调试器或Microsoft WinDbg，以在崩溃发生时恢复进程的内部状态。这些核心转储文件可用于推断导致崩溃的漏洞类型。例如，可以检查崩溃进程的堆栈跟踪缓冲区溢出的可能性，这是一种典型的软件漏洞。<br>Microsoft安全工程中心开发了一个名为！exploitable [4]的WinDbg扩展，根据其原因对崩溃进行分类，例如使用先前释放的堆缓冲区和堆栈缓冲区溢出。可以将每个原因视为漏洞类型，并且不同漏洞类型的可利用性不同。在！exploitable 的情况下，所有类型的软件漏洞都分为四类，具体取决于它们被开发的可能性，可利用，可能可利用 ，可泵不可利用和未知性。 Apple开发了一个名为CrashWrangler的类似工具来检查Mac OS平台上的软件崩溃[3]，并开发了CERT分类工具来评估Linux平台上的软件可利用性[5]。</p>\n<p>ExploitMeter依靠这些工具来推断导致程序崩溃的软件漏洞类型。表1中给出了可由CERT分类工具推断出的漏洞类型列表。尽管这些工具是ExploitMeter框架的一个组成部分，但我们知道它们在评估软件崩溃时的安全性方面并不完美。 [31]这些工具背后的一个基本假设是攻击者可以完全控制导致崩溃的错误指令的输入操作数。如果无法从程序的攻击面更改这些输入操作，则这些工具往往会高估发现软件漏洞的风险。此外，这些工具还应用基于规则的启发式和轻量级污点分析，这些技术中固有的局限性可能导致错误的漏洞分类。</p>\n<p><img src=\"/2019/04/08/ExploitMeter-Combining-Fuzzing-with-Machine-Learning-for-Automated-Evaluation-of-Software-Exploitability/2.jpg\" alt=\"table 1\"></p>\n<h2 id=\"D-训练分类模型\"><a href=\"#D-训练分类模型\" class=\"headerlink\" title=\"D.训练分类模型\"></a>D.训练分类模型</h2><p>ExploitMeter目前旨在评估ELF（可执行和可链接格式）可执行文件的可利用性。它从ELF可执行文件中提取特征以训练分类模型，该模型预测它们是否包含特定类型的漏洞。可以从ELF可执行文件的静态分析中提取各种类型的功能。<br>ExploitMeter目前使用以下类型的功能：</p>\n<ul>\n<li>Hexdump功能。我们使用hexdump实用程序从二进制程序中获取字节序列，然后计算软件程序中出现的每个n-gram字节序列的频率。有256个1-gram特征（即0x00到0xFF）和65536个2-gram特征（即0x0000到0xFFFF）。</li>\n<li>Objdump功能。我们使用objdump来反汇编二进制可执行程序，并且对于每个指令，我们将其表示为操作码及其操作数类型的组合。例如，指令mov edi，0x600dc0被抽象为mov-register-immediate，而指令mov rax，QWORD PTR [rip + 0x981375]被抽象为mov-register-memory。使用操作数类型扩展操作码的直觉是ExploitMeter目前专注于评估与内存相关的软件漏洞，因此希望明确识别指令是否访问内存有助于提高分类性能。然后，我们计算出软件程序代码部分中出现的每个n-gram序列的频率。由于软件开发针对合法软件，我们希望大多数合法程序不会使用恶意软件中的大量混淆来混淆反汇编过程。</li>\n<li>库功能。我们使用ldd实用程序来获取可执行程序所需的共享库列表。值得注意的是，严格来说，ldd实用程序不是静态分析工具，因为它使用动态加载程序来决定运行时需要哪些共享库，但它比静态分析工具（如objdump）提供了更准确的共享库覆盖。对于某些ELF可执行文件，例如mediainfo和pdftk，由于ld.so检测到不一致问题，在它们上运行ldd会崩溃。对于他们，我们使用objdump -p来查找所需的共享库。</li>\n<li>搬迁功能。我们使用readelf实用程序（使用-rW选项）来发现重定位部分的内容，然后使用c ++ filt实用程序对重定位的符号进行解码。每个已解密的符号都被视为值为1的要素，如果在重定位部分中找不到，则为0。</li>\n</ul>\n<p>在动态环境中，分类模型定期重新训练。我们按时间划分为几个时期，T = {T0，T1，…}。获得这些时期的选择可以是灵活的。例如，我们可以将时间划分为相等的长度（例如，三个月），或者让在不同时期测试的软件的数量大致相同，或者将模糊测试活动视为时期。让时期Ti中使用的分类模型cv被区分为c（vi），其中i = 0,1，……对于第一个时期T0，由于没有历史数据来训练每个漏洞类型的分类模型，我们可以使用领域知识来指定先前的概率。</p>\n<p>在每个时期的开始，使用所有历史数据对每个漏洞类型重新训练分类模型。通过略微滥用符号S，我们定义Si，其中i = 0,1，…作为已在时期Ti中测试的软件集。当在i ≥ 1的时期Ti的开始建立漏洞类型v的分类模型时，我们如下导出训练数据集。对于每个软件s∈{Sk} 0≤k≤i-1，我们让Ys（v）∈{positive，negative}表示软件s是否被任何模糊器检测到包含v类型的漏洞;我们将元组（f（s），Ys（v））添加到训练数据集中，其中我们记得f（s）是软件s的特征向量。用于时期Ti的分类模型c（vi）通过从f（s）预测所有s∈{Sk}0≤k≤i-1的Ys（v）来训练。 ExploitMeter中分类模型的选择是灵活的，我们将在实验中根据经验评估各种分类模型的性能</p>\n<h2 id=\"E-贝叶斯参数估计\"><a href=\"#E-贝叶斯参数估计\" class=\"headerlink\" title=\"E.贝叶斯参数估计\"></a>E.贝叶斯参数估计</h2><p>回想一下，参数q（v，z）表示模糊器z对漏洞类型v的检测率。为了估计q（v，z），我们维护一个性能计数表，用C表示，大小为| V | x | Z |。表C的每个条目C [v，z]是保持模糊器z成功检测到具有漏洞类型v的软件的次数的计数器。除了表C之外，长度为| V |的向量D也保留，其中每个i在[0，| V | -  1]，D [v]给出已用漏洞类型v识别的软件数量。</p>\n<p>表C和向量D更新如下。限定：<br>$$<br>V_s^{‘} = {v ∈ V : Esv = 1}.<br>$$</p>\n<p>因此，设置Vs’包含至少一个fuzzer在软件中找到的所有漏洞类型。对于每个v∈Vs’,我们将D [v]增加1，因为在软件中已发现v类型的新漏洞。此外，对于每个v∈Vs‘,我们得到模糊器列表L（s，v）在软件中成功识别出这种类型的漏洞。即，L（s，v）= {z∈Z：Ts [v，z] = 0}。然后，对于每个z∈L（s，v），我们将C [v，z]增加1。</p>\n<p>如果假设一个频率论者的观点，我们应该将表C和矢量D中的所有条目初始化为零，并且让q（v，z）简单地为C [v，z] / D [v]。但是，如果在漏洞类型v中找到的软件测试很少，则q（v，z）的估计值可能不稳定。这类似于这样一种情况，即一个先前相信硬币应该公平的人，即使在连续看到三个头之后也不会认为它应该始终产生头部。</p>\n<p>因此，我们在估算时考虑了评估者对q（v，z）的先验概率。我们假设当在具有概率q（v，z）的软件中查找漏洞类型v时，每个模糊器z遵循二项式过程。由于二项式过程的共轭先验是Beta分布，我们假设参数q（v，z）的先验取一个<br>$$<br>Beta（c_0^{（v，z）}+ 1，d_0^{（v）} - c_0^{（v，z）}+ 1）<br>$$<br>分布，其中d0（v）≥c0( v，z）。使用MAP（Maximum A Posteriori）方法估计q（v，z），我们得到：<br>$$<br>q(v, z) = \\frac{c_0^{(v,z)} + C[v, z]}<br>{d_0^{(v)}+ D[v]}<br>$$<br>其中表C和向量D被初始化为全0。简化等式（13），我们可以通过让C [v，z]为所有v∈V和z∈Z的c0（v，z）来初始化表C，并且对于所有v∈V，D [v]是d0（v） 。如果是这样等式（13）简单地变成：</p>\n<p>$$<br>q(v, z) = \\frac{C[v, z]}<br>{D[v]}<br>$$<br>注意：注意q（v，z）估计如公式(14)所示有偏见，因为D [v]不包括软件包含漏洞类型v的情况，但没有一个模糊检测器正确检测到它。因此等式（14）具有过高估计q（v，z）的真值的趋势。由于可能无法在复杂的软件程序中找到所有漏洞，因此可以通过在ExploitMeter中使用更大的互补模糊器来缓解此类系统错误。</p>\n<p>类似地，我们以贝叶斯方式估计等式（11）中的参数r（v）。还假设r（v）遵循具有共轭先验Beta（a0（v）+ 1，b0（v）+1）的二项分布。我们使用两个向量A和B，每个向量的大小为| V |，分别存储每种类型的软件漏洞可被利用和不可利用的次数。对于每个漏洞类型v，A [v]和B [v]分别被初始化为a0（v）和b0（v）。最终分析每次崩溃以验证它是否确实可以被利用。对于每次独特的崩溃，如果发现可利用，A [h（d）]增加1;否则，B [h（d）]增加1。 MAP方法导致以下公式：<br>$$<br>r(v) = \\frac{A[v]}<br>{A[v] + B[v]}<br>$$<br>因此，r（v）的先验估计由a0（v）/（a0（v）+ b0（v））给出，并且在分析由于模糊引起的崩溃之后r（v）的后验估计被连续更新手动。</p>\n<h1 id=\"五，实验结果\"><a href=\"#五，实验结果\" class=\"headerlink\" title=\"五，实验结果\"></a>五，实验结果</h1><p>目前，ExploitMeter已经实现了大约1300行Python代码（不包括模糊器代码）。出于评估目的，我们使用100个Linux应用程序，这些应用程序列在表IV中。所有实验都在以相同方式配置的KVM / QEMU虚拟机中执行：64位Ubuntu 14.04.1,8个逻辑主机CPU，8G RAM和16GB VirtIO磁盘。四个物理工作站专门用于实验，每个工作站有8个内核和32G RAM。在我们的实验中，每个应用程序在模糊测试中提供10个随机选择的种子文件，并且每个应用用这些种子模糊30小时。因此，完成所有模糊测试需要6000个CPU小时。由于有限的计算资源，我们仅使用10个种子来模糊每个应用程序，尽管可以理解，希望用更多种子模糊每个应用程序以实现更好的代码覆盖。对于每种漏洞类型v，ExploitMeter在评估每10个软件程序后重新训练其分类模型。</p>\n<h2 id=\"A-fuzzing-结果\"><a href=\"#A-fuzzing-结果\" class=\"headerlink\" title=\"A. fuzzing 结果\"></a>A. fuzzing 结果</h2><p>自从作为威斯康星大学麦迪逊分校[24]的课程项目引入的模糊概念开始以来，已经开发了许多开源模糊器。然而，许多这些模糊器不成熟，不稳定或支持不足[23]。在研究了许多开源模糊器的可用性之后，我们决定在ExploitMeter的当前实现中使用以下模糊器（尽管其他模糊器可以很容易地结合到ExploitMeter中）：</p>\n<ul>\n<li>BFF（基本模糊测试框架）[13]。 BFF是由CERT开发的用于查找Linux和Mac OS平台的软件安全漏洞的模糊测试框架。其核心是zzuf，一个流行的模糊测试软件，通过随机改变程序的输入来发现错误[6]。</li>\n<li>OFuzz [2]。来自卡内基梅隆大学的研究产品OFuzz是一个突变的模糊测试框架，旨在促进对模糊测试结果的严格统计分析。它采用OCaml语言实现，其模块化设计使得开发新的模糊测试功能变得容易，例如优化模糊测试的种子选择[29]，在模糊测试活动中更改调度算法[37]，以及优化突变比率一个模糊的[15]。</li>\n</ul>\n<p>表IV列出了BFF和OFuzz的模糊测试结果。这些结果的一些统计数据总结如下：</p>\n<ul>\n<li>BFF：在100个应用程序中，26个在模糊测试期间崩溃。对于这26个应用程序中的每一个，平均而言，它崩溃了21.6次，具有19.7个独特的堆栈哈希，归因于5.9种类型的软件漏洞。</li>\n<li>OFuzz：在100个应用程序中，29个在模糊测试期间崩溃。对于这29个应用程序中的每一个，平均而言，它崩溃了108270.4次，具有17.3个独特的堆栈哈希，归因于4.9种类型的软件漏洞。</li>\n</ul>\n<p>在被模糊器撞毁的35个应用程序中，其中20个被两个模糊器崩溃，这表明使用多个模糊器可以提高查找软件漏洞的效率。比较两个模糊器的模糊测试结果，虽然OFuzz比BFF崩溃的应用程序略多，但它平均崩溃的频率比BFF高5012.5倍。对于这些崩溃，我们使用CERT分类工具提供的堆栈哈希值，这些哈希值是在每次崩溃后对堆栈中前五个堆栈帧进行散列而得到的，以估算唯一崩溃的数量。显然，OFuzz往往比BFF更频繁地报告相同的崩溃，因为OFuzz报告的每个崩溃应用程序的平均堆栈哈希数小于BFF。使用CERT分类工具对每个崩溃的漏洞类型进行分类，我们发现对于每个崩溃的应用程序，BFF发现的软件漏洞类型比OFuzz更多。这与我们之前的观察结果一致，即BFF为每个崩溃的应用程序产生比OFuzz更多的独特崩溃。<br>在图2中，我们针对每个漏洞类型显示了基于两个模糊器的模糊测试结果而导致崩溃的不同应用程序的数量。结果发现，漏洞类型16（SourceAV）导致所有22种漏洞类型中的大多数应用程序崩溃。此外，大多数漏洞类型导致至少一个应用程序崩溃，但类型1（ReturnAv），类型2（UseAfterFree），类型5（StackCodeExecution）和类型14（BlockMoveAv）除外。</p>\n<p><img src=\"/2019/04/08/ExploitMeter-Combining-Fuzzing-with-Machine-Learning-for-Automated-Evaluation-of-Software-Exploitability/3.jpg\" alt=\"\"></p>\n<h2 id=\"B-软件漏洞的可预测性\"><a href=\"#B-软件漏洞的可预测性\" class=\"headerlink\" title=\"B.软件漏洞的可预测性\"></a>B.软件漏洞的可预测性</h2><p>接下来，我们评估软件程序可能具有四个函数名称的不同类型软件漏洞的可预测性。图4（1）显示了在从每个类型的软件漏洞的核心转储中恢复的堆栈上可以找到哪些共享库。结果发现，422个共享库中只有28个或6.6％出现在从核心转储中恢复的堆栈中至少一次。可以经常使用这些共享库。例如，由于漏洞类型4（BrachAv）和7（PossibleStackCorruption）以及库libX11.so.6和libpcre.so.3，32个应用程序使用的库libstdc ++.so.6被发现涉及核心转储。由于漏洞类型7，每个应用程序使用31个应用程序，都涉及核心转储。某些库与许多类型的软件漏洞相关联。例如，由于12种不同类型的软件漏洞，仅由应用程序abiword使用的库libabiword-3.0.so已出现在核心转储堆栈上。图4（2）分别显示了每个漏洞类型在核心转储堆栈上具有相关共享库名称的唯一崩溃的比例。显然，对于除18（BenignSignal）之外的任何漏洞类型，超过一半的独特崩溃涉及共享库。此外，图4（3）显示了可以在核心转储堆栈上找到其共享库名称的易受攻击应用程序的比例。我们发现，对于五种漏洞类型，所有易受攻击的应用程序在执行时都会在核心转储堆栈上留下共享库名称的痕迹。这些观察结果表明，ELF可执行文件使用的共享库列表提供了有价值的信息，用于预测它可能包含的软件漏洞类型。</p>\n<p><img src=\"/2019/04/08/ExploitMeter-Combining-Fuzzing-with-Machine-Learning-for-Automated-Evaluation-of-Software-Exploitability/4.jpg\" alt=\"\"></p>\n<p>与库功能相比，重定位功能在函数级别提供了更细粒度的信息，因为它们包括在修补代码时需要解析的功能名称。对于在核心转储堆栈上找到的函数名称，我们检查ELF可执行文件的重定位部分，以查看它们是否出现在重定位功能中。由于相同的函数名称可能出现在两个不同的共享库中，因此我们也需要匹配库名称。但是，重定位部分不提供确切的库名称。例如，应用程序mpv和mplayer在其重定位部分中都有函数pa_context_new @ PULSE_0，其中相应的库是libpulse.so.0。因此，我们从重定位部分中的每个函数名称中搜索库密钥，然后查找是否可以在核心转储堆栈上找到的库名中找到不区分大小写的密钥。按照前面的示例，不区分大小写的键是pulse，我们可以从库名libpulse.so.0中找到它。此外，还添加了两个异常情况：如果密钥是GLIBC或CXXABI，我们将分别在库名称中搜索libc.so和libstdc ++。图4（2）给出了唯一崩溃的部分，其中堆栈上的函数名称可以在ELF可执行文件的重定位部分中找到，类似地，图4（3）显示了某些函数名称上的易受攻击的应用程序的分数核心转储堆栈可以在其重定位部分中找到。据观察，这些分数是显着的，表明从重定位部分提取的特征确实可用于预测软件漏洞。虽然这些数字似乎低于库功能中的数字，但是知道应用程序调用易受攻击的函数显然提供了有关其漏洞的更多信息，而不是知道它链接了易受攻击的共享库。</p>\n<p><img src=\"/2019/04/08/ExploitMeter-Combining-Fuzzing-with-Machine-Learning-for-Automated-Evaluation-of-Software-Exploitability/5.jpg\" alt=\"\"></p>\n<h2 id=\"C-为什么选择贝叶斯？\"><a href=\"#C-为什么选择贝叶斯？\" class=\"headerlink\" title=\"C.为什么选择贝叶斯？\"></a>C.为什么选择贝叶斯？</h2><p>我们接下来解释在ExploitMeter中使用贝叶斯推理的好处。为了便于解释，我们仅考虑漏洞类型16的预测结果。由于只考虑了一种漏洞类型，我们假设评估者有一个置信度阈值来确定软件程序在评估的不同阶段是否存在16类漏洞： </p>\n<ul>\n<li><p>prior:先验概率计算为nv / n，其中我们记得nv是先前看到的包含漏洞类型v和n已经评估的样本数的样本的数量。</p>\n</li>\n<li><p>Prior+ ML：后验概率来自等式（2）和（3）使用分类模型预测软件程序是否包含漏洞类型16.在分类模型中，我们使用所有重定位，库和objdump 2-gram特征。</p>\n</li>\n<li>Prior + ML + BFF：在看到模糊器BFF的模糊测试结果后得出后验概率，模糊器BFF总是在模糊器Ofuzz之前使用。</li>\n</ul>\n<p>决策规则很简单：如果概率得分高于给定的置信度阈值，则被评估的软件被认为不易受攻击（对于类型16）。图6显示了在不同评估阶段应用决策规则的精确度和召回分数。为了比较，我们还显示了单独使用BFF和Ofuzz的精确度和召回分数。由于模糊测试结果没有误报，我们可以看到单个模糊器在图6（1）中的精度得分始终为1。</p>\n<p><img src=\"/2019/04/08/ExploitMeter-Combining-Fuzzing-with-Machine-Learning-for-Automated-Evaluation-of-Software-Exploitability/6.jpg\" alt=\"\"></p>\n<p>从图6中，我们发现现有方法的性能对置信度阈值敏感。当阈值较低时，该方法始终将新应用程序分类为负数，这会导致调用0和未定义的精度。当阈值超过阳性样本的分数时，该方法倾向于将新应用分类为正，这导致精度降低和具有置信度阈值的召回增加。先前的+ ML方法在看到机器学习的预测结果后，基于后验概率做出决定。该方法的精确度随置信度阈值降低，并且该方法的召回随置信度阈值增加，因为较高置信度阈值导致更多应用被归类为具有相同分类模型的正数。先前的+ ML + BFF方法在看到BFF的模糊测试结果后更新后验概率后作出决定。使用该方法的精度和召回曲线的趋势类似于先前的+ ML方法的趋势。<br>贝叶斯方法有助于在不同的操作环境下进行决策。例如，在军事网络等安全严密的环境中，在应用程序实际部署之前建立对应用程序安全性的高度信任至关重要。在这种情况下，操作员可以使用具有高置信度阈值的先前+ ML方法来查找具有高召回率的易受攻击的应用程序;然而，高置信度阈值也导致高误报率（即，低精度），并且操作员需要对机器学习模型检测到为正的那些应用执行更多模糊测试以确保它们不易受攻击。另一方面，具有低误报率容限的普通用户可以使用具有低置信度阈值的先前+ ML方法;但是，用户必须承担使用未被检测到的易受攻击程序的风险。</p>\n<p><img src=\"/2019/04/08/ExploitMeter-Combining-Fuzzing-with-Machine-Learning-for-Automated-Evaluation-of-Software-Exploitability/7.jpg\" alt=\"\"></p>\n<h2 id=\"D-可利用性评分的评估\"><a href=\"#D-可利用性评分的评估\" class=\"headerlink\" title=\"D.可利用性评分的评估\"></a>D.可利用性评分的评估</h2><p>ExploitMeter提供了一个包含各种输入参数的丰富框架。在本节中，我们将评估ExploitMeter如何使用表II中汇总的参数设置评估可利用性分数。对于每个漏洞类型v和每个模糊器z，漏洞类型v的模糊器z的初始检测率被设置为10/12（即，大约83.3％）。此外，对于CERT分类工具分类为EXPLOITABLE，PROBABLY_EXPLOITABLE，PROBABLY_NOT_EXPLOITABLE或UNKNOWN的漏洞类型，其初始可利用性分别设置为80％，60％，10％或1％。在我们的实验中，这些可利用性分数未更新，因为验证发现的每个漏洞的可利用性是耗时的。</p>\n<p>图7（1）显示了ExploitMeter在100个Linux应用程序上按顺序运行后每个应用程序的最终可利用性得分。图中的四条曲线表示每个应用程序在四个不同阶段的可利用性得分：计算先前的信念，从分类模型预测，使用BFF模糊测试，以及使用Ofuzz进行模糊测试。最终的可利用性分数（在使用fuzzer Ofuzz之后）有20个峰值，可利用性分数高于0.6。为了研究分数与表IV中显示的模糊测试结果之间的相关性，我们总结了表III中具有高可利用性分数的20个应用程序的列表，以及CERT分类工具中属于每个可利用性类别的漏洞类型的数量。在100个应用程序中，其中19个至少有一个漏洞类型属于EXPLOITABLE类别，只有它们的可利用性分数高于0.8。应用程序qpdfview有两种漏洞类型属于PROBABLY_EXPLOITABLE类别，也导致相对较高的可利用性得分为0.647。因此，最终的可利用性分数与其模糊测试结果高度相关。</p>\n<p> <img src=\"/2019/04/08/ExploitMeter-Combining-Fuzzing-with-Machine-Learning-for-Automated-Evaluation-of-Software-Exploitability/8.jpg\" alt=\"\"></p>\n<p>图7（1）还揭示了从机器学习模型预测的可利用性分数与从模糊测试结果估计的最终值不一致。由于分类性能较差，预计会出现这种情况，如图3所示，这些漏洞属于EXPLOITABLE或PROBABLY_EXPLOITABLE类别。</p>\n<p>图7（2）显示了每个应用程序的平均可利用性得分以及具有随机测试顺序的20个样本运行中的标准偏差。结果发现，对于具有高可利用性分数的20个应用程序，当测试顺序发生变化时，它们的可利用性分数差别很小。这是合理的，因为无论测试顺序如何，一旦发现一种易于利用的漏洞，它就会将评估者对该漏洞类型的后验信念降低为0，从而显着提高其可利用性评分。</p>\n<p><img src=\"/2019/04/08/ExploitMeter-Combining-Fuzzing-with-Machine-Learning-for-Automated-Evaluation-of-Software-Exploitability/9.jpg\" alt=\"\"></p>\n<p>相比之下，评估者基于机器学习模型的预测结果的初始信念更容易改变那些没有发现任何高度可利用漏洞的应用程序的可利用性分数。</p>\n<h1 id=\"VI-结论\"><a href=\"#VI-结论\" class=\"headerlink\" title=\"VI 结论\"></a>VI 结论</h1><p>在这项工作中，我们开发了一个名为ExploitMeter的框架，它将模糊测试与机器学习相结合，以评估软件的可利用性。 ExploitMeter依赖于分类建模来估计基于从静态分析中提取的特征的软件可利用性的初始信念。 ExploitMeter进一步使用动态模糊测试来更新可利用性的信念。 ExploitMeter采用的贝叶斯方法以有机的方式集成了基于机器学习的预测和模糊测试结果。我们将ExploitMeter应用于100个Linux应用程序列表，以深入了解其性能。</p>\n<p>在我们未来的工作中，我们计划提高ExploitMeter中使用的机器学习模型的预测准确性。我们将特别研究以下研究问题：更多的阳性样本是否有助于提高所用机器学习模型的预测准确度？是否有可能找到具有更好预测能力的其他类型的功能？或者，深度学习等新机器学习模型能否提升预测性能？</p>\n<p><img src=\"/2019/04/08/ExploitMeter-Combining-Fuzzing-with-Machine-Learning-for-Automated-Evaluation-of-Software-Exploitability/10.jpg\" alt=\"\"></p>\n","categories":[{"name":"论文","slug":"论文","permalink":"http://yama0xff.com/categories/论文/"},{"name":"fuzzing","slug":"论文/fuzzing","permalink":"http://yama0xff.com/categories/论文/fuzzing/"},{"name":"可利用性判定","slug":"论文/fuzzing/可利用性判定","permalink":"http://yama0xff.com/categories/论文/fuzzing/可利用性判定/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://yama0xff.com/tags/机器学习/"},{"name":"2017年","slug":"2017年","permalink":"http://yama0xff.com/tags/2017年/"},{"name":"可利用性判定","slug":"可利用性判定","permalink":"http://yama0xff.com/tags/可利用性判定/"}]},{"title":"Experimenting machine learning techniques to predict vulnerabilities","date":"2019-04-08T01:43:42.000Z","path":"2019/04/08/Experimenting-machine-learning-techniques-to-predict-vulnerabilities/","text":"Abstract软件度量标准可用作软件漏洞存在的指示器。这些指标已用于机器学习，以预测容易包含漏洞的源代码。虽然无法找到缺陷的确切位置，但模型可以显示在检查和测试期间哪些组件需要更多关注。每种新技术都使用他自己的评估数据集，该数据集多次具有有限的大小和代表性。在此体验报告中，我们使用大型且具有代表性的数据集来评估几种最先进的漏洞预测技术。该数据集是使用来自五个广泛使用的开源项目的2186个漏洞的信息构建的。结果表明，数据集可用于区分哪种是最佳技术。还表明，一些技术可以预测几乎所有数据集中存在的漏洞，尽管精度非常低。最后，准确性，精确度和召回率并不是表征这种工具有效性的最有效方法。关键词 - 机器学习，软件度量，软件安全，漏洞 relevant information 作者 Henrique Alves, Baldoino Fonseca,Nuno Antunes 单位 Instituto de Computac¸ao Universidade Federal de Alagoas;CISUC, Department of Informatics Engineering University of Coimbra 出处 7th Latin-American Symposium on Dependable Computing 原文地址 https://ieeexplore.ieee.org/document/7781850 数据集地址 https://eden.dei.uc.pt/~nmsa/metrics-dataset/index.html 发表时间 2016年 1. 简介软件漏洞代表了当今软件开发人员最头疼的问题之一。正在开发的大多数软件都以某种方式暴露给外部用户，这些用户迟早会试图利用恶意的方式利用它。即使在软件安全方面投入了大量精力，攻击仍然经常发生，每年的财务损失达到2260亿美元[1]。更糟糕的是，软件的大小和复杂性的增加加剧了这个问题。 开发安全代码是一项艰巨而昂贵的任务，需要花费大量时间。软件工程师有许多技术可以找到这些缺陷和漏洞，但众所周知，最有效的技术通常需要大量的时间和专业资源。代码检查和测试等技术是发现漏洞的有效且被广泛接受的方法，但这些方法有其局限性。代码审查和检查[2]被认为是减少错误数量的非常有效的方法，但众所周知，它们的成本限制了它们在大型工件中的适用性。即使测试虽然更容易和更便宜，但可能会导致测试代码多于其自己的系统代码，以覆盖整个系统代码。随着系统规模的增长变得越来越昂贵，以满足提供高度信任的严格覆盖要求[2]。为了解决这个问题，开发人员试图将精力集中在系统中最棘手的部分。 虽然识别系统中最有问题的部分是一个有趣且有效的解决方案，但执行此分析的标准可能是多样化和混乱的。诸如[3]，[4]，[5]，[6]等研究已经研究了这种可能性，并使用了几种与机器学习技术相结合的软件度量来完成这项活动。很明显，没有代码生而平等且具有不同的特征。这些工作表明，这些功能可以区分代码中漏洞的存在（最近的一项研究证实[7]）。 在这项工作中，我们感兴趣的是代表代码静态属性的软件度量。代码执行和代码流失度量标准不在范围之内。现有工作使用不同的配置和方法呈现不同的结果，并考虑不同的度量集。例如。虽然在[8]中使用了9个软件度量来构建预测模型，但在[9]中使用了17个软件度量。此外，还有各种各样的机器学习技术，通过这些技术，文章可以更频繁地使用某些技术，并且每种技术都支持基于其中任何一种的特定结果。我们意识到最常见的是朴素贝叶斯，决策树，随机森林和逻辑回归。 在这种情况下，很难比较这些工作并选择最适合每种利用方案的工作。此外，每项工作中提供的评估结果并不是评估其有效性的非常有用的方法，主要有两个原因[7] :( i）每项工作都使用特定的数据集来进行评估; （ii）使用的数据集具有有限的代表性[7]。 该实践经验报告提供了一项比较研究，以评估现有方法预测C / C ++软件项目漏洞的有效性。该研究基于一个大型数据集[7]，其中包含有关函数和文件的软件度量的信息，以及从安全角度来看五个项目中是否存在安全漏洞，因为它们被广泛使用并暴露于攻击。使用此数据集，可以评估第三方工作中呈现的预测模型的有效性。我们复制了六项研究中提出的方法，这些研究涉及基于软件指标预测软件漏洞。 此篇文章的结构如下。第二节介绍了进行的研究。第三节介绍并讨论了取得的成果。第四部分回顾了相关工作，第五部分讨论了对本研究有效性的潜在威胁，第六部分总结了论文。 II.研究本研究提出了在C / C ++软件环境下脆弱性预测方法有效性的实验评估。主要目标是从文献中提出的方法中了解哪些方法能够产生更好的模型来预测脆弱性。在实践中，该研究试图回答以下问题： 生成的模型于预测易受攻击的文件并避免误报有多好用？ 在这种环境中哪些技术表现更好？ 表征方法有效性的最佳指标是什么？ 为了回答这个问题，我们设计了一种基于五个关键组件的方法，如图1所示。以下小节将讨论这些组件中的每一个。 A. 数据集评估中使用的数据集在[7]中给出，可以从[10]下载。它包含有关函数和文件的软件度量标准以及是否存在安全漏洞的信息。表I列出了数据集中的数据摘要。我们可以观察到，数据集是基于2186安全补丁和相应源存储库的4372个快照构建的：1对应于紧接在补丁之前的提交，1对应于紧随其后的提交。 此数据集包含有关函数，文件的软件度量以及是否存在安全漏洞的信息。这些信息是针对五个开源项目收集的：Mozilla Firefox，Linux内核，Xen Hypervisor，Httpd和Glibc。这些项目具有良好的安全性，是区分漏洞的良好选择，因为它们是不同领域的项目。 Mozilla是一个Web浏览器，Linux内核是操作系统内核，Xen是虚拟器环境，Httpd是通信协议，Glibc是用C编写的系统调用库。最后，如图II-A所示，与中性代码相比，易受攻击代码的百分比非常低。 B.测试主题平衡和验证在这种工作中预计会出现差异，因为预计在这种数据集中，易受攻击的实例的数量远远小于非易受攻击的实例的数量。因此，针对此类任务的所有方法都需要执行数据平衡。评估的方法涉及称为随机欠采样（RU）的平衡技术，移除随机选择的多数类数据。选定的比例是直到多数类中的数据实例数与少数类的数相同。同样重要的是要强调的是，不同的方法对结果交叉验证使用不同的策略。在某些情况下，它使用了10倍交叉验证（[9]），而在其他情况下，这种重复使用重复10次，命名为10x10倍验证[6]，[11]。最后，一些案例使用下一个版本验证（Release-fold），其中模型使用以前的版本进行训练，并使用下一个版本进行测试[5]，[12]。这些配置总结在表II的配置列中。 C.评估方法在我们的研究中评估的方法来自已发布的工作，这些作品使用软件度量来构建预测模型，以找到具有更高可能性的漏洞的文件。 在[12]中提出了使用九种代码复杂度指标的案例研究。该方法提交来自Mozilla模块训练预测模型的逻辑回归数据。他们的结果表明，复杂度指标能够识别最容易出现漏洞的区域，但是，这种方法仍需要改进，因为结果显示低误报率和高假阴性率。 类似地，在[9]中使用了17个软件度量来训练预测模型，其中7个特定于面向对象语言。作者使用四台机器避免了最大限度，因为它们代表了不再关注模型的易受攻击的代码。 E.方法有效性的指标在我们的分析过程中，我们使用下面提供的一组指标来表征这些方法的有效性。这些指标是根据实验期间获得的基本测量值计算的：真阳性（TP）;误报（FP）;真阴性（TN）;和漏报（FN）。 准确度（1）表示正确分类的案例与总案例之间的比例。误报率（fpr）（2）表示错误预测的文件与实际中性文件易受攻击的比率。高fpr显示模型将许多实例作为误报返回给开发人员。$$accuracy = \\cfrac{T P + T N}{T P + F N + T N + F P}$$ $$fpr = \\cfrac{F P}{T N + F P}$$ 我们还使用了长期用于表征系统有效性的指标，特别是在信息检索领域。精度（3）表示正确预测的易受攻击文件与检测到的所有文件的比率。Recall（4）描述了模型正确预测为易受攻击的真实易受攻击文件的百分比。也称为真阳性率，它与模型如何覆盖易受攻击的实例有关。最后，FMeasure（5），也称为F1Score，代表精度和召回的调和平均值。$$precision = \\cfrac{T P}{T P + F P}$$ $$recall = \\cfrac{T P}{T P + F N} = tpr$$ $$FMeasure = 2 \\cfrac{precision recall}{precision + recall} = F_1Score$$ 虽然这些指标解决了不同的问题，但所有这些指标都存在一些可能影响其有用性和代表性的偏见[14]：1）阳性样例的患病率; 2）模型的偏差; 3）倾斜; 4）成本比率。这些偏见促使我们在分析中包含不同的指标。 受到博彩公司赔率[15]的启发，提出了无偏见的指标来表征考虑分类比例的预测因子的有效性，类似于投注赔率。Bookmaker Informedness（6）描述了预测因子的有效性，考虑了结果比例的测量。它量化了预测变量预测结果的一致程度，即预测变量对指定条件的信息与机会的相关性。另一方面，Markedness（7）量化了结果将预测变量作为标记的一致性，即指定预测变量的条件与机会的标记程度。$$Informedness = \\cfrac{T P}{T P + F N} - \\cfrac{F P}{T N + F P}$$ $$Markedness = \\cfrac{T P}{T P + F P} - \\cfrac{F N}{T N + F N}$$ III.结果和讨论在平衡数据集中应用论文的方法，我们得到了表III中的结果。我们可以观察到，取得的成果差异很大。精度值范围为0.32％至30.50％，召回值范围为0.36％至100.00％。 通过使用决策树算法的方法获得了精确度方面的最佳结果。 Logistic回归在recall方面呈现出最佳结果，但在精确度方面表现非常糟糕，这降低了报告实例的可信度。重要的是要注意该方法可以配置和调整，即配置要使用的阈值，但由于缺乏信息，我们使用了Weka的默认配置。 精确度度量的结果对于描述这些技术的有效性似乎并不十分有用。我们可以观察到，许多技术的准确度高于50％，除了7个案例从7.59％到45.33％不等，3个案例等于0.52％。然而，其中许多案例的精确度不到1％。精确度量提供的结果也没那么有用，因为它们专注于误报并完全忽略漏报。如果模型过于专注于避免误报，那么它最终会报告少量的真阳性。标记是一个更完整的指标，因为它也认为是假阴性。 我们可以清楚地看到，大多数方法的精度值非常低。这是因为学习模型报告的误报太多，因为他们使用平衡数据集进行训练，但随后使用不平衡数据集进行测试。这种不平衡的数据集具有更多中性实例，其中一些最终报告为易受攻击。 三种方法实现了100％的召回，另外六种方法实现了超过80％的召回。虽然这看起来非常令人印象深刻，但当我们考虑到机会以及假阳性和真阴性的分布时，我们理解结果并不像第一眼看上去那么好。事实上，没有一种方法达到Informedness值高于45％。这表明，在某些情况下，召回可能是误导性的指标。 由于精确度和召回率的这种限制，我们决定使用度量informedness 和markedness 对技术进行更详细的分析，这些分析不会受到偏差的影响。图3显示了这两个指标的所有方法的结果摘要。 第一个观察结果是树的方法在informedness 方面明显优于其他方法：23,24,27。正如我们所看到的，方法6,7,8显然远离这些树方法，尽管它们呈现出更高的recall比那些方法。事实上，只比较informedness 值，我们可以看到，在（4,6,7,8,26）中考虑了一系列机会非常差的方法。如上所述，虽然这些方法似乎具有非常高的召回率，但实际上这种高召回率是由于所产生的模型报告的事件比其余方法更为积极，导致误报过多。 IV 相关工作I软件度量已被多次使用，以训练有效预测故障的预测模型[16]，[17]，[18]。虽然圈复杂度受到了很多关注，但其他指标也与理解代码有关。例如，有一段时间讨论了哪个是“最具预测性”的指标：Cyclomatic Complexity或LoC数量[18]。我们认为，在安全漏洞的情况下，这些指标与具有报告漏洞的代码之间存在某种关系。下面我们回顾一下这些工作并讨论它们的优点和缺点。 一些工作集中评估和比较不同的技术。对于实际情况，将使用文本挖掘技术获得的结果与基于软件度量的方法进行比较，如[13]中所述。这些实验基于三个开源php项目的223个漏洞：Drupal，Moodle和PHPMyAdmin。在所有三种应用中，文本挖掘模型具有比软件度量更高的召回率。但是，使用的数据集具有明显的代表性问题 鉴于CCC指标在识别漏洞方面显示的有趣结果，[9]提出了一个框架，通过使用CCC指标和现有的机器学习技术自动预测漏洞。通过对Mozilla Firefox进行实证研究并使用四个预测器C4.5决策树，随机森林，Logistic回归和Naive Bayes来验证所提出的方法。结果表明，这些预测器能够预测与Mozilla Firefox中的文件相关的大部分漏洞。[19]中的工作提供了几种机器学习方法的比较分析，其中哪些方法在检测代码气味方面更有效。基于手动验证的数据集，在总共16种算法中包括若干技术和配置。在检测代码气味时，一些技术的准确度高于96％，使用决策树和随机森林算法可以获得最佳结果。 V.对有效性的威胁实验的有效性受到以下威胁：T1）并非所有方法的配置都可用，不能保证实验在理想条件下再现。 T2）数据集包含报告的漏洞，因此可能存在从未识别的易受攻击的代码。 T3）最后的威胁是，这些方法中的某些方法是针对不同语言提出的，而不是数据集代码：C / C ++。 VI. 结论本实践经验报告对基于软件指标的18种最先进的漏洞预测方法进行了评估。此评估基于一个大型且具有代表性的数据集，该数据集构建了五个广泛使用的开源项目中2875个漏洞的信息。 有可能观察到这样的传统指标，如准确性在这种情况下可能不是很有用，而且即使使用平衡数据集，精度和召回也可能略有误导。另一方面，诸如informedness 和markedness 等指标更有效。 结果表明，一些方法明显优于其他方法，随机森林实施在所考虑的所有指标中都取得了非常高的结果。未来的工作包括根据所考虑的语言扩大该分析的范围，以及脆弱性预测算法的基准程序提案","content":"<h1 id=\"Abstract\"><a href=\"#Abstract\" class=\"headerlink\" title=\"Abstract\"></a>Abstract</h1><p>软件度量标准可用作软件漏洞存在的指示器。这些指标已用于机器学习，以预测容易包含漏洞的源代码。虽然无法找到缺陷的确切位置，但模型可以显示在检查和测试期间哪些组件需要更多关注。每种新技术都使用他自己的评估数据集，该数据集多次具有有限的大小和代表性。在此体验报告中，我们使用大型且具有代表性的数据集来评估几种最先进的漏洞预测技术。该数据集是使用来自五个广泛使用的开源项目的2186个漏洞的信息构建的。结果表明，数据集可用于区分哪种是最佳技术。还表明，一些技术可以预测几乎所有数据集中存在的漏洞，尽管精度非常低。最后，准确性，精确度和召回率并不是表征这种工具有效性的最有效方法。<br>关键词 - 机器学习，软件度量，软件安全，漏洞</p>\n<table>\n<thead>\n<tr>\n<th>relevant information</th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><em>作者</em></td>\n<td>Henrique Alves, Baldoino Fonseca,Nuno Antunes</td>\n</tr>\n<tr>\n<td><em>单位</em></td>\n<td>Instituto de Computac¸ao Universidade Federal de Alagoas;CISUC, Department of Informatics Engineering University of Coimbra</td>\n</tr>\n<tr>\n<td><em>出处</em></td>\n<td>7th Latin-American Symposium on Dependable Computing</td>\n</tr>\n<tr>\n<td><em>原文地址</em></td>\n<td><a href=\"https://ieeexplore.ieee.org/document/7781850\" target=\"_blank\" rel=\"noopener\">https://ieeexplore.ieee.org/document/7781850</a></td>\n</tr>\n<tr>\n<td><em>数据集地址</em></td>\n<td><a href=\"https://eden.dei.uc.pt/~nmsa/metrics-dataset/index.html\" target=\"_blank\" rel=\"noopener\">https://eden.dei.uc.pt/~nmsa/metrics-dataset/index.html</a></td>\n</tr>\n<tr>\n<td><em>发表时间</em></td>\n<td>2016年</td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"1-简介\"><a href=\"#1-简介\" class=\"headerlink\" title=\"1. 简介\"></a>1. 简介</h1><p>软件漏洞代表了当今软件开发人员最头疼的问题之一。正在开发的大多数软件都以某种方式暴露给外部用户，这些用户迟早会试图利用恶意的方式利用它。即使在软件安全方面投入了大量精力，攻击仍然经常发生，每年的财务损失达到2260亿美元[1]。更糟糕的是，软件的大小和复杂性的增加加剧了这个问题。</p>\n<p>开发安全代码是一项艰巨而昂贵的任务，需要花费大量时间。软件工程师有许多技术可以找到这些缺陷和漏洞，但众所周知，最有效的技术通常需要大量的时间和专业资源。代码检查和测试等技术是发现漏洞的有效且被广泛接受的方法，但这些方法有其局限性。代码审查和检查[2]被认为是减少错误数量的非常有效的方法，但众所周知，它们的成本限制了它们在大型工件中的适用性。即使测试虽然更容易和更便宜，但可能会导致测试代码多于其自己的系统代码，以覆盖整个系统代码。随着系统规模的增长变得越来越昂贵，以满足提供高度信任的严格覆盖要求[2]。为了解决这个问题，开发人员试图将精力集中在系统中最棘手的部分。</p>\n<p>虽然识别系统中最有问题的部分是一个有趣且有效的解决方案，但执行此分析的标准可能是多样化和混乱的。诸如[3]，[4]，[5]，[6]等研究已经研究了这种可能性，并使用了几种与机器学习技术相结合的软件度量来完成这项活动。很明显，没有代码生而平等且具有不同的特征。这些工作表明，这些功能可以区分代码中漏洞的存在（最近的一项研究证实[7]）。</p>\n<p>在这项工作中，我们感兴趣的是代表代码静态属性的软件度量。代码执行和代码流失度量标准不在范围之内。现有工作使用不同的配置和方法呈现不同的结果，并考虑不同的度量集。例如。虽然在[8]中使用了9个软件度量来构建预测模型，但在[9]中使用了17个软件度量。此外，还有各种各样的机器学习技术，通过这些技术，文章可以更频繁地使用某些技术，并且每种技术都支持基于其中任何一种的特定结果。我们意识到最常见的是朴素贝叶斯，决策树，随机森林和逻辑回归。</p>\n<p>在这种情况下，很难比较这些工作并选择最适合每种利用方案的工作。此外，每项工作中提供的评估结果并不是评估其有效性的非常有用的方法，主要有两个原因[7] :( i）每项工作都使用特定的数据集来进行评估; （ii）使用的数据集具有有限的代表性[7]。</p>\n<p>该实践经验报告提供了一项比较研究，以评估现有方法预测C / C ++软件项目漏洞的有效性。该研究基于一个大型数据集[7]，其中包含有关函数和文件的软件度量的信息，以及从安全角度来看五个项目中是否存在安全漏洞，因为它们被广泛使用并暴露于攻击。使用此数据集，可以评估第三方工作中呈现的预测模型的有效性。我们复制了六项研究中提出的方法，这些研究涉及基于软件指标预测软件漏洞。</p>\n<p>此篇文章的结构如下。第二节介绍了进行的研究。第三节介绍并讨论了取得的成果。第四部分回顾了相关工作，第五部分讨论了对本研究有效性的潜在威胁，第六部分总结了论文。</p>\n<h1 id=\"II-研究\"><a href=\"#II-研究\" class=\"headerlink\" title=\"II.研究\"></a>II.研究</h1><p>本研究提出了在C / C ++软件环境下脆弱性预测方法有效性的实验评估。主要目标是从文献中提出的方法中了解哪些方法能够产生更好的模型来预测脆弱性。在实践中，该研究试图回答以下问题：</p>\n<ul>\n<li><p>生成的模型于预测易受攻击的文件并避免误报有多好用？</p>\n</li>\n<li><p>在这种环境中哪些技术表现更好？</p>\n</li>\n<li><p>表征方法有效性的最佳指标是什么？</p>\n</li>\n</ul>\n<p>为了回答这个问题，我们设计了一种基于五个关键组件的方法，如图1所示。以下小节将讨论这些组件中的每一个。</p>\n<p><img src=\"/2019/04/08/Experimenting-machine-learning-techniques-to-predict-vulnerabilities/1.jpg\" alt=\"\"></p>\n<h2 id=\"A-数据集\"><a href=\"#A-数据集\" class=\"headerlink\" title=\"A. 数据集\"></a>A. 数据集</h2><p>评估中使用的数据集在[7]中给出，可以从[10]下载。它包含有关函数和文件的软件度量标准以及是否存在安全漏洞的信息。表I列出了数据集中的数据摘要。我们可以观察到，数据集是基于2186安全补丁和相应源存储库的4372个快照构建的：1对应于紧接在补丁之前的提交，1对应于紧随其后的提交。</p>\n<p><img src=\"/2019/04/08/Experimenting-machine-learning-techniques-to-predict-vulnerabilities/2.jpg\" alt=\"table 1\"></p>\n<p>此数据集包含有关函数，文件的软件度量以及是否存在安全漏洞的信息。这些信息是针对五个开源项目收集的：Mozilla Firefox，Linux内核，Xen Hypervisor，Httpd和Glibc。这些项目具有良好的安全性，是区分漏洞的良好选择，因为它们是不同领域的项目。 Mozilla是一个Web浏览器，Linux内核是操作系统内核，Xen是虚拟器环境，Httpd是通信协议，Glibc是用C编写的系统调用库。<br>最后，如图II-A所示，与中性代码相比，易受攻击代码的百分比非常低。</p>\n<p><img src=\"/2019/04/08/Experimenting-machine-learning-techniques-to-predict-vulnerabilities/3.jpg\" alt=\"fig 2\"></p>\n<h2 id=\"B-测试主题平衡和验证\"><a href=\"#B-测试主题平衡和验证\" class=\"headerlink\" title=\"B.测试主题平衡和验证\"></a>B.测试主题平衡和验证</h2><p>在这种工作中预计会出现差异，因为预计在这种数据集中，易受攻击的实例的数量远远小于非易受攻击的实例的数量。因此，针对此类任务的所有方法都需要执行数据平衡。<br>评估的方法涉及称为随机欠采样（RU）的平衡技术，移除随机选择的多数类数据。选定的比例是直到多数类中的数据实例数与少数类的数相同。<br>同样重要的是要强调的是，不同的方法对结果交叉验证使用不同的策略。在某些情况下，它使用了10倍交叉验证（[9]），而在其他情况下，这种重复使用重复10次，命名为10x10倍验证[6]，[11]。最后，一些案例使用下一个版本验证（Release-fold），其中模型使用以前的版本进行训练，并使用下一个版本进行测试[5]，[12]。这些配置总结在表II的配置列中。</p>\n<p><img src=\"/2019/04/08/Experimenting-machine-learning-techniques-to-predict-vulnerabilities/4.jpg\" alt=\"\"></p>\n<h2 id=\"C-评估方法\"><a href=\"#C-评估方法\" class=\"headerlink\" title=\"C.评估方法\"></a>C.评估方法</h2><p>在我们的研究中评估的方法来自已发布的工作，这些作品使用软件度量来构建预测模型，以找到具有更高可能性的漏洞的文件。</p>\n<p>在[12]中提出了使用九种代码复杂度指标的案例研究。该方法提交来自Mozilla模块训练预测模型的逻辑回归数据。他们的结果表明，复杂度指标能够识别最容易出现漏洞的区域，但是，这种方法仍需要改进，因为结果显示低误报率和高假阴性率。</p>\n<p>类似地，在[9]中使用了17个软件度量来训练预测模型，其中7个特定于面向对象语言。作者使用四台机器避免了最大限度，因为它们代表了不再关注模型的易受攻击的代码。</p>\n<h2 id=\"E-方法有效性的指标\"><a href=\"#E-方法有效性的指标\" class=\"headerlink\" title=\"E.方法有效性的指标\"></a>E.方法有效性的指标</h2><p>在我们的分析过程中，我们使用下面提供的一组指标来表征这些方法的有效性。这些指标是根据实验期间获得的基本测量值计算的：真阳性（TP）;误报（FP）;真阴性（TN）;和漏报（FN）。</p>\n<p>准确度（1）表示正确分类的案例与总案例之间的比例。误报率（fpr）（2）表示错误预测的文件与实际中性文件易受攻击的比率。高fpr显示模型将许多实例作为误报返回给开发人员。<br>$$<br>accuracy = \\cfrac{T P + T N}{T P + F N + T N + F P}<br>$$</p>\n<p>$$<br>fpr = \\cfrac{F P}{T N + F P}<br>$$</p>\n<p>我们还使用了长期用于表征系统有效性的指标，特别是在信息检索领域。精度（3）表示正确预测的易受攻击文件与检测到的所有文件的比率。Recall（4）描述了模型正确预测为易受攻击的真实易受攻击文件的百分比。也称为真阳性率，它与模型如何覆盖易受攻击的实例有关。最后，FMeasure（5），也称为F1Score，代表精度和召回的调和平均值。<br>$$<br>precision = \\cfrac{T P}{T P + F P}<br>$$</p>\n<p>$$<br>recall = \\cfrac{T P}{T P + F N} = tpr<br>$$</p>\n<p>$$<br>FMeasure = 2 <em> \\cfrac{precision </em> recall}{precision + recall} = F_1Score<br>$$</p>\n<p>虽然这些指标解决了不同的问题，但所有这些指标都存在一些可能影响其有用性和代表性的偏见[14]：1）阳性样例的患病率; 2）模型的偏差; 3）倾斜; 4）成本比率。这些偏见促使我们在分析中包含不同的指标。</p>\n<p>受到博彩公司赔率[15]的启发，提出了无偏见的指标来表征考虑分类比例的预测因子的有效性，类似于投注赔率。Bookmaker Informedness（6）描述了预测因子的有效性，考虑了结果比例的测量。它量化了预测变量预测结果的一致程度，即预测变量对指定条件的信息与机会的相关性。另一方面，Markedness（7）量化了结果将预测变量作为标记的一致性，即指定预测变量的条件与机会的标记程度。<br>$$<br>Informedness =  \\cfrac{T P}{T P + F N} - \\cfrac{F P}{T N + F P}<br>$$</p>\n<p>$$<br>Markedness = \\cfrac{T P}{T P + F P} - \\cfrac{F N}{T N + F N}<br>$$</p>\n<p><img src=\"/2019/04/08/Experimenting-machine-learning-techniques-to-predict-vulnerabilities/6.jpg\" alt=\"table 3\"></p>\n<h1 id=\"III-结果和讨论\"><a href=\"#III-结果和讨论\" class=\"headerlink\" title=\"III.结果和讨论\"></a>III.结果和讨论</h1><p>在平衡数据集中应用论文的方法，我们得到了表III中的结果。我们可以观察到，取得的成果差异很大。精度值范围为0.32％至30.50％，召回值范围为0.36％至100.00％。</p>\n<p>通过使用决策树算法的方法获得了精确度方面的最佳结果。 Logistic回归在recall方面呈现出最佳结果，但在精确度方面表现非常糟糕，这降低了报告实例的可信度。重要的是要注意该方法可以配置和调整，即配置要使用的阈值，但由于缺乏信息，我们使用了Weka的默认配置。</p>\n<p>精确度度量的结果对于描述这些技术的有效性似乎并不十分有用。我们可以观察到，许多技术的准确度高于50％，除了7个案例从7.59％到45.33％不等，3个案例等于0.52％。然而，其中许多案例的精确度不到1％。精确度量提供的结果也没那么有用，因为它们专注于误报并完全忽略漏报。如果模型过于专注于避免误报，那么它最终会报告少量的真阳性。<br>标记是一个更完整的指标，因为它也认为是假阴性。</p>\n<p>我们可以清楚地看到，大多数方法的精度值非常低。这是因为学习模型报告的误报太多，因为他们使用平衡数据集进行训练，但随后使用不平衡数据集进行测试。这种不平衡的数据集具有更多中性实例，其中一些最终报告为易受攻击。</p>\n<p>三种方法实现了100％的召回，另外六种方法实现了超过80％的召回。虽然这看起来非常令人印象深刻，但当我们考虑到机会以及假阳性和真阴性的分布时，我们理解结果并不像第一眼看上去那么好。事实上，没有一种方法达到Informedness值高于45％。这表明，在某些情况下，召回可能是误导性的指标。</p>\n<p>由于精确度和召回率的这种限制，我们决定使用度量informedness 和markedness 对技术进行更详细的分析，这些分析不会受到偏差的影响。图3显示了这两个指标的所有方法的结果摘要。</p>\n<p>第一个观察结果是树的方法在informedness 方面明显优于其他方法：23,24,27。正如我们所看到的，方法6,7,8显然远离这些树方法，尽管它们呈现出更高的recall比那些方法。事实上，只比较informedness 值，我们可以看到，在（4,6,7,8,26）中考虑了一系列机会非常差的方法。如上所述，虽然这些方法似乎具有非常高的召回率，但实际上这种高召回率是由于所产生的模型报告的事件比其余方法更为积极，导致误报过多。</p>\n<p><img src=\"/2019/04/08/Experimenting-machine-learning-techniques-to-predict-vulnerabilities/5.jpg\" alt=\"\"></p>\n<h1 id=\"IV-相关工作\"><a href=\"#IV-相关工作\" class=\"headerlink\" title=\"IV 相关工作\"></a>IV 相关工作</h1><p>I软件度量已被多次使用，以训练有效预测故障的预测模型[16]，[17]，[18]。虽然圈复杂度受到了很多关注，但其他指标也与理解代码有关。例如，有一段时间讨论了哪个是“最具预测性”的指标：Cyclomatic Complexity或LoC数量[18]。我们认为，在安全漏洞的情况下，这些指标与具有报告漏洞的代码之间存在某种关系。下面我们回顾一下这些工作并讨论它们的优点和缺点。</p>\n<p>一些工作集中评估和比较不同的技术。对于实际情况，将使用文本挖掘技术获得的结果与基于软件度量的方法进行比较，如[13]中所述。这些实验基于三个开源php项目的223个漏洞：Drupal，Moodle和PHPMyAdmin。在所有三种应用中，文本挖掘模型具有比软件度量更高的召回率。但是，使用的数据集具有明显的代表性问题</p>\n<p>鉴于CCC指标在识别漏洞方面显示的有趣结果，[9]提出了一个框架，通过使用CCC指标和现有的机器学习技术自动预测漏洞。通过对Mozilla Firefox进行实证研究并使用四个预测器C4.5决策树，随机森林，Logistic回归和Naive Bayes来验证所提出的方法。结果表明，这些预测器能够预测与Mozilla Firefox中的文件相关的大部分漏洞。<br>[19]中的工作提供了几种机器学习方法的比较分析，其中哪些方法在检测代码气味方面更有效。基于手动验证的数据集，在总共16种算法中包括若干技术和配置。在检测代码气味时，一些技术的准确度高于96％，使用决策树和随机森林算法可以获得最佳结果。</p>\n<h1 id=\"V-对有效性的威胁\"><a href=\"#V-对有效性的威胁\" class=\"headerlink\" title=\"V.对有效性的威胁\"></a>V.对有效性的威胁</h1><p>实验的有效性受到以下威胁：T1）并非所有方法的配置都可用，不能保证实验在理想条件下再现。 T2）数据集包含报告的漏洞，因此可能存在从未识别的易受攻击的代码。 T3）最后的威胁是，这些方法中的某些方法是针对不同语言提出的，而不是数据集代码：C / C ++。</p>\n<h1 id=\"VI-结论\"><a href=\"#VI-结论\" class=\"headerlink\" title=\"VI. 结论\"></a>VI. 结论</h1><p>本实践经验报告对基于软件指标的18种最先进的漏洞预测方法进行了评估。此评估基于一个大型且具有代表性的数据集，该数据集构建了五个广泛使用的开源项目中2875个漏洞的信息。</p>\n<p>有可能观察到这样的传统指标，如准确性在这种情况下可能不是很有用，而且即使使用平衡数据集，精度和召回也可能略有误导。另一方面，诸如informedness 和markedness 等指标更有效。</p>\n<p>结果表明，一些方法明显优于其他方法，随机森林实施在所考虑的所有指标中都取得了非常高的结果。<br>未来的工作包括根据所考虑的语言扩大该分析的范围，以及脆弱性预测算法的基准程序提案</p>\n","categories":[{"name":"论文","slug":"论文","permalink":"http://yama0xff.com/categories/论文/"},{"name":"fuzzing","slug":"论文/fuzzing","permalink":"http://yama0xff.com/categories/论文/fuzzing/"},{"name":"评估","slug":"论文/fuzzing/评估","permalink":"http://yama0xff.com/categories/论文/fuzzing/评估/"}],"tags":[{"name":"综述","slug":"综述","permalink":"http://yama0xff.com/tags/综述/"},{"name":"2016年","slug":"2016年","permalink":"http://yama0xff.com/tags/2016年/"},{"name":"评估","slug":"评估","permalink":"http://yama0xff.com/tags/评估/"}]},{"title":"如何做科研","date":"2019-04-04T06:32:22.000Z","path":"2019/04/04/如何做科研/","text":"内容主要分为四个部分：1.科学研究的内涵与外延。2.科学研究的方法与手段。3.博士生如何开展科学工作。4.其它。该内容为上课中从王俊峰教授PPT中记录而来。主要介绍了博士生在读博期间如何做科研的相关问题。 1. 科学研究的内涵与外延1.1 对科学研究的认识相当普遍的看法 开发一个软/硬件系统或平台 解决一个有难度的理论问题 发表了高水平的学术论文 发表了很多篇SCI/EI/ISTP检索的论文 申请了软件登记、发明专利、提交了标准或草案 升职或获得学位 上述看法都是片面的 不是发论文、争名利、混学位 启发性的观点 是发现问题，解决问题的过程 是要做创新的工作 科学研究是多样性的，没有固定的模式 更客观的观点 科学研究是对未知的客观事件认知的过程，加深人类对客观世界的理解，扩展人类对客观事件的利用、改造和适应的能力。 1.2 科学研究的目的和意义解决实际存在的问题（第一阶段） 发现需求和问题是进行科学研究的前提条件 利用、改造和适应客观世界 探索未知的领域（第二阶段） 从未知到已知 1.3 科学研究成果主要研究成果 最有价值的是思想 思想的交流 研究成果的载体 学术论文、研究报告、专著、专利、奖励 只能从一个侧面反映所获得研究成果和思想体会 现状 学术论文是研究成果的主要窄体 学术论文是获得博士学位的前提条件 2. 科学研究的方法与手段2.1 科学研究的一般过程 – 提出问题发现问题 科研工作中发现问题是最重要的步骤 问题或需求驱动研究 一流高手提问题、二流高手解问题、三流高手做习题 如何发现问题 在打的研究方向上需要经验 那些已清除定义的问题，往往研究空间很小，且难度也大 从实际工作中发现问题，从综述中凝练问题，从前人工作不总中挖掘问题 问题的抽象 不能只见树木，不见森林，跳出问题看问题 2.2 科学研究的一般过程 – 分析问题在解决问题之前，需要对问题有准确的定义 理清问题的来龙去脉 给出问题的清晰定义，深入理解问题 问题的分析要“言之有理”，“言之有物” “分而治之”的分析方法 将无从下手的大问题分解成具体的小问题 “细分”与“专业化”是科学研究的重要发展 在“细分”的过程中发现研究的机会 注意联系的思想 注意学科交叉、方法借鉴 注意问题背后的假设与场景 假设与场景往往是问题存在的基石和前提条件 假设与场景的变化往往是影响问题的内涵，产生新的问题 问题的分析是个迭代的过程2.3 科学研究的一般过程 – 解决问题分清主次，抓住重点 人的精力是有限的，不可能解决所有问题，彻底解决一个问题的可能性也不大 列出所有涉及的问题，按重要程度进行排序 列出正在解决问题所设计的关键技术，逐个攻关 博士生研究工作应是系统的，研究的问题应是相关的 先解决简单问题，积累经验后再解决复杂问题 解决同样的问题，往往有很多思路，不应满足于一种思路 解决同样的问题，不同的思路或方法往往存在折中，找一种完美的方法对博士生来说可能是危险的 针对一种解决问题的思路，往往鱼与熊掌不可兼得 3. 博士生如何开展科学工作3.1 博士生培养一般过程 阶段 事情 时间流程（月，总共3年） 1 课程 10个月 2 选课 3 文献调研 4 科研设计 5 开题报告 15个月 6 科研工作 7 中期检查 8 整理资料 9 撰写论文 31个月 10 论文答辩 33个月 11 学位委员会审议 12 授予学位 34个月 3.2 博士生的心态典型心态 茫然型：两眼一抹黑 躁动型：有感兴趣的研究方向，但无从下手 试探型：在做具体工作，不知能否做出成果 春风得意型：取得部分研究成果 失落型 古今之成大事业、大学问者，必经过三种之境界 昨夜西风凋碧树，独上高楼，望尽天涯路。（晏殊） 衣带渐宽终不悔，为伊消得人憔悴。（柳永） 众里寻他千百度，蓦然回首，那人却在，灯火阑珊处。（辛弃疾） 3.3 如何选题 – 课题的来源导师的项目 科研项目：重点研发计划，NSFC，国防预研基金 开发项目：重大工程装备项目 横向委托：企业委托的一般开发项目 个人兴趣 通过个人工作积累，提炼出研究方向 延续硕士期间工作 突发灵感的研究方向，奇思妙想 跟风 人做亦做 无病呻吟 3.4 如何定题 导师的科研项目：一般选题比较先进，有较大可能在较短时间内有做出成果，认可度高 导师的重大开发项目：应结合国家或行业重大应用提炼问题，有较大可能在短期内得到应用推广，认可程度高 通过个人积累或延续前期工作，也有望在较短时间内做出程度，认可程度较高 横向委托项目：一般不宜作为博士生的选题方向，采用成熟的技术，不侧重与理论或技术上创新，风险较大 跟风选题：认可程度高，具体方向需要提炼，风险大 突发灵感的选题：看运气 3.5 如何查资料 – SCI、EI、ISTP 科学引文索引：SCI, Science Citation Index 工程索引：EI, Engineering Index 科技会议论文集索引：ISTP, Index to Scientific &amp; Technical PRoceedings 国内电子信息类 中国科学E辑 中国科学E辑，英文版 JCST 电子学报英文版 计算机学报英文版 软件学报 计算机研究与发展 通信学报 系统工程与电子学英文版 航空学报英文版 几个高校学报 重要的外文全文数据库 ACM(美国计算机学会)Digital Library IEL (IEEE/IEE E;ectronic Library) Elsevier SDOS Springer- Link Kluwer Online Journals Wiley InrerScience WorldSciNet ISI Web of Science//档次稍微低点 EI Village//档次稍微低点 PQDD·B（博硕士论文网络数据库）//档次稍微低点 好的习惯 建立本领域主流期刊、重要会议、主要科研团队和知名专家数据库 订阅期刊目录（Table of Contents）邮件列表 定期浏览主流刊物主页，了解感兴趣研究论文摘要 关注本领域主要国际会议的Conference Program 定期了解主流科研团队和专家的科研进展，科研重点，Survey或Keynote Speech、 3.6 如何阅读文献 – 自上而下的方法阅读文献的两种目的 已有具体研究问题，通过阅读文献找到解决方法 无具体研究问题，通过阅读文献来找问题 从Survey , Review, the State of the Art, Tutorial入手 Google、Google Scholar IEEE COMM Survey &amp;Tutorial 期刊或会议中Related Work 泛读为主 侧重于摘要、前言与结论 广度优先 针对一个具体问题，看20-30篇密切相关的文献 论文太多，无法聚焦 针对3-5篇文献，精度，深度优先 带着问题看文献 能解决自己所遇到的问题？ 哪些问题不能解决？ … 挑剔的眼光看文献 在新的应用背景下的自适应新如何？ 方法或技术效率如何？ 3.7 开展具体研究工作 因学科领域不同而不同 因人而异 研究过程本身无统一标准 研究过程无优劣之分 4. 其它4.1 朴素的博士生科研工作观 要踏踏实实，勤勤恳恳，甚至默默无闻；不要指望做明星 要循序渐进，一步登天可能性不大 要学会从事本领域科研工作的基本技能，先做实干家，在做指挥家 不要经常师徒去颠覆经典理论，时间有限，又开创新理论可能时先与导师沟通 不要在自己的研究成果中严厉地批评他人的成果，更不能人生攻击，就事论事，宜委婉 不要挑剔所从事的科研项目优劣，导师也在探索过程中，博士生是科研的主力军 不以物喜，不以己悲（范仲淹） 4.2 数学基础很重要？ 数学基础和能力比较重要 数学基础不是影响博士生研究工作质量的主要因素，更不是罪关键因素 时间有限，不要无的放矢的学数学 带着问题补充相关的数学基础 对论文中所采用的新颖数学方法要有敏感、博闻 经常泛读相关的数学书 4.3 英语很重要？ 英语基础和写作能力比较重要 时间有限，不要无的放矢的学英语 通过阅读专业文献学英语 英语写作要学会模范，但不是抄袭 不要以应对英语写作的方式写英文报告或论文 不要卖弄英语文发，少使用长句，不使用生僻词 4.4 基本技能要掌握 至少要精通word,有条件学习LaTex 至少要使用好一种绘图工具 至少要使用好一种仿真工具（计算机网络领域，其它未知） 4.5 结束语 博士生阶段做什么具体课题是次要的，重要的是一种训练过程和思考问题的方法 博士生阶段是最艰苦的阶段之一，是最值得怀恋的经历之一","content":"<p>内容主要分为四个部分：1.科学研究的内涵与外延。2.科学研究的方法与手段。3.博士生如何开展科学工作。4.其它。该内容为上课中从王俊峰教授PPT中记录而来。主要介绍了博士生在读博期间如何做科研的相关问题。</p>\n<h1 id=\"1-科学研究的内涵与外延\"><a href=\"#1-科学研究的内涵与外延\" class=\"headerlink\" title=\"1. 科学研究的内涵与外延\"></a>1. 科学研究的内涵与外延</h1><h2 id=\"1-1-对科学研究的认识\"><a href=\"#1-1-对科学研究的认识\" class=\"headerlink\" title=\"1.1 对科学研究的认识\"></a>1.1 对科学研究的认识</h2><h4 id=\"相当普遍的看法\"><a href=\"#相当普遍的看法\" class=\"headerlink\" title=\"相当普遍的看法\"></a>相当普遍的看法</h4><ul>\n<li>开发一个软/硬件系统或平台</li>\n<li>解决一个有难度的理论问题</li>\n<li>发表了高水平的学术论文</li>\n<li>发表了很多篇SCI/EI/ISTP检索的论文</li>\n<li>申请了软件登记、发明专利、提交了标准或草案</li>\n<li>升职或获得学位</li>\n</ul>\n<h4 id=\"上述看法都是片面的\"><a href=\"#上述看法都是片面的\" class=\"headerlink\" title=\"上述看法都是片面的\"></a>上述看法都是片面的</h4><ul>\n<li>不是发论文、争名利、混学位</li>\n</ul>\n<h4 id=\"启发性的观点\"><a href=\"#启发性的观点\" class=\"headerlink\" title=\"启发性的观点\"></a>启发性的观点</h4><ul>\n<li>是<strong>发现问题，解决问题</strong>的过程</li>\n<li>是<strong>要做创新的工作</strong></li>\n<li>科学研究是<strong>多样性的</strong>，没有固定的模式</li>\n</ul>\n<h4 id=\"更客观的观点\"><a href=\"#更客观的观点\" class=\"headerlink\" title=\"更客观的观点\"></a>更客观的观点</h4><ul>\n<li>科学研究是对未知的客观事件认知的过程，加深人类对客观世界的理解，扩展人类对客观事件的利用、改造和适应的能力。</li>\n</ul>\n<h2 id=\"1-2-科学研究的目的和意义\"><a href=\"#1-2-科学研究的目的和意义\" class=\"headerlink\" title=\"1.2 科学研究的目的和意义\"></a>1.2 科学研究的目的和意义</h2><h4 id=\"解决实际存在的问题（第一阶段）\"><a href=\"#解决实际存在的问题（第一阶段）\" class=\"headerlink\" title=\"解决实际存在的问题（第一阶段）\"></a>解决实际存在的问题（第一阶段）</h4><ul>\n<li>发现需求和问题是进行科学研究的前提条件</li>\n<li>利用、改造和适应客观世界</li>\n</ul>\n<h4 id=\"探索未知的领域（第二阶段）\"><a href=\"#探索未知的领域（第二阶段）\" class=\"headerlink\" title=\"探索未知的领域（第二阶段）\"></a>探索未知的领域（第二阶段）</h4><ul>\n<li>从未知到已知</li>\n</ul>\n<h2 id=\"1-3-科学研究成果\"><a href=\"#1-3-科学研究成果\" class=\"headerlink\" title=\"1.3 科学研究成果\"></a>1.3 科学研究成果</h2><h4 id=\"主要研究成果\"><a href=\"#主要研究成果\" class=\"headerlink\" title=\"主要研究成果\"></a>主要研究成果</h4><ul>\n<li>最有价值的是思想</li>\n<li>思想的交流</li>\n</ul>\n<h4 id=\"研究成果的载体\"><a href=\"#研究成果的载体\" class=\"headerlink\" title=\"研究成果的载体\"></a>研究成果的载体</h4><ul>\n<li>学术论文、研究报告、专著、专利、奖励</li>\n<li>只能从一个侧面反映所获得研究成果和思想体会</li>\n</ul>\n<h4 id=\"现状\"><a href=\"#现状\" class=\"headerlink\" title=\"现状\"></a>现状</h4><ul>\n<li>学术论文是研究成果的主要窄体</li>\n<li>学术论文是获得博士学位的前提条件</li>\n</ul>\n<hr>\n<h1 id=\"2-科学研究的方法与手段\"><a href=\"#2-科学研究的方法与手段\" class=\"headerlink\" title=\"2. 科学研究的方法与手段\"></a>2. 科学研究的方法与手段</h1><h2 id=\"2-1-科学研究的一般过程-–-提出问题\"><a href=\"#2-1-科学研究的一般过程-–-提出问题\" class=\"headerlink\" title=\"2.1 科学研究的一般过程 – 提出问题\"></a>2.1 科学研究的一般过程 – 提出问题</h2><h4 id=\"发现问题\"><a href=\"#发现问题\" class=\"headerlink\" title=\"发现问题\"></a>发现问题</h4><ul>\n<li>科研工作中发现问题是最重要的步骤</li>\n<li>问题或需求驱动研究</li>\n<li>一流高手提问题、二流高手解问题、三流高手做习题</li>\n</ul>\n<h4 id=\"如何发现问题\"><a href=\"#如何发现问题\" class=\"headerlink\" title=\"如何发现问题\"></a>如何发现问题</h4><ul>\n<li>在打的研究方向上需要经验</li>\n<li>那些已清除定义的问题，往往研究空间很小，且难度也大</li>\n<li>从实际工作中发现问题，从综述中凝练问题，从前人工作不总中挖掘问题</li>\n</ul>\n<h4 id=\"问题的抽象\"><a href=\"#问题的抽象\" class=\"headerlink\" title=\"问题的抽象\"></a>问题的抽象</h4><ul>\n<li>不能<strong>只见树木，不见森林</strong>，<strong>跳出问题看问题</strong></li>\n</ul>\n<h2 id=\"2-2-科学研究的一般过程-–-分析问题\"><a href=\"#2-2-科学研究的一般过程-–-分析问题\" class=\"headerlink\" title=\"2.2 科学研究的一般过程 – 分析问题\"></a>2.2 科学研究的一般过程 – 分析问题</h2><h4 id=\"在解决问题之前，需要对问题有准确的定义\"><a href=\"#在解决问题之前，需要对问题有准确的定义\" class=\"headerlink\" title=\"在解决问题之前，需要对问题有准确的定义\"></a>在解决问题之前，需要对问题有准确的定义</h4><ul>\n<li>理清问题的来龙去脉</li>\n<li>给出问题的清晰定义，深入理解问题</li>\n<li>问题的分析要“言之有理”，“言之有物”</li>\n</ul>\n<h4 id=\"“分而治之”的分析方法\"><a href=\"#“分而治之”的分析方法\" class=\"headerlink\" title=\"“分而治之”的分析方法\"></a>“分而治之”的分析方法</h4><ul>\n<li>将无从下手的大问题分解成具体的小问题</li>\n<li>“细分”与“专业化”是科学研究的重要发展</li>\n<li>在“细分”的过程中发现研究的机会</li>\n</ul>\n<h4 id=\"注意联系的思想\"><a href=\"#注意联系的思想\" class=\"headerlink\" title=\"注意联系的思想\"></a>注意联系的思想</h4><ul>\n<li>注意学科交叉、方法借鉴</li>\n</ul>\n<h4 id=\"注意问题背后的假设与场景\"><a href=\"#注意问题背后的假设与场景\" class=\"headerlink\" title=\"注意问题背后的假设与场景\"></a>注意问题背后的假设与场景</h4><ul>\n<li>假设与场景往往是问题存在的基石和前提条件</li>\n<li>假设与场景的变化往往是影响问题的内涵，产生新的问题</li>\n</ul>\n<h4 id=\"问题的分析是个迭代的过程\"><a href=\"#问题的分析是个迭代的过程\" class=\"headerlink\" title=\"问题的分析是个迭代的过程\"></a>问题的分析是个迭代的过程</h4><h2 id=\"2-3-科学研究的一般过程-–-解决问题\"><a href=\"#2-3-科学研究的一般过程-–-解决问题\" class=\"headerlink\" title=\"2.3 科学研究的一般过程 – 解决问题\"></a>2.3 科学研究的一般过程 – 解决问题</h2><h4 id=\"分清主次，抓住重点\"><a href=\"#分清主次，抓住重点\" class=\"headerlink\" title=\"分清主次，抓住重点\"></a>分清主次，抓住重点</h4><ul>\n<li>人的精力是有限的，不可能解决所有问题，彻底解决一个问题的可能性也不大</li>\n<li>列出所有涉及的问题，按重要程度进行排序</li>\n<li>列出正在解决问题所设计的关键技术，逐个攻关</li>\n<li>博士生研究工作应是系统的，研究的问题应是相关的</li>\n</ul>\n<h4 id=\"先解决简单问题，积累经验后再解决复杂问题\"><a href=\"#先解决简单问题，积累经验后再解决复杂问题\" class=\"headerlink\" title=\"先解决简单问题，积累经验后再解决复杂问题\"></a>先解决简单问题，积累经验后再解决复杂问题</h4><ul>\n<li>解决同样的问题，往往有很多思路，不应满足于一种思路</li>\n<li>解决同样的问题，不同的思路或方法往往存在折中，找一种完美的方法对博士生来说可能是危险的</li>\n<li>针对一种解决问题的思路，往往鱼与熊掌不可兼得</li>\n</ul>\n<h1 id=\"3-博士生如何开展科学工作\"><a href=\"#3-博士生如何开展科学工作\" class=\"headerlink\" title=\"3. 博士生如何开展科学工作\"></a>3. 博士生如何开展科学工作</h1><h2 id=\"3-1-博士生培养一般过程\"><a href=\"#3-1-博士生培养一般过程\" class=\"headerlink\" title=\"3.1 博士生培养一般过程\"></a>3.1 博士生培养一般过程</h2><table>\n<thead>\n<tr>\n<th>阶段</th>\n<th>事情</th>\n<th>时间流程（月，总共3年）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>课程</td>\n<td>10个月</td>\n</tr>\n<tr>\n<td>2</td>\n<td>选课</td>\n<td></td>\n</tr>\n<tr>\n<td>3</td>\n<td>文献调研</td>\n<td></td>\n</tr>\n<tr>\n<td>4</td>\n<td>科研设计</td>\n<td></td>\n</tr>\n<tr>\n<td>5</td>\n<td>开题报告</td>\n<td>15个月</td>\n</tr>\n<tr>\n<td>6</td>\n<td>科研工作</td>\n<td></td>\n</tr>\n<tr>\n<td>7</td>\n<td>中期检查</td>\n<td></td>\n</tr>\n<tr>\n<td>8</td>\n<td>整理资料</td>\n<td></td>\n</tr>\n<tr>\n<td>9</td>\n<td>撰写论文</td>\n<td>31个月</td>\n</tr>\n<tr>\n<td>10</td>\n<td>论文答辩</td>\n<td>33个月</td>\n</tr>\n<tr>\n<td>11</td>\n<td>学位委员会审议</td>\n<td></td>\n</tr>\n<tr>\n<td>12</td>\n<td>授予学位</td>\n<td>34个月</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"3-2-博士生的心态\"><a href=\"#3-2-博士生的心态\" class=\"headerlink\" title=\"3.2 博士生的心态\"></a>3.2 博士生的心态</h2><h4 id=\"典型心态\"><a href=\"#典型心态\" class=\"headerlink\" title=\"典型心态\"></a>典型心态</h4><ul>\n<li>茫然型：两眼一抹黑</li>\n<li>躁动型：有感兴趣的研究方向，但无从下手</li>\n<li>试探型：在做具体工作，不知能否做出成果</li>\n<li>春风得意型：取得部分研究成果</li>\n<li>失落型</li>\n</ul>\n<h4 id=\"古今之成大事业、大学问者，必经过三种之境界\"><a href=\"#古今之成大事业、大学问者，必经过三种之境界\" class=\"headerlink\" title=\"古今之成大事业、大学问者，必经过三种之境界\"></a>古今之成大事业、大学问者，必经过三种之境界</h4><ul>\n<li>昨夜西风凋碧树，独上高楼，望尽天涯路。（晏殊）</li>\n<li>衣带渐宽终不悔，为伊消得人憔悴。（柳永）</li>\n<li>众里寻他千百度，蓦然回首，那人却在，灯火阑珊处。（辛弃疾）</li>\n</ul>\n<h2 id=\"3-3-如何选题-–-课题的来源\"><a href=\"#3-3-如何选题-–-课题的来源\" class=\"headerlink\" title=\"3.3 如何选题 – 课题的来源\"></a>3.3 如何选题 – 课题的来源</h2><h4 id=\"导师的项目\"><a href=\"#导师的项目\" class=\"headerlink\" title=\"导师的项目\"></a>导师的项目</h4><ul>\n<li>科研项目：重点研发计划，NSFC，国防预研基金</li>\n<li>开发项目：重大工程装备项目</li>\n<li>横向委托：企业委托的一般开发项目</li>\n</ul>\n<h4 id=\"个人兴趣\"><a href=\"#个人兴趣\" class=\"headerlink\" title=\"个人兴趣\"></a>个人兴趣</h4><ul>\n<li>通过个人工作积累，提炼出研究方向</li>\n<li>延续硕士期间工作</li>\n<li>突发灵感的研究方向，奇思妙想</li>\n</ul>\n<h4 id=\"跟风\"><a href=\"#跟风\" class=\"headerlink\" title=\"跟风\"></a>跟风</h4><ul>\n<li>人做亦做</li>\n<li>无病呻吟</li>\n</ul>\n<h4 id=\"3-4-如何定题\"><a href=\"#3-4-如何定题\" class=\"headerlink\" title=\"3.4 如何定题\"></a>3.4 如何定题</h4><ul>\n<li>导师的科研项目：一般选题比较先进，有较大可能在较短时间内有做出成果，认可度高</li>\n<li>导师的重大开发项目：应结合国家或行业重大应用提炼问题，有较大可能在短期内得到应用推广，认可程度高</li>\n<li>通过个人积累或延续前期工作，也有望在较短时间内做出程度，认可程度较高</li>\n<li>横向委托项目：一般不宜作为博士生的选题方向，采用成熟的技术，不侧重与理论或技术上创新，风险较大</li>\n<li>跟风选题：认可程度高，具体方向需要提炼，风险大</li>\n<li>突发灵感的选题：看运气</li>\n</ul>\n<h2 id=\"3-5-如何查资料-–-SCI、EI、ISTP\"><a href=\"#3-5-如何查资料-–-SCI、EI、ISTP\" class=\"headerlink\" title=\"3.5 如何查资料 – SCI、EI、ISTP\"></a>3.5 如何查资料 – SCI、EI、ISTP</h2><ul>\n<li>科学引文索引：SCI, Science Citation Index</li>\n<li>工程索引：EI, Engineering Index</li>\n<li>科技会议论文集索引：ISTP, Index to Scientific &amp; Technical PRoceedings</li>\n</ul>\n<h4 id=\"国内电子信息类\"><a href=\"#国内电子信息类\" class=\"headerlink\" title=\"国内电子信息类\"></a>国内电子信息类</h4><ul>\n<li>中国科学E辑</li>\n<li>中国科学E辑，英文版</li>\n<li>JCST</li>\n<li>电子学报英文版</li>\n<li>计算机学报英文版</li>\n<li>软件学报</li>\n<li>计算机研究与发展</li>\n<li>通信学报</li>\n<li>系统工程与电子学英文版</li>\n<li>航空学报英文版</li>\n<li>几个高校学报</li>\n</ul>\n<h4 id=\"重要的外文全文数据库\"><a href=\"#重要的外文全文数据库\" class=\"headerlink\" title=\"重要的外文全文数据库\"></a>重要的外文全文数据库</h4><ul>\n<li>ACM(美国计算机学会)Digital Library</li>\n<li>IEL (IEEE/IEE E;ectronic Library)</li>\n<li>Elsevier SDOS</li>\n<li>Springer- Link</li>\n<li>Kluwer Online Journals</li>\n<li>Wiley InrerScience</li>\n<li>WorldSciNet</li>\n<li>ISI Web of Science//档次稍微低点</li>\n<li>EI Village//档次稍微低点</li>\n<li>PQDD·B（博硕士论文网络数据库）//档次稍微低点</li>\n</ul>\n<h4 id=\"好的习惯\"><a href=\"#好的习惯\" class=\"headerlink\" title=\"好的习惯\"></a>好的习惯</h4><ul>\n<li>建立本领域主流期刊、重要会议、主要科研团队和知名专家数据库</li>\n<li>订阅期刊目录（Table of Contents）邮件列表</li>\n<li>定期浏览主流刊物主页，了解感兴趣研究论文摘要</li>\n<li>关注本领域主要国际会议的Conference Program</li>\n<li>定期了解主流科研团队和专家的科研进展，科研重点，Survey或Keynote Speech、</li>\n</ul>\n<h2 id=\"3-6-如何阅读文献-–-自上而下的方法\"><a href=\"#3-6-如何阅读文献-–-自上而下的方法\" class=\"headerlink\" title=\"3.6 如何阅读文献 – 自上而下的方法\"></a>3.6 如何阅读文献 – 自上而下的方法</h2><h4 id=\"阅读文献的两种目的\"><a href=\"#阅读文献的两种目的\" class=\"headerlink\" title=\"阅读文献的两种目的\"></a>阅读文献的两种目的</h4><ul>\n<li>已有具体研究问题，通过阅读文献找到解决方法</li>\n<li>无具体研究问题，通过阅读文献来找问题</li>\n</ul>\n<h4 id=\"从Survey-Review-the-State-of-the-Art-Tutorial入手\"><a href=\"#从Survey-Review-the-State-of-the-Art-Tutorial入手\" class=\"headerlink\" title=\"从Survey , Review, the State of the Art, Tutorial入手\"></a>从Survey , Review, the State of the Art, Tutorial入手</h4><ul>\n<li>Google、Google Scholar</li>\n<li>IEEE COMM Survey &amp;Tutorial</li>\n<li>期刊或会议中Related Work</li>\n</ul>\n<h4 id=\"泛读为主\"><a href=\"#泛读为主\" class=\"headerlink\" title=\"泛读为主\"></a>泛读为主</h4><ul>\n<li>侧重于摘要、前言与结论</li>\n</ul>\n<h4 id=\"广度优先\"><a href=\"#广度优先\" class=\"headerlink\" title=\"广度优先\"></a>广度优先</h4><ul>\n<li>针对一个具体问题，看20-30篇密切相关的文献</li>\n<li>论文太多，无法聚焦</li>\n<li>针对3-5篇文献，精度，深度优先</li>\n</ul>\n<h4 id=\"带着问题看文献\"><a href=\"#带着问题看文献\" class=\"headerlink\" title=\"带着问题看文献\"></a>带着问题看文献</h4><ul>\n<li>能解决自己所遇到的问题？</li>\n<li>哪些问题不能解决？</li>\n<li>…</li>\n</ul>\n<h4 id=\"挑剔的眼光看文献\"><a href=\"#挑剔的眼光看文献\" class=\"headerlink\" title=\"挑剔的眼光看文献\"></a>挑剔的眼光看文献</h4><ul>\n<li>在新的应用背景下的自适应新如何？</li>\n<li>方法或技术效率如何？</li>\n</ul>\n<h2 id=\"3-7-开展具体研究工作\"><a href=\"#3-7-开展具体研究工作\" class=\"headerlink\" title=\"3.7 开展具体研究工作\"></a>3.7 开展具体研究工作</h2><ul>\n<li>因学科领域不同而不同</li>\n<li>因人而异</li>\n<li>研究过程本身无统一标准</li>\n<li>研究过程无优劣之分</li>\n</ul>\n<h1 id=\"4-其它\"><a href=\"#4-其它\" class=\"headerlink\" title=\"4. 其它\"></a>4. 其它</h1><h2 id=\"4-1-朴素的博士生科研工作观\"><a href=\"#4-1-朴素的博士生科研工作观\" class=\"headerlink\" title=\"4.1 朴素的博士生科研工作观\"></a>4.1 朴素的博士生科研工作观</h2><ul>\n<li>要踏踏实实，勤勤恳恳，甚至默默无闻；不要指望做明星</li>\n<li>要循序渐进，一步登天可能性不大</li>\n<li>要学会从事本领域科研工作的基本技能，先做实干家，在做指挥家</li>\n<li>不要经常师徒去颠覆经典理论，时间有限，又开创新理论可能时先与导师沟通</li>\n<li>不要在自己的研究成果中严厉地批评他人的成果，更不能人生攻击，就事论事，宜委婉</li>\n<li>不要挑剔所从事的科研项目优劣，导师也在探索过程中，博士生是科研的主力军</li>\n<li>不以物喜，不以己悲（范仲淹）</li>\n</ul>\n<h2 id=\"4-2-数学基础很重要？\"><a href=\"#4-2-数学基础很重要？\" class=\"headerlink\" title=\"4.2 数学基础很重要？\"></a>4.2 数学基础很重要？</h2><ul>\n<li>数学基础和能力比较重要</li>\n<li>数学基础不是影响博士生研究工作质量的主要因素，更不是罪关键因素</li>\n<li>时间有限，不要无的放矢的学数学</li>\n<li>带着问题补充相关的数学基础</li>\n<li>对论文中所采用的新颖数学方法要有敏感、博闻</li>\n<li>经常泛读相关的数学书</li>\n</ul>\n<h2 id=\"4-3-英语很重要？\"><a href=\"#4-3-英语很重要？\" class=\"headerlink\" title=\"4.3 英语很重要？\"></a>4.3 英语很重要？</h2><ul>\n<li>英语基础和写作能力比较重要</li>\n<li>时间有限，不要无的放矢的学英语</li>\n<li>通过阅读专业文献学英语</li>\n<li>英语写作要学会模范，但不是抄袭</li>\n<li>不要以应对英语写作的方式写英文报告或论文</li>\n<li>不要卖弄英语文发，少使用长句，不使用生僻词</li>\n</ul>\n<h2 id=\"4-4-基本技能要掌握\"><a href=\"#4-4-基本技能要掌握\" class=\"headerlink\" title=\"4.4 基本技能要掌握\"></a>4.4 基本技能要掌握</h2><ul>\n<li>至少要精通word,有条件学习LaTex</li>\n<li>至少要使用好一种绘图工具</li>\n<li>至少要使用好一种仿真工具（计算机网络领域，其它未知）</li>\n</ul>\n<h2 id=\"4-5-结束语\"><a href=\"#4-5-结束语\" class=\"headerlink\" title=\"4.5 结束语\"></a>4.5 结束语</h2><ul>\n<li>博士生阶段做什么具体课题是次要的，重要的是一种训练过程和思考问题的方法</li>\n<li>博士生阶段是最艰苦的阶段之一，是最值得怀恋的经历之一</li>\n</ul>\n","categories":[{"name":"科研","slug":"科研","permalink":"http://yama0xff.com/categories/科研/"}],"tags":[{"name":"科研","slug":"科研","permalink":"http://yama0xff.com/tags/科研/"}]},{"title":"A Review of Machine Learning in Software Vulnerability Research","date":"2019-04-03T08:16:36.000Z","path":"2019/04/03/A-Review-of-Machine-Learning-in-Software-Vulnerability-Research/","text":"Abstract搜索和识别计算机软件中的漏洞具有悠久而丰富的历史，可用于预防或恶意目的。在本文中，我们研究了机器学习（ML）技术在软件漏洞研究（SVR）中的应用，讨论了以前和当前的工作，以说明学术界和工业界如何利用ML。我们发现，主要关注的不仅仅是发现新方法，而是通过简化和自动化流程来帮助SVR从业者。考虑到已经证明的各种应用，我们相信ML将在未来继续为SVR提供帮助，因为探索了新的使用领域，并且可以使用改进的算法来增强现有功能。 relevant information 作者 Tamas Abraham and Olivier de Vel 单位 Cyber and Electronic Warfare Division Principal ScientistDefence Science and Technology Group 出处 Cyber and Electronic Warfare Division 原文地址 https://www.dst.defence.gov.au/sites/default/files/publications/documents/DST-Group-GD-0979.pdf 源码地址 发表时间 2017年 1. 简介创建计算机软件是一个非常重要的复杂过程，通常会产生包含一些缺陷和脆弱点的代码。大型代码库的验证可能很困难，或者有时由于成本而被忽略，导致操作系统由于它们表现出来的意外和不良行为而可能崩溃或被操纵。虽然软件安全性错误的严重程度是可变的，但有些可能会非常严重，以至于被利用导致生产力损失，知识产权损失甚至物理损坏来对用户造成严重伤害。 Dowd等人[30]将术语软件错误中能被用于恶意目的的子类称为漏洞， 虽然在特定环境中实际利用漏洞可能并非总是可能，或者也不适合攻击者的目标。解决易受攻击软件引起的问题的方法已经在软件漏洞研究（SVR）中创建了研究。对影响计算机系统的漏洞的研究不仅限于软件。但是，我们在本文中的重点是基于软件的漏洞，我们不考虑硬件或系统架构。软件本身可以作为源代码或二进制文件进行分析，提供多种途径来发现漏洞。软件漏洞的研究过程可以定期分为发现，分析和利用的过程，并将缓解作为预防活动[73]。每个阶段探讨了处理漏洞的不同方面，通常需要代码审计员等从业者的长期和费力的投入。自动化在许多SVR活动中起着重要作用，然而目前通过人工解释发现了大多数漏洞。越来越多的机器学习（ML）技术被整合到SVR过程中，以进一步减少对手动交互的需求。成功应用后，ML算法可以引导用户找到最可能的解决方案，并可能发现以前未知的漏洞。本文的目的是对利用机器学习的SVR内部的目录进行编目，以突出当前事业的状态，并确定可能在未来做出进一步贡献的可能领域。 2. 背景本文的重点是机器学习在软件漏洞研究中的应用。为了进行讨论，我们分别介绍了两个领域和一些一般细节。在审查各个出版物时，后续章节将根据需要提供进一步的详情。接下来是对这两个研究领域的简单概述，在这个阶段，没有强调它们之间的任何联系。 2.1 软件漏洞研究对软件漏洞进行分类不是一项简单的任务。特定漏洞所属的类别通常在分析软件错误期间显示。有时，在漏洞发现过程中可以预期某种类型，因为某些技术隐含地针对有限范围的漏洞类型。扫描程序等工具会查找错误的结构，例如过时的库函数以及代码中的其他与安全相关的错误。模糊测试是为软件可执行文件提供异常输入以引起意外行为（如崩溃或内存泄漏）的过程，然后可以在相应的源代码中进行调查。全面的手动代码审查也可用于发现错误，但它们可能是其他漏洞发现方法的昂贵替代方案。格式校验提供了正确性的数学证明，如果不成功，则可以指出问题。然而，由于复杂性和成本，它通常限于小代码段或算法。符号执行是一种分析通过程序分支遍历变量值（输入）的技术，是另一种发现方法，尽管它可能遭受诸如路径爆炸之类的扩展问题。 源代码中的一些错误可能很容易组合，尽管某些漏洞仅与其他因素（例如它们部署在其上的平台）结合使用，因此可能难以进行初始分类。计算机体系结构，操作系统，计算机语言的多样性以及语言特定错误的存在使分析更加复杂化。我们使用Dowd等人的书中给出的分类法 [30]作为定义软件漏洞类型的指南。语言特定问题包括： 内存损坏，例如缓冲区（堆栈，off-by-one，堆，全局和静态数据） 算术边界条件（如数字上溢和下溢） 类型转换错误（有符号/无符号，符号扩展，截断，比较） 操作符误用（sizeof（），移位，模数，除法） 指针算术错误 其他错误（评估顺序逻辑，结构填充，优先级，宏/预处理器，拼写错误） 其他漏洞更复杂。问题类别包括实际应用程序中存在的问题类别，例如与操作系统或应用程序平台相关的问题类别，即使基础问题可能由更简单的错误（如内存损坏或指针错误）引起： 字符串和元字符漏洞 特定于操作系统的漏洞（特权问题，文件权限问题，竞争条件，进程，IPC，线程，环境和信令问题） 平台漏洞（SQL注入，跨站点脚本（XSS） ），跨站点请求伪造（CSRF），文件包含和访问，shell调用，配置，访问控制和授权？aws） 对漏洞进行分类的另一种方法是从攻击角度出发。例如，Open Web Application Security Project [3]提供了一个攻击类型列表，并定期编译一系列顶级当代漏洞[1]，并非所有漏洞都与源代码或二进制文件有关。在那些注入攻击（代码，SQL，HTML脚本，远程文件和shell）和控制流劫持，如溢出（buffer，整数，字符串格式）和堆喷射类似于我们上面列出的那些。像Bletsch这样的其他作者提供类似的分类，讨论如何通过代码重用（面向返回的编程（ROP），返回到libc（RILC），面向跳转的编程（JOP））来利用漏洞[80]。 。 随着软件中的漏洞被发现，它们通常与更广泛的社区共享。The Common Vulnerabilities and Exposures （CVE）是一个公知的信息安全漏洞和风险的库 [4]，目前由MITRE组织维护。漏洞通常附加一个分数来描述其严重性，通用漏洞评分系统（CVSS）[40]是最常用的评分标准之一。提供对CVE，分数和其他相关信息的访问的服务包括诸如开源漏洞数据库（OSVDB）和美国国家漏洞数据库（NVD）之类的数据库。和允许对新发现的漏洞进行实时更新的API（如VulnDB和vFeed）。根据不同类别中发现的漏洞数量，每年都会根据流行漏洞编制统计数据，尽管每种类型的攻击频率和严重程度之间可能没有相关性。例如，Price和Kouns [46]列出了跨站点脚本，SQL注入，跨站点请求伪造，文件包含，拒绝服务和过度攻击，这是2014年根据OSVDB最常见的滥用行为。 减轻软件漏洞影响的方法也产生了各种策略和解决方案。尽管可能无法实现完全错误预防，但软件生产商仍希望尽量减少其产品包含漏洞的可能性。这些包括在开发周期中的全面测试和修复错误，在软件发布后提供数据，以及在安全编程语言中编写代码。在Vanegue [82]中列出了在软件发布之前可以使用的漏洞发现技术列表，例如软件测试，模糊测试和程序验证（定理证明，抽象解释，模型检查）。使用抽象语法树（AST），控制流图（CFG），程序依赖图（PDG）和代码属性图（CPG）等图形建模代码执行可以帮助识别开发过程中的问题。 OS和硬件制造商也提供了软件发布后使用的其他缓解技术。数据执行保护（DEP）/不执行（NX），地址空间布局随机化（ASLR），指令集随机化（ISR），运行时检查（金丝雀，LibSafe），程序引导，控制流完整性（CFI），数据流完整性（DFI）和控制流锁定是当前使用的一些技术，参见[80]。用于执行各种发现任务的软件工具随时可用，包括商业和开源[87]。 程序分析是分析软件行为问题的核心。从理论上讲，软件错误的识别是不可判定的，即在一般情况下不可能编写程序来表示和计算另一个程序的所有可能的执行[67]。在实践中，某些程序行为可能会被忽略，因为它们与当前分析无关。然而，这可能导致在近似下 - 排除可能有效的行为，并且过度近似–包含可能但无效的行为–增加复杂性和资源需求。图1将一些程序分析技术组织到一个图表中，突出显示了各个方法的样式和自动化级别。静态分析在不执行程序的情况下进行，可以提供良好的代码覆盖率和所有可能执行的原因，但无法分析可执行环境，例如操作系统和硬件。另一方面，动态分析是在程序执行期间进行的，或者通过检测程序来分析行为。但是，它只能推断观察到的执行路径而不是所有可能的程序路径。 2.2 机器学习在本节中，我们简要概述了机器学习概念，并重点介绍了我们在本文后面讨论的出版物中遇到的一些相关技术。存在许多不同的分类法用于分类ML技术。为方便起见，我们使用Barber [13]的书作为本节的参考源，除非给出了具体的参考。 机器学习领域关注数据的自动化探索，产生可用于预测的描述性模型。通常，认识到两种主要的学习方式：监督学习从标记数据源构建其模型并关注预测的准确性，而无监督学习则集中于从未标记数据提供紧凑描述。除了这两种主要风格外，还可以观察到几种变化。异常检测会查找与建模模型不同的数据中的异常值。随着新数据的出现，在线学习能够不断更新模型。主动学习可以通过要求来自当前模型无法有效描述的环境区域的更多数据来构建更好的模型。强化学习能够以反复试验的方式与环境互动，以创建根据某种形式的奖励进行优化的模型。最后，半监督学习利用标记和未标记的数据，使用一种类型的数据来改进可以仅从其他类型的数据创建的模型。 多年来，在上述学习方式中已经提出并开发了大量算法。监督学习主要使用多种类型的分类器中的一种来预测数据点所属的组（类）。这是一种离散学习形式，因为输出仅限于一组值。当结果需要在一个值范围内时（即它是一个连续变量），回归就是使用的技术。最简单的分类算法之一是K-最近邻（kNN）算法，它通过查看其K个最近邻居的标签并选择最常见的邻居来确定数据点的类标签，例如基于实例学习使用数据集中的示例而不是使用从中构建的模型来决定类的决策。 NaïveBayes分类器是一种概率算法，它假设描述数据的变量之间具有条件独立性，以简化生成模型的构建。点的类标签是通过使用贝叶斯规则给出不同标签的数据的概率及其条件概率来估计的。其他分类技术对数据进行线性模型，并根据与已知示例计算的决策边界相对应的数据点的位置确定类成员资格。逻辑回归是一种分类算法，它使用最大似然函数来近似属于类的数据点的概率。线性支持向量机（SVM）产生超平面以分离类，使得平面每侧上的最近点之间的距离最大化。 决策树分类器将顺序决策过程建模为特殊图形，每个节点用作特征测试，以便给定特征的不同值沿着不同的分支布置。树的叶子决定了类型成员资格。从任何特定的示例数据集中，可以构建许多不同的树，并且通常使用来自单个数据集的多个树的组合来构建更好的模型。随机森林是决策树的集合，旨在提供对作为单个树创建的模型的改进预测。图表在表示用作分类器的各种形式的神经网络（NN）[14]中也很突出。神经网络按节点层组织，包含输入层和输出层，其间有隐藏层。每个节点对应于一个函数，该函数使用分配给节点连接边的权重将其输入值映射到单个输出值。 NN分类的流行变体包括多层感知器（MLP）前馈神经网络，卷积神经网络和长期短期记忆复现神经网络。神经网络也是深度学习的核心，深度学习是一种机器学习范式，它也关注数据表示的学习。 无监督学习通常与聚类分析相关联，即基于相似性的定义将数据组织成组。这些可以包括基于数据分布的统计方法，例如使用期望最大化（EM）来构建高斯混合模型（GMM）。利用数据连接的算法是层次聚类的示例，或者是自下而上构建的，即从每个数据点开始作为集群然后是合并操作，或者自上而下，从单个集群开始并根据某种策略进行拆分。基于质心的聚类通过确定选定数量的聚类中心并将每个数据点分配给最近的聚类中心来识别聚类。另一方面，基于密度的聚类根据某个距离测量的阈值找到彼此接近的点集群，并且如果它们不满足这些要求，则可以将数据保留为未分配的噪声。Associations [5]是受市场数据分析启发的规则。它们代表了if…then构造描述数据中以某种最小所需频率出现的强模式。找到频繁项目集或特征值比其他项目更频繁地出现，可以揭示数据的趋势。顺序模式挖掘是一种具有相同目标的学习活动，但随着时间的推移分析数据，利用数据点的时间顺序来构建模型。遗传算法也是规则发现算法，它通过将交叉和变异算子应用于初始数据集并评估后续世代的精度直到满足某些终止条件来模拟自然选择。 学习通常先于预处理过程，然后是模型评估等任务。一些预处理包括特征提取，以及数据中噪声和错误的处理。特征选择和降维旨在识别与学习任务相关的特征并降低复杂性以便改进由学习算法生成的模型。有监督和无监督的学习者都可以从这个过程中受益。一些重要的例子包括主成分分析（PCA），线性判别分析（LDA），非负矩阵因子分解（NMF）和奇异值分解（SVD）。采样以减少数据大小和平衡输入数据可以提高算法的效率和性能。使用套袋和增强等集成方法可以提高单个学习算法的预测性能。出于评估目的，可以使用性能评估方法来评估算法的有效性。在二进制分类中，可以使用若干概念来描述预测条件与数据点的实际条件之间的关系。真阳性（TP）或命中，是正确预测的阳性实例。假阳性（FP）是错误预测为阳性的阴性实例。对于真阴性和假阴性，存在类似的定义。真阳性率（TPR）或算法的召回是所有阳性实例的真阳性率。精度是TP与TP和FP之和的比率，表示在预测正实例时所犯错误的数量。算法的准确性是所有数据点上正确识别的实例（TP加TN）的比率。存在许多模型评估方法，例如ROC分析[31]。结合起来，它们不仅可以提供算法评估，还可以确定其他学习策略，例如不同的特征选择方法或参数优化。 机器学习已应用于众多研究领域。可以与检查计算机程序相关的一个是自然语言处理（NLP），这是一个关注语言建模，解析和语音识别等任务的领域。可用于文档分类的一些值得注意的技术包括Latent Dirichlet Allocation（LDA）和Latent Semantic Indexing（LSI），它们都将文本建模为主题集合。 3.机器学习在软件漏洞中的研究机器学习可以为软件漏洞研究等复杂的研究领域带来许多好处。它可用于模拟代码的语法和语义，并推断代码模式以分析大型代码库，协助代码审计和代码理解，同时实现可容忍的误报率。随着SVR流程复杂性的增加，对SVR从业者可用的自动化水平的需求也在增加。结果，提出了用于发现和预防目的的分析软件的新方法。其中一些是特别的。其他人使用来自其他科学领域的现成技术，包括统计学，机器学习和数据挖掘。在接下来的部分中，我们将讨论利用主要机器学习的现有工作，根据基于内容相似性的松散分组来组织它们。 我们首先指出一小部分最近的论文，这些论文考虑在更广泛的层面上解决软件漏洞问题。例如，Avgerinos等 [11]承认在广泛使用的大型软件项目中存在软件错误，例如Firefox浏览器和Linux内核，一些已知，但其他可能仍未被发现。由于在关键软件中发现了如此多的错误，作者提出了以下问题：“我们应该尝试优先修复哪些错误？”，“我们可以确定哪些是可利用的？” Jimenez等 [41]可能表明未来可能的方式。他们分析过去已知的漏洞（在本例中为Android）并建立一个分类，列出导致软件漏洞的问题，漏洞所在代码中位置的特征，这些位置的复杂性以及漏洞的复杂性。创建公共数据集，如VDiscovery [34]收集测试用例的结果，并可用于促进进一步的研究是另一项有希望的举措，众包试的寻找bug的想法这个模型由zhao等人描述[93]。 3.1 源代码分析如前所述，减少SVR人类从业者的手动任务量是许多提议方法的主要目标。自动化的例子包括Parfait [26]，一个用于发现C / C ++代码中的错误的框架。 Parfa的每个bug类型都设计有多层，用于速度和可扩展性的程序分析。该解决方案背后的理念是采用更简单的分析来预测某些类型的错误，然后转向计算量更大的错误，以实现最佳的覆盖率和精度。另一个平台Mélange[74]也分享了同样的理念，同时也分析了C和C ++代码。 Mélange执行数据和控制流分析，并生成错误报告，以解释发现的错误，以帮助解决必要的问题。在执行阶段进行分析，包含局部和全局，后者按需使用以验证局部分析的结果。另一个例子是SZZ算法[88]，它被开发用于自动识别诱导修复的代码提交，并且可以被研究人员用来验证软件度量或模型以预测故障组件，这是防止bug的重要活动。 然而，这些方法是向自动化迈进并不一定依赖于机器学习技术的示例。以下类别详细说明了它们的用途。 3.1.1 编码实践用于代码分析的机器学习的早期用途之一是PR-Miner [50]，数据挖掘技术的应用，为源代码构建一组编程规则。它从大型代码库（如Linux，PostgreSQL和Apache HTTP Server）生成频繁的项目集，以自动生成隐式编程规则，然后可以使用其他算法检查违规。对结果进行排序并按照假设的严重程度提供给分析师，以确定它们是否构成实际错误。这个过程很快，作者认为它能够识别比使用用户定义模板的类似工具更复杂的违规行为（例如，包含两个以上的规则组件）。 AutoISES [77]是一种类似的工具，它通过从源代码推断安全规范来检测漏洞，而不是要求手动提供这些漏洞。规范的推断仍然受到与安全编码实践相关的概念的指导，但现在根据代码中观察到的证据提取规则，并且违规被提供用于手动验证。 Linux内核和Xen用作测试用例，对于84个提取规则，发现了8个新漏洞。 协助开发人员正确使用应用程序编程接口（API）方法一直是一些论文的焦点，通常受到缺乏足够可用文档的启发。UP-Miner工具[83]采用了几种数据挖掘方法，例如聚类和频繁闭合序列挖掘，以创建频繁的API使用模式。它还包含新的度量标准，以优化所得模式的简洁性和覆盖范围，然后将其作为概率图提供给用户以供检查和理解。与Microsoft开发人员合作对大型Microsoft代码库进行的测试证实了该方法的实用性。Nguyen等人详细介绍了另一个有趣的贡献 [59]。他们研究API前置条件，这些条件需要在调用之前通过API方法的参数来满足。他们开发了一个系统，该系统找到调用API的客户端方法，计算每个调用站点的控制依赖关系，然后挖掘用于访问这些调用站点的条件，最终推断出每个API的前提条件。使用SourceForge和Apache项目对Java Development Kit进行的大规模评估确定了书面规范中缺少的一些先决条件。此外，结果可用于识别不满足源代码中的前提条件的编码错误。本文还对早期API挖掘文献中的参考文献进行了很好的收集。 VCCFinder [62]是一个工具，它将有关代码中的漏洞的知识与有关对存储库的commits的元数据相结合，以识别可能存在漏洞的软件代码commits。为两种源类型的每个提交生成的一系列功能与已知的漏洞贡献提交案例的功能相匹配？ （VCC），从CVE的提交数据中识别，以确定新提交是否可能是漏洞的来源。为此目的构建了两级SVM。对66个GitHub项目的测试表明，与现有工具相比，误报率（FPR）大大降低，同时保持了类似的真阳性率。虽然成功识别VCC可以大大减少检查安全性的代码量，但是从业者仍然需要重要的专业知识和审核它们的手册。 3.1.2克隆检测重复代码不仅会使软件项目由于代码膨胀而更难以维护，而且还会因为复制粘贴编程而分散在大型代码库中问题的问题难以解决。因此，检测克隆在文献中引起了很多关注，包括从脆弱性的角度来看。 Roy等人最近的一项调查 [70]提供了克隆检测技术的概念和定性比较和评估。与克隆检测相关的许多研究都集中在确定代码片段相似性以定位复制的代码。Udagawa [81]提出了一种代码结构基础的方法，使用解析器提取从Java源代码片段词汇数据，并应用相似性度量通过令牌的完全匹配序列的数目的比率定义到部分序列匹配状态的数量。 Lazar和Banias [47]在基于结构的方法的另一个例子中使用抽象语法树在多个文件集中使用子树相似性度量。这些通常优于基于文本或令牌的方法，因为它们对代码和变量名称更改是健壮的，尽管由于可伸缩性问题它们通常不适合大型程序。 克隆检测算法也被用于与机器学习相结合的bug修复目的，例如Steild和Göde[76]。他们的想法是从克隆中提取特征，并在训练分类模型后，确定类似的克隆是否具有不完整的bug修复。克隆检测本质上是基于令牌的，即语句被标记化而不是表示为树，并且这反映在从代码片段中提取的特征类型中：全局上下文特征与本地词汇特征相互补充，允许克隆中的轻微不一致。作者研究了多种分类技术，发现决策树是最有希望的，并且对用户来说是一种易于理解的表示。测试结果表明，即使假阳性与真阳性的比例很高（大约四个五分之一是假的），与人工分析相比，他们的方法代表了显着的改善。 进一步采用克隆检测的概念，C3系统[45]研究了源代码库中的代码变化。这个想法是通过自动定位类似的代码更改来简化bug修复的应用，而无需与用户交互和/或现有的代码更改模式，将其传递给其他应用程序工具。提出了两种相似性度量，一种基于传统的基于二维的表示，另一种基于抽象语法树，其用于提取的代码变化以生成相似性矩阵。然后使用聚类来检测类似变化的组（而不是与克隆的情况相同的组）。大型代码存储库的结果表明，它们可以以高效的方式交付，其成功率类似于专家手动提取所获得的成功率。 3.1.3错误检测代码错误无论是否可利用，都难以识别，特别是在大型软件项目中。在源代码的情况下，一些更常用的发现错误的技术包括使用模板来指导搜索已知漏洞;检查源代码文件的内容并与已知的易受攻击者进行比较;并分析代码结构以诊断潜在的错误。通常，使用方法的组合来强化结果，这些活动的主题要么是识别与正常不同的代码，要么是识别与类似的已知坏的代码。 当用于定位特定的漏洞模式时，使用先验知识可能非常有效。被忽视的条件是Chang等人的主题 [25]。他们的方法要求用户指定用于从代码中学习条件规则的约束，该代码用于发现指示被忽略条件的违规。提取的规则表示为图形和最大频繁子图挖掘算法，后跟图形匹配算法分类规则违规。可以咨询用户以评估所提取的规则的有用性并在匹配发生之前调整它们。使用这种方法测试了各种开源软件项目，并揭示了以前未知的违规行为。 Alattin [79]是另一个使用一种名为ImMiner的修改频繁模式挖掘算法来识别被忽视条件的提议。它引入了替代模式的概念，作为在程序中执行相同API调用的两个规则的分离。当两个单独的模式频繁时，替代模式称为平衡;当只有一个时，替代模式被称为不平衡，并且可以用于程序理解和缺陷检测。已经开发了频繁项集挖掘算法的变体来搜索平衡和不平衡的替代模式，并且应用于检测API调用周围的被忽略的条件。与类似的解决方案相比，该方法测试良好，可作为Eclipse插件使用。 描述正常行为而非违规的模式也用于错误检测。Gruska等 [35]解析大量的软件项目，以提取表示函数调用之间的数据流的频繁时态属性。然后使用异常检测算法来使用关联规则提升措施来检测对学习模式的违反，以对它们进行排序和过滤以供用户评估。在实际测试中，排名靠前的25％的违规行为被发现是问题，无论是实际缺陷还是代码设计中的弱点。 将源代码作为文档集处理并构建描述它们的模型是另一种开发对软件项目的理解的方法。 Lukins等人[52]使用Latent Dirichlet Allocation生成关于字符串文字，注释和标识符的主题模型，然后在几个案例研究中使用手动制作的错误描述查询来评估它们。他们发现他们的技术与竞争方法相比具有优势，并且在大型源代码库中使用时可以很好地扩展。 Hovsepyan等 [39]还会查看单个源代码文件，并通过删除注释，字符串和数值将其转换为特征向量，并将剩余的代码元素（关键字，变量和函数名称）标记为监督学习的特征词。在运行支持向量机算法之前，将标签分配给每个文件以训练用于预测从测试文件中提取的易受攻击的特征向量的模型。该技术能够以较低的错误发现率识别大多数测试的漏洞，并且旨在补充基于软件度量的现有漏洞发现解决方案。Pang等人[60]通过将n-gram包含在生成的特征向量中来扩展这项工作。考虑多达五个令牌的序列而不是单个单词，并且为了避免产生的特征爆炸，使用统计特征选择算法来提供排名。然后，前20％的特征与SVM算法一起使用。对四个Android Java项目的测试取得了比早期尝试稍微更好的分类结果。 Scandariato等[72]在将源代码文件标记化为特征向量时，使用单个单词（包括注释和字符串值），但引入离散化以对各种特征计数进行分类，以便改进其机器学习算法生成的模型。除了SVM之外，他们还使用决策树，k-最近邻居，朴素贝叶斯和随机森林进行测试，后两种算法在他们的实验中表现最佳。本文还回顾了以前的可比较的工作，包括那些依赖软件指标来确定文件是否包含软件漏洞的工具。这些在文本挖掘解决方案的指标的优化是Tang等人的主题 [78]。他们认为虽然许多基于机器学习的解决方案可能会显示出改进的结果，但它们并不足以证明应用这些模型而不是基于软件指标的模型所需的额外成本是合理的。 许多研究人员研究利用程序结构特性的解决方案。机器学习已经在Kremenek等人中使用。 [44]研究源代码程序分析和概率图模型的组合，以直接从程序中自动推断程序规范。通过创建注释因子图来进行推理，该图可用于在检查任何推断的规范之前通过其概率对可能的错误进行排序。对开源代码库的测试表明，在内存分配/释放规范的情况下，真正的阳性率很高。彭等人[61]探索深度学习对程序分析的可能性。他们认为基于自然语言令牌的粒度可以产生稀疏数据，而是将抽象语法树节点编码表示为矢量，将AST中的节点编码为单个神经层。然后将它们用作卷积神经网络的输入，用于深度监督学习以对程序进行分类。使用k均值聚类进行矢量表示的定量评估，以表明类似的节点可以成功地组合在一起，而对分类任务的定性评估显示，与基线分类器（如逻辑）相比，深度学习的结果比回归和支持向量机稍微优越一些。 利用特定于漏洞发现的程序结构一直是Yamaguchi及其合作者的焦点。抽象语法树节点的潜在语义分析[90]是在审计源代码库期间向安全分析师提供帮助的早期尝试。在提取API和语法节点之后，它们被嵌入到向量空间中，并且使用LSA来识别结构模式以生成主题。然后可以将这些与已知漏洞识别的特征进行比较。对几个开源项目的测试有助于发现新的零日漏洞。缺少检查是另一个Yamaguchi等人的目标。详细介绍了Chucky [92]，这是一种异常检测器，可以静态地污染源代码，并识别源代码中与安全关键对象相关的异常或缺失条件。在提取抽象语法树之后，使用k近邻算法来执行相关函数的邻域发现。轻量级污染，然后将函数嵌入向量空间，然后通过几何比较检查与代码库其余部分中类似函数嵌入的已知检查，识别异常，可以比较缺失的检查。 Chucky经过测试，以极高的检测率诊断已知漏洞，并且还能够通过生成各种开源项目的异常排序列表，帮助分析师识别以前未知的漏洞。Joern项目[89]引入了代码属性图（CPG）的概念，它是抽象语法树，控制流图（CFG）和程序依赖图（PDG）的组合，三个现有的代码表示，每个代码都是能够捕获一些但不是所有对漏洞研究很重要的软件特征。这个想法是，CPG将这些特征结合起来，形成一个可以用来更普遍地模拟现有漏洞的表示。然后检查代码库将成为构建代码并将代码表示为CPG的练习，并针对生成的图形发出图形遍历查询以找到漏洞模式的匹配项。该平台已针对Linux内核代码库进行了测试，并能够识别18个先前未知的漏洞。设计的局限性在一项提案中得到了部分解决，该提议旨在自动推断污点式漏洞的搜索模式[91]。后置控制器树（PDT）用于增强代码属性图，以捕获在另一个之前执行语句的情况，从而能够检测代码中的函数调用，从而导致对其参数进行修改。然后可以使用这些来生成图遍历模式以搜索污点风格的漏洞。该方法已作为Joern的插件实现，并显示可大幅减少代码检查。 3.1.4 Bug修复和补丁Bug修复，无论是反应性的还是预防性的，仍然是软件开发中的必要活动。 Vulture [57]是一种工具，可以自动从过去的漏洞位置学习，以预测新组件在完全实施之前的未来漏洞。这是通过从源代码组件中提取import语句并应用频繁模式挖掘来确定它们是否与现有漏洞相关来实现的。然后可以使用基于项目导入矩阵构建的分类模型和从上一步骤获得的漏洞向量，评估新组件以确定它是否会基于其导入而易受攻击。使用SVM分类器进行预测的系统在Mozilla项目上进行了评估。 Kim等人 [43]提出了一种称为“改变”的技术。在代码行而不是完整的模块，文件或功能上运行的分类。这是通过检查软件配置管理系统中的代码历史来实现的。针对bug修复和根据更改元数据，软件复杂性指标，日志消息和代码的常规提交来提取特征。选择SVM分类器来构建模型，以预测新代码更改是否有缺陷或干净，并在新的更改提交时立即获得结果。本文还分析了不同特征群的预测能力。 但是，了解软件项目中易受攻击的组件并不能解决这些漏洞被利用的可能性的问题。 Bozorgi等人[15]提出了自动对漏洞进行排序的潜在解决方案。利用CVE和OSVDB等公共漏洞数据库对最有可能被利用的漏洞进行分类和预测。从现有漏洞披露报告中的文本字段，时间戳，交叉引用和其他条目中提取了大量特征。然后在随机平衡样本上训练线性SVM，使用具有漏洞的漏洞的正标签和不具有漏洞的漏洞的负标签。然后，该方法用于研究离线和在线漏洞利用预测，识别与预测最相关的特征，并估计利用漏洞所需的时间。后一主题也在Wijayasekara等人 [86]的研究中进行了研究，其中讨论了使用文本挖掘技术挖掘bug数据库中的错误报告，以帮助发现隐藏的影响漏洞。隐藏影响漏洞是在相关错误通常通过补丁发布向公众披露之后的某个时间识别的漏洞，攻击者可以使用该漏洞发现潜在的高影响漏洞。通过处理（标记，词干等）错误报告中的文本来获得特征向量，并且通过计算贝叶斯检测率或者如果检测到错误是隐藏的影响漏洞的概率来获得分类。并将该bug标为漏洞。 Linux内核和MySQL错误数据库用作数据源。对隐藏影响漏洞与漏洞的比率的分析表明它相对较高，并且在研究的最后两年中还观察到其增加。 一旦确定了错误并确定了优先级，就必须对它们进行修复。 Prophet [51]是一个自动补丁生成系统的示例，它从开源软件存储库中获取补丁并构建正确代码的模型。该概率模型是在从先前代码修订中提取的成功补丁的特征的初始训练阶段中学习的，并且用于生成新缺陷的候选补丁并对其进行优先级排序。然后验证候选补丁并将其提供给开发者进行手动检查和插入。对来自8个开源项目的69个真实世界缺陷的基准测试表明，Prophet比现有的补丁生成系统更有优势。 GenProg [84]在抽象语法树和加权程序路径上使用遗传编程方法来纠正代码中的缺陷。一旦识别出错误，例如，程序未通过测试用例，就会搜索原始程序的变体，直到找到有效版本。该技术使用观察来通过采用来自程序中的另一位置的现有代码来修复缺陷。通过使用类似的模板改变缺陷代码，可以通过程序成功修补先前失败的测试用例来识别修复。DeepSoft框架[29]是一种雄心勃勃的方法，用于模拟软件及其开发，以预测和降低风险，并自动为已识别的错误生成代码补丁。它采用深度学习，LSTM来模拟源代码及其演变。他表示结合自然语言处理使得能够自动生成用于解决问题的代码补丁。 Le等人 [48]调查应用自动修复软件错误识别案例的有效性。他们有兴趣在合理的时间内进行维修，并认为根据某些定义的时间预算，有时手动而非自动干预可能会更具成本效益。为此，他们构建了一个随机森林分类器，它使用多次GenProg运行来生成数据，并添加了一个有效性指标作为分类标签。随后的模型用作预测未来修复实例的有效性的预言。结果表明，对于更合适的修复类型，正确地识别出四分之三的修复。 3.1.5 缓解和预防在文献中也经常探索减少软件开发过程中引入的错误数量的方法。减少代码错误概率的一种可能方法是引导自动生成正确的代码片段。许多作者讨论了代码完成，包括Hindle等 [36]，他们使用自然语言处理中的n-gram概念来统计模拟代码令牌序列，基于代码类似于语言，重复和可预测的假设。他们发现源代码的熵远低于自然语言的熵。他们从他们的模型开发一个新的Eclipse插件作为概念验证，显示出优于内置代码完成引擎的功能。 Allamanis和Sutton [7]通过编译和分析更大的数据集，进一步扩展到giga-token 模型并引入新的数据驱动指标来衡量代码复杂性。他们证明这些模型在代码建议方面更胜一筹。 SLANG [66]补充了具有递归神经网络的n-gram模型，使用API方法调用以解决在代码中生成完整的holes（间隙，缺少行）的问题。代码完成被视为预测句子概率的自然语言处理问题。由此产生的工具能够合成具有多个语句和参数的复杂解决方案，这些语句和参数可以正确地进行检查，并在90％的案例中包含前3个结果中的所需结果。 DeepSyn [65]是JavaScript程序的代码完成系统。它利用领域特定语言而不是抽象语法树，它删除了代码规范并促进了对部分解析树的学习。然后可以生成该语言中与训练数据最佳匹配的程序，该程序在代码完成任务中表现得比现有解决方案更好。 Bruch等人讨论了用于智能代码完成的数据挖掘技术 [17]。设计了三个独立的解决方案来改进内置的Eclipse代码建议系统。首先，通过频率计数简单地命令所有可用的建议，而不是默认的Eclipse排序。第二个使用关联规则来查找代码对象之间的相关性，并建议与观察对象密切相关的那些。第三种解决方案是k近邻算法的变体，称为最佳匹配邻居算法。它为代码库中的每个变量提取二进制特征向量，编码有关使用它们的API调用的指示符，并根据汉明距离的修改使用计算当前代码库和示例代码库之间的距离。然后根据所选最近邻居的频率推荐代码完成。在测试中，每个提案都优于默认的Eclipse建议系统，最佳匹配邻居算法产生了领先的结果。 GraLan [58]是一种基于图形的统计语言建模方法，它计算使用图出现概率并将其用于代码完成。在从源代码示例构建语言模型之后，可以从当前编辑的代码的邻域中提取使用子图，并且可以使用GraLan来计算给定那些使用子图的children图的概率。这些被收集并作为建议的候选API元素排名。这种方法进一步扩展到ASTLan，这是一种基于AST的语言模型，用于在当前编辑位置建议语法模板而不是API元素。 GraLan和ASTLan都比以前的API代码和语法模板建议更有优势，本文还提供了代码完成研究的广泛概述。 机器学习技术也被用于帮助证明程序的存储器安全性和功能正确性。一个例子是Cricket [16]，这是一种验证工具扩展，它利用逻辑回归和双层神经网络来自动化具有适当不变量的程序注释。最初，只学习形状属性并用于验证堆程序的正确性。如果失败，则在具有数据不变量的第二阶段中加强有效的形状不变量，以再次采用ML算法来改善所获得的存储器安全性证据。 3.1.6 归属 代码漏洞分析后的潜在后续活动是代码归属于其作者。这些信息可以识别软件项目之间的关系，可以证明代码的质量和成熟度，并协助开发和应用适当的漏洞预防解决方案。 Caliskan-Islam等 [24]使用机器学习解决了C ++源代码的作者属性问题。他们的方法考虑了三种类型的特征，总共最多20,000个特征：代码样式特征是布局特征，例如不改变程序含义的空格;词法特征来自程序令牌，或具有识别含义的字符串，例如循环次数，if / then语句和注释;语法特征源自AST，如AST节点类型的术语频率逆文档频率（TFIDF）。使用信息增益标准，原始特征集大幅减少，随机森林集合分类器用于作者身份归属，具有高度准确的结果。作者认为语法特征对代码混淆尝试具有弹性，并且发现高级程序员具有比新手更具识别性/唯一性的编码风格。 3.2. 二进制代码分析二进制文件是源代码的转换，因此，它来自高级编程语言中固有的一些语义损失。因此，漏洞研究中的一些活动，特别是那些旨在防止漏洞被引入软件的活动，要么不可用，要么不适用，要么采用不同的方法或技术。当可以分析源代码和相应的二进制文件时，研究人员有机会使用丰富的数据集。但是，二进制文件通常都是可用的，可以进行调查。与源代码类似，它们可以转换为不同的表示，这可能使一些早期看到的技术适合与此媒体一起使用。但是，不同的计算机体系结构和对相同源代码的不同编译器优化可能会在二进制分析中引入额外的复杂性层。 自动化仍然是二进制代码的SVR活动的主要目标。一些示例包括GUEB [32]，一种静态工具，用于检测反汇编代码上的释放后使用（UaF）漏洞。它利用抽象存储器表示，在其上执行值集分析，使用控制流图的正向遍历来促进UaF检测。 Sword [23]是一个自动模糊测试系统，它优先考虑二进制区域以进行模糊测试。它结合了多种漏洞检测方法来提高效率，即搜索和识别目标程序所需执行路径的符号执行，以及污点分析以检查执行路径并生成路径相关信息以引导模糊器执行漏洞分析。 Code Phage [75]是一个自动将正确的代码从施体者应用程序转移到接收者应用程序中以消除后者错误的系统。一旦为程序识别出引起错误的输入，就会在数据库中搜索施体者应用程序，其中相同的输入不会触发错误。各种活动，包括候选检查发现，补丁切除，插入和验证都遵循此步骤，如果它们不能产生安全的解决方案，则会重复这些活动。本文还概述了早期的程序修复工作。 Brumley等人[20]讨论了与修复相反的问题，即基于对为其发布的检查补丁的自动利用程序。 我们的想法是找到补丁中引入的任何新的校验检查，并找到他们防范的输入。攻击者可以利用这些信息，假设这些输入可能是未修补程序的潜在攻击，这些程序通常不会及时收到更新。 代码相似性也可用于漏洞识别。 Tree Edit Distance-Equational Matching [64]是一种用于自动识别包含已知错误的二进制代码区域的方法。在预处理阶段，提取表达树形式的语义信息，其总结在基本块中执行的计算的结果。对于已知错误，这用作签名以定位类似的代码区域，使用基于树编辑距离的以块为中心的度量来测量二进制代码的相似性。该度量标准允许代码中的小型语法差异，并已用于识别软件中的未知漏洞，例如流行的SSH客户端PuTTY的分支。 Pewny等人 [63]提出了使用代码相似性度量在多个CPU架构中基于签名的错误发现方法的概括。 3.2.1 数据结构二进制程序分析的一项基本任务是了解程序特征，以便进一步调查隐藏在代码中的潜在问题。 Laika [28]使用贝叶斯无监督学习来识别程序图像中的数据结构及其实例化。它定位指向潜在数据对象的指针，并使用机器把word转换为块类型的向量作为特征来估计它们的大小。然后使用概率相似性度量将相似序列聚类在一起以确定数据结构的类别。生成的数据结构在病毒检测场景中进行了测试，并证明是高效的。 White和Lüttgen[85]使用遗传编程从程序执行轨迹中识别动态数据结构，方法是将它们与预定义的模板进行匹配以进行标记。模板捕获操纵复杂数据结构（如链表和二叉树）所需的操作，测试表明这种方法能够以较低的误报率推断出这种数据结构。 3.2.2程序结构二进制文件中的结构也扩展到可执行代码。 Rosenblum等 [68]解决了“函数开始识别”问题，或者在剥离的二进制代码中识别函数入口点（FEP）。他们使用基于Conditional Random Fields （CRF）统计建模方法的监督分类算法。每个字节偏移被假定为候选FEP，考虑两个模型：一个基于单个FEP的分类，另一个基于结构方面，例如可以调用其他函数的函数。第一个模型使用短指令模式作为特征集，逻辑回归模型被表述为用于分类的条件随机字段。第二个模型使用CRF使用成对函数/结构调用和重叠特征来模拟函数调用交互。该方法优于使用现有工具（例如Dyninst [37]和商业反汇编IDA Pro）所获得的结果。 ByteWeight [12]改进了这种方法，通过采用基于prefix树的技术来学习用于函数开始识别目的的签名，然后通过将二进制片段与签名匹配来识别函数。这是通过在源代码的参考语料库及其相应的二进制文件上训练分类模型来完成的，其中函数地址是已知的。该模型采用加权的prefix树的形式，其对函数开始字节序列进行编码：如果prefix树中的相应序列终端节点具有大于给定阈值的权重值，则检测实际函数开始。一旦找到函数开始，可以使用其他技术从二进制文件中提取完整函数。 描述二进制文件的一般结构以实现详细分析是许多出版物中探索的目标。例如，BAP [19]是一个多用途分析平台，用于对二进制文件执行程序验证和分析任务。与许多类似的解决方案一样，它将二进制指令转换为中间语言，以便能够以语法导向的形式编写后续分析。以这种方式提供的任务可以包括创建控制流和程序依赖图，消除死代码，执行值集分析以及根据给定的后置条件生成验证条件。 3.2.3。动态分析 VDiscover [34]是一种应用机器学习方法的系统，该方法使用从二进制文件中提取的可伸缩，轻量级静态和动态特性来预测漏洞测试用例是否可能包含软件漏洞。通过检测从程序调用图的随机遍历获得的库函数调用的潜在子序列，从反汇编代码中提取静态特征。动态特征从执行跟踪中捕获，包含用其参数扩充的具体函数调用。为了减少大量的特征值，对参数值进行子类型化，并通过将函数调用的每个执行跟踪视为文档进行预处理，并使用潜在语义分析来降低维数。在系统中测试的机器学习分类算法包括逻辑回归，多层感知器和随机森林。随机森林在一项旨在识别内存损坏程序的大型实验中取得了最好的结果。 3.2.4 符号执行符号执行探索程序的执行空间并生成具有高覆盖率的测试用例。该方法的局限性在于可能的程序路径的数量通常过大。已经提出了各种方案来指导根据一些选定的策略来探索程序路径以克服该问题。李等人 [49]通过检查长度为n的子路径的频率分布来关注较少行进的路径，以便改进测试覆盖率和错误检测。我们的想法是通过维护之前探索子路径的次数来对已经覆盖的子路径进行统计分析。然后，对于给定的执行状态，选择具有最低计数的子路径以继续执行。该策略已在符号执行引擎KLEE [21]中实现，并在GNU Coreutils程序上进行了测试。 Cadar和Sen [22]提供了类似提案的概述，并讨论了与符号执行相关的挑战。特别是，他们专注于更高级别的自动化，例如修剪冗余路径，生成导致错误的输入，甚至创建相应的漏洞。 Avancini和Ceccato [10]使用遗传算法和符号执行来生成测试用例，以识别Web应用程序中的跨站点脚本（XSS）漏洞。他们将这两种技术结合起来，首先执行遗传算法，并在切换到符号执行之前将一组测试用例演化几代。收集，解决和重新插入符号约束作为新的输入值并且执行返回到遗传算法。重复该过程直到满足一些预先定义的终止条件。测试表明，与随机测试用例生成和单独使用的两种方法相比，使用这种组合技术可以实现更高的覆盖率。 BitScope [18]是用于恶意二进制文件自动路径分析的示例平台。它的体系结构包含监视恶意二进制文件内外信息流的组件，优先考虑可用的探索路径，并执行结合二进制符号（复杂）执行以构建公式以表示执行的满意度路径。然后，提取器模块生成已发现代码的控制图，二进制文件沿不同执行路径传输所需的输入以及二进制文件的输入和输出之间的依赖关系信息。然后，从业者可以使用该数据来进一步分析该程序。 基于相似度函数的自动漏洞发现（SFAVD）[53]是一个将源代码中的机器学习与符号执行测试相结合以检测漏洞的过程。首先，使用多步骤过程生成类似于已知易受攻击的一组函数，该多步骤过程包括为每个函数创建抽象语法树表示，将它们枚举成特征向量并对易受攻击的函数执行相似性评估。然后，为具有最大相似性的函数生成函数调用图，并且将KLEE与约束求解器一起使用以确定它们是否易受攻击。测试表明，与仅使用KLEE分析程序相比，可以实现执行时间的显着缩短。 3.2.5 恶意软件虽然恶意软件分析不是软件漏洞研究的各种活动的严格组成部分，但它是机器学习受到广泛关注并且显示有用的相关领域之一。恶意软件分析还可以帮助开发漏洞缓解策略，并且通常采用与其他SVR任务直接相关的技术，从而暴露在这些区域中使用相同或类似ML方法的机会。对恶意软件的分析通常始于相关特征的识别。艾哈迈德等人 [6]从Windows API调用参数和序列中提供的空间和时间信息中提取统计特征。它们包括地址指针的均值，方差和熵以及从API序列的离散时间马尔可夫链建模获得的大小参数和特征。使用这些特征比较各种机器学习算法，包括基于实例的学习器，决策树分类器，朴素贝叶斯，归纳规则学习器和支持向量机，并且它们表明当使用时可以实现改进的结果。用于分类的空间和时间特征的组合。 OPEM [71]还使用一系列算法检查恶意软件，例如决策树，贝叶斯分类器，支持向量机和k近邻，但使用了一组不同的特性。静态功能基于恶意软件中的固定长度的操作代码序列的频率。动态要素从执行跟踪中提取为二进制向量，表示可执行文件中存在特定的系统调用，操作和引发的异常。使用信息增益将特征减少应用于静态特征，以便产生可管理的特征集。结果表明，与仅使用单一类型的特征相比，组合的静态和动态特征产生更好的结果。安德森等人[9]描述了仅使用一种类型的特征的示例，在这种情况下，使用来自动态收集的指令轨迹的特征。指令序列被转换为马尔可夫链表示，形成有向指令跟踪图（ITG），由加权邻接矩阵表示。两级支持向量机用于分类并产生高度准确的结果。不幸的是，用于确定ITG之间相似性的图形内核对于大图来说计算起来可能很昂贵。 Gascon等 [33]也使用SVM，但它通过采用受线性时间图内核启发的显式映射，基于函数调用图的结构嵌入来推导其特征，从而产生静态特征集。在测试中，使用此技术实现的恶意软件检测率相当高，误报率低。 Saxe [42]提出了一系列相似性措施，以抵抗恶意软件中的混淆，以更好地识别它们所属的类。这是一项重要任务，因为确定恶意软件样本的正确组可以协助归因和后续活动。这个想法是对整个恶意软件的完全混淆是困难的，因此即使在个体相似性度量无效的情况下，使用多种分析技术也应该产生可靠的结果。提出的四种措施基于PE（可移植可执行）元数据相似性，动态相似性，指令 - 克相似性和文件相似性。与其他可用技术（如群集）相比，此方法是识别恶意软件组的更简单且更具可扩展性的解决方案。 3.2.6 二进制文件的归属也可以对二进制文件进行作者分析。 Rosenblum等 [69]收集具有已知作者身份的程序集，并使用控制流图和指令序列，根据特征和标签之间的相互信息，从每个程序中提取和确定相关的文体特征。这些功能使用支持向量机分类器进行测试，并用于学习一个度量，该度量最小化同一作者在程序之间的特征空间中的距离。然后，该度量与k-means聚类一起用于对未知作者的程序进行分组。该技术实现了合理的性能（正确作者排名在前五位的时间的94％），这使得论文的作者得出结论，程序员风格可以通过编译过程得以保留。随后提出了对该技术的若干改进。 Alrabaee等 [8]认为需要更加分层的方法。首先，预处理层过滤掉库代码以消除与样式无关的功能。然后，代码分析层提取对应于源代码词汇表的二进制代码块，以构建用于分类的作者分类。最后，一个寄存器流分析层使用寄存器流程图来描述寄存器的操作方式，用于定义作者风格的签名和识别程序作者。与[69]中取得的结果相比，归因准确度有所提高。但是，这些方法都没有专门设计用于处理具有多个作者的程序。 Meng [54]为团队编写的属性代码引入了新的块级功能。在分析从属性源代码[55]生成的机器指令之后，基本块被确定为属于单个作者的合适候选者。因此，在这个级别提出了几个新功能，以补充以前的现有功能。基本块的线性SVM分类器与早期报告的结果相当，表明作者身份识别在基本块级和多个作者中都是实用的。 4.总结在本文中，我们报告了软件漏洞研究社区最近涉及使用机器学习的一些活动。虽然没有提供详尽的清单，但我们的目的是提供一份代表性的出版物集，说明使用ML支持SVR。我们发现，除了寻找解决大型代码库的解决方案的新方法之外，SVR中最大的主题是帮助代码审计员等从业者，尽可能简化或自动化他们的流程。机器学习是越来越多地用于改进传统方法的工具之一。它已成功应用于解决单个SVR任务或通过多个步骤来提供复杂过程的指导。在这个角色中，ML应该继续受益于未来。 SVR中仍然存在有限使用ML的区域（例如，模糊测试[38]），甚至那些当前利用机器学习的区域也可以改进，因为提出了新的，更有效和更有效的技术。识别这些趋势并认识到它们对特定SVR问题的适应性并非易事，并且需要SVR从业者，程序分析和机器学习专家之间的密切联系。特别是，我们认为使用语义输入信息的机器学习而不是其在句法特征上的应用可以为许多SVR活动产生更有意义的结果。最后，我们想要认识到最近几个旨在为软件漏洞研究目的提高认识和鼓励协作的方法。 2016年网络大挑战[2]是研究人员之间的竞赛，旨在评估软件，测试漏洞并在网络计算机上自动生成和应用安全补丁。MUSE项目[56]是一项正在进行的计划，旨在通过开发自动构建和修复软件程序的方法，寻求来自多个学科的专家使用大数据分析来提高软件可靠性。","content":"<h1 id=\"Abstract\"><a href=\"#Abstract\" class=\"headerlink\" title=\"Abstract\"></a>Abstract</h1><p>搜索和识别计算机软件中的漏洞具有悠久而丰富的历史，可用于预防或恶意目的。在本文中，我们研究了机器学习（ML）技术在软件漏洞研究（SVR）中的应用，讨论了以前和当前的工作，以说明学术界和工业界如何利用ML。我们发现，主要关注的不仅仅是发现新方法，而是通过简化和自动化流程来帮助SVR从业者。考虑到已经证明的各种应用，我们相信ML将在未来继续为SVR提供帮助，因为探索了新的使用领域，并且可以使用改进的算法来增强现有功能。</p>\n<table>\n<thead>\n<tr>\n<th>relevant information</th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><em>作者</em></td>\n<td>Tamas Abraham  and Olivier de Vel</td>\n</tr>\n<tr>\n<td><em>单位</em></td>\n<td>Cyber and Electronic Warfare Division  Principal Scientist<br>Defence Science and Technology Group</td>\n</tr>\n<tr>\n<td><em>出处</em></td>\n<td>Cyber and Electronic Warfare Division</td>\n</tr>\n<tr>\n<td><em>原文地址</em></td>\n<td><a href=\"https://www.dst.defence.gov.au/sites/default/files/publications/documents/DST-Group-GD-0979.pdf\" target=\"_blank\" rel=\"noopener\">https://www.dst.defence.gov.au/sites/default/files/publications/documents/DST-Group-GD-0979.pdf</a></td>\n</tr>\n<tr>\n<td><em>源码地址</em></td>\n<td></td>\n</tr>\n<tr>\n<td><em>发表时间</em></td>\n<td>2017年</td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"1-简介\"><a href=\"#1-简介\" class=\"headerlink\" title=\"1. 简介\"></a>1. 简介</h1><p>创建计算机软件是一个非常重要的复杂过程，通常会产生包含一些缺陷和脆弱点的代码。大型代码库的验证可能很困难，或者有时由于成本而被忽略，导致操作系统由于它们表现出来的意外和不良行为而可能崩溃或被操纵。虽然软件安全性错误的严重程度是可变的，但有些可能会非常严重，以至于被利用导致生产力损失，知识产权损失甚至物理损坏来对用户造成严重伤害。 Dowd等人[30]将术语软件错误中能被用于恶意目的的子类称为漏洞， 虽然在特定环境中实际利用漏洞可能并非总是可能，或者也不适合攻击者的目标。解决易受攻击软件引起的问题的方法已经在软件漏洞研究（SVR）中创建了研究。<br>对影响计算机系统的漏洞的研究不仅限于软件。但是，我们在本文中的重点是基于软件的漏洞，我们不考虑硬件或系统架构。软件本身可以作为源代码或二进制文件进行分析，提供多种途径来发现漏洞。软件漏洞的研究过程可以定期分为发现，分析和利用的过程，并将缓解作为预防活动[73]。每个阶段探讨了处理漏洞的不同方面，通常需要代码审计员等从业者的长期和费力的投入。自动化在许多SVR活动中起着重要作用，然而目前通过人工解释发现了大多数漏洞。越来越多的机器学习（ML）技术被整合到SVR过程中，以进一步减少对手动交互的需求。成功应用后，ML算法可以引导用户找到最可能的解决方案，并可能发现以前未知的漏洞。本文的目的是对利用机器学习的SVR内部的目录进行编目，以突出当前事业的状态，并确定可能在未来做出进一步贡献的可能领域。</p>\n<h1 id=\"2-背景\"><a href=\"#2-背景\" class=\"headerlink\" title=\"2. 背景\"></a>2. 背景</h1><p>本文的重点是机器学习在软件漏洞研究中的应用。为了进行讨论，我们分别介绍了两个领域和一些一般细节。在审查各个出版物时，后续章节将根据需要提供进一步的详情。接下来是对这两个研究领域的简单概述，在这个阶段，没有强调它们之间的任何联系。</p>\n<h2 id=\"2-1-软件漏洞研究\"><a href=\"#2-1-软件漏洞研究\" class=\"headerlink\" title=\"2.1 软件漏洞研究\"></a>2.1 软件漏洞研究</h2><p>对软件漏洞进行分类不是一项简单的任务。特定漏洞所属的类别通常在分析软件错误期间显示。有时，在漏洞发现过程中可以预期某种类型，因为某些技术隐含地针对有限范围的漏洞类型。<strong>扫描程序</strong>等工具会查找错误的结构，例如过时的库函数以及代码中的其他与安全相关的错误。<strong>模糊测试</strong>是为软件可执行文件提供异常输入以引起意外行为（如崩溃或内存泄漏）的过程，然后可以在相应的源代码中进行调查。全面的<strong>手动代码审查</strong>也可用于发现错误，但它们可能是其他漏洞发现方法的昂贵替代方案。<strong>格式校验</strong>提供了正确性的数学证明，如果不成功，则可以指出问题。然而，由于复杂性和成本，它通常限于小代码段或算法。<strong>符号执行</strong>是一种分析通过程序分支遍历变量值（输入）的技术，是另一种发现方法，尽管它可能遭受诸如路径爆炸之类的扩展问题。</p>\n<p>源代码中的一些错误可能很容易组合，尽管某些漏洞仅与其他因素（例如它们部署在其上的平台）结合使用，因此可能难以进行初始分类。计算机体系结构，操作系统，计算机语言的多样性以及语言特定错误的存在使分析更加复杂化。我们使用Dowd等人的书中给出的分类法 [30]作为定义软件漏洞类型的指南。语言特定问题包括：</p>\n<ul>\n<li><p>内存损坏，例如缓冲区（堆栈，off-by-one，堆，全局和静态数据）</p>\n</li>\n<li><p>算术边界条件（如数字上溢和下溢）</p>\n</li>\n<li><p>类型转换错误（有符号/无符号，符号扩展，截断，比较）</p>\n</li>\n<li><p>操作符误用（sizeof（），移位，模数，除法）</p>\n</li>\n<li><p>指针算术错误</p>\n</li>\n<li>其他错误（评估顺序逻辑，结构填充，优先级，宏/预处理器，拼写错误）</li>\n</ul>\n<p>其他漏洞更复杂。问题类别包括实际应用程序中存在的问题类别，例如与操作系统或应用程序平台相关的问题类别，即使基础问题可能由更简单的错误（如内存损坏或指针错误）引起：</p>\n<ul>\n<li><p>字符串和元字符漏洞</p>\n</li>\n<li><p>特定于操作系统的漏洞（特权问题，文件权限问题，竞争条件，进程，IPC，线程，环境和信令问题）</p>\n</li>\n<li><p>平台漏洞（SQL注入，跨站点脚本（XSS） ），跨站点请求伪造（CSRF），文件包含和访问，shell调用，配置，访问控制和授权？aws）</p>\n</li>\n</ul>\n<p>对漏洞进行分类的另一种方法是从攻击角度出发。例如，Open Web Application Security Project [3]提供了一个攻击类型列表，并定期编译一系列顶级当代漏洞[1]，并非所有漏洞都与源代码或二进制文件有关。在那些注入攻击（代码，SQL，HTML脚本，远程文件和shell）和控制流劫持，如溢出（buffer，整数，字符串格式）和堆喷射类似于我们上面列出的那些。像Bletsch这样的其他作者提供类似的分类，讨论如何通过代码重用（面向返回的编程（ROP），返回到libc（RILC），面向跳转的编程（JOP））来利用漏洞[80]。 。</p>\n<p>随着软件中的漏洞被发现，它们通常与更广泛的社区共享。The Common Vulnerabilities and Exposures  （CVE）是一个公知的信息安全漏洞和风险的库 [4]，目前由MITRE组织维护。漏洞通常附加一个分数来描述其严重性，通用漏洞评分系统（CVSS）[40]是最常用的评分标准之一。提供对CVE，分数和其他相关信息的访问的服务包括诸如开源漏洞数据库（OSVDB）和美国国家漏洞数据库（NVD）之类的数据库。和允许对新发现的漏洞进行实时更新的API（如VulnDB和vFeed）。根据不同类别中发现的漏洞数量，每年都会根据流行漏洞编制统计数据，尽管每种类型的攻击频率和严重程度之间可能没有相关性。例如，Price和Kouns [46]列出了跨站点脚本，SQL注入，跨站点请求伪造，文件包含，拒绝服务和过度攻击，这是2014年根据OSVDB最常见的滥用行为。</p>\n<p>减轻软件漏洞影响的方法也产生了各种策略和解决方案。尽管可能无法实现完全错误预防，但软件生产商仍希望尽量减少其产品包含漏洞的可能性。这些包括在开发周期中的全面测试和修复错误，在软件发布后提供数据，以及在安全编程语言中编写代码。在Vanegue [82]中列出了在软件发布之前可以使用的漏洞发现技术列表，例如软件测试，模糊测试和程序验证（定理证明，抽象解释，模型检查）。使用抽象语法树（AST），控制流图（CFG），程序依赖图（PDG）和代码属性图（CPG）等图形建模代码执行可以帮助识别开发过程中的问题。 OS和硬件制造商也提供了软件发布后使用的其他缓解技术。数据执行保护（DEP）/不执行（NX），地址空间布局随机化（ASLR），指令集随机化（ISR），运行时检查（金丝雀，LibSafe），程序引导，控制流完整性（CFI），数据流完整性（DFI）和控制流锁定是当前使用的一些技术，参见[80]。用于执行各种发现任务的软件工具随时可用，包括商业和开源[87]。</p>\n<p>程序分析是分析软件行为问题的核心。从理论上讲，软件错误的识别是不可判定的，即在一般情况下不可能编写程序来表示和计算另一个程序的所有可能的执行[67]。在实践中，某些程序行为可能会被忽略，因为它们与当前分析无关。然而，这可能导致在近似下 - 排除可能有效的行为，并且过度近似–包含可能但无效的行为–增加复杂性和资源需求。图1将一些程序分析技术组织到一个图表中，突出显示了各个方法的样式和自动化级别。静态分析在不执行程序的情况下进行，可以提供良好的代码覆盖率和所有可能执行的原因，但无法分析可执行环境，例如操作系统和硬件。另一方面，动态分析是在程序执行期间进行的，或者通过检测程序来分析行为。但是，它只能推断观察到的执行路径而不是所有可能的程序路径。</p>\n<p><img src=\"/2019/04/03/A-Review-of-Machine-Learning-in-Software-Vulnerability-Research/1.jpg\" alt=\"\"></p>\n<h2 id=\"2-2-机器学习\"><a href=\"#2-2-机器学习\" class=\"headerlink\" title=\"2.2 机器学习\"></a>2.2 机器学习</h2><p>在本节中，我们简要概述了机器学习概念，并重点介绍了我们在本文后面讨论的出版物中遇到的一些相关技术。<br>存在许多不同的分类法用于分类ML技术。为方便起见，我们使用Barber [13]的书作为本节的参考源，除非给出了具体的参考。</p>\n<p>机器学习领域关注数据的自动化探索，产生可用于预测的描述性模型。通常，认识到两种主要的学习方式：<strong>监督学习</strong>从标记数据源构建其模型并关注预测的准确性，而<strong>无监督学习</strong>则集中于从未标记数据提供紧凑描述。除了这两种主要风格外，还可以观察到几种变化。<strong>异常检测</strong>会查找与建模模型不同的数据中的异常值。随着新数据的出现，<strong>在线学习</strong>能够不断更新模型。<strong>主动学习</strong>可以通过要求来自当前模型无法有效描述的环境区域的更多数据来构建更好的模型。<strong>强化学习</strong>能够以反复试验的方式与环境互动，以创建根据某种形式的奖励进行优化的模型。最后，<strong>半监督学习</strong>利用标记和未标记的数据，使用一种类型的数据来改进可以仅从其他类型的数据创建的模型。</p>\n<p>多年来，在上述学习方式中已经提出并开发了大量算法。监督学习主要使用多种类型的分类器中的一种来预测数据点所属的组（类）。这是一种离散学习形式，因为输出仅限于一组值。当结果需要在一个值范围内时（即它是一个连续变量），回归就是使用的技术。最简单的分类算法之一是K-最近邻（kNN）算法，它通过查看其K个最近邻居的标签并选择最常见的邻居来确定数据点的类标签，例如基于实例学习使用数据集中的示例而不是使用从中构建的模型来决定类的决策。 NaïveBayes分类器是一种概率算法，它假设描述数据的变量之间具有条件独立性，以简化生成模型的构建。点的类标签是通过使用贝叶斯规则给出不同标签的数据的概率及其条件概率来估计的。其他分类技术对数据进行线性模型，并根据与已知示例计算的决策边界相对应的数据点的位置确定类成员资格。逻辑回归是一种分类算法，它使用最大似然函数来近似属于类的数据点的概率。线性支持向量机（SVM）产生超平面以分离类，使得平面每侧上的最近点之间的距离最大化。</p>\n<p>决策树分类器将顺序决策过程建模为特殊图形，每个节点用作特征测试，以便给定特征的不同值沿着不同的分支布置。树的叶子决定了类型成员资格。从任何特定的示例数据集中，可以构建许多不同的树，并且通常使用来自单个数据集的多个树的组合来构建更好的模型。随机森林是决策树的集合，旨在提供对作为单个树创建的模型的改进预测。图表在表示用作分类器的各种形式的神经网络（NN）[14]中也很突出。神经网络按节点层组织，包含输入层和输出层，其间有隐藏层。每个节点对应于一个函数，该函数使用分配给节点连接边的权重将其输入值映射到单个输出值。 NN分类的流行变体包括多层感知器（MLP）前馈神经网络，卷积神经网络和长期短期记忆复现神经网络。神经网络也是深度学习的核心，深度学习是一种机器学习范式，它也关注数据表示的学习。</p>\n<p>无监督学习通常与聚类分析相关联，即基于相似性的定义将数据组织成组。这些可以包括基于数据分布的统计方法，例如使用期望最大化（EM）来构建高斯混合模型（GMM）。利用数据连接的算法是层次聚类的示例，或者是自下而上构建的，即从每个数据点开始作为集群然后是合并操作，或者自上而下，从单个集群开始并根据某种策略进行拆分。基于质心的聚类通过确定选定数量的聚类中心并将每个数据点分配给最近的聚类中心来识别聚类。另一方面，基于密度的聚类根据某个距离测量的阈值找到彼此接近的点集群，并且如果它们不满足这些要求，则可以将数据保留为未分配的噪声。Associations [5]是受市场数据分析启发的规则。它们代表了if…then构造描述数据中以某种最小所需频率出现的强模式。找到频繁项目集或特征值比其他项目更频繁地出现，可以揭示数据的趋势。顺序模式挖掘是一种具有相同目标的学习活动，但随着时间的推移分析数据，利用数据点的时间顺序来构建模型。遗传算法也是规则发现算法，它通过将交叉和变异算子应用于初始数据集并评估后续世代的精度直到满足某些终止条件来模拟自然选择。</p>\n<p>学习通常先于预处理过程，然后是模型评估等任务。一些预处理包括特征提取，以及数据中噪声和错误的处理。特征选择和降维旨在识别与学习任务相关的特征并降低复杂性以便改进由学习算法生成的模型。有监督和无监督的学习者都可以从这个过程中受益。一些重要的例子包括主成分分析（PCA），线性判别分析（LDA），非负矩阵因子分解（NMF）和奇异值分解（SVD）。采样以减少数据大小和平衡输入数据可以提高算法的效率和性能。使用套袋和增强等集成方法可以提高单个学习算法的预测性能。出于评估目的，可以使用性能评估方法来评估算法的有效性。在二进制分类中，可以使用若干概念来描述预测条件与数据点的实际条件之间的关系。真阳性（TP）或命中，是正确预测的阳性实例。假阳性（FP）是错误预测为阳性的阴性实例。对于真阴性和假阴性，存在类似的定义。真阳性率（TPR）或算法的召回是所有阳性实例的真阳性率。精度是TP与TP和FP之和的比率，表示在预测正实例时所犯错误的数量。算法的准确性是所有数据点上正确识别的实例（TP加TN）的比率。存在许多模型评估方法，例如ROC分析[31]。结合起来，它们不仅可以提供算法评估，还可以确定其他学习策略，例如不同的特征选择方法或参数优化。</p>\n<p>机器学习已应用于众多研究领域。可以与检查计算机程序相关的一个是自然语言处理（NLP），这是一个关注语言建模，解析和语音识别等任务的领域。可用于文档分类的一些值得注意的技术包括Latent Dirichlet Allocation（LDA）和Latent Semantic Indexing（LSI），它们都将文本建模为主题集合。</p>\n<h1 id=\"3-机器学习在软件漏洞中的研究\"><a href=\"#3-机器学习在软件漏洞中的研究\" class=\"headerlink\" title=\"3.机器学习在软件漏洞中的研究\"></a>3.机器学习在软件漏洞中的研究</h1><p>机器学习可以为软件漏洞研究等复杂的研究领域带来许多好处。它可用于模拟代码的语法和语义，并推断代码模式以分析大型代码库，协助代码审计和代码理解，同时实现可容忍的误报率。随着SVR流程复杂性的增加，对SVR从业者可用的自动化水平的需求也在增加。结果，提出了用于发现和预防目的的分析软件的新方法。其中一些是特别的。其他人使用来自其他科学领域的现成技术，包括统计学，机器学习和数据挖掘。在接下来的部分中，我们将讨论利用主要机器学习的现有工作，根据基于内容相似性的松散分组来组织它们。</p>\n<p>我们首先指出一小部分最近的论文，这些论文考虑在更广泛的层面上解决软件漏洞问题。例如，Avgerinos等 [11]承认在广泛使用的大型软件项目中存在软件错误，例如Firefox浏览器和Linux内核，一些已知，但其他可能仍未被发现。由于在关键软件中发现了如此多的错误，作者提出了以下问题：“我们应该尝试优先修复哪些错误？”，“我们可以确定哪些是可利用的？” Jimenez等 [41]可能表明未来可能的方式。他们分析过去已知的漏洞（在本例中为Android）并建立一个分类，列出导致软件漏洞的问题，漏洞所在代码中位置的特征，这些位置的复杂性以及漏洞的复杂性。创建公共数据集，如VDiscovery [34]收集测试用例的结果，并可用于促进进一步的研究是另一项有希望的举措，众包试的寻找bug的想法这个模型由zhao等人描述[93]。</p>\n<h2 id=\"3-1-源代码分析\"><a href=\"#3-1-源代码分析\" class=\"headerlink\" title=\"3.1 源代码分析\"></a>3.1 源代码分析</h2><p>如前所述，减少SVR人类从业者的手动任务量是许多提议方法的主要目标。自动化的例子包括Parfait [26]，一个用于发现C / C ++代码中的错误的框架。 Parfa的每个bug类型都设计有多层，用于速度和可扩展性的程序分析。该解决方案背后的理念是采用更简单的分析来预测某些类型的错误，然后转向计算量更大的错误，以实现最佳的覆盖率和精度。另一个平台Mélange[74]也分享了同样的理念，同时也分析了C和C ++代码。 Mélange执行数据和控制流分析，并生成错误报告，以解释发现的错误，以帮助解决必要的问题。在执行阶段进行分析，包含局部和全局，后者按需使用以验证局部分析的结果。另一个例子是SZZ算法[88]，它被开发用于自动识别诱导修复的代码提交，并且可以被研究人员用来验证软件度量或模型以预测故障组件，这是防止bug的重要活动。</p>\n<p>然而，这些方法是向自动化迈进并不一定依赖于机器学习技术的示例。以下类别详细说明了它们的用途。</p>\n<h3 id=\"3-1-1-编码实践\"><a href=\"#3-1-1-编码实践\" class=\"headerlink\" title=\"3.1.1 编码实践\"></a>3.1.1 编码实践</h3><p>用于代码分析的机器学习的早期用途之一是PR-Miner [50]，数据挖掘技术的应用，为源代码构建一组编程规则。它从大型代码库（如Linux，PostgreSQL和Apache HTTP Server）生成频繁的项目集，以自动生成隐式编程规则，然后可以使用其他算法检查违规。对结果进行排序并按照假设的严重程度提供给分析师，以确定它们是否构成实际错误。这个过程很快，作者认为它能够识别比使用用户定义模板的类似工具更复杂的违规行为（例如，包含两个以上的规则组件）。 AutoISES [77]是一种类似的工具，它通过从源代码推断安全规范来检测漏洞，而不是要求手动提供这些漏洞。规范的推断仍然受到与安全编码实践相关的概念的指导，但现在根据代码中观察到的证据提取规则，并且违规被提供用于手动验证。 Linux内核和Xen用作测试用例，对于84个提取规则，发现了8个新漏洞。</p>\n<p>协助开发人员正确使用应用程序编程接口（API）方法一直是一些论文的焦点，通常受到缺乏足够可用文档的启发。<br>UP-Miner工具[83]采用了几种数据挖掘方法，例如聚类和频繁闭合序列挖掘，以创建频繁的API使用模式。它还包含新的度量标准，以优化所得模式的简洁性和覆盖范围，然后将其作为概率图提供给用户以供检查和理解。与Microsoft开发人员合作对大型Microsoft代码库进行的测试证实了该方法的实用性。Nguyen等人详细介绍了另一个有趣的贡献 [59]。他们研究API前置条件，这些条件需要在调用之前通过API方法的参数来满足。他们开发了一个系统，该系统找到调用API的客户端方法，计算每个调用站点的控制依赖关系，然后挖掘用于访问这些调用站点的条件，最终推断出每个API的前提条件。使用SourceForge和Apache项目对Java Development Kit进行的大规模评估确定了书面规范中缺少的一些先决条件。此外，结果可用于识别不满足源代码中的前提条件的编码错误。本文还对早期API挖掘文献中的参考文献进行了很好的收集。</p>\n<p>VCCFinder [62]是一个工具，它将有关代码中的漏洞的知识与有关对存储库的commits的元数据相结合，以识别可能存在漏洞的软件代码commits。为两种源类型的每个提交生成的一系列功能与已知的漏洞贡献提交案例的功能相匹配？ （VCC），从CVE的提交数据中识别，以确定新提交是否可能是漏洞的来源。为此目的构建了两级SVM。对66个GitHub项目的测试表明，与现有工具相比，误报率（FPR）大大降低，同时保持了类似的真阳性率。虽然成功识别VCC可以大大减少检查安全性的代码量，但是从业者仍然需要重要的专业知识和审核它们的手册。</p>\n<h3 id=\"3-1-2克隆检测\"><a href=\"#3-1-2克隆检测\" class=\"headerlink\" title=\"3.1.2克隆检测\"></a>3.1.2克隆检测</h3><p>重复代码不仅会使软件项目由于代码膨胀而更难以维护，而且还会因为复制粘贴编程而分散在大型代码库中问题的问题难以解决。因此，检测克隆在文献中引起了很多关注，包括从脆弱性的角度来看。 Roy等人最近的一项调查 [70]提供了克隆检测技术的概念和定性比较和评估。与克隆检测相关的许多研究都集中在确定代码片段相似性以定位复制的代码。Udagawa [81]提出了一种代码结构基础的方法，使用解析器提取从Java源代码片段词汇数据，并应用相似性度量通过令牌的完全匹配序列的数目的比率定义到部分序列匹配状态的数量。 Lazar和Banias [47]在基于结构的方法的另一个例子中使用抽象语法树在多个文件集中使用子树相似性度量。这些通常优于基于文本或令牌的方法，因为它们对代码和变量名称更改是健壮的，尽管由于可伸缩性问题它们通常不适合大型程序。</p>\n<p>克隆检测算法也被用于与机器学习相结合的bug修复目的，例如Steild和Göde[76]。他们的想法是从克隆中提取特征，并在训练分类模型后，确定类似的克隆是否具有不完整的bug修复。克隆检测本质上是基于令牌的，即语句被标记化而不是表示为树，并且这反映在从代码片段中提取的特征类型中：全局上下文特征与本地词汇特征相互补充，允许克隆中的轻微不一致。作者研究了多种分类技术，发现决策树是最有希望的，并且对用户来说是一种易于理解的表示。测试结果表明，即使假阳性与真阳性的比例很高（大约四个五分之一是假的），与人工分析相比，他们的方法代表了显着的改善。</p>\n<p>进一步采用克隆检测的概念，C3系统[45]研究了源代码库中的代码变化。这个想法是通过自动定位类似的代码更改来简化bug修复的应用，而无需与用户交互和/或现有的代码更改模式，将其传递给其他应用程序工具。提出了两种相似性度量，一种基于传统的基于二维的表示，另一种基于抽象语法树，其用于提取的代码变化以生成相似性矩阵。然后使用聚类来检测类似变化的组（而不是与克隆的情况相同的组）。大型代码存储库的结果表明，它们可以以高效的方式交付，其成功率类似于专家手动提取所获得的成功率。</p>\n<h3 id=\"3-1-3错误检测\"><a href=\"#3-1-3错误检测\" class=\"headerlink\" title=\"3.1.3错误检测\"></a>3.1.3错误检测</h3><p>代码错误无论是否可利用，都难以识别，特别是在大型软件项目中。在源代码的情况下，一些更常用的发现错误的技术包括使用模板来指导搜索已知漏洞;检查源代码文件的内容并与已知的易受攻击者进行比较;并分析代码结构以诊断潜在的错误。通常，使用方法的组合来强化结果，这些活动的主题要么是识别与正常不同的代码，要么是识别与类似的已知坏的代码。</p>\n<p>当用于定位特定的漏洞模式时，使用先验知识可能非常有效。被忽视的条件是Chang等人的主题 [25]。他们的方法要求用户指定用于从代码中学习条件规则的约束，该代码用于发现指示被忽略条件的违规。提取的规则表示为图形和最大频繁子图挖掘算法，后跟图形匹配算法分类规则违规。可以咨询用户以评估所提取的规则的有用性并在匹配发生之前调整它们。使用这种方法测试了各种开源软件项目，并揭示了以前未知的违规行为。 Alattin [79]是另一个使用一种名为ImMiner的修改频繁模式挖掘算法来识别被忽视条件的提议。它引入了替代模式的概念，作为在程序中执行相同API调用的两个规则的分离。当两个单独的模式频繁时，替代模式称为平衡;当只有一个时，替代模式被称为不平衡，并且可以用于程序理解和缺陷检测。已经开发了频繁项集挖掘算法的变体来搜索平衡和不平衡的替代模式，并且应用于检测API调用周围的被忽略的条件。与类似的解决方案相比，该方法测试良好，可作为Eclipse插件使用。</p>\n<p>描述正常行为而非违规的模式也用于错误检测。Gruska等 [35]解析大量的软件项目，以提取表示函数调用之间的数据流的频繁时态属性。然后使用异常检测算法来使用关联规则提升措施来检测对学习模式的违反，以对它们进行排序和过滤以供用户评估。在实际测试中，排名靠前的25％的违规行为被发现是问题，无论是实际缺陷还是代码设计中的弱点。</p>\n<p>将源代码作为文档集处理并构建描述它们的模型是另一种开发对软件项目的理解的方法。 Lukins等人[52]使用Latent Dirichlet Allocation生成关于字符串文字，注释和标识符的主题模型，然后在几个案例研究中使用手动制作的错误描述查询来评估它们。他们发现他们的技术与竞争方法相比具有优势，并且在大型源代码库中使用时可以很好地扩展。 Hovsepyan等 [39]还会查看单个源代码文件，并通过删除注释，字符串和数值将其转换为特征向量，并将剩余的代码元素（关键字，变量和函数名称）标记为监督学习的特征词。在运行支持向量机算法之前，将标签分配给每个文件以训练用于预测从测试文件中提取的易受攻击的特征向量的模型。该技术能够以较低的错误发现率识别大多数测试的漏洞，并且旨在补充基于软件度量的现有漏洞发现解决方案。Pang等人[60]通过将n-gram包含在生成的特征向量中来扩展这项工作。考虑多达五个令牌的序列而不是单个单词，并且为了避免产生的特征爆炸，使用统计特征选择算法来提供排名。然后，前20％的特征与SVM算法一起使用。对四个Android Java项目的测试取得了比早期尝试稍微更好的分类结果。 Scandariato等[72]在将源代码文件标记化为特征向量时，使用单个单词（包括注释和字符串值），但引入离散化以对各种特征计数进行分类，以便改进其机器学习算法生成的模型。除了SVM之外，他们还使用决策树，k-最近邻居，朴素贝叶斯和随机森林进行测试，后两种算法在他们的实验中表现最佳。本文还回顾了以前的可比较的工作，包括那些依赖软件指标来确定文件是否包含软件漏洞的工具。这些在文本挖掘解决方案的指标的优化是Tang等人的主题 [78]。他们认为虽然许多基于机器学习的解决方案可能会显示出改进的结果，但它们并不足以证明应用这些模型而不是基于软件指标的模型所需的额外成本是合理的。</p>\n<p>许多研究人员研究利用程序结构特性的解决方案。机器学习已经在Kremenek等人中使用。 [44]研究源代码程序分析和概率图模型的组合，以直接从程序中自动推断程序规范。通过创建注释因子图来进行推理，该图可用于在检查任何推断的规范之前通过其概率对可能的错误进行排序。对开源代码库的测试表明，在内存分配/释放规范的情况下，真正的阳性率很高。彭等人[61]探索深度学习对程序分析的可能性。他们认为基于自然语言令牌的粒度可以产生稀疏数据，而是将抽象语法树节点编码表示为矢量，将AST中的节点编码为单个神经层。然后将它们用作卷积神经网络的输入，用于深度监督学习以对程序进行分类。使用k均值聚类进行矢量表示的定量评估，以表明类似的节点可以成功地组合在一起，而对分类任务的定性评估显示，与基线分类器（如逻辑）相比，深度学习的结果比回归和支持向量机稍微优越一些。</p>\n<p>利用特定于漏洞发现的程序结构一直是Yamaguchi及其合作者的焦点。抽象语法树节点的潜在语义分析[90]是在审计源代码库期间向安全分析师提供帮助的早期尝试。在提取API和语法节点之后，它们被嵌入到向量空间中，并且使用LSA来识别结构模式以生成主题。然后可以将这些与已知漏洞识别的特征进行比较。对几个开源项目的测试有助于发现新的零日漏洞。缺少检查是另一个Yamaguchi等人的目标。详细介绍了Chucky [92]，这是一种异常检测器，可以静态地污染源代码，并识别源代码中与安全关键对象相关的异常或缺失条件。在提取抽象语法树之后，使用k近邻算法来执行相关函数的邻域发现。轻量级污染，然后将函数嵌入向量空间，然后通过几何比较检查与代码库其余部分中类似函数嵌入的已知检查，识别异常，可以比较缺失的检查。 Chucky经过测试，以极高的检测率诊断已知漏洞，并且还能够通过生成各种开源项目的异常排序列表，帮助分析师识别以前未知的漏洞。Joern项目[89]引入了代码属性图（CPG）的概念，它是抽象语法树，控制流图（CFG）和程序依赖图（PDG）的组合，三个现有的代码表示，每个代码都是能够捕获一些但不是所有对漏洞研究很重要的软件特征。这个想法是，CPG将这些特征结合起来，形成一个可以用来更普遍地模拟现有漏洞的表示。然后检查代码库将成为构建代码并将代码表示为CPG的练习，并针对生成的图形发出图形遍历查询以找到漏洞模式的匹配项。该平台已针对Linux内核代码库进行了测试，并能够识别18个先前未知的漏洞。设计的局限性在一项提案中得到了部分解决，该提议旨在自动推断污点式漏洞的搜索模式[91]。后置控制器树（PDT）用于增强代码属性图，以捕获在另一个之前执行语句的情况，从而能够检测代码中的函数调用，从而导致对其参数进行修改。然后可以使用这些来生成图遍历模式以搜索污点风格的漏洞。该方法已作为Joern的插件实现，并显示可大幅减少代码检查。</p>\n<h3 id=\"3-1-4-Bug修复和补丁\"><a href=\"#3-1-4-Bug修复和补丁\" class=\"headerlink\" title=\"3.1.4 Bug修复和补丁\"></a>3.1.4 Bug修复和补丁</h3><p>Bug修复，无论是反应性的还是预防性的，仍然是软件开发中的必要活动。 Vulture [57]是一种工具，可以自动从过去的漏洞位置学习，以预测新组件在完全实施之前的未来漏洞。这是通过从源代码组件中提取import语句并应用频繁模式挖掘来确定它们是否与现有漏洞相关来实现的。然后可以使用基于项目导入矩阵构建的分类模型和从上一步骤获得的漏洞向量，评估新组件以确定它是否会基于其导入而易受攻击。使用SVM分类器进行预测的系统在Mozilla项目上进行了评估。 Kim等人 [43]提出了一种称为“改变”的技术。在代码行而不是完整的模块，文件或功能上运行的分类。这是通过检查软件配置管理系统中的代码历史来实现的。针对bug修复和根据更改元数据，软件复杂性指标，日志消息和代码的常规提交来提取特征。选择SVM分类器来构建模型，以预测新代码更改是否有缺陷或干净，并在新的更改提交时立即获得结果。本文还分析了不同特征群的预测能力。</p>\n<p>但是，了解软件项目中易受攻击的组件并不能解决这些漏洞被利用的可能性的问题。 Bozorgi等人[15]提出了自动对漏洞进行排序的潜在解决方案。利用CVE和OSVDB等公共漏洞数据库对最有可能被利用的漏洞进行分类和预测。从现有漏洞披露报告中的文本字段，时间戳，交叉引用和其他条目中提取了大量特征。然后在随机平衡样本上训练线性SVM，使用具有漏洞的漏洞的正标签和不具有漏洞的漏洞的负标签。然后，该方法用于研究离线和在线漏洞利用预测，识别与预测最相关的特征，并估计利用漏洞所需的时间。后一主题也在Wijayasekara等人 [86]的研究中进行了研究，其中讨论了使用文本挖掘技术挖掘bug数据库中的错误报告，以帮助发现隐藏的影响漏洞。隐藏影响漏洞是在相关错误通常通过补丁发布向公众披露之后的某个时间识别的漏洞，攻击者可以使用该漏洞发现潜在的高影响漏洞。通过处理（标记，词干等）错误报告中的文本来获得特征向量，并且通过计算贝叶斯检测率或者如果检测到错误是隐藏的影响漏洞的概率来获得分类。并将该bug标为漏洞。 Linux内核和MySQL错误数据库用作数据源。对隐藏影响漏洞与漏洞的比率的分析表明它相对较高，并且在研究的最后两年中还观察到其增加。</p>\n<p>一旦确定了错误并确定了优先级，就必须对它们进行修复。 Prophet [51]是一个自动补丁生成系统的示例，它从开源软件存储库中获取补丁并构建正确代码的模型。该概率模型是在从先前代码修订中提取的成功补丁的特征的初始训练阶段中学习的，并且用于生成新缺陷的候选补丁并对其进行优先级排序。然后验证候选补丁并将其提供给开发者进行手动检查和插入。对来自8个开源项目的69个真实世界缺陷的基准测试表明，Prophet比现有的补丁生成系统更有优势。 GenProg [84]在抽象语法树和加权程序路径上使用遗传编程方法来纠正代码中的缺陷。一旦识别出错误，例如，程序未通过测试用例，就会搜索原始程序的变体，直到找到有效版本。该技术使用观察来通过采用来自程序中的另一位置的现有代码来修复缺陷。通过使用类似的模板改变缺陷代码，可以通过程序成功修补先前失败的测试用例来识别修复。DeepSoft框架[29]是一种雄心勃勃的方法，用于模拟软件及其开发，以预测和降低风险，并自动为已识别的错误生成代码补丁。它采用深度学习，LSTM来模拟源代码及其演变。他表示结合自然语言处理使得能够自动生成用于解决问题的代码补丁。 Le等人 [48]调查应用自动修复软件错误识别案例的有效性。他们有兴趣在合理的时间内进行维修，并认为根据某些定义的时间预算，有时手动而非自动干预可能会更具成本效益。为此，他们构建了一个随机森林分类器，它使用多次GenProg运行来生成数据，并添加了一个有效性指标作为分类标签。随后的模型用作预测未来修复实例的有效性的预言。结果表明，对于更合适的修复类型，正确地识别出四分之三的修复。</p>\n<h3 id=\"3-1-5-缓解和预防\"><a href=\"#3-1-5-缓解和预防\" class=\"headerlink\" title=\"3.1.5 缓解和预防\"></a>3.1.5 缓解和预防</h3><p>在文献中也经常探索减少软件开发过程中引入的错误数量的方法。减少代码错误概率的一种可能方法是引导自动生成正确的代码片段。许多作者讨论了代码完成，包括Hindle等 [36]，他们使用自然语言处理中的n-gram概念来统计模拟代码令牌序列，基于代码类似于语言，重复和可预测的假设。他们发现源代码的熵远低于自然语言的熵。他们从他们的模型开发一个新的Eclipse插件作为概念验证，显示出优于内置代码完成引擎的功能。 Allamanis和Sutton [7]通过编译和分析更大的数据集，进一步扩展到giga-token 模型并引入新的数据驱动指标来衡量代码复杂性。他们证明这些模型在代码建议方面更胜一筹。 SLANG [66]补充了具有递归神经网络的n-gram模型，使用API方法调用以解决在代码中生成完整的holes（间隙，缺少行）的问题。代码完成被视为预测句子概率的自然语言处理问题。由此产生的工具能够合成具有多个语句和参数的复杂解决方案，这些语句和参数可以正确地进行检查，并在90％的案例中包含前3个结果中的所需结果。 DeepSyn [65]是JavaScript程序的代码完成系统。它利用领域特定语言而不是抽象语法树，它删除了代码规范并促进了对部分解析树的学习。然后可以生成该语言中与训练数据最佳匹配的程序，该程序在代码完成任务中表现得比现有解决方案更好。</p>\n<p>Bruch等人讨论了用于智能代码完成的数据挖掘技术 [17]。设计了三个独立的解决方案来改进内置的Eclipse代码建议系统。首先，通过频率计数简单地命令所有可用的建议，而不是默认的Eclipse排序。第二个使用关联规则来查找代码对象之间的相关性，并建议与观察对象密切相关的那些。第三种解决方案是k近邻算法的变体，称为最佳匹配邻居算法。它为代码库中的每个变量提取二进制特征向量，编码有关使用它们的API调用的指示符，并根据汉明距离的修改使用计算当前代码库和示例代码库之间的距离。然后根据所选最近邻居的频率推荐代码完成。在测试中，每个提案都优于默认的Eclipse建议系统，最佳匹配邻居算法产生了领先的结果。</p>\n<p>GraLan [58]是一种基于图形的统计语言建模方法，它计算使用图出现概率并将其用于代码完成。在从源代码示例构建语言模型之后，可以从当前编辑的代码的邻域中提取使用子图，并且可以使用GraLan来计算给定那些使用子图的children图的概率。这些被收集并作为建议的候选API元素排名。这种方法进一步扩展到ASTLan，这是一种基于AST的语言模型，用于在当前编辑位置建议语法模板而不是API元素。 GraLan和ASTLan都比以前的API代码和语法模板建议更有优势，本文还提供了代码完成研究的广泛概述。</p>\n<p>机器学习技术也被用于帮助证明程序的存储器安全性和功能正确性。一个例子是Cricket [16]，这是一种验证工具扩展，它利用逻辑回归和双层神经网络来自动化具有适当不变量的程序注释。最初，只学习形状属性并用于验证堆程序的正确性。如果失败，则在具有数据不变量的第二阶段中加强有效的形状不变量，以再次采用ML算法来改善所获得的存储器安全性证据。</p>\n<p>3.1.6 归属</p>\n<p>代码漏洞分析后的潜在后续活动是代码归属于其作者。这些信息可以识别软件项目之间的关系，可以证明代码的质量和成熟度，并协助开发和应用适当的漏洞预防解决方案。 Caliskan-Islam等 [24]使用机器学习解决了C ++源代码的作者属性问题。他们的方法考虑了三种类型的特征，总共最多20,000个特征：代码样式特征是布局特征，例如不改变程序含义的空格;词法特征来自程序令牌，或具有识别含义的字符串，例如循环次数，if / then语句和注释;语法特征源自AST，如AST节点类型的术语频率逆文档频率（TFIDF）。使用信息增益标准，原始特征集大幅减少，随机森林集合分类器用于作者身份归属，具有高度准确的结果。作者认为语法特征对代码混淆尝试具有弹性，并且发现高级程序员具有比新手更具识别性/唯一性的编码风格。</p>\n<h2 id=\"3-2-二进制代码分析\"><a href=\"#3-2-二进制代码分析\" class=\"headerlink\" title=\"3.2. 二进制代码分析\"></a>3.2. 二进制代码分析</h2><p>二进制文件是源代码的转换，因此，它来自高级编程语言中固有的一些语义损失。因此，漏洞研究中的一些活动，特别是那些旨在防止漏洞被引入软件的活动，要么不可用，要么不适用，要么采用不同的方法或技术。当可以分析源代码和相应的二进制文件时，研究人员有机会使用丰富的数据集。但是，二进制文件通常都是可用的，可以进行调查。与源代码类似，它们可以转换为不同的表示，这可能使一些早期看到的技术适合与此媒体一起使用。但是，不同的计算机体系结构和对相同源代码的不同编译器优化可能会在二进制分析中引入额外的复杂性层。</p>\n<p>自动化仍然是二进制代码的SVR活动的主要目标。一些示例包括GUEB [32]，一种静态工具，用于检测反汇编代码上的释放后使用（UaF）漏洞。它利用抽象存储器表示，在其上执行值集分析，使用控制流图的正向遍历来促进UaF检测。 Sword [23]是一个自动模糊测试系统，它优先考虑二进制区域以进行模糊测试。它结合了多种漏洞检测方法来提高效率，即搜索和识别目标程序所需执行路径的符号执行，以及污点分析以检查执行路径并生成路径相关信息以引导模糊器执行漏洞分析。 Code Phage [75]是一个自动将正确的代码从施体者应用程序转移到接收者应用程序中以消除后者错误的系统。一旦为程序识别出引起错误的输入，就会在数据库中搜索施体者应用程序，其中相同的输入不会触发错误。各种活动，包括候选检查发现，补丁切除，插入和验证都遵循此步骤，如果它们不能产生安全的解决方案，则会重复这些活动。本文还概述了早期的程序修复工作。 Brumley等人[20]讨论了与修复相反的问题，即基于对为其发布的检查补丁的自动利用程序。 我们的想法是找到补丁中引入的任何新的校验检查，并找到他们防范的输入。攻击者可以利用这些信息，假设这些输入可能是未修补程序的潜在攻击，这些程序通常不会及时收到更新。</p>\n<p>代码相似性也可用于漏洞识别。 Tree Edit Distance-Equational Matching [64]是一种用于自动识别包含已知错误的二进制代码区域的方法。在预处理阶段，提取表达树形式的语义信息，其总结在基本块中执行的计算的结果。对于已知错误，这用作签名以定位类似的代码区域，使用基于树编辑距离的以块为中心的度量来测量二进制代码的相似性。该度量标准允许代码中的小型语法差异，并已用于识别软件中的未知漏洞，例如流行的SSH客户端PuTTY的分支。 Pewny等人 [63]提出了使用代码相似性度量在多个CPU架构中基于签名的错误发现方法的概括。</p>\n<h3 id=\"3-2-1-数据结构\"><a href=\"#3-2-1-数据结构\" class=\"headerlink\" title=\"3.2.1 数据结构\"></a>3.2.1 数据结构</h3><p>二进制程序分析的一项基本任务是了解程序特征，以便进一步调查隐藏在代码中的潜在问题。 Laika [28]使用贝叶斯无监督学习来识别程序图像中的数据结构及其实例化。它定位指向潜在数据对象的指针，并使用机器把word转换为块类型的向量作为特征来估计它们的大小。然后使用概率相似性度量将相似序列聚类在一起以确定数据结构的类别。生成的数据结构在病毒检测场景中进行了测试，并证明是高效的。 White和Lüttgen[85]使用遗传编程从程序执行轨迹中识别动态数据结构，方法是将它们与预定义的模板进行匹配以进行标记。模板捕获操纵复杂数据结构（如链表和二叉树）所需的操作，测试表明这种方法能够以较低的误报率推断出这种数据结构。</p>\n<h3 id=\"3-2-2程序结构\"><a href=\"#3-2-2程序结构\" class=\"headerlink\" title=\"3.2.2程序结构\"></a>3.2.2程序结构</h3><p>二进制文件中的结构也扩展到可执行代码。 Rosenblum等 [68]解决了“函数开始识别”问题，或者在剥离的二进制代码中识别函数入口点（FEP）。他们使用基于Conditional Random Fields （CRF）统计建模方法的监督分类算法。每个字节偏移被假定为候选FEP，考虑两个模型：一个基于单个FEP的分类，另一个基于结构方面，例如可以调用其他函数的函数。第一个模型使用短指令模式作为特征集，逻辑回归模型被表述为用于分类的条件随机字段。第二个模型使用CRF使用成对函数/结构调用和重叠特征来模拟函数调用交互。该方法优于使用现有工具（例如Dyninst [37]和商业反汇编IDA Pro）所获得的结果。 ByteWeight [12]改进了这种方法，通过采用基于prefix树的技术来学习用于函数开始识别目的的签名，然后通过将二进制片段与签名匹配来识别函数。这是通过在源代码的参考语料库及其相应的二进制文件上训练分类模型来完成的，其中函数地址是已知的。该模型采用加权的prefix树的形式，其对函数开始字节序列进行编码：如果prefix树中的相应序列终端节点具有大于给定阈值的权重值，则检测实际函数开始。一旦找到函数开始，可以使用其他技术从二进制文件中提取完整函数。</p>\n<p>描述二进制文件的一般结构以实现详细分析是许多出版物中探索的目标。例如，BAP [19]是一个多用途分析平台，用于对二进制文件执行程序验证和分析任务。与许多类似的解决方案一样，它将二进制指令转换为中间语言，以便能够以语法导向的形式编写后续分析。以这种方式提供的任务可以包括创建控制流和程序依赖图，消除死代码，执行值集分析以及根据给定的后置条件生成验证条件。</p>\n<p>3.2.3。动态分析</p>\n<p>VDiscover [34]是一种应用机器学习方法的系统，该方法使用从二进制文件中提取的可伸缩，轻量级静态和动态特性来预测漏洞测试用例是否可能包含软件漏洞。通过检测从程序调用图的随机遍历获得的库函数调用的潜在子序列，从反汇编代码中提取静态特征。动态特征从执行跟踪中捕获，包含用其参数扩充的具体函数调用。为了减少大量的特征值，对参数值进行子类型化，并通过将函数调用的每个执行跟踪视为文档进行预处理，并使用潜在语义分析来降低维数。在系统中测试的机器学习分类算法包括逻辑回归，多层感知器和随机森林。随机森林在一项旨在识别内存损坏程序的大型实验中取得了最好的结果。</p>\n<h3 id=\"3-2-4-符号执行\"><a href=\"#3-2-4-符号执行\" class=\"headerlink\" title=\"3.2.4 符号执行\"></a>3.2.4 符号执行</h3><p>符号执行探索程序的执行空间并生成具有高覆盖率的测试用例。该方法的局限性在于可能的程序路径的数量通常过大。已经提出了各种方案来指导根据一些选定的策略来探索程序路径以克服该问题。李等人 [49]通过检查长度为n的子路径的频率分布来关注较少行进的路径，以便改进测试覆盖率和错误检测。我们的想法是通过维护之前探索子路径的次数来对已经覆盖的子路径进行统计分析。然后，对于给定的执行状态，选择具有最低计数的子路径以继续执行。该策略已在符号执行引擎KLEE [21]中实现，并在GNU Coreutils程序上进行了测试。 Cadar和Sen [22]提供了类似提案的概述，并讨论了与符号执行相关的挑战。特别是，他们专注于更高级别的自动化，例如修剪冗余路径，生成导致错误的输入，甚至创建相应的漏洞。 Avancini和Ceccato [10]使用遗传算法和符号执行来生成测试用例，以识别Web应用程序中的跨站点脚本（XSS）漏洞。他们将这两种技术结合起来，首先执行遗传算法，并在切换到符号执行之前将一组测试用例演化几代。收集，解决和重新插入符号约束作为新的输入值并且执行返回到遗传算法。重复该过程直到满足一些预先定义的终止条件。<br>测试表明，与随机测试用例生成和单独使用的两种方法相比，使用这种组合技术可以实现更高的覆盖率。</p>\n<p>BitScope [18]是用于恶意二进制文件自动路径分析的示例平台。它的体系结构包含监视恶意二进制文件内外信息流的组件，优先考虑可用的探索路径，并执行结合二进制符号（复杂）执行以构建公式以表示执行的满意度路径。然后，提取器模块生成已发现代码的控制图，二进制文件沿不同执行路径传输所需的输入以及二进制文件的输入和输出之间的依赖关系信息。然后，从业者可以使用该数据来进一步分析该程序。</p>\n<p>基于相似度函数的自动漏洞发现（SFAVD）[53]是一个将源代码中的机器学习与符号执行测试相结合以检测漏洞的过程。首先，使用多步骤过程生成类似于已知易受攻击的一组函数，该多步骤过程包括为每个函数创建抽象语法树表示，将它们枚举成特征向量并对易受攻击的函数执行相似性评估。然后，为具有最大相似性的函数生成函数调用图，并且将KLEE与约束求解器一起使用以确定它们是否易受攻击。测试表明，与仅使用KLEE分析程序相比，可以实现执行时间的显着缩短。</p>\n<h3 id=\"3-2-5-恶意软件\"><a href=\"#3-2-5-恶意软件\" class=\"headerlink\" title=\"3.2.5 恶意软件\"></a>3.2.5 恶意软件</h3><p>虽然恶意软件分析不是软件漏洞研究的各种活动的严格组成部分，但它是机器学习受到广泛关注并且显示有用的相关领域之一。恶意软件分析还可以帮助开发漏洞缓解策略，并且通常采用与其他SVR任务直接相关的技术，从而暴露在这些区域中使用相同或类似ML方法的机会。对恶意软件的分析通常始于相关特征的识别。艾哈迈德等人 [6]从Windows API调用参数和序列中提供的空间和时间信息中提取统计特征。它们包括地址指针的均值，方差和熵以及从API序列的离散时间马尔可夫链建模获得的大小参数和特征。使用这些特征比较各种机器学习算法，包括基于实例的学习器，决策树分类器，朴素贝叶斯，归纳规则学习器和支持向量机，并且它们表明当使用时可以实现改进的结果。用于分类的空间和时间特征的组合。 OPEM [71]还使用一系列算法检查恶意软件，例如决策树，贝叶斯分类器，支持向量机和k近邻，但使用了一组不同的特性。静态功能基于恶意软件中的固定长度的操作代码序列的频率。动态要素从执行跟踪中提取为二进制向量，表示可执行文件中存在特定的系统调用，操作和引发的异常。使用信息增益将特征减少应用于静态特征，以便产生可管理的特征集。结果表明，与仅使用单一类型的特征相比，组合的静态和动态特征产生更好的结果。安德森等人[9]描述了仅使用一种类型的特征的示例，在这种情况下，使用来自动态收集的指令轨迹的特征。指令序列被转换为马尔可夫链表示，形成有向指令跟踪图（ITG），由加权邻接矩阵表示。两级支持向量机用于分类并产生高度准确的结果。不幸的是，用于确定ITG之间相似性的图形内核对于大图来说计算起来可能很昂贵。 Gascon等 [33]也使用SVM，但它通过采用受线性时间图内核启发的显式映射，基于函数调用图的结构嵌入来推导其特征，从而产生静态特征集。在测试中，使用此技术实现的恶意软件检测率相当高，误报率低。</p>\n<p>Saxe [42]提出了一系列相似性措施，以抵抗恶意软件中的混淆，以更好地识别它们所属的类。这是一项重要任务，因为确定恶意软件样本的正确组可以协助归因和后续活动。这个想法是对整个恶意软件的完全混淆是困难的，因此即使在个体相似性度量无效的情况下，使用多种分析技术也应该产生可靠的结果。提出的四种措施基于PE（可移植可执行）元数据相似性，动态相似性，指令 - 克相似性和文件相似性。与其他可用技术（如群集）相比，此方法是识别恶意软件组的更简单且更具可扩展性的解决方案。</p>\n<h3 id=\"3-2-6-二进制文件的归属\"><a href=\"#3-2-6-二进制文件的归属\" class=\"headerlink\" title=\"3.2.6 二进制文件的归属\"></a>3.2.6 二进制文件的归属</h3><p>也可以对二进制文件进行作者分析。 Rosenblum等 [69]收集具有已知作者身份的程序集，并使用控制流图和指令序列，根据特征和标签之间的相互信息，从每个程序中提取和确定相关的文体特征。这些功能使用支持向量机分类器进行测试，并用于学习一个度量，该度量最小化同一作者在程序之间的特征空间中的距离。然后，该度量与k-means聚类一起用于对未知作者的程序进行分组。该技术实现了合理的性能（正确作者排名在前五位的时间的94％），这使得论文的作者得出结论，程序员风格可以通过编译过程得以保留。随后提出了对该技术的若干改进。 Alrabaee等 [8]认为需要更加分层的方法。首先，预处理层过滤掉库代码以消除与样式无关的功能。然后，代码分析层提取对应于源代码词汇表的二进制代码块，以构建用于分类的作者分类。最后，一个寄存器流分析层使用寄存器流程图来描述寄存器的操作方式，用于定义作者风格的签名和识别程序作者。与[69]中取得的结果相比，归因准确度有所提高。但是，这些方法都没有专门设计用于处理具有多个作者的程序。 Meng [54]为团队编写的属性代码引入了新的块级功能。在分析从属性源代码[55]生成的机器指令之后，基本块被确定为属于单个作者的合适候选者。因此，在这个级别提出了几个新功能，以补充以前的现有功能。基本块的线性SVM分类器与早期报告的结果相当，表明作者身份识别在基本块级和多个作者中都是实用的。</p>\n<h1 id=\"4-总结\"><a href=\"#4-总结\" class=\"headerlink\" title=\"4.总结\"></a>4.总结</h1><p>在本文中，我们报告了软件漏洞研究社区最近涉及使用机器学习的一些活动。虽然没有提供详尽的清单，但我们的目的是提供一份代表性的出版物集，说明使用ML支持SVR。我们发现，除了寻找解决大型代码库的解决方案的新方法之外，SVR中最大的主题是帮助代码审计员等从业者，尽可能简化或自动化他们的流程。机器学习是越来越多地用于改进传统方法的工具之一。它已成功应用于解决单个SVR任务或通过多个步骤来提供复杂过程的指导。在这个角色中，ML应该继续受益于未来。 SVR中仍然存在有限使用ML的区域（例如，模糊测试[38]），甚至那些当前利用机器学习的区域也可以改进，因为提出了新的，更有效和更有效的技术。识别这些趋势并认识到它们对特定SVR问题的适应性并非易事，并且需要SVR从业者，程序分析和机器学习专家之间的密切联系。特别是，我们认为使用语义输入信息的机器学习而不是其在句法特征上的应用可以为许多SVR活动产生更有意义的结果。最后，我们想要认识到最近几个旨在为软件漏洞研究目的提高认识和鼓励协作的方法。 2016年网络大挑战[2]是研究人员之间的竞赛，旨在评估软件，测试漏洞并在网络计算机上自动生成和应用安全补丁。MUSE项目[56]是一项正在进行的计划，旨在通过开发自动构建和修复软件程序的方法，寻求来自多个学科的专家使用大数据分析来提高软件可靠性。</p>\n","categories":[{"name":"论文","slug":"论文","permalink":"http://yama0xff.com/categories/论文/"},{"name":"fuzzing","slug":"论文/fuzzing","permalink":"http://yama0xff.com/categories/论文/fuzzing/"},{"name":"综述","slug":"论文/fuzzing/综述","permalink":"http://yama0xff.com/categories/论文/fuzzing/综述/"}],"tags":[{"name":"综述","slug":"综述","permalink":"http://yama0xff.com/tags/综述/"},{"name":"2017年","slug":"2017年","permalink":"http://yama0xff.com/tags/2017年/"}]},{"title":"Sofware Vulnerability Analysis and Discovery Using Machine-Learning and Data-Mining Techniques: A Survey","date":"2019-04-02T13:50:44.000Z","path":"2019/04/02/Sofware-Vulnerability-Analysis-and-Discovery-Using-Machine-Learning-and-Data-Mining-Techniques-A-Survey/","text":"由于其中主要内容都是关于数据挖掘技术在源代码漏洞和分析中的使用总结，涉及到使用机器学习方法的较少，所以未翻译阅读完，后续再继续翻译。 Abstract软件安全漏洞是计算机安全领域的关键问题之一。由于其潜在的高严重性影响，在过去几十年中已经提出了许多不同的方法来减轻软件漏洞的损害。机器学习和数据挖掘技术也是解决该问题的众多方法之一。在本文中，我们对利用机器学习和数据挖掘技术的软件漏洞分析和发现的许多不同工作进行了广泛的回顾。我们回顾了这个领域中不同类别的工作，讨论了优点和缺点，并指出了挑战和一些未知的领域。 relevant information 作者 SEYED MOHAMMAD GHAFFARIAN；HAMID REZA SHAHRIARI 单位 Amirkabir University of Technology 出处 ACM Comput. Surv 原文地址 https://dl.acm.org/citation.cfm?id=3092566 源码地址 发表时间 2017年 1. 简介如今，计算机软件无处不在，现代人类生活在很大程度上依赖于各种各样的软件。在不同的平台上运行不同形式的计算机软件，从手持移动设备上的简单应用程序到复杂的分布式企业软件系统。这些软件采用多种不同的方法生成，基于各种各样的技术，每种技术都有自己的优点和局限。这个庞大的关键行业以及计算机安全领域的一个重要问题是软件安全漏洞问题。在这个问题上引用行业专家的话： “In the context of software security, vulnerabilities are specifc ﬂaws or oversightsin a piece of software that allow attackers to do something malicious: expose or altersensitive information, disrupt or destroy a system, or take control of a computer systemor program.” Dowd et al. (2007) 软件漏洞所带来的威胁的严重程度不同取决于开发复杂性和攻击面等因素（Nayak等人，2014）。在过去的二十年中，存在大量的例子和事件，其中软件漏洞给公司和个人带来了重大损害。为了强调这个问题的重要性，我们近年来提到了一些例子。一个突出的例子是流行浏览器插件中的漏洞情况，这些漏洞威胁到数百万互联网用户的安全和隐私（例如，Adobe Flash Player（US-CERT 2015; Adobe Security Bulletin 2015）和Oracle Java（US-CERT 2013） ）。此外，流行和基础开源软件中的漏洞也威胁到全球数千家公司及其客户的安全（例如Heartbleed（Codenomicon 2014）ShellShock（赛门铁克安全响应2014）和Apache Commons（Breen 2015） ）。 上述示例只是每年报告的大量漏洞中的一小部分。由于这个问题的重要性，学术界和软件行业的研究人员已经研究了许多不同的缓解方法。 Shahriar和Zulkernine（2012）提出了一项针对缓解计划安全漏洞的不同方法的广泛调查，包括测试，静态分析和混合分析，以及1994年至2010年期间发布的安全编程，程序转换和修补方法。 除了在Shahriar和Zulkernine（2012）中审查的众所周知且经过深入研究的方法之外，还存在一种不同的方法，这些方法利用来自数据科学和人工智能（AI）的技术来解决软件漏洞分析和发现。 Shahriar和Zulkernine（2012）忽略了这类有趣的方法，但在接下来的几年中（从2011年开始），研究界越来越关注这一方法。 在本文中，我们针对利用数据挖掘和机器学习技术的软件漏洞分析和发现的这类方法提出了分类评论。首先，我们确定了软件漏洞分析和发现的问题，并简要介绍了在这个领域的传统方法。我们还简要介绍了机器学习和数据挖掘技术以及它们使用背后的动机。之后，我们将分别回顾利用机器学习和数据挖掘技术解决软件漏洞分析和发现问题的许多不同工作。我们为这类作品提出了不同的类别，并讨论了它们的优点和局限性。最后，我们在结束本文时讨论了在这个领域的挑战，并指出了一些未知的领域，以激发这一新兴研究领域的未来工作。 2.背景：软件漏洞分析和发现2.1 定义我们首先说明软件安全漏洞的定义。在他关于软件漏洞分析问题的博士论文中，Ivan Krsul将软件漏洞定义为： “an instance of an error in the specifcation, development, or confguration of softwaresuch that its execution can violate the security policy.” (Krsul 1998) 差不多十年之后，Ozment承认Krsul的定义，但建议稍作修改： “A software vulnerability is an instance of a mistake in the specifcation, development,or confguration of software such that its execution can violate the explicit or implicitsecurity policy.” Ozment (2007) Ozment将单词error更改为mistake，并引用IEEE标准术语软件工程术语（IEEE Standards 1990）来证明这一点。如前所述，行业专家提供了类似的定义： “In the context of software security, vulnerabilities are specifc ﬂaws or oversightsin a piece of software that allow attackers to do something malicious: expose or altersensitive information, disrupt or destroy a system, or take control of a computer systemor program.” Dowd et al. (2007) 从上述定义可以看出，不同的关键术语用于定义软件漏洞。为了澄清这些术语并选择最合适的术语，我们参考IEEE标准软件工程术语表（IEEE标准1990）。我们查找四个关键术语的定义：“error”，“fault”，“failure”和”mistake”根据IEEE标准（1990），error的定义是：“计算的，观察的或测量的值或条件与真实的，规定的或理论上正确的值或条件之间的差异”（IEEE标准1990）。fault是：“计算机程序中的步骤，过程或数据定义不正确”（IEEE标准1990）。faults也称为flaws或bugs。failure是：“系统或组件无法在规定的性能要求下执行其所需的功能”（IEEE标准1990）。最后，mistake是：“产生错误结果的人为行为”（IEEE标准1990）。这些术语的关系的总结和澄清是“区分人类行为（mistake），其表现（硬件或软件faults），故障结果（failure）以及结果的数量不正确（error）“（IEEE标准1990）。 从这些定义可以清楚地看出，用于定义软件漏洞的合适关键术语是“fault”（也是flaw或bug）。更确切地说： A software vulnerability is an instance of a flaw, caused by a mistake in the design, development, or configuration of software such that it can be exploited to violate some explicit or implicit security policy. 软件漏洞的原因是人为错误，其表现形式是flaw（fault或bug）。执行faulty 状态的软件不一定违反安全策略;直到某些特制数据（漏洞利用代码）或某些具有某些条件的随机数据到达有缺陷的语句，此时，其执行可能违反某些安全策略（利用导致安全性失败）。 其他人已经承认将软件漏洞定义为faults，并将mistake定义为其原因。 Ozment指出“由于开发错误导致的漏洞是一个fault”（Ozment 2007），但他区分了开发错误导致的漏洞，以及设计或配置错误导致的漏洞;但没有提供这种差异的解释。 Dowd等人。还说： “In general, software vulnerabilities can be thought of as a subset of the larger phenomenon of software bugs. Security vulnerabilities are bugs that pack an extra hidden surprise: A malicious user can leverage them to launch attacks against the software and supporting systems.” Dowd et al. (2007) 2.2 健全性，完整性和不可判定性程序漏洞分析是确定给定程序是否包含已知安全漏洞（根据安全策略）的问题。基于图灵停止问题和赖斯定理的不可判定性，可以证明许多程序分析问题在一般情况下也是不可判定的（Landi 1992; Reps 2000）。对于从业者来说，不可判断性意味着不存在对问题的完整解决方案。 在数学逻辑中，如果系统不能批准无效参数，则证明系统是合理的。如果所有有效参数都可以被系统批准，则证明系统是完整的。通过推论，一个完整的证据系统是一个可以批准所有有效论证并反驳所有无效论证的系统（Xie et al.2005）。 在软件安全的背景下，如果漏洞分析系统从未批准易受攻击的程序（没有漏掉漏洞），那么它就是健全的。如果可以批准所有安全程序（没有虚假漏洞），则漏洞分析系统是完整的。根据推论，健全且完整的漏洞分析系统可以批准所有安全程序并拒绝所有易受攻击的程序（没有错过漏洞且没有漏洞）（Xie et al.2005）。如前所述，已知这种完善和完整的系统是不存在的（Jhala和Majumdar，2009）。 除了漏洞分析之外，更实用的系统是程序漏洞发现（或漏洞报告）系统。与批准或不批准给定程序的安全性（即二进制输出）的漏洞分析系统相比，程序漏洞发现系统报告给定的每个漏洞的更详细信息（例如类型，位置等）程序。这是软件行业更有用和理想的系统，它可以帮助开发人员和工程师更轻松地检测和修复漏洞。同样，众所周知，一个完善的软件漏洞发现系统（一个不报告漏洞，报告所有实际漏洞的系统）是不存在的。 2.3传统方法尽管软件漏洞分析和发现问题具有不可判定的性质，但由于该问题的重要性，学术界和软件行业的从业者已经研究和提出了大量的方法。提出的方法都不可避免地是近似解;他们都缺乏健全性或完整性，或两者兼而有之。因此，与以前的工作相比，所有研究工作都试图提出一种改进的方法，涉及软件漏洞分析和发现过程的特定方面;例如，漏洞覆盖率，发现精度，运行时效率等。 Shahriar和Zulkernine（2012）提出了对缓解程序安全漏洞的不同方法的广泛审查，包括在1994年至2010年期间的程序漏洞分析和发现方法。所有程序分析方法可分为三大类： 静态分析：根据源代码分析给定程序，无需执行。这些方法利用广义抽象来分析程序的属性，因此静态分析方法最健全的（即没有错过的漏洞，但可能会报告错误的漏洞）。泛化越准确，报告的漏洞就越少。在实践中，必须在分析精度和计算效率之间进行交易。 动态分析：通过使用特定的输入数据执行并监视其运行时行为来分析给定程序。在这种方法中，一组输入测试用例用于分析程序的属性，并且由于通常存在无限可能的输入和运行时状态，因此动态分析系统无法分析整个程序的行为。因此，动态分析系统是最完整性的（即，批准所有安全程序而不报告虚假漏洞），但它们不可能是健全的，因为它可能会遗漏一些隐藏在看不见的程序状态中的漏洞。动态分析方法存在实际缺点，即对给定程序的工作运行时的环境要求，以及在分析大型复杂软件时处理所有输入测试用例所需的长时间和高成本。然而，动态分析方法在软件行业中得到了极大的应用。 混合分析：使用静态分析和动态分析技术的混合分析给定程序。基于先前关于静态和动态分析方法的讨论可能存在误解，混合分析方法可能是完整的和健全的（因此，违反了问题的不可判定性）。不幸的是，事实并非如此，虽然混合分析方法可以从静态和动态分析的优势中获益，但它们也受到两种方法的局限性的影响。混合分析方法可以是利用动态分析来识别错误漏洞的静态分析系统，也可以是利用静态分析技术来指导测试用例选择和分析过程的动态分析方法。 但应注意，并非所有静态分析系统都是健全的，并非所有动态分析系统都是完整的。在众多不同的漏洞发现方法中，有些在软件行业中更为成熟;亦即 Software Penetration Testing: a manual software security testing approach, carried out by a team of security experts (also referred to as white-hat hackers) (Arkin et al. 2005; Bishop2007). Fuzz-Testing: also known as random-testing, where well-formed input data are randomly mutated and fed to the program under test at large, while monitoring for failures (Godefroid 2007; Godefroid et al. 2012). Static Data-Flow Analysis: also known as “Tainted Data-ﬂow Analysis,” it is a static program analysis approach where untrusted data from input sources is marked as tainted and its ﬂow to sensitive program statements known as sinks is tracked as a potential indicator of vulnerability (Evans and Larochelle 2002; Larus et al. 2004; Ayewah et al. 2008; Bessey et al. 2010). 3.使用机器学习和数据挖掘技术除了上述方法之外，还有一类不同的工作利用数据科学和人工智能（AI）的技术来解决软件漏洞分析和发现的问题。在Shahriar和Zulkernine（2012）的评论中忽略了这一类有趣的方法，而在接下来的几年（从2011年起），研究界越来越关注这一方法。人工智能技术中的机器学习技术在许多不同的应用领域都被证明是有效的（Russell和Norvig 2009）。对于计算机安全和隐私领域也是如此，许多不同的应用程序已经使用这些技术解决（例如，垃圾邮件过滤（Guzella和Caminhas 2009; Caruana和Li 2012）和入侵检测系统（Garcia-Teodoro等。 2009; Zhou et al.2010），仅举几例）。 正如Arthur Samuel在他的开创性工作中所定义的那样，机器学习是开发计算技术和算法的研究，使计算机系统能够在没有明确编程的情况下获得新的能力（Samuel，1959）。数据挖掘是从大量数据中提取知识的计算过程，包括以下几个步骤：数据提取和收集，数据清理和集成，数据选择和转换，知识挖掘以及最终可视化和通信（Han et al.2011） 。机器学习算法和技术经常用于数据挖掘的过程中，用于预处理，模式识别和生成预测模型。 机器学习技术可大致分为三种主要方法：（1）监督学习：学习系统基于一组标记的训练样例推断出所需的功能/模型，其中每个例子由输入数据（通常是矢量）和所需的相应输出值（标签）。 （2）无监督学习：在没有标记训练数据的情况下，学习系统的目标是识别给定数据集中的模式和结构。 （3）强化学习：学习系统通过与动态环境的交互来接受奖励和惩罚，通过训练来达到某个目标。 3.1希望和恐惧尽管机器学习技术在安全应用中的应用可以追溯到几十年，但近年来机器学习和数据挖掘技术的进步和能力以及它们解决许多困难应用问题的成功案例促使研究人员更加彻底调查这些技术的有效利用，以解决计算机安全和隐私领域的难题。例如，Carl Landwehr分享了他对此事的看法如下： “在他们的早期，计算机安全和人工智能似乎没有太多可说的对…安全研究人员的目的是解决他们认为防漏的计算基础设施或设计基础设施的漏洞……但是多年来，这两个地方的距离越来越近，特别是在攻击旨在模拟合法行为的地方……我们可能会想象系统会对他们处理的数据有一定程度的自我意识。反射系统（可以参考和修改自己的行为的系统）的概念起源于AI社区……想象一下，一个管道系统包含一个可以检测初期泄漏的智能管道系统。包含智能管道模拟的网络基础设施将引起极大兴趣。“Landwehr（2008） 其他研究人员强调了人工智能技术在计算机安全和隐私领域获得解决复杂问题的重要作用。例如，Tyugu（2011）指出：“很明显，只有在使用人工智能方法时才能成功解决许多网络防御问题。”Heinl（2014）提出了类似的观点。 另一方面，安全社区也担心使用人工智能技术。例如，尽管在基于异常的入侵检测系统的研究中发表了大量研究，但是之前的一些研究表明这些系统很少部署在入侵检测行业（Sommer和Paxson 2010）。其他研究也对网络入侵检测的异常检测范例提出了挑战（Gates和Taylor 2006）。这些研究的结果强调了这样一个事实，即在计算机安全和隐私领域有效使用AI技术并非易事，需要对这些技术的特性有充分的了解（Sommer和Paxson 2010）。为了获得最佳结果，应该定制机器学习和数据挖掘技术以适应安全问题的特征。在这件事上，莫瑞尔说： “尽管过去已经完成了一些工作，但AI并没有在当今的网络安全中发挥核心作用，网络安全并不像人工智能那样强烈追求人工智能的发展领域，而其他人…… AI技术是围绕应用程序开发的。网络安全从未成为人工智能集中的一个领域……人工智能已经取得了很多成就，并且有许多与网络安全相关的知识，许多适合网络安全的新技术可以从人工智能中的现有技术中获得启发。“Morel（ 2011） 为此，应该研究针对计算机安全问题量身定制的机器学习技术。 3.2 以前工作的分类在软件漏洞分析和发现的过程中，许多研究在前几年发表研究机器学习和数据挖掘技术的使用，我们在本文中对此进行了广泛的综述。我们将审查的工作分为四大类，总结如下，并将其区分如下： （1）基于软件度量的漏洞预测模型：大量研究利用（主要是监督的）机器学习方法构建基于众所周知的软件度量作为特征集的预测模型，然后使用该模型根据测量的软件工程指标评估软件工件的漏洞状态。 （2）异常检测方法：这类工作利用无监督学习方法从软件源代码中自动提取正常模型或挖掘规则，并将漏洞检测为多数正常和规则的异常行为。 （3）漏洞代码模式识别：这类工作利用（主要是监督的）机器学习方法从许多漏洞代码示例中提取漏洞代码段的模式，然后使用模式匹配技术来检测和定位软件中的漏洞源代码。 （4）杂项方法：一些值得注意的近期着作，利用AI和数据科学的技术进行软件漏洞分析和发现，这些技术不属于任何上述类别，也不构成一个连贯的类别。 提议分类背后的基本原理是双重的：首先，我们区分分析程序语法和语义的工作，而不区分程序语法和语义。大多数不分析程序语法和语义的工作使用软件工程指标进行漏洞预测。另一方面，在基于分析程序语法和语义的大量研究中，我们观察到两种主要方法：漏洞代码模式识别和异常检测方法。图1直观地总结了分类方案。 虽然其他标准也可用于分类目的（例如：监督与非监督学习范式，不同的学习和挖掘技术，特征表示方案等），但它们不能创建先前作品的语义连贯类别。我们认为，拟议的分类结果会产生更有意义的研究家族，从而可以更好地比较各种方法，因此我们认为这是对有史以来研究的有组织调查的合适选择。 4基于软件度量的漏洞预测我们在本文中讨论的第一类方法是“漏洞预测模型”，它利用数据挖掘，机器学习和统计分析技术来预测易受攻击的软件工件（源代码文件，面向对象的类，二进制组件，等）基于通用软件工程指标。这些方法的主要思想来自于软件工程领域的软件质量和可靠性保证，其中软件测试和验证的有限资源需要一个指导模型来实现更有效的软件测试计划。为此，已经研究并在工业中使用“故障预测模型”（或“缺陷预测模型”）（Khoshgoftaar等人1997）。故障预测模型是基于从软件项目收集的历史数据训练的计算模型，并提供更可能包含故障的软件工件列表以优先考虑软件测试。历史数据基于不同的软件工程指标，例如源代码大小，复杂性，代码流失和开发人员活动指标（Kaner和Bond 2004）。根据IEEE标准软件工程术语表，术语“度量”被定义为“系统，组件或过程拥有给定属性的程度的定量度量”（1990）。在调查文章中回顾的软件工程领域的故障预测模型的主题上进行了广泛的研究和发表（Catal和Diri 2009; Malhotra 2015）。 基于与故障预测模型类似的动机，在软件工程领域中提出了漏洞预测模型。检测和缓解安全漏洞需要经过安全思维培训的专家进行人工分析（Heelan 2011）;然而，软件质量和可靠性保证团队的资源有限，需要引导他们进行更有效，更有效的安全审计和测试。基于漏洞是一种特定类型的故障这一事实，已经在业界和学术界提出并研究了漏洞预测模型。与故障预测模型类似，脆弱性预测模型也基于各种软件度量建立，并且不包含程序分析方法（即，分析某些属性的程序源代码）。在下文中，我们将回顾一下这个领域的一些最新作品。 4.1最近工作总结Zimmermann 等人（2010）研究了基于先前用于缺陷预测的研究中使用的经典度量来预测专有商业产品（Microsoft Windows Vista）的二进制模块中存在漏洞的可能性。作为第一个分析，他们使用Spearman的秩相关性计算度量与每个二进制的漏洞数量之间的相关性。结果表明，经典度量与漏洞数量具有统计上的显着相关性;但是，效果很小。另一项分析是评估这些指标的预测能力。作者使用二元Logistic回归分析了经典指标（流失，复杂性，覆盖，依赖和组织）的五组。模型评估采用十倍交叉验证和计算精度以及召回值。作者报告说，大多数指标预测的漏洞具有平均精度（低误报率）;然而，召回率非常低（错误的假阴性或错过的漏洞）并且覆盖率指标未能产生任何有意义的结果。结果包括精度低于67％，召回率低于21％。 Meneely和Williams（2010）研究了开发者活动指标和软件漏洞之间的关系。正在研究的开发人员活动指标包括：更改源文件的不同开发人员数量，向文件提交的提交数量，以及在贡献网络中包含文件的测序路径数量。作者对三个开源软件项目进行了研究。每个研究中收集的数据集包括一个标签，表明源代码文件是否已修补，以及版本控制日志中的开发人员活动指标。使用统计相关性分析，作者报告发现每个指标与漏洞数量存在显着的显着相关性;但相关性各不相同，并不是很强。作者使用贝叶斯网络作为预测模型，通过十倍交叉验证生成训练和验证集。据作者说，分析表明开发人员活动可以用来预测脆弱的人群;然而，精确度和召回率值令人失望（精确度在12％-29％之间，召回率在32％-56％之间）。 Doyle和Walden（2011）分析了2006年至2008年间14个最广泛使用的开源Web应用程序中的软件度量和漏洞之间的关系，例如WordPress和Mediawiki。作者使用静态分析工具（例如，Fortify源代码分析器，PHP CodeSni等等）来测量这些应用程序的源代码库中的各种度量，包括静态分析漏洞密度（SAVD），源代码大小，圈复杂度，嵌套复杂性，以及作者提出的另一个名为安全资源指标（SRI）的指标。为了预测，Spearman的等级相关性是在SAVD和其他指标之间计算的。结果表明，没有一个度量标准适用于区分高漏洞Web应用程序和低漏洞Web应用程序;然而，每个函数的平均圈复杂度是几个应用程序的有效预测器，特别是当与SRI分数结合使用时，将应用程序分类为高安全性和低安全性焦点应用程序。由于静态分析工具可能会产生很高的误报，作者手动审查了两个选定的Web应用程序的一个工具（Fortify SCA）的报告，其误报率为18％;得出结论认为假阳性率是可以接受的，对有效性没有威胁。 Shin和Williams（2013）研究了基于复杂性和代码流失度量的传统故障预测模型是否可用于漏洞预测。为此，作者使用18个复杂度指标，5个代码流失度量标准和故障历史度量标准对Mozilla Firefox进行了实证研究。测试了几种分类技术来预测故障和脆弱的人群;作者声称所有技术的结果都相似。虽然故障源代码的数量是脆弱源数量的7倍，但故障预测模型和漏洞预测模型在漏洞预测方面表现相似;召回率约为83％，精确度约为11％。基于这些结果，作者得出结论，基于传统度量的故障预测模型也可用于脆弱性预测;然而，未来的研究需要提高精确度（减少误报），同时保持高召回率 在同一作者的另一个工作中，Shin和Williams（2011）研究了使用执行复杂度指标作为软件漏洞的指标。这组作者说，这项研究背后的动机是基于安全专家的直觉，安全专家经常假设“软件复杂性是软件安全的敌人。”为此，作者对两个开源项目进行了实证案例研究，比较执行复杂性和静态复杂性指标对漏洞检测的有效性。总共，本研究收集了23个复杂度指标。作者对指标进行了判别和预测分析。对于判别分析，作者使用Welch的t检验来比较弱势文件与中性文件的度量值的均值。结果显示，其中一个项目的23个指标中有20个表现出统计上显着的判别力;但是，这仅适用于其他项目的大约一半指标，包括没有执行复杂性指标。为了评估指标的预测能力，作者使用Logistic回归进行了二元分类，并进行了十倍的交叉验证。为了解释许多指标中的冗余信息，作者基于信息增益排名执行了特征空间缩减。另一个问题是大多数（中立的人）和少数群体（弱势群体）之间的严重失衡，作者通过随机抽样多数阶层来解决这个问题。最终结果是，对于所有三组指标（代码，依赖关系，所有组合），召回率是公平的（67％-81％），但精确度令人失望（8％-12％）。总之，结果表明这些指标没有静态显着的判别力，预测能力不可靠。 Shin等人（2011）对复杂性，代码流失和开发人员活动（CCD）指标是否可用于漏洞预测进行了更广泛的研究。为此，作者对两个开源项目进行了实证案例研究。本研究共分析了28个CCD软件指标，包括14个复杂度指标，3个代码流失指标和11个开发人员活动指标。为了评估指标的判别能力，作者使用了Welch的t检验，其中两个项目的28个指标中至少有24个支持检验假设。为了评估指标的预测能力，作者测试了几种分类技术，但它们只呈现了一种分类结果，因为所有技术都提供了类似的性能。为了验证模型的预测能力，作者进行了下一次发布验证，其中有几个版本可供使用，交叉验证只有一个版本可用。评估了单变量和多变量预测假设。基于从故障预测文献中找到的平均值，作者选择阈值至少为70％用于回忆，并且最多25％用于假阳性率以支持预测假设。 28个单变量模型中只有2个，以及使用基于发展历史的指标的4个多变量模型中的3个预测了两个项目的高召回率和低误报率的脆弱性。作者得出结论，与本研究中收集的代码复杂度指标相比，开发历史指标是更强的漏洞指标。 Moshtari等人（2013）提到了先前关于脆弱性预测模型的研究的三个主要局限性，因此他们提出了一种新方法，通过解决先前研究的局限性，基于复杂性度量来预测软件中的脆弱位置。作者提出了一种半自动分析框架来检测软件漏洞，并将其输出用作漏洞信息，而不是报告的漏洞，作者声称这些漏洞提供了有关软件漏洞的更完整信息。与之前仅研究项目内漏洞预测的研究不同，本研究基于从开源项目收集的数据调查了项目内和项目间的漏洞预测。各种分类技术用于实验。在fle级别粒度下测量了一组11个单元复杂度度量和4个耦合度量。在Mozilla Firefox上进行的项目内预测的报告结果对于各种分类技术而言令人印象深刻（召回率高于90％，误报率低于10％）。作者声称，更完整的漏洞信息有助于这种改进，并通过将提出的方法与Shin等人之前的工作的复制进行比较来证明其声称的合理性。 （2011年）。在随机选择的五个项目版本上进行跨项目实验，其中一个项目被视为测试数据，模型在另外四个项目上进行了培训。根据报告的F2测量，跨项目预测的最佳模型实现了约70％的检测率，约26％的误报。 Moshtari等人。 （2013）提到了先前关于脆弱性预测模型的研究的三个主要局限性，因此他们提出了一种新方法，通过解决先前研究的局限性，基于复杂性度量来预测软件中的脆弱位置。作者提出了一种半自动分析框架来检测软件漏洞，并将其输出用作漏洞信息，而不是报告的漏洞，作者声称这些漏洞提供了有关软件漏洞的更完整信息。与之前仅研究项目内漏洞预测的研究不同，本研究基于从开源项目收集的数据调查了项目内和项目间的漏洞预测。各种分类技术用于实验。在fle级别粒度下测量了一组11个单元复杂度度量和4个耦合度量。在Mozilla Firefox上进行的项目内预测的报告结果对于各种分类技术而言令人印象深刻（召回率高于90％，误报率低于10％）。作者声称，更完整的漏洞信息有助于这种改进，并通过将提出的方法与Shin等人之前的工作的复制进行比较来证明其声称的合理性。 （2011年）。在随机选择的五个项目版本上进行跨项目实验，其中一个项目被视为测试数据，模型在另外四个项目上进行了培训。根据报告的F2测量，跨项目预测的最佳模型实现了约70％的检测率，约26％的误报。 Meneely等人（2013）通过将Apache HTTPD Web服务器中的65个以上漏洞追溯到最初贡献易受攻击代码的版本控制提交，探讨了漏洞贡献提交（VCC）的属性。作者手动发现了124个VCC，跨越17年，他们使用统计分析技术根据代码流失和开发人员活动指标进行分析。根据这项探索性研究的结果，他们提出了几个方面：（1）代码流失度量标准与VCC在经验上相关，其方式是更大的提交可能会引入漏洞; （2）承诺更多的开发人员更有可能成为VCC; （3）由新开发商提交给来源，更有可能是VCC。 Bosu等人（2014）进行了类似的实证研究，他们分析了来自10个开源项目的260,000多个代码审查请求，使用三阶段半自动化流程识别了400多个易受攻击的代码更改。他们的目标是确定漏洞代码更改的特征，并确定可能引入漏洞的开发人员的特征。一些关键的因素包括：（1）经验不足的贡献者的变化显然更有可能引入漏洞; （2）漏洞可能性随着变化的大小而增加（更多行改变）; （3）与修改后的文件相比，新文件不太可能包含漏洞。 Perl等人（2015）研究了使用代码存储库中包含的元数据以及代码度量来识别漏洞贡献提交的效果。作者声称软件逐渐增长，大多数开源项目都使用版本控制系统，因此，提交是检查漏洞的自然单位。有了这个动机，作者编译了一个包含来自66个C / C ++ GitHub项目的170,860个提交的数据集，其中包括映射到相关CVE ID的640个漏洞贡献提交（VCC）。作者选择了一组代码流失和开发人员活动指标，以及来自不同范围（项目，作者，提交和文件夹）的GitHub元数据，并为收集的数据集提取这些功能。基于该数据集，作者评估了他们提出的名为VCCFinder的系统，该系统使用支持向量机（SVM）分类器来识别来自中立提交的VCC。为了评估，该系统在2010年底之前接受了数据培训，并根据2011年至2014年报告的CVE进行了测试。作者将他们提出的系统的结果与FlawFinder静态分析工具的结果进行了比较。在相同的召回水平（召回率= 24％），FlawFinder的精度仅达到1％，而VCCFinder达到60％的精度，产生的误报率要低得多。上述数据集由作者公开发表，作为对研究界的贡献。 Walden等人（2014）进行了一项研究，以比较基于软件度量与文本挖掘技术预测漏洞软件组件的性能。为此，作者首先构建了一个手工策划的漏洞数据集，这些数据集来自三个大型流行的开源PHP Web应用程序（Drupal，Moodle，PhpMyAdmin），包含223个漏洞。该数据集作为贡献提供给研究界。对于基于软件度量的漏洞预测，为该研究选择了一组12个代码复杂度度量。对于文本挖掘，每个PHP源文件都是第一个标记化的，不必要的标记被删除或转换（注释，标点符号，字符串和数字文字等），并计算最终标记的频率。众所周知的“词袋”技术用于从每个PHP源文本的文本标记构造数字特征向量。基于先前的漏洞预测研究经验，作者选择随机森林模型作为主要分类算法。对于模型评估，作者使用分层三重交叉验证。作者还通过对多数类（非易受攻击代码）执行随机欠采样来解决不平衡类数据的问题。根据作者的各种实验，基于文本挖掘的预测技术平均表现更好（即，更高的召回率和精确度），并且差异在统计上是显着的。作者还测试了跨项目漏洞预测，但两种方法的跨项目预测性能普遍较差。由于作者没有考虑应用程序之间数据的不均等分布，因此预计跨项目预测表现不佳。 Morrison等人（2015）指出，虽然微软团队采用了缺陷预测模型，但漏洞预测模型（VPM）并非如此。为了解释这种差异，作者尝试复制Zimmermann等人提出的VPM。 （2010）有两个较新版本的Microsoft Windows操作系统。作者将二进制水平预测精度提高了约75％，并且召回率约为20％;然而，二进制文件通常对于实际检查来说非常大，并且工程师首选源级别预测。因此，作者为源流水平粒度建立了相同的模型，其精度低于50％，召回率低于20％。基于这些结果，作者得出结论：“必须通过安全特定指标来”重新调整VPM以实现可操作的性能。“ Younis等人。 （2016）尝试识别包含更可能被利用的漏洞的代码的属性。为此，作者收集了来自Linux内核和Apache HTTPD Web服务器项目的183个漏洞，其中包括82个可利用的漏洞。作者从四个不同的类别中选择八个软件度量来表征这些漏洞，并使用Welch的t检验来检验每个度量的判别力。指标的判别力的结果是混合的;一些指标在统计上具有显着的判别力，而其他指标则没有。作者还研究了是否存在可用作可利用漏洞预测因子的指标组合，其中测试了三种不同的特征选择方法和四种不同的分类算法。表现最佳的模型是具有包装子集选择方法的随机森林分类，其实现了84％的F-度量。 4.2讨论在前一小节中，我们回顾了基于软件度量的脆弱性预测模型的最新研究。表1列出了本节所述所有文章的摘要，其中我们指定了每项工作的主要差异因素。 人们可能会质疑基于软件工程指标来预测软件漏洞存在的基本决策，作为混淆症状和原因的一个例子（Zeller etal. 2011 ）。一些研究（例如，Walden等人（2014）强调了这种批评，这些研究表明，与基于某些软件度量的脆弱性预测模型相比，软件源代码的基本文本挖掘可以在预测性能方面产生更好的结果;尽管如此，这种实证研究不能推广到所有软件项目和所有软件指标。另一方面，Tang等人最近的一项研究（2015）批评了Walden等人的结论（2014），因为他们没有考虑影响代码检查的单个组件的大小;因此，他们比较了这两种预测模型在易受影响的漏洞预测背景下的预测能力，并得出结论，这两种指标的表现相似。 使用软件度量进行漏洞预测的一个理由是，这些度量标准通常很容易获得，或者很容易在软件工程项目中获得。此外，软件故障/缺陷预测模型已经在一些软件项目中使用，而构建漏洞预测模型不需要额外的专业知识。另一方面，这些系统的目的是仅作为更好地规划和分配软件工程团队资源的指导模型。因此，基于软件度量的漏洞预测模型是工业界和学术界的一系列研究。 基于上面回顾的上述工作，很明显，基于软件指标的漏洞预测模型尚未成熟。从以往研究的回顾中可以得出一些结论，包括挑战和可能的未来工作： 脆弱性预测模型的统计挑战是由数据集中的漏洞很少而且稀疏的事实引入的。在数据挖掘和机器学习的过程中，这个问题被称为不平衡类数据，它可以极大地阻碍机器学习算法的性能，并且有解决该问题的实践（Domingos 2012）。本节中回顾的一些先前的工作已经解决了不平衡类数据问题，并且对大多数类进行了随机欠采样。这是一个重要的问题，任何利用机器学习和数据挖掘技术的研究都不应忽视这一问题。 与之前的大多数研究相比，Moshtari等人（2013）使用半自动化框架进行漏洞检测，他们使用这种框架代替通过公共咨询和漏洞数据库（例如NVD）提供的信息。与之前的作品相比，他们获得了显着更高的召回率和精确度值（即使在跨项目设置中）。这可能是一种很有前景的方法，未来的研究也可以用来收集更完整的漏洞信息并获得更好的结果。 漏洞预测模型领域中的跨项目研究很少，因此是未来工作的一个领域。特别是与缺陷预测模型相比，跨项目漏洞预测的研究非常不足。跨项目预测引入了额外的挑战，这些挑战源于训练和测试集中的数据分布可能显着变化并且阻碍传统机器学习和统计分析技术的性能。这一挑战在机器学习研究中被称为“归纳转移”（或“转移学习”）技术（Pan and Yang 2010），它们的使用已经在软件缺陷预测研究中得到了研究（Ma et al.2012 ; Nam et al.2013）。这些研究可以成为未来跨项目脆弱性预测模型研究的基础。 基于软件指标的漏洞预测研究中的大多数研究报告结果不佳。一个可能的结论是传统的软件度量标准不适合软件漏洞。 Morrison等人明确讨论了这一结论（2015年）。从此以后，确定安全特定指标，例如Doyle和Walden（2011）提出的安全资源指标（SRI）是未来研究的另一个领域。 这个领域的未知领域正在使用深度学习方法进行漏洞预测。深度学习是机器学习研究中新出现的一个主题，它在几个应用领域取得了巨大成就，并且越来越受到研究人员和从业者的关注（LeCun等人，2015）。Yang等人（2015）提出了一项关于应用深度学习方法进行即时软件缺陷预测的研究。这是脆弱性预测模型的未来研究的另一个有希望的领域。 5异常检测方法在本节中，我们将回顾一类使用机器学习和数据挖掘技术进行软件漏洞分析和发现的异常检测方法。异常检测是指数据中的模式不符合正常和预期行为的问题;通常被称为anomalies或outliers（Chandola等，2009）。在许多不同的研究领域和应用领域中已经广泛研究了这个问题;包括软件缺陷和漏洞发现领域。 在软件质量保证的背景下，异常检测方法旨在通过使源代码中的位置不符合应用程序编程接口（API）的通常或预期代码模式来识别软件缺陷。这种API使用模式的简单示例是malloc和free的函数调用对，或者lock和unlock。除了这些简单的众所周知的模式之外，每个API都有自己的规则和模式份额，这些规则和模式也很复杂，而且记录不完善。不符合API的预期规则和使用模式可能导致软件缺陷，也可能导致软件漏洞。 异常检测方法应用于软件质量保证的另一个领域是检测被忽视的条件或缺少检查。缺少检查是许多软件缺陷和漏洞的根源。这些检查可大致分为两类：（1）正确使用API所需的检查; （2）检查实现程序逻辑。这两种类型都可能导致软件缺陷或软件漏洞。第一种类型的示例是检查用作API函数调用的参数的输入数据的正确类型或值。缺少这样的检查可能导致软件崩溃，未定义或不期望的行为（例如，除以零）。失败也可能产生安全后果（例如，流量溢出，SQL注入等）。在访问资源对象时，缺少第二种类型的示例来检查主题的权限或权限。同样，这些逻辑缺陷可能具有安全性后果，从而导致安全逻辑漏洞（例如，机密性和完整性访问控制）。 已经提出异常检测方法用于检测不正确的API使用模式和丢失检查。这些方法的一个重要方面是自动提取正常行为，换句话说，自动提取规范，规则和模式，然后将其用作检测异常行为的基础。自动提取正常行为对于这些方法的适用性和成功性至关重要，而如果人类用户提供正常行为或规范，则会极大地妨碍该方法的效率，因为：（1）编写规范是艰巨而乏味的任务; （2）人为错误可导致不准确的指定，导致不正确的结果。 在下文中，我们按时间顺序回顾和总结以前的工作，从过去十年的早期工作开始，到近年来在软件缺陷和漏洞检测的异常检测方法中的最新工作。请注意，一些经过审核的工作侧重于安全漏洞，而其他漏洞则没有;但我们仍在审查这些工作，因为所提出的方法并非专门针对非安全性缺陷。 5.1 最近工作总结已经提出异常检测方法用于检测不正确的API使用模式和丢失检查。这些方法的一个重要方面是自动提取正常行为，换句话说，自动提取规范，规则和模式，然后将其用作检测异常行为的基础。自动提取正常行为对于这些方法的适用性和成功性至关重要，而如果人类用户提供正常行为或规范，则会极大地妨碍该方法的效率，因为：（1）编写规范是艰巨而乏味的任务; （2）人为错误可导致不准确的指定，导致不正确的结果。 在下文中，我们按时间顺序回顾和总结以前的工作，从过去十年的早期工作开始，到近年来在软件缺陷和漏洞检测的异常检测方法中的最新工作。请注意，一些经过审核的工作侧重于安全漏洞，而其他漏洞则没有;但我们仍在审查这些工作，因为所提出的方法并非专门针对非安全性缺陷。 Engler 等人（2001）指出，解决程序错误的一个主要障碍是知道系统必须遵守的正确性规则，这些规则通常是无证的或以临时方式指定的。为了解决这个问题，他们演示了一种自动提取程序源代码隐含的程序员beliefs的技术。为此，他们讨论了错误作为异常行为的概念，并提出了一种方法，通过为源代码定制“规则模板”来提取程序员的beliefs（例如，规则模板“必须与之配对的函数调用 “）。提取了两种类型的规则：（1）Must-beliefs 和（2）May-beliefs。Must-beliefs 是某些众所周知的编程规则（例如，“指针解引用意味着程序员必须相信指针是非空的”）。 May-belief是一些代码特征表明beliefs的情况，但可能是巧合。为了区分有效的May-beliefs 和巧合，使用称为Z-排名的统计分析技术来发现这些beliefs的违规（或错误），以对错误进行排序和分类。为了评估，作者检查了复杂软件系统上的各种规则模板，例如Linux和OpenBSD项目。结果显示不同情景下的假阳性率不同，从4％到57％不等。作者还使用众所周知的安全漏洞规则测试安全检查程序，导致Linux和OpenBSD中出现35个安全漏洞。 Livshits和Zimmermann（2005）提出了一个名为DynaMine的工具，它根据高度相关的方法调用分析修订历史中的源代码校验，以自动提取特定于应用程序的编码模式。 DynaMine分析增量变化，这有助于实现更精确的结果。所提出的方法首先预处理已插入的方法调用的软件修订历史，并将该信息存储在要挖掘的数据库中。挖掘方法基于经典先验算法的修改版本，其使用一组项目作为其输入并且在项目之间产生频繁的项目集和强关联规则。这些修改改进了算法的运行时间，并允许该方法进行扩展以分析大型软件系统。此外，作者将几种排名策略应用于算法挖掘的模式。提取的模式被呈现给用户以进行评估。在用户选择模式之后，使用动态分析工具进一步验证所选模式并检测违规。该方法在两个大型Java项目上进行了评估。据作者称，拟议的挖掘方法发现了56种以前未知的，高度应用程序特定的模式。根据实验结果，56个（57％）模式中有32个在运行时被击中，其中32个（66％）模式中的21个被认为是非常有效的模式。此外，发现超过260种模式违规，但作者没有评估假阳性率。 Li和Zhou（2005）断言程序通常遵循许多隐式和未记录的编程规则，这些规则违反了这些规则，不知情的程序员很容易引入缺陷。作者提出了一种名为PR-Miner的方法，用于从大型源代码中提取隐式编程规则，而无需事先了解软件，也不需要程序员的大量工作。 PRMiner旨在以一般形式（没有fxed模板）提取编程规则，包含不同类型的多个元素，如函数，变量和数据类型。总之，PR-Miner首先解析和预处理程序源代码，删除不必要的元素，如关键字，常量数据值等，并根据数据将结构中的函数和数据中的局部变量重命名为相似的名称类型。在预处理之后，所有程序元素被散列为数字，并且函数定义被映射到函数内的所有元素的一组数字散列值，作为行插入到项集数据库中。使用频繁项集挖掘算法（即FPclose）挖掘该数据库，以找出一起出现的频繁程序元素。这些频繁的程序元素集称为编程模式。有效的规则生成算法用于从频繁的编程模式中提取编程规则。编程规则用于检测违规，这是基于在大多数情况下通常遵循编程规则并且很少发生违规的想法。对三个大型开源项目进行评估。结果表明，PR-Miner在这些软件项目中发现了数以千计的规则，作者无法对所有这些规则进行验证，只讨论了一些样本。 PR-Miner还报告了许多违规行为，作者设法仅手动评估前60位报告，揭示假阳性率很高（73％-90％之间）。 Wasylkowski等（2007）重申这样一个事实，即与对象交互通常需要遵循模型或协议，这些模型或协议并不总是记录在案，并且违规可能导致缺陷。为了自动提取典型的对象使用模型，作者提出了在程序源代码中挖掘方法调用的序列，然后将其用作偏差作为缺陷候选者。首先，从Java字节码中提取对象使用模型，Java字节码是具有匿名状态的fnite状态自动机，以及作为状态转换的可行方法调用。使用每个单一方法的过程内静态分析来提取该模型。然后，使用对封闭模式的频繁项集挖掘，从使用模型中挖掘方法调用的时间属性（例如，“方法next（）可以在hasNext（）之前”）。这些频繁的模式表示正常的对象使用，并用于训练分类器以识别对这些模式的违反，这些模式被视为可能的缺陷位置。此外，作者还引入了一个缺陷指标，该指标根据几个因素对异常进行排序。提出的方法是作为一个名为JADET（用于Java异常检测器）的工具实现的。评估是在fve流行的开源Java程序上进行的。根据报告的结果，在所有5个项目中JADET检测到的前77个异常中，有40个（52％）误报，5个缺陷，5个代码smells和27个提示。 Acharya等（2007）指出以前的方法无法在API使用模式中捕获一些有用的排序信息，特别是当跨不同的进程涉及多个API时。作者提出了一种从API客户端代码中提取“频繁部分规则”的自动方法。该方法包括四个主要步骤，并基于一些名为MAPO的作者的先前工作（Xie和Pei 2006）。在第一步中，采用下推模型检查（PDMC）过程来提取与API相关的进程间控制流敏感的静态迹线。在第二步中，在给定的跟踪上使用算法来分离不同的使用场景，因此可以单独挖掘每个场景。在第三步中，名为FRECPO的方法用于从每个静态执行跟踪中提取的一组场景中挖掘“频繁闭合的部分规则”（FCPO）。 FCPO可能不是通用模式，只能针对分析的客户端代码进行指定。为了解决这个问题，引入了一个名为Mine-Verify的算法，该算法使用两个随机拆分的不相交的客户端集来验证模式。为了评估，该框架应用于X11 UNIX窗口系统的72个客户端程序。对于每个实验，随机选择36个客户作为挖掘客户端，其余36个客户端用作验证客户端。作者没有对他们的实验结果进行评估，而是仅对一个例子进行评估;为此，通过该方法成功检测到6种已知模式中的5种，并且仅报告了一种错误模式。 Chang等 （2008）通过对Firefox项目的版本1.0和1.5中的bug fxes进行初步研究，强调忽略条件作为一种难以解决的缺陷类别的重要性，该项目显示167个选定的错误中有109个（65％）涉及一个或多个被忽视的条件。为此，作者提出了一种方法，将数据挖掘技术与静态程序分析相结合，以提取代码库中的隐式条件规则，并将被忽视的条件作为规则违规进行检测。因此，程序由“系统依赖图（SDG）”表示，作为修改的“过程依赖图（PDG）”的集合，称为“增强PDG”（EPDG）。 EPDG增加了所谓的“共享数据依赖边缘”（SDDE），它链接在控制流路径中使用相同变量定义的程序元素。潜在规则由EPDG minors代表，可以将其视为EPDG的子图，其中一些路径已经收缩到边缘。 “启发式最大频繁子图挖掘（HMFSM）”算法用于在EPDG子图的“近传递闭包（NTC）”的数据库中找到重复的图minors。在提取和确认有效规则之后，使用启发式图匹配算法搜索NTC图数据库的规则违反（忽略条件）。为了评估，作者通过在四个开源项目中应用该方法进行了实验。在所有四个项目中，该方法检测到超过1200个候选规则，平均不到25％的检测规则无效（没有语义意义）。启发式图匹配算法在fnding规则实例中完全成功，具有100％的精度，但违规检测的结果并不令人印象深刻，其中所有四个项目中79％的报告违规都是误报。作者声称“大约一半的误报是由语义上等同的陈述给出了不同的标签”，并提出了改善未来工作情况的一些建议。 Thummalapenta和Xie（2009）提出了一种新方法来降低自动挖掘编程规则的误报率。为此，他们引入了“替代模式”的概念，其中API调用的各种频繁模式被一起考虑。例如，替代模式可以是P1或P2形式，其中P1和P2都是频繁的，P2是P1的语义替代。误报的另一个原因是不平衡的替代模式，其中P1和P2是语义上有效的替代方案，但P1是高频率的，而P2在整个代码库中并不常见。这些不平衡的替代方案表示为“P1或P2”，使用传统的挖掘技术更具挑战性。提出了一种称为“Alattin”的方法，其包括称为“ImMiner”的新挖掘算法，其使用迭代挖掘策略来挖掘平衡和不平衡模式以及用于检测被忽略条件的技术。首先，Alattin在源代码中提取重用的API，并将它们提供给代码搜索引擎以收集其他相关的代码示例。在收集的数据库上执行频繁的项集挖掘以提取频繁的模式。然后，对于每个频繁模式，输入数据库被分成两个负数据库和正数据库，其中否定数据库包括不符合模式的所有模式候选者，而肯定数据库包括所有符合候选者。频繁的项目集挖掘再次应用于否定数据库以构建不平衡的替代模式。然后使用这些挖掘的模式来检测方法调用站点处的违规。为了检测被忽略的条件，Alattin提取围绕API调用站点的所有条件检查。由于每个挖掘模式都包含多个备选方案，因此只有在呼叫站点不满足任何备选方案时，Alattin才会报告违规行为。出于评估的目的，对6个Java库执行了经验实验，其中总共144个模式被挖掘，运行时间约为1小时。作者手动评估了144种模式中的90种，其中75种（83％）是真实规则，7种是部分规则，8种（9％）是错误规则。与类似方法相比，对相同文库进行违规检测的实验导致假阳性减少28％。 Gruska等（2010）研究了跨项目异常检测的可能性。为此，作者引入了一种轻量级，与语言无关的解析器，适用于分析用几种语言编写的程序，语法类似（包括C，C ++，Java和PHP）。由于所提出的方法基于程序结构和函数调用，因此可以忽略源代码中存在的许多细节，并且解析器仅解析源代码的选定部分;这就是使解析器轻量级和语言无关的原因。解析过程包括几个步骤，包括创建令牌，识别结构和提取函数调用。类似于抽象语法树（AST）的专门设计的通用抽象表示用于存储由解析器提取的信息。抽象表示用于创建函数模型，这些函数模型是有限状态机，其中状态表示代码中的位置，转换是函数调用。此模型用于在特定函数中提取所有可能的函数调用序列以及其他相关信息，例如被调用函数的名称，参数数量，参数，返回值和目标。然后，将每个函数模型转换为一组时间属性，表示函数调用之间的值的流动。这是通过使用作者之前的工作中的JADET工具来实现的（Wasylkowski等人，2007）。扩展JADET工具以支持上述模型，并用于从功能模型中挖掘频繁的时间属性。概念分析方法用于异常检测，类似于JADET工具中使用的方法。最后，在呈现给用户之前对检测到的异常进行排序和过滤。为了进行评估，开发了6000多个开源Linux项目，以提取1600万个临时属性，反映正常的API使用情况。作者从分布中随机选择了20个项目，并应用了异常检测。从总共138个检测到的异常中，只有前25％是由作者手动评估的，这导致仅4个缺陷，7个代码异味和39个（78％）误报。作者还将其分析系统作为基于网络的服务提供给checkmycode.org，该服务目前已停止服务，截至2011年底。 Yamaguchi等人 （2013）提出了一个名为Chucky的系统，用于自动检测源代码中的缺失检查，旨在协助手动代码审计。 Chucky将机器学习技术与静态程序分析相结合，以确定缺失的检查。作者在源代码中区分了两种类型的安全检查：（1）检查实现安全逻辑（例如，访问控制）; （2）检查确保安全的API使用（例如，检查大小）。 Chucky采用了一个五步程序，为审核员选择的每个源和接收器执行。分析从基于岛语法的强大解析开始，其中为每个函数定义提取条件，赋值和API符号。其次，基于函数中API符号的相似性，使用最近邻和词袋技术来执行邻域发现。第三，执行轻量污染以仅确定与目标源或接收器相关联的那些检查。第四，基于受污染的条件将所有函数及其邻居嵌入向量空间中。最后，通过首先计算所有嵌入相邻向量的质心作为正态性模型来执行异常检测，然后基于其向量与其邻域的正常模型的距离计算每个函数的异常分数。基于异常分数对最终结果进行排序并呈现给用户。进行定性和定量评估以证明该方法的有效性，他们分析了几个开源项目代码中缺失的检查。作者报告说，Chucky在所有项目中都发现了几张丢失的支票，其中几乎所有前10名都报告了每项功能的异常，其中包含缺陷或安全漏洞。此外，在本研究过程中还使用Chucky发现了12个先前未知的漏洞（即0-day）。 5.2 讨论在上一小节中，我们回顾并总结了异常检测领域的一些研究，以发现软件缺陷和漏洞为异常行为。表2中还列出了本节中所有文章的概览，其中我们指定了每项工作的主要差异因素。 如前所述，异常检测方法可用于解决由于API使用不当导致的技术软件漏洞，以及由于忽略条件或缺少检查而导致的逻辑漏洞。需要注意的一个重要事实是，此过程可以由工具自动执行，而无需指定安全策略或安全性规范。我们认为，这是异常检测方法最有希望的方面。但是，软件缺陷和漏洞发现的异常检测方法存在局限性： 异常检测方法仅适用于成熟的软件系统。此限制是因为基本假设缺少检查或不正确的API使用是罕见事件，并且应用于安全对象的大多数条件以及软件项目中的API使用都是正确的。这种假设在成熟的软件项目中主要适用。 在代码库中必须经常进行条件检查或API使用，以便通过挖掘算法将其检测为模式。罕见的检查或API使用不太可能作为模式被挖掘，因此无法检测到偏差。所有利用频繁项集挖掘方法的工作都受此限制（例如，Li和Zhou（2005），Wasylkowski等（2007年），和Gruska等人（2010））。 有时，异常检测方法无法指定缺陷或漏洞的类型，因为这些方法只能说明给定代码不符合任何正常规则或模式，并且可能违反任何规则或模式。当然，可能存在实例明显违反单个规则或模式而不是任何其他实例的情况，在这种情况下，系统可以指定缺陷的类型甚至修复。 先前方法的高假阳性率表明这些系统尚不可靠，输出需要仔细的人工审核，这限制了异常检测系统的可用性。从高假阳性率中得到的一些值得注意的工作包括（Li和Zhou 2005; Wasylkowski等人2007; Chang等人2008）。 异常检测方法的局限性并不仅限于软件缺陷和漏洞发现领域，许多其他应用领域也存在这些缺点。异常检测范式在网络入侵检测领域受到挑战;例如盖茨和泰勒（Gates and Taylor，2006）提出了一个具有挑衅性的讨论，他们质疑研究人员通常做出的一些假设。Sommer和Paxson（2010）还提供了关于采用异常检测方法进行网络入侵检测的挑战的讨论。 Chandola等人提供了关于不同应用领域中异常检测系统的挑战和不同方面的更一般性讨论（2009年）。 很明显，在使用异常检测的漏洞发现方面仍有进一步发展的空间。从先前研究的回顾中得出的一些可能的未来工作如下： 先前关于缺陷和脆弱性发现的异常检测的工作中的普遍问题是高假阳性率。分析工具输出中的高误报率使其用户压倒无效。通过降低假阳性率来提高准确性对于未来的工作非常重要。 Thummalapenta和Xie（2009）的工作是这方面研究的一个例子，它提供了有趣的贡献。 像Chucky（Yamaguchi等人，2013）这样以安全为重点的方法存在的一个问题是无法区分安全相关的异常（漏洞异常）和非漏洞的异常。这些方法可以成功地解决缺少检查和不正确的API使用缺陷，但并非所有这些缺陷都是安全漏洞。未来的工作可以提出新方法来帮助区分缺陷和安全漏洞，使结果与安全分析师更相关并提高可用性。 Graphs是丰富的表示，广泛用于程序分析，软件测试和软件漏洞发现领域。 Chang等（2008）研究了使用图挖掘和图匹配技术来发现软件中的缺失检查缺陷。如前所述，这项工作在提取规则和匹配实例方面取得了可喜的成果，但却产生了很高的误报率。最近的一项调查由Akoglu等人发表（2015），回顾了基于图的异常检测和描述的最新进展。在未来的工作中可以进一步研究用于漏洞发现的基于图的异常检测领域。 6漏洞代码模式识别6.1最近工作总结6.2讨论7其他方法8应用技术分析8.1特征工程和表示8.2模型构建8.3模型评估9结论和未来工作","content":"<p><strong>由于其中主要内容都是关于数据挖掘技术在源代码漏洞和分析中的使用总结，涉及到使用机器学习方法的较少，所以未翻译阅读完，后续再继续翻译。</strong></p>\n<h1 id=\"Abstract\"><a href=\"#Abstract\" class=\"headerlink\" title=\"Abstract\"></a>Abstract</h1><p>软件安全漏洞是计算机安全领域的关键问题之一。由于其潜在的高严重性影响，在过去几十年中已经提出了许多不同的方法来减轻软件漏洞的损害。机器学习和数据挖掘技术也是解决该问题的众多方法之一。在本文中，我们对利用机器学习和数据挖掘技术的软件漏洞分析和发现的许多不同工作进行了广泛的回顾。我们回顾了这个领域中不同类别的工作，讨论了优点和缺点，并指出了挑战和一些未知的领域。</p>\n<table>\n<thead>\n<tr>\n<th>relevant information</th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><em>作者</em></td>\n<td>SEYED MOHAMMAD GHAFFARIAN；HAMID REZA SHAHRIARI</td>\n</tr>\n<tr>\n<td><em>单位</em></td>\n<td>Amirkabir University of Technology</td>\n</tr>\n<tr>\n<td><em>出处</em></td>\n<td>ACM Comput. Surv</td>\n</tr>\n<tr>\n<td><em>原文地址</em></td>\n<td><a href=\"https://dl.acm.org/citation.cfm?id=3092566\" target=\"_blank\" rel=\"noopener\">https://dl.acm.org/citation.cfm?id=3092566</a></td>\n</tr>\n<tr>\n<td><em>源码地址</em></td>\n<td></td>\n</tr>\n<tr>\n<td><em>发表时间</em></td>\n<td>2017年</td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"1-简介\"><a href=\"#1-简介\" class=\"headerlink\" title=\"1. 简介\"></a>1. 简介</h1><p>如今，计算机软件无处不在，现代人类生活在很大程度上依赖于各种各样的软件。在不同的平台上运行不同形式的计算机软件，从手持移动设备上的简单应用程序到复杂的分布式企业软件系统。这些软件采用多种不同的方法生成，基于各种各样的技术，每种技术都有自己的优点和局限。这个庞大的关键行业以及计算机安全领域的一个重要问题是软件安全漏洞问题。在这个问题上引用行业专家的话：</p>\n<blockquote>\n<p>“In the context of software security, vulnerabilities are specifc ﬂaws or oversights<br>in a piece of software that allow attackers to do something malicious: expose or alter<br>sensitive information, disrupt or destroy a system, or take control of a computer system<br>or program.” Dowd et al. (2007) </p>\n</blockquote>\n<p>软件漏洞所带来的威胁的严重程度不同取决于开发复杂性和攻击面等因素（Nayak等人，2014）。在过去的二十年中，存在大量的例子和事件，其中软件漏洞给公司和个人带来了重大损害。为了强调这个问题的重要性，我们近年来提到了一些例子。一个突出的例子是流行浏览器插件中的漏洞情况，这些漏洞威胁到数百万互联网用户的安全和隐私（例如，Adobe Flash Player（US-CERT 2015; Adobe Security Bulletin 2015）和Oracle Java（US-CERT 2013） ）。此外，流行和基础开源软件中的漏洞也威胁到全球数千家公司及其客户的安全（例如Heartbleed（Codenomicon 2014）ShellShock（赛门铁克安全响应2014）和Apache Commons（Breen 2015） ）。</p>\n<p>上述示例只是每年报告的大量漏洞中的一小部分。由于这个问题的重要性，学术界和软件行业的研究人员已经研究了许多不同的缓解方法。 Shahriar和Zulkernine（2012）提出了一项针对缓解计划安全漏洞的不同方法的广泛调查，包括测试，静态分析和混合分析，以及1994年至2010年期间发布的安全编程，程序转换和修补方法。</p>\n<p>除了在Shahriar和Zulkernine（2012）中审查的众所周知且经过深入研究的方法之外，还存在一种不同的方法，这些方法利用来自数据科学和人工智能（AI）的技术来解决软件漏洞分析和发现。 Shahriar和Zulkernine（2012）忽略了这类有趣的方法，但在接下来的几年中（从2011年开始），研究界越来越关注这一方法。</p>\n<p>在本文中，我们针对利用数据挖掘和机器学习技术的软件漏洞分析和发现的这类方法提出了分类评论。首先，我们确定了软件漏洞分析和发现的问题，并简要介绍了在这个领域的传统方法。我们还简要介绍了机器学习和数据挖掘技术以及它们使用背后的动机。之后，我们将分别回顾利用机器学习和数据挖掘技术解决软件漏洞分析和发现问题的许多不同工作。我们为这类作品提出了不同的类别，并讨论了它们的优点和局限性。最后，我们在结束本文时讨论了在这个领域的挑战，并指出了一些未知的领域，以激发这一新兴研究领域的未来工作。</p>\n<h1 id=\"2-背景：软件漏洞分析和发现\"><a href=\"#2-背景：软件漏洞分析和发现\" class=\"headerlink\" title=\"2.背景：软件漏洞分析和发现\"></a>2.背景：软件漏洞分析和发现</h1><h2 id=\"2-1-定义\"><a href=\"#2-1-定义\" class=\"headerlink\" title=\"2.1 定义\"></a>2.1 定义</h2><p>我们首先说明软件安全漏洞的定义。在他关于软件漏洞分析问题的博士论文中，Ivan Krsul将软件漏洞定义为：</p>\n<blockquote>\n<p>“an instance of an error in the specifcation, development, or confguration of software<br>such that its execution can violate the security policy.” (Krsul 1998) </p>\n</blockquote>\n<p>差不多十年之后，Ozment承认Krsul的定义，但建议稍作修改：</p>\n<blockquote>\n<p>“A software vulnerability is an instance of a mistake in the specifcation, development,<br>or confguration of software such that its execution can violate the explicit or implicit<br>security policy.” Ozment (2007) </p>\n</blockquote>\n<p>Ozment将单词error更改为mistake，并引用IEEE标准术语软件工程术语（IEEE Standards 1990）来证明这一点。如前所述，行业专家提供了类似的定义：</p>\n<blockquote>\n<p>“In the context of software security, vulnerabilities are specifc ﬂaws or oversights<br>in a piece of software that allow attackers to do something malicious: expose or alter<br>sensitive information, disrupt or destroy a system, or take control of a computer system<br>or program.” Dowd et al. (2007) </p>\n</blockquote>\n<p>从上述定义可以看出，不同的关键术语用于定义软件漏洞。为了澄清这些术语并选择最合适的术语，我们参考IEEE标准软件工程术语表（IEEE标准1990）。我们查找四个关键术语的定义：“error”，“fault”，“failure”和”mistake”根据IEEE标准（1990），<strong>error</strong>的定义是：“计算的，观察的或测量的值或条件与真实的，规定的或理论上正确的值或条件之间的差异”（IEEE标准1990）。<strong>fault</strong>是：“计算机程序中的步骤，过程或数据定义不正确”（IEEE标准1990）。<strong>faults</strong>也称为flaws或bugs。<strong>failure</strong>是：“系统或组件无法在规定的性能要求下执行其所需的功能”（IEEE标准1990）。最后，<strong>mistake</strong>是：“产生错误结果的人为行为”（IEEE标准1990）。这些术语的关系的总结和澄清是“区分人类行为（mistake），其表现（硬件或软件faults），故障结果（failure）以及结果的数量不正确（error）“（IEEE标准1990）。</p>\n<p>从这些定义可以清楚地看出，用于定义软件漏洞的合适关键术语是“fault”（也是flaw或bug）。更确切地说：</p>\n<blockquote>\n<p>A software vulnerability is an instance of a flaw, caused by a mistake in the design, development, or configuration of software such that it can be exploited to violate some explicit or implicit security policy.</p>\n</blockquote>\n<p>软件漏洞的原因是人为错误，其表现形式是flaw（fault或bug）。执行faulty 状态的软件不一定违反安全策略;直到某些特制数据（漏洞利用代码）或某些具有某些条件的随机数据到达有缺陷的语句，此时，其执行可能违反某些安全策略（利用导致安全性失败）。</p>\n<p>其他人已经承认将软件漏洞定义为faults，并将mistake定义为其原因。 Ozment指出“由于开发错误导致的漏洞是一个fault”（Ozment 2007），但他区分了开发错误导致的漏洞，以及设计或配置错误导致的漏洞;但没有提供这种差异的解释。 Dowd等人。还说：</p>\n<blockquote>\n<p>“In general, software vulnerabilities can be thought of as a subset of the larger phenomenon of software bugs. Security vulnerabilities are bugs that pack an extra hidden surprise: A malicious user can leverage them to launch attacks against the software and supporting systems.” Dowd et al. (2007)</p>\n</blockquote>\n<h2 id=\"2-2-健全性，完整性和不可判定性\"><a href=\"#2-2-健全性，完整性和不可判定性\" class=\"headerlink\" title=\"2.2 健全性，完整性和不可判定性\"></a>2.2 健全性，完整性和不可判定性</h2><p>程序漏洞分析是确定给定程序是否包含已知安全漏洞（根据安全策略）的问题。基于图灵停止问题和赖斯定理的不可判定性，可以证明许多程序分析问题在一般情况下也是不可判定的（Landi 1992; Reps 2000）。对于从业者来说，不可判断性意味着不存在对问题的完整解决方案。</p>\n<p>在数学逻辑中，如果系统不能批准无效参数，则证明系统是合理的。如果所有有效参数都可以被系统批准，则证明系统是完整的。通过推论，一个完整的证据系统是一个可以批准所有有效论证并反驳所有无效论证的系统（Xie et al.2005）。</p>\n<p>在软件安全的背景下，如果漏洞分析系统从未批准易受攻击的程序（没有漏掉漏洞），那么它就是健全的。如果可以批准所有安全程序（没有虚假漏洞），则漏洞分析系统是完整的。根据推论，健全且完整的漏洞分析系统可以批准所有安全程序并拒绝所有易受攻击的程序（没有错过漏洞且没有漏洞）（Xie et al.2005）。如前所述，已知这种完善和完整的系统是不存在的（Jhala和Majumdar，2009）。</p>\n<p>除了漏洞分析之外，更实用的系统是程序漏洞发现（或漏洞报告）系统。与批准或不批准给定程序的安全性（即二进制输出）的漏洞分析系统相比，程序漏洞发现系统报告给定的每个漏洞的更详细信息（例如类型，位置等）程序。这是软件行业更有用和理想的系统，它可以帮助开发人员和工程师更轻松地检测和修复漏洞。同样，众所周知，一个完善的软件漏洞发现系统（一个不报告漏洞，报告所有实际漏洞的系统）是不存在的。</p>\n<h2 id=\"2-3传统方法\"><a href=\"#2-3传统方法\" class=\"headerlink\" title=\"2.3传统方法\"></a>2.3传统方法</h2><p>尽管软件漏洞分析和发现问题具有不可判定的性质，但由于该问题的重要性，学术界和软件行业的从业者已经研究和提出了大量的方法。提出的方法都不可避免地是近似解;他们都缺乏健全性或完整性，或两者兼而有之。因此，与以前的工作相比，所有研究工作都试图提出一种改进的方法，涉及软件漏洞分析和发现过程的特定方面;例如，漏洞覆盖率，发现精度，运行时效率等。</p>\n<p>Shahriar和Zulkernine（2012）提出了对缓解程序安全漏洞的不同方法的广泛审查，包括在1994年至2010年期间的程序漏洞分析和发现方法。所有程序分析方法可分为三大类：</p>\n<ul>\n<li><strong>静态分析</strong>：根据源代码分析给定程序，无需执行。这些方法利用广义抽象来分析程序的属性，因此静态分析方法最健全的（即没有错过的漏洞，但可能会报告错误的漏洞）。泛化越准确，报告的漏洞就越少。在实践中，必须在分析精度和计算效率之间进行交易。</li>\n<li><strong>动态分析</strong>：通过使用特定的输入数据执行并监视其运行时行为来分析给定程序。在这种方法中，一组输入测试用例用于分析程序的属性，并且由于通常存在无限可能的输入和运行时状态，因此动态分析系统无法分析整个程序的行为。因此，动态分析系统是最完整性的（即，批准所有安全程序而不报告虚假漏洞），但它们不可能是健全的，因为它可能会遗漏一些隐藏在看不见的程序状态中的漏洞。动态分析方法存在实际缺点，即对给定程序的工作运行时的环境要求，以及在分析大型复杂软件时处理所有输入测试用例所需的长时间和高成本。然而，动态分析方法在软件行业中得到了极大的应用。<ul>\n<li><strong>混合分析</strong>：使用静态分析和动态分析技术的混合分析给定程序。基于先前关于静态和动态分析方法的讨论可能存在误解，混合分析方法可能是完整的和健全的（因此，违反了问题的不可判定性）。不幸的是，事实并非如此，虽然混合分析方法可以从静态和动态分析的优势中获益，但它们也受到两种方法的局限性的影响。混合分析方法可以是利用动态分析来识别错误漏洞的静态分析系统，也可以是利用静态分析技术来指导测试用例选择和分析过程的动态分析方法。</li>\n</ul>\n</li>\n</ul>\n<p>但应注意，并非所有静态分析系统都是健全的，并非所有动态分析系统都是完整的。在众多不同的漏洞发现方法中，有些在软件行业中更为成熟;亦即</p>\n<ul>\n<li>Software Penetration Testing: a manual software security testing approach, carried out  by a team of security experts (also referred to as white-hat hackers) (Arkin et al. 2005; Bishop<br>2007).                                                       </li>\n<li>Fuzz-Testing: also known as random-testing, where well-formed input data are randomly  mutated and fed to the program under test at large, while monitoring for failures (Godefroid   2007; Godefroid et al. 2012).                                </li>\n<li>Static Data-Flow Analysis: also known as “Tainted Data-ﬂow Analysis,” it is a static program analysis approach where untrusted data from input sources is marked as tainted and  its ﬂow to sensitive program statements known as sinks is tracked as a potential indicator  of vulnerability (Evans and Larochelle 2002; Larus et al. 2004; Ayewah et al. 2008; Bessey  et al. 2010).                                                </li>\n</ul>\n<h1 id=\"3-使用机器学习和数据挖掘技术\"><a href=\"#3-使用机器学习和数据挖掘技术\" class=\"headerlink\" title=\"3.使用机器学习和数据挖掘技术\"></a>3.使用机器学习和数据挖掘技术</h1><p>除了上述方法之外，还有一类不同的工作利用数据科学和人工智能（AI）的技术来解决软件漏洞分析和发现的问题。在Shahriar和Zulkernine（2012）的评论中忽略了这一类有趣的方法，而在接下来的几年（从2011年起），研究界越来越关注这一方法。<br>人工智能技术中的机器学习技术在许多不同的应用领域都被证明是有效的（Russell和Norvig 2009）。对于计算机安全和隐私领域也是如此，许多不同的应用程序已经使用这些技术解决（例如，垃圾邮件过滤（Guzella和Caminhas 2009; Caruana和Li 2012）和入侵检测系统（Garcia-Teodoro等。 2009; Zhou et al.2010），仅举几例）。</p>\n<p>正如Arthur Samuel在他的开创性工作中所定义的那样，机器学习是开发计算技术和算法的研究，使计算机系统能够在没有明确编程的情况下获得新的能力（Samuel，1959）。数据挖掘是从大量数据中提取知识的计算过程，包括以下几个步骤：数据提取和收集，数据清理和集成，数据选择和转换，知识挖掘以及最终可视化和通信（Han et al.2011） 。机器学习算法和技术经常用于数据挖掘的过程中，用于预处理，模式识别和生成预测模型。</p>\n<p>机器学习技术可大致分为三种主要方法：（1）监督学习：学习系统基于一组标记的训练样例推断出所需的功能/模型，其中每个例子由输入数据（通常是矢量）和所需的相应输出值（标签）。 （2）无监督学习：在没有标记训练数据的情况下，学习系统的目标是识别给定数据集中的模式和结构。 （3）强化学习：学习系统通过与动态环境的交互来接受奖励和惩罚，通过训练来达到某个目标。</p>\n<h2 id=\"3-1希望和恐惧\"><a href=\"#3-1希望和恐惧\" class=\"headerlink\" title=\"3.1希望和恐惧\"></a>3.1希望和恐惧</h2><p>尽管机器学习技术在安全应用中的应用可以追溯到几十年，但近年来机器学习和数据挖掘技术的进步和能力以及它们解决许多困难应用问题的成功案例促使研究人员更加彻底调查这些技术的有效利用，以解决计算机安全和隐私领域的难题。例如，Carl Landwehr分享了他对此事的看法如下：</p>\n<blockquote>\n<p>“在他们的早期，计算机安全和人工智能似乎没有太多可说的对…安全研究人员的目的是解决他们认为防漏的计算基础设施或设计基础设施的漏洞……但是多年来，这两个地方的距离越来越近，特别是在攻击旨在模拟合法行为的地方……我们可能会想象系统会对他们处理的数据有一定程度的自我意识。反射系统（可以参考和修改自己的行为的系统）的概念起源于AI社区……想象一下，一个管道系统包含一个可以检测初期泄漏的智能管道系统。包含智能管道模拟的网络基础设施将引起极大兴趣。“Landwehr（2008）</p>\n</blockquote>\n<p>其他研究人员强调了人工智能技术在计算机安全和隐私领域获得解决复杂问题的重要作用。例如，Tyugu（2011）指出：“很明显，只有在使用人工智能方法时才能成功解决许多网络防御问题。”Heinl（2014）提出了类似的观点。</p>\n<p>另一方面，安全社区也担心使用人工智能技术。例如，尽管在基于异常的入侵检测系统的研究中发表了大量研究，但是之前的一些研究表明这些系统很少部署在入侵检测行业（Sommer和Paxson 2010）。其他研究也对网络入侵检测的异常检测范例提出了挑战（Gates和Taylor 2006）。这些研究的结果强调了这样一个事实，即在计算机安全和隐私领域有效使用AI技术并非易事，需要对这些技术的特性有充分的了解（Sommer和Paxson 2010）。为了获得最佳结果，应该定制机器学习和数据挖掘技术以适应安全问题的特征。在这件事上，莫瑞尔说：</p>\n<blockquote>\n<p>“尽管过去已经完成了一些工作，但AI并没有在当今的网络安全中发挥核心作用，网络安全并不像人工智能那样强烈追求人工智能的发展领域，而其他人…… AI技术是围绕应用程序开发的。网络安全从未成为人工智能集中的一个领域……人工智能已经取得了很多成就，并且有许多与网络安全相关的知识，许多适合网络安全的新技术可以从人工智能中的现有技术中获得启发。“Morel（ 2011）</p>\n</blockquote>\n<p>为此，应该研究针对计算机安全问题量身定制的机器学习技术。</p>\n<h2 id=\"3-2-以前工作的分类\"><a href=\"#3-2-以前工作的分类\" class=\"headerlink\" title=\"3.2 以前工作的分类\"></a>3.2 以前工作的分类</h2><p>在软件漏洞分析和发现的过程中，许多研究在前几年发表研究机器学习和数据挖掘技术的使用，我们在本文中对此进行了广泛的综述。我们将审查的工作分为四大类，总结如下，并将其区分如下：</p>\n<ul>\n<li><p>（1）基于软件度量的漏洞预测模型：大量研究利用（主要是监督的）机器学习方法构建基于众所周知的软件度量作为特征集的预测模型，然后使用该模型根据测量的软件工程指标评估软件工件的漏洞状态。</p>\n</li>\n<li><p>（2）异常检测方法：这类工作利用无监督学习方法从软件源代码中自动提取正常模型或挖掘规则，并将漏洞检测为多数正常和规则的异常行为。</p>\n</li>\n<li><p>（3）漏洞代码模式识别：这类工作利用（主要是监督的）机器学习方法从许多漏洞代码示例中提取漏洞代码段的模式，然后使用模式匹配技术来检测和定位软件中的漏洞源代码。</p>\n</li>\n<li><p>（4）杂项方法：一些值得注意的近期着作，利用AI和数据科学的技术进行软件漏洞分析和发现，这些技术不属于任何上述类别，也不构成一个连贯的类别。</p>\n</li>\n</ul>\n<p>提议分类背后的基本原理是双重的：首先，我们区分分析程序语法和语义的工作，而不区分程序语法和语义。大多数不分析程序语法和语义的工作使用软件工程指标进行漏洞预测。另一方面，在基于分析程序语法和语义的大量研究中，我们观察到两种主要方法：漏洞代码模式识别和异常检测方法。图1直观地总结了分类方案。</p>\n<p>虽然其他标准也可用于分类目的（例如：监督与非监督学习范式，不同的学习和挖掘技术，特征表示方案等），但它们不能创建先前作品的语义连贯类别。我们认为，拟议的分类结果会产生更有意义的研究家族，从而可以更好地比较各种方法，因此我们认为这是对有史以来研究的有组织调查的合适选择。</p>\n<p><img src=\"/2019/04/02/Sofware-Vulnerability-Analysis-and-Discovery-Using-Machine-Learning-and-Data-Mining-Techniques-A-Survey/1.jpg\" alt=\"\"></p>\n<h1 id=\"4基于软件度量的漏洞预测\"><a href=\"#4基于软件度量的漏洞预测\" class=\"headerlink\" title=\"4基于软件度量的漏洞预测\"></a>4基于软件度量的漏洞预测</h1><p>我们在本文中讨论的第一类方法是“漏洞预测模型”，它利用数据挖掘，机器学习和统计分析技术来预测易受攻击的软件工件（源代码文件，面向对象的类，二进制组件，等）基于通用软件工程指标。这些方法的主要思想来自于软件工程领域的软件质量和可靠性保证，其中软件测试和验证的有限资源需要一个指导模型来实现更有效的软件测试计划。为此，已经研究并在工业中使用“故障预测模型”（或“缺陷预测模型”）（Khoshgoftaar等人1997）。故障预测模型是基于从软件项目收集的历史数据训练的计算模型，并提供更可能包含故障的软件工件列表以优先考虑软件测试。历史数据基于不同的软件工程指标，例如源代码大小，复杂性，代码流失和开发人员活动指标（Kaner和Bond 2004）。根据IEEE标准软件工程术语表，术语“度量”被定义为“系统，组件或过程拥有给定属性的程度的定量度量”（1990）。在调查文章中回顾的软件工程领域的故障预测模型的主题上进行了广泛的研究和发表（Catal和Diri 2009; Malhotra 2015）。</p>\n<p>基于与故障预测模型类似的动机，在软件工程领域中提出了漏洞预测模型。检测和缓解安全漏洞需要经过安全思维培训的专家进行人工分析（Heelan 2011）;然而，软件质量和可靠性保证团队的资源有限，需要引导他们进行更有效，更有效的安全审计和测试。基于漏洞是一种特定类型的故障这一事实，已经在业界和学术界提出并研究了漏洞预测模型。与故障预测模型类似，脆弱性预测模型也基于各种软件度量建立，并且不包含程序分析方法（即，分析某些属性的程序源代码）。在下文中，我们将回顾一下这个领域的一些最新作品。</p>\n<h2 id=\"4-1最近工作总结\"><a href=\"#4-1最近工作总结\" class=\"headerlink\" title=\"4.1最近工作总结\"></a>4.1最近工作总结</h2><p>Zimmermann 等人（2010）研究了基于先前用于缺陷预测的研究中使用的经典度量来预测专有商业产品（Microsoft Windows Vista）的二进制模块中存在漏洞的可能性。作为第一个分析，他们使用Spearman的秩相关性计算度量与每个二进制的漏洞数量之间的相关性。结果表明，经典度量与漏洞数量具有统计上的显着相关性;但是，效果很小。另一项分析是评估这些指标的预测能力。作者使用二元Logistic回归分析了经典指标（流失，复杂性，覆盖，依赖和组织）的五组。模型评估采用十倍交叉验证和计算精度以及召回值。作者报告说，大多数指标预测的漏洞具有平均精度（低误报率）;然而，召回率非常低（错误的假阴性或错过的漏洞）并且覆盖率指标未能产生任何有意义的结果。结果包括精度低于67％，召回率低于21％。</p>\n<p>Meneely和Williams（2010）研究了开发者活动指标和软件漏洞之间的关系。正在研究的开发人员活动指标包括：更改源文件的不同开发人员数量，向文件提交的提交数量，以及在贡献网络中包含文件的测序路径数量。作者对三个开源软件项目进行了研究。每个研究中收集的数据集包括一个标签，表明源代码文件是否已修补，以及版本控制日志中的开发人员活动指标。使用统计相关性分析，作者报告发现每个指标与漏洞数量存在显着的显着相关性;但相关性各不相同，并不是很强。作者使用贝叶斯网络作为预测模型，通过十倍交叉验证生成训练和验证集。据作者说，分析表明开发人员活动可以用来预测脆弱的人群;然而，精确度和召回率值令人失望（精确度在12％-29％之间，召回率在32％-56％之间）。</p>\n<p>Doyle和Walden（2011）分析了2006年至2008年间14个最广泛使用的开源Web应用程序中的软件度量和漏洞之间的关系，例如WordPress和Mediawiki。作者使用静态分析工具（例如，Fortify源代码分析器，PHP CodeSni等等）来测量这些应用程序的源代码库中的各种度量，包括静态分析漏洞密度（SAVD），源代码大小，圈复杂度，嵌套复杂性，以及作者提出的另一个名为安全资源指标（SRI）的指标。为了预测，Spearman的等级相关性是在SAVD和其他指标之间计算的。结果表明，没有一个度量标准适用于区分高漏洞Web应用程序和低漏洞Web应用程序;然而，每个函数的平均圈复杂度是几个应用程序的有效预测器，特别是当与SRI分数结合使用时，将应用程序分类为高安全性和低安全性焦点应用程序。由于静态分析工具可能会产生很高的误报，作者手动审查了两个选定的Web应用程序的一个工具（Fortify SCA）的报告，其误报率为18％;得出结论认为假阳性率是可以接受的，对有效性没有威胁。</p>\n<p>Shin和Williams（2013）研究了基于复杂性和代码流失度量的传统故障预测模型是否可用于漏洞预测。为此，作者使用18个复杂度指标，5个代码流失度量标准和故障历史度量标准对Mozilla Firefox进行了实证研究。测试了几种分类技术来预测故障和脆弱的人群;作者声称所有技术的结果都相似。虽然故障源代码的数量是脆弱源数量的7倍，但故障预测模型和漏洞预测模型在漏洞预测方面表现相似;召回率约为83％，精确度约为11％。基于这些结果，作者得出结论，基于传统度量的故障预测模型也可用于脆弱性预测;然而，未来的研究需要提高精确度（减少误报），同时保持高召回率</p>\n<p>在同一作者的另一个工作中，Shin和Williams（2011）研究了使用执行复杂度指标作为软件漏洞的指标。这组作者说，这项研究背后的动机是基于安全专家的直觉，安全专家经常假设“软件复杂性是软件安全的敌人。”为此，作者对两个开源项目进行了实证案例研究，比较执行复杂性和静态复杂性指标对漏洞检测的有效性。总共，本研究收集了23个复杂度指标。作者对指标进行了判别和预测分析。对于判别分析，作者使用Welch的t检验来比较弱势文件与中性文件的度量值的均值。结果显示，其中一个项目的23个指标中有20个表现出统计上显着的判别力;但是，这仅适用于其他项目的大约一半指标，包括没有执行复杂性指标。为了评估指标的预测能力，作者使用Logistic回归进行了二元分类，并进行了十倍的交叉验证。为了解释许多指标中的冗余信息，作者基于信息增益排名执行了特征空间缩减。另一个问题是大多数（中立的人）和少数群体（弱势群体）之间的严重失衡，作者通过随机抽样多数阶层来解决这个问题。最终结果是，对于所有三组指标（代码，依赖关系，所有组合），召回率是公平的（67％-81％），但精确度令人失望（8％-12％）。总之，结果表明这些指标没有静态显着的判别力，预测能力不可靠。</p>\n<p>Shin等人（2011）对复杂性，代码流失和开发人员活动（CCD）指标是否可用于漏洞预测进行了更广泛的研究。为此，作者对两个开源项目进行了实证案例研究。本研究共分析了28个CCD软件指标，包括14个复杂度指标，3个代码流失指标和11个开发人员活动指标。为了评估指标的判别能力，作者使用了Welch的t检验，其中两个项目的28个指标中至少有24个支持检验假设。为了评估指标的预测能力，作者测试了几种分类技术，但它们只呈现了一种分类结果，因为所有技术都提供了类似的性能。为了验证模型的预测能力，作者进行了下一次发布验证，其中有几个版本可供使用，交叉验证只有一个版本可用。评估了单变量和多变量预测假设。基于从故障预测文献中找到的平均值，作者选择阈值至少为70％用于回忆，并且最多25％用于假阳性率以支持预测假设。 28个单变量模型中只有2个，以及使用基于发展历史的指标的4个多变量模型中的3个预测了两个项目的高召回率和低误报率的脆弱性。作者得出结论，与本研究中收集的代码复杂度指标相比，开发历史指标是更强的漏洞指标。</p>\n<p>Moshtari等人（2013）提到了先前关于脆弱性预测模型的研究的三个主要局限性，因此他们提出了一种新方法，通过解决先前研究的局限性，基于复杂性度量来预测软件中的脆弱位置。作者提出了一种半自动分析框架来检测软件漏洞，并将其输出用作漏洞信息，而不是报告的漏洞，作者声称这些漏洞提供了有关软件漏洞的更完整信息。与之前仅研究项目内漏洞预测的研究不同，本研究基于从开源项目收集的数据调查了项目内和项目间的漏洞预测。各种分类技术用于实验。在fle级别粒度下测量了一组11个单元复杂度度量和4个耦合度量。在Mozilla Firefox上进行的项目内预测的报告结果对于各种分类技术而言令人印象深刻（召回率高于90％，误报率低于10％）。作者声称，更完整的漏洞信息有助于这种改进，并通过将提出的方法与Shin等人之前的工作的复制进行比较来证明其声称的合理性。 （2011年）。在随机选择的五个项目版本上进行跨项目实验，其中一个项目被视为测试数据，模型在另外四个项目上进行了培训。根据报告的F2测量，跨项目预测的最佳模型实现了约70％的检测率，约26％的误报。</p>\n<p>Moshtari等人。 （2013）提到了先前关于脆弱性预测模型的研究的三个主要局限性，因此他们提出了一种新方法，通过解决先前研究的局限性，基于复杂性度量来预测软件中的脆弱位置。作者提出了一种半自动分析框架来检测软件漏洞，并将其输出用作漏洞信息，而不是报告的漏洞，作者声称这些漏洞提供了有关软件漏洞的更完整信息。与之前仅研究项目内漏洞预测的研究不同，本研究基于从开源项目收集的数据调查了项目内和项目间的漏洞预测。各种分类技术用于实验。在fle级别粒度下测量了一组11个单元复杂度度量和4个耦合度量。在Mozilla Firefox上进行的项目内预测的报告结果对于各种分类技术而言令人印象深刻（召回率高于90％，误报率低于10％）。作者声称，更完整的漏洞信息有助于这种改进，并通过将提出的方法与Shin等人之前的工作的复制进行比较来证明其声称的合理性。 （2011年）。在随机选择的五个项目版本上进行跨项目实验，其中一个项目被视为测试数据，模型在另外四个项目上进行了培训。根据报告的F2测量，跨项目预测的最佳模型实现了约70％的检测率，约26％的误报。 </p>\n<p>Meneely等人（2013）通过将Apache HTTPD Web服务器中的65个以上漏洞追溯到最初贡献易受攻击代码的版本控制提交，探讨了漏洞贡献提交（VCC）的属性。作者手动发现了124个VCC，跨越17年，他们使用统计分析技术根据代码流失和开发人员活动指标进行分析。根据这项探索性研究的结果，他们提出了几个方面：（1）代码流失度量标准与VCC在经验上相关，其方式是更大的提交可能会引入漏洞; （2）承诺更多的开发人员更有可能成为VCC; （3）由新开发商提交给来源，更有可能是VCC。</p>\n<p>Bosu等人（2014）进行了类似的实证研究，他们分析了来自10个开源项目的260,000多个代码审查请求，使用三阶段半自动化流程识别了400多个易受攻击的代码更改。他们的目标是确定漏洞代码更改的特征，并确定可能引入漏洞的开发人员的特征。一些关键的因素包括：（1）经验不足的贡献者的变化显然更有可能引入漏洞; （2）漏洞可能性随着变化的大小而增加（更多行改变）; （3）与修改后的文件相比，新文件不太可能包含漏洞。</p>\n<p>Perl等人（2015）研究了使用代码存储库中包含的元数据以及代码度量来识别漏洞贡献提交的效果。作者声称软件逐渐增长，大多数开源项目都使用版本控制系统，因此，提交是检查漏洞的自然单位。有了这个动机，作者编译了一个包含来自66个C / C ++ GitHub项目的170,860个提交的数据集，其中包括映射到相关CVE ID的640个漏洞贡献提交（VCC）。作者选择了一组代码流失和开发人员活动指标，以及来自不同范围（项目，作者，提交和文件夹）的GitHub元数据，并为收集的数据集提取这些功能。基于该数据集，作者评估了他们提出的名为VCCFinder的系统，该系统使用支持向量机（SVM）分类器来识别来自中立提交的VCC。为了评估，该系统在2010年底之前接受了数据培训，并根据2011年至2014年报告的CVE进行了测试。作者将他们提出的系统的结果与FlawFinder静态分析工具的结果进行了比较。在相同的召回水平（召回率= 24％），FlawFinder的精度仅达到1％，而VCCFinder达到60％的精度，产生的误报率要低得多。上述数据集由作者公开发表，作为对研究界的贡献。</p>\n<p>Walden等人（2014）进行了一项研究，以比较基于软件度量与文本挖掘技术预测漏洞软件组件的性能。为此，作者首先构建了一个手工策划的漏洞数据集，这些数据集来自三个大型流行的开源PHP Web应用程序（Drupal，Moodle，PhpMyAdmin），包含223个漏洞。该数据集作为贡献提供给研究界。对于基于软件度量的漏洞预测，为该研究选择了一组12个代码复杂度度量。对于文本挖掘，每个PHP源文件都是第一个标记化的，不必要的标记被删除或转换（注释，标点符号，字符串和数字文字等），并计算最终标记的频率。众所周知的“词袋”技术用于从每个PHP源文本的文本标记构造数字特征向量。基于先前的漏洞预测研究经验，作者选择随机森林模型作为主要分类算法。对于模型评估，作者使用分层三重交叉验证。作者还通过对多数类（非易受攻击代码）执行随机欠采样来解决不平衡类数据的问题。根据作者的各种实验，基于文本挖掘的预测技术平均表现更好（即，更高的召回率和精确度），并且差异在统计上是显着的。作者还测试了跨项目漏洞预测，但两种方法的跨项目预测性能普遍较差。由于作者没有考虑应用程序之间数据的不均等分布，因此预计跨项目预测表现不佳。</p>\n<p>Morrison等人（2015）指出，虽然微软团队采用了缺陷预测模型，但漏洞预测模型（VPM）并非如此。为了解释这种差异，作者尝试复制Zimmermann等人提出的VPM。 （2010）有两个较新版本的Microsoft Windows操作系统。作者将二进制水平预测精度提高了约75％，并且召回率约为20％;然而，二进制文件通常对于实际检查来说非常大，并且工程师首选源级别预测。因此，作者为源流水平粒度建立了相同的模型，其精度低于50％，召回率低于20％。基于这些结果，作者得出结论：“必须通过安全特定指标来”重新调整VPM以实现可操作的性能。“</p>\n<p>Younis等人。 （2016）尝试识别包含更可能被利用的漏洞的代码的属性。为此，作者收集了来自Linux内核和Apache HTTPD Web服务器项目的183个漏洞，其中包括82个可利用的漏洞。作者从四个不同的类别中选择八个软件度量来表征这些漏洞，并使用Welch的t检验来检验每个度量的判别力。指标的判别力的结果是混合的;一些指标在统计上具有显着的判别力，而其他指标则没有。作者还研究了是否存在可用作可利用漏洞预测因子的指标组合，其中测试了三种不同的特征选择方法和四种不同的分类算法。表现最佳的模型是具有包装子集选择方法的随机森林分类，其实现了84％的F-度量。</p>\n<h2 id=\"4-2讨论\"><a href=\"#4-2讨论\" class=\"headerlink\" title=\"4.2讨论\"></a>4.2讨论</h2><p>在前一小节中，我们回顾了基于软件度量的脆弱性预测模型的最新研究。表1列出了本节所述所有文章的摘要，其中我们指定了每项工作的主要差异因素。</p>\n<p><img src=\"/2019/04/02/Sofware-Vulnerability-Analysis-and-Discovery-Using-Machine-Learning-and-Data-Mining-Techniques-A-Survey/2.jpg\" alt=\"\"></p>\n<p>人们可能会质疑基于软件工程指标来预测软件漏洞存在的基本决策，作为混淆症状和原因的一个例子（Zeller etal. 2011 ）。一些研究（例如，Walden等人（2014）强调了这种批评，这些研究表明，与基于某些软件度量的脆弱性预测模型相比，软件源代码的基本文本挖掘可以在预测性能方面产生更好的结果;尽管如此，这种实证研究不能推广到所有软件项目和所有软件指标。另一方面，Tang等人最近的一项研究（2015）批评了Walden等人的结论（2014），因为他们没有考虑影响代码检查的单个组件的大小;因此，他们比较了这两种预测模型在易受影响的漏洞预测背景下的预测能力，并得出结论，这两种指标的表现相似。</p>\n<p>使用软件度量进行漏洞预测的一个理由是，这些度量标准通常很容易获得，或者很容易在软件工程项目中获得。此外，软件故障/缺陷预测模型已经在一些软件项目中使用，而构建漏洞预测模型不需要额外的专业知识。另一方面，这些系统的目的是仅作为更好地规划和分配软件工程团队资源的指导模型。因此，基于软件度量的漏洞预测模型是工业界和学术界的一系列研究。</p>\n<p>基于上面回顾的上述工作，很明显，基于软件指标的漏洞预测模型尚未成熟。从以往研究的回顾中可以得出一些结论，包括挑战和可能的未来工作： </p>\n<ul>\n<li><p>脆弱性预测模型的统计挑战是由数据集中的漏洞很少而且稀疏的事实引入的。在数据挖掘和机器学习的过程中，这个问题被称为不平衡类数据，它可以极大地阻碍机器学习算法的性能，并且有解决该问题的实践（Domingos 2012）。本节中回顾的一些先前的工作已经解决了不平衡类数据问题，并且对大多数类进行了随机欠采样。这是一个重要的问题，任何利用机器学习和数据挖掘技术的研究都不应忽视这一问题。</p>\n<ul>\n<li>与之前的大多数研究相比，Moshtari等人（2013）使用半自动化框架进行漏洞检测，他们使用这种框架代替通过公共咨询和漏洞数据库（例如NVD）提供的信息。与之前的作品相比，他们获得了显着更高的召回率和精确度值（即使在跨项目设置中）。这可能是一种很有前景的方法，未来的研究也可以用来收集更完整的漏洞信息并获得更好的结果。</li>\n<li>漏洞预测模型领域中的跨项目研究很少，因此是未来工作的一个领域。特别是与缺陷预测模型相比，跨项目漏洞预测的研究非常不足。跨项目预测引入了额外的挑战，这些挑战源于训练和测试集中的数据分布可能显着变化并且阻碍传统机器学习和统计分析技术的性能。这一挑战在机器学习研究中被称为“归纳转移”（或“转移学习”）技术（Pan and Yang 2010），它们的使用已经在软件缺陷预测研究中得到了研究（Ma et al.2012 ; Nam et al.2013）。这些研究可以成为未来跨项目脆弱性预测模型研究的基础。</li>\n<li>基于软件指标的漏洞预测研究中的大多数研究报告结果不佳。一个可能的结论是传统的软件度量标准不适合软件漏洞。 Morrison等人明确讨论了这一结论（2015年）。从此以后，确定安全特定指标，例如Doyle和Walden（2011）提出的安全资源指标（SRI）是未来研究的另一个领域。</li>\n<li>这个领域的未知领域正在使用深度学习方法进行漏洞预测。深度学习是机器学习研究中新出现的一个主题，它在几个应用领域取得了巨大成就，并且越来越受到研究人员和从业者的关注（LeCun等人，2015）。Yang等人（2015）提出了一项关于应用深度学习方法进行即时软件缺陷预测的研究。这是脆弱性预测模型的未来研究的另一个有希望的领域。</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"5异常检测方法\"><a href=\"#5异常检测方法\" class=\"headerlink\" title=\"5异常检测方法\"></a>5异常检测方法</h1><p>在本节中，我们将回顾一类使用机器学习和数据挖掘技术进行软件漏洞分析和发现的异常检测方法。异常检测是指数据中的模式不符合正常和预期行为的问题;通常被称为anomalies或outliers（Chandola等，2009）。在许多不同的研究领域和应用领域中已经广泛研究了这个问题;包括软件缺陷和漏洞发现领域。</p>\n<p>在软件质量保证的背景下，异常检测方法旨在通过使源代码中的位置不符合应用程序编程接口（API）的通常或预期代码模式来识别软件缺陷。这种API使用模式的简单示例是malloc和free的函数调用对，或者lock和unlock。除了这些简单的众所周知的模式之外，每个API都有自己的规则和模式份额，这些规则和模式也很复杂，而且记录不完善。不符合API的预期规则和使用模式可能导致软件缺陷，也可能导致软件漏洞。</p>\n<p>异常检测方法应用于软件质量保证的另一个领域是检测被忽视的条件或缺少检查。缺少检查是许多软件缺陷和漏洞的根源。这些检查可大致分为两类：（1）正确使用API所需的检查; （2）检查实现程序逻辑。这两种类型都可能导致软件缺陷或软件漏洞。第一种类型的示例是检查用作API函数调用的参数的输入数据的正确类型或值。缺少这样的检查可能导致软件崩溃，未定义或不期望的行为（例如，除以零）。失败也可能产生安全后果（例如，流量溢出，SQL注入等）。在访问资源对象时，缺少第二种类型的示例来检查主题的权限或权限。同样，这些逻辑缺陷可能具有安全性后果，从而导致安全逻辑漏洞（例如，机密性和完整性访问控制）。</p>\n<p>已经提出异常检测方法用于检测不正确的API使用模式和丢失检查。这些方法的一个重要方面是自动提取正常行为，换句话说，自动提取规范，规则和模式，然后将其用作检测异常行为的基础。自动提取正常行为对于这些方法的适用性和成功性至关重要，而如果人类用户提供正常行为或规范，则会极大地妨碍该方法的效率，因为：（1）编写规范是艰巨而乏味的任务; （2）人为错误可导致不准确的指定，导致不正确的结果。</p>\n<p>在下文中，我们按时间顺序回顾和总结以前的工作，从过去十年的早期工作开始，到近年来在软件缺陷和漏洞检测的异常检测方法中的最新工作。请注意，一些经过审核的工作侧重于安全漏洞，而其他漏洞则没有;但我们仍在审查这些工作，因为所提出的方法并非专门针对非安全性缺陷。</p>\n<h2 id=\"5-1-最近工作总结\"><a href=\"#5-1-最近工作总结\" class=\"headerlink\" title=\"5.1 最近工作总结\"></a>5.1 最近工作总结</h2><p>已经提出异常检测方法用于检测不正确的API使用模式和丢失检查。这些方法的一个重要方面是自动提取正常行为，换句话说，自动提取规范，规则和模式，然后将其用作检测异常行为的基础。自动提取正常行为对于这些方法的适用性和成功性至关重要，而如果人类用户提供正常行为或规范，则会极大地妨碍该方法的效率，因为：（1）编写规范是艰巨而乏味的任务; （2）人为错误可导致不准确的指定，导致不正确的结果。</p>\n<p>在下文中，我们按时间顺序回顾和总结以前的工作，从过去十年的早期工作开始，到近年来在软件缺陷和漏洞检测的异常检测方法中的最新工作。请注意，一些经过审核的工作侧重于安全漏洞，而其他漏洞则没有;但我们仍在审查这些工作，因为所提出的方法并非专门针对非安全性缺陷。</p>\n<p>Engler 等人（2001）指出，解决程序错误的一个主要障碍是知道系统必须遵守的正确性规则，这些规则通常是无证的或以临时方式指定的。为了解决这个问题，他们演示了一种自动提取程序源代码隐含的程序员beliefs的技术。为此，他们讨论了错误作为异常行为的概念，并提出了一种方法，通过为源代码定制“规则模板”来提取程序员的beliefs（例如，规则模板“<a>必须与之配对的函数调用 <b>“）。提取了两种类型的规则：（1）Must-beliefs 和（2）May-beliefs。Must-beliefs 是某些众所周知的编程规则（例如，“指针解引用意味着程序员必须相信指针是非空的”）。 May-belief是一些代码特征表明beliefs的情况，但可能是巧合。为了区分有效的May-beliefs 和巧合，使用称为Z-排名的统计分析技术来发现这些beliefs的违规（或错误），以对错误进行排序和分类。为了评估，作者检查了复杂软件系统上的各种规则模板，例如Linux和OpenBSD项目。结果显示不同情景下的假阳性率不同，从4％到57％不等。作者还使用众所周知的安全漏洞规则测试安全检查程序，导致Linux和OpenBSD中出现35个安全漏洞。</b></a></p>\n<p>Livshits和Zimmermann（2005）提出了一个名为DynaMine的工具，它根据高度相关的方法调用分析修订历史中的源代码校验，以自动提取特定于应用程序的编码模式。 DynaMine分析增量变化，这有助于实现更精确的结果。所提出的方法首先预处理已插入的方法调用的软件修订历史，并将该信息存储在要挖掘的数据库中。挖掘方法基于经典先验算法的修改版本，其使用一组项目作为其输入并且在项目之间产生频繁的项目集和强关联规则。这些修改改进了算法的运行时间，并允许该方法进行扩展以分析大型软件系统。此外，作者将几种排名策略应用于算法挖掘的模式。提取的模式被呈现给用户以进行评估。在用户选择模式之后，使用动态分析工具进一步验证所选模式并检测违规。该方法在两个大型Java项目上进行了评估。据作者称，拟议的挖掘方法发现了56种以前未知的，高度应用程序特定的模式。根据实验结果，56个（57％）模式中有32个在运行时被击中，其中32个（66％）模式中的21个被认为是非常有效的模式。此外，发现超过260种模式违规，但作者没有评估假阳性率。</p>\n<p>Li和Zhou（2005）断言程序通常遵循许多隐式和未记录的编程规则，这些规则违反了这些规则，不知情的程序员很容易引入缺陷。作者提出了一种名为PR-Miner的方法，用于从大型源代码中提取隐式编程规则，而无需事先了解软件，也不需要程序员的大量工作。 PRMiner旨在以一般形式（没有fxed模板）提取编程规则，包含不同类型的多个元素，如函数，变量和数据类型。总之，PR-Miner首先解析和预处理程序源代码，删除不必要的元素，如关键字，常量数据值等，并根据数据将结构中的函数和数据中的局部变量重命名为相似的名称类型。在预处理之后，所有程序元素被散列为数字，并且函数定义被映射到函数内的所有元素的一组数字散列值，作为行插入到项集数据库中。使用频繁项集挖掘算法（即FPclose）挖掘该数据库，以找出一起出现的频繁程序元素。这些频繁的程序元素集称为编程模式。有效的规则生成算法用于从频繁的编程模式中提取编程规则。编程规则用于检测违规，这是基于在大多数情况下通常遵循编程规则并且很少发生违规的想法。对三个大型开源项目进行评估。结果表明，PR-Miner在这些软件项目中发现了数以千计的规则，作者无法对所有这些规则进行验证，只讨论了一些样本。 PR-Miner还报告了许多违规行为，作者设法仅手动评估前60位报告，揭示假阳性率很高（73％-90％之间）。</p>\n<p>Wasylkowski等（2007）重申这样一个事实，即与对象交互通常需要遵循模型或协议，这些模型或协议并不总是记录在案，并且违规可能导致缺陷。为了自动提取典型的对象使用模型，作者提出了在程序源代码中挖掘方法调用的序列，然后将其用作偏差作为缺陷候选者。首先，从Java字节码中提取对象使用模型，Java字节码是具有匿名状态的fnite状态自动机，以及作为状态转换的可行方法调用。使用每个单一方法的过程内静态分析来提取该模型。然后，使用对封闭模式的频繁项集挖掘，从使用模型中挖掘方法调用的时间属性（例如，“方法next（）可以在hasNext（）之前”）。这些频繁的模式表示正常的对象使用，并用于训练分类器以识别对这些模式的违反，这些模式被视为可能的缺陷位置。此外，作者还引入了一个缺陷指标，该指标根据几个因素对异常进行排序。提出的方法是作为一个名为JADET（用于Java异常检测器）的工具实现的。评估是在fve流行的开源Java程序上进行的。根据报告的结果，在所有5个项目中JADET检测到的前77个异常中，有40个（52％）误报，5个缺陷，5个代码smells和27个提示。</p>\n<p>Acharya等（2007）指出以前的方法无法在API使用模式中捕获一些有用的排序信息，特别是当跨不同的进程涉及多个API时。作者提出了一种从API客户端代码中提取“频繁部分规则”的自动方法。该方法包括四个主要步骤，并基于一些名为MAPO的作者的先前工作（Xie和Pei 2006）。在第一步中，采用下推模型检查（PDMC）过程来提取与API相关的进程间控制流敏感的静态迹线。在第二步中，在给定的跟踪上使用算法来分离不同的使用场景，因此可以单独挖掘每个场景。在第三步中，名为FRECPO的方法用于从每个静态执行跟踪中提取的一组场景中挖掘“频繁闭合的部分规则”（FCPO）。 FCPO可能不是通用模式，只能针对分析的客户端代码进行指定。为了解决这个问题，引入了一个名为Mine-Verify的算法，该算法使用两个随机拆分的不相交的客户端集来验证模式。为了评估，该框架应用于X11 UNIX窗口系统的72个客户端程序。对于每个实验，随机选择36个客户作为挖掘客户端，其余36个客户端用作验证客户端。作者没有对他们的实验结果进行评估，而是仅对一个例子进行评估;为此，通过该方法成功检测到6种已知模式中的5种，并且仅报告了一种错误模式。</p>\n<p>Chang等 （2008）通过对Firefox项目的版本1.0和1.5中的bug fxes进行初步研究，强调忽略条件作为一种难以解决的缺陷类别的重要性，该项目显示167个选定的错误中有109个（65％）涉及一个或多个被忽视的条件。为此，作者提出了一种方法，将数据挖掘技术与静态程序分析相结合，以提取代码库中的隐式条件规则，并将被忽视的条件作为规则违规进行检测。因此，程序由“系统依赖图（SDG）”表示，作为修改的“过程依赖图（PDG）”的集合，称为“增强PDG”（EPDG）。 EPDG增加了所谓的“共享数据依赖边缘”（SDDE），它链接在控制流路径中使用相同变量定义的程序元素。潜在规则由EPDG minors代表，可以将其视为EPDG的子图，其中一些路径已经收缩到边缘。 “启发式最大频繁子图挖掘（HMFSM）”算法用于在EPDG子图的“近传递闭包（NTC）”的数据库中找到重复的图minors。在提取和确认有效规则之后，使用启发式图匹配算法搜索NTC图数据库的规则违反（忽略条件）。为了评估，作者通过在四个开源项目中应用该方法进行了实验。在所有四个项目中，该方法检测到超过1200个候选规则，平均不到25％的检测规则无效（没有语义意义）。启发式图匹配算法在fnding规则实例中完全成功，具有100％的精度，但违规检测的结果并不令人印象深刻，其中所有四个项目中79％的报告违规都是误报。作者声称“大约一半的误报是由语义上等同的陈述给出了不同的标签”，并提出了改善未来工作情况的一些建议。</p>\n<p>Thummalapenta和Xie（2009）提出了一种新方法来降低自动挖掘编程规则的误报率。为此，他们引入了“替代模式”的概念，其中API调用的各种频繁模式被一起考虑。例如，替代模式可以是P1或P2形式，其中P1和P2都是频繁的，P2是P1的语义替代。误报的另一个原因是不平衡的替代模式，其中P1和P2是语义上有效的替代方案，但P1是高频率的，而P2在整个代码库中并不常见。这些不平衡的替代方案表示为“P1或P2”，使用传统的挖掘技术更具挑战性。提出了一种称为“Alattin”的方法，其包括称为“ImMiner”的新挖掘算法，其使用迭代挖掘策略来挖掘平衡和不平衡模式以及用于检测被忽略条件的技术。首先，Alattin在源代码中提取重用的API，并将它们提供给代码搜索引擎以收集其他相关的代码示例。在收集的数据库上执行频繁的项集挖掘以提取频繁的模式。然后，对于每个频繁模式，输入数据库被分成两个负数据库和正数据库，其中否定数据库包括不符合模式的所有模式候选者，而肯定数据库包括所有符合候选者。频繁的项目集挖掘再次应用于否定数据库以构建不平衡的替代模式。然后使用这些挖掘的模式来检测方法调用站点处的违规。为了检测被忽略的条件，Alattin提取围绕API调用站点的所有条件检查。由于每个挖掘模式都包含多个备选方案，因此只有在呼叫站点不满足任何备选方案时，Alattin才会报告违规行为。出于评估的目的，对6个Java库执行了经验实验，其中总共144个模式被挖掘，运行时间约为1小时。作者手动评估了144种模式中的90种，其中75种（83％）是真实规则，7种是部分规则，8种（9％）是错误规则。与类似方法相比，对相同文库进行违规检测的实验导致假阳性减少28％。</p>\n<p>Gruska等（2010）研究了跨项目异常检测的可能性。为此，作者引入了一种轻量级，与语言无关的解析器，适用于分析用几种语言编写的程序，语法类似（包括C，C ++，Java和PHP）。由于所提出的方法基于程序结构和函数调用，因此可以忽略源代码中存在的许多细节，并且解析器仅解析源代码的选定部分;这就是使解析器轻量级和语言无关的原因。解析过程包括几个步骤，包括创建令牌，识别结构和提取函数调用。类似于抽象语法树（AST）的专门设计的通用抽象表示用于存储由解析器提取的信息。抽象表示用于创建函数模型，这些函数模型是有限状态机，其中状态表示代码中的位置，转换是函数调用。此模型用于在特定函数中提取所有可能的函数调用序列以及其他相关信息，例如被调用函数的名称，参数数量，参数，返回值和目标。然后，将每个函数模型转换为一组时间属性，表示函数调用之间的值的流动。这是通过使用作者之前的工作中的JADET工具来实现的（Wasylkowski等人，2007）。扩展JADET工具以支持上述模型，并用于从功能模型中挖掘频繁的时间属性。概念分析方法用于异常检测，类似于JADET工具中使用的方法。最后，在呈现给用户之前对检测到的异常进行排序和过滤。为了进行评估，开发了6000多个开源Linux项目，以提取1600万个临时属性，反映正常的API使用情况。作者从分布中随机选择了20个项目，并应用了异常检测。从总共138个检测到的异常中，只有前25％是由作者手动评估的，这导致仅4个缺陷，7个代码异味和39个（78％）误报。作者还将其分析系统作为基于网络的服务提供给checkmycode.org，该服务目前已停止服务，截至2011年底。</p>\n<p>Yamaguchi等人 （2013）提出了一个名为Chucky的系统，用于自动检测源代码中的缺失检查，旨在协助手动代码审计。 Chucky将机器学习技术与静态程序分析相结合，以确定缺失的检查。作者在源代码中区分了两种类型的安全检查：（1）检查实现安全逻辑（例如，访问控制）; （2）检查确保安全的API使用（例如，检查大小）。 Chucky采用了一个五步程序，为审核员选择的每个源和接收器执行。分析从基于岛语法的强大解析开始，其中为每个函数定义提取条件，赋值和API符号。其次，基于函数中API符号的相似性，使用最近邻和词袋技术来执行邻域发现。第三，执行轻量污染以仅确定与目标源或接收器相关联的那些检查。第四，基于受污染的条件将所有函数及其邻居嵌入向量空间中。最后，通过首先计算所有嵌入相邻向量的质心作为正态性模型来执行异常检测，然后基于其向量与其邻域的正常模型的距离计算每个函数的异常分数。基于异常分数对最终结果进行排序并呈现给用户。进行定性和定量评估以证明该方法的有效性，他们分析了几个开源项目代码中缺失的检查。作者报告说，Chucky在所有项目中都发现了几张丢失的支票，其中几乎所有前10名都报告了每项功能的异常，其中包含缺陷或安全漏洞。此外，在本研究过程中还使用Chucky发现了12个先前未知的漏洞（即0-day）。</p>\n<h2 id=\"5-2-讨论\"><a href=\"#5-2-讨论\" class=\"headerlink\" title=\"5.2 讨论\"></a>5.2 讨论</h2><p>在上一小节中，我们回顾并总结了异常检测领域的一些研究，以发现软件缺陷和漏洞为异常行为。表2中还列出了本节中所有文章的概览，其中我们指定了每项工作的主要差异因素。</p>\n<p><img src=\"/2019/04/02/Sofware-Vulnerability-Analysis-and-Discovery-Using-Machine-Learning-and-Data-Mining-Techniques-A-Survey/3.jpg\" alt=\"\"></p>\n<p>如前所述，异常检测方法可用于解决由于API使用不当导致的技术软件漏洞，以及由于忽略条件或缺少检查而导致的逻辑漏洞。需要注意的一个重要事实是，此过程可以由工具自动执行，而无需指定安全策略或安全性规范。我们认为，这是异常检测方法最有希望的方面。但是，软件缺陷和漏洞发现的异常检测方法存在局限性：</p>\n<ul>\n<li>异常检测方法仅适用于成熟的软件系统。此限制是因为基本假设缺少检查或不正确的API使用是罕见事件，并且应用于安全对象的大多数条件以及软件项目中的API使用都是正确的。这种假设在成熟的软件项目中主要适用。</li>\n<li>在代码库中必须经常进行条件检查或API使用，以便通过挖掘算法将其检测为模式。罕见的检查或API使用不太可能作为模式被挖掘，因此无法检测到偏差。所有利用频繁项集挖掘方法的工作都受此限制（例如，Li和Zhou（2005），Wasylkowski等（2007年），和Gruska等人（2010））。</li>\n<li><p>有时，异常检测方法无法指定缺陷或漏洞的类型，因为这些方法只能说明给定代码不符合任何正常规则或模式，并且可能违反任何规则或模式。当然，可能存在实例明显违反单个规则或模式而不是任何其他实例的情况，在这种情况下，系统可以指定缺陷的类型甚至修复。</p>\n</li>\n<li><p>先前方法的高假阳性率表明这些系统尚不可靠，输出需要仔细的人工审核，这限制了异常检测系统的可用性。从高假阳性率中得到的一些值得注意的工作包括（Li和Zhou 2005; Wasylkowski等人2007; Chang等人2008）。</p>\n</li>\n</ul>\n<p>异常检测方法的局限性并不仅限于软件缺陷和漏洞发现领域，许多其他应用领域也存在这些缺点。异常检测范式在网络入侵检测领域受到挑战;例如盖茨和泰勒（Gates and Taylor，2006）提出了一个具有挑衅性的讨论，他们质疑研究人员通常做出的一些假设。Sommer和Paxson（2010）还提供了关于采用异常检测方法进行网络入侵检测的挑战的讨论。 Chandola等人提供了关于不同应用领域中异常检测系统的挑战和不同方面的更一般性讨论（2009年）。</p>\n<p>很明显，在使用异常检测的漏洞发现方面仍有进一步发展的空间。从先前研究的回顾中得出的一些可能的未来工作如下： </p>\n<ul>\n<li><p>先前关于缺陷和脆弱性发现的异常检测的工作中的普遍问题是高假阳性率。分析工具输出中的高误报率使其用户压倒无效。通过降低假阳性率来提高准确性对于未来的工作非常重要。 Thummalapenta和Xie（2009）的工作是这方面研究的一个例子，它提供了有趣的贡献。</p>\n<ul>\n<li>像Chucky（Yamaguchi等人，2013）这样以安全为重点的方法存在的一个问题是无法区分安全相关的异常（漏洞异常）和非漏洞的异常。这些方法可以成功地解决缺少检查和不正确的API使用缺陷，但并非所有这些缺陷都是安全漏洞。未来的工作可以提出新方法来帮助区分缺陷和安全漏洞，使结果与安全分析师更相关并提高可用性。</li>\n<li>Graphs是丰富的表示，广泛用于程序分析，软件测试和软件漏洞发现领域。 Chang等（2008）研究了使用图挖掘和图匹配技术来发现软件中的缺失检查缺陷。如前所述，这项工作在提取规则和匹配实例方面取得了可喜的成果，但却产生了很高的误报率。最近的一项调查由Akoglu等人发表（2015），回顾了基于图的异常检测和描述的最新进展。在未来的工作中可以进一步研究用于漏洞发现的基于图的异常检测领域。</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"6漏洞代码模式识别\"><a href=\"#6漏洞代码模式识别\" class=\"headerlink\" title=\"6漏洞代码模式识别\"></a>6漏洞代码模式识别</h1><h2 id=\"6-1最近工作总结\"><a href=\"#6-1最近工作总结\" class=\"headerlink\" title=\"6.1最近工作总结\"></a>6.1最近工作总结</h2><h2 id=\"6-2讨论\"><a href=\"#6-2讨论\" class=\"headerlink\" title=\"6.2讨论\"></a>6.2讨论</h2><h1 id=\"7其他方法\"><a href=\"#7其他方法\" class=\"headerlink\" title=\"7其他方法\"></a>7其他方法</h1><h1 id=\"8应用技术分析\"><a href=\"#8应用技术分析\" class=\"headerlink\" title=\"8应用技术分析\"></a>8应用技术分析</h1><h2 id=\"8-1特征工程和表示\"><a href=\"#8-1特征工程和表示\" class=\"headerlink\" title=\"8.1特征工程和表示\"></a>8.1特征工程和表示</h2><h2 id=\"8-2模型构建\"><a href=\"#8-2模型构建\" class=\"headerlink\" title=\"8.2模型构建\"></a>8.2模型构建</h2><h2 id=\"8-3模型评估\"><a href=\"#8-3模型评估\" class=\"headerlink\" title=\"8.3模型评估\"></a>8.3模型评估</h2><h1 id=\"9结论和未来工作\"><a href=\"#9结论和未来工作\" class=\"headerlink\" title=\"9结论和未来工作\"></a>9结论和未来工作</h1>","categories":[{"name":"论文","slug":"论文","permalink":"http://yama0xff.com/categories/论文/"},{"name":"数据挖掘","slug":"论文/数据挖掘","permalink":"http://yama0xff.com/categories/论文/数据挖掘/"},{"name":"综述","slug":"论文/数据挖掘/综述","permalink":"http://yama0xff.com/categories/论文/数据挖掘/综述/"}],"tags":[{"name":"综述","slug":"综述","permalink":"http://yama0xff.com/tags/综述/"},{"name":"2017年","slug":"2017年","permalink":"http://yama0xff.com/tags/2017年/"},{"name":"数据挖掘","slug":"数据挖掘","permalink":"http://yama0xff.com/tags/数据挖掘/"}]},{"title":"A Survey on Source Code Review Using Machine Learning","date":"2019-04-02T12:14:25.000Z","path":"2019/04/02/A-Survey-on-Source-Code-Review-Using-Machine-Learning/","text":"Abstract源代码审查充分限制了软件系统的安全性。可伸缩性和精度对于代码审查工具的部署非常重要。但是，传统工具只能通过繁琐的大规模源代码审查来自动检测一些高误报和漏报的安全漏洞。各种脆弱点和漏洞在源代码中显示出特定的特征。机器学习系统建立了源代码的特征矩阵作为输入，包括变量，函数和文件，通过区分或生成方法生成ad-hoc标签，以自动和智能地查看源代码。无论编程语言如何，源代码本质上都是文本信息。安全和易受攻击的函数都可以从源代码凸出。幸运的是，已经开发了各种机器学习方法来学习和检测智能源代码安全审查中的脆弱点和漏洞。代码语义和句法特征的组合有助于在源代码审查期间对假阳性和假阴性的优化。在本文中，我们使用机器学习方法对与智能源代码安全性审查相关的文献进行了回顾。它说明了在源代码安全审查中接近ML的主要证据。我们相信机器学习及其分支机构将在源代码审查中脱颖而出。 relevant information 作者 Wang Xiaomeng, Zhang Tao, Xin Wei,Hou Changyu 单位 China Information Technology Security Evaluation Center Beijing, China;China anhua technology Limited company Beijing, China 出处 2018 3rd International Conference on Information Systems Engineering 原文地址 https://ieeexplore.ieee.org/document/8614720 源码地址 发表时间 2018年 I. 介绍​ 本文介绍了机器学习（ML）在源代码审查中文献综述的研究成果。代码审查目标是发现错误，安全漏洞和违反程序规范。代码错误，弱点或漏洞在软件中很普遍，并且可能导致各种安全问题，包括死锁，信息泄露或系统崩溃，更严重的是，一些黑客攻击[1]。WannaCry勒索软件攻击是2017年5月WannaCry勒索软件发起的全球网络攻击[2]。该攻击于2017年5月12日星期五开始[3] [4]，据报道，在一天之内，已有150多个国家的230,000多台计算机受到感染。 [5] [6]英国国家健康服务（NHS）的部分地区受到感染，导致其在袭击期间仅在紧急情况下运行一些服务，西班牙的TelefónicaFedEx和Deutsche Bahn以及许多其他世界各国和公司[7]。中国的一些Windows操作系统已经被感染，而校园网用户已经是第一个遭受严重破坏的用户。大量的实验室数据和毕业设计已被锁定。一些大型企业的应用系统和数据库文件在加密后无法正常运行。这些袭击威胁到企业，政府和消费者，随着黑客犯罪对全球经济的年度成本增加，费率和成本也在增加。2017年，估计全球安全市场将超过1200亿[1]。因此，检测到更早的漏洞或错误，软件系统将更好。作为软件安全保护最重要的部分之一，源代码审查已经服务了数十年，并且已经通过ML和数据挖掘将更多智能方法植入到挖掘代码漏洞中。 ​ 在过去的十年中，ML在代码审查中得以蓬勃发展[8] [9] [10] [11]。本文描述和讨论了ML算法和应用的最新技术。机器学习已经在源代码安全任务中得到应用，例如代码推荐，源代码错误检测和代码检索。传统的机器学习系统利用手动特征工程来进行代码错误检测，这是标签只能临时的用于特定项目。随着机器学习的核心扩展，深度学习方法能够通过很少的手动操作捕获复杂的自下而上功能。深度学习可以智能地提取错误的代码特征，将程序特征与查询的特征匹配，并预测下一个可能代码的概率[1]。源代码最终是文本信息，主要涉及深度学习中的自然语言（NLP）研究。不幸的是，考虑到编程语言和自然语言之间的结构差异，现有的NLP算法对于代码表示是不合适的。为了提取适用的特征表示，需要整理现有方案和改进策略的缺陷[12]。 ​ 在本文中，我们从以下几个方面对源代码审查进行了详尽的概述：第二节简要介绍了经典的源代码分析(SCA)，包括典型的验证方法和进程流程。第三节说明了现有的机器学习SCA方法，如传统的机器学习方法和深度学习应用在源代码审查中。第四部分总结了整篇论文的一些结论，说明了存在的问题，并展示了一些未来的工作，并承认了本文的贡献者。 II 经典的静态代码分析​ 静态代码分析（SCA）通常作为代码审查的一部分执行，并在安全开发生命周期（SDL）的实施阶段执行。 SCA的程序。 SCA通常是指通过使用数据流分析，污点分析，符号执行等技术的工具来试图发现“静态”（非运行）源代码中可能存在的漏洞。​ 假阳性和假阴性揭示了SCA的局限性。在分析与闭源组件或外部系统交互的应用程序时，可能会报告误报结果，因为如果没有源代码，则无法跟踪外部系统中的数据流，从而确保数据的完整性和安全性。静态代码分析工具的使用也可能由于工具不会报告漏洞导致漏报。如果在外部组件中发现新漏洞，或者分析工具不了解运行时环境以及是否已安全配置，则可能会发生这种情况。​ 以前的工作已经证明，经典SCA能够预测源代码漏洞，尽管有时会出现不可接受的误报和漏报。最近，人工智能，尤其是机器学习及其相关分支，对SCA的学术对话产生了重大影响，下一部分将对此进行研究。 图1.经典SCA的草图。从易受攻击的代码中提取的功能揭示了漏洞规则。模型构建有助于对程序进行建模。经典SCA探索数据流，符号执行，污点分析，模型检查和定理证明来审查源代码。审核结果需要通过认证和分类。最终，建立了漏洞收集。 III 机器学习SCA​ 在过去十年中，ML在基于特征表示的智能代码审查中蓬勃发展。 ML任务可以分为传统的机器学习，深度学习和强化学习，如图2所示。传统的机器学习包括监督学习和无监督学习。对于监督学习，计算机将显示示例输入及其所需标签，目标是学习将输入映射到输出的一般规则或功能。然而，对于无监督学习，没有给学习算法赋予标签，使其自己在其输入中找到结构。无监督学习可以是特征学习过程。 ​ 深度学习使用多层非线性处理单元级联进行特征提取和转换[13]。每个连续层使用前一层的输出作为输入，以有监督和/或无监督的方式学习，学习对应于不同抽象级别的多个级别的表示，并利用某种形式的梯度下降通过反向传播进行训练[14] 。它们还可以包括在深度生成模型中逐层组织的潜在变量，例如Deep Belief Networks 和Deep Boltzmann Machines 中的节点。相比之下，强化学习似乎更加智能，计算机程序与必须执行某个目标的动态环境相互作用。该程序在奖励和惩罚方面提供反馈，因为它在问题空间中导航。这些输入来自在线或离线源代码存档。 图2.源代码在ML，DL和RL的审查项目中占主导地位。数据集和知识库管理ML和DL中静态分析的数据空间。虽然提取预处理和特征表示表面和潜在特征作为ML和DL训练的输入。 DL采用复杂的多层结构，如深度神经网络，与ML中的不同，利用简单的神经网络。 ML和DL都生成一个模型来预测它所属的输入源代码片。 RL提出了一些区别。源代码在预处理和特征表示中组装。结果输出到RL闭环，通过奖励和状态在环境行动的条件下实现目标。环境向知识库提供反馈，直到实现目标 A.传统机器学习SCA​ Internet上有各种源代码存档。这些档案通常由应用程序类别和各种编程语言组成。但是，手动组织源代码存储库并不是一件容易的事，因为它们会迅速增长到非常大的规模。用于归档源代码自动分类的机器学习方法被演示为11个应用主题和10种编程语言。对于局部分类，近年来来自Ibiblio和Sourceforge档案的C和C ++程序主导了研究。支持向量机（SVM）分类器在给定编程语言或特定类别的程序的示例上进行训练。源代码可以准确地自动分类为主题类别，并且可以被识别为特定的编程语言。群集假设和信息理论的基本假设被用来发现软件系统中语义连贯的主题[15]。生成主题的有用性通过人工判断凭经验验证。此外，一个案例研究表明，报告了在分析代码演变时所提出的方法的操作。与传统的主题建模技术相比，这种提出的方法产生了稳定，可解释和更具表现力的主题，而无需进行广泛的参数校准。仍然缺少在有限时间预算内进行OS规模计划评估的方法。 [3] VDiscovery，收集了轻量级的静态和动态功能，以预测测试用例是否可能包含ML上的软件漏洞。在静态级别，比较程序切片之间的相似性可能是个好主意。智能手机用户面临着一个安全困境：他们安装的许多应用程序都依赖于隐私敏感的数据，尽管它们可能来自可靠性难以判断的开发人员。研究人员已经使用越来越复杂的静态和动态分析工具解决了这个问题，以帮助评估应用程序如何使用私有用户数据[16]。SUSI提出一种新颖的机器学习指导方法，用于直接从任何Android API的代码中识别源和目的。给定一组手工注释的源和接收器，SUSI识别整个API中的其他源和接收器。为了提供更细粒度的信息，SUSI进一步对源和目的[17]进行了分类。输入验证不充分导致许多漏洞，因此省略或缺少检查可以找到发现安全漏洞的宝贵线索。 Chucky能够实时准确地识别丢失的校验，最终使我们能够发现其中两个项目中12个以前未知的漏洞[18]。由于算法密集型特性或对潜在大规模数据的应用，机器学习系统是独特的，因此值得特别考虑。进行实证研究以分析机器学习系统中的错误并报告错误类别与错误严重性之间的关系[19]。 B. 深度学习SCA​ 最近，深度学习极大地影响了SCA的审查。卷积神经网络（CNN）已经在处理各种NLP任务中获得了普及。特别是对于文本分类，深度学习模型取得了显着成果[1] [16] [18] [20]。所提出的模型使用字嵌入层，接着是具有多个滤波器的卷积层，最大池化层，最后是softmax层。采用非静态和随机初始化的嵌入层，因此从头开始训练载体。最常见的ML任务依赖于代表代码特征的手动特征设计。不幸的是，所有这些都在检索源代码的语义和句法解释方面遇到了挑战，这是构建准确预测模型的重要能力[1]。卷积网络能够进行恶意软件分类和分析。实现了由卷积和前馈神经构造组成的神经网络。该体系结构体现了一种分层特征提取方法，该方法将n-gram指令的卷积与从可移植可执行文件（PE）的头部派生的特征的简单矢量化相结合。评估结果表明，我们的方法优于基线方法，例如简单的前馈神经网络和支持向量机，因为它在精度和召回率方面达到了93％，即使在数据混淆的情况下也是如此[20]。 ​ 一种新兴的方法是将软件代码视为一种文本形式，并利用（NLP）技术自动提取特征。以前的工作使用BOW将源代码文件表示为与频率相关的代码令牌的集合。这些术语是用作其脆弱性预测模型的预测变量的特征。 ​ 经典NLP技术与深度学习结合使用被用于检测、分类非NLP应用和报告与人为约束语言（如编程语言及其编译对应语言）中发现的漏洞或不良编码实践相关的弱点[21]。在我们的结果中将NLP方法与信号处理方法进行比较和对比。它显示了用C，C ++和JAVA编写的开源软件的特定测试用例的有希望的结果。 ​ 源代码实际上是文本信息。机器学习中深度学习模型的最新进展为软件度量和BOW代表软件代码提供了强有力的替代方案。最广泛使用的深度学习模型之一是长期短期记忆（LSTM）[22]，这是一种特殊的递归神经网络，在学习文本和语音等顺序数据中的长期依赖性方面非常有效。 LSTM在许多应用中表现出突破性的性能，例如机器翻译，视频分析和速度识别[1]。一些研究人员提出了一种新颖的基于深度学习的方法来自动学习用于预测软件代码中的漏洞的功能，利用LSTM捕获源代码中的长的上下文关系，其中相关的代码元素分散得很远。建立了强大的深度长期短期记忆（LSTM）模型，以同步自动学习代码的语义和句法特征。同时，RNN编码器 - 解码器用于为给定的API相关自然语言查询生成API使用序列[23]。它可能涉及其他软件工程问题，如代码搜索和错误本地化。代码克隆检测也是软件维护和SCA的一个重要问题[24]。所提出的代码分析工具利用深度学习的优势，并自动将词汇层面挖掘的模式与句法层面挖掘的模式联系起来。 IV 结论和未来工作本文代表了源代码审查中机器学习（ML）文献综述的研究成果。 ML和一些分支提出了一些新的想法来实现分类器，回归和代理来预测源代码漏洞，具有较低的误报和漏报。幸运的是，深度处理安全网络以随着数据量的增加自动调整和调整连接的能力将改善学习过程。特别是，这将允许我们自动化和使用网络专门从事某些领域。通过深入学习，安全系统可以通过尝试数十亿种组合并进行数百万次观察来自动学习。针对特定类别的问题，这是非常有希望的，但它不是一个灵丹妙药。仅仅因为一项技术使用深度学习并不意味着其他传统的AI和机器学习方法并不具有更高的价值或实用性。人工智能是一种多用途技术，我们可以在安全和其他行业中工作，学习，迭代和改进。不幸的是，没有找到通过强化学习来审查源代码的论文。主要原因是在审查过程中没有建立动态交互，但是，提出了将静态和动态方法结合起来测量源代码的有希望的方法。 最重要的是，漏洞数据规模不足仍然是一个挑战。跨文件，跨版本和跨项目需要占主导地位，因为对象大多不存在于训练集中。 ML，DL和RL的评论在源代码分析研究中一直走在前列。 个人观点关于源代码漏洞发现总结的较少，所列举文献大多为关于机器学习和深度学习。","content":"<h1 id=\"Abstract\"><a href=\"#Abstract\" class=\"headerlink\" title=\"Abstract\"></a>Abstract</h1><p>源代码审查充分限制了软件系统的安全性。可伸缩性和精度对于代码审查工具的部署非常重要。但是，传统工具只能通过繁琐的大规模源代码审查来自动检测一些高误报和漏报的安全漏洞。各种脆弱点和漏洞在源代码中显示出特定的特征。机器学习系统建立了源代码的特征矩阵作为输入，包括变量，函数和文件，通过区分或生成方法生成ad-hoc标签，以自动和智能地查看源代码。无论编程语言如何，源代码本质上都是文本信息。安全和易受攻击的函数都可以从源代码凸出。幸运的是，已经开发了各种机器学习方法来学习和检测智能源代码安全审查中的脆弱点和漏洞。代码语义和句法特征的组合有助于在源代码审查期间对假阳性和假阴性的优化。在本文中，我们使用机器学习方法对与智能源代码安全性审查相关的文献进行了回顾。它说明了在源代码安全审查中接近ML的主要证据。我们相信机器学习及其分支机构将在源代码审查中脱颖而出。</p>\n<table>\n<thead>\n<tr>\n<th>relevant information</th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><em>作者</em></td>\n<td>Wang Xiaomeng, Zhang Tao, Xin Wei,Hou Changyu</td>\n</tr>\n<tr>\n<td><em>单位</em></td>\n<td>China Information Technology Security Evaluation Center Beijing, China;China anhua technology Limited company Beijing, China</td>\n</tr>\n<tr>\n<td><em>出处</em></td>\n<td>2018 3rd International Conference on Information Systems Engineering</td>\n</tr>\n<tr>\n<td><em>原文地址</em></td>\n<td><a href=\"https://ieeexplore.ieee.org/document/8614720\" target=\"_blank\" rel=\"noopener\">https://ieeexplore.ieee.org/document/8614720</a></td>\n</tr>\n<tr>\n<td><em>源码地址</em></td>\n<td></td>\n</tr>\n<tr>\n<td><em>发表时间</em></td>\n<td>2018年</td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"I-介绍\"><a href=\"#I-介绍\" class=\"headerlink\" title=\"I. 介绍\"></a>I. 介绍</h1><p>​        本文介绍了机器学习（ML）在源代码审查中文献综述的研究成果。代码审查目标是发现错误，安全漏洞和违反程序规范。代码错误，弱点或漏洞在软件中很普遍，并且可能导致各种安全问题，包括死锁，信息泄露或系统崩溃，更严重的是，一些黑客攻击[1]。WannaCry勒索软件攻击是2017年5月WannaCry勒索软件发起的全球网络攻击[2]。该攻击于2017年5月12日星期五开始[3] [4]，据报道，在一天之内，已有150多个国家的230,000多台计算机受到感染。 [5] [6]英国国家健康服务（NHS）的部分地区受到感染，导致其在袭击期间仅在紧急情况下运行一些服务，西班牙的TelefónicaFedEx和Deutsche Bahn以及许多其他世界各国和公司[7]。中国的一些Windows操作系统已经被感染，而校园网用户已经是第一个遭受严重破坏的用户。大量的实验室数据和毕业设计已被锁定。一些大型企业的应用系统和数据库文件在加密后无法正常运行。这些袭击威胁到企业，政府和消费者，随着黑客犯罪对全球经济的年度成本增加，费率和成本也在增加。2017年，估计全球安全市场将超过1200亿[1]。因此，检测到更早的漏洞或错误，软件系统将更好。作为软件安全保护最重要的部分之一，源代码审查已经服务了数十年，并且已经通过ML和数据挖掘将更多智能方法植入到挖掘代码漏洞中。</p>\n<p>​        在过去的十年中，ML在代码审查中得以蓬勃发展[8] [9] [10] [11]。本文描述和讨论了ML算法和应用的最新技术。机器学习已经在源代码安全任务中得到应用，例如代码推荐，源代码错误检测和代码检索。传统的机器学习系统利用手动特征工程来进行代码错误检测，这是标签只能临时的用于特定项目。随着机器学习的核心扩展，深度学习方法能够通过很少的手动操作捕获复杂的自下而上功能。深度学习可以智能地提取错误的代码特征，将程序特征与查询的特征匹配，并预测下一个可能代码的概率[1]。源代码最终是文本信息，主要涉及深度学习中的自然语言（NLP）研究。不幸的是，考虑到编程语言和自然语言之间的结构差异，现有的NLP算法对于代码表示是不合适的。为了提取适用的特征表示，需要整理现有方案和改进策略的缺陷[12]。</p>\n<p>​        在本文中，我们从以下几个方面对源代码审查进行了详尽的概述：第二节简要介绍了经典的源代码分析(SCA)，包括典型的验证方法和进程流程。第三节说明了现有的机器学习SCA方法，如传统的机器学习方法和深度学习应用在源代码审查中。第四部分总结了整篇论文的一些结论，说明了存在的问题，并展示了一些未来的工作，并承认了本文的贡献者。</p>\n<h1 id=\"II-经典的静态代码分析\"><a href=\"#II-经典的静态代码分析\" class=\"headerlink\" title=\"II 经典的静态代码分析\"></a>II 经典的静态代码分析</h1><p>​        静态代码分析（SCA）通常作为代码审查的一部分执行，并在安全开发生命周期（SDL）的实施阶段执行。 SCA的程序。 SCA通常是指通过使用数据流分析，污点分析，符号执行等技术的工具来试图发现“静态”（非运行）源代码中可能存在的漏洞。<br>​        假阳性和假阴性揭示了SCA的局限性。在分析与闭源组件或外部系统交互的应用程序时，可能会报告误报结果，因为如果没有源代码，则无法跟踪外部系统中的数据流，从而确保数据的完整性和安全性。静态代码分析工具的使用也可能由于工具不会报告漏洞导致漏报。如果在外部组件中发现新漏洞，或者分析工具不了解运行时环境以及是否已安全配置，则可能会发生这种情况。<br>​        以前的工作已经证明，经典SCA能够预测源代码漏洞，尽管有时会出现不可接受的误报和漏报。最近，人工智能，尤其是机器学习及其相关分支，对SCA的学术对话产生了重大影响，下一部分将对此进行研究。</p>\n<p><img src=\"/2019/04/02/A-Survey-on-Source-Code-Review-Using-Machine-Learning/1.jpg\" alt=\"\"><br>图1.经典SCA的草图。从易受攻击的代码中提取的功能揭示了漏洞规则。模型构建有助于对程序进行建模。经典SCA探索数据流，符号执行，污点分析，模型检查和定理证明来审查源代码。审核结果需要通过认证和分类。最终，建立了漏洞收集。</p>\n<h1 id=\"III-机器学习SCA\"><a href=\"#III-机器学习SCA\" class=\"headerlink\" title=\"III 机器学习SCA\"></a>III 机器学习SCA</h1><p>​        在过去十年中，ML在基于特征表示的智能代码审查中蓬勃发展。 ML任务可以分为传统的机器学习，深度学习和强化学习，如图2所示。传统的机器学习包括监督学习和无监督学习。对于监督学习，计算机将显示示例输入及其所需标签，目标是学习将输入映射到输出的一般规则或功能。然而，对于无监督学习，没有给学习算法赋予标签，使其自己在其输入中找到结构。无监督学习可以是特征学习过程。</p>\n<p>​        深度学习使用多层非线性处理单元级联进行特征提取和转换[13]。每个连续层使用前一层的输出作为输入，以有监督和/或无监督的方式学习，学习对应于不同抽象级别的多个级别的表示，并利用某种形式的梯度下降通过反向传播进行训练[14] 。它们还可以包括在深度生成模型中逐层组织的潜在变量，例如Deep Belief Networks  和Deep Boltzmann Machines 中的节点。相比之下，强化学习似乎更加智能，计算机程序与必须执行某个目标的动态环境相互作用。该程序在奖励和惩罚方面提供反馈，因为它在问题空间中导航。这些输入来自在线或离线源代码存档。</p>\n<p><img src=\"/2019/04/02/A-Survey-on-Source-Code-Review-Using-Machine-Learning/2.jpg\" alt=\"\"></p>\n<p>图2.源代码在ML，DL和RL的审查项目中占主导地位。数据集和知识库管理ML和DL中静态分析的数据空间。虽然提取预处理和特征表示表面和潜在特征作为ML和DL训练的输入。 DL采用复杂的多层结构，如深度神经网络，与ML中的不同，利用简单的神经网络。 ML和DL都生成一个模型来预测它所属的输入源代码片。 RL提出了一些区别。源代码在预处理和特征表示中组装。结果输出到RL闭环，通过奖励和状态在环境行动的条件下实现目标。环境向知识库提供反馈，直到实现目标</p>\n<h2 id=\"A-传统机器学习SCA\"><a href=\"#A-传统机器学习SCA\" class=\"headerlink\" title=\"A.传统机器学习SCA\"></a>A.传统机器学习SCA</h2><p>​        Internet上有各种源代码存档。这些档案通常由应用程序类别和各种编程语言组成。但是，手动组织源代码存储库并不是一件容易的事，因为它们会迅速增长到非常大的规模。用于归档源代码自动分类的机器学习方法被演示为11个应用主题和10种编程语言。对于局部分类，近年来来自Ibiblio和Sourceforge档案的C和C ++程序主导了研究。支持向量机（SVM）分类器在给定编程语言或特定类别的程序的示例上进行训练。源代码可以准确地自动分类为主题类别，并且可以被识别为特定的编程语言。群集假设和信息理论的基本假设被用来发现软件系统中语义连贯的主题[15]。生成主题的有用性通过人工判断凭经验验证。此外，一个案例研究表明，报告了在分析代码演变时所提出的方法的操作。与传统的主题建模技术相比，这种提出的方法产生了稳定，可解释和更具表现力的主题，而无需进行广泛的参数校准。仍然缺少在有限时间预算内进行OS规模计划评估的方法。 [3] <strong>VDiscovery</strong>，收集了轻量级的静态和动态功能，以预测测试用例是否可能包含ML上的软件漏洞。在静态级别，比较程序切片之间的相似性可能是个好主意。智能手机用户面临着一个安全困境：他们安装的许多应用程序都依赖于隐私敏感的数据，尽管它们可能来自可靠性难以判断的开发人员。研究人员已经使用越来越复杂的静态和动态分析工具解决了这个问题，以帮助评估应用程序如何使用私有用户数据[16]。<strong>SUSI</strong>提出一种新颖的机器学习指导方法，用于直接从任何Android API的代码中识别源和目的。给定一组手工注释的源和接收器，SUSI识别整个API中的其他源和接收器。为了提供更细粒度的信息，SUSI进一步对源和目的[17]进行了分类。输入验证不充分导致许多漏洞，因此省略或缺少检查可以找到发现安全漏洞的宝贵线索。 <strong>Chucky</strong>能够实时准确地识别丢失的校验，最终使我们能够发现其中两个项目中12个以前未知的漏洞[18]。由于算法密集型特性或对潜在大规模数据的应用，机器学习系统是独特的，因此值得特别考虑。进行实证研究以分析机器学习系统中的错误并报告错误类别与错误严重性之间的关系[19]。</p>\n<h2 id=\"B-深度学习SCA\"><a href=\"#B-深度学习SCA\" class=\"headerlink\" title=\"B. 深度学习SCA\"></a>B. 深度学习SCA</h2><p>​        最近，深度学习极大地影响了SCA的审查。卷积神经网络（CNN）已经在处理各种NLP任务中获得了普及。特别是对于文本分类，深度学习模型取得了显着成果[1] [16] [18] [20]。所提出的模型使用字嵌入层，接着是具有多个滤波器的卷积层，最大池化层，最后是softmax层。采用非静态和随机初始化的嵌入层，因此从头开始训练载体。最常见的ML任务依赖于代表代码特征的手动特征设计。不幸的是，所有这些都在检索源代码的语义和句法解释方面遇到了挑战，这是构建准确预测模型的重要能力[1]。卷积网络能够进行恶意软件分类和分析。实现了由卷积和前馈神经构造组成的神经网络。该体系结构体现了一种分层特征提取方法，该方法将n-gram指令的卷积与从可移植可执行文件（PE）的头部派生的特征的简单矢量化相结合。评估结果表明，我们的方法优于基线方法，例如简单的前馈神经网络和支持向量机，因为它在精度和召回率方面达到了93％，即使在数据混淆的情况下也是如此[20]。</p>\n<p>​        一种新兴的方法是将软件代码视为一种文本形式，并利用（NLP）技术自动提取特征。以前的工作使用BOW将源代码文件表示为与频率相关的代码令牌的集合。这些术语是用作其脆弱性预测模型的预测变量的特征。</p>\n<p>​        经典NLP技术与深度学习结合使用被用于检测、分类非NLP应用和报告与人为约束语言（如编程语言及其编译对应语言）中发现的漏洞或不良编码实践相关的弱点[21]。在我们的结果中将NLP方法与信号处理方法进行比较和对比。它显示了用C，C ++和JAVA编写的开源软件的特定测试用例的有希望的结果。</p>\n<p>​        源代码实际上是文本信息。机器学习中深度学习模型的最新进展为软件度量和BOW代表软件代码提供了强有力的替代方案。最广泛使用的深度学习模型之一是长期短期记忆（LSTM）[22]，这是一种特殊的递归神经网络，在学习文本和语音等顺序数据中的长期依赖性方面非常有效。 LSTM在许多应用中表现出突破性的性能，例如机器翻译，视频分析和速度识别[1]。一些研究人员提出了一种新颖的基于深度学习的方法来自动学习用于预测软件代码中的漏洞的功能，利用LSTM捕获源代码中的长的上下文关系，其中相关的代码元素分散得很远。建立了强大的深度长期短期记忆（LSTM）模型，以同步自动学习代码的语义和句法特征。同时，RNN编码器 - 解码器用于为给定的API相关自然语言查询生成API使用序列[23]。它可能涉及其他软件工程问题，如代码搜索和错误本地化。代码克隆检测也是软件维护和SCA的一个重要问题[24]。所提出的代码分析工具利用深度学习的优势，并自动将词汇层面挖掘的模式与句法层面挖掘的模式联系起来。</p>\n<h1 id=\"IV-结论和未来工作\"><a href=\"#IV-结论和未来工作\" class=\"headerlink\" title=\"IV 结论和未来工作\"></a>IV 结论和未来工作</h1><p>本文代表了源代码审查中机器学习（ML）文献综述的研究成果。 ML和一些分支提出了一些新的想法来实现分类器，回归和代理来预测源代码漏洞，具有较低的误报和漏报。幸运的是，深度处理安全网络以随着数据量的增加自动调整和调整连接的能力将改善学习过程。特别是，这将允许我们自动化和使用网络专门从事某些领域。通过深入学习，安全系统可以通过尝试数十亿种组合并进行数百万次观察来自动学习。针对特定类别的问题，这是非常有希望的，但它不是一个灵丹妙药。仅仅因为一项技术使用深度学习并不意味着其他传统的AI和机器学习方法并不具有更高的价值或实用性。人工智能是一种多用途技术，我们可以在安全和其他行业中工作，学习，迭代和改进。不幸的是，没有找到通过强化学习来审查源代码的论文。主要原因是在审查过程中没有建立动态交互，但是，提出了将静态和动态方法结合起来测量源代码的有希望的方法。</p>\n<p>最重要的是，漏洞数据规模不足仍然是一个挑战。跨文件，跨版本和跨项目需要占主导地位，因为对象大多不存在于训练集中。 ML，DL和RL的评论在源代码分析研究中一直走在前列。</p>\n<h1 id=\"个人观点\"><a href=\"#个人观点\" class=\"headerlink\" title=\"个人观点\"></a>个人观点</h1><p>关于源代码漏洞发现总结的较少，所列举文献大多为关于机器学习和深度学习。</p>\n","categories":[{"name":"论文","slug":"论文","permalink":"http://yama0xff.com/categories/论文/"},{"name":"fuzzing","slug":"论文/fuzzing","permalink":"http://yama0xff.com/categories/论文/fuzzing/"},{"name":"综述","slug":"论文/fuzzing/综述","permalink":"http://yama0xff.com/categories/论文/fuzzing/综述/"}],"tags":[{"name":"2018年","slug":"2018年","permalink":"http://yama0xff.com/tags/2018年/"},{"name":"fuzzing","slug":"fuzzing","permalink":"http://yama0xff.com/tags/fuzzing/"},{"name":"综述","slug":"综述","permalink":"http://yama0xff.com/tags/综述/"}]},{"title":"From automation to intelligence: Survey of research on vulnerability discovery techniques","date":"2019-04-02T02:08:03.000Z","path":"2019/04/02/From-automation-to-intelligence-Survey-of-research-on-vulnerability-discovery-techniques/","text":"Abstract近年来，随着软件规模和复杂度的日益增加，软件漏洞挖掘技术正逐渐向高度自动化和智能化演变，该文从传统漏洞挖掘技术和基于学习的智能化漏洞挖掘技术两方面深入调研和分析了相关的研究进展。首先，从静态和动态挖掘技术2方面详细介绍了传统漏洞挖掘技术的研究现状，涉及的技术包括模型检测、二进制比对、模糊测试、符号执行以及漏洞可利用性分析等，并分析了各项技术存在的问题，提出当前的研究难点是实现漏洞挖掘全自动化。然后，介绍了机器学习和深度学习技术在漏洞挖掘领域的应用，具体应用场景包括二进制函数识别、函数相似性检测、测试输入生成、路径约束求解等，并提出了其存在的机器学习算法不够健壮安全、算法选择依靠经验、数据样本不足、特征选择依赖专家知识等问题。最后，对未来研究工作进行了展望，提出应该围绕提高漏洞挖掘的精度和效率、提高自动化和智能化的程度这2方面展开工作。 relevant information 作者 邹权臣，张涛，吴润浦, 马金鑫, 李美聪, 陈晨,侯长玉 单位 中国信息安全测评中心,空军工程大学 信息与导航学院,北京邮电大学 网络空间安全学院,北京中测安华科技有限公司 出处 清华大学学报 原文地址 http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#outline_anchor_17 源码地址 发表时间 2018年 1. 简介漏洞信息的不对称性已经成为导致网络战争中的实力对比悬殊的关键因素。从早年爆发的蠕虫王、冲击波、震荡波病毒，到近年来爆发的WannaCry病毒，都借助了软件或系统的安全漏洞进行传播。另外，高级的网络攻击(如APT攻击)甚至会基于多个漏洞交叉、组合使用，目的是绕过防火墙、杀毒软件、入侵检测系统等，摧毁隔离网的安全性，突破核心网络节点而进入内网，进行后续的渗透攻击(如窃取、修改、加密重要数据，摧毁核心设施等)。特别是未公开的0day漏洞常常被当成秘密的终极武器使用，有时候甚至能起到决定性的作用。 鉴于软件漏洞在网络攻防中的重要性，各大软件厂商及高校、科研院所的研究人员对漏洞挖掘技术展开了大量的研究。当前，常用的漏洞挖掘技术包括模型检测、模糊测试、符号执行、二进制比对等，这些传统的漏洞挖掘技术在理论研究上已经比较成熟，并已从各类软件中挖掘出大量漏洞。其中大部分的技术如模糊测试、符号执行等都已基本实现自动化，可以在不需要或较少的人工干预的前提下，针对被测试程序和输入数据的不同特点，借助各种程序动、静态分析技术，寻找分析深度和分析效率之间的平衡点，缓解代码覆盖率低、扩展性差等问题；目的是提高漏洞挖掘的效率，实现在更短的时间内发现更多或更深层次的漏洞。 机器学习、深度学习的研究进展带动了其在软件漏洞挖掘领域的应用，目前已经开展了一些探索性的工作，如二进制函数相似性识别、函数相似性检测、测试输入生成、路径约束求解等，这些应用为解决传统漏洞挖掘技术的瓶颈问题提供了新的思路，也使得软件漏洞挖掘逐渐变得智能化。随着机器学习、深度学习研究的爆炸式发展，以及这方面研究积累的数据集的增多，将可能成为软件漏洞挖掘技术发展的关键点之一。 本文以近年来软件漏洞挖掘技术所呈现出的自动化和智能化的趋势作为切入点，介绍了传统漏洞挖掘技术和基于学习的智能化漏洞挖掘技术的研究进展。首先，本文从静态和动态漏洞挖掘两方面对传统的漏洞挖掘技术进行了分类分析，指出了各自的优势和面临的问题；并介绍了漏洞可利用性分析以及自动化漏洞挖掘(如CGC大赛)的研究进展，指出漏洞挖掘的全自动化是当前研究的难点问题。然后，对基于学习的智能化软件漏洞挖掘技术进行了分类，并深入分析了二进制函数识别、函数相似性检测等不同应用场景的研究工作，归纳总结了其面临的机器学习算法不够健壮安全、算法选择依靠经验、数据样本不足、特征选择依赖专家知识等四大问题。最后进行了总结和展望，指出未来应在提高漏洞挖掘的精度和效率，以及自动化和智能化方面展开研究。 2.传统漏洞挖掘技术传统的漏洞挖掘技术主要可分为静态和动态漏洞挖掘技术，漏洞可利用性分析也已经成为漏洞挖掘的重要环节，如[图 1]所示 2.1 静态漏洞挖掘静态漏洞挖掘是指在不运行目标程序的前提下分析目标程序(源代码或二进制)的词法、语法和语义等，并结合程序的数据流、控制流信息，通过类型推导、安全规则检查、模型检测等技术挖掘程序中的漏洞。静态漏洞挖掘是常用的软件测试技术，在软件测试中占有非常重要的地位。具有代表性的静态漏洞挖掘工具有面向C/C++源码的Cppcheck[1]、FlawFinder[2], 面向PHP源码的RIPS[3], 面向JAVA源码的FindBugs[4]，以及能支持多种类型目标对象的著名商业化漏洞检测工具VeraCode[5]、Fortify[6]、Coverity[7]、Checkmarx[8]等。另外，LLVM[9]、Clang[10]等编译器也提供了大量的静态检测功能，能在编译阶段实现对源代码的安全性检查。 针对目标程序的不同形式，采用的静态分析技术也不尽相同。本节将按源代码和二进制2种目标程序分别介绍静态漏洞挖掘技术的研究现状。 面向源代码的漏洞挖掘主要采用基于中间表示的分析和基于逻辑推理的分析技术[11]。其中，基于中间表示的分析技术主要包括数据流分析、控制流分析、污点分析、符号执行等。Pixy[12]采用了取值分析、污点分析、指针别名分析等静态分析技术实现对PHP源码中的SQL注入和跨站脚本等漏洞的检测。Prefix[13]采用了静态符号执行技术模拟执行C/C++源码程序，并采用约束求解对程序中的部分路径进行检测。Melange[14]采用数据流分析的框架，通过对程序进行数据流、控制流等复杂分析检测安全相关的漏洞，并支持对大型C/C++源码程序的分析。K-Miner[15]利用内核代码中高度标准化的接口实现了可扩展性良好的指针分析以及全局的上下文敏感的分析技术，支持对空指针引用、指针释放后重引用(use-after-free, UAF)、指针重释放(double free)、双重检查锁定(double-checked lock)等内存崩溃漏洞的检测。基于逻辑推理的分析技术主要是指模型检测，如MOPS[16]、BLAST[17]、SLAM[18]是典型的面向C程序的模型检测工具，其基本思路是将程序结构抽象为状态机(布尔程序)，然后基于归纳的安全属性对状态机进行遍历，检测其中存在的漏洞。 面向二进制程序的静态漏洞的挖掘技术由于缺少源代码中的结构化信息，面临着值集分析(vaule-set analysis，VSA)[19]与控制流恢复[20-25]不精确的问题。当前，二进制静态漏洞挖掘技术主要包括基于模式匹配和基于补丁比对的技术。其中，在基于模式匹配的漏洞挖掘技术方面，GUEB[26]提出了二进制程序中UAF漏洞模式，并基于此模式挖掘出了ProFTPD程序中的漏洞。具体而言，首先抽象出二进制函数中的内存模型，然后采用VSA分析技术追踪堆分配和释放指令相关的操作变量，并基于此建立UAF模式。LoongChecker[27]使用了称为半仿真的二进制静态漏洞挖掘技术。通过VSA分析和数据依赖分析(data dependence analysis，DDA)技术实现对变量地址的追踪和数据流依赖分析，并采用污点分析技术检测潜在的漏洞。Saluki[28]使用了路径敏感和上下文敏感的数据依赖分析，并采用完备的逻辑系统推理检测程序中的漏洞。在基于补丁比对的漏洞挖掘技术方面，PVDF[29]以二进制漏洞程序(带有权限提升漏洞)和补丁作为输入，从比对中提取多维属性描述的漏洞语义信息，并应用于后续的模糊测试中。BinHunt[30]通过对二进制程序和带补丁的二进制程序间的比对提取漏洞相关的语义信息。具体而言，就是把二进制程序翻译成中间表示，并在此基础上构建控制流图，基于控制流图对比程序间的差异，提取相关的约束，然后采用符号执行技术进行验证，以此找出补丁对应的漏洞。 静态漏洞挖掘技术直接对目标程序进行分析，不需要构造程序的执行环境，能提取较为完整的控制流等信息，可能发现动态漏洞挖掘技术难以发现的漏洞。但是，一方面，由于静态漏洞挖掘技术往往依赖于人工构造的漏洞模式，对先验知识依赖性较大；另一方面，因为无法获得程序实际动态运行过程中的上下文信息，静态漏洞挖掘技术具有精度低、误报率高的缺陷。 2.2 动态漏洞挖掘动态漏洞挖掘技术是指在实际执行程序的基础上采用的分析技术，常用的动态漏洞挖掘技术包括模糊测试、符号执行等。 2.2.1 模糊测试模糊测试(fuzzing)是一种自动化或者半自动化的软件测试技术，通过构造随机的、非预期的畸形数据作为程序的输入，并监控程序执行过程中可能产生的异常，之后将这些异常作为分析的起点，确定漏洞的可利用性。模糊测试技术可扩展性好，能对大型商业软件进行测试，是当前最有效的用于挖掘通用程序漏洞的分析技术，已经被广泛用于如微软、谷歌和Adobe等主流软件公司的软件产品测试和安全审计，也是当前安全公司和研究人员用于挖掘漏洞的主要方法之一。 按程序内部结构分析的量级轻重程度分，模糊测试技术主要可以分为白盒、黑盒、灰盒模糊测试。其中，白盒模糊测试是在对被测试程程序内部结构、逻辑进行系统性分析的基础上进行测试；黑盒模糊测试把程序当成黑盒处理，不对程序内部进行分析；灰盒模糊测试介于黑盒和白盒模糊测试之间，在对程序进行轻量级分析的基础上进行测试。按样本生成方式划分，模糊测试的测试输入可分为基于变异和基于生成2种方式。其中，基于变异的模糊测试在修改已知测试输入的基础上生成新的测试用例，而基于生成的模糊测试则是直接在已知输入样本格式的基础上生成新的测试输入。 根据不同的研究侧重点，本文分别介绍基于变异的模糊测试、基于生成的模糊测试和其他优化策略。 1) 基于变异的模糊测试。在基于变异的模糊测试方面，研究人员借助程序执行环境信息和程序分析技术，有导向性地辅助、引导模糊测试的变异，具有代表性的工作有AFL[31]、VUzzer[32]、Honggfuzz[33]、libFuzzer[34]、Steelix[35]、T-Fuzz[36]、AFLFast[37]、AFLGo[38]、Driller[39]等。 a) 代码覆盖率制导 AFL[31]使用进化算法(evolutionary algorithms)生成测试输入，在正常输入的基础上，通过简单的反馈回路的方式评估测试输入的质量。AFL会保留任何能触发新路径的测试输入，并对其进行变异及检查能否触发崩溃。AFL已经在Mozilla Firefox、FFmpeg、OpenSSL等软件中发现了大量的漏洞。但AFL也存在较大的缺陷：首先，变异的位置以及变异的方式是盲目的，缺少更进一步的筛选和变异策略，依赖这种方式很难发现深层次的漏洞；其次，通过哈希函数检测分支覆盖筛选种子的方式具有较高的误报率，其哈希位图(bitmap)只有64 kB大小，导致普遍存在哈希碰撞的情况，进而导致其分支覆盖统计存在漏报，进而影响种子筛选，间接影响了代码覆盖率的增长。CollFuzz[40]采用静态控制流图信息作为辅助，并设计了能避免哈希碰撞的基本块ID分配策略，从而实现比AFL更精确的分支覆盖检测。 b) 污点分析辅助 BuzzFuzz[41]使用动态污点分析技术自动定位影响程序脆弱点的测试输入中的字段，然后保留其他语法部分内容，只对这些字段进行变异。这样既能通过语法检查，也能有针对性地进行变异，提高漏洞挖掘的效率。TaintScope[42]使用污点分析技术推断程序中与校验和处理相关的代码，以此帮助模糊测试工具绕过校验和检查。 c) 符号执行制导 Driller[39]采用模糊测试和符号执行交替探索程序执行路径，解决模糊测试陷入代码覆盖率增长慢的情况，这样能引导模糊测试探索到程序更深层次的节点，也能直接避免符号执行可能带来的路径爆炸问题。但文[39]和[43]等的实验结果表明，使用符号执行对模糊测试中部分路径约束求解时，仍然有很大一部分路径出现求解失败的情况(文[39]实验中有41个测试程序陷入了较浅路径，使用符号执行对其求解时只有13个程序能够生成新的测试输入)。因此，基于符号执行增强的模糊测试技术仍然会受限于符号执行中的约束求解问题，符号执行的引入可能会弱化模糊测试本身的可扩展性。 d) 控制流和数据流信息制导 VUzzer[32]在“轻量级”的动、静态分析基础上提取了程序的控制流和数据流信息引导变异。具体而言，VUzzer先在静态控制流分析基础上计算基本块的权重，然后在动态执行时筛选权重更高即路径更深的执行路径对应的测试输入为种子文件，并用动态污点分析定位变异点。相比AFL、Driller，VUzzer有更好的种子筛选、路径探索策略以及污染点定位、变异策略，能定向引导探索更深的执行路径，并定点变异。在DARPA CGC和LAVA测试集以及部分常用应用程序上，VUzzer都取得了更好的效果(用更少的测试输入挖掘出了更多的漏洞)。Steelix[35]采用了轻量级的静态分析和二进制插桩技术提取代码覆盖率信息和魔术字节(magic byte)比较信息等作为程序状态信息引导变异。这种方式能在较小的开销下定位魔术字节在测试输入中的位置，进而辅助模糊测试工具更高效地生成能通过魔术字节检验的测试输入。 2) 基于生成的模糊测试。基于生成的模糊测试主要基于模型或者语法生成能满足程序语法和语义检查的测试输入，常用于高度结构化的测试输入生成。 a) 基于模型的模糊测试 Peach[44]、Spike[45]是典型的基于模型的模糊测试工具(Peach也具有基于变异进行模糊测试的功能)，通过对输入格式定制编写数据模型(data model)和状态模型(state model)的方式指定输入数据的类型和依赖关系, 并结合变异策略生成测试输入。其中Peach通过编写配置文件实现对样本格式的约束，而Spike需要利用提供的编程接口来对样本格式进行约束。Pham等[46]结合输入模型和符号执行技术生成测试输入，使用符号执行鉴别输入格式约束能有效保证输入的合法性。 b) 基于语法的模糊测试 CSmith[47]根据C语言语法生成C程序源码，实现对C编译器的模糊测试。在C源码生成方面，CSmith随机选取符合生成规则和语法规则的C程序，这种方法能避免因未定义和未声明而导致编译报错的情况出现。LangFuzz[48]基于语法学习测试集中的代码片段，并进行片段重组生成新的测试输入。在测试输入集选择上，LangFuzz假设基于问题测试集重组生成的测试输入比随机收集的测试输入更有可能触发程序缺陷。IFuzzer[49]使用上下文无关的语言语法作为输入，并使用语法生成解析树，然后从测试集中抽取代码片段，并使用遗传进化算法对代码片段重组生成新的测试输入。Jsfunfuzz[50]使用了历史漏洞知识和硬编码规则生成测试输入，以Mozilla浏览器中的Javascript解释器为测试目标，发现了1 800多个缺陷。Dewey等[51]使用了称为约束逻辑编程(constraint logic programming, CLP)的技术生成测试输入。通过指定句法特征和语义行为，CLP能生成满足语法和语义合法性的测试输入。 3) 其他优化策略。除了上述进展外，还有一些重要研究侧重于种子筛选策略优化[37-38, 52-55]和调度策略优化[37-38]。Rebert等[53]把种子筛选问题转化成整数线性规划问题，并以挖掘更多漏洞为目标提出了多种种子筛选策略。AFLFast[37]采用了把模糊测试问题建模为Markov模型，并采用特定的策略引导AFL优先选择低频路径和变异频率较低的文件作为种子文件进行变异，以此在相同的测试时间内探索更多的路径。AFLGo[38]采用了模拟退火(simulated annealing，SA)算法对能逼近特定目标位置的测试输入分配更高的能量，并优先选取高能量种子文件进行变异。AFLGo的实验结果表明，这种导向型灰盒模糊测试(directed greybox fuzzing，DFG)比符号执行引导的白盒模糊测试和非导向型模糊测试具有更好的性能、更高的代码覆盖率并可挖掘出更多的漏洞。 总体而言，模糊测试是当前挖掘漏洞最有效的方法，比其他漏洞挖掘技术更能应对复杂的程序，具有可扩展性好的优势。但在大规模漏洞分析测试中，模糊测试方法仍然依赖于种子输入的质量，依赖于对测试输入对象格式的深度理解和定制，存在测试冗余、测试攻击面模糊、测试路径盲目性较高等问题。另外，目前模糊测试也存在整体测试时间长、生成单个测试用例漏洞触发能力弱的问题。 2.2.2 符号执行符号执行于20世纪70年代被提出[56-59]，是一种能够系统性探索程序执行路径的程序分析技术，通过对程序执行过程中的被污染的分支条件及其相关变量的收集和翻译，生成路径约束条件，然后使用可满足模理论(SMT)求解器进行求解, 判断路径的可达性以及生成相应的测试输入。通过这种方式产生的测试输入与执行路径之间具有一对一的关系，能够避免冗余测试输入的产生，进而能有效解决模糊测试冗余测试用例过多导致的代码覆盖率增长慢的问题。 符号执行技术应用已经被学术和工业界应用在漏洞挖掘领域。自从符号执行特别是动态符号执行技术被提出以来，已经有很多相关的工具被应用到实际的软件测试当中，如SAGE[60]、S2E[61]、Mayhem[62]、KLEE[63]、Triton[64]、angr[65-66]等。其中SAGE已经被应用到了微软内部的日常开发安全测试中，每天有上百台机器同时在运行此工具，并发现了Windows 7系统中三分之一的漏洞[60]。MergePoint[67]已经在Debian系统下发现上百个可利用漏洞。 虽然符号执行相比其他程序测试和分析技术有诸多的优势，但就当前的形势而言，要大规模应用到工业领域仍然还有很多问题需要解决。符号执行概念提出至今已有40多年，而现代符号执行技术特别是动态符号执行技术的提出也有10多年之久，但至今符号执行仍然难以在主流的软件测试和漏洞挖掘中占据主导地位，归因于以下尚待解决的难题。 1) 路径爆炸(path explosion)问题。路径爆炸又称为状态爆炸(state explosion)，是指在程序运行过程中路径数随着分支条件的增多而出现指数级增长的情况。由于路径爆炸问题的存在，在大型复杂的程序中，符号执行容易出现代码覆盖率增长慢的问题，很难在合理有限的时间内遍历程序的所有执行路径。为了缓解这一问题，研究人员采用了具有制导性的启发式搜索以及状态空间简化等操作减少对冗余状态的探索。 启发式搜索(search heuristics)是一种以特定目标优先的路径搜索策略。符号执行过程中对路径的探索可以看成是对符号执行树的探索，在执行树中，从根节点到叶子节点的一条路径代表程序实际执行中的一条路径，而其中的分支节点则表示程序实际执行中的分支条件。大部分启发式技术都专注于避免因陷入某部分相似路径而导致代码覆盖率低增长的情况，以期获得更高的代码和路径覆盖。KLEE[63]中提出结合随机路径选择(random path selection)和覆盖优化搜索(coverage-optimized search)的混合搜索算法，2种路径选择方法交叉使用探索执行路径既能达到高代码覆盖率的目的，又能防止某种算法陷入困境导致路径探索无法进行。Ma等[68]提出了以指定行代码可达性(line reachability)为目标的搜索策略。以程序中某行或多行代码为目标，找出能够驱动程序执行这些代码的实际输入问题称为代码行可达性问题。Godefroid等[60]提出了代搜索(generational search)算法，在每一代新生成的路径约束中，对所有分支条件取反，然后能选择覆盖新代码块最多的测试输入作为新的种子输入。 状态空间简化通过相似路径合并、冗余路径删减的方式达到减少路径探测的目的。除了启发式探索程序执行路径之外，研究人员还提出了利用程序分析和软件验证等技术减少精简路径的措施来缓解路径爆炸问题。Godefroid等[69]采用了函数摘要的方式，对重用的函数提取约束组合(摘要)，实现对函数路径的组合执行，避免了多次重复符号执行带来的开销。Ramos等[70]提出的限定约束的符号执行(under-constrainted symbolic execution)采用了直接面向独立函数的符号执行技术，此技术限定了符号执行的范围，用精确度换取可扩展性的方式来提升符号执行的性能。Veritesting[67]采用了静态符号执行技术增强动态符号执行技术，实现路径合并和冗余路径删减。Boonstoppel等[71]提出了RWSet，从状态变量的相似性鉴别冗余性，如果当前状态的变量跟之前的路径变量一样，则会停止对当前状态的探索。 2) 约束求解问题。约束求解问题是动态符号执行遇到的另一个瓶颈问题。在动态符号执行中，对路径约束条件可达性的判定以及相应测试输入生成都需要频繁地调用SMT求解器进行求解；而约束求解本身又是一个NP完全(NP-complete)问题，在最差的情况下求解NP完全问题的复杂度为指数级。频繁调用加上高的求解难度直接导致约束求解消耗了符号执行系统中的大部分资源。 当前约束求解问题可以归结为求解能力和求解效率问题。求解能力问题是指当前求解器对复杂约束条件处理能力的不足。例如对于浮点数运算、非线性运算等一些复杂运算的约束，求解器都不能很好地处理。而求解效率问题是指对于含有大量的约束条件的路径约束，求解器的性能会随着约束条件数量的增长而逐渐下降。这使得符号执行对大型程序进行分析时整体性能下降，从而影响其可扩展性。 针对约束求解的两大问题，研究人员提出了很多约束求解性能优化措施，主要可分为内部优化和外部优化。求解器内部优化是指通过优化求解器本身对约束条件处理能力和效率来提高符号执行的性能，虽然近年来这方面的研究已经取得了比较大的突破[72-76]，但仍然严重依赖于可满足模理论以及NP完全问题的研究进展。求解器外部优化主要是指在调用约束求解器对路径约束求解之前的优化，是通过减少甚至避免符号查询的工作来增加符号执行性能的措施。例如，CUTE[77]和KLEE[63]采用了如表达式重写、符号值的实际替换、不相关约束的删除以及约束缓存等一系列措施，对路径约束进行精简和结果重用。而近年来在这方面的研究又有了不小的突破，包括Green[78]、Recal[79]、GeenTrie[80]、Memoise[81]等，这些工具的提出主要侧重于解决优化符号执行结果切分、标准化命名、约束式逻辑转化、求解结果的缓存、搜索和重用的效率问题。有关这些工具的实验结果表明：路径约束的精简能减轻约束求解的负担，而约束求解结果的缓存和重复使用能在同一程序的不同路径以及不同程序的不同路径间的约束求解问题上极大地减少对求解器的调用。 3) 其他问题。除了上述2个问题之外，符号执行还面临着内存建模[62, 65-66]、环境交互[61, 63, 82-83]、并行计算[67, 84]等问题。 总体而言，基于符号执行的漏洞挖掘技术依赖于约束求解器的求解能力和效率，并受限于程序状态爆炸问题。另外，它在主动漏洞挖掘方面还依赖于在对程序进行分析的基础上构造预置条件(漏洞约束)。符号执行应用于大型程序是一个多种性能优化措施并行且不断地对性能调优的过程，虽然研究人员提出了一系列性能优化措施来改善符号执行的可扩展性，但当前业界和学术界普遍认为，单独使用符号执行技术对大型程序进行漏洞挖掘仍然比较困难。 2.3 漏洞可利用性分析在漏洞可利用性判定方面，现有的一些工具如!exploitable[85]、gdb-exploitable[86]、ASan[87]等，已经可以对漏洞挖掘过程中的异常或崩溃的可利用性进行初步分类。例如，!exploitable对崩溃按可利用(exploitable)、高可利用(probably exploitable)、不可利用(probably not exploitable)、未知(unknown)进行评级划分，并提供了哈希去重功能。但上述工具具有误报率高的缺陷，实际验证的时候仍然需要具有丰富漏洞挖掘和分析经验的专家进行手工逆向分析、调试进行审核确认，并编写利用漏洞的验证程序。在崩溃样本量较大时，这种方式低效而且对分析人员具有较高要求。 在自动化漏洞利用生成方面，APEG [88]使用了基于补丁对比的漏洞利用生成技术，该技术基于补丁定位漏洞位置，并采用切分技术(slicing technique)生成从输入源至漏洞点的路径约束，但APEG只适用于单检查点修补的补丁。Heelan等[89]提出了自动化提取控制流劫持的漏洞利用技术，但该技术只在提供崩溃输入和已知漏洞(如栈溢出覆盖EIP指针)的前提下适用。AGE[83]、Mayhem[90]采用预置条件的符号执行(pre-conditioned symbolic execution)技术寻找可利用的漏洞路径，并自动生成利用代码。但该技术只支持对栈溢出、格式化字符串等部分漏洞的检测；另外，其自动化生成的漏洞利用程序不支持绕过编译器或OS对抗机制如ASLR(address space layout randomization)、DEP(data execution prevention)、CFI(control-flow integrity)等。FlowStitch[91]采用了称为数据流缝合(data-flow stitching)的面向数据流的自动化漏洞利用生成技术，该技术在不改变程序控制流的情况下，利用已知的内存错误修改数据流中关键变量的方式构建漏洞利用程序。FlowStitch从已知漏洞程序中发现了多个未知的漏洞利用方式，自动生成的所有利用程序都能通过CFI和DEP, 并有部分能绕过ASLR, 进而实现信息泄露或权限提升。但该方案仍然依赖于已知的内存错误和相应的测试输入。 总体而言，漏洞可利用性判定、漏洞利用程序生成是制约实现漏洞挖掘自动化的主要瓶颈之一。 2.4 自动化漏洞挖掘2016年8月，美国国防部高等研究计划署(DARPA)举办了网络超级挑战赛(cyber grand challenge，CGC)大赛的决赛。参赛团队研发的网络推理系统(cyber reasoning system，CRS)具备自动化挖掘漏洞、自动部署补丁和进行系统防御的能力，可以快速有效地应对新的攻击，降低从攻击出现到防御生效之间的时间差，实现网络安全攻防系统的全自动化。CGC大赛提供了一个自动化的攻防比赛平台，所设置的科学的评测体系可以比较全面地评估CRS系统的自动化网络推理能力，也为以后的自动化、智能化网络攻防研究指明了方向。此外，大赛提供的赛题还成为后续研究的测试集，用于评估平台、工具的漏洞挖掘能力和性能，在关于VUzzer[32]、Steelix[35]、Driller[40]等的文献中都被采用。 但CGC大赛仍然有比较大的局限性。首先，比赛环境与真实环境有差别。为了简化比赛环境，增加可控性，为比赛定制开发的DECREE(DARPA experimental cybersecurity research evaluation environment)系统只提供了7个系统调用；其次，CRS系统漏洞挖掘能力有限，只能挖掘一些简单程序的低级漏洞，对于浏览器等比较复杂的大型程序还不能很好地分析和处理；最后，自动化、智能化能力有限，在大赛中各参赛队伍使用的仍然是传统的模糊测试、符号执行等技术，并结合预设的漏洞模式、攻击模式进行部署，没有使用机器学习、深度学习技术，缺乏自我学习的能力。CGC大赛离实现高度自动化甚至是智能化漏洞挖掘还有比较大的差距。 综上所述，模型检测、二进制比对、模糊测试、符号执行等传统技术是当前漏洞挖掘的主要手段，漏洞可利用性分析仍然依赖人工参与，以CGC大赛为代表的自动化漏洞挖掘研究离现实应用有比较大的差距，实现漏洞挖掘全自动化是当前研究的难点问题。 3 基于学习的智能化漏洞挖掘技术机器学习、深度学习[92]已经广泛应用于图像识别、语音识别、自然语言处理、医学自动诊断、搜索引擎广告推送等众多的领域，并取得了大量突破性进展。在网络安全领域，也已经应用于恶意软件检测、垃圾邮件和网络钓鱼分类、账户异常检测和日志分析等场景。 受益于上述的研究进展，研究人员在近年来也开始采用机器学习技术缓解软件漏洞挖掘领域的一些瓶颈问题。通过采用现有的机器学习、深度学习等技术，帮助相应的漏洞挖掘工具、系统在海量的漏洞相关的数据中提取经验和知识，然后根据训练生成的模型对新的样本进行分类、预测，提高对软件漏洞挖掘的精度和效率。 3.1 应用场景近年来已经有智能化漏洞挖掘技术研究基于机器学习、深度学习技术展开，如表 1所示。从应用场景看，涉及了二进制程序函数识别、函数相似性检测、测试输入生成、测试输入筛选、路径约束求解等领域；从使用的机器学习算法看，这些工作中分别采用了逻辑回归、随机森林、长短时记忆网络(LSTM)、强化学习等多种机器学习、深度学习的算法；从发表年份看，这方面的研究成果从2014年开始发表在信息安全顶级会议上，自2017年以来其数量逐渐上升，并已经成为当前信息安全研究领域的热点。 3.1.1 二进制程序函数识别二进制程序函数识别是二进制分析的基础，对于软件漏洞分析与修复，甚至恶意软件检测、协议逆向等都至关重要。由于二进制代码缺少高级语言程序中的信息，函数的识别往往比较困难，现有的反汇编分析工具具有识别正确率低的缺陷。Bao等[93]提出了ByteWeight方案，采用机器学习算法实现对二进制程序函数的识别。具体而言，首先采用加权前缀树(weighted prefix tree)学习函数的签名，并通过签名匹配二进制片段的方式识别函数。其中，树中每个节点与二进制中的字节或指令相对应，而从根节点到某个既定节点的路径代表了可能的字节或指令序列，权重则表示了对数据集采用简单线性扫描算法学习到的字节或指令序列的置信度。在鉴别函数的同时，ByteWeight采用值集分析(value set analysis, VSA)和增量控制流恢复算法实现对函数边界的识别。此种方案可以获得比IDA Pro和BAP工具[94]更高的准确率。Shin等[95]用循环神经网络算法改进了ByteWeight的性能，在模型训练时间上有了数量级上的提升，并取得了更高的准确率。 3.1.2 函数相似性检测现代应用程序中，直接调用第三方函数可以节约开发成本、提高开发效率，是被广泛接受的开发惯例。但这种方式容易导致供应链安全风险，一旦被调用函数存在漏洞，则调用这一函数的程序也可能存在漏洞。通过函数相似性检测技术可以实现对不同程序间的同源性漏洞的检测，但当前基于图的相似度匹配的方法具有计算量大、准确率低的缺陷。Xu等[97]提出了Gemini方案，Gemini把函数控制流图CFG简化为带节点属性(数字特征)的控制流图(ACFG)，然后用Structure2vec算法转化为数字向量，使用Siamese网络架构训练，实现相似的函数距离近的目标，最后通过计算函数向量距离实现函数相似性的检测。Gemini能应用到跨平台的二进制函数相似性检测，并取得了比其他基于图相似性匹配的工具(如Genius[98])更高的准确率和检测效率。 3.1.3 测试输入生成在软件漏洞挖掘中，构造代码覆盖率高或脆弱性导向型的测试输入能提高漏洞挖掘的效率和针对性。利用机器学习技术可以对海量测试样本进行分析、学习，并利用生成模型指导生成更高质量的测试输入样本。Godefroid等[99]首次把模糊测试中的高结构化样本生成问题转换成了NLP领域的文本生成问题，采用了Char-RNN(recurrent neural network)模型实现对PDF文件格式中的obj语法的学习，并用训练好的模型生成具有多样性的obj对象和PDF文件。She等[100]提出了采用深度神经网络指导模糊测试输入生成的方案Neuzz。Neuzz采用了CNN(convolutional neural network)学习连续可微的神经程序(neural program)，用来近似模拟目标程序中的实际逻辑，然后通过对学习好的神经程序求梯度的方式指导测试输入生成，以此取得对目标程序更高的分支覆盖。与AFL相比，Neuzz在6个不同的常用程序中多发现了70倍的分支，并多发现了36个缺陷。Bottinger等[101]提出了深度强化学习增强的模糊测试技术，借助Markov模型把模糊测试问题转化成强化学习问题，并利用Q-learning算法优化预定义的奖励函数。实验结果表明，使用深度强化学习增强的模糊测试技术比随机变异能取得更高的代码覆盖率。Nichols等[102]提出了生成对抗网络(GAN)增强模糊测试技术。该方案不依赖于大数据量的样本训练，并能比AFL的随机变异和基于LSTM模型引导的变异更高效地发现更多的路径。 3.1.4 测试输入筛选动态漏洞挖掘依赖于测试输入的实际运行来检测是否能触发崩溃或漏洞，当有海量样本需要被执行测试时，会非常耗时且低效。测试样本筛选的目的是从海量样本中选择更有可能触发新路径或触发漏洞的测试输入。使用机器学习技术通过对大量的测试样本进行处理，从而决定哪些应该被进一步分析，尽可能准确地对样本进行标记，然后再用于寻找安全漏洞。Rajpal等[103]使用LSTM、序列到序列(Seq2seq)等神经网络学习模糊测试过程中的历史变异样本及代码覆盖率等数据，训练出能指导对输入文件进行定向变异的模型。实验结果表明，使用这种方法能获得比随机变异更高的代码覆盖率。但文[103]中采用的热力图生成模型仅仅依赖于基础样本以及能带来代码覆盖率增长的变异样本，训练生成的模型并没有记录测试输入与变异点、变异方法、代码覆盖增长情况之间的关联信息，基于这种模型生成的热力图不能精确标注记录测试输入中变异点与代码覆盖之间的关联性，因此热力图可能带有误标注和漏标注。此外，Spieker等[104]还提出了采用强化学习的算法优先筛选漏洞导向型的测试用例，应用在持续集成(continuous integration, CI)及回归测试(regression test)中。 2.1.5 路径约束求解 模糊测试，特别是代码覆盖率制导的模糊测试(如AFL)，侧重于筛选可以覆盖新路径的样本为种子文件，但对种子文件变异时并没有充分利用程序数据流等信息指导变异，这使得变异盲目低效，生成样本冗余。现有的一些启发式优化工作如Steelix[35]能够对魔术字节跟踪定位，但无法对其他路径约束求解。具备路径约束求解能力是符号执行比模糊测试等漏洞挖掘技术更先进的体现，也使得符号执行在理论上具备了系统性探索程序执行路径的能力。但复杂程序中的路径爆炸问题带来的对SMT求解器的频繁调用，以及SMT求解器本身的能力和效率的不足，使得约束求解占用了符号执行中主要的性能开销，约束求解问题也成为符号执行中面临的主要瓶颈问题之一。Chen等[105]提出了Angora，采用污点追踪测试输入中影响条件分支的字节，然后使用梯度下降的方式对变异后生成的路径约束进行求解。这种方式避免了符号执行调用SMT求解器可能带来的开销以及复杂约束不可解的问题，但梯度下降对目标函数不可导或存在不可导点时，仍然会出现求解困难的问题。 3.1.6 漏洞程序筛选传统的漏洞挖掘技术如模糊测试、符号执行等已经成功地从各类软件中发现了大量的漏洞，但当被测试程序复杂且数量庞大的时候，使用这些技术挖掘漏洞显得效率低下。VDiscover[106]采用机器学习技术从大量的程序中快速筛选更有可能带有漏洞的程序。具体而言，VDiscover收集程序中的标准C库函数调用序列及其参数的动态值作为静态和动态特征，并对其做标注，然后采用带监督的机器学习算法(如随机森林，逻辑回归等)训练模型，当有新的被测试程序需要分类的时候，训练好的模型可以直接对提取的相应特征进行预判和标注。 VDiscover首次验证了采用机器学习技术筛选漏洞程序的可行性，但其采用人工定义和提取特征的方法具有较大的局限性。漏洞成因复杂，VDiscover提取的程序静态特征和动态特征并不能精确地表征各种类型的漏洞, 这可能造成较高的误报和漏报。另外，采用机器学习直接对漏洞程序进行预测的方式无法生成测试用例来动态验证漏洞。 3.1.7 源代码漏洞点预测传统静态漏洞挖掘技术中，依赖于人工定义漏洞模式的检测方式经常会导致较高的漏报率。Li等[107]提出了VulDeePecker方案，采用BLSTM算法对C/C++源代码中的漏洞点进行预测。鉴于传统的漏洞分类过细导致难以抽象提取为特征的问题，其设计了能覆盖多种漏洞类型的特征，这种方式不以函数为粒度，只考虑数据流保留语义上关联的代码行作为代码小部件(code gadgets)对程序进行表征，然后转换成向量作为深度学习的输入。但VulDeePecker方案中，代码小部件转换成向量的过程存在较大的信息丢失问题；另外，该方案只支持对缓冲区溢出和资源管理相关的漏洞的检测。 3.1.8 其他此外，机器学习还应用于模糊测试参数配置预测[108]和漏洞可利用性分析[109-110]等场景中。 3.2 面临的问题3.2.1 机器学习的局限性虽然以机器学习为代表的人工智能技术取得了非常瞩目的进展，但其本身也面临着巨大的挑战。基于机器学习的漏洞挖掘技术受限于算法本身的能力，也受限于算法本身的安全性和健壮性。 当前的机器学习技术并没有解决人工智能的核心问题，不是通向人工智能的最佳途径[111]。传统的机器学习技术需要人工设计、构建特征，然后转换成向量作为机器学习算法的输入，不具备对原始数据自动提取特征的能力，严重依赖于专家知识。深度学习具有在高维数据中自动提取特征的能力，并已经取得了广泛应用，但其仍然面临着持续学习、数据饥饿、可解释性等问题[111-112]。 另外，当前的机器学习算法的安全性和健壮性问题也逐渐暴露出来。一方面，常用机器学习工具存在漏洞。Stevens等[113]利用模糊测试方法挖掘出了OpenCVScikit-Learn、NumPy等常用的机器学习软件的库文件中的堆溢出等漏洞，这些漏洞能导致Dos攻击或任意代码执行，或直接修改分类判定结果。另一方面，机器学习算法本身的健壮性问题容易导致对抗式攻击(adversarial attack)[114-119]。对抗式攻击又称为对抗性训练或对抗性机器学习，通过在数据集中注入被污染的数据而欺骗模型做出错误的判断。此外，健壮性问题还容易导致污染攻击[120-122]，逃逸攻击[123-126]、模型倒置攻击[127-128]，模型(参数)提取攻击[129-131]等，这类攻击通常具有较高的隐蔽性。 3.2.2 算法选择机器学习、深度学习虽然已经在图像识别、自然语言处理等领域已经有比较成熟的应用，但在漏洞挖掘领域，不同的应用场景下可能只适用于部分机器学习算法，甚至同一场景中，选择不同的适用算法也会导致结果的显著差异。但现有的研究工作大部分只凭经验选取了部分机器学习算法，并未对各类算法性能进行较系统性的比对。如在文[103, 107]中采用了LSTM等循环神经网络算法实现可变长序列预测和文本生成，但当前CNN已经可以取得比LSTM更好的性能[132-133]。其次，还要考虑根据数据量大小的问题，如果数据量小，人工指定规则的传统机器学习可能会有更好地性能。深度学习虽然能自动对各种简单的特征学习并组合成更加复杂的特征，在特征提取上比传统的机器学习算法具有更大的优势，但深度学习更适合大数据量的学习。另外，对同一种算法的不同参数配置也能产生不同的模型，需要在对模型进行评估的基础上选择泛化误差小的模型。 3.2.3 数据收集机器学习、深度学习需要大量的样本，特别是深度学习在数据量不足时容易导致过拟合的问题。目前，在现有工作中针对不同应用场景和学习任务，收集的样本对象包括了二进制程序、PDF文件、C/C++源码、IOT固件等，这些数据的收集方式参差不齐，如模糊测试生成、符号执行生成、人工编译生成、网络爬虫等。对于常用的文件格式如DOC、PDF、SWF等，采用网络爬虫获取测试输入集是比较常用的方法。爬取方式可按特定文件扩展名(后缀)为筛选条件进行下载，或者按特定魔术字节或其他签名的方式下载，爬取的结果很容易就能达到TB数量级(如Skyfire[133])。但对于其他数据如崩溃样本、漏洞程序等，因其具有稀缺性，存在收集困难的问题。当前缺少通用的、认可度较高的漏洞相关的数据集可供基于机器学习、深度学习的技术进行训练和测试。 收集漏洞相关的大数据集能为基于机器学习的智能化漏洞挖掘和分析提供学习素材，也关系到训练模型的效果。构建面向机器学习的大规模漏洞数据集对后续的研究将起到至关重要的作用，应当成为未来研究的重点问题之一。 3.2.4 特征选择传统机器学习算法分类、预测的准确性既与数据量的大小有关，也依赖于从数据中提取的特征。在漏洞挖掘中，程序结构和执行信息与漏洞并没有直接的关联性，如何从程序中筛选出漏洞相关的显著特征、摒弃非显著特征，需要结合机器学习算法、程序执行环境及漏洞产生原理等多方面考虑。例如在二进制程序中，静态特征可以从调用图、控制流图、数据流图等获取(同时要考虑图信息获取不精确的问题)，动态特征可以通过插桩执行跟踪(trace)实际函数调用以及调用参数的方式捕获。另外，还要考虑动、静态特征提取时带来的开销和可扩展性问题。如在二进制程序中，对目标程序建立各种基于图的结构计算量较大，动态特征提取则依赖于实际执行插桩跟踪测试程序，而插桩特别是动态插桩会带来比较大的开销，甚至会影响程序实际执行时的内存空间布局。 综上所述，探索基于学习的漏洞挖掘技术，研究机器学习算法对软件漏洞挖掘中的不同应用场景的适用性，借助机器学习的分类、预测能力甚至深度学习的自动特征提取能力来缓解、突破传统技术的瓶颈问题，是当前智能化漏洞挖掘研究的热点和难点。 4 结论与展望本文分析了传统漏洞挖掘技术及基于学习的智能化漏洞挖掘技术的研究进展，针对这些技术呈现出的自动化、智能化的趋势及面临的问题进行了深入的调研分析、归类和总结。 下一步的研究应从以下2点展开： 1) 提高漏洞挖掘的效率与精度 漏洞挖掘是计算密集型的工作，与软件的规模和复杂度、硬件系统性能、采用的分析技术都有非常大的关联性，在研究实践中往往需要根据这些影响因素动态调整程序分析策略，在分析效率与分析深度之间取得较好的平衡和折中。一方面，需要研究轻量级分析技术、启发式状态空间探测技术(如脆弱路径筛选、低频路径筛选等)，在较小的开销内增强漏洞挖掘的导向性。另一方面，需要研究高效的规模化、并行化分析方法。漏洞挖掘在算法、分析数据存储和处理方面都有显著特征，现有的技术对大型复杂程序分析效率低下，没有充分利用高性能硬件设备提供的并行处理能力。探索规模化、并行化漏洞挖掘技术，增强对异构化计算资源的利用率，能很好应对大型复杂软件快速分析的需求。 2) 提高漏洞挖掘的自动化与智能化 在自动化方面，研究不依赖或较少依赖于人工参与的漏洞挖掘技术如漏洞利用程序自动生成、高结构化测试输入生成等仍然是当前研究的难点，这对实现全自动的漏洞挖掘甚至网络攻防都有重要的推进作用。在智能化方面，需要研究机器学习(如深度学习、强化学习、生成对抗网络等)在漏洞挖掘领域的应用。适用场景还应包括脆弱路径筛选、高结构化输入生成、约束求解配置预测等。基于机器学习的漏洞挖掘技术为解决传统漏洞挖掘技术的一些瓶颈问题提供了新途径，既能提升漏洞挖掘的自动化程度，也能提高漏洞挖掘的效率和精度。","content":"<h1 id=\"Abstract\"><a href=\"#Abstract\" class=\"headerlink\" title=\"Abstract\"></a>Abstract</h1><p>近年来，随着软件规模和复杂度的日益增加，软件漏洞挖掘技术正逐渐向高度自动化和智能化演变，该文从传统漏洞挖掘技术和基于学习的智能化漏洞挖掘技术两方面深入调研和分析了相关的研究进展。首先，从静态和动态挖掘技术2方面详细介绍了传统漏洞挖掘技术的研究现状，涉及的技术包括模型检测、二进制比对、模糊测试、符号执行以及漏洞可利用性分析等，并分析了各项技术存在的问题，提出当前的研究难点是实现漏洞挖掘全自动化。然后，介绍了机器学习和深度学习技术在漏洞挖掘领域的应用，具体应用场景包括二进制函数识别、函数相似性检测、测试输入生成、路径约束求解等，并提出了其存在的机器学习算法不够健壮安全、算法选择依靠经验、数据样本不足、特征选择依赖专家知识等问题。最后，对未来研究工作进行了展望，提出应该围绕提高漏洞挖掘的精度和效率、提高自动化和智能化的程度这2方面展开工作。</p>\n<table>\n<thead>\n<tr>\n<th>relevant information</th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><em>作者</em></td>\n<td>邹权臣，张涛，吴润浦, 马金鑫, 李美聪, 陈晨,侯长玉</td>\n</tr>\n<tr>\n<td><em>单位</em></td>\n<td>中国信息安全测评中心,空军工程大学 信息与导航学院,北京邮电大学 网络空间安全学院,北京中测安华科技有限公司</td>\n</tr>\n<tr>\n<td><em>出处</em></td>\n<td>清华大学学报</td>\n</tr>\n<tr>\n<td><em>原文地址</em></td>\n<td><a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#outline_anchor_17\" target=\"_blank\" rel=\"noopener\">http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#outline_anchor_17</a></td>\n</tr>\n<tr>\n<td><em>源码地址</em></td>\n<td></td>\n</tr>\n<tr>\n<td><em>发表时间</em></td>\n<td>2018年</td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"1-简介\"><a href=\"#1-简介\" class=\"headerlink\" title=\"1. 简介\"></a>1. 简介</h1><p>漏洞信息的不对称性已经成为导致网络战争中的实力对比悬殊的关键因素。从早年爆发的蠕虫王、冲击波、震荡波病毒，到近年来爆发的WannaCry病毒，都借助了软件或系统的安全漏洞进行传播。另外，高级的网络攻击(如APT攻击)甚至会基于多个漏洞交叉、组合使用，目的是绕过防火墙、杀毒软件、入侵检测系统等，摧毁隔离网的安全性，突破核心网络节点而进入内网，进行后续的渗透攻击(如窃取、修改、加密重要数据，摧毁核心设施等)。特别是未公开的0day漏洞常常被当成秘密的终极武器使用，有时候甚至能起到决定性的作用。</p>\n<p>鉴于软件漏洞在网络攻防中的重要性，各大软件厂商及高校、科研院所的研究人员对漏洞挖掘技术展开了大量的研究。当前，常用的漏洞挖掘技术包括模型检测、模糊测试、符号执行、二进制比对等，这些传统的漏洞挖掘技术在理论研究上已经比较成熟，并已从各类软件中挖掘出大量漏洞。其中大部分的技术如模糊测试、符号执行等都已基本实现自动化，可以在不需要或较少的人工干预的前提下，针对被测试程序和输入数据的不同特点，借助各种程序动、静态分析技术，寻找分析深度和分析效率之间的平衡点，缓解代码覆盖率低、扩展性差等问题；目的是提高漏洞挖掘的效率，实现在更短的时间内发现更多或更深层次的漏洞。</p>\n<p>机器学习、深度学习的研究进展带动了其在软件漏洞挖掘领域的应用，目前已经开展了一些探索性的工作，如二进制函数相似性识别、函数相似性检测、测试输入生成、路径约束求解等，这些应用为解决传统漏洞挖掘技术的瓶颈问题提供了新的思路，也使得软件漏洞挖掘逐渐变得智能化。随着机器学习、深度学习研究的爆炸式发展，以及这方面研究积累的数据集的增多，将可能成为软件漏洞挖掘技术发展的关键点之一。</p>\n<p>本文以近年来软件漏洞挖掘技术所呈现出的自动化和智能化的趋势作为切入点，介绍了传统漏洞挖掘技术和基于学习的智能化漏洞挖掘技术的研究进展。首先，本文从静态和动态漏洞挖掘两方面对传统的漏洞挖掘技术进行了分类分析，指出了各自的优势和面临的问题；并介绍了漏洞可利用性分析以及自动化漏洞挖掘(如CGC大赛)的研究进展，指出漏洞挖掘的全自动化是当前研究的难点问题。然后，对基于学习的智能化软件漏洞挖掘技术进行了分类，并深入分析了二进制函数识别、函数相似性检测等不同应用场景的研究工作，归纳总结了其面临的机器学习算法不够健壮安全、算法选择依靠经验、数据样本不足、特征选择依赖专家知识等四大问题。最后进行了总结和展望，指出未来应在提高漏洞挖掘的精度和效率，以及自动化和智能化方面展开研究。</p>\n<h1 id=\"2-传统漏洞挖掘技术\"><a href=\"#2-传统漏洞挖掘技术\" class=\"headerlink\" title=\"2.传统漏洞挖掘技术\"></a>2.传统漏洞挖掘技术</h1><p>传统的漏洞挖掘技术主要可分为静态和动态漏洞挖掘技术，漏洞可利用性分析也已经成为漏洞挖掘的重要环节，如[图 1]所示</p>\n<p><img src=\"/2019/04/02/From-automation-to-intelligence-Survey-of-research-on-vulnerability-discovery-techniques/1.jpg\" alt=\"\"></p>\n<h2 id=\"2-1-静态漏洞挖掘\"><a href=\"#2-1-静态漏洞挖掘\" class=\"headerlink\" title=\"2.1 静态漏洞挖掘\"></a>2.1 静态漏洞挖掘</h2><p>静态漏洞挖掘是指在不运行目标程序的前提下分析目标程序(源代码或二进制)的词法、语法和语义等，并结合程序的数据流、控制流信息，通过类型推导、安全规则检查、模型检测等技术挖掘程序中的漏洞。静态漏洞挖掘是常用的软件测试技术，在软件测试中占有非常重要的地位。具有代表性的静态漏洞挖掘工具有面向C/C++源码的Cppcheck[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b1\" target=\"_blank\" rel=\"noopener\">1</a>]、FlawFinder[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b2\" target=\"_blank\" rel=\"noopener\">2</a>], 面向PHP源码的RIPS[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b3\" target=\"_blank\" rel=\"noopener\">3</a>], 面向JAVA源码的FindBugs[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b4\" target=\"_blank\" rel=\"noopener\">4</a>]，以及能支持多种类型目标对象的著名商业化漏洞检测工具VeraCode[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b5\" target=\"_blank\" rel=\"noopener\">5</a>]、Fortify[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b6\" target=\"_blank\" rel=\"noopener\">6</a>]、Coverity[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b7\" target=\"_blank\" rel=\"noopener\">7</a>]、Checkmarx[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b8\" target=\"_blank\" rel=\"noopener\">8</a>]等。另外，LLVM[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b9\" target=\"_blank\" rel=\"noopener\">9</a>]、Clang[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b10\" target=\"_blank\" rel=\"noopener\">10</a>]等编译器也提供了大量的静态检测功能，能在编译阶段实现对源代码的安全性检查。</p>\n<p>针对目标程序的不同形式，采用的静态分析技术也不尽相同。本节将按源代码和二进制2种目标程序分别介绍静态漏洞挖掘技术的研究现状。</p>\n<p>面向源代码的漏洞挖掘主要采用基于中间表示的分析和基于逻辑推理的分析技术[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b11\" target=\"_blank\" rel=\"noopener\">11</a>]。其中，基于中间表示的分析技术主要包括数据流分析、控制流分析、污点分析、符号执行等。Pixy[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b12\" target=\"_blank\" rel=\"noopener\">12</a>]采用了取值分析、污点分析、指针别名分析等静态分析技术实现对PHP源码中的SQL注入和跨站脚本等漏洞的检测。Prefix[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b13\" target=\"_blank\" rel=\"noopener\">13</a>]采用了静态符号执行技术模拟执行C/C++源码程序，并采用约束求解对程序中的部分路径进行检测。Melange[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b14\" target=\"_blank\" rel=\"noopener\">14</a>]采用数据流分析的框架，通过对程序进行数据流、控制流等复杂分析检测安全相关的漏洞，并支持对大型C/C++源码程序的分析。K-Miner[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b15\" target=\"_blank\" rel=\"noopener\">15</a>]利用内核代码中高度标准化的接口实现了可扩展性良好的指针分析以及全局的上下文敏感的分析技术，支持对空指针引用、指针释放后重引用(use-after-free, UAF)、指针重释放(double free)、双重检查锁定(double-checked lock)等内存崩溃漏洞的检测。基于逻辑推理的分析技术主要是指模型检测，如MOPS[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b16\" target=\"_blank\" rel=\"noopener\">16</a>]、BLAST[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b17\" target=\"_blank\" rel=\"noopener\">17</a>]、SLAM[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b18\" target=\"_blank\" rel=\"noopener\">18</a>]是典型的面向C程序的模型检测工具，其基本思路是将程序结构抽象为状态机(布尔程序)，然后基于归纳的安全属性对状态机进行遍历，检测其中存在的漏洞。</p>\n<p>面向二进制程序的静态漏洞的挖掘技术由于缺少源代码中的结构化信息，面临着值集分析(vaule-set analysis，VSA)[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b19\" target=\"_blank\" rel=\"noopener\">19</a>]与控制流恢复[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b20\" target=\"_blank\" rel=\"noopener\">20</a>-<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b25\" target=\"_blank\" rel=\"noopener\">25</a>]不精确的问题。当前，二进制静态漏洞挖掘技术主要包括基于模式匹配和基于补丁比对的技术。其中，在基于模式匹配的漏洞挖掘技术方面，GUEB[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b26\" target=\"_blank\" rel=\"noopener\">26</a>]提出了二进制程序中UAF漏洞模式，并基于此模式挖掘出了ProFTPD程序中的漏洞。具体而言，首先抽象出二进制函数中的内存模型，然后采用VSA分析技术追踪堆分配和释放指令相关的操作变量，并基于此建立UAF模式。LoongChecker[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b27\" target=\"_blank\" rel=\"noopener\">27</a>]使用了称为半仿真的二进制静态漏洞挖掘技术。通过VSA分析和数据依赖分析(data dependence analysis，DDA)技术实现对变量地址的追踪和数据流依赖分析，并采用污点分析技术检测潜在的漏洞。Saluki[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b28\" target=\"_blank\" rel=\"noopener\">28</a>]使用了路径敏感和上下文敏感的数据依赖分析，并采用完备的逻辑系统推理检测程序中的漏洞。在基于补丁比对的漏洞挖掘技术方面，PVDF[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b29\" target=\"_blank\" rel=\"noopener\">29</a>]以二进制漏洞程序(带有权限提升漏洞)和补丁作为输入，从比对中提取多维属性描述的漏洞语义信息，并应用于后续的模糊测试中。BinHunt[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b30\" target=\"_blank\" rel=\"noopener\">30</a>]通过对二进制程序和带补丁的二进制程序间的比对提取漏洞相关的语义信息。具体而言，就是把二进制程序翻译成中间表示，并在此基础上构建控制流图，基于控制流图对比程序间的差异，提取相关的约束，然后采用符号执行技术进行验证，以此找出补丁对应的漏洞。</p>\n<p>静态漏洞挖掘技术直接对目标程序进行分析，不需要构造程序的执行环境，能提取较为完整的控制流等信息，可能发现动态漏洞挖掘技术难以发现的漏洞。但是，一方面，由于静态漏洞挖掘技术往往依赖于人工构造的漏洞模式，对先验知识依赖性较大；另一方面，因为无法获得程序实际动态运行过程中的上下文信息，静态漏洞挖掘技术具有精度低、误报率高的缺陷。</p>\n<h2 id=\"2-2-动态漏洞挖掘\"><a href=\"#2-2-动态漏洞挖掘\" class=\"headerlink\" title=\"2.2 动态漏洞挖掘\"></a>2.2 动态漏洞挖掘</h2><p>动态漏洞挖掘技术是指在实际执行程序的基础上采用的分析技术，常用的动态漏洞挖掘技术包括模糊测试、符号执行等。</p>\n<h3 id=\"2-2-1-模糊测试\"><a href=\"#2-2-1-模糊测试\" class=\"headerlink\" title=\"2.2.1 模糊测试\"></a>2.2.1 模糊测试</h3><p>模糊测试(fuzzing)是一种自动化或者半自动化的软件测试技术，通过构造随机的、非预期的畸形数据作为程序的输入，并监控程序执行过程中可能产生的异常，之后将这些异常作为分析的起点，确定漏洞的可利用性。模糊测试技术可扩展性好，能对大型商业软件进行测试，是当前最有效的用于挖掘通用程序漏洞的分析技术，已经被广泛用于如微软、谷歌和Adobe等主流软件公司的软件产品测试和安全审计，也是当前安全公司和研究人员用于挖掘漏洞的主要方法之一。</p>\n<p>按程序内部结构分析的量级轻重程度分，模糊测试技术主要可以分为白盒、黑盒、灰盒模糊测试。其中，白盒模糊测试是在对被测试程程序内部结构、逻辑进行系统性分析的基础上进行测试；黑盒模糊测试把程序当成黑盒处理，不对程序内部进行分析；灰盒模糊测试介于黑盒和白盒模糊测试之间，在对程序进行轻量级分析的基础上进行测试。按样本生成方式划分，模糊测试的测试输入可分为基于变异和基于生成2种方式。其中，基于变异的模糊测试在修改已知测试输入的基础上生成新的测试用例，而基于生成的模糊测试则是直接在已知输入样本格式的基础上生成新的测试输入。</p>\n<p>根据不同的研究侧重点，本文分别介绍基于变异的模糊测试、基于生成的模糊测试和其他优化策略。</p>\n<h4 id=\"1-基于变异的模糊测试。\"><a href=\"#1-基于变异的模糊测试。\" class=\"headerlink\" title=\"1) 基于变异的模糊测试。\"></a>1) 基于变异的模糊测试。</h4><p>在基于变异的模糊测试方面，研究人员借助程序执行环境信息和程序分析技术，有导向性地辅助、引导模糊测试的变异，具有代表性的工作有AFL[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b31\" target=\"_blank\" rel=\"noopener\">31</a>]、VUzzer[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b32\" target=\"_blank\" rel=\"noopener\">32</a>]、Honggfuzz[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b33\" target=\"_blank\" rel=\"noopener\">33</a>]、libFuzzer[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b34\" target=\"_blank\" rel=\"noopener\">34</a>]、Steelix[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b35\" target=\"_blank\" rel=\"noopener\">35</a>]、T-Fuzz[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b36\" target=\"_blank\" rel=\"noopener\">36</a>]、AFLFast[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b37\" target=\"_blank\" rel=\"noopener\">37</a>]、AFLGo[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b38\" target=\"_blank\" rel=\"noopener\">38</a>]、Driller[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b39\" target=\"_blank\" rel=\"noopener\">39</a>]等。</p>\n<ul>\n<li><strong>a) 代码覆盖率制导</strong></li>\n</ul>\n<p>AFL[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b31\" target=\"_blank\" rel=\"noopener\">31</a>]使用进化算法(evolutionary algorithms)生成测试输入，在正常输入的基础上，通过简单的反馈回路的方式评估测试输入的质量。AFL会保留任何能触发新路径的测试输入，并对其进行变异及检查能否触发崩溃。AFL已经在Mozilla Firefox、FFmpeg、OpenSSL等软件中发现了大量的漏洞。但AFL也存在较大的缺陷：首先，变异的位置以及变异的方式是盲目的，缺少更进一步的筛选和变异策略，依赖这种方式很难发现深层次的漏洞；其次，通过哈希函数检测分支覆盖筛选种子的方式具有较高的误报率，其哈希位图(bitmap)只有64 kB大小，导致普遍存在哈希碰撞的情况，进而导致其分支覆盖统计存在漏报，进而影响种子筛选，间接影响了代码覆盖率的增长。CollFuzz[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b40\" target=\"_blank\" rel=\"noopener\">40</a>]采用静态控制流图信息作为辅助，并设计了能避免哈希碰撞的基本块ID分配策略，从而实现比AFL更精确的分支覆盖检测。</p>\n<ul>\n<li><strong>b) 污点分析辅助</strong></li>\n</ul>\n<p>BuzzFuzz[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b41\" target=\"_blank\" rel=\"noopener\">41</a>]使用动态污点分析技术自动定位影响程序脆弱点的测试输入中的字段，然后保留其他语法部分内容，只对这些字段进行变异。这样既能通过语法检查，也能有针对性地进行变异，提高漏洞挖掘的效率。TaintScope[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b42\" target=\"_blank\" rel=\"noopener\">42</a>]使用污点分析技术推断程序中与校验和处理相关的代码，以此帮助模糊测试工具绕过校验和检查。</p>\n<ul>\n<li><strong>c) 符号执行制导</strong></li>\n</ul>\n<p>Driller[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b39\" target=\"_blank\" rel=\"noopener\">39</a>]采用模糊测试和符号执行交替探索程序执行路径，解决模糊测试陷入代码覆盖率增长慢的情况，这样能引导模糊测试探索到程序更深层次的节点，也能直接避免符号执行可能带来的路径爆炸问题。但文[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b39\" target=\"_blank\" rel=\"noopener\">39</a>]和[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b43\" target=\"_blank\" rel=\"noopener\">43</a>]等的实验结果表明，使用符号执行对模糊测试中部分路径约束求解时，仍然有很大一部分路径出现求解失败的情况(文[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b39\" target=\"_blank\" rel=\"noopener\">39</a>]实验中有41个测试程序陷入了较浅路径，使用符号执行对其求解时只有13个程序能够生成新的测试输入)。因此，基于符号执行增强的模糊测试技术仍然会受限于符号执行中的约束求解问题，符号执行的引入可能会弱化模糊测试本身的可扩展性。</p>\n<ul>\n<li><strong>d) 控制流和数据流信息制导</strong></li>\n</ul>\n<p>VUzzer[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b32\" target=\"_blank\" rel=\"noopener\">32</a>]在“轻量级”的动、静态分析基础上提取了程序的控制流和数据流信息引导变异。具体而言，VUzzer先在静态控制流分析基础上计算基本块的权重，然后在动态执行时筛选权重更高即路径更深的执行路径对应的测试输入为种子文件，并用动态污点分析定位变异点。相比AFL、Driller，VUzzer有更好的种子筛选、路径探索策略以及污染点定位、变异策略，能定向引导探索更深的执行路径，并定点变异。在DARPA CGC和LAVA测试集以及部分常用应用程序上，VUzzer都取得了更好的效果(用更少的测试输入挖掘出了更多的漏洞)。Steelix[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b35\" target=\"_blank\" rel=\"noopener\">35</a>]采用了轻量级的静态分析和二进制插桩技术提取代码覆盖率信息和魔术字节(magic byte)比较信息等作为程序状态信息引导变异。这种方式能在较小的开销下定位魔术字节在测试输入中的位置，进而辅助模糊测试工具更高效地生成能通过魔术字节检验的测试输入。</p>\n<h4 id=\"2-基于生成的模糊测试。\"><a href=\"#2-基于生成的模糊测试。\" class=\"headerlink\" title=\"2) 基于生成的模糊测试。\"></a>2) 基于生成的模糊测试。</h4><p>基于生成的模糊测试主要基于模型或者语法生成能满足程序语法和语义检查的测试输入，常用于高度结构化的测试输入生成。</p>\n<ul>\n<li><strong>a) 基于模型的模糊测试</strong></li>\n</ul>\n<p>Peach[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b44\" target=\"_blank\" rel=\"noopener\">44</a>]、Spike[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b45\" target=\"_blank\" rel=\"noopener\">45</a>]是典型的基于模型的模糊测试工具(Peach也具有基于变异进行模糊测试的功能)，通过对输入格式定制编写数据模型(data model)和状态模型(state model)的方式指定输入数据的类型和依赖关系, 并结合变异策略生成测试输入。其中Peach通过编写配置文件实现对样本格式的约束，而Spike需要利用提供的编程接口来对样本格式进行约束。Pham等[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b46\" target=\"_blank\" rel=\"noopener\">46</a>]结合输入模型和符号执行技术生成测试输入，使用符号执行鉴别输入格式约束能有效保证输入的合法性。</p>\n<ul>\n<li><strong>b) 基于语法的模糊测试</strong></li>\n</ul>\n<p>CSmith[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b47\" target=\"_blank\" rel=\"noopener\">47</a>]根据C语言语法生成C程序源码，实现对C编译器的模糊测试。在C源码生成方面，CSmith随机选取符合生成规则和语法规则的C程序，这种方法能避免因未定义和未声明而导致编译报错的情况出现。LangFuzz[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b48\" target=\"_blank\" rel=\"noopener\">48</a>]基于语法学习测试集中的代码片段，并进行片段重组生成新的测试输入。在测试输入集选择上，LangFuzz假设基于问题测试集重组生成的测试输入比随机收集的测试输入更有可能触发程序缺陷。IFuzzer[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b49\" target=\"_blank\" rel=\"noopener\">49</a>]使用上下文无关的语言语法作为输入，并使用语法生成解析树，然后从测试集中抽取代码片段，并使用遗传进化算法对代码片段重组生成新的测试输入。Jsfunfuzz[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b50\" target=\"_blank\" rel=\"noopener\">50</a>]使用了历史漏洞知识和硬编码规则生成测试输入，以Mozilla浏览器中的Javascript解释器为测试目标，发现了1 800多个缺陷。Dewey等[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b51\" target=\"_blank\" rel=\"noopener\">51</a>]使用了称为约束逻辑编程(constraint logic programming, CLP)的技术生成测试输入。通过指定句法特征和语义行为，CLP能生成满足语法和语义合法性的测试输入。</p>\n<h4 id=\"3-其他优化策略。\"><a href=\"#3-其他优化策略。\" class=\"headerlink\" title=\"3) 其他优化策略。\"></a>3) 其他优化策略。</h4><p>除了上述进展外，还有一些重要研究侧重于种子筛选策略优化[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b37\" target=\"_blank\" rel=\"noopener\">37</a>-<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b38\" target=\"_blank\" rel=\"noopener\">38</a>, <a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b52\" target=\"_blank\" rel=\"noopener\">52</a>-<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b55\" target=\"_blank\" rel=\"noopener\">55</a>]和调度策略优化[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b37\" target=\"_blank\" rel=\"noopener\">37</a>-<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b38\" target=\"_blank\" rel=\"noopener\">38</a>]。Rebert等[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b53\" target=\"_blank\" rel=\"noopener\">53</a>]把种子筛选问题转化成整数线性规划问题，并以挖掘更多漏洞为目标提出了多种种子筛选策略。AFLFast[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b37\" target=\"_blank\" rel=\"noopener\">37</a>]采用了把模糊测试问题建模为Markov模型，并采用特定的策略引导AFL优先选择低频路径和变异频率较低的文件作为种子文件进行变异，以此在相同的测试时间内探索更多的路径。AFLGo[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b38\" target=\"_blank\" rel=\"noopener\">38</a>]采用了模拟退火(simulated annealing，SA)算法对能逼近特定目标位置的测试输入分配更高的能量，并优先选取高能量种子文件进行变异。AFLGo的实验结果表明，这种导向型灰盒模糊测试(directed greybox fuzzing，DFG)比符号执行引导的白盒模糊测试和非导向型模糊测试具有更好的性能、更高的代码覆盖率并可挖掘出更多的漏洞。</p>\n<p>总体而言，模糊测试是当前挖掘漏洞最有效的方法，比其他漏洞挖掘技术更能应对复杂的程序，具有可扩展性好的优势。但在大规模漏洞分析测试中，模糊测试方法仍然依赖于种子输入的质量，依赖于对测试输入对象格式的深度理解和定制，存在测试冗余、测试攻击面模糊、测试路径盲目性较高等问题。另外，目前模糊测试也存在整体测试时间长、生成单个测试用例漏洞触发能力弱的问题。</p>\n<h3 id=\"2-2-2-符号执行\"><a href=\"#2-2-2-符号执行\" class=\"headerlink\" title=\"2.2.2 符号执行\"></a>2.2.2 符号执行</h3><p>符号执行于20世纪70年代被提出[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b56\" target=\"_blank\" rel=\"noopener\">56</a>-<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b59\" target=\"_blank\" rel=\"noopener\">59</a>]，是一种能够系统性探索程序执行路径的程序分析技术，通过对程序执行过程中的被污染的分支条件及其相关变量的收集和翻译，生成路径约束条件，然后使用可满足模理论(SMT)求解器进行求解, 判断路径的可达性以及生成相应的测试输入。通过这种方式产生的测试输入与执行路径之间具有一对一的关系，能够避免冗余测试输入的产生，进而能有效解决模糊测试冗余测试用例过多导致的代码覆盖率增长慢的问题。</p>\n<p>符号执行技术应用已经被学术和工业界应用在漏洞挖掘领域。自从符号执行特别是动态符号执行技术被提出以来，已经有很多相关的工具被应用到实际的软件测试当中，如SAGE[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b60\" target=\"_blank\" rel=\"noopener\">60</a>]、S2E[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b61\" target=\"_blank\" rel=\"noopener\">61</a>]、Mayhem[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b62\" target=\"_blank\" rel=\"noopener\">62</a>]、KLEE[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b63\" target=\"_blank\" rel=\"noopener\">63</a>]、Triton[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b64\" target=\"_blank\" rel=\"noopener\">64</a>]、angr[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b65\" target=\"_blank\" rel=\"noopener\">65</a>-<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b66\" target=\"_blank\" rel=\"noopener\">66</a>]等。其中SAGE已经被应用到了微软内部的日常开发安全测试中，每天有上百台机器同时在运行此工具，并发现了Windows 7系统中三分之一的漏洞[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b60\" target=\"_blank\" rel=\"noopener\">60</a>]。MergePoint[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b67\" target=\"_blank\" rel=\"noopener\">67</a>]已经在Debian系统下发现上百个可利用漏洞。</p>\n<p>虽然符号执行相比其他程序测试和分析技术有诸多的优势，但就当前的形势而言，要大规模应用到工业领域仍然还有很多问题需要解决。符号执行概念提出至今已有40多年，而现代符号执行技术特别是动态符号执行技术的提出也有10多年之久，但至今符号执行仍然难以在主流的软件测试和漏洞挖掘中占据主导地位，归因于以下尚待解决的难题。</p>\n<h4 id=\"1-路径爆炸-path-explosion-问题。\"><a href=\"#1-路径爆炸-path-explosion-问题。\" class=\"headerlink\" title=\"1) 路径爆炸(path explosion)问题。\"></a>1) 路径爆炸(path explosion)问题。</h4><p>路径爆炸又称为状态爆炸(state explosion)，是指在程序运行过程中路径数随着分支条件的增多而出现指数级增长的情况。由于路径爆炸问题的存在，在大型复杂的程序中，符号执行容易出现代码覆盖率增长慢的问题，很难在合理有限的时间内遍历程序的所有执行路径。为了缓解这一问题，研究人员采用了具有制导性的启发式搜索以及状态空间简化等操作减少对冗余状态的探索。</p>\n<p>启发式搜索(search heuristics)是一种以特定目标优先的路径搜索策略。符号执行过程中对路径的探索可以看成是对符号执行树的探索，在执行树中，从根节点到叶子节点的一条路径代表程序实际执行中的一条路径，而其中的分支节点则表示程序实际执行中的分支条件。大部分启发式技术都专注于避免因陷入某部分相似路径而导致代码覆盖率低增长的情况，以期获得更高的代码和路径覆盖。KLEE[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b63\" target=\"_blank\" rel=\"noopener\">63</a>]中提出结合随机路径选择(random path selection)和覆盖优化搜索(coverage-optimized search)的混合搜索算法，2种路径选择方法交叉使用探索执行路径既能达到高代码覆盖率的目的，又能防止某种算法陷入困境导致路径探索无法进行。Ma等[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b68\" target=\"_blank\" rel=\"noopener\">68</a>]提出了以指定行代码可达性(line reachability)为目标的搜索策略。以程序中某行或多行代码为目标，找出能够驱动程序执行这些代码的实际输入问题称为代码行可达性问题。Godefroid等[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b60\" target=\"_blank\" rel=\"noopener\">60</a>]提出了代搜索(generational search)算法，在每一代新生成的路径约束中，对所有分支条件取反，然后能选择覆盖新代码块最多的测试输入作为新的种子输入。</p>\n<p>状态空间简化通过相似路径合并、冗余路径删减的方式达到减少路径探测的目的。除了启发式探索程序执行路径之外，研究人员还提出了利用程序分析和软件验证等技术减少精简路径的措施来缓解路径爆炸问题。Godefroid等[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b69\" target=\"_blank\" rel=\"noopener\">69</a>]采用了函数摘要的方式，对重用的函数提取约束组合(摘要)，实现对函数路径的组合执行，避免了多次重复符号执行带来的开销。Ramos等[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b70\" target=\"_blank\" rel=\"noopener\">70</a>]提出的限定约束的符号执行(under-constrainted symbolic execution)采用了直接面向独立函数的符号执行技术，此技术限定了符号执行的范围，用精确度换取可扩展性的方式来提升符号执行的性能。Veritesting[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b67\" target=\"_blank\" rel=\"noopener\">67</a>]采用了静态符号执行技术增强动态符号执行技术，实现路径合并和冗余路径删减。Boonstoppel等[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b71\" target=\"_blank\" rel=\"noopener\">71</a>]提出了RWSet，从状态变量的相似性鉴别冗余性，如果当前状态的变量跟之前的路径变量一样，则会停止对当前状态的探索。</p>\n<h4 id=\"2-约束求解问题。\"><a href=\"#2-约束求解问题。\" class=\"headerlink\" title=\"2) 约束求解问题。\"></a>2) 约束求解问题。</h4><p>约束求解问题是动态符号执行遇到的另一个瓶颈问题。在动态符号执行中，对路径约束条件可达性的判定以及相应测试输入生成都需要频繁地调用SMT求解器进行求解；而约束求解本身又是一个NP完全(NP-complete)问题，在最差的情况下求解NP完全问题的复杂度为指数级。频繁调用加上高的求解难度直接导致约束求解消耗了符号执行系统中的大部分资源。</p>\n<p>当前约束求解问题可以归结为求解能力和求解效率问题。求解能力问题是指当前求解器对复杂约束条件处理能力的不足。例如对于浮点数运算、非线性运算等一些复杂运算的约束，求解器都不能很好地处理。而求解效率问题是指对于含有大量的约束条件的路径约束，求解器的性能会随着约束条件数量的增长而逐渐下降。这使得符号执行对大型程序进行分析时整体性能下降，从而影响其可扩展性。</p>\n<p>针对约束求解的两大问题，研究人员提出了很多约束求解性能优化措施，主要可分为内部优化和外部优化。求解器内部优化是指通过优化求解器本身对约束条件处理能力和效率来提高符号执行的性能，虽然近年来这方面的研究已经取得了比较大的突破[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b72\" target=\"_blank\" rel=\"noopener\">72</a>-<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b76\" target=\"_blank\" rel=\"noopener\">76</a>]，但仍然严重依赖于可满足模理论以及NP完全问题的研究进展。求解器外部优化主要是指在调用约束求解器对路径约束求解之前的优化，是通过减少甚至避免符号查询的工作来增加符号执行性能的措施。例如，CUTE[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b77\" target=\"_blank\" rel=\"noopener\">77</a>]和KLEE[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b63\" target=\"_blank\" rel=\"noopener\">63</a>]采用了如表达式重写、符号值的实际替换、不相关约束的删除以及约束缓存等一系列措施，对路径约束进行精简和结果重用。而近年来在这方面的研究又有了不小的突破，包括Green[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b78\" target=\"_blank\" rel=\"noopener\">78</a>]、Recal[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b79\" target=\"_blank\" rel=\"noopener\">79</a>]、GeenTrie[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b80\" target=\"_blank\" rel=\"noopener\">80</a>]、Memoise[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b81\" target=\"_blank\" rel=\"noopener\">81</a>]等，这些工具的提出主要侧重于解决优化符号执行结果切分、标准化命名、约束式逻辑转化、求解结果的缓存、搜索和重用的效率问题。有关这些工具的实验结果表明：路径约束的精简能减轻约束求解的负担，而约束求解结果的缓存和重复使用能在同一程序的不同路径以及不同程序的不同路径间的约束求解问题上极大地减少对求解器的调用。</p>\n<h4 id=\"3-其他问题。\"><a href=\"#3-其他问题。\" class=\"headerlink\" title=\"3) 其他问题。\"></a>3) 其他问题。</h4><p>除了上述2个问题之外，符号执行还面临着内存建模[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b62\" target=\"_blank\" rel=\"noopener\">62</a>, <a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b65\" target=\"_blank\" rel=\"noopener\">65</a>-<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b66\" target=\"_blank\" rel=\"noopener\">66</a>]、环境交互[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b61\" target=\"_blank\" rel=\"noopener\">61</a>, <a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b63\" target=\"_blank\" rel=\"noopener\">63</a>, <a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b82\" target=\"_blank\" rel=\"noopener\">82</a>-<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b83\" target=\"_blank\" rel=\"noopener\">83</a>]、并行计算[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b67\" target=\"_blank\" rel=\"noopener\">67</a>, <a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b84\" target=\"_blank\" rel=\"noopener\">84</a>]等问题。</p>\n<p>总体而言，基于符号执行的漏洞挖掘技术依赖于约束求解器的求解能力和效率，并受限于程序状态爆炸问题。另外，它在主动漏洞挖掘方面还依赖于在对程序进行分析的基础上构造预置条件(漏洞约束)。符号执行应用于大型程序是一个多种性能优化措施并行且不断地对性能调优的过程，虽然研究人员提出了一系列性能优化措施来改善符号执行的可扩展性，但当前业界和学术界普遍认为，单独使用符号执行技术对大型程序进行漏洞挖掘仍然比较困难。</p>\n<h2 id=\"2-3-漏洞可利用性分析\"><a href=\"#2-3-漏洞可利用性分析\" class=\"headerlink\" title=\"2.3 漏洞可利用性分析\"></a>2.3 漏洞可利用性分析</h2><p>在漏洞可利用性判定方面，现有的一些工具如!exploitable[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b85\" target=\"_blank\" rel=\"noopener\">85</a>]、gdb-exploitable[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b86\" target=\"_blank\" rel=\"noopener\">86</a>]、ASan[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b87\" target=\"_blank\" rel=\"noopener\">87</a>]等，已经可以对漏洞挖掘过程中的异常或崩溃的可利用性进行初步分类。例如，!exploitable对崩溃按可利用(exploitable)、高可利用(probably exploitable)、不可利用(probably not exploitable)、未知(unknown)进行评级划分，并提供了哈希去重功能。但上述工具具有误报率高的缺陷，实际验证的时候仍然需要具有丰富漏洞挖掘和分析经验的专家进行手工逆向分析、调试进行审核确认，并编写利用漏洞的验证程序。在崩溃样本量较大时，这种方式低效而且对分析人员具有较高要求。</p>\n<p>在自动化漏洞利用生成方面，APEG [<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b88\" target=\"_blank\" rel=\"noopener\">88</a>]使用了基于补丁对比的漏洞利用生成技术，该技术基于补丁定位漏洞位置，并采用切分技术(slicing technique)生成从输入源至漏洞点的路径约束，但APEG只适用于单检查点修补的补丁。Heelan等[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b89\" target=\"_blank\" rel=\"noopener\">89</a>]提出了自动化提取控制流劫持的漏洞利用技术，但该技术只在提供崩溃输入和已知漏洞(如栈溢出覆盖EIP指针)的前提下适用。AGE[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b83\" target=\"_blank\" rel=\"noopener\">83</a>]、Mayhem[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b90\" target=\"_blank\" rel=\"noopener\">90</a>]采用预置条件的符号执行(pre-conditioned symbolic execution)技术寻找可利用的漏洞路径，并自动生成利用代码。但该技术只支持对栈溢出、格式化字符串等部分漏洞的检测；另外，其自动化生成的漏洞利用程序不支持绕过编译器或OS对抗机制如ASLR(address space layout randomization)、DEP(data execution prevention)、CFI(control-flow integrity)等。FlowStitch[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b91\" target=\"_blank\" rel=\"noopener\">91</a>]采用了称为数据流缝合(data-flow stitching)的面向数据流的自动化漏洞利用生成技术，该技术在不改变程序控制流的情况下，利用已知的内存错误修改数据流中关键变量的方式构建漏洞利用程序。FlowStitch从已知漏洞程序中发现了多个未知的漏洞利用方式，自动生成的所有利用程序都能通过CFI和DEP, 并有部分能绕过ASLR, 进而实现信息泄露或权限提升。但该方案仍然依赖于已知的内存错误和相应的测试输入。</p>\n<p>总体而言，漏洞可利用性判定、漏洞利用程序生成是制约实现漏洞挖掘自动化的主要瓶颈之一。</p>\n<h2 id=\"2-4-自动化漏洞挖掘\"><a href=\"#2-4-自动化漏洞挖掘\" class=\"headerlink\" title=\"2.4 自动化漏洞挖掘\"></a>2.4 自动化漏洞挖掘</h2><p>2016年8月，美国国防部高等研究计划署(DARPA)举办了网络超级挑战赛(cyber grand challenge，CGC)大赛的决赛。参赛团队研发的网络推理系统(cyber reasoning system，CRS)具备自动化挖掘漏洞、自动部署补丁和进行系统防御的能力，可以快速有效地应对新的攻击，降低从攻击出现到防御生效之间的时间差，实现网络安全攻防系统的全自动化。CGC大赛提供了一个自动化的攻防比赛平台，所设置的科学的评测体系可以比较全面地评估CRS系统的自动化网络推理能力，也为以后的自动化、智能化网络攻防研究指明了方向。此外，大赛提供的赛题还成为后续研究的测试集，用于评估平台、工具的漏洞挖掘能力和性能，在关于VUzzer[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b32\" target=\"_blank\" rel=\"noopener\">32</a>]、Steelix[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b35\" target=\"_blank\" rel=\"noopener\">35</a>]、Driller[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b40\" target=\"_blank\" rel=\"noopener\">40</a>]等的文献中都被采用。</p>\n<p>但CGC大赛仍然有比较大的局限性。首先，比赛环境与真实环境有差别。为了简化比赛环境，增加可控性，为比赛定制开发的DECREE(DARPA experimental cybersecurity research evaluation environment)系统只提供了7个系统调用；其次，CRS系统漏洞挖掘能力有限，只能挖掘一些简单程序的低级漏洞，对于浏览器等比较复杂的大型程序还不能很好地分析和处理；最后，自动化、智能化能力有限，在大赛中各参赛队伍使用的仍然是传统的模糊测试、符号执行等技术，并结合预设的漏洞模式、攻击模式进行部署，没有使用机器学习、深度学习技术，缺乏自我学习的能力。CGC大赛离实现高度自动化甚至是智能化漏洞挖掘还有比较大的差距。</p>\n<p>综上所述，模型检测、二进制比对、模糊测试、符号执行等传统技术是当前漏洞挖掘的主要手段，漏洞可利用性分析仍然依赖人工参与，以CGC大赛为代表的自动化漏洞挖掘研究离现实应用有比较大的差距，实现漏洞挖掘全自动化是当前研究的难点问题。</p>\n<h1 id=\"3-基于学习的智能化漏洞挖掘技术\"><a href=\"#3-基于学习的智能化漏洞挖掘技术\" class=\"headerlink\" title=\"3 基于学习的智能化漏洞挖掘技术\"></a>3 基于学习的智能化漏洞挖掘技术</h1><p>机器学习、深度学习[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b92\" target=\"_blank\" rel=\"noopener\">92</a>]已经广泛应用于图像识别、语音识别、自然语言处理、医学自动诊断、搜索引擎广告推送等众多的领域，并取得了大量突破性进展。在网络安全领域，也已经应用于恶意软件检测、垃圾邮件和网络钓鱼分类、账户异常检测和日志分析等场景。</p>\n<p>受益于上述的研究进展，研究人员在近年来也开始采用机器学习技术缓解软件漏洞挖掘领域的一些瓶颈问题。通过采用现有的机器学习、深度学习等技术，帮助相应的漏洞挖掘工具、系统在海量的漏洞相关的数据中提取经验和知识，然后根据训练生成的模型对新的样本进行分类、预测，提高对软件漏洞挖掘的精度和效率。</p>\n<h2 id=\"3-1-应用场景\"><a href=\"#3-1-应用场景\" class=\"headerlink\" title=\"3.1 应用场景\"></a>3.1 应用场景</h2><p>近年来已经有智能化漏洞挖掘技术研究基于机器学习、深度学习技术展开，如<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#Table1\" target=\"_blank\" rel=\"noopener\">表 1</a>所示。从应用场景看，涉及了二进制程序函数识别、函数相似性检测、测试输入生成、测试输入筛选、路径约束求解等领域；从使用的机器学习算法看，这些工作中分别采用了逻辑回归、随机森林、长短时记忆网络(LSTM)、强化学习等多种机器学习、深度学习的算法；从发表年份看，这方面的研究成果从2014年开始发表在信息安全顶级会议上，自2017年以来其数量逐渐上升，并已经成为当前信息安全研究领域的热点。</p>\n<p><img src=\"/2019/04/02/From-automation-to-intelligence-Survey-of-research-on-vulnerability-discovery-techniques/2.jpg\" alt=\"\"></p>\n<h3 id=\"3-1-1-二进制程序函数识别\"><a href=\"#3-1-1-二进制程序函数识别\" class=\"headerlink\" title=\"3.1.1 二进制程序函数识别\"></a>3.1.1 二进制程序函数识别</h3><p>二进制程序函数识别是二进制分析的基础，对于软件漏洞分析与修复，甚至恶意软件检测、协议逆向等都至关重要。由于二进制代码缺少高级语言程序中的信息，函数的识别往往比较困难，现有的反汇编分析工具具有识别正确率低的缺陷。Bao等[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b93\" target=\"_blank\" rel=\"noopener\">93</a>]提出了ByteWeight方案，采用机器学习算法实现对二进制程序函数的识别。具体而言，首先采用加权前缀树(weighted prefix tree)学习函数的签名，并通过签名匹配二进制片段的方式识别函数。其中，树中每个节点与二进制中的字节或指令相对应，而从根节点到某个既定节点的路径代表了可能的字节或指令序列，权重则表示了对数据集采用简单线性扫描算法学习到的字节或指令序列的置信度。在鉴别函数的同时，ByteWeight采用值集分析(value set analysis, VSA)和增量控制流恢复算法实现对函数边界的识别。此种方案可以获得比IDA Pro和BAP工具[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b94\" target=\"_blank\" rel=\"noopener\">94</a>]更高的准确率。Shin等[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b95\" target=\"_blank\" rel=\"noopener\">95</a>]用循环神经网络算法改进了ByteWeight的性能，在模型训练时间上有了数量级上的提升，并取得了更高的准确率。</p>\n<h3 id=\"3-1-2-函数相似性检测\"><a href=\"#3-1-2-函数相似性检测\" class=\"headerlink\" title=\"3.1.2 函数相似性检测\"></a>3.1.2 函数相似性检测</h3><p>现代应用程序中，直接调用第三方函数可以节约开发成本、提高开发效率，是被广泛接受的开发惯例。但这种方式容易导致供应链安全风险，一旦被调用函数存在漏洞，则调用这一函数的程序也可能存在漏洞。通过函数相似性检测技术可以实现对不同程序间的同源性漏洞的检测，但当前基于图的相似度匹配的方法具有计算量大、准确率低的缺陷。Xu等[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b97\" target=\"_blank\" rel=\"noopener\">97</a>]提出了Gemini方案，Gemini把函数控制流图CFG简化为带节点属性(数字特征)的控制流图(ACFG)，然后用Structure2vec算法转化为数字向量，使用Siamese网络架构训练，实现相似的函数距离近的目标，最后通过计算函数向量距离实现函数相似性的检测。Gemini能应用到跨平台的二进制函数相似性检测，并取得了比其他基于图相似性匹配的工具(如Genius[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b98\" target=\"_blank\" rel=\"noopener\">98</a>])更高的准确率和检测效率。</p>\n<h3 id=\"3-1-3-测试输入生成\"><a href=\"#3-1-3-测试输入生成\" class=\"headerlink\" title=\"3.1.3 测试输入生成\"></a>3.1.3 测试输入生成</h3><p>在软件漏洞挖掘中，构造代码覆盖率高或脆弱性导向型的测试输入能提高漏洞挖掘的效率和针对性。利用机器学习技术可以对海量测试样本进行分析、学习，并利用生成模型指导生成更高质量的测试输入样本。Godefroid等[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b99\" target=\"_blank\" rel=\"noopener\">99</a>]首次把模糊测试中的高结构化样本生成问题转换成了NLP领域的文本生成问题，采用了Char-RNN(recurrent neural network)模型实现对PDF文件格式中的obj语法的学习，并用训练好的模型生成具有多样性的obj对象和PDF文件。She等[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b100\" target=\"_blank\" rel=\"noopener\">100</a>]提出了采用深度神经网络指导模糊测试输入生成的方案Neuzz。Neuzz采用了CNN(convolutional neural network)学习连续可微的神经程序(neural program)，用来近似模拟目标程序中的实际逻辑，然后通过对学习好的神经程序求梯度的方式指导测试输入生成，以此取得对目标程序更高的分支覆盖。与AFL相比，Neuzz在6个不同的常用程序中多发现了70倍的分支，并多发现了36个缺陷。Bottinger等[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b101\" target=\"_blank\" rel=\"noopener\">101</a>]提出了深度强化学习增强的模糊测试技术，借助Markov模型把模糊测试问题转化成强化学习问题，并利用Q-learning算法优化预定义的奖励函数。实验结果表明，使用深度强化学习增强的模糊测试技术比随机变异能取得更高的代码覆盖率。Nichols等[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b102\" target=\"_blank\" rel=\"noopener\">102</a>]提出了生成对抗网络(GAN)增强模糊测试技术。该方案不依赖于大数据量的样本训练，并能比AFL的随机变异和基于LSTM模型引导的变异更高效地发现更多的路径。</p>\n<h3 id=\"3-1-4-测试输入筛选\"><a href=\"#3-1-4-测试输入筛选\" class=\"headerlink\" title=\"3.1.4 测试输入筛选\"></a>3.1.4 测试输入筛选</h3><p>动态漏洞挖掘依赖于测试输入的实际运行来检测是否能触发崩溃或漏洞，当有海量样本需要被执行测试时，会非常耗时且低效。测试样本筛选的目的是从海量样本中选择更有可能触发新路径或触发漏洞的测试输入。使用机器学习技术通过对大量的测试样本进行处理，从而决定哪些应该被进一步分析，尽可能准确地对样本进行标记，然后再用于寻找安全漏洞。Rajpal等[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b103\" target=\"_blank\" rel=\"noopener\">103</a>]使用LSTM、序列到序列(Seq2seq)等神经网络学习模糊测试过程中的历史变异样本及代码覆盖率等数据，训练出能指导对输入文件进行定向变异的模型。实验结果表明，使用这种方法能获得比随机变异更高的代码覆盖率。但文[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b103\" target=\"_blank\" rel=\"noopener\">103</a>]中采用的热力图生成模型仅仅依赖于基础样本以及能带来代码覆盖率增长的变异样本，训练生成的模型并没有记录测试输入与变异点、变异方法、代码覆盖增长情况之间的关联信息，基于这种模型生成的热力图不能精确标注记录测试输入中变异点与代码覆盖之间的关联性，因此热力图可能带有误标注和漏标注。此外，Spieker等[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b104\" target=\"_blank\" rel=\"noopener\">104</a>]还提出了采用强化学习的算法优先筛选漏洞导向型的测试用例，应用在持续集成(continuous integration, CI)及回归测试(regression test)中。</p>\n<p>2.1.5 路径约束求解</p>\n<p>模糊测试，特别是代码覆盖率制导的模糊测试(如AFL)，侧重于筛选可以覆盖新路径的样本为种子文件，但对种子文件变异时并没有充分利用程序数据流等信息指导变异，这使得变异盲目低效，生成样本冗余。现有的一些启发式优化工作如Steelix[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b35\" target=\"_blank\" rel=\"noopener\">35</a>]能够对魔术字节跟踪定位，但无法对其他路径约束求解。具备路径约束求解能力是符号执行比模糊测试等漏洞挖掘技术更先进的体现，也使得符号执行在理论上具备了系统性探索程序执行路径的能力。但复杂程序中的路径爆炸问题带来的对SMT求解器的频繁调用，以及SMT求解器本身的能力和效率的不足，使得约束求解占用了符号执行中主要的性能开销，约束求解问题也成为符号执行中面临的主要瓶颈问题之一。Chen等[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b105\" target=\"_blank\" rel=\"noopener\">105</a>]提出了Angora，采用污点追踪测试输入中影响条件分支的字节，然后使用梯度下降的方式对变异后生成的路径约束进行求解。这种方式避免了符号执行调用SMT求解器可能带来的开销以及复杂约束不可解的问题，但梯度下降对目标函数不可导或存在不可导点时，仍然会出现求解困难的问题。</p>\n<h3 id=\"3-1-6-漏洞程序筛选\"><a href=\"#3-1-6-漏洞程序筛选\" class=\"headerlink\" title=\"3.1.6 漏洞程序筛选\"></a>3.1.6 漏洞程序筛选</h3><p>传统的漏洞挖掘技术如模糊测试、符号执行等已经成功地从各类软件中发现了大量的漏洞，但当被测试程序复杂且数量庞大的时候，使用这些技术挖掘漏洞显得效率低下。VDiscover[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b106\" target=\"_blank\" rel=\"noopener\">106</a>]采用机器学习技术从大量的程序中快速筛选更有可能带有漏洞的程序。具体而言，VDiscover收集程序中的标准C库函数调用序列及其参数的动态值作为静态和动态特征，并对其做标注，然后采用带监督的机器学习算法(如随机森林，逻辑回归等)训练模型，当有新的被测试程序需要分类的时候，训练好的模型可以直接对提取的相应特征进行预判和标注。</p>\n<p>VDiscover首次验证了采用机器学习技术筛选漏洞程序的可行性，但其采用人工定义和提取特征的方法具有较大的局限性。漏洞成因复杂，VDiscover提取的程序静态特征和动态特征并不能精确地表征各种类型的漏洞, 这可能造成较高的误报和漏报。另外，采用机器学习直接对漏洞程序进行预测的方式无法生成测试用例来动态验证漏洞。</p>\n<h3 id=\"3-1-7-源代码漏洞点预测\"><a href=\"#3-1-7-源代码漏洞点预测\" class=\"headerlink\" title=\"3.1.7 源代码漏洞点预测\"></a>3.1.7 源代码漏洞点预测</h3><p>传统静态漏洞挖掘技术中，依赖于人工定义漏洞模式的检测方式经常会导致较高的漏报率。Li等[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b107\" target=\"_blank\" rel=\"noopener\">107</a>]提出了VulDeePecker方案，采用BLSTM算法对C/C++源代码中的漏洞点进行预测。鉴于传统的漏洞分类过细导致难以抽象提取为特征的问题，其设计了能覆盖多种漏洞类型的特征，这种方式不以函数为粒度，只考虑数据流保留语义上关联的代码行作为代码小部件(code gadgets)对程序进行表征，然后转换成向量作为深度学习的输入。但VulDeePecker方案中，代码小部件转换成向量的过程存在较大的信息丢失问题；另外，该方案只支持对缓冲区溢出和资源管理相关的漏洞的检测。</p>\n<h3 id=\"3-1-8-其他\"><a href=\"#3-1-8-其他\" class=\"headerlink\" title=\"3.1.8 其他\"></a>3.1.8 其他</h3><p>此外，机器学习还应用于模糊测试参数配置预测[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b108\" target=\"_blank\" rel=\"noopener\">108</a>]和漏洞可利用性分析[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b109\" target=\"_blank\" rel=\"noopener\">109</a>-<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b110\" target=\"_blank\" rel=\"noopener\">110</a>]等场景中。</p>\n<h2 id=\"3-2-面临的问题\"><a href=\"#3-2-面临的问题\" class=\"headerlink\" title=\"3.2 面临的问题\"></a>3.2 面临的问题</h2><h3 id=\"3-2-1-机器学习的局限性\"><a href=\"#3-2-1-机器学习的局限性\" class=\"headerlink\" title=\"3.2.1 机器学习的局限性\"></a>3.2.1 机器学习的局限性</h3><p>虽然以机器学习为代表的人工智能技术取得了非常瞩目的进展，但其本身也面临着巨大的挑战。基于机器学习的漏洞挖掘技术受限于算法本身的能力，也受限于算法本身的安全性和健壮性。</p>\n<p>当前的机器学习技术并没有解决人工智能的核心问题，不是通向人工智能的最佳途径[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b111\" target=\"_blank\" rel=\"noopener\">111</a>]。传统的机器学习技术需要人工设计、构建特征，然后转换成向量作为机器学习算法的输入，不具备对原始数据自动提取特征的能力，严重依赖于专家知识。深度学习具有在高维数据中自动提取特征的能力，并已经取得了广泛应用，但其仍然面临着持续学习、数据饥饿、可解释性等问题[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b111\" target=\"_blank\" rel=\"noopener\">111</a>-<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b112\" target=\"_blank\" rel=\"noopener\">112</a>]。</p>\n<p>另外，当前的机器学习算法的安全性和健壮性问题也逐渐暴露出来。一方面，常用机器学习工具存在漏洞。Stevens等[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b113\" target=\"_blank\" rel=\"noopener\">113</a>]利用模糊测试方法挖掘出了OpenCVScikit-Learn、NumPy等常用的机器学习软件的库文件中的堆溢出等漏洞，这些漏洞能导致Dos攻击或任意代码执行，或直接修改分类判定结果。另一方面，机器学习算法本身的健壮性问题容易导致对抗式攻击(adversarial attack)[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b114\" target=\"_blank\" rel=\"noopener\">114</a>-<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b119\" target=\"_blank\" rel=\"noopener\">119</a>]。对抗式攻击又称为对抗性训练或对抗性机器学习，通过在数据集中注入被污染的数据而欺骗模型做出错误的判断。此外，健壮性问题还容易导致污染攻击[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b120\" target=\"_blank\" rel=\"noopener\">120</a>-<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b122\" target=\"_blank\" rel=\"noopener\">122</a>]，逃逸攻击[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b123\" target=\"_blank\" rel=\"noopener\">123</a>-<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b126\" target=\"_blank\" rel=\"noopener\">126</a>]、模型倒置攻击[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b127\" target=\"_blank\" rel=\"noopener\">127</a>-<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b128\" target=\"_blank\" rel=\"noopener\">128</a>]，模型(参数)提取攻击[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b129\" target=\"_blank\" rel=\"noopener\">129</a>-<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b131\" target=\"_blank\" rel=\"noopener\">131</a>]等，这类攻击通常具有较高的隐蔽性。</p>\n<h3 id=\"3-2-2-算法选择\"><a href=\"#3-2-2-算法选择\" class=\"headerlink\" title=\"3.2.2 算法选择\"></a>3.2.2 算法选择</h3><p>机器学习、深度学习虽然已经在图像识别、自然语言处理等领域已经有比较成熟的应用，但在漏洞挖掘领域，不同的应用场景下可能只适用于部分机器学习算法，甚至同一场景中，选择不同的适用算法也会导致结果的显著差异。但现有的研究工作大部分只凭经验选取了部分机器学习算法，并未对各类算法性能进行较系统性的比对。如在文[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b103\" target=\"_blank\" rel=\"noopener\">103</a>, <a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b107\" target=\"_blank\" rel=\"noopener\">107</a>]中采用了LSTM等循环神经网络算法实现可变长序列预测和文本生成，但当前CNN已经可以取得比LSTM更好的性能[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b132\" target=\"_blank\" rel=\"noopener\">132</a>-<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b133\" target=\"_blank\" rel=\"noopener\">133</a>]。其次，还要考虑根据数据量大小的问题，如果数据量小，人工指定规则的传统机器学习可能会有更好地性能。深度学习虽然能自动对各种简单的特征学习并组合成更加复杂的特征，在特征提取上比传统的机器学习算法具有更大的优势，但深度学习更适合大数据量的学习。另外，对同一种算法的不同参数配置也能产生不同的模型，需要在对模型进行评估的基础上选择泛化误差小的模型。</p>\n<h3 id=\"3-2-3-数据收集\"><a href=\"#3-2-3-数据收集\" class=\"headerlink\" title=\"3.2.3 数据收集\"></a>3.2.3 数据收集</h3><p>机器学习、深度学习需要大量的样本，特别是深度学习在数据量不足时容易导致过拟合的问题。目前，在现有工作中针对不同应用场景和学习任务，收集的样本对象包括了二进制程序、PDF文件、C/C++源码、IOT固件等，这些数据的收集方式参差不齐，如模糊测试生成、符号执行生成、人工编译生成、网络爬虫等。对于常用的文件格式如DOC、PDF、SWF等，采用网络爬虫获取测试输入集是比较常用的方法。爬取方式可按特定文件扩展名(后缀)为筛选条件进行下载，或者按特定魔术字节或其他签名的方式下载，爬取的结果很容易就能达到TB数量级(如Skyfire[<a href=\"http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b133\" target=\"_blank\" rel=\"noopener\">133</a>])。但对于其他数据如崩溃样本、漏洞程序等，因其具有稀缺性，存在收集困难的问题。当前缺少通用的、认可度较高的漏洞相关的数据集可供基于机器学习、深度学习的技术进行训练和测试。</p>\n<p>收集漏洞相关的大数据集能为基于机器学习的智能化漏洞挖掘和分析提供学习素材，也关系到训练模型的效果。构建面向机器学习的大规模漏洞数据集对后续的研究将起到至关重要的作用，应当成为未来研究的重点问题之一。</p>\n<h3 id=\"3-2-4-特征选择\"><a href=\"#3-2-4-特征选择\" class=\"headerlink\" title=\"3.2.4 特征选择\"></a>3.2.4 特征选择</h3><p>传统机器学习算法分类、预测的准确性既与数据量的大小有关，也依赖于从数据中提取的特征。在漏洞挖掘中，程序结构和执行信息与漏洞并没有直接的关联性，如何从程序中筛选出漏洞相关的显著特征、摒弃非显著特征，需要结合机器学习算法、程序执行环境及漏洞产生原理等多方面考虑。例如在二进制程序中，静态特征可以从调用图、控制流图、数据流图等获取(同时要考虑图信息获取不精确的问题)，动态特征可以通过插桩执行跟踪(trace)实际函数调用以及调用参数的方式捕获。另外，还要考虑动、静态特征提取时带来的开销和可扩展性问题。如在二进制程序中，对目标程序建立各种基于图的结构计算量较大，动态特征提取则依赖于实际执行插桩跟踪测试程序，而插桩特别是动态插桩会带来比较大的开销，甚至会影响程序实际执行时的内存空间布局。</p>\n<p>综上所述，探索基于学习的漏洞挖掘技术，研究机器学习算法对软件漏洞挖掘中的不同应用场景的适用性，借助机器学习的分类、预测能力甚至深度学习的自动特征提取能力来缓解、突破传统技术的瓶颈问题，是当前智能化漏洞挖掘研究的热点和难点。</p>\n<h1 id=\"4-结论与展望\"><a href=\"#4-结论与展望\" class=\"headerlink\" title=\"4 结论与展望\"></a>4 结论与展望</h1><p>本文分析了传统漏洞挖掘技术及基于学习的智能化漏洞挖掘技术的研究进展，针对这些技术呈现出的自动化、智能化的趋势及面临的问题进行了深入的调研分析、归类和总结。</p>\n<p>下一步的研究应从以下2点展开：</p>\n<ul>\n<li><strong>1) 提高漏洞挖掘的效率与精度</strong></li>\n</ul>\n<p>漏洞挖掘是计算密集型的工作，与软件的规模和复杂度、硬件系统性能、采用的分析技术都有非常大的关联性，在研究实践中往往需要根据这些影响因素动态调整程序分析策略，在分析效率与分析深度之间取得较好的平衡和折中。一方面，需要研究轻量级分析技术、启发式状态空间探测技术(如脆弱路径筛选、低频路径筛选等)，在较小的开销内增强漏洞挖掘的导向性。另一方面，需要研究高效的规模化、并行化分析方法。漏洞挖掘在算法、分析数据存储和处理方面都有显著特征，现有的技术对大型复杂程序分析效率低下，没有充分利用高性能硬件设备提供的并行处理能力。探索规模化、并行化漏洞挖掘技术，增强对异构化计算资源的利用率，能很好应对大型复杂软件快速分析的需求。</p>\n<ul>\n<li><strong>2) 提高漏洞挖掘的自动化与智能化</strong></li>\n</ul>\n<p>在自动化方面，研究不依赖或较少依赖于人工参与的漏洞挖掘技术如漏洞利用程序自动生成、高结构化测试输入生成等仍然是当前研究的难点，这对实现全自动的漏洞挖掘甚至网络攻防都有重要的推进作用。在智能化方面，需要研究机器学习(如深度学习、强化学习、生成对抗网络等)在漏洞挖掘领域的应用。适用场景还应包括脆弱路径筛选、高结构化输入生成、约束求解配置预测等。基于机器学习的漏洞挖掘技术为解决传统漏洞挖掘技术的一些瓶颈问题提供了新途径，既能提升漏洞挖掘的自动化程度，也能提高漏洞挖掘的效率和精度。</p>\n","categories":[{"name":"论文","slug":"论文","permalink":"http://yama0xff.com/categories/论文/"},{"name":"fuzzing","slug":"论文/fuzzing","permalink":"http://yama0xff.com/categories/论文/fuzzing/"},{"name":"综述","slug":"论文/fuzzing/综述","permalink":"http://yama0xff.com/categories/论文/fuzzing/综述/"}],"tags":[{"name":"2018年","slug":"2018年","permalink":"http://yama0xff.com/tags/2018年/"},{"name":"综述","slug":"综述","permalink":"http://yama0xff.com/tags/综述/"},{"name":"Fuzzing","slug":"Fuzzing","permalink":"http://yama0xff.com/tags/Fuzzing/"}]},{"title":"Fuzzing: Art, Science, and Engineering","date":"2019-03-20T09:02:30.000Z","path":"2019/03/20/Fuzzing-Art-Science-and-Engineering/","text":"Abstract在当今可用的众多软件漏洞发现技术中，模糊测试由于其概念简单，部署的低屏障以及发现现实世界软件漏洞的大量经验证据而一直非常受欢迎。虽然近年来研究人员和从业人员都为改进模糊测试投入了大量不同的努力，但这项工作的激增也使得难以获得全面和一致的模糊测试观点。为了帮助保存并使大量的模糊测量文献保持连贯性，本文提出了一种统一的，通用的模糊测试模型以及当前模糊文献的分类。我们通过调查相关文献和艺术，科学和工程方面的创新，有条不紊地探索模型模糊器的每个阶段的设计决策，使现代模糊器有效。 relevant information 作者 VALENTIN J.M. MANÈS，HYUNGSEOK HAN,CHOONGWOO HAN,SANG KIL CHA∗,MANUEL EGELE,EDWARD J. SCHWARTZ,MAVERICK WOO, 单位 出处 CSUR‘19 原文地址 https://github.com/wtwofire/database/blob/master/papers/fuzzing/Review/2019-fuzzing%EF%BC%9A%20Art%2C%20Science%2C%20and%20Engineering.pdf 源码地址 发表时间 2019 1. 简介自从20世纪90年代初引入[139]以来，模糊测试一直是发现软件安全漏洞的最广泛部署的技术之一。在高级别，模糊测试指的是重复运行程序和构造的输入的过程，该输入可能在语法上或语义上不正确。在实践中，攻击者通常在诸如漏洞利用生成和渗透测试的场景中部署模糊测试[20,102]; 2016年DARPA网络大挑战赛（CGC）的几支队伍也在他们的网络推理系统中使用模糊测试[9,33,87,184]。在这些活动的推动下，防御者开始使用模糊测试来试图在攻击者发现漏洞之前发现漏洞。例如，Adobe [1]，Cisco [2]，Google [5,14,55]和Microsoft [8,34]等知名厂商都将模糊测试作为其安全开发实践的一部分。最近，安全审计员[217]和开源开发人员[4]也开始使用模糊测试来衡量商品软件包的安全性，并为最终用户提供一些合适的保证形式。 模糊社区非常有活力。在撰写本文时，仅GitHub就拥有了超过一千个与模糊测试相关的公共存储库[80]。正如我们将要展示的那样，文献中还包含大量的模糊器（参见第7页的图1），并且越来越多的模糊测试研究出现在主要安全会议上（例如[33,48,164,165,199,206] ]）。此外，博客圈中充满了许多模糊测试的成功故事，其中一些还包含了我们认为是精华的东西，这些精华在文献中占有一席之地。 不幸的是，研究人员和从业人员在模糊测试方面的工作激增也带来了阻碍进展的警告信号。例如，一些模糊器的描述不会超出其源代码和手册页。因此，随着时间的推移，很容易忘记这些模糊测试中的设计决策和潜在的重要调整。此外，各种模糊器使用的术语中存在可观察到的碎片。例如，虽然AFL [211]使用术语“测试用例最小化”来指代减小崩溃输入大小的技术，但同样的技术在funfuzz中也被称为“测试用例减少”[143]。虽然BFF [45]包含一种称为“崩溃最小化”的技术，听起来非常相似，但崩溃最小化的目的实际上是最小化崩溃输入和原始种子文件之间不同的位数，而不是减少崩溃输入的大小。我们认为这种分散使得难以发现和传播 fuzzing 知识，从长远来看，这可能严重阻碍 fuzzing 研究的进展。 基于我们的研究和我们在模糊测试方面的个人经验，本文作者认为现在是整合和提炼模糊测试大量进展的黄金时间，其中许多是在2007-2008 [73,187,189]年出版的三本关于该主题的贸易书籍之后发生的 。我们注意到Li等人同时进行了调查。 [125]侧重于基于覆盖的模糊测试的最新进展，但我们的目标是提供有关该领域近期发展的综合研究。为此，我们将首先使用§2来展示我们的模糊术语和统一的模糊测试模型。坚持本文的目的，选择我们的模糊术语来密切反映当前的主要用法，我们的模型模糊器（算法1，第4页）旨在适应大量的模糊测试任务，如分类在目前的模糊文献（图1，第7页）。通过这种设置，我们将在§3-§7中有条不紊地探索模型模糊器的每个阶段，并在表1中详细介绍主要模糊器（第9页）。在每个阶段，我们将调查相关文献来解释设计选择，讨论重要的权衡，并突出许多奇妙的工程努力，帮助使现代模糊器有效地完成他们的任务。 2. 系统化，分类和测试程序术语“fuzz”最初由Miller等人创造。在1990年，它指的是“生成一个由目标程序消耗的随机字符流”的程序[139，p.4]。从那时起，模糊的概念及其动作 - “fuzzing” - 出现在各种各样的语境中，包括动态符号执行[84,207]，基于语法的测试用例生成[82,98,196]，权限测试[21,74]，行为测试[114,163,205]，表示依赖性测试[113]，函数检测[208]，健壮性评估[204]，漏洞利用开发[104]，GUI测试[181]，签名生成[66]和渗透测试[75,145]。为了使大量的模糊测试文献中的知识系统化，让我们首先提出从当前使用中提取的模糊测试术语。 2.1 Fuzzing &amp; Fuzzing Testing直观地说，fuzzing是使用“模糊输入”运行被测程序（PUT）的行为。Honoring Miller等人，我们认为模糊输入是PUT可能不期望的输入，即PUT可能错误处理的输入并且触发PUT开发者无意识的行为。为了捕捉这个想法，我们将术语fuzzing定义如下。 定义2.1（fuzzing）。模糊测试是使用从输入空间（“模糊输入空间”）采样的输入执行PUT，该输入空间突出了PUT的预期的输入空间。 三个评论是有序的。首先，尽管通常看到模糊输入空间包含预期的输入空间，但这不是必需的 - 前者包含d的输入不在后者中就足够了。其次，在实践中，模糊测试几乎肯定会进行多次迭代;因此，在上面写“重复执行”仍然很准确。第三，抽样过程不一定是随机的，我们将在§5中看到. Fuzz testing是一种利用fuzzing的软件测试技术。为了区别于其他人并尊重我们认为最突出的目标，我们认为它有一个特定的目标，即找到与安全相关的错误，其中包括程序崩溃。此外，我们还定义了fuzzer和fuzz campaign，这两者都是模糊测试中的常用术语。 定义2.2（Fuzz Testing）。Fuzz Testing是使用fuzzing，其目标是测试PUT违反安全策略的地方。定义2.3（Fuzzer）。Fuzzer是一种在PUT上执行fuzz testing的程序。定义2.4（Fuzz Campaign）。Fuzz Campaign是一个在有特定安全策略的PUT上的特定执行的Fuzzer。 通过fuzzing campaign运行PUT的目的是找到违反所需安全策略的错误[23]。例如，早期fuzzer使用的安全策略仅测试生成的输入 - 测试用例 - 是否使PUT崩溃。但是，fuzz testing 实际上可用于测试任何可执行的安全策略，即EMenforceable [171]。决定执行是否违反安全策略的具体机制称为bug oracle。 定义2.5（Bug Oracle）。 bug oracle是一个程序，可能作为fuzzer的一部分，用于确定PUT的给定执行是否违反特定的安全策略。 我们将fuzzer实现的算法简称为“fuzz algorithm”。几乎所有 fuzz algorithm都依赖于PUT之外的一些参数（路径）。参数的每个具体设置都是fuzz configuration： 定义2.6（Fuzz Configuration）。fuzz algorithm的fuzz configuration包括控制fuzz algorithm的参数值。 Fuzz configuration通常被写为元组。请注意，fuzz configuration中的值类型取决于fuzz algorithm的类型。例如，将随机字节流发送到PUT [139]的fuzz algorithm具有简单的配置空间{（PUT）}。另一方面，复杂的fuzzer包含接受一组配置并随时间推移设置的算法 - 这包括添加和删除配置。例如，CERT BFF [45]在活动过程中改变了突变率和种子（在第5.2节中定义），因此其配置空间为{(PUT，s1，r1)，(PUT，s2，r2）,. … }。最后，对于每个配置，我们还允许fuzzer存储一些数据。例如，覆盖引导的模糊器可以存储每个配置的获得的覆盖范围。 2.2 Paper Selection Criteria为了达到明确的范围，我们选择在2008年1月至2018年5月的4个主要安全会议和3个主要软件工程会议的最后一个议程中包括所有关于模糊测试的出版物。按字母顺序排列，前者包括（i）ACM会议计算机和通信安全（CCS），（ii）IEEE安全和隐私（S＆P）研讨会，（iii）网络和分布式系统安全研讨会（NDSS），以及（iv）USENIX安全研讨会（USEC）;后者包括（i）ACM国际软件工程基础研讨会（FSE），（ii）IEEE / ACM自动软件工程国际会议（ASE），以及（iii）国际软件工程会议（ICSE）。对于出现在其他场所或媒介中的作品，我们根据自己对其相关性的判断将它们包括在内。 正如§2.1中所提到的，fuzz testing与软件测试的区别仅在于它与安全相关。尽管瞄准安全漏洞并不意味着除了在理论上使用bug oracle之外的测试过程中存在差异，但所使用的技术在实践中通常会有所不同。在设计测试工具时，我们经常假设源代码的存在和PUT的知识。与fuzzer相比，这些假设通常会将工具的开发推向不同的形状。尽管如此，这两个领域仍然彼此纠缠不清。因此，当我们自己的判断力不足以区分它们时，我们遵循一个简单的经验法则：如果出版物中没有出现fuzz这个词，我们就不包括它。 2.3 Fuzz Testing Algorithm我们提出了一种用于fuzz testing的通用算法，算法1，我们想象它已经在模型fuzzer中实现。它足以适应现有的模糊测试技术，包括§2.4中定义的黑色，灰色和白盒模糊测试。算法1将一组fuzz configurations C和一个超时 t_limit 作为输入，并输出一组发现的错误B.它由两部分组成。第一部分是预处理功能，它在fuzz campaign开始时执行。第二部分是循环内的一系列五个函数：Schedule，InputGen，InputEval，ConfUpdate和Continue。此循环的每次执行都称为fuzz iteration，并且在单个测试用例上执行InputEval称为fuzz run。请注意，一些模糊器不会实现所有五个功能。例如，为了模拟Radamsa [95]，我们让ConfUpdate简单地返回C，即它不会更新C. Preprocess（C）–&gt;C 用户为Preprocess提供一组fuzz configurations作为输入，并返回一组可能已修改的fuzz configurations。根据fuzz algorithm，Preprocess可以执行各种操作，例如将检测代码插入PUT，或测量种子文件的执行速度。见§3 Schedule(C,telapsed,tlimit) –&gt; conf Schedule接收当前的fuzz configurations，当前时间t_elapsed和超时t_limit作为输入，并选择要用于当前模糊迭代的fuzz configuration。见§4。 InputGen（conf）–&gt;tcs InputGen将fuzz configurations作为输入，并返回一组具体测试用例 tcs 作为输出。生成测试用例时，InputGen使用conf中的特定参数。一些模糊测试器使用conf中的种子来生成测试用例，而其他模糊器则使用模型或语法作为参数。见§5。 InputEval (conf, tcs, Obug) –&gt; B′, execinfos InputEval采用fuzz配置conf，一组测试用例 tcs 和一个bug oracle Obug作为输入。它在tcs上执行PUT并使用bug oracle O_bug检查执行是否违反了安全策略。然后它输出发现的错误集B’和关于每个fuzz运行的信息 execinfos。我们假设O_bug嵌入在我们的模型模糊器中。见§6。 ConfUpdate(C，conf，execinfos) –&gt; C ConfUpdate采用一组fuzz configurations C，当前配置 conf，以及每个模糊运行的信息 execinfos作为输入。它可能会更新一组fuzz configurations C.例如，许多灰盒模糊器会根据execinfos减少C中的模糊配置数量。见§7。 Continue (C) –&gt; {True, False} Continue将一组fuzz configurations C作为输入，并输出一个布尔值，指示是否应该进行下一个模糊迭代。此功能对于模型白盒模糊器很有用，当没有更多路径可以发现时，它可以终止。 2.4 Fuzzers 的分类在本文中，我们根据模糊器在每个模糊运行中观察到的语义粒度将模糊器分为三组：黑盒，灰盒和白盒fuzzer。请注意，这与传统的软件测试不同，传统的软件测试只有两个主要类别（黑盒和白盒测试）[147]。正如我们将在§2.4.3中讨论的那样，灰盒模糊测试是白盒模糊测试的一种变体，它只能从每次模糊运行中获取一些部分信息。 图1按时间顺序列出了现有fuzzer的分类。从Miller等人的开创性工作开始。 [139]，我们手动选择了在大型会议上出现或获得超过100个GitHub stars的流行fuzzer，并将其关系显示在图上。黑盒fuzzer位于图的左半部分，灰盒和白盒模糊器位于右半部分。 表1详细介绍了主要会议上出现的每个主要fuzzer所使用的技术。由于空间限制，我们省略了几个主要的fuzzer。每个模糊器都投影在我们上面提到的模型模糊器的五个功能上，其中一个杂项部分提供了有关fuzzer的额外细节。第一列（检测粒度）表示基于静态或动态分析从PUT获取多少信息。当fuzzer在两个阶段使用不同类型的插桩时，出现两个圆圈。例如，SymFuzz [48]运行白盒分析作为预处理，以便为随后的黑盒活动提取信息，而Driller [184]在白盒和灰盒模糊之间交替进行。 第二列显示来源是否公开。 第三列表示模糊器是否需要源代码才能运行。 第四列指出了模糊器是否支持内存模糊测试（参见§3.1.2）。 第五列是关于fuzzer是否可以推断模型（参见§5.1.2）。 第六列显示了在Preprocess中，fuzzer是执行静态分析还是动态分析。第七列指示fuzzers是否支持处理多个种子，并执行调度。 变异列指定fuzzers是否执行输入变异以生成测试用例。我们使用“半黑半白”来表示fuzzer根据执行反馈引导输入变异。基于模型的专栏是关于fuzzer是否基于模型生成测试用例。 基于约束的列显示fuzzers执行符号分析以生成测试用例。污点分析列意味着模糊测试器利用污点分析来指导其测试用例生成过程。 InputEval部分中的两列显示fuzzers是使用堆栈哈希还是使用代码覆盖率执行崩溃分类。 ConfUpdate部分的第一列指示在ConfUpdate期间模糊器是否进化种子池，例如，向池中添加有趣的种子（参见§7.1）。 ConfUpdate部分的第二列是关于fuzzers是否以在线方式学习模型。最后，ConfUpdate部分的第三列显示了从种子池中删除种子（参见§7.2）。 2.4.1黑盒fuzzer术语“黑盒”通常用于软件测试[29,147]，fuzzing表示没有看到PUT内部的技术 - 这些技术只能观察PUT的输入/输出行为，将其视为一个黑盒子。在软件测试中，黑盒测试也称为IO驱动或数据驱动测试[147]。大多数传统的模糊器[6,13,45,46,96]属于这一类。一些现代模糊器，例如funfuzz [143]和Peach [70]，也考虑了有关输入的结构信息，以生成更有意义的测试用例，同时保持不检查PUT的特性。类似的直觉用于自适应随机测试[51]。 2.4.2白盒Fuzzer在频谱的另一个极端，白盒模糊[84]通过分析PUT的内部和执行PUT时收集的信息来生成测试用例。因此，白盒模糊器能够系统地探索PUT的状态空间。术语白盒模糊是由Godefroid [81]在2007年引入的，它指的是动态符号执行（DSE），它是符号执行的变体[35,101,118]。在DSE中，符号和具体执行同时进行，其中具体的程序状态用于简化符号约束，例如，具体化系统调用。因此，DSE通常被称为concolic testing（具体的+符号的）[83,176]。此外，白盒模糊测试也被用于描述采用污点分析的模糊器[78]。白盒模糊测试的开销通常远高于黑盒模糊测试的开销。这部分是因为DSE实现[22,42,84]经常采用动态插桩和SMT求解[142]。虽然DSE是一个活跃的研究领域[34,82,84,105,160]，但许多DSE不是白盒模糊器，因为它们的目的不是找到安全漏洞。因此，本文没有提供有关DSE的全面调查，我们将读者引用到最近的调查论文[16,173]以获取更多信息。 2.4.3灰盒Fuzzer一些安全专家[62,72,189]提出了一种中间方法，并将其称为灰盒模糊测试。通常，灰盒模糊器可以获得PUT内部和/或其执行的一些信息。与白盒模糊器不同，灰盒模糊器不具备PUT的完整语义;相反，他们可以对PUT执行轻量级静态分析和/或收集有关其执行的动态信息，例如覆盖范围。 Greybox模糊器使用信息近似来测试更多输入。尽管安全专家之间通常存在共识，但黑盒，灰盒和白盒模糊测试之间的区别并不总是很明显。黑盒模糊器可能仍会收集一些信息，而白盒模糊器通常被迫做一些近似。本次调查中的选择，特别是表1中的选择，是有争议的，但是作者最好的判断。 灰盒模糊器的早期示例是EFS [62]，它使用从每个模糊运行中收集的代码覆盖率来使用进化算法生成测试用例。 Randoop [155]也使用了类似的方法，但它没有针对安全漏洞。现代模糊器如AFL [211]和VUzzer [164]是此类别中的示例。 3 预处理(PREPROCESS)一些模糊器在第一次模糊迭代之前修改了初始的fuzz configurations。这种预处理通常用于插桩PUT，清除潜在的冗余配置（即(seed selection)种子选择[165]），并修剪种子 3.1 插桩（Instrumentation ）与黑盒模糊器不同，灰盒和白盒模糊器可以在InputEval执行模糊运行（参见§6），或者在运行时模糊内存内容时插桩PUT以收集执行反馈。虽然还有其他方法可以获取PUT内部的信息（例如处理器跟踪或系统调用[86,188]），但插桩通常是收集最有价值信息的方法，因此几乎完全定义了颜色。模糊（从表1的第一列）。 程序插桩可以是静态的也可以是动态的 - 前者在PUT运行之前发生，而后者在PUT运行时发生。由于静态检测在运行时之前发生，因此它通常比动态检测产生更少的运行时开销。 静态插桩通常在编译时在源代码或中间代码上执行。如果PUT依赖于库，则必须单独插桩它们，通常通过使用相同的插桩重新编译它们。除了基于源代码的插桩，研究人员还开发了二进制级静态插桩（即二进制重写）工具[71,122,218]。 虽然它比静态插桩具有更高的开销，但动态插桩的优势在于它可以轻松地插桩动态链接库，因为插桩是在运行时执行的。有几种众所周知的动态插桩工具，如DynInst[161]，DynamoRIO [38]，Pin[131]，Valgrind [152]和QEMU [30]。通常，动态插桩在运行时发生，这意味着它对应于模型中的InputEval。但为了方便读者，我们在本节中总结了静态和动态插桩。 给定的模糊器可以支持多种类型的插桩。例如，AFL在源代码级别使用修改后的编译器支持静态插桩，或者在QEMU的帮助下支持二进制级别的动态插桩[30]。使用动态插桩时，AFL可以插桩（1）PUT本身的可执行代码（默认设置），或者（2）PUT中的可执行代码和任何外部库（使用AFL_INST_LIBS选项）。第二个选项 - 插桩所有遇到的代码 - 可以报告外部库中代码的覆盖信息，从而提供有关覆盖范围的更完整的图像。但是，这反过来会导致AFL模糊外部库函数中的其他路径。 3.1.1执行反馈（Execution Feedback. ）灰盒模糊器通常将执行反馈作为输入来演化测试用例。 AFL及其后代通过检测PUT中的每个分支指令来计算分支覆盖。但是，它们将分支覆盖信息存储在一个byte向量中，这可能导致路径冲突。 CollAFL [77]最近通过引入一个新的路径敏感哈希函数来解决这个问题。同时，LibFuzzer [7]和Syzkaller [198]使用节点覆盖作为执行反馈。Honggfuzz[188]允许用户选择要使用的执行反馈。 3.1.2 内存模糊测试（In-Memory Fuzzing ）在测试大型程序时，有时需要仅模糊PUT的一部分而不为每个模糊迭代重新生成进程，以便最小化执行开销。例如，复杂（例如，GUI）应用程序在接受输入之前通常需要几秒钟的处理。模糊这些程序的一种方法是在初始化GUI之后拍摄PUT的快照。为了模糊新的测试用例，可以在将新测试用例直接写入内存并执行之前恢复内存快照。同样的直觉适用于涉及客户端和服务器之间的大量交互的模糊网络应用程序。这种技术称为内存模糊[97]。例如，GRR [86,194]在加载任何输入字节之前创建快照。这样，它可以跳过不必要的启动代码。 AFL还使用fork服务器来避免一些流程启动成本。尽管它与内存模糊测试具有相同的动机，但是fork服务器涉及为每个模糊迭代分离一个新进程（参见§6）。 一些模糊器[7,211]对函数执行内存模糊测试，而不会在每次迭代后恢复PUT的状态。我们称这种技术为内存API模糊测试。例如，AFL有一个名为persistent mode [213]的选项，它在循环中重复执行内存API模糊测试而不重新启动进程。在这种情况下，AFL忽略了在同一执行中被多次调用的函数的潜在副作用。 虽然有效的内存API模糊测试会受到不合理的模糊测试结果的影响：内存模糊测试中发现的错误（或崩溃）可能无法重现，因为（1）为目标函数构造有效的调用上下文并不总是可行的，并且（ 2）可能存在多个函数调用未捕获的副作用。请注意，内存中API模糊的健全性主要取决于入口点函数，找到这样的函数是一项具有挑战性的任务。 3.1.3线程调度（Thread Scheduling ）竞争条件错误可能难以触发，因为它们依赖于可能不经常发生的非确定性行为。但是，通过显式控制线程的调度方式，也可以使用插桩来触发不同的非确定性程序行为[43,410,121,157,169,174,175]。现有工作表明，即使是随机调度线程也可以有效地找到竞争条件错误[174]。 3.2 种子选择（seed selection problem）回忆§2，模糊器接收一组控制fuzzing algorithm行为的fuzz configurations。不幸的是，fuzz configurations的一些参数，例如基于突变的模糊器的种子，具有大的值域。例如，假设分析师模糊测试接受MP3文件作为输入的MP3播放器。有无数的有效MP3文件，这提出了一个自然的问题：我们应该使用哪些种子进行模糊测试？这个问题被称为(seed selection problem )种子选择问题[165]。 有几种方法和工具可以解决种子选择问题[70,165]。常见的方法是找到最大化覆盖度量的最小种子集，例如节点覆盖，并且该过程称为计算最小集。例如，假设当前配置集C由两个seeds s1和s2组成，它们覆盖PUT的以下地址：{s1→{10,20}，s2→{20,30}}。如果我们有第三个种子s3→{10,20,30}的执行速度与s1和s2一样快，那么人们可能会认为fuzz s3而不是s1和s2是有意义的，因为它直观地测试了更多程序逻辑以一半的执行时间成本。这种直觉得到了Miller的报告[140]的支持，该报告显示，代码覆盖率增加1％会使发现的错误百分比增加0.92％。如§7.2所述，此步骤也可以是ConfUpdate的一部分。 Fuzzers在实践中使用各种不同的覆盖度量。例如，AFL的minset基于分支覆盖，每个分支上都有一个对数计数器。该决定背后的基本原理是，只有当分支计数在数量级上不同时才允许它们被认为是不同的。 Honggfuzz [188]根据执行指令数，执行分支数和唯一基本块计算覆盖率。此度量标准允许模糊器向minset添加更长的执行时间，这有助于发现拒绝服务漏洞或性能问题。 3.3 种子修剪（Seed Trimming ）较小的种子可能消耗较少的内存并且意味着更高的吞吐量。因此，一些模糊器试图在模糊种子之前减小种子的尺寸，这称为种子修剪。种子修剪可以在Preprocess中的主模糊循环之前或作为ConfUpdate的一部分进行。使用种子修剪的一个值得注意的模糊器是AFL [211]，只要修改后的种子达到相同的覆盖范围，它就使用其代码覆盖率插桩迭代地移除一部分种子。同时，雷伯特等人 [165]报道，他们的size minset算法，通过给予较小的种子更高优先级来选择种子，与随机种子选择相比，导致更少数量的独特错误。 3.4准备驱动程序应用程序当难以直接fuzz PUT时，准备一个模糊驱动程序是有意义的。这个过程在很大程度上是手动的，尽管这只在模糊测试活动开始时才进行一次。例如，当我们的目标是库时，我们需要准备一个调用库中函数的驱动程序。类似地，内核模糊器可能会模糊用户态应用程序来测试内核[28,117,154]。 MutaGen [115]利用其他程序（驱动程序）中包含的PUT知识进行模糊测试。具体来说，它使用动态程序切片来改变驱动程序本身，以生成测试用例。 IoTFuzzer [50]通过让驱动程序成为相应的智能手机应用程序来定位物联网设备。 4 调度(SEHEDULING)在模糊测试中，调度意味着为下一个模糊运行选择模糊配置。正如我们在§2.1中所解释的，每个配置的内容取决于模糊器的类型。对于简单的模糊器，调度可以很简单 - 例如，zzuf [96]在其默认模式下只允许一个配置（PUT和其他参数的默认值），因此根本没有决定。但对于更高级的模糊器，如BFF [45]和AFLFast [33]，他们成功的一个主要因素在于他们的创新调度算法。在本节中，我们将仅讨论黑盒和灰盒模糊测试的调度算法;白盒模糊测试中的调度需要符号执行器独有的复杂设置，我们将读者引用到[34]。 4.1 Fuzz配置调度（FCS）问题(The Fuzz Configuration Scheduling (FCS) Problem)调度的目标是分析当前可用的配置信息，并选择一个更有可能产生最有利结果的信息，例如，找到最多的唯一错误，或生成的输入集所达到的最大化覆盖范围。从根本上说，每个调度算法都面临相同的探索与剥削冲突，时间可以花费在收集关于每个配置的更准确信息上，以便为将来的决策（探索）提供信息，或者模糊当前被认为可以产生更有利结果的配置。 （利用）。 Woo等人 [206]将此固有冲突称为模糊配置调度（FCS）问题。 在我们的模型模糊器（算法1）中，函数Schedule基于（i）当前的模糊配置集 C，（ii）当前时间 t_elapsed，以及（iii）总时间预算 t_limit 来选择下一个配置。然后，此配置将用于下一次模糊运行。请注意，Schedule仅与决策有关。完成此决策的信息由 Preprocess 和 ConfUpdate 通过更新C获取。 4.2 黑盒FCS 算法在黑盒设置中，FCS算法可以使用的唯一信息是配置的模糊结果 - 与其一起发现的崩溃和错误的数量以及到目前为止花费的时间。 Householder和Foote [100]是第一个研究如何在CERT BFF黑盒突变模糊器中利用这些信息的人[45]。他们假定应该优先选择观察成功率较高的配置（#bugs / #runs）。事实上，在替换BFF中的统一采样调度算法后，他们观察到在运行 ffmpeg 500万次中独特崩溃次数增加了85％，证明了更先进的FCS算法的潜在优势。 不久之后，Woo等人在多个方面改进了上述想法 [206]。首先，他们从[100]中的伯努利试验序列到Weighted Coupon Collector’s Problem with Unknown Weights（WCCP / UW），改进了黑盒突变模糊测试的数学模型。前者假设每个配置具有固定的最终成功概率并且随着时间的推移而学习它，后者在衰减时明确地保持该概率的上限。其次，WCCP / UW模型自然会引领Woo等人去研究multi-armed bandit（MAB）问题的算法，这是一种流行的形式以应对决策科学中的探索与剥削冲突[31]。为此，他们能够设计MAB算法以准确地利用尚未发生衰减的配置。第三，他们观察到，在其他条件相同的情况下，让fuzzing更快的配置允许模糊器收集更多的独特错误，或者更快地降低其未来成功概率的上限。这激发了他们将配置的成功概率标准化为花费在其上的时间，从而使得更快的配置更加可取。第四，他们将BFF中模糊运行的编排从每个配置选择的固定运行次数（BFF用语中的“epochs”）改为每次选择的固定时间量。通过此更改，BFF不再需要在可重新选择之前花费更多时间在慢速配置中。通过组合上述内容，评估[206]显示使用与现有BFF相同的时间量发现的独特错误数量增加1.5倍。 4.3 灰盒FCS算法在灰盒设置中，FCS算法可以选择使用关于每种配置的更丰富的信息集，例如，在模糊配置时获得的覆盖范围。 AFL [211]是此类别的先行者，它基于进化算法（EA）。直观地，EA维持一组配置，每个配置具有一些“适应性”值。 EA选择合适的配置并将其应用于遗传转化，例如突变和重组，以产生后代，后代可能成为新的配置。假设是这些产生的配置更可能适合。 要在EA的上下文中理解FCS，我们需要定义（i）使配置适合的内容是什么，（ii）如何选择配置，以及（iii）如何使用所选配置。作为高级近似法，在执行控制流边缘的配置中，AFL认为包含最快和最小输入的那个适合（AFL用语中的“favorite”）。 AFL维护一个配置队列，从中选择下一个匹配配置，就好像队列是循环的一样。一旦选择了配置，AFL就会使其基本上以恒定的运行次数进行模糊处理。从FCS的角度来看，请注意快速配置的首选项与黑盒设置的[206]相同。 最近，Böhme等人的AFLFast [33]在上述三个方面的每个方面都改进了AFL。首先，AFLFast为输入添加了两个最重要的标准，使其成为“favorite”：（i）在执行控制流边缘的配置中，AFLFast倾向于选择最少的输入。这具有在执行该边缘的配置之间循环的效果，从而增加了探索。 （ii）当（i）中存在平局时，AFLFast倾向于选择其中执行最少路径的那个。这具有增加稀有路径的执行效果，这可能揭示更多未观察到的行为。其次，AFLFast放弃了AFL中的循环选择，而是根据优先级选择下一个拟合配置。特别是，如果选择配置的频率较低，或者在平局时，如果它运行的路径较少，则适配配置的优先级高于另一配置。与第一次改变的想法相同，这具有增加适合配置和稀有路径执行的探索的效果。第三，AFLFast根据能量计划确定所选配置的次数变量。 AFLFast中的FAST能量计划以较小的“能量”值开始，以确保配置之间的初始探索，并以指数方式增加到极限，以快速确保充分利用。此外，它还通过生成相同路径的生成输入的数量来标准化能量，从而促进对频率较低的模糊配置的探索。这些变化的总体影响非常显着 - 在24小时的评估中，Böhme等人观察到AFLFast发现了AFL没有发现的3个错误，并且在两者都发现的6个错误上比AFL快7倍。 AFLGo [32]通过修改其优先级来扩展AFLFast，以便针对特定的程序位置。 QTEP [200]使用静态分析来推断二进制文件的哪个部分更“错误”并优先考虑覆盖它们的配置。 5.输入生成(INPUT GENERATION)由于测试用例的内容直接控制是否触发bug，因此输入生成技术自然是模糊测试中最有影响力的设计决策之一。传统上，模糊器分为基于生成或基于突变的模糊器[187]。基于生成的模糊器基于给定模型生成测试用例，该模型描述了PUT期望的输入。我们在本文中称这种模糊器为基于模型的模糊器。另一方面，基于突变的模糊器通过改变给定的种子输入来产生测试案例。基于突变的模糊器通常被认为是无模型的，因为种子仅仅是示例输入，并且即使在大量数量下它们也不能完全描述PUT的预期输入空间。在本节中，我们将基于底层测试用例生成（InputGen）机制对模糊器使用的各种输入生成技术进行解释和分类。 5.1基于模型（基于生成）的模糊器基于模型的模糊器基于给定模型生成测试用例，该模型描述了PUT可以接受的输入或执行，例如精确表征输入格式的语法或不太精确的约束,例如标识文件类型的magic值。 5.1.1预定义模型一些模糊器使用可由用户配置的模型。例如，Peach [70]，PROTOS [112]和Dharma [3]接受用户提供的规范。 Autodafé [197]，Sulley [15]，SPIKE [13]和SPIKEfile [186]公开了API，允许分析师创建自己的输入模型。 Tavor [219]还接受以Extended Backus-Naur形式（EBNF）编写的输入规范，并生成符合相应语法的测试用例。类似地，诸如PROTOS [112]，SNOOZE [26]，KiF [12]和T-Fuzz [107]之类的网络协议模糊器也接受来自用户的协议规范。内核API模糊器[108,146,151,198,203]以系统调用模板的形式定义输入模型。这些模板通常指定系统调用期望作为输入的参数的数量和类型。在内核模糊测试中使用模型的想法源于Koopman等人 [119]开创性的工作，他们将操作系统的稳健性与一系列有限的手动选择的系统调用测试用例进行了比较。 其他基于模型的模糊器针对特定的语言或语法，并且该语言的模型内置于模糊器本身。例如，cross_fuzz [212]和DOMfuzz [143]生成随机文档对象模型（DOM）对象。同样，jsfunfuzz [143]基于其自己的语法模型生成随机但语法正确的JavaScript代码。 QuickFuzz [88]利用现有的Haskell库来描述生成测试用例时的文件格式。一些网络协议模糊器如Frankencerts [37]，TLS-Attacker [180]，tlsfuzzer [116]和llfuzzer[182]设计有特定网络协议模型，如TLS和NFC。 Dewey等人[63,64]提出了一种生成测试用例的方法，这些测试用例不仅语法正确，而且通过利用约束逻辑编程也具有语义多样性。LangFuzz [98]通过解析作为输入给出的一组种子来产生代码片段。然后它随机组合片段，并将种子与片段一起变异以生成测试用例。由于它提供了语法，因此它始终生成语法正确的代码。 LangFuzz应用于JavaScript和PHP。 BlendFuzz [210]基于与LangFuzz类似的想法，但它以XML和正则表达式解析器为目标。 5.1.2 推断模型推断模型而不是依赖于预定义的逻辑或用户提供的模型获得牵引力。虽然有大量关于自动输入格式和协议逆向工程主题的已发表研究[25,41,57,60,128]，但只有少数模糊测试者利用这些技术。模型推断可以分两个阶段完成：Preprocess或ConfUpdate。Preprocess中的模型推理。一些模糊推测器将模型推断为模糊运动之前的第一步。 TestMiner [61]使用代码中可用的数据来挖掘和预测合适的输入。 Skyfire [199]使用数据驱动方法从给定语法和一组输入样本生成一组种子。与以前的作品不同，他们的重点是生成一组语义上有效的新种子。 IMF [93]通过分析系统API日志来学习内核API模型，并生成使用推断模型调用一系列API调用的C代码。 Neural [56]和Learn＆Fuzz [85]使用基于神经网络的机器学习技术从给定的一组测试文件中学习模型，并使用推断的模型生成测试用例。Liu等人[129]提出了一种特定于文本输入的类似方法。 ConfUpdate中的模型推断。在每个模糊迭代中都有模糊器更新模型。 PULSAR [79]从捕获到的程序生成的一组的网络数据包中自动的推断出网络协议模型。然后，学习的网络协议用于模糊程序。 PULSAR在内部构建状态机，并映射哪个消息令牌与状态相关。此信息稍后用于生成覆盖状态机中更多状态的测试用例。 Doupé等人 [67]提出了一种通过观察I / O行为来推断Web服务的状态机的方法。然后使用推断的模型来扫描Web漏洞。Ruiter等人 [168]工作类似，但目标是TLS，并将其实施基于LearnLib [162]。最后，GLADE [27]从一组I / O样本中合成了一个无上下文语法，并使用推断的语法来模糊PUT。 5.2 无模型（基于突变）的模糊器经典随机测试[19,92]在生成满足特定路径条件的测试用例时效率不高。假设有一个简单的C语句：if（input == 42）。如果输入是32位整数，则随机猜测正确输入值的概率是2的32次方之一。当我们考虑结构良好的输入（如MP3文件）时，情况会变得更糟。随机测试极不可能在合理的时间内生成有效的MP3文件作为测试用例。因此，MP3播放器将主要在到达程序的更深层部分之前的解析阶段拒绝从随机测试中生成的测试用例。 这个问题促使使用基于种子的输入生成以及白盒输入生成（见§5.3）。大多数无模型模糊器使用种子，它是PUT的输入，以便通过改变种子来生成测试用例。种子通常是PUT支持的类型的结构良好的输入：文件，网络包或一系列UI事件。通过仅改变有效文件的一小部分，通常可以生成大多数有效的新测试用例，但也包含异常值以触发PUT的崩溃。有多种方法可用于改变种子，我们将在下面描述常见的方法。 5.2.1 比特翻转比特翻转是许多无模型模糊器使用的常用技术[6,95,96,188,211]。一些模糊器简单地翻转固定数量的比特，而其他模糊器确定随机翻转的比特数。为了随机改变种子，一些模糊器使用一个称为突变比的用户可配置参数，该参数确定单次执行InputGen时要翻转的位位置数。假设一个模糊器想要从给定的N位种子中翻转K个随机位。在这种情况下，模糊器的突变比是K / N.SymFuzz等 [48]表明模糊性能对突变率非常敏感，并且没有一个比率适用于所有PUT。有几种方法可以找到良好的突变率。 BFF [45]和FOE [46]使用每个种子的指数缩放比例集，并将更多迭代分配给证明在统计学上有效的突变比[100]。 SymFuzz [48]利用白盒程序分析来推断出良好的突变率。然而，请注意，所提出的技术仅考虑推断单个最佳突变比率。使用多个突变比率进行模糊测试比使用单个最佳比率进行模糊测试更有可能，这仍然是一个开放的研究挑战。 5.2.2 算术变异AFL [211]和honggfuzz [188]包含另一个变异操作，它将所选字节序列视为整数，并对该值执行简单算术。然后使用计算的值替换所选的字节序列。关键的直觉是通过少量的数值来限制突变的影响。例如，AFL从种子中选择一个4字节的值，并将该值视为整数 i。然后用 i ± r 替换种子中的值，其中r是随机生成的小整数。 r的范围取决于模糊器，通常是用户可配置的。在AFL中，默认范围是：0≤r&lt;35。 5.2.3 基于块的变有几种基于块的变异方法，其中块是种子的字节序列：（1）将随机生成的块插入种子的随机位置[7,211]; （2）从种子中删除随机选择的块[7,95,188,211]; （3）用随机值替换随机选择的块[7,95,188,211]; （4）随机置换一系列块的顺序[7,95]; （5）通过附加随机区块来调整种子的大小[188]; （6）从种子中取一个随机块来插入/替换另一个种子的随机块[7,211]。 5.2.4 基于字典的变异一些模糊器使用具有潜在显着语义权重的一组预定义值，例如0或-1，以及用于变异的格式字符串。例如，AFL [211]，honggfuzz [188]和LibFuzzer [7]在变换整数时使用诸如0，-1和1的值。 Radamsa [95]使用Unicode字符串，GPF [6]使用格式字符（如％x和％s）来改变字符串。 5.3 白盒模糊器白盒模糊器也可以分为基于模型或无模型的模糊器。例如，传统的动态符号执行[24,84,105,134,184]在基于变异的模糊器中不需要任何模型，但一些符号执行器[82,117,160]利用输入模型，如输入语法指导符号执行。 虽然许多白盒模糊器包括Godefroid等人[84]的开创性工作使用动态符号执行来生成测试用例，但并非所有的白盒模糊器都是动态符号执行器。一些模糊器[48,132,170,201]利用白盒程序分析来查找有关PUT接受的输入的信息，以便将其与黑盒或灰盒模糊测试一起使用。在本小节的其余部分中，我们将基于其基础测试用例算法简要总结现有的白盒模糊测试技术。请注意，我们故意省略动态符号执行器，如[42,47,54,83,176,192]，除非他们明确称自己为§2.2中提到的模糊器。 5.3.1 动态符号执行在高级别，经典的符号执行[35,101,118]运行一个带有符号值作为程序的输入，它代表所有可能的值。在执行PUT时，它会构建符号表达式，而不是评估具体值。每当它到达条件分支指令时，它在概念上分叉两个符号解释器，一个用于真正的分支，另一个用于假分支。对于每个路径，符号解释器为执行期间遇到的每个分支指令构建路径公式（或路径谓词）。如果存在执行所需路径的具体输入，则路径公式是可满足的。可以通过查询SMT求解器[142]来生成具体输入，以获得路径公式的解。动态符号执行是传统符号执行的变体，其中符号执行和具体执行同时运行。这个想法是具体的执行状态可以帮助减少符号约束的复杂性。除了应用于模糊测试之外，对动态符号执行的学术文献的广泛回顾超出了本文的范围。然而，动态符号执行的更广泛处理可以在[16,173]中找到。 5.3.2 引导式模糊测试一些模糊器利用静态或动态程序分析技术来增强模糊测试的有效性。这些技术通常涉及两个阶段的模糊测试：（i）用于获得关于PUT的有用信息的昂贵程序分析，以及（ii）在先前分析的指导下生成测试用例。这在表1的第六列（第9页）中表示。例如，TaintScope [201]使用细粒度污点分析来查找“热字节”，这是流入关键系统调用或API调用的输入字节。其他安全研究人员提出了类似的想法[69,103]。 Dowser [91]在编译期间执行静态分析，以找到可能包含基于启发式的错误的循环。具体来说，它查找包含指针解引用的循环。然后，它使用污点分析计算输入字节和候选循环之间的关系。最后，Dowser运行动态符号执行，同时只使关键字节成为符号，从而提高性能。VUzzer [164]和GRT [132]利用静态和动态分析技术从PUT中提取控制和数据流特征，并使用它们来指导输入生成。 Angora [50]通过使用污点分析将每个路径约束与相应的字节相关联来改进“热字节”的想法。然后，它通过梯度下降算法进行搜索，以指导其突变以解决这些约束。 5.3.3 PUT 突变模糊测试的一个实际挑战是绕过校验和验证。例如，当PUT在解析输入之前计算输入的校验和时，来自模糊器的大多数生成的测试用例将被PUT拒绝。为了应对这一挑战，TaintScope [201]提出了一种校验和感知模糊测试技术，该技术通过污点分析识别校验和测试指令，并修补PUT以绕过校验和验证。一旦发现程序崩溃，它们就会为输入生成正确的校验和，以生成一个崩溃未修改的PUT的测试用例。 Caballero [40]提出了一种称为拼接动态符号执行的技术，它可以在校验和存在的情况下生成测试用例。 T-Fuzz [158]扩展了这个想法，通过灰盒模糊来有效地穿透所有类型的条件分支。它首先构建一组非关键检查（NCC），这些检查是可以在不修改程序逻辑的情况下进行转换的分支。当模糊测试活动停止发现新路径时，它会选择NCC，对其进行转换，然后在修改后的PUT上重新启动模糊测试活动。最后，当发现崩溃模糊转换程序时，T-Fuzz尝试使用符号执行在原始程序上重建它。 6. 输入评估生成输入后，模糊器执行输入，并决定如何处理该输入。由于模糊测试的主要动机是发现违反安全策略的行为，因此模糊测试程序必须能够检测到执行违反安全策略的行为。该策略的实现称为bug oracle，O_bug（参见§2.1）。 oracle标记的输入通常在被分类后写入磁盘。如算法1所示，为模糊器生成的每个输入调用oracle。因此，oracle能够有效地确定输入是否违反安全策略是至关重要的。 回想一下§3，一些模糊器还在执行每个输入时收集附加信息，以改善模糊测试过程。 Preprocess和InputEval在许多模糊器中彼此紧密耦合，因为检测到的PUT（来自Preprocess）将在执行时输出附加信息（来自InputEval）。 6.1执行优化我们的模型考虑按顺序执行单个模糊迭代。虽然这种方法的直接实现只是在每次模糊迭代开始时开始新过程时加载PUT，但是可以显着加速重复加载过程。为此，现代模糊器提供了跳过这些重复加载过程的功能。例如，AFL [211]提供了一个fork-server，它允许每个新的模糊迭代从已经初始化的进程中fork。类似地，内存中模糊测试是优化执行速度的另一种方法，如第3.1.2节中所述。无论确切的机制如何，加载和初始化PUT的开销都会在很多次迭代中摊销。Xu等人 [209]通过设计一个替换fork（）的新系统调用，进一步降低了迭代的成本。 6.2 Bug Oracles与模糊测试一起使用的规范安全策略认为每个程序执行都会被致命信号（例如分段错误）终止。此策略检测到许多内存漏洞，因为使用无效值覆盖数据或代码指针的内存漏洞通常会导致分段错误或在取消引用时中止。此外，该策略高效且易于实现，因为操作系统允许模糊器在没有任何仪器的情况下捕获这种异常情况。 但是，传统的检测崩溃的策略不会检测到触发的每个内存漏洞。例如，如果堆栈缓冲区溢出使用有效的内存地址覆盖堆栈上的指针，则程序可能会运行完成且结果无效而不是崩溃，并且模糊器不会检测到此情况。为了缓解这种情况，研究人员提出了各种有效的程序转换，可以检测不安全或不需要的程序行为并中止程序。这些通常被称为sanitizers。 内存和类型安全。内存安全错误可以分为两类：空间和时间。非正式地，当指针被访问到其预期范围之外时，会发生空间存储器错误。例如，缓冲区溢出和下溢是空间内存错误的典型示例。在指针不在有效后访问时会发生时间内存错误。例如，use-after-free 漏洞，当一片内存的指针被释放之后又被使用，这是典型的时间内存错误。 Address Sanitizer（ASan）[177]是一个快速存储器错误检测器，可在编译时检测程序。 ASan可以检测空间和时间内存错误，平均减速仅为73％，使其成为基本碰撞安全带的有吸引力的替代品。 ASan采用了一个影子存储器，允许每个存储器地址在被解除引用之前被快速检查其有效性，从而允许它检测许多（但不是全部）不安全的存储器访问，即使它们不会使原始程序崩溃。 MEDS [94]通过利用64位虚拟空间提供的近乎无限的内存空间并创建redzones来改进ASAN。 SoftBound / CETS[148,149]是另一种在编译过程中监控程序的内存错误检测器。然而，SoftBound / CETS不是像ASan那样跟踪有效的内存地址，而是将边界和时间信息与每个指针相关联，理论上可以检测所有空间和时间内存错误。然而，正如预期的那样，这种完整性带来了更高的平均开销116％[149]。 CaVer[123]，TypeSan[90]和HexType[106]在编译期间插桩程序，以便它们可以检测C ++类型转换中的错误转换。当对象转换为不兼容的类型时，例如当基类的对象强制转换为派生类型时，会发生错误的转换。事实证明，CaVer可以扩展到Web浏览器，这些浏览器历来包含这种类型的漏洞，并且开销在7.6到64.6％之间。 另一类存储器安全保护是控制流完整性[10,11]（CFI），它在运行时检测原始程序中不可能的控制流转换。 CFI可用于检测非法修改程序控制流的测试用例。最近一个专注于防范CFI违规子集的项目已经进入主流gcc和clang编译器[191]。 未定义的行为。诸如C之类的语言包含许多由语言规范未定义的行为。编译器可以以各种方式自由处理这些构造。在许多情况下，程序员可以（有意或无意地）编写他们的代码，这样它只对某些编译器实现是正确的。虽然这看起来似乎不太危险，但许多因素都会影响编译器如何实现未定义的行为，包括优化设置，体系结构，编译器甚至编译器版本。当编译器的未定义行为的实现与程序员的期望不匹配时，通常会出现漏洞和错误[202]。 Memory Sanitizer（MSan）是一种工具，可以在编译期间检测程序，以检测由于在C和C ++中使用未初始化的内存而导致的未定义行为[183]。与ASan类似，MSan使用一个影子内存来表示每个可寻址位是否已初始化。 Memory Sanitizer的开销约为150％。 Undefied Behavior Sanitizer（UBSan）[65]在编译时修改程序以检测未定义的行为。与其他专注于未定义行为的特定来源的检测工具不同，UBSan可以检测各种未定义的行为，例如使用未对齐的指针，除以零，解除引用空指针和整数溢出。 Thread Sanitizer（TSan）[178]是一种编译时修改，它通过精度和性能之间的权衡来检测数据竞争。当两个线程同时访问共享内存位置并且至少一个访问是写入时，发生数据争用。这样的错误可能导致数据损坏，并且由于非确定性而极难重现。 输入验证。测试输入验证漏洞（如XSS（跨站点脚本）和SQL注入漏洞）是一个具有挑战性的问题，因为它需要了解为Web浏览器和数据库引擎提供支持的非常复杂的解析器的行为。KameleonFuzz [68]通过使用真实Web浏览器解析测试用例，提取文档对象模型树，并将其与人工提取的XSS工具模式进行比较来检测成功的XSS攻击。 μ4SQLi[17]使用类似的技巧来检测SQL注入。由于无法从Web应用程序响应中可靠地检测SQL注入，因此μ4SQLi使用数据库代理拦截目标Web应用程序与数据库之间的通信，以检测输入是否触发了有害行为。 语义差异。通常通过比较类似（但不同）的程序来发现语义错误。它通常被称为差分测试[135]，并被几个模糊器[37,53,159]使用。在这种情况下，bug oracle是作为一组类似的程序给出的。Jung等人 [111]引入了术语黑盒差分模糊测试，它测量了给定两个或更多不同输入的PUT输出之间的差异。根据输出之间的差异，它们检测PUT的信息泄漏。 6.3 分类分类是分析和报告导致违反策略的测试用例的过程。分类可以分为三个步骤：重复数据删除，优先级排序和测试用例最小化。 6.3.1 重复数据删除重复数据删除是从输出集中修剪与其它测试样例触发相同的错误的测试样例的过程，理想情况下，重复数据删除会返回一组测试用例，其中每个测试用例都会触发一个独特的错误。 由于多种原因，重复数据删除是大多数模糊器的重要组成部分。作为一种实际的实现方式，它通过在删除硬盘上存储重复的结果来避免浪费磁盘空间和其他资源。作为可用性考虑因素，重复数据删除使用户可以轻松了解存在多少不同的错误，并能够分析每个错误的示例。这对各种模糊用户都很有用；例如，攻击者可能只想查看可能导致可靠利用的“home run”漏洞。 目前在实践中使用了两种主要的重复数据删除实现：堆栈回溯哈希和基于覆盖的重复数据删除。 堆栈回溯哈希(Stack Backtrace Hashing )。堆栈回溯哈希[141]是用于重复数据删除崩溃的最古老和最广泛使用的方法之一，其中自动化工具在崩溃时记录堆栈回溯，并根据该回溯的内容分配堆栈散列。例如，如果程序在函数foo中执行一行代码时崩溃，并且调用堆栈为main→d→c→b→a→foo，那么n = 5的堆栈回溯散列实现会将所有执行组合在一起回溯以d→c→b→a→foo结束。 堆栈哈希实现差别很大，从哈希中包含的堆栈帧数开始。一些实现使用一个[18]，三个[141,206]，五个[45,76]，或者没有任何限制[115]。实现方式也包括每个堆栈帧中包含的信息量。某些实现只会哈希函数的名称或地址，但其他实现将哈希名称和偏移量或行。这两个选项都不能很好地工作，因此一些实现[76,137]产生两个哈希：主要和次要哈希。主要哈希很可能将不同的崩溃组合在一起，因为它只散列函数名称，而次要散列更精确，因为它使用函数名称和行号，并且还包括无限数量的堆栈帧。 虽然堆栈回溯哈希被广泛使用，但它并非没有缺点。堆栈回溯哈希的基本假设是类似的崩溃是由类似的错误引起的，反之亦然，但据我们所知，这个假设从未被直接测试过。有一些理由怀疑它的真实性：在导致崩溃的代码附近不会发生一些崩溃。例如，导致堆损坏的漏洞可能仅在代码的不相关部分尝试分配内存时崩溃，而不是在发生堆溢出时崩溃。 基于覆盖的重复数据删除（Coverage-based Deduplication ）。 AFL [211]是一种流行的灰盒模糊器，它采用高效的源代码检测器来记录PUT每次执行的边缘覆盖范围，并测量每个边缘的粗略命中计数。作为灰盒模糊器，AFL主要使用此覆盖信息来选择新的种子文件。但是，它也会导致相当独特的重复数据删除方案。正如其文档中所描述的那样，如果（i）碰撞覆盖了以前看不见的边缘，或者（ii）碰撞未覆盖所有早期碰撞中存在的边缘，AFL认为碰撞是唯一的。 语义感知的重复数据删除。Cui等人[59]提出了一个名为RETracer的系统，根据从反向数据流分析中恢复的语义对崩溃进行分类。具体来说，在崩溃之后，RETracer会检查哪个指针导致崩溃，并以递归方式识别哪个指令为其分配了错误值。它最终找到一个具有最大帧级别的函数，并“blames”该函数。blames功能可用于群集崩溃。作者表明，他们的技术成功地将数百万个Internet Explorer bugs合并为一个，这些漏洞通过堆栈散列分散到大量不同的组中。 6.3.2 优先级和可利用性优先级，a.k.a.fuzzer taming问题[52]，是根据严重性和唯一性对违反测试用例进行排名或分组的过程。传统上使用模糊测试来发现内存漏洞，在这种情况下，优先级更好地称为确定崩溃的可利用性。可利用性非正式地描述了攻击者能够为测试用例暴露的漏洞编写实际漏洞的可能性。防御者和攻击者都对可利用的漏洞感兴趣。防御者通常会在不可利用的漏洞之前修复可利用的漏洞，并且出于显而易见的原因，攻击者对可利用的漏洞感兴趣。 第一个可利用性排名系统之一是Microsoft的 !exploitable` [137]，它的名字来自它提供的 !exploitable 的WinDbg命令名称。 ！exploitable采用了几种启发式方法，并配有简化的污点分析[153,173]。它按以下严重性等级对每次崩溃进行分类：EXPLOITABLE&gt; PROBABLY_EXPLOITABLE&gt; UNKNOWN&gt; NOT_LIKELY_EXPLOITABLE，其中x&gt; y表示x比y严重。虽然这些分类没有正式定义，但是可利用的非正式意图是保守和错误报告的东西比它更具可利用性。例如，！exploitable断定，如果执行非法指令，则崩溃是可利用的，这是基于攻击者能够劫持控制流的假设。另一方面，除零崩溃被视为NOT_LIKELY_EXPLOITABLE。 自从！exploitable被引入以来，已经提出了其他类似的基于规则的启发式系统，包括GDB [76]和Apple的CrashWrangler `[18]的可利用插件。然而，它们的正确性尚未得到系统的研究和评估。 6.3.3测试用例最小化分类的另一个重要部分是测试用例最小化。测试用例最小化是识别触发违规所必需的违规测试用例部分的过程，并且可选地产生比原始测试用例更小且更简单但仍然导致违规的测试用例。 一些模糊器使用自己的实现和算法。 BFF [45]包括针对模糊测试[99]的最小化算法，其尝试最小化与原始种子文件不同的比特数。AFL [211]还包括一个测试用例最小化器，它试图通过机会性地将字节设置为零并缩短测试用例的长度来简化测试用例。Lithium[167]是一种通用测试用例最小化工具，它通过尝试以指数递减的大小删除相邻行或字节的“块”来最小化文件。Lithium是由JavaScript模糊器（如jsfunfuzz [143]）生成的复杂测试案例推动的。 还有各种测试用例减少器，它们不是专门用于模糊测试，但仍可用于模糊测试识别的测试用例。这些包括格式不可知技术，如delta调试[216]，以及特定格式的专用技术，如C-Reduce [166]用于C / C ++文件。尽管专业技术明显受限于它们可以减少的文件类型，但它们的优势在于它们可以比通用技术更有效，因为它们了解它们试图简化的语法。 7.配置更新(CONFIGURATION UPDATING )ConfUpdate函数在区分黑盒模糊器与灰盒和白盒模糊器的行为方面起着关键作用。如算法1中所讨论的，ConfUpdate函数可以基于在当前模糊测试运行期间收集的配置和执行信息来修改配置集（C）。在最简单的形式中，ConfUpdate返回未修改的C参数。除了评估bug oracle O_bug之外，黑盒模糊器不执行任何程序自我测试，因此它们通常不会修改C，因为它们没有收集任何允许它们修改它的信息。 但是，灰色和白盒模糊器的主要区别在于它们更复杂的ConfUpdate函数实现，它允许它们包含新的模糊配置，或者删除可能已被取代的旧模糊配置。 ConfUpdate允许在一次迭代期间传输收集的信息，以便在将来的循环迭代期间使用。例如，白盒模糊器中的路径选择启发式通常会为每个生成的新测试用例创建一个新的模糊配置。 7.1进化种子库更新进化算法（EA）是一种基于启发式的方法，涉及生物进化机制，如突变，重组和选择。尽管EA看似非常简单，但它构成了许多灰盒模糊器的基础[7,198,211]。他们维持一个种子库，这是在模糊测试期间EA演变的人口。选择要变异的种子和突变本身的过程分别在§4.3和§5中详述。 可以说，EA最重要的一步是将新配置添加到配置集C中，这对应于模糊测试的ConfUpdate步骤。大多数模糊器通常使用节点或分支覆盖作为适应度函数：如果测试用例发现新节点或分支，则将其添加到种子池中。 AFL [211]进一步考虑了分支机构被采取的次数。Angora[158]通过考虑每个分支的调用上下文来改进AFL的适应性标准。 Steelix [126]检查哪个输入偏移影响PUT的比较指令的过程以及进化种子池的代码覆盖率。 VUzzer [164]仅在发现新的非错误处理基本块时才向C添加配置。他们的见解是将时间投入到程序分析中，以获得特定应用知识，从而提高EA效率。具体地，VUzzer为每个基本块定义权重，并且配置的适合度是每个运动的基本块上的频率的对数的加权和。 VUzzer具有内置的程序分析功能，可将基本块分类为普通和错误处理（EH）块。根据经验，他们的假设是，遍历EH块表示漏洞的可能性较低，因为可能由于未处理的错误而发生错误。对于正常块，其权重与包含该块的CFG上的随机游走根据VUzzer定义的转移概率访问它的概率成反比。对于EH块，其权重为负，并且是基本块的数量与此配置所执行的EH块的数量之间的缩放比率。实际上，这使得VUzzer更喜欢采用上述随机游走所认为罕见的正常块的配置。 7.2 维护Minset由于能够创建新的模糊测试配置，因此还存在创建过多配置的风险。用于降低此风险的常见策略是维护最小化或最小化测试用例集，以最大化覆盖度量。在预处理期间也使用Minsetting，并在§3.2中有更详细的描述。 一些模糊器使用维护专用于配置更新的minset的变体。作为一个例子，AFL [211]使用剔除程序将minset配置标记为有利，而不是完全删除不在minset中的配置（这是Cyberdyne [86]所做的）。通过调度函数，有利的模糊测试配置被选择用于模糊测试的可能性显着提高。 AFL的作者指出“这在队列循环速度和测试用例多样性之间提供了合理的平衡”[215]。 8. 结束语正如我们在§1中所阐述的那样，本文的第一个目标是提炼出对现代fuzzing文献的全面而连贯的观点。为此，我们首先提出了一个通用模型模糊器以方便我们解释当前使用中的多种形式的模糊测试。然后，我们使用图1（第7页）和表1（第9页）说明了对模糊器的丰富分类。我们通过讨论设计决策以及展示整个社区的众多成就，探索了模型模糊器的每个阶段。","content":"<h1 id=\"Abstract\"><a href=\"#Abstract\" class=\"headerlink\" title=\"Abstract\"></a>Abstract</h1><p>在当今可用的众多软件漏洞发现技术中，模糊测试由于其概念简单，部署的低屏障以及发现现实世界软件漏洞的大量经验证据而一直非常受欢迎。虽然近年来研究人员和从业人员都为改进模糊测试投入了大量不同的努力，但这项工作的激增也使得难以获得全面和一致的模糊测试观点。为了帮助保存并使大量的模糊测量文献保持连贯性，本文提出了一种统一的，通用的模糊测试模型以及当前模糊文献的分类。我们通过调查相关文献和艺术，科学和工程方面的创新，有条不紊地探索模型模糊器的每个阶段的设计决策，使现代模糊器有效。</p>\n<table>\n<thead>\n<tr>\n<th>relevant information</th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><em>作者</em></td>\n<td>VALENTIN J.M. MANÈS，HYUNGSEOK HAN,CHOONGWOO HAN,SANG KIL CHA∗,MANUEL EGELE,EDWARD J. SCHWARTZ,MAVERICK WOO,</td>\n</tr>\n<tr>\n<td><em>单位</em></td>\n<td></td>\n</tr>\n<tr>\n<td><em>出处</em></td>\n<td>CSUR‘19</td>\n</tr>\n<tr>\n<td><em>原文地址</em></td>\n<td><a href=\"https://github.com/wtwofire/database/blob/master/papers/fuzzing/Review/2019-fuzzing%EF%BC%9A%20Art%2C%20Science%2C%20and%20Engineering.pdf\" target=\"_blank\" rel=\"noopener\">https://github.com/wtwofire/database/blob/master/papers/fuzzing/Review/2019-fuzzing%EF%BC%9A%20Art%2C%20Science%2C%20and%20Engineering.pdf</a></td>\n</tr>\n<tr>\n<td><em>源码地址</em></td>\n<td></td>\n</tr>\n<tr>\n<td><em>发表时间</em></td>\n<td>2019</td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"1-简介\"><a href=\"#1-简介\" class=\"headerlink\" title=\"1. 简介\"></a>1. 简介</h1><p>自从20世纪90年代初引入[139]以来，模糊测试一直是发现软件安全漏洞的最广泛部署的技术之一。在高级别，模糊测试指的是重复运行程序和构造的输入的过程，该输入可能在语法上或语义上不正确。在实践中，攻击者通常在诸如漏洞利用生成和渗透测试的场景中部署模糊测试[20,102]; 2016年DARPA网络大挑战赛（CGC）的几支队伍也在他们的网络推理系统中使用模糊测试[9,33,87,184]。在这些活动的推动下，防御者开始使用模糊测试来试图在攻击者发现漏洞之前发现漏洞。例如，Adobe [1]，Cisco [2]，Google [5,14,55]和Microsoft [8,34]等知名厂商都将模糊测试作为其安全开发实践的一部分。最近，安全审计员[217]和开源开发人员[4]也开始使用模糊测试来衡量商品软件包的安全性，并为最终用户提供一些合适的保证形式。</p>\n<p>模糊社区非常有活力。在撰写本文时，仅GitHub就拥有了超过一千个与模糊测试相关的公共存储库[80]。正如我们将要展示的那样，文献中还包含大量的模糊器（参见第7页的图1），并且越来越多的模糊测试研究出现在主要安全会议上（例如[33,48,164,165,199,206] ]）。此外，博客圈中充满了许多模糊测试的成功故事，其中一些还包含了我们认为是<a href=\"https://goo.gl/37GYKN\" target=\"_blank\" rel=\"noopener\">精华</a>的东西，这些精华在文献中占有一席之地。</p>\n<p>不幸的是，研究人员和从业人员在模糊测试方面的工作激增也带来了阻碍进展的警告信号。例如，一些模糊器的描述不会超出其源代码和手册页。因此，随着时间的推移，很容易忘记这些模糊测试中的设计决策和潜在的重要调整。此外，各种模糊器使用的术语中存在可观察到的碎片。例如，虽然AFL [211]使用术语“测试用例最小化”来指代减小崩溃输入大小的技术，但同样的技术在funfuzz中也被称为“测试用例减少”[143]。虽然BFF [45]包含一种称为“崩溃最小化”的技术，听起来非常相似，但崩溃最小化的目的实际上是最小化崩溃输入和原始种子文件之间不同的位数，而不是减少崩溃输入的大小。我们认为这种分散使得难以发现和传播 fuzzing 知识，从长远来看，这可能严重阻碍 fuzzing 研究的进展。</p>\n<p>基于我们的研究和我们在模糊测试方面的个人经验，本文作者认为现在是整合和提炼模糊测试大量进展的黄金时间，其中许多是在2007-2008 [73,187,189]年出版的三本关于该主题的贸易书籍之后发生的 。我们注意到Li等人同时进行了调查。 [125]侧重于基于覆盖的模糊测试的最新进展，但我们的目标是提供有关该领域近期发展的综合研究。为此，我们将首先使用§2来展示我们的模糊术语和统一的模糊测试模型。坚持本文的目的，选择我们的模糊术语来密切反映当前的主要用法，我们的模型模糊器（算法1，第4页）旨在适应大量的模糊测试任务，如分类在目前的模糊文献（图1，第7页）。通过这种设置，我们将在§3-§7中有条不紊地探索模型模糊器的每个阶段，并在表1中详细介绍主要模糊器（第9页）。<br>在每个阶段，我们将调查相关文献来解释设计选择，讨论重要的权衡，并突出许多奇妙的工程努力，帮助使现代模糊器有效地完成他们的任务。</p>\n<h1 id=\"2-系统化，分类和测试程序\"><a href=\"#2-系统化，分类和测试程序\" class=\"headerlink\" title=\"2. 系统化，分类和测试程序\"></a>2. 系统化，分类和测试程序</h1><p>术语“fuzz”最初由Miller等人创造。在1990年，它指的是“生成一个由目标程序消耗的随机字符流”的程序[139，p.4]。从那时起，模糊的概念及其动作 - “fuzzing” - 出现在各种各样的语境中，包括动态符号执行[84,207]，基于语法的测试用例生成[82,98,196]，权限测试[21,74]，行为测试[114,163,205]，表示依赖性测试[113]，函数检测[208]，健壮性评估[204]，漏洞利用开发[104]，GUI测试[181]，签名生成[66]和渗透测试[75,145]。为了使大量的模糊测试文献中的知识系统化，让我们首先提出从当前使用中提取的模糊测试术语。</p>\n<h2 id=\"2-1-Fuzzing-amp-Fuzzing-Testing\"><a href=\"#2-1-Fuzzing-amp-Fuzzing-Testing\" class=\"headerlink\" title=\"2.1 Fuzzing &amp; Fuzzing Testing\"></a>2.1 Fuzzing &amp; Fuzzing Testing</h2><p>直观地说，fuzzing是使用“模糊输入”运行被测程序（PUT）的行为。Honoring Miller等人，我们认为模糊输入是PUT可能不期望的输入，即PUT可能错误处理的输入并且触发PUT开发者无意识的行为。为了捕捉这个想法，我们将术语fuzzing定义如下。</p>\n<blockquote>\n<p><strong>定义2.1（fuzzing）</strong>。模糊测试是使用从输入空间（“模糊输入空间”）采样的输入执行PUT，该输入空间突出了PUT的预期的输入空间。</p>\n</blockquote>\n<p>三个评论是有序的。首先，尽管通常看到模糊输入空间包含预期的输入空间，但这不是必需的 - 前者包含d的输入不在后者中就足够了。其次，在实践中，模糊测试几乎肯定会进行多次迭代;因此，在上面写“重复执行”仍然很准确。第三，抽样过程不一定是随机的，我们将在§5中看到.</p>\n<p>Fuzz testing是一种利用fuzzing的软件测试技术。为了区别于其他人并尊重我们认为最突出的目标，我们认为它有一个特定的目标，即找到与安全相关的错误，其中包括程序崩溃。此外，我们还定义了fuzzer和fuzz campaign，这两者都是模糊测试中的常用术语。</p>\n<blockquote>\n<p><strong>定义2.2（Fuzz Testing）</strong>。Fuzz Testing是使用fuzzing，其目标是测试PUT违反安全策略的地方。<br><strong>定义2.3（Fuzzer）</strong>。Fuzzer是一种在PUT上执行fuzz testing的程序。<br><strong>定义2.4（Fuzz Campaign）</strong>。Fuzz Campaign是一个在有特定安全策略的PUT上的特定执行的Fuzzer。</p>\n</blockquote>\n<p>通过fuzzing campaign运行PUT的目的是找到违反所需安全策略的错误[23]。例如，早期fuzzer使用的安全策略仅测试生成的输入 - 测试用例 - 是否使PUT崩溃。但是，fuzz testing 实际上可用于测试任何可执行的安全策略，即EMenforceable [171]。决定执行是否违反安全策略的具体机制称为<strong>bug oracle</strong>。</p>\n<blockquote>\n<p><strong>定义2.5（Bug Oracle）</strong>。 bug oracle是一个程序，可能作为fuzzer的一部分，用于确定PUT的给定执行是否违反特定的安全策略。</p>\n</blockquote>\n<p> 我们将fuzzer实现的算法简称为<strong>“fuzz algorithm”</strong>。几乎所有 fuzz algorithm都依赖于PUT之外的一些参数（路径）。参数的每个具体设置都是<strong>fuzz configuration：</strong></p>\n<blockquote>\n<p><strong>定义2.6（Fuzz Configuration）</strong>。fuzz algorithm的fuzz configuration包括控制fuzz algorithm的参数值。</p>\n</blockquote>\n<p>Fuzz configuration通常被写为元组。请注意，fuzz configuration中的值类型取决于fuzz algorithm的类型。例如，将随机字节流发送到PUT [139]的fuzz algorithm具有简单的配置空间{（PUT）}。另一方面，复杂的fuzzer包含接受一组配置并随时间推移设置的算法 - 这包括添加和删除配置。例如，CERT BFF [45]在活动过程中改变了突变率和种子（在第5.2节中定义），因此其配置空间为{(PUT，s1，r1)，(PUT，s2，r2）,. … }。最后，对于每个配置，我们还允许fuzzer存储一些数据。例如，覆盖引导的模糊器可以存储每个配置的获得的覆盖范围。</p>\n<h2 id=\"2-2-Paper-Selection-Criteria\"><a href=\"#2-2-Paper-Selection-Criteria\" class=\"headerlink\" title=\"2.2 Paper Selection Criteria\"></a>2.2 Paper Selection Criteria</h2><p>为了达到明确的范围，我们选择在2008年1月至2018年5月的4个主要安全会议和3个主要软件工程会议的最后一个议程中包括所有关于模糊测试的出版物。按字母顺序排列，前者包括（i）ACM会议计算机和通信安全（<code>CCS</code>），（ii）IEEE安全和隐私（<code>S＆P</code>）研讨会，（iii）网络和分布式系统安全研讨会（<code>NDSS</code>），以及（iv）USENIX安全研讨会（<code>USEC</code>）;后者包括（i）ACM国际软件工程基础研讨会（<code>FSE</code>），（ii）IEEE / ACM自动软件工程国际会议（<code>ASE</code>），以及（iii）国际软件工程会议（<code>ICSE</code>）。对于出现在其他场所或媒介中的作品，我们根据自己对其相关性的判断将它们包括在内。</p>\n<p>正如§2.1中所提到的，fuzz testing与软件测试的区别仅在于它与安全相关。尽管瞄准安全漏洞并不意味着除了在理论上使用bug oracle之外的测试过程中存在差异，但所使用的技术在实践中通常会有所不同。在设计测试工具时，我们经常假设源代码的存在和PUT的知识。与fuzzer相比，这些假设通常会将工具的开发推向不同的形状。尽管如此，这两个领域仍然彼此纠缠不清。因此，当我们自己的判断力不足以区分它们时，我们遵循一个简单的经验法则：如果出版物中没有出现fuzz这个词，我们就不包括它。</p>\n<h2 id=\"2-3-Fuzz-Testing-Algorithm\"><a href=\"#2-3-Fuzz-Testing-Algorithm\" class=\"headerlink\" title=\"2.3 Fuzz Testing Algorithm\"></a>2.3 Fuzz Testing Algorithm</h2><p>我们提出了一种用于fuzz testing的通用算法，算法1，我们想象它已经在模型fuzzer中实现。它足以适应现有的模糊测试技术，包括§2.4中定义的黑色，灰色和白盒模糊测试。算法1将一组fuzz configurations C和一个超时 t_limit 作为输入，并输出一组发现的错误B.它由两部分组成。第一部分是预处理功能，它在fuzz campaign开始时执行。第二部分是循环内的一系列五个函数：<strong>Schedule，InputGen，InputEval，ConfUpdate和Continue</strong>。此循环的每次执行都称为<strong>fuzz iteration</strong>，并且在单个测试用例上执行InputEval称为<strong>fuzz run</strong>。请注意，一些模糊器不会实现所有五个功能。例如，为了模拟Radamsa [95]，我们让ConfUpdate简单地返回C，即它不会更新C.</p>\n<p><img src=\"/2019/03/20/Fuzzing-Art-Science-and-Engineering/1.Fuzz Test.jpg\" alt=\"Fuzz Test\"></p>\n<p><strong>Preprocess（C）–&gt;C</strong></p>\n<blockquote>\n<p> 用户为Preprocess提供一组fuzz configurations作为输入，并返回一组可能已修改的fuzz configurations。根据fuzz algorithm，Preprocess可以执行各种操作，例如将检测代码插入PUT，或测量种子文件的执行速度。见§3</p>\n</blockquote>\n<p><strong>Schedule(C,telapsed,tlimit) –&gt; conf </strong></p>\n<blockquote>\n<p>Schedule接收当前的fuzz configurations，当前时间t_elapsed和超时t_limit作为输入，并选择要用于当前模糊迭代的fuzz configuration。见§4。</p>\n</blockquote>\n<p><strong>InputGen（conf）–&gt;tcs </strong></p>\n<blockquote>\n<p>InputGen将fuzz configurations作为输入，并返回一组具体测试用例 tcs 作为输出。生成测试用例时，InputGen使用conf中的特定参数。一些模糊测试器使用conf中的种子来生成测试用例，而其他模糊器则使用模型或语法作为参数。见§5。</p>\n</blockquote>\n<p><strong>InputEval (conf, tcs, Obug) –&gt; B′, execinfos</strong></p>\n<blockquote>\n<p>InputEval采用fuzz配置conf，一组测试用例 tcs 和一个bug oracle Obug作为输入。它在tcs上执行PUT并使用bug oracle O_bug检查执行是否违反了安全策略。然后它输出发现的错误集B’和关于每个fuzz运行的信息 execinfos。我们假设O_bug嵌入在我们的模型模糊器中。见§6。</p>\n</blockquote>\n<p><strong>ConfUpdate(C，conf，execinfos) –&gt; C </strong></p>\n<blockquote>\n<p>ConfUpdate采用一组fuzz configurations C，当前配置 conf，以及每个模糊运行的信息 execinfos作为输入。它可能会更新一组fuzz configurations C.例如，许多灰盒模糊器会根据execinfos减少C中的模糊配置数量。见§7。</p>\n</blockquote>\n<p><strong>Continue (C) –&gt;  {True, False} </strong></p>\n<blockquote>\n<p>Continue将一组fuzz configurations C作为输入，并输出一个布尔值，指示是否应该进行下一个模糊迭代。此功能对于模型白盒模糊器很有用，当没有更多路径可以发现时，它可以终止。</p>\n</blockquote>\n<h2 id=\"2-4-Fuzzers-的分类\"><a href=\"#2-4-Fuzzers-的分类\" class=\"headerlink\" title=\"2.4  Fuzzers 的分类\"></a>2.4  Fuzzers 的分类</h2><p>在本文中，我们根据模糊器在每个模糊运行中观察到的语义粒度将模糊器分为三组：黑盒，灰盒和白盒fuzzer。请注意，这与传统的软件测试不同，传统的软件测试只有两个主要类别（黑盒和白盒测试）[147]。正如我们将在§2.4.3中讨论的那样，灰盒模糊测试是白盒模糊测试的一种变体，它只能从每次模糊运行中获取一些部分信息。 </p>\n<p>图1按时间顺序列出了现有fuzzer的分类。从Miller等人的开创性工作开始。 [139]，我们手动选择了在大型会议上出现或获得超过100个GitHub stars的流行fuzzer，并将其关系显示在图上。黑盒fuzzer位于图的左半部分，灰盒和白盒模糊器位于右半部分。</p>\n<p><img src=\"/2019/03/20/Fuzzing-Art-Science-and-Engineering/2.jpg\" alt=\"2\"></p>\n<p>表1详细介绍了主要会议上出现的每个主要fuzzer所使用的技术。由于空间限制，我们省略了几个主要的fuzzer。每个模糊器都投影在我们上面提到的模型模糊器的五个功能上，其中一个杂项部分提供了有关fuzzer的额外细节。第一列（检测粒度）表示基于静态或动态分析从PUT获取多少信息。当fuzzer在两个阶段使用不同类型的插桩时，出现两个圆圈。例如，SymFuzz [48]运行白盒分析作为预处理，以便为随后的黑盒活动提取信息，而Driller [184]在白盒和灰盒模糊之间交替进行。</p>\n<ul>\n<li><p><strong>第二列</strong>显示来源是否公开。</p>\n</li>\n<li><p><strong>第三列</strong>表示模糊器是否需要源代码才能运行。</p>\n</li>\n<li><p><strong>第四列</strong>指出了模糊器是否支持内存模糊测试（参见§3.1.2）。</p>\n</li>\n<li><p><strong>第五列</strong>是关于fuzzer是否可以推断模型（参见§5.1.2）。</p>\n</li>\n<li><p><strong>第六列</strong>显示了在Preprocess中，fuzzer是执行静态分析还是动态分析。<strong>第七列</strong>指示fuzzers是否支持处理多个种子，并执行调度。</p>\n</li>\n<li><p><strong>变异列</strong>指定fuzzers是否执行输入变异以生成测试用例。我们使用“半黑半白”来表示fuzzer根据执行反馈引导输入变异。基于模型的专栏是关于fuzzer是否基于模型生成测试用例。</p>\n</li>\n<li><p><strong>基于约束的列</strong>显示fuzzers执行符号分析以生成测试用例。<strong>污点分析列</strong>意味着模糊测试器利用污点分析来指导其测试用例生成过程。</p>\n</li>\n<li><p><strong>InputEval部分</strong>中的两列显示fuzzers是使用堆栈哈希还是使用代码覆盖率执行崩溃分类。</p>\n</li>\n<li><p><strong>ConfUpdate部分</strong>的第一列指示在ConfUpdate期间模糊器是否进化种子池，例如，向池中添加有趣的种子（参见§7.1）。 ConfUpdate部分的第二列是关于fuzzers是否以在线方式学习模型。最后，ConfUpdate部分的第三列显示了从种子池中删除种子（参见§7.2）。</p>\n</li>\n</ul>\n<p><img src=\"/2019/03/20/Fuzzing-Art-Science-and-Engineering/3.jpg\" alt=\"表1\"></p>\n<h3 id=\"2-4-1黑盒fuzzer\"><a href=\"#2-4-1黑盒fuzzer\" class=\"headerlink\" title=\"2.4.1黑盒fuzzer\"></a>2.4.1黑盒fuzzer</h3><p>术语“黑盒”通常用于软件测试[29,147]，fuzzing表示没有看到PUT内部的技术 - 这些技术只能观察PUT的输入/输出行为，将其视为一个黑盒子。在软件测试中，黑盒测试也称为IO驱动或数据驱动测试[147]。大多数传统的模糊器[6,13,45,46,96]属于这一类。一些现代模糊器，例如<code>funfuzz</code> [143]和<code>Peach</code> [70]，也考虑了有关输入的结构信息，以生成更有意义的测试用例，同时保持不检查PUT的特性。类似的直觉用于自适应随机测试[51]。</p>\n<h3 id=\"2-4-2白盒Fuzzer\"><a href=\"#2-4-2白盒Fuzzer\" class=\"headerlink\" title=\"2.4.2白盒Fuzzer\"></a>2.4.2白盒Fuzzer</h3><p>在频谱的另一个极端，白盒模糊[84]通过分析PUT的内部和执行PUT时收集的信息来生成测试用例。因此，白盒模糊器能够系统地探索PUT的状态空间。术语白盒模糊是由Godefroid [81]在2007年引入的，它指的是动态符号执行（DSE），它是符号执行的变体[35,101,118]。在DSE中，符号和具体执行同时进行，其中具体的程序状态用于简化符号约束，例如，具体化系统调用。因此，DSE通常被称为concolic testing（具体的+符号的）[83,176]。此外，白盒模糊测试也被用于描述采用污点分析的模糊器[78]。<br>白盒模糊测试的开销通常远高于黑盒模糊测试的开销。这部分是因为DSE实现[22,42,84]经常采用动态插桩和SMT求解[142]。虽然DSE是一个活跃的研究领域[34,82,84,105,160]，但许多DSE不是白盒模糊器，因为它们的目的不是找到安全漏洞。因此，本文没有提供有关DSE的全面调查，我们将读者引用到最近的调查论文[16,173]以获取更多信息。</p>\n<h3 id=\"2-4-3灰盒Fuzzer\"><a href=\"#2-4-3灰盒Fuzzer\" class=\"headerlink\" title=\"2.4.3灰盒Fuzzer\"></a>2.4.3灰盒Fuzzer</h3><p>一些安全专家[62,72,189]提出了一种中间方法，并将其称为灰盒模糊测试。通常，灰盒模糊器可以获得PUT内部和/或其执行的一些信息。与白盒模糊器不同，灰盒模糊器不具备PUT的完整语义;相反，他们可以对PUT执行轻量级静态分析和/或收集有关其执行的动态信息，例如覆盖范围。 Greybox模糊器使用信息近似来测试更多输入。尽管安全专家之间通常存在共识，但黑盒，灰盒和白盒模糊测试之间的区别并不总是很明显。黑盒模糊器可能仍会收集一些信息，而白盒模糊器通常被迫做一些近似。本次调查中的选择，特别是表1中的选择，是有争议的，但是作者最好的判断。</p>\n<p>灰盒模糊器的早期示例是EFS [62]，它使用从每个模糊运行中收集的代码覆盖率来使用进化算法生成测试用例。 <code>Randoop</code> [155]也使用了类似的方法，但它没有针对安全漏洞。现代模糊器如<code>AFL</code> [211]和<code>VUzzer</code> [164]是此类别中的示例。</p>\n<h1 id=\"3-预处理-PREPROCESS\"><a href=\"#3-预处理-PREPROCESS\" class=\"headerlink\" title=\"3 预处理(PREPROCESS)\"></a>3 预处理(PREPROCESS)</h1><p>一些模糊器在第一次模糊迭代之前修改了初始的fuzz configurations。这种预处理通常用于插桩PUT，清除潜在的冗余配置（即(seed selection)种子选择[165]），并修剪种子</p>\n<h2 id=\"3-1-插桩（Instrumentation-）\"><a href=\"#3-1-插桩（Instrumentation-）\" class=\"headerlink\" title=\"3.1 插桩（Instrumentation ）\"></a>3.1 插桩（Instrumentation ）</h2><p>与黑盒模糊器不同，灰盒和白盒模糊器可以在InputEval执行模糊运行（参见§6），或者在运行时模糊内存内容时插桩PUT以收集执行反馈。虽然还有其他方法可以获取PUT内部的信息（例如处理器跟踪或系统调用[86,188]），但插桩通常是收集最有价值信息的方法，因此几乎完全定义了颜色。模糊（从表1的第一列）。</p>\n<p>程序插桩可以是静态的也可以是动态的 - 前者在PUT运行之前发生，而后者在PUT运行时发生。由于静态检测在运行时之前发生，因此它通常比动态检测产生更少的运行时开销。</p>\n<p>静态插桩通常在编译时在源代码或中间代码上执行。如果PUT依赖于库，则必须单独插桩它们，通常通过使用相同的插桩重新编译它们。除了基于源代码的插桩，研究人员还开发了二进制级静态插桩（即二进制重写）工具[71,122,218]。</p>\n<p>虽然它比静态插桩具有更高的开销，但动态插桩的优势在于它可以轻松地插桩动态链接库，因为插桩是在运行时执行的。有几种众所周知的动态插桩工具，如<code>DynInst</code>[161]，<code>DynamoRIO</code> [38]，<code>Pin</code>[131]，<code>Valgrind</code> [152]和<code>QEMU</code> [30]。通常，动态插桩在运行时发生，这意味着它对应于模型中的InputEval。但为了方便读者，我们在本节中总结了静态和动态插桩。</p>\n<p>给定的模糊器可以支持多种类型的插桩。例如，AFL在源代码级别使用修改后的编译器支持静态插桩，或者在QEMU的帮助下支持二进制级别的动态插桩[30]。使用动态插桩时，AFL可以插桩（1）PUT本身的可执行代码（默认设置），或者（2）PUT中的可执行代码和任何外部库（使用AFL_INST_LIBS选项）。第二个选项 - 插桩所有遇到的代码 - 可以报告外部库中代码的覆盖信息，从而提供有关覆盖范围的更完整的图像。但是，这反过来会导致AFL模糊外部库函数中的其他路径。</p>\n<h3 id=\"3-1-1执行反馈（Execution-Feedback-）\"><a href=\"#3-1-1执行反馈（Execution-Feedback-）\" class=\"headerlink\" title=\"3.1.1执行反馈（Execution Feedback. ）\"></a>3.1.1执行反馈（Execution Feedback. ）</h3><p>灰盒模糊器通常将执行反馈作为输入来演化测试用例。 AFL及其后代通过检测PUT中的每个分支指令来计算分支覆盖。但是，它们将分支覆盖信息存储在一个byte向量中，这可能导致路径冲突。 <code>CollAFL</code> [77]最近通过引入一个新的路径敏感哈希函数来解决这个问题。同时，<code>LibFuzzer</code> [7]和<code>Syzkaller</code> [198]使用节点覆盖作为执行反馈。<code>Honggfuzz</code>[188]允许用户选择要使用的执行反馈。</p>\n<h3 id=\"3-1-2-内存模糊测试（In-Memory-Fuzzing-）\"><a href=\"#3-1-2-内存模糊测试（In-Memory-Fuzzing-）\" class=\"headerlink\" title=\"3.1.2 内存模糊测试（In-Memory Fuzzing ）\"></a>3.1.2 内存模糊测试（In-Memory Fuzzing ）</h3><p>在测试大型程序时，有时需要仅模糊PUT的一部分而不为每个模糊迭代重新生成进程，以便最小化执行开销。例如，复杂（例如，GUI）应用程序在接受输入之前通常需要几秒钟的处理。模糊这些程序的一种方法是在初始化GUI之后拍摄PUT的快照。为了模糊新的测试用例，可以在将新测试用例直接写入内存并执行之前恢复内存快照。同样的直觉适用于涉及客户端和服务器之间的大量交互的模糊网络应用程序。这种技术称为内存模糊[97]。例如，<code>GRR</code> [86,194]在加载任何输入字节之前创建快照。这样，它可以跳过不必要的启动代码。 AFL还使用fork服务器来避免一些流程启动成本。尽管它与内存模糊测试具有相同的动机，但是fork服务器涉及为每个模糊迭代分离一个新进程（参见§6）。</p>\n<p>一些模糊器[7,211]对函数执行内存模糊测试，而不会在每次迭代后恢复PUT的状态。我们称这种技术为内存API模糊测试。例如，AFL有一个名为persistent mode [213]的选项，它在循环中重复执行内存API模糊测试而不重新启动进程。在这种情况下，AFL忽略了在同一执行中被多次调用的函数的潜在副作用。</p>\n<p>虽然有效的内存API模糊测试会受到不合理的模糊测试结果的影响：内存模糊测试中发现的错误（或崩溃）可能无法重现，因为（1）为目标函数构造有效的调用上下文并不总是可行的，并且（ 2）可能存在多个函数调用未捕获的副作用。请注意，内存中API模糊的健全性主要取决于入口点函数，找到这样的函数是一项具有挑战性的任务。</p>\n<h3 id=\"3-1-3线程调度（Thread-Scheduling-）\"><a href=\"#3-1-3线程调度（Thread-Scheduling-）\" class=\"headerlink\" title=\"3.1.3线程调度（Thread Scheduling ）\"></a>3.1.3线程调度（Thread Scheduling ）</h3><p>竞争条件错误可能难以触发，因为它们依赖于可能不经常发生的非确定性行为。但是，通过显式控制线程的调度方式，也可以使用插桩来触发不同的非确定性程序行为[43,410,121,157,169,174,175]。现有工作表明，即使是随机调度线程也可以有效地找到竞争条件错误[174]。</p>\n<h2 id=\"3-2-种子选择（seed-selection-problem）\"><a href=\"#3-2-种子选择（seed-selection-problem）\" class=\"headerlink\" title=\"3.2 种子选择（seed selection problem）\"></a>3.2 种子选择（seed selection problem）</h2><p>回忆§2，模糊器接收一组控制fuzzing algorithm行为的fuzz configurations。不幸的是，fuzz configurations的一些参数，例如基于突变的模糊器的种子，具有大的值域。例如，假设分析师模糊测试接受MP3文件作为输入的MP3播放器。有无数的有效MP3文件，这提出了一个自然的问题：我们应该使用哪些种子进行模糊测试？这个问题被称为(<strong>seed selection problem</strong> )种子选择问题[165]。</p>\n<p>有几种方法和工具可以解决种子选择问题[70,165]。常见的方法是找到最大化覆盖度量的最小种子集，例如节点覆盖，并且该过程称为计算最小集。例如，假设当前配置集C由两个seeds s1和s2组成，它们覆盖PUT的以下地址：{s1→{10,20}，s2→{20,30}}。如果我们有第三个种子s3→{10,20,30}的执行速度与s1和s2一样快，那么人们可能会认为fuzz s3而不是s1和s2是有意义的，因为它直观地测试了更多程序逻辑以一半的执行时间成本。这种直觉得到了Miller的报告[140]的支持，该报告显示，代码覆盖率增加1％会使发现的错误百分比增加0.92％。如§7.2所述，此步骤也可以是ConfUpdate的一部分。</p>\n<p>Fuzzers在实践中使用各种不同的覆盖度量。例如，AFL的minset基于分支覆盖，每个分支上都有一个对数计数器。该决定背后的基本原理是，只有当分支计数在数量级上不同时才允许它们被认为是不同的。 Honggfuzz [188]根据执行指令数，执行分支数和唯一基本块计算覆盖率。此度量标准允许模糊器向minset添加更长的执行时间，这有助于发现拒绝服务漏洞或性能问题。</p>\n<h2 id=\"3-3-种子修剪（Seed-Trimming-）\"><a href=\"#3-3-种子修剪（Seed-Trimming-）\" class=\"headerlink\" title=\"3.3 种子修剪（Seed Trimming ）\"></a>3.3 种子修剪（Seed Trimming ）</h2><p>较小的种子可能消耗较少的内存并且意味着更高的吞吐量。因此，一些模糊器试图在模糊种子之前减小种子的尺寸，这称为种子修剪。种子修剪可以在Preprocess中的主模糊循环之前或作为ConfUpdate的一部分进行。使用种子修剪的一个值得注意的模糊器是AFL [211]，只要修改后的种子达到相同的覆盖范围，它就使用其代码覆盖率插桩迭代地移除一部分种子。同时，雷伯特等人 [165]报道，他们的size minset算法，通过给予较小的种子更高优先级来选择种子，与随机种子选择相比，导致更少数量的独特错误。</p>\n<h2 id=\"3-4准备驱动程序\"><a href=\"#3-4准备驱动程序\" class=\"headerlink\" title=\"3.4准备驱动程序\"></a>3.4准备驱动程序</h2><p>应用程序当难以直接fuzz PUT时，准备一个模糊驱动程序是有意义的。这个过程在很大程度上是手动的，尽管这只在模糊测试活动开始时才进行一次。例如，当我们的目标是库时，我们需要准备一个调用库中函数的驱动程序。类似地，内核模糊器可能会模糊用户态应用程序来测试内核[28,117,154]。 <code>MutaGen</code> [115]利用其他程序（驱动程序）中包含的PUT知识进行模糊测试。具体来说，它使用动态程序切片来改变驱动程序本身，以生成测试用例。 <code>IoTFuzzer</code> [50]通过让驱动程序成为相应的智能手机应用程序来定位物联网设备。</p>\n<h1 id=\"4-调度-SEHEDULING\"><a href=\"#4-调度-SEHEDULING\" class=\"headerlink\" title=\"4 调度(SEHEDULING)\"></a>4 调度(SEHEDULING)</h1><p>在模糊测试中，调度意味着为下一个模糊运行选择模糊配置。正如我们在§2.1中所解释的，每个配置的内容取决于模糊器的类型。对于简单的模糊器，调度可以很简单 - 例如，<code>zzuf</code> [96]在其默认模式下只允许一个配置（PUT和其他参数的默认值），因此根本没有决定。但对于更高级的模糊器，如<code>BFF</code> [45]和<code>AFLFast</code> [33]，他们成功的一个主要因素在于他们的创新调度算法。在本节中，我们将仅讨论黑盒和灰盒模糊测试的调度算法;白盒模糊测试中的调度需要符号执行器独有的复杂设置，我们将读者引用到[34]。</p>\n<h2 id=\"4-1-Fuzz配置调度（FCS）问题-The-Fuzz-Configuration-Scheduling-FCS-Problem\"><a href=\"#4-1-Fuzz配置调度（FCS）问题-The-Fuzz-Configuration-Scheduling-FCS-Problem\" class=\"headerlink\" title=\"4.1  Fuzz配置调度（FCS）问题(The Fuzz Configuration Scheduling (FCS) Problem)\"></a>4.1  Fuzz配置调度（FCS）问题(The Fuzz Configuration Scheduling (FCS) Problem)</h2><p>调度的目标是分析当前可用的配置信息，并选择一个更有可能产生最有利结果的信息，例如，找到最多的唯一错误，或生成的输入集所达到的最大化覆盖范围。从根本上说，每个调度算法都面临相同的探索与剥削冲突，时间可以花费在收集关于每个配置的更准确信息上，以便为将来的决策（探索）提供信息，或者模糊当前被认为可以产生更有利结果的配置。 （利用）。 Woo等人 [206]将此固有冲突称为模糊配置调度（FCS）问题。</p>\n<p>在我们的模型模糊器（算法1）中，函数Schedule基于（i）当前的模糊配置集 C，（ii）当前时间 t_elapsed，以及（iii）总时间预算 t_limit 来选择下一个配置。然后，此配置将用于下一次模糊运行。请注意，Schedule仅与决策有关。完成此决策的信息由 Preprocess 和 ConfUpdate 通过更新C获取。</p>\n<h2 id=\"4-2-黑盒FCS-算法\"><a href=\"#4-2-黑盒FCS-算法\" class=\"headerlink\" title=\"4.2 黑盒FCS 算法\"></a>4.2 黑盒FCS 算法</h2><p>在黑盒设置中，FCS算法可以使用的唯一信息是配置的模糊结果 - 与其一起发现的崩溃和错误的数量以及到目前为止花费的时间。 <code>Householder</code>和<code>Foote</code> [100]是第一个研究如何在CERT BFF黑盒突变模糊器中利用这些信息的人[45]。他们假定应该优先选择观察成功率较高的配置（#bugs / #runs）。事实上，在替换BFF中的统一采样调度算法后，他们观察到在运行 ffmpeg 500万次中独特崩溃次数增加了85％，证明了更先进的FCS算法的潜在优势。</p>\n<p>不久之后，Woo等人在多个方面改进了上述想法 [206]。首先，他们从[100]中的伯努利试验序列到<code>Weighted Coupon\nCollector’s Problem with Unknown Weights</code>（WCCP / UW），改进了黑盒突变模糊测试的数学模型。前者假设每个配置具有固定的最终成功概率并且随着时间的推移而学习它，后者在衰减时明确地保持该概率的上限。其次，WCCP / UW模型自然会引领Woo等人去研究<code>multi-armed bandit</code>（MAB）问题的算法，这是一种流行的形式以应对决策科学中的探索与剥削冲突[31]。为此，他们能够设计MAB算法以准确地利用尚未发生衰减的配置。第三，他们观察到，在其他条件相同的情况下，让fuzzing更快的配置允许模糊器收集更多的独特错误，或者更快地降低其未来成功概率的上限。这激发了他们将配置的成功概率标准化为花费在其上的时间，从而使得更快的配置更加可取。第四，他们将BFF中模糊运行的编排从每个配置选择的固定运行次数（BFF用语中的“epochs”）改为每次选择的固定时间量。通过此更改，BFF不再需要在可重新选择之前花费更多时间在慢速配置中。通过组合上述内容，评估[206]显示使用与现有BFF相同的时间量发现的独特错误数量增加1.5倍。</p>\n<h2 id=\"4-3-灰盒FCS算法\"><a href=\"#4-3-灰盒FCS算法\" class=\"headerlink\" title=\"4.3 灰盒FCS算法\"></a>4.3 灰盒FCS算法</h2><p>在灰盒设置中，FCS算法可以选择使用关于每种配置的更丰富的信息集，例如，在模糊配置时获得的覆盖范围。 AFL [211]是此类别的先行者，它基于进化算法（EA）。直观地，EA维持一组配置，每个配置具有一些“适应性”值。 EA选择合适的配置并将其应用于遗传转化，例如突变和重组，以产生后代，后代可能成为新的配置。假设是这些产生的配置更可能适合。</p>\n<p>要在EA的上下文中理解FCS，我们需要定义<strong>（i）使配置适合的内容是什么，（ii）如何选择配置，以及（iii）如何使用所选配置</strong>。作为高级近似法，在执行控制流边缘的配置中，AFL认为包含最快和最小输入的那个适合（AFL用语中的“favorite”）。 AFL维护一个配置队列，从中选择下一个匹配配置，就好像队列是循环的一样。一旦选择了配置，AFL就会使其基本上以恒定的运行次数进行模糊处理。从FCS的角度来看，请注意快速配置的首选项与黑盒设置的[206]相同。</p>\n<p>最近，Böhme等人的AFLFast [33]在上述三个方面的每个方面都改进了AFL。首先，AFLFast为输入添加了两个最重要的标准，使其成为“favorite”：（i）在执行控制流边缘的配置中，AFLFast倾向于选择最少的输入。这具有在执行该边缘的配置之间循环的效果，从而增加了探索。 （ii）当（i）中存在平局时，AFLFast倾向于选择其中执行最少路径的那个。这具有增加稀有路径的执行效果，这可能揭示更多未观察到的行为。其次，AFLFast放弃了AFL中的循环选择，而是根据优先级选择下一个拟合配置。特别是，如果选择配置的频率较低，或者在平局时，如果它运行的路径较少，则适配配置的优先级高于另一配置。与第一次改变的想法相同，这具有增加适合配置和稀有路径执行的探索的效果。第三，AFLFast根据能量计划确定所选配置的次数变量。 AFLFast中的FAST能量计划以较小的“能量”值开始，以确保配置之间的初始探索，并以指数方式增加到极限，以快速确保充分利用。此外，它还通过生成相同路径的生成输入的数量来标准化能量，从而促进对频率较低的模糊配置的探索。这些变化的总体影响非常显着 - 在24小时的评估中，Böhme等人观察到AFLFast发现了AFL没有发现的3个错误，并且在两者都发现的6个错误上比AFL快7倍。 AFLGo [32]通过修改其优先级来扩展AFLFast，以便针对特定的程序位置。 QTEP [200]使用静态分析来推断二进制文件的哪个部分更“错误”并优先考虑覆盖它们的配置。</p>\n<h1 id=\"5-输入生成-INPUT-GENERATION\"><a href=\"#5-输入生成-INPUT-GENERATION\" class=\"headerlink\" title=\"5.输入生成(INPUT GENERATION)\"></a>5.输入生成(INPUT GENERATION)</h1><p>由于测试用例的内容直接控制是否触发bug，因此输入生成技术自然是模糊测试中最有影响力的设计决策之一。传统上，模糊器分为基于生成或基于突变的模糊器[187]。基于生成的模糊器基于给定模型生成测试用例，该模型描述了PUT期望的输入。我们在本文中称这种模糊器为基于模型的模糊器。另一方面，基于突变的模糊器通过改变给定的种子输入来产生测试案例。基于突变的模糊器通常被认为是无模型的，因为种子仅仅是示例输入，并且即使在大量数量下它们也不能完全描述PUT的预期输入空间。在本节中，我们将基于底层测试用例生成（InputGen）机制对模糊器使用的各种输入生成技术进行解释和分类。</p>\n<h2 id=\"5-1基于模型（基于生成）的模糊器\"><a href=\"#5-1基于模型（基于生成）的模糊器\" class=\"headerlink\" title=\"5.1基于模型（基于生成）的模糊器\"></a>5.1基于模型（基于生成）的模糊器</h2><p>基于模型的模糊器基于给定模型生成测试用例，该模型描述了PUT可以接受的输入或执行，例如精确表征输入格式的语法或不太精确的约束,例如标识文件类型的magic值。</p>\n<h3 id=\"5-1-1预定义模型\"><a href=\"#5-1-1预定义模型\" class=\"headerlink\" title=\"5.1.1预定义模型\"></a>5.1.1预定义模型</h3><p>一些模糊器使用可由用户配置的模型。例如，Peach [70]，PROTOS [112]和Dharma [3]接受用户提供的规范。 Autodafé [197]，Sulley [15]，SPIKE [13]和SPIKEfile [186]公开了API，允许分析师创建自己的输入模型。 Tavor [219]还接受以Extended Backus-Naur形式（EBNF）编写的输入规范，并生成符合相应语法的测试用例。类似地，诸如PROTOS [112]，SNOOZE [26]，KiF [12]和T-Fuzz [107]之类的网络协议模糊器也接受来自用户的协议规范。内核API模糊器[108,146,151,198,203]以系统调用模板的形式定义输入模型。这些模板通常指定系统调用期望作为输入的参数的数量和类型。在内核模糊测试中使用模型的想法源于Koopman等人 [119]开创性的工作，他们将操作系统的稳健性与一系列有限的手动选择的系统调用测试用例进行了比较。</p>\n<p>其他基于模型的模糊器针对特定的语言或语法，并且该语言的模型内置于模糊器本身。例如，<code>cross_fuzz</code> [212]和<code>DOMfuzz</code> [143]生成随机文档对象模型（DOM）对象。同样，<code>jsfunfuzz</code> [143]基于其自己的语法模型生成随机但语法正确的JavaScript代码。 <code>QuickFuzz</code> [88]利用现有的Haskell库来描述生成测试用例时的文件格式。一些网络协议模糊器如<code>Frankencerts</code> [37]，TLS-Attacker [180]<code>，</code>tlsfuzzer <code>[116]</code>和<code>llfuzzer</code>[182]设计有特定网络协议模型，如TLS和NFC。 Dewey等人[63,64]提出了一种生成测试用例的方法，这些测试用例不仅语法正确，而且通过利用约束逻辑编程也具有语义多样性。<code>LangFuzz</code> [98]通过解析作为输入给出的一组种子来产生代码片段。然后它随机组合片段，并将种子与片段一起变异以生成测试用例。由于它提供了语法，因此它始终生成语法正确的代码。 LangFuzz应用于JavaScript和PHP。 BlendFuzz [210]基于与LangFuzz类似的想法，但它以XML和正则表达式解析器为目标。</p>\n<h3 id=\"5-1-2-推断模型\"><a href=\"#5-1-2-推断模型\" class=\"headerlink\" title=\"5.1.2 推断模型\"></a>5.1.2 推断模型</h3><p>推断模型而不是依赖于预定义的逻辑或用户提供的模型获得牵引力。虽然有大量关于自动输入格式和协议逆向工程主题的已发表研究[25,41,57,60,128]，但只有少数模糊测试者利用这些技术。模型推断可以分两个阶段完成：<code>Preprocess</code>或<code>ConfUpdate</code>。<br>Preprocess中的模型推理。一些模糊推测器将模型推断为模糊运动之前的第一步。 TestMiner [61]使用代码中可用的数据来挖掘和预测合适的输入。 Skyfire [199]使用数据驱动方法从给定语法和一组输入样本生成一组种子。与以前的作品不同，他们的重点是生成一组语义上有效的新种子。 IMF [93]通过分析系统API日志来学习内核API模型，并生成使用推断模型调用一系列API调用的C代码。 Neural [56]和Learn＆Fuzz [85]使用基于神经网络的机器学习技术从给定的一组测试文件中学习模型，并使用推断的模型生成测试用例。Liu等人[129]提出了一种特定于文本输入的类似方法。</p>\n<p>ConfUpdate中的模型推断。在每个模糊迭代中都有模糊器更新模型。 PULSAR [79]从捕获到的程序生成的一组的网络数据包中自动的推断出网络协议模型。然后，学习的网络协议用于模糊程序。 PULSAR在内部构建状态机，并映射哪个消息令牌与状态相关。此信息稍后用于生成覆盖状态机中更多状态的测试用例。 Doupé等人 [67]提出了一种通过观察I / O行为来推断Web服务的状态机的方法。然后使用推断的模型来扫描Web漏洞。Ruiter等人 [168]工作类似，但目标是TLS，并将其实施基于<code>LearnLib</code> [162]。最后，<code>GLADE</code> [27]从一组I / O样本中合成了一个无上下文语法，并使用推断的语法来模糊PUT。</p>\n<h2 id=\"5-2-无模型（基于突变）的模糊器\"><a href=\"#5-2-无模型（基于突变）的模糊器\" class=\"headerlink\" title=\"5.2 无模型（基于突变）的模糊器\"></a>5.2 无模型（基于突变）的模糊器</h2><p>经典随机测试[19,92]在生成满足特定路径条件的测试用例时效率不高。假设有一个简单的C语句：if（input == 42）。如果输入是32位整数，则随机猜测正确输入值的概率是2的32次方之一。当我们考虑结构良好的输入（如MP3文件）时，情况会变得更糟。随机测试极不可能在合理的时间内生成有效的MP3文件作为测试用例。因此，MP3播放器将主要在到达程序的更深层部分之前的解析阶段拒绝从随机测试中生成的测试用例。</p>\n<p>这个问题促使使用基于种子的输入生成以及白盒输入生成（见§5.3）。大多数无模型模糊器使用种子，它是PUT的输入，以便通过改变种子来生成测试用例。<br>种子通常是PUT支持的类型的结构良好的输入：文件，网络包或一系列UI事件。通过仅改变有效文件的一小部分，通常可以生成大多数有效的新测试用例，但也包含异常值以触发PUT的崩溃。有多种方法可用于改变种子，我们将在下面描述常见的方法。</p>\n<h3 id=\"5-2-1-比特翻转\"><a href=\"#5-2-1-比特翻转\" class=\"headerlink\" title=\"5.2.1 比特翻转\"></a>5.2.1 比特翻转</h3><p>比特翻转是许多无模型模糊器使用的常用技术[6,95,96,188,211]。一些模糊器简单地翻转固定数量的比特，而其他模糊器确定随机翻转的比特数。为了随机改变种子，一些模糊器使用一个称为突变比的用户可配置参数，该参数确定单次执行InputGen时要翻转的位位置数。假设一个模糊器想要从给定的N位种子中翻转K个随机位。在这种情况下，模糊器的突变比是K / N.<br><code>SymFuzz</code>等 [48]表明模糊性能对突变率非常敏感，并且没有一个比率适用于所有PUT。有几种方法可以找到良好的突变率。 BFF [45]和FOE [46]使用每个种子的指数缩放比例集，并将更多迭代分配给证明在统计学上有效的突变比[100]。 SymFuzz [48]利用白盒程序分析来推断出良好的突变率。然而，请注意，所提出的技术仅考虑推断单个最佳突变比率。使用多个突变比率进行模糊测试比使用单个最佳比率进行模糊测试更有可能，这仍然是一个开放的研究挑战。</p>\n<h3 id=\"5-2-2-算术变异\"><a href=\"#5-2-2-算术变异\" class=\"headerlink\" title=\"5.2.2 算术变异\"></a>5.2.2 算术变异</h3><p>AFL [211]和honggfuzz [188]包含另一个变异操作，它将所选字节序列视为整数，并对该值执行简单算术。然后使用计算的值替换所选的字节序列。关键的直觉是通过少量的数值来限制突变的影响。例如，AFL从种子中选择一个4字节的值，并将该值视为整数 i。然后用 i ± r 替换种子中的值，其中r是随机生成的小整数。 r的范围取决于模糊器，通常是用户可配置的。在AFL中，默认范围是：0≤r&lt;35。</p>\n<h3 id=\"5-2-3-基于块的变\"><a href=\"#5-2-3-基于块的变\" class=\"headerlink\" title=\"5.2.3 基于块的变\"></a>5.2.3 基于块的变</h3><p>有几种基于块的变异方法，其中块是种子的字节序列：（1）将随机生成的块插入种子的随机位置[7,211]; （2）从种子中删除随机选择的块[7,95,188,211]; （3）用随机值替换随机选择的块[7,95,188,211]; （4）随机置换一系列块的顺序[7,95]; （5）通过附加随机区块来调整种子的大小[188]; （6）从种子中取一个随机块来插入/替换另一个种子的随机块[7,211]。</p>\n<h3 id=\"5-2-4-基于字典的变异\"><a href=\"#5-2-4-基于字典的变异\" class=\"headerlink\" title=\"5.2.4 基于字典的变异\"></a>5.2.4 基于字典的变异</h3><p>一些模糊器使用具有潜在显着语义权重的一组预定义值，例如0或-1，以及用于变异的格式字符串。例如，AFL [211]，honggfuzz [188]和LibFuzzer [7]在变换整数时使用诸如0，-1和1的值。 Radamsa [95]使用Unicode字符串，GPF [6]使用格式字符（如％x和％s）来改变字符串。</p>\n<h2 id=\"5-3-白盒模糊器\"><a href=\"#5-3-白盒模糊器\" class=\"headerlink\" title=\"5.3 白盒模糊器\"></a>5.3 白盒模糊器</h2><p>白盒模糊器也可以分为基于模型或无模型的模糊器。例如，传统的动态符号执行[24,84,105,134,184]在基于变异的模糊器中不需要任何模型，但一些符号执行器[82,117,160]利用输入模型，如输入语法指导符号执行。</p>\n<p>虽然许多白盒模糊器包括Godefroid等人[84]的开创性工作使用动态符号执行来生成测试用例，但并非所有的白盒模糊器都是动态符号执行器。一些模糊器[48,132,170,201]利用白盒程序分析来查找有关PUT接受的输入的信息，以便将其与黑盒或灰盒模糊测试一起使用。在本小节的其余部分中，我们将基于其基础测试用例算法简要总结现有的白盒模糊测试技术。请注意，我们故意省略动态符号执行器，如[42,47,54,83,176,192]，除非他们明确称自己为§2.2中提到的模糊器。</p>\n<h3 id=\"5-3-1-动态符号执行\"><a href=\"#5-3-1-动态符号执行\" class=\"headerlink\" title=\"5.3.1 动态符号执行\"></a>5.3.1 动态符号执行</h3><p>在高级别，经典的符号执行[35,101,118]运行一个带有符号值作为程序的输入，它代表所有可能的值。在执行PUT时，它会构建符号表达式，而不是评估具体值。每当它到达条件分支指令时，它在概念上分叉两个符号解释器，一个用于真正的分支，另一个用于假分支。对于每个路径，符号解释器为执行期间遇到的每个分支指令构建路径公式（或路径谓词）。如果存在执行所需路径的具体输入，则路径公式是可满足的。可以通过查询SMT求解器[142]来生成具体输入，以获得路径公式的解。动态符号执行是传统符号执行的变体，其中符号执行和具体执行同时运行。这个想法是具体的执行状态可以帮助减少符号约束的复杂性。除了应用于模糊测试之外，对动态符号执行的学术文献的广泛回顾超出了本文的范围。然而，动态符号执行的更广泛处理可以在[16,173]中找到。</p>\n<h3 id=\"5-3-2-引导式模糊测试\"><a href=\"#5-3-2-引导式模糊测试\" class=\"headerlink\" title=\"5.3.2 引导式模糊测试\"></a>5.3.2 引导式模糊测试</h3><p>一些模糊器利用静态或动态程序分析技术来增强模糊测试的有效性。这些技术通常涉及两个阶段的模糊测试：（i）用于获得关于PUT的有用信息的昂贵程序分析，以及（ii）在先前分析的指导下生成测试用例。这在表1的第六列（第9页）中表示。例如，TaintScope [201]使用细粒度污点分析来查找“热字节”，这是流入关键系统调用或API调用的输入字节。其他安全研究人员提出了类似的想法[69,103]。 Dowser [91]在编译期间执行静态分析，以找到可能包含基于启发式的错误的循环。具体来说，它查找包含指针解引用的循环。然后，它使用污点分析计算输入字节和候选循环之间的关系。最后，Dowser运行动态符号执行，同时只使关键字节成为符号，从而提高性能。VUzzer [164]和GRT [132]利用静态和动态分析技术从PUT中提取控制和数据流特征，并使用它们来指导输入生成。 Angora [50]通过使用污点分析将每个路径约束与相应的字节相关联来改进“热字节”的想法。然后，它通过梯度下降算法进行搜索，以指导其突变以解决这些约束。</p>\n<h3 id=\"5-3-3-PUT-突变\"><a href=\"#5-3-3-PUT-突变\" class=\"headerlink\" title=\"5.3.3 PUT 突变\"></a>5.3.3 PUT 突变</h3><p>模糊测试的一个实际挑战是绕过校验和验证。例如，当PUT在解析输入之前计算输入的校验和时，来自模糊器的大多数生成的测试用例将被PUT拒绝。为了应对这一挑战，TaintScope [201]提出了一种校验和感知模糊测试技术，该技术通过污点分析识别校验和测试指令，并修补PUT以绕过校验和验证。一旦发现程序崩溃，它们就会为输入生成正确的校验和，以生成一个崩溃未修改的PUT的测试用例。 Caballero [40]提出了一种称为拼接动态符号执行的技术，它可以在校验和存在的情况下生成测试用例。</p>\n<p>T-Fuzz [158]扩展了这个想法，通过灰盒模糊来有效地穿透所有类型的条件分支。它首先构建一组非关键检查（NCC），这些检查是可以在不修改程序逻辑的情况下进行转换的分支。当模糊测试活动停止发现新路径时，它会选择NCC，对其进行转换，然后在修改后的PUT上重新启动模糊测试活动。最后，当发现崩溃模糊转换程序时，T-Fuzz尝试使用符号执行在原始程序上重建它。</p>\n<h1 id=\"6-输入评估\"><a href=\"#6-输入评估\" class=\"headerlink\" title=\"6. 输入评估\"></a>6. 输入评估</h1><p>生成输入后，模糊器执行输入，并决定如何处理该输入。由于模糊测试的主要动机是发现违反安全策略的行为，因此模糊测试程序必须能够检测到执行违反安全策略的行为。该策略的实现称为bug oracle，O_bug（参见§2.1）。 oracle标记的输入通常在被分类后写入磁盘。如算法1所示，为模糊器生成的每个输入调用oracle。因此，oracle能够有效地确定输入是否违反安全策略是至关重要的。</p>\n<p>回想一下§3，一些模糊器还在执行每个输入时收集附加信息，以改善模糊测试过程。 Preprocess和InputEval在许多模糊器中彼此紧密耦合，因为检测到的PUT（来自Preprocess）将在执行时输出附加信息（来自InputEval）。</p>\n<h2 id=\"6-1执行优化\"><a href=\"#6-1执行优化\" class=\"headerlink\" title=\"6.1执行优化\"></a>6.1执行优化</h2><p>我们的模型考虑按顺序执行单个模糊迭代。虽然这种方法的直接实现只是在每次模糊迭代开始时开始新过程时加载PUT，但是可以显着加速重复加载过程。为此，现代模糊器提供了跳过这些重复加载过程的功能。例如，AFL [211]提供了一个fork-server，它允许每个新的模糊迭代从已经初始化的进程中fork。类似地，内存中模糊测试是优化执行速度的另一种方法，如第3.1.2节中所述。无论确切的机制如何，加载和初始化PUT的开销都会在很多次迭代中摊销。Xu等人 [209]通过设计一个替换fork（）的新系统调用，进一步降低了迭代的成本。</p>\n<h2 id=\"6-2-Bug-Oracles\"><a href=\"#6-2-Bug-Oracles\" class=\"headerlink\" title=\"6.2  Bug Oracles\"></a>6.2  Bug Oracles</h2><p>与模糊测试一起使用的规范安全策略认为每个程序执行都会被致命信号（例如分段错误）终止。此策略检测到许多内存漏洞，因为使用无效值覆盖数据或代码指针的内存漏洞通常会导致分段错误或在取消引用时中止。此外，该策略高效且易于实现，因为操作系统允许模糊器在没有任何仪器的情况下捕获这种异常情况。</p>\n<p>但是，传统的检测崩溃的策略不会检测到触发的每个内存漏洞。例如，如果堆栈缓冲区溢出使用有效的内存地址覆盖堆栈上的指针，则程序可能会运行完成且结果无效而不是崩溃，并且模糊器不会检测到此情况。为了缓解这种情况，研究人员提出了各种有效的程序转换，可以检测不安全或不需要的程序行为并中止程序。这些通常被称为<code>sanitizers</code>。</p>\n<p><strong>内存和类型安全</strong>。内存安全错误可以分为两类：空间和时间。非正式地，当指针被访问到其预期范围之外时，会发生空间存储器错误。例如，缓冲区溢出和下溢是空间内存错误的典型示例。在指针不在有效后访问时会发生时间内存错误。例如，use-after-free 漏洞，当一片内存的指针被释放之后又被使用，这是典型的时间内存错误。</p>\n<p><code>Address Sanitizer（ASan）</code>[177]是一个快速存储器错误检测器，可在编译时检测程序。 ASan可以检测空间和时间内存错误，平均减速仅为73％，使其成为基本碰撞安全带的有吸引力的替代品。 ASan采用了一个影子存储器，允许每个存储器地址在被解除引用之前被快速检查其有效性，从而允许它检测许多（但不是全部）不安全的存储器访问，即使它们不会使原始程序崩溃。 MEDS [94]通过利用64位虚拟空间提供的近乎无限的内存空间并创建<code>redzones</code>来改进ASAN。</p>\n<p><code>SoftBound / CETS</code>[148,149]是另一种在编译过程中监控程序的内存错误检测器。然而，SoftBound / CETS不是像ASan那样跟踪有效的内存地址，而是将边界和时间信息与每个指针相关联，理论上可以检测所有空间和时间内存错误。然而，正如预期的那样，这种完整性带来了更高的平均开销116％[149]。</p>\n<p><code>CaVer</code>[123]，<code>TypeSan</code>[90]和<code>HexType</code>[106]在编译期间插桩程序，以便它们可以检测C ++类型转换中的错误转换。当对象转换为不兼容的类型时，例如当基类的对象强制转换为派生类型时，会发生错误的转换。事实证明，CaVer可以扩展到Web浏览器，这些浏览器历来包含这种类型的漏洞，并且开销在7.6到64.6％之间。</p>\n<p>另一类存储器安全保护是控制流完整性[10,11]（CFI），它在运行时检测原始程序中不可能的控制流转换。 CFI可用于检测非法修改程序控制流的测试用例。最近一个专注于防范CFI违规子集的项目已经进入主流gcc和clang编译器[191]。</p>\n<p><strong>未定义的行为</strong>。诸如C之类的语言包含许多由语言规范未定义的行为。编译器可以以各种方式自由处理这些构造。在许多情况下，程序员可以（有意或无意地）编写他们的代码，这样它只对某些编译器实现是正确的。虽然这看起来似乎不太危险，但许多因素都会影响编译器如何实现未定义的行为，包括优化设置，体系结构，编译器甚至编译器版本。当编译器的未定义行为的实现与程序员的期望不匹配时，通常会出现漏洞和错误[202]。</p>\n<p><code>Memory Sanitizer（MSan）</code>是一种工具，可以在编译期间检测程序，以检测由于在C和C ++中使用未初始化的内存而导致的未定义行为[183]。与ASan类似，MSan使用一个影子内存来表示每个可寻址位是否已初始化。 Memory Sanitizer的开销约为150％。</p>\n<p><code>Undefied Behavior Sanitizer（UBSan）</code>[65]在编译时修改程序以检测未定义的行为。与其他专注于未定义行为的特定来源的检测工具不同，UBSan可以检测各种未定义的行为，例如使用未对齐的指针，除以零，解除引用空指针和整数溢出。</p>\n<p><code>Thread Sanitizer（TSan）</code>[178]是一种编译时修改，它通过精度和性能之间的权衡来检测数据竞争。当两个线程同时访问共享内存位置并且至少一个访问是写入时，发生数据争用。这样的错误可能导致数据损坏，并且由于非确定性而极难重现。</p>\n<p><strong>输入验证</strong>。测试输入验证漏洞（如XSS（跨站点脚本）和SQL注入漏洞）是一个具有挑战性的问题，因为它需要了解为Web浏览器和数据库引擎提供支持的非常复杂的解析器的行为。<code>KameleonFuzz</code> [68]通过使用真实Web浏览器解析测试用例，提取文档对象模型树，并将其与人工提取的XSS工具模式进行比较来检测成功的XSS攻击。 <code>μ4SQLi</code>[17]使用类似的技巧来检测SQL注入。由于无法从Web应用程序响应中可靠地检测SQL注入，因此μ4SQLi使用数据库代理拦截目标Web应用程序与数据库之间的通信，以检测输入是否触发了有害行为。</p>\n<p><strong>语义差异</strong>。通常通过比较类似（但不同）的程序来发现语义错误。它通常被称为差分测试[135]，并被几个模糊器[37,53,159]使用。在这种情况下，bug oracle是作为一组类似的程序给出的。Jung等人 [111]引入了术语黑盒差分模糊测试，它测量了给定两个或更多不同输入的PUT输出之间的差异。根据输出之间的差异，它们检测PUT的信息泄漏。</p>\n<h2 id=\"6-3-分类\"><a href=\"#6-3-分类\" class=\"headerlink\" title=\"6.3 分类\"></a>6.3 分类</h2><p>分类是分析和报告导致违反策略的测试用例的过程。分类可以分为三个步骤：重复数据删除，优先级排序和测试用例最小化。</p>\n<h3 id=\"6-3-1-重复数据删除\"><a href=\"#6-3-1-重复数据删除\" class=\"headerlink\" title=\"6.3.1 重复数据删除\"></a>6.3.1 重复数据删除</h3><p>重复数据删除是从输出集中修剪与其它测试样例触发相同的错误的测试样例的过程，理想情况下，重复数据删除会返回一组测试用例，其中每个测试用例都会触发一个独特的错误。</p>\n<p>由于多种原因，重复数据删除是大多数模糊器的重要组成部分。作为一种实际的实现方式，它通过在删除硬盘上存储重复的结果来避免浪费磁盘空间和其他资源。作为可用性考虑因素，重复数据删除使用户可以轻松了解存在多少不同的错误，并能够分析每个错误的示例。这对各种模糊用户都很有用；例如，攻击者可能只想查看可能导致可靠利用的“home run”漏洞。</p>\n<p>目前在实践中使用了两种主要的重复数据删除实现：<code>堆栈回溯哈希</code>和<code>基于覆盖的重复数据删除</code>。</p>\n<p><strong>堆栈回溯哈希</strong>(Stack Backtrace Hashing )。堆栈回溯哈希[141]是用于重复数据删除崩溃的最古老和最广泛使用的方法之一，其中自动化工具在崩溃时记录堆栈回溯，并根据该回溯的内容分配堆栈散列。例如，如果程序在函数foo中执行一行代码时崩溃，并且调用堆栈为main→d→c→b→a→foo，那么n = 5的堆栈回溯散列实现会将所有执行组合在一起回溯以d→c→b→a→foo结束。</p>\n<p>堆栈哈希实现差别很大，从哈希中包含的堆栈帧数开始。一些实现使用一个[18]，三个[141,206]，五个[45,76]，或者没有任何限制[115]。实现方式也包括每个堆栈帧中包含的信息量。某些实现只会哈希函数的名称或地址，但其他实现将哈希名称和偏移量或行。这两个选项都不能很好地工作，因此一些实现[76,137]产生两个哈希：主要和次要哈希。主要哈希很可能将不同的崩溃组合在一起，因为它只散列函数名称，而次要散列更精确，因为它使用函数名称和行号，并且还包括无限数量的堆栈帧。</p>\n<p>虽然堆栈回溯哈希被广泛使用，但它并非没有缺点。堆栈回溯哈希的基本假设是类似的崩溃是由类似的错误引起的，反之亦然，但据我们所知，这个假设从未被直接测试过。有一些理由怀疑它的真实性：在导致崩溃的代码附近不会发生一些崩溃。例如，导致堆损坏的漏洞可能仅在代码的不相关部分尝试分配内存时崩溃，而不是在发生堆溢出时崩溃。</p>\n<p><strong>基于覆盖的重复数据删除</strong>（Coverage-based Deduplication ）。 AFL [211]是一种流行的灰盒模糊器，它采用高效的源代码检测器来记录PUT每次执行的边缘覆盖范围，并测量每个边缘的粗略命中计数。作为灰盒模糊器，AFL主要使用此覆盖信息来选择新的种子文件。但是，它也会导致相当独特的重复数据删除方案。正如其文档中所描述的那样，如果（i）碰撞覆盖了以前看不见的边缘，或者（ii）碰撞未覆盖所有早期碰撞中存在的边缘，AFL认为碰撞是唯一的。</p>\n<p><strong>语义感知的重复数据删除</strong>。Cui等人[59]提出了一个名为RETracer的系统，根据从反向数据流分析中恢复的语义对崩溃进行分类。具体来说，在崩溃之后，RETracer会检查哪个指针导致崩溃，并以递归方式识别哪个指令为其分配了错误值。它最终找到一个具有最大帧级别的函数，并“blames”该函数。blames功能可用于群集崩溃。作者表明，他们的技术成功地将数百万个Internet Explorer bugs合并为一个，这些漏洞通过堆栈散列分散到大量不同的组中。</p>\n<h3 id=\"6-3-2-优先级和可利用性\"><a href=\"#6-3-2-优先级和可利用性\" class=\"headerlink\" title=\"6.3.2 优先级和可利用性\"></a>6.3.2 优先级和可利用性</h3><p>优先级，a.k.a.fuzzer taming问题[52]，是根据严重性和唯一性对违反测试用例进行排名或分组的过程。传统上使用模糊测试来发现内存漏洞，在这种情况下，优先级更好地称为确定崩溃的可利用性。可利用性非正式地描述了攻击者能够为测试用例暴露的漏洞编写实际漏洞的可能性。防御者和攻击者都对可利用的漏洞感兴趣。防御者通常会在不可利用的漏洞之前修复可利用的漏洞，并且出于显而易见的原因，攻击者对可利用的漏洞感兴趣。</p>\n<p>第一个可利用性排名系统之一是Microsoft的 <code></code>!exploitable` [137]，它的名字来自它提供的 !exploitable 的WinDbg命令名称。 ！exploitable采用了几种启发式方法，并配有简化的污点分析[153,173]。它按以下严重性等级对每次崩溃进行分类：EXPLOITABLE&gt; PROBABLY_EXPLOITABLE&gt; UNKNOWN&gt; NOT_LIKELY_EXPLOITABLE，其中x&gt; y表示x比y严重。虽然这些分类没有正式定义，但是可利用的非正式意图是保守和错误报告的东西比它更具可利用性。例如，！exploitable断定，如果执行非法指令，则崩溃是可利用的，这是基于攻击者能够劫持控制流的假设。另一方面，除零崩溃被视为NOT_LIKELY_EXPLOITABLE。</p>\n<p>自从！exploitable被引入以来，已经提出了其他类似的基于规则的启发式系统，包括GDB [76]和Apple的<code></code>CrashWrangler `[18]的可利用插件。然而，它们的正确性尚未得到系统的研究和评估。</p>\n<h3 id=\"6-3-3测试用例最小化\"><a href=\"#6-3-3测试用例最小化\" class=\"headerlink\" title=\"6.3.3测试用例最小化\"></a>6.3.3测试用例最小化</h3><p>分类的另一个重要部分是测试用例最小化。测试用例最小化是识别触发违规所必需的违规测试用例部分的过程，并且可选地产生比原始测试用例更小且更简单但仍然导致违规的测试用例。</p>\n<p>一些模糊器使用自己的实现和算法。 BFF [45]包括针对模糊测试[99]的最小化算法，其尝试最小化与原始种子文件不同的比特数。AFL [211]还包括一个测试用例最小化器，它试图通过机会性地将字节设置为零并缩短测试用例的长度来简化测试用例。<code>Lithium</code>[167]是一种通用测试用例最小化工具，它通过尝试以指数递减的大小删除相邻行或字节的“块”来最小化文件。Lithium是由JavaScript模糊器（如jsfunfuzz [143]）生成的复杂测试案例推动的。</p>\n<p>还有各种测试用例减少器，它们不是专门用于模糊测试，但仍可用于模糊测试识别的测试用例。这些包括格式不可知技术，如<code>delta调试</code>[216]，以及特定格式的专用技术，如<code>C-Reduce</code> [166]用于C / C ++文件。尽管专业技术明显受限于它们可以减少的文件类型，但它们的优势在于它们可以比通用技术更有效，因为它们了解它们试图简化的语法。</p>\n<h1 id=\"7-配置更新-CONFIGURATION-UPDATING\"><a href=\"#7-配置更新-CONFIGURATION-UPDATING\" class=\"headerlink\" title=\"7.配置更新(CONFIGURATION UPDATING )\"></a>7.配置更新(CONFIGURATION UPDATING )</h1><p>ConfUpdate函数在区分黑盒模糊器与灰盒和白盒模糊器的行为方面起着关键作用。如算法1中所讨论的，ConfUpdate函数可以基于在当前模糊测试运行期间收集的配置和执行信息来修改配置集（C）。在最简单的形式中，ConfUpdate返回未修改的C参数。除了评估bug oracle O_bug之外，黑盒模糊器不执行任何程序自我测试，因此它们通常不会修改C，因为它们没有收集任何允许它们修改它的信息。</p>\n<p>但是，灰色和白盒模糊器的主要区别在于它们更复杂的ConfUpdate函数实现，它允许它们包含新的模糊配置，或者删除可能已被取代的旧模糊配置。 ConfUpdate允许在一次迭代期间传输收集的信息，以便在将来的循环迭代期间使用。例如，白盒模糊器中的路径选择启发式通常会为每个生成的新测试用例创建一个新的模糊配置。</p>\n<h2 id=\"7-1进化种子库更新\"><a href=\"#7-1进化种子库更新\" class=\"headerlink\" title=\"7.1进化种子库更新\"></a>7.1进化种子库更新</h2><p>进化算法（EA）是一种基于启发式的方法，涉及生物进化机制，如突变，重组和选择。尽管EA看似非常简单，但它构成了许多灰盒模糊器的基础[7,198,211]。他们维持一个种子库，这是在模糊测试期间EA演变的人口。选择要变异的种子和突变本身的过程分别在§4.3和§5中详述。</p>\n<p>可以说，EA最重要的一步是将新配置添加到配置集C中，这对应于模糊测试的ConfUpdate步骤。大多数模糊器通常使用节点或分支覆盖作为适应度函数：如果测试用例发现新节点或分支，则将其添加到种子池中。 AFL [211]进一步考虑了分支机构被采取的次数。Angora[158]通过考虑每个分支的调用上下文来改进AFL的适应性标准。 Steelix [126]检查哪个输入偏移影响PUT的比较指令的过程以及进化种子池的代码覆盖率。</p>\n<p>VUzzer [164]仅在发现新的非错误处理基本块时才向C添加配置。他们的见解是将时间投入到程序分析中，以获得特定应用知识，从而提高EA效率。具体地，VUzzer为每个基本块定义权重，并且配置的适合度是每个运动的基本块上的频率的对数的加权和。 VUzzer具有内置的程序分析功能，可将基本块分类为普通和错误处理（EH）块。根据经验，他们的假设是，遍历EH块表示漏洞的可能性较低，因为可能由于未处理的错误而发生错误。对于正常块，其权重与包含该块的CFG上的随机游走根据VUzzer定义的转移概率访问它的概率成反比。对于EH块，其权重为负，并且是基本块的数量与此配置所执行的EH块的数量之间的缩放比率。实际上，这使得VUzzer更喜欢采用上述随机游走所认为罕见的正常块的配置。</p>\n<h2 id=\"7-2-维护Minset\"><a href=\"#7-2-维护Minset\" class=\"headerlink\" title=\"7.2 维护Minset\"></a>7.2 维护Minset</h2><p>由于能够创建新的模糊测试配置，因此还存在创建过多配置的风险。用于降低此风险的常见策略是维护最小化或最小化测试用例集，以最大化覆盖度量。在预处理期间也使用Minsetting，并在§3.2中有更详细的描述。</p>\n<p>一些模糊器使用维护专用于配置更新的minset的变体。作为一个例子，AFL [211]使用剔除程序将minset配置标记为有利，而不是完全删除不在minset中的配置（这是Cyberdyne [86]所做的）。通过调度函数，有利的模糊测试配置被选择用于模糊测试的可能性显着提高。 AFL的作者指出“这在队列循环速度和测试用例多样性之间提供了合理的平衡”[215]。</p>\n<h1 id=\"8-结束语\"><a href=\"#8-结束语\" class=\"headerlink\" title=\"8. 结束语\"></a>8. 结束语</h1><p>正如我们在§1中所阐述的那样，本文的第一个目标是提炼出对现代fuzzing文献的全面而连贯的观点。为此，我们首先提出了一个通用模型模糊器以方便我们解释当前使用中的多种形式的模糊测试。然后，我们使用图1（第7页）和表1（第9页）说明了对模糊器的丰富分类。我们通过讨论设计决策以及展示整个社区的众多成就，探索了模型模糊器的每个阶段。</p>\n","categories":[{"name":"论文","slug":"论文","permalink":"http://yama0xff.com/categories/论文/"},{"name":"fuzzing","slug":"论文/fuzzing","permalink":"http://yama0xff.com/categories/论文/fuzzing/"},{"name":"综述","slug":"论文/fuzzing/综述","permalink":"http://yama0xff.com/categories/论文/fuzzing/综述/"}],"tags":[{"name":"综述","slug":"综述","permalink":"http://yama0xff.com/tags/综述/"},{"name":"Fuzzing","slug":"Fuzzing","permalink":"http://yama0xff.com/tags/Fuzzing/"}]},{"title":"Lord of the X86 Rings: A Portable User Mode Privilege Separation Architecture on X86","date":"2019-02-15T09:09:42.000Z","path":"2019/02/15/Lord-of-the-X86-Rings-A-Portable-User-Mode-Privilege-Separation-Architecture-on-X86/","text":"Abstract前heartbleed漏洞导致的敏感信息常泄露一直是人们要解决的问题，即如何保护程序中的隐私数据不被任意的访问到。研究人员想到的方法根本出发点为，将隐私数据隔离，即使存在程序漏洞，也不能任意访问到这些敏感数据。而将隐私数据存放于什么位置，是人们一直以来需要解决的问题。此前的解决办法包括，线程隔离，进程隔离，使用可以信执行区域(如Intel SGX)等。这些方法或者性能影响比较大，或者受限到CPU型号。而在这篇论文里作者使用Intel x86处理器一直以来存在的r0-r3四个特权等级来将数据隔离访问，一方面解决了处理器兼容问题(几乎所有Intel AMD处理器均支持这四个特权级别)，一方面解决了性能问题。 relevant information 作者 Hojoon Lee, Chihyun Song, Brent Byunghoon Kang 单位 CISPA Helmholtz Center i.G. GSIS, School of Computing, KAIST 出处 ACM CCS’18 原文地址 https://github.com/wtwofire/database/blob/master/papers/reverse/2018-Lord%20of%20the%20X86%20Rings%20A%20Portable%20User%20Mode%20Privilege%20Separation%20Architecture%20on%20X86.pdf 源码地址 发表时间 2018年 x86 特权级别及切换这篇论文带读者复习了x86处理器的环(ring)特权等级，门描述，GDT，LDT，段选择子，段间跳转等内容。而这篇论文的内容主要基于现代操作系统几乎没有用到的r1,r2两个特权等级。用户程序运行在R3等级，而操作系统内核运行在R0级别。用户程序不能访问到内核数据空间，原因在于页表的访问权限的限制。以下将内核页面权限简称S页面，将用户页面权限称为U页面。作者将用户的敏感数据及访问这些数据的代码放置于S页面，从而达到普通用户程序无法访问到敏感数据。然后将段代码所运行的特级等级设置于r1，从而阻止代码访问到内核数据。达到双向隔离。即普通程序无法访问到敏感代码数据，敏感代码无法访问到内核数据。 权限访问控制 如上图所示，作者将敏感数据代码所在特权等级(r2)称为PrivUser-mode。用户模式由于页面属性的限制不能访问到内核及PrivUser，而作者将R2所在段的段基地地址与段限写在固定的位置，使得PrivUser的代码不能访问到内核。用户可以将特殊的数据如密钥等标记为敏感数据从而存放在PrivUser所在的S页面中。而需要访问到这些敏感数据需要先将处理器提升到R2级别。作者将访问数据的函数同样放到PrivUser所在的内存中，调用这些函数首先需要一个跨段跳转提升处理器级别。然后在R2特权中执行函数。 如上图即为作者的跨段跳转示意图，作者借助r1作为一个跨段跳转板，原因是他将R2段中的L标志(32位兼容模式)置位了，而跨段跳转指令不允许从一个非32位段跳到一个32位段，而允许从一个非32位段返回32位段，因此先进入R1将特权等级提升，再通过段返回指令如(lret)到PrivUser mode。这里我不能理解为何要将PrivUser段设置为32位兼容模式，从而导致多需要R1层作为跨段跳转中转。 编译套件作者将这套系统命名为LOTRx86。其中包含一系列的能够帮助用户编译保护隐私数据的软件。整个编译系统的流程如下图所示 作者定义了一个宏，这个宏接受函数名称和参数类型等作为参数，并对外导出一个调用接口。开发者将访问敏感数据的函数导出，然后在主程序中使用系统所提供的宏来访问这个函数。由于PrivUser层的数据代码是32位兼容的，因此作者直接将这段内容直接链接进可以执行文件中。并且作者修改了libc中的malloc等内存分配函数使得PrivUser中的函数分配的内存始终在PrivUser内存中。其中包含一个内核模块，其功能为初始化LDT，初始化PrivUser内存，写入跨段跳转中转指令等。 评估作者使用Privcall与一些常规的系统调用作对比，并且使用运行多次程序与在一次程序中多次调用来模拟程序使用接口的频繁程度。从图中可以看出Privcall相对于一些常规系统调用所带来的开销并不高。 接下来作者将LOTRx86方法与其他的两种方法作比较，即使页面保护与进程隔离两种方法。可以看出LOTRx86所带来的开销小于另外两个方法。 评价相对于传统的使用进程隔离，页面保护的方法，使用段隔离的方法带的开销的确是比较小的。方法比较新颖。但是除了作者提到的几个缺点： 参数仅支持32位 不支持ASLR 不能与用户程序共享数据空间 我觉得作者的论文来缺乏了一点：没有将所用到的段描述详细的描述出来。 另外我觉得作者的关于对敏感数据的访问定义不够好，我觉得对于敏感数据的访问，不应该以代码段或者说函数来看，而应该以程序运行的时间段来看。即不能说某个函数是可以访问敏感数据的，而应该说在程序运行的某个时间段是可以访问敏感数据的。由于这个定义的不够好，所以我发现作者的设计中的一个缺陷。比如某个访问敏感数据 的函数需要使用libc中的fread函数，那么由于访问控制的原因，那么fread函数同样必须位于PrivUser层，而这样正常的函数需要使用fread的函数又必须将这函数位置PrivUser层中，这样的关联导致大片的函数无法分开。而我提出我的一个想法： 构造一个LDT或者GDT，将段基地址写为0而将段限写为用户空间地址最大值。将这个段特权等级设置为1或者2，对应的SS,CS,DS都设置为使用这个LDT或者GDT。 将敏感数据放置于S页面中，当程序需要访问到敏感数据时，使用一个段跨越跳转跳到这个转中，跳转地址写为下一条指令。那么程序的执行流程正常进行，但是特权等级却切换到了高的特权等级上。 当不再需要访问敏感数据时则伪造一个栈结构，跨段返回到下一条指令，这样程正常继续以低特权运行。 这样做的好处有： 作法简单，只需要定义两个宏用于平衡栈和跨段跳转及返回 由于段空间与用户空间重叠，因此可以直接访问用户空间数据 符合访问敏感数据的定义，即访问敏感数据的代码与正常代码在内存中存在于一块，不需要另外编写一个宏将这段函数放在另外一个地方，只是访问时的特权等级变了。这样我所提到的函数牵连问就不存在。 粒度更加可控，作者提出的粒度基于函数，即将整个函数作为访问敏感数据的代码块，而这里可以选择一小块代码，外包一个跨段宏和退段宏即可。","content":"<h1 id=\"Abstract\"><a href=\"#Abstract\" class=\"headerlink\" title=\"Abstract\"></a>Abstract</h1><p>前heartbleed漏洞导致的敏感信息常泄露一直是人们要解决的问题，即如何保护程序中的隐私数据不被任意的访问到。研究人员想到的方法根本出发点为，将隐私数据隔离，即使存在程序漏洞，也不能任意访问到这些敏感数据。而将隐私数据存放于什么位置，是人们一直以来需要解决的问题。此前的解决办法包括，线程隔离，进程隔离，使用可以信执行区域(如Intel SGX)等。这些方法或者性能影响比较大，或者受限到CPU型号。<strong><em>而在这篇论文里作者使用Intel x86处理器一直以来存在的r0-r3四个特权等级来将数据隔离访问，一方面解决了处理器兼容问题(几乎所有Intel AMD处理器均支持这四个特权级别)，一方面解决了性能问题。</em></strong></p>\n<table>\n<thead>\n<tr>\n<th>relevant information</th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><em>作者</em></td>\n<td>Hojoon Lee, Chihyun Song, Brent Byunghoon Kang</td>\n</tr>\n<tr>\n<td><em>单位</em></td>\n<td>CISPA Helmholtz Center i.G. GSIS, School of Computing, KAIST</td>\n</tr>\n<tr>\n<td><em>出处</em></td>\n<td>ACM CCS’18</td>\n</tr>\n<tr>\n<td><em>原文地址</em></td>\n<td><a href=\"https://github.com/wtwofire/database/blob/master/papers/reverse/2018-Lord%20of%20the%20X86%20Rings%20A%20Portable%20User%20Mode%20Privilege%20Separation%20Architecture%20on%20X86.pdf\" target=\"_blank\" rel=\"noopener\">https://github.com/wtwofire/database/blob/master/papers/reverse/2018-Lord%20of%20the%20X86%20Rings%20A%20Portable%20User%20Mode%20Privilege%20Separation%20Architecture%20on%20X86.pdf</a></td>\n</tr>\n<tr>\n<td><em>源码地址</em></td>\n<td></td>\n</tr>\n<tr>\n<td><em>发表时间</em></td>\n<td>2018年</td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"x86-特权级别及切换\"><a href=\"#x86-特权级别及切换\" class=\"headerlink\" title=\"x86 特权级别及切换\"></a>x86 特权级别及切换</h1><p>这篇论文带读者复习了x86处理器的环(ring)特权等级，门描述，GDT，LDT，段选择子，段间跳转等内容。而这篇论文的内容主要基于现代操作系统几乎没有用到的r1,r2两个特权等级。用户程序运行在R3等级，而操作系统内核运行在R0级别。用户程序不能访问到内核数据空间，原因在于页表的访问权限的限制。以下将内核页面权限简称S页面，将用户页面权限称为U页面。作者将用户的敏感数据及访问这些数据的代码放置于S页面，从而达到普通用户程序无法访问到敏感数据。然后将段代码所运行的特级等级设置于r1，从而阻止代码访问到内核数据。达到双向隔离。即普通程序无法访问到敏感代码数据，敏感代码无法访问到内核数据。</p>\n<h1 id=\"权限访问控制\"><a href=\"#权限访问控制\" class=\"headerlink\" title=\"权限访问控制\"></a>权限访问控制</h1><p><img src=\"/2019/02/15/Lord-of-the-X86-Rings-A-Portable-User-Mode-Privilege-Separation-Architecture-on-X86/1.png\" alt=\"\"></p>\n<p>如上图所示，作者将敏感数据代码所在特权等级(r2)称为PrivUser-mode。用户模式由于页面属性的限制不能访问到内核及PrivUser，而作者将R2所在段的段基地地址与段限写在固定的位置，使得PrivUser的代码不能访问到内核。用户可以将特殊的数据如密钥等标记为敏感数据从而存放在PrivUser所在的S页面中。而需要访问到这些敏感数据需要先将处理器提升到R2级别。作者将访问数据的函数同样放到PrivUser所在的内存中，调用这些函数首先需要一个跨段跳转提升处理器级别。然后在R2特权中执行函数。</p>\n<p><img src=\"/2019/02/15/Lord-of-the-X86-Rings-A-Portable-User-Mode-Privilege-Separation-Architecture-on-X86/2.png\" alt=\"\"></p>\n<p>如上图即为作者的跨段跳转示意图，作者借助r1作为一个跨段跳转板，原因是他将R2段中的L标志(32位兼容模式)置位了，而跨段跳转指令不允许从一个非32位段跳到一个32位段，而允许从一个非32位段返回32位段，因此先进入R1将特权等级提升，再通过段返回指令如(lret)到PrivUser mode。这里我不能理解为何要将PrivUser段设置为32位兼容模式，从而导致多需要R1层作为跨段跳转中转。</p>\n<h1 id=\"编译套件\"><a href=\"#编译套件\" class=\"headerlink\" title=\"编译套件\"></a>编译套件</h1><p>作者将这套系统命名为LOTRx86。其中包含一系列的能够帮助用户编译保护隐私数据的软件。整个编译系统的流程如下图所示</p>\n<p><img src=\"/2019/02/15/Lord-of-the-X86-Rings-A-Portable-User-Mode-Privilege-Separation-Architecture-on-X86/3.png\" alt=\"\"></p>\n<p>作者定义了一个宏，这个宏接受函数名称和参数类型等作为参数，并对外导出一个调用接口。开发者将访问敏感数据的函数导出，然后在主程序中使用系统所提供的宏来访问这个函数。由于PrivUser层的数据代码是32位兼容的，因此作者直接将这段内容直接链接进可以执行文件中。并且作者修改了libc中的malloc等内存分配函数使得PrivUser中的函数分配的内存始终在PrivUser内存中。其中包含一个内核模块，其功能为初始化LDT，初始化PrivUser内存，写入跨段跳转中转指令等。</p>\n<h1 id=\"评估\"><a href=\"#评估\" class=\"headerlink\" title=\"评估\"></a>评估</h1><p>作者使用Privcall与一些常规的系统调用作对比，并且使用运行多次程序与在一次程序中多次调用来模拟程序使用接口的频繁程度。从图中可以看出Privcall相对于一些常规系统调用所带来的开销并不高。</p>\n<p>接下来作者将LOTRx86方法与其他的两种方法作比较，即使页面保护与进程隔离两种方法。可以看出LOTRx86所带来的开销小于另外两个方法。</p>\n<p><img src=\"/2019/02/15/Lord-of-the-X86-Rings-A-Portable-User-Mode-Privilege-Separation-Architecture-on-X86/4.png\" alt=\"\"></p>\n<h1 id=\"评价\"><a href=\"#评价\" class=\"headerlink\" title=\"评价\"></a>评价</h1><p>相对于传统的使用进程隔离，页面保护的方法，使用段隔离的方法带的开销的确是比较小的。方法比较新颖。但是除了作者提到的几个缺点：</p>\n<ol>\n<li>参数仅支持32位</li>\n<li>不支持ASLR</li>\n<li>不能与用户程序共享数据空间</li>\n</ol>\n<p>我觉得作者的论文来缺乏了一点：没有将所用到的段描述详细的描述出来。</p>\n<p>另外我觉得作者的关于对敏感数据的访问定义不够好，我觉得对于敏感数据的访问，不应该以代码段或者说函数来看，而应该以程序运行的时间段来看。即不能说某个函数是可以访问敏感数据的，而应该说在程序运行的某个时间段是可以访问敏感数据的。由于这个定义的不够好，所以我发现作者的设计中的一个缺陷。比如某个访问敏感数据 的函数需要使用libc中的fread函数，那么由于访问控制的原因，那么fread函数同样必须位于PrivUser层，而这样正常的函数需要使用fread的函数又必须将这函数位置PrivUser层中，这样的关联导致大片的函数无法分开。而我提出我的一个想法：</p>\n<ol>\n<li>构造一个LDT或者GDT，将段基地址写为0而将段限写为用户空间地址最大值。将这个段特权等级设置为1或者2，对应的SS,CS,DS都设置为使用这个LDT或者GDT。</li>\n<li>将敏感数据放置于S页面中，当程序需要访问到敏感数据时，使用一个段跨越跳转跳到这个转中，跳转地址写为下一条指令。那么程序的执行流程正常进行，但是特权等级却切换到了高的特权等级上。</li>\n<li>当不再需要访问敏感数据时则伪造一个栈结构，跨段返回到下一条指令，这样程正常继续以低特权运行。</li>\n</ol>\n<p>这样做的好处有：</p>\n<ol>\n<li>作法简单，只需要定义两个宏用于平衡栈和跨段跳转及返回</li>\n<li>由于段空间与用户空间重叠，因此可以直接访问用户空间数据</li>\n<li>符合访问敏感数据的定义，即访问敏感数据的代码与正常代码在内存中存在于一块，不需要另外编写一个宏将这段函数放在另外一个地方，只是访问时的特权等级变了。这样我所提到的函数牵连问就不存在。</li>\n<li>粒度更加可控，作者提出的粒度基于函数，即将整个函数作为访问敏感数据的代码块，而这里可以选择一小块代码，外包一个跨段宏和退段宏即可。</li>\n</ol>\n","categories":[{"name":"论文","slug":"论文","permalink":"http://yama0xff.com/categories/论文/"},{"name":"软件分析","slug":"论文/软件分析","permalink":"http://yama0xff.com/categories/论文/软件分析/"}],"tags":[{"name":"2018年","slug":"2018年","permalink":"http://yama0xff.com/tags/2018年/"},{"name":"防护","slug":"防护","permalink":"http://yama0xff.com/tags/防护/"},{"name":"ACM CCS'18","slug":"ACM-CCS-18","permalink":"http://yama0xff.com/tags/ACM-CCS-18/"}]},{"title":"Digtool: A Virtualization-Based Framework for Detecting Kernel Vulnerabilities","date":"2019-02-15T07:53:36.000Z","path":"2019/02/15/Digtool-A-Virtualization-Based-Framework-for-Detecting-Kernel-Vulnerabilities/","text":"Abstract发现操作系统（OS）内核中的漏洞并对其进行修补对于操作系统安全至关重要。但是，缺乏有效的内核漏洞检测工具，尤其是对于Microsoft Windows等封闭源操作系统。在本文中，我们介绍了Digtool，一个有效的，仅二进制代码的内核漏洞检测框架。 Digtool构建于我们设计的虚拟化监视器之上，成功捕获内核执行的各种动态行为，例如内核对象分配，内核内存访问，线程调度和函数调用。通过这些行为，Digtool已经确定了45个零日漏洞，例如最近版本的Microsoft Windows的内核代码和设备驱动程序中的out–bounds访问，free-after-free和check-time-of-use-of-use ，包括Windows 7和Windows 10。 relevant information 作者 Jianfeng Pan, Guanglu Yan, Xiaocao Fan 单位 IceSword Lab, 360 Internet Security Center 出处 USENIX’17 原文地址 https://github.com/wtwofire/database/blob/master/papers/fuzzing/2017-Digtool%EF%BC%9AA%20Virtualization-Based%20Framework%20for%20Detecting%20Kernel%20Vulnerabilities.pdf 源码地址 无，相关材料：Slide,Video 发表时间 2017年 一、背景目前，自动化检测系统内核漏洞的工具比较少，而且，很多的工具都是只能检测开源的系统内核（例如：Linux操作系统），对于不开源的操作系统（例如：Microsoft Windows）则无能为力。因此，很有必要开发一款专用的系统内核漏洞检测工具，在二进制层面检测系统内核潜在的漏洞。漏洞检测工具通常分为两个方面：路径探测和漏洞识别，路径探测通常使用fuzzer工具，查找尽可能多的分支路径；漏洞识别则用于检测这些路径上可能存在的漏洞。而在这篇文章中，作者结合了这两个方面的技术，具体检测了内核中的以下四种漏洞类型： 1. UNPROBE在这篇文章中，作者把未经检查的、从用户层传下来的输入缓冲区指针所造成的漏洞叫做UNPROBE。很多内核模块都可能会忽略对用户层的指针进行检查，特别是一些被嵌套的指针，而这种情况是非常危险的，因为它可能会导致非法内存引用、任意的内存读或者写等严重后果。 2. TOCTTOU (Time-Of-Check-To-Time-Of-Use)TOCTTOU漏洞来源于对同一个用户层的数据进行多次的访问。在有些系统调用处理例程中，当它要访问某一个用户层数据的时候，它首先会检查这个数据是否合法，然后再使用它，这就会产生两次对该数据的访问，而在这两次访问之间就会存在一个攻击窗口，一旦这个攻击窗口被攻击者利用，就有可能导致非法内存引用、任意的内存读或者写等严重后果。 3. UAF (Use-After-Free)UAF漏洞是由于使用了被释放的内存导致的。很多情况下，这种漏洞可能会导致本地提权。在Linux上，像AddressSanitizer这样的工具已经可以用于检测这类漏洞；在Windows上，微软自己开发的DriverVerifier也可以用于检测这种类型的漏洞，但是限制条件比较多。 4. OOB (Out-Of-Bound access)OOB漏洞是由于访问了目标内存块之外的内存导致的。该漏洞导致的后果跟UAF漏洞导致的后果一样，都可能会导致本地提权，并且用于检测这两种漏洞的工具也基本一样。 二、提出的方法以及解决的问题像Windows这样的闭源操作系统，要检测系统中存在的漏洞，就不能再使用基于源码的检测工具，必须使用基于二进制代码的检测工具。因此，为了检测Windows内核中出现的以上四种漏洞类型，作者提出了一个基于二进制代码的检测框架：DigTool。该框架建立在作者自己设计的一个虚拟化监视器（Hypervisor）之上，用来捕获内核执行过程中的各种动态行为，例如：内核对象的分配、内核中的内存访问、线程调度和函数调用等，并基于这些行为，发掘系统中存在的漏洞。 三、技术方法 DigTool的总体架构如图1所示，它的各个模块分布在系统的不同的层次当中，它们分别包括：Hypervisor中、客户机的内核中以及客户机的用户空间。通过箭头可以知道它们之间的各个模块的相互作用关系：细箭头所连接的两个模块表明它们之间有直接的调用关系或者是直接的传输信息通道，粗箭头表明两个模块之间通过某种事件触发机制进行间接的相互作用。 (1). Hypervisor 组件：DigTool不依赖于Xen、KVM等当前存在的Hypervisor，而是自己开发一个Hypervisor，它包含三个重要的组成部分：VMM（Virtual Machine Monitor）infrastructure、Interface detection 和 memory detection。 虚拟机监控模块（VMM infrastructure）： 首先，它负责检测机器上的硬件环境和操作系统的版本等，以确保DigTool能正确的运行；然后，它再初始化Hypervisor，并把一个原始的操作系统加载到一个VM虚拟机当中运行。 接口检测（Interface detection）： 它负责监控用户层的应用程序在调用系统调用的时候传递到内核中的参数。在内核中，它跟踪这些参数被使用和被检查所发生的位置，以发掘潜在的漏洞。为了提高性能，DigTool并不是监控所有的系统调用，它只监控自己感兴趣的系统调用（通过配置文件进行配置）。因此，它限制了被监控的系统调用的范围，以检查特定的系统调用所产生的漏洞。 内存检测（Memory detection）： 该模块通过使用SPT（Shadow Page Table）技术，监控客户机操作系统内核中的非法内存访问。为了检测特定的内核模块（例如Win32k等），该模块可以通过调用相应的服务接口（Hypervisor提供给客户机操作系统内核的接口）来限制被监控的内核模块和地址范围。 (2). Kernel-Space 组件：DigTool在客户机操作系统内核中的所有模块被统称为：Middleware，它属于一个中间桥梁（或者说是一个中间件），用于连接Hypervisor和客户机用户空间程序，具有承上启下的作用。 例如图1中，在Loader加载Fuzzer之前，可以通过用户空间中的configuration文件配置被检测的系统调用的范围，然后通过Middleware把相应的信息传送到Hypervisor，这就使得Hypervisor可以在Fuzzer进程空间中检测相应系统调用中的漏洞了。 对于接口检测，Middleware通过一个工作线程（Work thread）把所有的相关信息（包括系统调用号、事件类型、事件发生的时间、指令地址以及访问的内存）都记录到日志文件中。以便于日志分析模块（Log analyzer）可以通过日志文件分析并查找出相应的漏洞。 对于内存检测，Middleware通过Hook特定的内存操作函数，辅助内存检测模块矫正被检测的内存范围（因为DigTool只检测部分相关的内存范围），并且通过调用Hypervisor提供的接口来限制被监控的内存区域，以提高性能。另外，如果在这个过程中发现一个潜在的漏洞，Middleware还会中断客户机，使之进入单步调试模式，等待外部调试工具（例如 WinDbg）连接，并获取有用的上下文环境，辅助漏洞分析。 (3). User-Space 组件：为了提高系统的稳定性和健壮性，作者把DigTool的一部分作用功能模块放到用户空间中，这些模块包括：Loader模块、Fuzzer模块和Log Analyzer模块。 Loader模块，它负责装载一个特定的进程，给DigTool提供一个检测漏洞的进程环境。该模块还需要配置configuration文件，限制被检测的系统调用的范围等（要检测哪些系统调用就把这些系统调用添加到配置文件中）。 Fuzzer模块，该模块由Loader模块装载，通过Fuzzer模块调用系统调用，并通过调整系统调用的参数，探索尽可能多的路径，使得漏洞检测模块可以发掘尽可能多的漏洞。 Log Analyzer模块，该模块负责分析日志文件，分析代码中可能存在的漏洞。 四、实验评估(1). 有效性评估作者通过测试不同的软件产品来评估DigTool的有效性，这些产品包括Windows操作系统和一些反病毒软件，并且这些产品都是当时最新的版本。实验环境包括Windows 7和Windows 10。为了安全起见，在这篇文章中，作者使用的例子是当时发现的0Day漏洞，并且是已经被相应的厂商修复的漏洞。 Detecting Vulnerability via Interface：如表1所示，对于Avast Free Antivirus v11.2.2262、Dr. Web 11.0、AhnLab v8.0、Norman Security Suite v11.0.0和Spyware Detector v2.0.0.3这五个反病毒软件，被检测出存在UNPROBE漏洞的数量总共为23个。 如表2所示，对于同样的五个反病毒软件，被检测出存在TOCTTOU漏洞的数量总共为18个。 Detecting Vulerabiliry via Memory Footprints:为了检测UAF和OOB漏洞，作者选择32位的Windows 10为实验环境。检测这两类漏洞不再使用日志的形式，而是使用中断客户机系统的形式，即：当发现可能存在的漏洞的时候，中断客户机系统，等待调试工具连接，等调试工具连接上来之后，可以获取当前产生漏洞的位置对应的上下文环境，用于分析漏洞。但是这种方式的不足之处在于：它需要手工去分析漏洞。 在win32kfull.sys文件中，DigTool最先发现了MS16-123/CVE-2016-7211 CVE漏洞。 而对于OOB漏洞，作者使用DigTool发现了三个win32kbase中的CVE，它们分别是：MS16-090/CVE-2016-3252、MS16-034/CVE-2016-0096 和 MS16-151/CVE-2016-7260。 (2). 效率评估目前，由于Bochspwn（一个基于Bochs模拟器的内核漏洞检测工具）只能检测前文中提到的四种漏洞类型的一类：TOCTTOU，因此，作者只能将DigTool与Bochspwn进行TOCTTOU漏洞测试比较。基于相同的环境下（相同的硬件、相同的操作系统版本、相同的系统调用参数和相同的测试程序），作者选用了十个最经常使用、最经常被反病毒软件Hook的系统调用的系统调用来测试性能开销。此外，为了测试结果的完整性，作者还选用了一个常用的软件WinRAR来加入这个测试实验当中，这两个工具的性能比较结果如图2所示。 在上图的实验结果中，作者分两种情况进行比较:“Unrecorded”和“Recorded”,具体如下： Unrecorded在这种测试模式下，在DigTool的配置文件中不添加任何的系统调用（相当于没有内存页面被监控），也不做任何的日志操作，但是在接口检测（Interface Detection）模块中的其它子功能是处于工作状态当中的。由于在检测TOCTTOU漏洞的时候，大部分系统调用和线程都处于不被监控状态，因此，该模式可以反映整个系统的基本性能开销，很适合与Bochspwn进行比较。 该模式下的性能开销比Windows模式（既没有DigTool，也没有Bochs）下慢2.18到5.03倍，比Bochspwn（操作系统运行在Bochs中）快45.4到156.5倍。对于WinRAR的测试结果，DigTool比Windows模式慢2.25倍，比Bochspwn模式快428.8倍。 Recorded在这种测试模式下，相应的系统调用将被写入到配置文件中，并且相应的行为也会被记录下来（监控配置文件中指定的系统调用和相关的线程，对于无关的系统调用和线程都不做任何操作）。 该模式下的性能开销比Windows模式（既没有DigTool，也没有Bochs）下慢70到90倍，但任然比Bochspwn（操作系统运行在Bochs中）稍快。对于WinRAR的测试结果，这次测试使用极端情况，即：监控NT kernel中的所有系统调用。测试结果表明：DigTool比Windows模式慢13.45倍，比Bochspwn模式快71.8倍。 五、优缺点优点： DigTool相对于Bochspwn来说，在性能方面有很大的优势。不管是在“Unrecorded”模式还是“Recorded”模式下，DigTool都比Bochspwn快。 相对于DriverVerifier（一款微软开发的、用于检测Windows内核漏洞的工具），DigTool具有更好的弹性。在检测到一个可能的漏洞的时候，DriverVerifier会造成系统蓝屏死机（BSOD）,而且当这个潜在的漏洞在没有被修复之前，DriverVerifier就不能继续往下运行，因此无法同时检测多个漏洞；而DigTool则不会出现这种情况，DigTool在检测到潜在的漏洞的时候，只会记录漏洞发生的地点等一些有用的信息，不会造成系统蓝屏死机，并且可以同时检测多个漏洞。 对于OOB漏洞和UAF漏洞，DigTool在检测到潜在的漏洞的时候，可以直接中断客户机，等待外部调试器（如WinDbg等）连接，查看产生漏洞时刻的上下文，方便分析人员获取有用的信息；而DriverVerifier在检测到潜在的漏洞的时候，只能Crash客户机，并且无法获取产生漏洞时的上下文环境，若要分析产生漏洞的原因，分析人员还需要做额外的逆向分析工作，以确定漏洞产生的具体位置以及具体原因。 DigTool可以检测UNPROBE和TOCTTOU漏洞类型，而DriverVerifier则不可以。 在检测UAF和OOB漏洞的时候，如果漏洞没有造成系统崩溃，则DriverVerifier无法检测到它的存在。 DigTool发现了45个0Day内核漏洞。 缺点： 虽然DigTool的性能相对于Bochspwn好很多，但是，由于DigTool需要从Hypervisor和客户机之间频繁的进行切换，性能开销依然比较大。 DigTool的可移植性依然不是那么好，它目前只能运行Windows平台上。虽然DigTool的Hypervisor层与平台无关，但是它的Middleware层是与特定的平台相关的，要想使得DigTool在别的平台上能够运行，则必须修改它的Middleware。 DigTool目前只能检测四种漏洞类型：UNPROBE、TOCTTOU、UAF和OOB。对于其它的漏洞类型（例如：空指针解引用、双重释放等）却无法检测到。 该工具不是开源的工具，目前网上没有该工具的源代码。 该工具只能应用于内核漏洞检测，无法用于应用层的漏洞检测。 六、个人观点目前，已经存在很多用于检测漏洞的工具，既有收费的工具，又有免费的工具，不同的工具一般都有不同的用途，并且很多工具都只是检测具体的某一类或者是某几类漏洞。它们的检测方法也各不相同，有些基于源码检测，有些则基于二进制代码检测。而基于源码检测的工具比较多，这些工具大部分都是用于检测应用层的应用程序，以及开源的系统内核（例如Linux内核等）。很少有检测Windows内核漏洞的工具，因为Windows内核是闭源的，无法获取到它的源代码。 对于检测Windows内核漏洞，目前有一款功能非常受限的、微软开发的检测工具DriverVerifier，前文也提到，该工具的限制条件比较多，检测的漏洞类型也很少，因此，作者自己开发了一款检测Windows内核漏洞的工具：DigTool，作为DriverVerifier的补充工具。 DigTool主要关注两个部分的内容，一个是系统调用入口，当应用程序调用系统调用的时候，可能会由于各种原因，导致非法的、或者是不适当的参数被传入到系统内核中，如果内核代码不能处理好外部传入的参数，攻击者就可能会利用这些入口点，来获得额外的权限，这可能会导致系统内核沦陷。另一种情况是，内核代码如果对内存操作不当，也可能会导致严重的后果（例如，系统可能会出现崩溃、拒绝服务等现象）。 DigTool是基于二进制代码的一个漏洞检测工具，它的总体架构分为三个组成部分（Hypervisor Component、Kernel-Space Component 和 User-Space Component），其中Hypervisor Component是与平台无关的，而另外两个部分是与平台相关的，如果我们能够把它的Kernel-Space Component（其实就是它的Middleware部分）移植到别的系统上（例如MacOS、Linux OS等），那么，我们也可以利用作者的这个工具检测别的系统上的漏洞。虽然DigTool的User-Space Component也是与平台相关的，但是这部分的移植相对于Middleware来说简单的多，因此，DigTool的可移植性主要体现在它的Middleware上。 作者的DigTool目前已经可以检测四种漏洞类型（UNPROBE、TOCTTOU、UAF和OOB），如果稍作改进，可能也会比较容易检测双重释放等类型的漏洞，因为作者的这个工具可以检测到任意的内存地址空间。作者在文章中说道，当检测OOB漏洞的时候，作者使用AVL树来保存已经分配的内存区域，如果一片内存区域已经被释放，则它将会从AVL树中被移除，如果再次释放该内存区域，则DigTool会首先在AVL树中查找该内存区域，若找到，则释放（一般不可能）；若没有找到，则表明已经被释放，或者是没有该内存区域，即：可以发现双重释放类型的漏洞。但是，有一个很大的问题限制了这个想法，那就是：作者的DigTool不开源，我们无法获取到他的源代码，因此，我们也就无法在他的这个工具上做二次开发。 ​ 转载于GoSSIP","content":"<h1 id=\"Abstract\"><a href=\"#Abstract\" class=\"headerlink\" title=\"Abstract\"></a>Abstract</h1><p>发现操作系统（OS）内核中的漏洞并对其进行修补对于操作系统安全至关重要。但是，缺乏有效的内核漏洞检测工具，尤其是对于Microsoft Windows等封闭源操作系统。在本文中，我们介绍了Digtool，一个有效的，仅二进制代码的内核漏洞检测框架。 Digtool构建于我们设计的虚拟化监视器之上，成功捕获内核执行的各种动态行为，例如内核对象分配，内核内存访问，线程调度和函数调用。通过这些行为，Digtool已经确定了45个零日漏洞，例如最近版本的Microsoft Windows的内核代码和设备驱动程序中的out–bounds访问，free-after-free和check-time-of-use-of-use ，包括Windows 7和Windows 10。</p>\n<table>\n<thead>\n<tr>\n<th>relevant information</th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><em>作者</em></td>\n<td>Jianfeng Pan, Guanglu Yan, Xiaocao Fan</td>\n</tr>\n<tr>\n<td><em>单位</em></td>\n<td>IceSword Lab, 360 Internet Security Center</td>\n</tr>\n<tr>\n<td><em>出处</em></td>\n<td>USENIX’17</td>\n</tr>\n<tr>\n<td><em>原文地址</em></td>\n<td><a href=\"https://github.com/wtwofire/database/blob/master/papers/fuzzing/2017-Digtool%EF%BC%9AA%20Virtualization-Based%20Framework%20for%20Detecting%20Kernel%20Vulnerabilities.pdf\" target=\"_blank\" rel=\"noopener\">https://github.com/wtwofire/database/blob/master/papers/fuzzing/2017-Digtool%EF%BC%9AA%20Virtualization-Based%20Framework%20for%20Detecting%20Kernel%20Vulnerabilities.pdf</a></td>\n</tr>\n<tr>\n<td><em>源码地址</em></td>\n<td>无，相关材料：<a href=\"https://www.usenix.org/sites/default/files/conference/protected-files/usenixsecurity17_slides_guanglu_yan.pdf\" target=\"_blank\" rel=\"noopener\">Slide</a>,<a href=\"https://www.youtube.com/watch?v=EOhIxpcyAiw\" target=\"_blank\" rel=\"noopener\">Video</a></td>\n</tr>\n<tr>\n<td><em>发表时间</em></td>\n<td>2017年</td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"一、背景\"><a href=\"#一、背景\" class=\"headerlink\" title=\"一、背景\"></a>一、背景</h1><p>目前，自动化检测系统内核漏洞的工具比较少，而且，很多的工具都是只能检测开源的系统内核（例如：Linux操作系统），对于不开源的操作系统（例如：Microsoft Windows）则无能为力。因此，很有必要开发一款专用的系统内核漏洞检测工具，在二进制层面检测系统内核潜在的漏洞。漏洞检测工具通常分为两个方面：路径探测和漏洞识别，路径探测通常使用fuzzer工具，查找尽可能多的分支路径；漏洞识别则用于检测这些路径上可能存在的漏洞。而在这篇文章中，作者结合了这两个方面的技术，具体检测了内核中的以下四种漏洞类型：</p>\n<h2 id=\"1-UNPROBE\"><a href=\"#1-UNPROBE\" class=\"headerlink\" title=\"1. UNPROBE\"></a><strong>1. UNPROBE</strong></h2><p>在这篇文章中，作者把未经检查的、从用户层传下来的输入缓冲区指针所造成的漏洞叫做UNPROBE。很多内核模块都可能会忽略对用户层的指针进行检查，特别是一些被嵌套的指针，而这种情况是非常危险的，因为它可能会导致非法内存引用、任意的内存读或者写等严重后果。</p>\n<h2 id=\"2-TOCTTOU-Time-Of-Check-To-Time-Of-Use\"><a href=\"#2-TOCTTOU-Time-Of-Check-To-Time-Of-Use\" class=\"headerlink\" title=\"2. TOCTTOU (Time-Of-Check-To-Time-Of-Use)\"></a><strong>2. TOCTTOU (Time-Of-Check-To-Time-Of-Use)</strong></h2><p>TOCTTOU漏洞来源于对同一个用户层的数据进行多次的访问。在有些系统调用处理例程中，当它要访问某一个用户层数据的时候，它首先会检查这个数据是否合法，然后再使用它，这就会产生两次对该数据的访问，而在这两次访问之间就会存在一个攻击窗口，一旦这个攻击窗口被攻击者利用，就有可能导致非法内存引用、任意的内存读或者写等严重后果。</p>\n<h2 id=\"3-UAF-Use-After-Free\"><a href=\"#3-UAF-Use-After-Free\" class=\"headerlink\" title=\"3. UAF (Use-After-Free)\"></a><strong>3. UAF (Use-After-Free)</strong></h2><p>UAF漏洞是由于使用了被释放的内存导致的。很多情况下，这种漏洞可能会导致本地提权。在Linux上，像AddressSanitizer这样的工具已经可以用于检测这类漏洞；在Windows上，微软自己开发的DriverVerifier也可以用于检测这种类型的漏洞，但是限制条件比较多。</p>\n<h2 id=\"4-OOB-Out-Of-Bound-access\"><a href=\"#4-OOB-Out-Of-Bound-access\" class=\"headerlink\" title=\"4. OOB (Out-Of-Bound access)\"></a><strong>4. OOB (Out-Of-Bound access)</strong></h2><p>OOB漏洞是由于访问了目标内存块之外的内存导致的。该漏洞导致的后果跟UAF漏洞导致的后果一样，都可能会导致本地提权，并且用于检测这两种漏洞的工具也基本一样。</p>\n<h1 id=\"二、提出的方法以及解决的问题\"><a href=\"#二、提出的方法以及解决的问题\" class=\"headerlink\" title=\"二、提出的方法以及解决的问题\"></a>二、提出的方法以及解决的问题</h1><p>像Windows这样的闭源操作系统，要检测系统中存在的漏洞，就不能再使用基于源码的检测工具，必须使用基于二进制代码的检测工具。因此，为了检测Windows内核中出现的以上四种漏洞类型，作者提出了一个基于二进制代码的检测框架：DigTool。该框架建立在作者自己设计的一个虚拟化监视器（Hypervisor）之上，用来捕获内核执行过程中的各种动态行为，例如：内核对象的分配、内核中的内存访问、线程调度和函数调用等，并基于这些行为，发掘系统中存在的漏洞。</p>\n<h1 id=\"三、技术方法\"><a href=\"#三、技术方法\" class=\"headerlink\" title=\"三、技术方法\"></a>三、技术方法</h1><p><img src=\"/2019/02/15/Digtool-A-Virtualization-Based-Framework-for-Detecting-Kernel-Vulnerabilities/1.jpg\" alt=\"\"></p>\n<p>DigTool的总体架构如图1所示，它的各个模块分布在系统的不同的层次当中，它们分别包括：Hypervisor中、客户机的内核中以及客户机的用户空间。通过箭头可以知道它们之间的各个模块的相互作用关系：细箭头所连接的两个模块表明它们之间有直接的调用关系或者是直接的传输信息通道，粗箭头表明两个模块之间通过某种事件触发机制进行间接的相互作用。</p>\n<h2 id=\"1-Hypervisor-组件：\"><a href=\"#1-Hypervisor-组件：\" class=\"headerlink\" title=\"(1). Hypervisor 组件：\"></a><strong>(1). Hypervisor 组件：</strong></h2><p>DigTool不依赖于Xen、KVM等当前存在的Hypervisor，而是自己开发一个Hypervisor，它包含三个重要的组成部分：VMM（Virtual Machine Monitor）infrastructure、Interface detection 和 memory detection。</p>\n<ul>\n<li>虚拟机监控模块（VMM infrastructure）： 首先，它负责检测机器上的硬件环境和操作系统的版本等，以确保DigTool能正确的运行；然后，它再初始化Hypervisor，并把一个原始的操作系统加载到一个VM虚拟机当中运行。</li>\n<li>接口检测（Interface detection）： 它负责监控用户层的应用程序在调用系统调用的时候传递到内核中的参数。在内核中，它跟踪这些参数被使用和被检查所发生的位置，以发掘潜在的漏洞。为了提高性能，DigTool并不是监控所有的系统调用，它只监控自己感兴趣的系统调用（通过配置文件进行配置）。因此，它限制了被监控的系统调用的范围，以检查特定的系统调用所产生的漏洞。</li>\n<li>内存检测（Memory detection）： 该模块通过使用SPT（Shadow Page Table）技术，监控客户机操作系统内核中的非法内存访问。为了检测特定的内核模块（例如Win32k等），该模块可以通过调用相应的服务接口（Hypervisor提供给客户机操作系统内核的接口）来限制被监控的内核模块和地址范围。</li>\n</ul>\n<h2 id=\"2-Kernel-Space-组件：\"><a href=\"#2-Kernel-Space-组件：\" class=\"headerlink\" title=\"(2). Kernel-Space 组件：\"></a><strong>(2). Kernel-Space 组件：</strong></h2><p>DigTool在客户机操作系统内核中的所有模块被统称为：Middleware，它属于一个中间桥梁（或者说是一个中间件），用于连接Hypervisor和客户机用户空间程序，具有承上启下的作用。</p>\n<ul>\n<li>例如图1中，在Loader加载Fuzzer之前，可以通过用户空间中的configuration文件配置被检测的系统调用的范围，然后通过Middleware把相应的信息传送到Hypervisor，这就使得Hypervisor可以在Fuzzer进程空间中检测相应系统调用中的漏洞了。</li>\n<li>对于接口检测，Middleware通过一个工作线程（Work thread）把所有的相关信息（包括系统调用号、事件类型、事件发生的时间、指令地址以及访问的内存）都记录到日志文件中。以便于日志分析模块（Log analyzer）可以通过日志文件分析并查找出相应的漏洞。</li>\n<li>对于内存检测，Middleware通过Hook特定的内存操作函数，辅助内存检测模块矫正被检测的内存范围（因为DigTool只检测部分相关的内存范围），并且通过调用Hypervisor提供的接口来限制被监控的内存区域，以提高性能。另外，如果在这个过程中发现一个潜在的漏洞，Middleware还会中断客户机，使之进入单步调试模式，等待外部调试工具（例如 WinDbg）连接，并获取有用的上下文环境，辅助漏洞分析。</li>\n</ul>\n<h2 id=\"3-User-Space-组件：\"><a href=\"#3-User-Space-组件：\" class=\"headerlink\" title=\"(3). User-Space 组件：\"></a><strong>(3). User-Space 组件：</strong></h2><p>为了提高系统的稳定性和健壮性，作者把DigTool的一部分作用功能模块放到用户空间中，这些模块包括：Loader模块、Fuzzer模块和Log Analyzer模块。</p>\n<ul>\n<li>Loader模块，它负责装载一个特定的进程，给DigTool提供一个检测漏洞的进程环境。该模块还需要配置configuration文件，限制被检测的系统调用的范围等（要检测哪些系统调用就把这些系统调用添加到配置文件中）。</li>\n<li>Fuzzer模块，该模块由Loader模块装载，通过Fuzzer模块调用系统调用，并通过调整系统调用的参数，探索尽可能多的路径，使得漏洞检测模块可以发掘尽可能多的漏洞。</li>\n<li>Log Analyzer模块，该模块负责分析日志文件，分析代码中可能存在的漏洞。</li>\n</ul>\n<h1 id=\"四、实验评估\"><a href=\"#四、实验评估\" class=\"headerlink\" title=\"四、实验评估\"></a>四、实验评估</h1><h2 id=\"1-有效性评估\"><a href=\"#1-有效性评估\" class=\"headerlink\" title=\"(1). 有效性评估\"></a><strong>(1). 有效性评估</strong></h2><p>作者通过测试不同的软件产品来评估DigTool的有效性，这些产品包括Windows操作系统和一些反病毒软件，并且这些产品都是当时最新的版本。实验环境包括Windows 7和Windows 10。为了安全起见，在这篇文章中，作者使用的例子是当时发现的0Day漏洞，并且是已经被相应的厂商修复的漏洞。</p>\n<h4 id=\"Detecting-Vulnerability-via-Interface：\"><a href=\"#Detecting-Vulnerability-via-Interface：\" class=\"headerlink\" title=\"Detecting Vulnerability via Interface：\"></a><strong>Detecting Vulnerability via Interface：</strong></h4><p>如表1所示，对于Avast Free Antivirus v11.2.2262、Dr. Web 11.0、AhnLab v8.0、Norman Security Suite v11.0.0和Spyware Detector v2.0.0.3这五个反病毒软件，被检测出存在UNPROBE漏洞的数量总共为23个。</p>\n<p><img src=\"/2019/02/15/Digtool-A-Virtualization-Based-Framework-for-Detecting-Kernel-Vulnerabilities/Table1.jpg\" alt=\"\"></p>\n<p>如表2所示，对于同样的五个反病毒软件，被检测出存在TOCTTOU漏洞的数量总共为18个。</p>\n<p><img src=\"/2019/02/15/Digtool-A-Virtualization-Based-Framework-for-Detecting-Kernel-Vulnerabilities/Table2.jpg\" alt=\"\"></p>\n<h4 id=\"Detecting-Vulerabiliry-via-Memory-Footprints\"><a href=\"#Detecting-Vulerabiliry-via-Memory-Footprints\" class=\"headerlink\" title=\"Detecting Vulerabiliry via Memory Footprints:\"></a><strong>Detecting Vulerabiliry via Memory Footprints:</strong></h4><p>为了检测UAF和OOB漏洞，作者选择32位的Windows 10为实验环境。检测这两类漏洞不再使用日志的形式，而是使用中断客户机系统的形式，即：当发现可能存在的漏洞的时候，中断客户机系统，等待调试工具连接，等调试工具连接上来之后，可以获取当前产生漏洞的位置对应的上下文环境，用于分析漏洞。但是这种方式的不足之处在于：它需要手工去分析漏洞。</p>\n<p>在win32kfull.sys文件中，DigTool最先发现了MS16-123/CVE-2016-7211 CVE漏洞。</p>\n<p>而对于OOB漏洞，作者使用DigTool发现了三个win32kbase中的CVE，它们分别是：MS16-090/CVE-2016-3252、MS16-034/CVE-2016-0096 和 MS16-151/CVE-2016-7260。</p>\n<h2 id=\"2-效率评估\"><a href=\"#2-效率评估\" class=\"headerlink\" title=\"(2). 效率评估\"></a><strong>(2). 效率评估</strong></h2><p>目前，由于Bochspwn（一个基于Bochs模拟器的内核漏洞检测工具）只能检测前文中提到的四种漏洞类型的一类：TOCTTOU，因此，作者只能将DigTool与Bochspwn进行TOCTTOU漏洞测试比较。基于相同的环境下（相同的硬件、相同的操作系统版本、相同的系统调用参数和相同的测试程序），作者选用了十个最经常使用、最经常被反病毒软件Hook的系统调用的系统调用来测试性能开销。此外，为了测试结果的完整性，作者还选用了一个常用的软件WinRAR来加入这个测试实验当中，这两个工具的性能比较结果如图2所示。</p>\n<p>在上图的实验结果中，作者分两种情况进行比较:“Unrecorded”和“Recorded”,具体如下：</p>\n<h4 id=\"Unrecorded\"><a href=\"#Unrecorded\" class=\"headerlink\" title=\"Unrecorded\"></a><strong>Unrecorded</strong></h4><p>在这种测试模式下，在DigTool的配置文件中不添加任何的系统调用（相当于没有内存页面被监控），也不做任何的日志操作，但是在接口检测（Interface Detection）模块中的其它子功能是处于工作状态当中的。由于在检测TOCTTOU漏洞的时候，大部分系统调用和线程都处于不被监控状态，因此，该模式可以反映整个系统的基本性能开销，很适合与Bochspwn进行比较。</p>\n<p>该模式下的性能开销比Windows模式（既没有DigTool，也没有Bochs）下慢2.18到5.03倍，比Bochspwn（操作系统运行在Bochs中）快45.4到156.5倍。对于WinRAR的测试结果，DigTool比Windows模式慢2.25倍，比Bochspwn模式快428.8倍。</p>\n<h4 id=\"Recorded\"><a href=\"#Recorded\" class=\"headerlink\" title=\"Recorded\"></a><strong>Recorded</strong></h4><p>在这种测试模式下，相应的系统调用将被写入到配置文件中，并且相应的行为也会被记录下来（监控配置文件中指定的系统调用和相关的线程，对于无关的系统调用和线程都不做任何操作）。</p>\n<p>该模式下的性能开销比Windows模式（既没有DigTool，也没有Bochs）下慢70到90倍，但任然比Bochspwn（操作系统运行在Bochs中）稍快。对于WinRAR的测试结果，这次测试使用极端情况，即：监控NT kernel中的所有系统调用。测试结果表明：DigTool比Windows模式慢13.45倍，比Bochspwn模式快71.8倍。</p>\n<h1 id=\"五、优缺点\"><a href=\"#五、优缺点\" class=\"headerlink\" title=\"五、优缺点\"></a>五、优缺点</h1><h2 id=\"优点：\"><a href=\"#优点：\" class=\"headerlink\" title=\"优点：\"></a>优点：</h2><ul>\n<li>DigTool相对于Bochspwn来说，在性能方面有很大的优势。不管是在“Unrecorded”模式还是“Recorded”模式下，DigTool都比Bochspwn快。</li>\n<li>相对于DriverVerifier（一款微软开发的、用于检测Windows内核漏洞的工具），DigTool具有更好的弹性。在检测到一个可能的漏洞的时候，DriverVerifier会造成系统蓝屏死机（BSOD）,而且当这个潜在的漏洞在没有被修复之前，DriverVerifier就不能继续往下运行，因此无法同时检测多个漏洞；而DigTool则不会出现这种情况，DigTool在检测到潜在的漏洞的时候，只会记录漏洞发生的地点等一些有用的信息，不会造成系统蓝屏死机，并且可以同时检测多个漏洞。</li>\n<li>对于OOB漏洞和UAF漏洞，DigTool在检测到潜在的漏洞的时候，可以直接中断客户机，等待外部调试器（如WinDbg等）连接，查看产生漏洞时刻的上下文，方便分析人员获取有用的信息；而DriverVerifier在检测到潜在的漏洞的时候，只能Crash客户机，并且无法获取产生漏洞时的上下文环境，若要分析产生漏洞的原因，分析人员还需要做额外的逆向分析工作，以确定漏洞产生的具体位置以及具体原因。</li>\n<li>DigTool可以检测UNPROBE和TOCTTOU漏洞类型，而DriverVerifier则不可以。</li>\n<li>在检测UAF和OOB漏洞的时候，如果漏洞没有造成系统崩溃，则DriverVerifier无法检测到它的存在。</li>\n<li>DigTool发现了45个0Day内核漏洞。</li>\n</ul>\n<h2 id=\"缺点：\"><a href=\"#缺点：\" class=\"headerlink\" title=\"缺点：\"></a>缺点：</h2><ul>\n<li>虽然DigTool的性能相对于Bochspwn好很多，但是，由于DigTool需要从Hypervisor和客户机之间频繁的进行切换，性能开销依然比较大。</li>\n<li>DigTool的可移植性依然不是那么好，它目前只能运行Windows平台上。虽然DigTool的Hypervisor层与平台无关，但是它的Middleware层是与特定的平台相关的，要想使得DigTool在别的平台上能够运行，则必须修改它的Middleware。</li>\n<li>DigTool目前只能检测四种漏洞类型：UNPROBE、TOCTTOU、UAF和OOB。对于其它的漏洞类型（例如：空指针解引用、双重释放等）却无法检测到。</li>\n<li>该工具不是开源的工具，目前网上没有该工具的源代码。</li>\n<li>该工具只能应用于内核漏洞检测，无法用于应用层的漏洞检测。</li>\n</ul>\n<h1 id=\"六、个人观点\"><a href=\"#六、个人观点\" class=\"headerlink\" title=\"六、个人观点\"></a>六、个人观点</h1><p>目前，已经存在很多用于检测漏洞的工具，既有收费的工具，又有免费的工具，不同的工具一般都有不同的用途，并且很多工具都只是检测具体的某一类或者是某几类漏洞。它们的检测方法也各不相同，有些基于源码检测，有些则基于二进制代码检测。而基于源码检测的工具比较多，这些工具大部分都是用于检测应用层的应用程序，以及开源的系统内核（例如Linux内核等）。很少有检测Windows内核漏洞的工具，因为Windows内核是闭源的，无法获取到它的源代码。</p>\n<p>对于检测Windows内核漏洞，目前有一款功能非常受限的、微软开发的检测工具DriverVerifier，前文也提到，该工具的限制条件比较多，检测的漏洞类型也很少，因此，作者自己开发了一款检测Windows内核漏洞的工具：DigTool，作为DriverVerifier的补充工具。</p>\n<p>DigTool主要关注两个部分的内容，一个是系统调用入口，当应用程序调用系统调用的时候，可能会由于各种原因，导致非法的、或者是不适当的参数被传入到系统内核中，如果内核代码不能处理好外部传入的参数，攻击者就可能会利用这些入口点，来获得额外的权限，这可能会导致系统内核沦陷。另一种情况是，内核代码如果对内存操作不当，也可能会导致严重的后果（例如，系统可能会出现崩溃、拒绝服务等现象）。</p>\n<p>DigTool是基于二进制代码的一个漏洞检测工具，它的总体架构分为三个组成部分（Hypervisor Component、Kernel-Space Component 和 User-Space Component），其中Hypervisor Component是与平台无关的，而另外两个部分是与平台相关的，如果我们能够把它的Kernel-Space Component（其实就是它的Middleware部分）移植到别的系统上（例如MacOS、Linux OS等），那么，我们也可以利用作者的这个工具检测别的系统上的漏洞。虽然DigTool的User-Space Component也是与平台相关的，但是这部分的移植相对于Middleware来说简单的多，因此，DigTool的可移植性主要体现在它的Middleware上。</p>\n<p>作者的DigTool目前已经可以检测四种漏洞类型（UNPROBE、TOCTTOU、UAF和OOB），如果稍作改进，可能也会比较容易检测双重释放等类型的漏洞，因为作者的这个工具可以检测到任意的内存地址空间。作者在文章中说道，当检测OOB漏洞的时候，作者使用AVL树来保存已经分配的内存区域，如果一片内存区域已经被释放，则它将会从AVL树中被移除，如果再次释放该内存区域，则DigTool会首先在AVL树中查找该内存区域，若找到，则释放（一般不可能）；若没有找到，则表明已经被释放，或者是没有该内存区域，即：可以发现双重释放类型的漏洞。但是，有一个很大的问题限制了这个想法，那就是：作者的DigTool不开源，我们无法获取到他的源代码，因此，我们也就无法在他的这个工具上做二次开发。</p>\n<p>​                                                                                                                                                               <strong><em>转载于GoSSIP</em></strong></p>\n","categories":[{"name":"论文","slug":"论文","permalink":"http://yama0xff.com/categories/论文/"},{"name":"fuzzing","slug":"论文/fuzzing","permalink":"http://yama0xff.com/categories/论文/fuzzing/"}],"tags":[{"name":"fuzzing","slug":"fuzzing","permalink":"http://yama0xff.com/tags/fuzzing/"},{"name":"2017年","slug":"2017年","permalink":"http://yama0xff.com/tags/2017年/"},{"name":"内核","slug":"内核","permalink":"http://yama0xff.com/tags/内核/"},{"name":"USENIX'17","slug":"USENIX-17","permalink":"http://yama0xff.com/tags/USENIX-17/"}]},{"title":"SoK: Security Evaluation of Home-Based IoT Deployments","date":"2019-02-15T02:37:32.000Z","path":"2019/02/15/SoK-Security-Evaluation-of-Home-Based-IoT-Deployments/","text":"Abstract智能家居在安全方面一直表现得不尽人意，究其原因，在于IoT系统相对于传统的嵌入式系统，还引入了智能终端和网络，这就导致了其本身暴露了更多的攻击面。本文通过总结大量论文来帮助研究人员和从业者更好的理解针对智能家居的攻击技术，缓解措施，以及利益相关者应该如何解决这些问题。最后作者利用这些方法评估了45款智能家居设备，并将实验数据公布在https://yourthings.info%E3%80%82 relevant information 作者 Omar Alrawi、Chaz Lever、Manos Antonakakis、Fabian Monrose† 单位 Georgia Institute of Technology 出处 S&amp;P’19 原文地址 https://github.com/wtwofire/database/blob/master/papers/IOT/2019-SoK%EF%BC%9ASecurity%20Evaluation%20of%20Home-Based%20IoT%20Deployments.pdf 源码地址 发表时间 2019年 方法论抽象模型 V: A(apps)、C(cloud)、D(devices) E: communication 安全特性攻击面 Device Vulnerable services Weak authentications Default configurations（出厂设置） Mobile application (Android, iOS) Permissions: over-privileged Programming: 密码学误用 Data protection: API keys, passwords, hard-coded keys Communication (local, Internet) Encryption MITM Cloud Vulnerable services Weak authentications Encryption 缓解措施 patching framework: 重构 利益相关 vendors end-user 其实还可以细分，芯片厂商，物联网平台，经销商，第三方的开发者等，来定义谁来负责解决谁的问题。 分类的方法 Merit: 创新性、有效性 Scope: 集中在讨论安全性（攻击性和防御性） Impact: 影响力 Disruption: 揭示了一个新的领域 威胁模型只考虑Internet protocol network attacker，不考虑low-energy based devices，作者认为攻击所需要的资源在大多数家庭都没有。同时如果能hacking hub devices，就默认exploit了所有的low-energy based devices。（这里就限制了讨论的范围） 相关的研究 Device Attack Vectors 设备上暴露的引脚可以让攻击者轻而易举的获得权限，不安全的配置会加剧漏洞的产生， 而缺少或弱的身份认证是最容易出现的问题，这些都导致设备上的安全问题被频繁曝出。 August Smart Lock，硬编码的密钥、debug接口 cloud-based cameras，强口令但是是mac地址的base64编码 Sonos device，在高端口开了后门服务，并且没有认证 厂商集成第三方库的安全使得其很难保证整体的安全性 Philips Hue device，通过侧信道攻击得到master key，配合协议的漏洞完成蠕虫 Mitigations 要想解决以上问题，就要求vendor通过设备更新来打patch，要求security by design。 Fear and logging in the internet of things SmartAuth，识别IoT应用的权限，这个主要是针对SmartThings和Apple Home FlowFence，把应用分成sensitive和non-sensitive两部分，这部分需要开发者来做。 Stakeholders Vendors有责任patch和update有漏洞的设备，但也要授权给end-user一定的权限，比如可以关闭某些有问题的服务。 SmartAuth提供一种可以导出认证规则的方式，但只能vendor来做。 Sonos device允许用户使用网络隔离的方式来缓解漏洞。 Mobile Application Attack Vectors over-privileges、programming error、hard-coded sensitive information August Smart Lock，作者用敏感信息dump密钥 IoTFuzzer，利用app来对设备做fuzzing，当然也可以利用app做攻击 用app来收集设备的有关信息，然后重新配置路由器的防火墙，使得设备处于公网 Hanguard，app宽松的安全假设导致设备的隐私泄露（App作为设备的入口，厂商往往默认App所处的网络是可信的） Mitigations 基于角色的访问控制 Stakeholders mobile的安全依赖user和vendor，user往往有权限控制的权利，同时user应该遵守从app store上下载app。vendor应该解决programming error并且安全存储数据。 Cloud Endpoint Attack Vectors August Smart Lock，cloud端实现的不安全的API导致越权 cloud没有对固件的更新包签名 web的xss漏洞，username枚举。。 AutoForge，伪造app的请求，实现爆破密码，token劫持等 Mitigations 身份认证 细粒度的访问控制 Stakeholders 由于云平台一般只有厂商管理，所以cloud上的基础设施和API实现的安全应该由他们来负责。 Communicationclasses of protocols Internet protocol low-energy protocol 123ZigbeeZ-Waveluetooth-LE Application layer protocols，DNS、HTTP、UPnP、NTP Attack Vectors EDNS解析 导致信息泄露 用NTP的MITM攻击绕过HSTS UPnP实现时缺少认证，内存破坏漏洞等问题 TLS/SSL， TLS 1.0的IV问题，TLS RC4的问题 BLE、Zigbee、Z-Wave，协议设计本身的问题 LE的重放攻击更容易 Mitigations 对于HTTP，UPnP，DNS和NTP协议，放弃使用不安全的协议，使用最新的协议。 为有实现缺陷的TLS/SSL，升级服务器端和客户端库到最新版本应解决漏洞。 对于基于LE的通信，第一代Zigbee和Z-Wave协议有严重的缺陷，并且缓解方案有限。供应商可以禁用这些协议。 最近也有研究者发现通过监控物联网设备的流量，可以侧信道出一些隐私数据。 Apthorpe 等设计了如何在家中构造流量网络来防止旁道攻击。 Stakeholders 互联网服务提供商（ISP）可以看到基于IP的协议的数据包，但它们不是负任何缓解。 对于ISP来说，他们必须提供其相应的义务（这个我理解是比如说Mira DDoS，ISP虽然不能阻止设备发出去的恶意流量，但是他可以ban掉设备访问C&amp;C域名）。 对于LE协议，供应商可以缓解禁用易受攻击的设备的配对。 评估作者对45款比较流行的不同的设备进行了各方面的评估。这些设备主要包括 appliances cameras home assistants home automation media network devices 实验配置的网络环境，包含一个linux machine用于监听所有的流量和一个路由器（包含Wi-Fi热点）。对流量抓包后分析，对device和cloud使用漏扫分析，对app使用自动化审计工具。这里存在几个难点， 设备自动更新 – 手动关掉 云平台的分类 – 人工识别，排除CDN 无线流量分析 – Wireless to wireless， iOS应用解密 – 砸壳 … MobSF(Mobile Security Framework）、Qark，Kryptowire这些针对app的漏洞扫描器。45个设备有42个有app，其中包含41个Android平台，42个iOS平台。24个Over-privileged。15个包含硬编码的API key。17个使用了硬编码的key和IV。 Nessus Scanner扫描。45个设备4000个域名。这些域名包括 基于云的服务（950）， 第三方的服务。CDN（1287） 混合，使用了AWS，Azure的服务的厂商（630） ，未知（1288）。 Nessus Scanner扫描，分析设备的操作系统，服务，漏洞等。在45个设备中发现了84个服务，39个有issue。这些服务主要是SSH，UPnP，HTTP，DNS，Telnet，RTSP。这些issues包括 错误配置的TLS/SSL, 比如自签名的证书、过期的证书、短的密钥。 UPnp未授权访问。 Nessus Monitor，ntop-ng，Wireshark，sslsplit。用sslsplit做MITM。43个D-C，35个A-C，27个A-D（LAN）。IP 通信包括DNS（41）、HTTP（38）、UPnP（21）和私有的协议（5）。 MITM: D-C(4), A-C(2), A-D(20) Encryption: D-C(40), A-C(24), A-D(7) 缓解措施 Device 通过安全信道更新并确保更新内容的完整性。设备在激活前可以检查配置是否正确并安全。设备应该保证只与验证过身份的设备交互。 Mobile 敏感信息，比如API key应该在安装的时候导出并秘密存起来。密码算法应该尽量使用成熟的第三方库实现。 Cloud 厂商应该尽量使用商业化的云平台。通过API管理endpoint的配置。不应该再支持不安全的协议。 Communication 验证endpoint的身份，防止中间人攻击。保护通信协议的完整性。 ​ 转载于GoSSIP","content":"<h1 id=\"Abstract\"><a href=\"#Abstract\" class=\"headerlink\" title=\"Abstract\"></a>Abstract</h1><p>智能家居在安全方面一直表现得不尽人意，究其原因，在于IoT系统相对于传统的嵌入式系统，还引入了智能终端和网络，这就导致了其本身暴露了更多的攻击面。本文通过总结大量论文来帮助研究人员和从业者更好的理解针对智能家居的攻击技术，缓解措施，以及利益相关者应该如何解决这些问题。最后作者利用这些方法评估了45款智能家居设备，并将实验数据公布在<a href=\"https://yourthings.info./\" target=\"_blank\" rel=\"noopener\">https://yourthings.info%E3%80%82</a></p>\n<table>\n<thead>\n<tr>\n<th>relevant information</th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><em>作者</em></td>\n<td>Omar Alrawi、Chaz Lever、Manos Antonakakis、Fabian Monrose†</td>\n</tr>\n<tr>\n<td><em>单位</em></td>\n<td>Georgia Institute of Technology</td>\n</tr>\n<tr>\n<td><em>出处</em></td>\n<td>S&amp;P’19</td>\n</tr>\n<tr>\n<td><em>原文地址</em></td>\n<td><a href=\"https://github.com/wtwofire/database/blob/master/papers/IOT/2019-SoK%EF%BC%9ASecurity%20Evaluation%20of%20Home-Based%20IoT%20Deployments.pdf\" target=\"_blank\" rel=\"noopener\">https://github.com/wtwofire/database/blob/master/papers/IOT/2019-SoK%EF%BC%9ASecurity%20Evaluation%20of%20Home-Based%20IoT%20Deployments.pdf</a></td>\n</tr>\n<tr>\n<td><em>源码地址</em></td>\n<td></td>\n</tr>\n<tr>\n<td><em>发表时间</em></td>\n<td>2019年</td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"方法论\"><a href=\"#方法论\" class=\"headerlink\" title=\"方法论\"></a>方法论</h1><h2 id=\"抽象模型\"><a href=\"#抽象模型\" class=\"headerlink\" title=\"抽象模型\"></a>抽象模型</h2><p><img src=\"/2019/02/15/SoK-Security-Evaluation-of-Home-Based-IoT-Deployments/1.jpg\" alt=\"\"></p>\n<ul>\n<li>V: A(apps)、C(cloud)、D(devices)</li>\n<li>E: communication</li>\n</ul>\n<h2 id=\"安全特性\"><a href=\"#安全特性\" class=\"headerlink\" title=\"安全特性\"></a>安全特性</h2><h3 id=\"攻击面\"><a href=\"#攻击面\" class=\"headerlink\" title=\"攻击面\"></a>攻击面</h3><ul>\n<li>Device<ul>\n<li>Vulnerable services</li>\n<li>Weak authentications</li>\n<li>Default configurations（出厂设置）</li>\n</ul>\n</li>\n<li>Mobile application (Android, iOS)<ul>\n<li>Permissions: over-privileged</li>\n<li>Programming: 密码学误用</li>\n<li>Data protection: API keys, passwords, hard-coded keys</li>\n</ul>\n</li>\n<li>Communication (local, Internet)<ul>\n<li>Encryption</li>\n<li>MITM</li>\n</ul>\n</li>\n<li>Cloud<ul>\n<li>Vulnerable services</li>\n<li>Weak authentications</li>\n<li>Encryption</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"缓解措施\"><a href=\"#缓解措施\" class=\"headerlink\" title=\"缓解措施\"></a>缓解措施</h3><ul>\n<li>patching</li>\n<li>framework: 重构</li>\n</ul>\n<h3 id=\"利益相关\"><a href=\"#利益相关\" class=\"headerlink\" title=\"利益相关\"></a>利益相关</h3><ul>\n<li>vendors</li>\n<li>end-user</li>\n</ul>\n<p>其实还可以细分，芯片厂商，物联网平台，经销商，第三方的开发者等，来定义谁来负责解决谁的问题。</p>\n<h2 id=\"分类的方法\"><a href=\"#分类的方法\" class=\"headerlink\" title=\"分类的方法\"></a>分类的方法</h2><ul>\n<li>Merit: 创新性、有效性</li>\n<li>Scope: 集中在讨论安全性（攻击性和防御性）</li>\n<li>Impact: 影响力</li>\n<li>Disruption: 揭示了一个新的领域</li>\n</ul>\n<h2 id=\"威胁模型\"><a href=\"#威胁模型\" class=\"headerlink\" title=\"威胁模型\"></a>威胁模型</h2><p>只考虑Internet protocol network attacker，不考虑low-energy based devices，作者认为攻击所需要的资源在大多数家庭都没有。同时如果能hacking hub devices，就默认exploit了所有的low-energy based devices。（这里就限制了讨论的范围）</p>\n<h1 id=\"相关的研究\"><a href=\"#相关的研究\" class=\"headerlink\" title=\"相关的研究\"></a>相关的研究</h1><p><img src=\"/2019/02/15/SoK-Security-Evaluation-of-Home-Based-IoT-Deployments/2.jpg\" alt=\"\"></p>\n<h2 id=\"Device\"><a href=\"#Device\" class=\"headerlink\" title=\"Device\"></a>Device</h2><ol>\n<li>Attack Vectors 设备上暴露的引脚可以让攻击者轻而易举的获得权限，不安全的配置会加剧漏洞的产生， 而缺少或弱的身份认证是最容易出现的问题，这些都导致设备上的安全问题被频繁曝出。<ul>\n<li>August Smart Lock，硬编码的密钥、debug接口</li>\n<li>cloud-based cameras，强口令但是是mac地址的base64编码</li>\n<li>Sonos device，在高端口开了后门服务，并且没有认证</li>\n<li>厂商集成第三方库的安全使得其很难保证整体的安全性</li>\n<li>Philips Hue device，通过侧信道攻击得到master key，配合协议的漏洞完成蠕虫</li>\n</ul>\n</li>\n<li>Mitigations 要想解决以上问题，就要求vendor通过设备更新来打patch，要求security by design。<ul>\n<li>Fear and logging in the internet of things</li>\n<li>SmartAuth，识别IoT应用的权限，这个主要是针对SmartThings和Apple Home</li>\n<li>FlowFence，把应用分成sensitive和non-sensitive两部分，这部分需要开发者来做。</li>\n</ul>\n</li>\n<li>Stakeholders Vendors有责任patch和update有漏洞的设备，但也要授权给end-user一定的权限，比如可以关闭某些有问题的服务。<ul>\n<li>SmartAuth提供一种可以导出认证规则的方式，但只能vendor来做。</li>\n<li>Sonos device允许用户使用网络隔离的方式来缓解漏洞。</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"Mobile-Application\"><a href=\"#Mobile-Application\" class=\"headerlink\" title=\"Mobile Application\"></a>Mobile Application</h2><ol>\n<li>Attack Vectors over-privileges、programming error、hard-coded sensitive information<ul>\n<li>August Smart Lock，作者用敏感信息dump密钥</li>\n<li>IoTFuzzer，利用app来对设备做fuzzing，当然也可以利用app做攻击</li>\n<li>用app来收集设备的有关信息，然后重新配置路由器的防火墙，使得设备处于公网</li>\n<li>Hanguard，app宽松的安全假设导致设备的隐私泄露（App作为设备的入口，厂商往往默认App所处的网络是可信的）</li>\n</ul>\n</li>\n<li>Mitigations<ul>\n<li>基于角色的访问控制</li>\n</ul>\n</li>\n<li>Stakeholders mobile的安全依赖user和vendor，user往往有权限控制的权利，同时user应该遵守从app store上下载app。vendor应该解决programming error并且安全存储数据。</li>\n</ol>\n<h2 id=\"Cloud-Endpoint\"><a href=\"#Cloud-Endpoint\" class=\"headerlink\" title=\"Cloud Endpoint\"></a>Cloud Endpoint</h2><ol>\n<li>Attack Vectors<ul>\n<li>August Smart Lock，cloud端实现的不安全的API导致越权</li>\n<li>cloud没有对固件的更新包签名</li>\n<li>web的xss漏洞，username枚举。。</li>\n<li>AutoForge，伪造app的请求，实现爆破密码，token劫持等</li>\n</ul>\n</li>\n<li>Mitigations<ul>\n<li>身份认证</li>\n<li>细粒度的访问控制</li>\n</ul>\n</li>\n<li>Stakeholders 由于云平台一般只有厂商管理，所以cloud上的基础设施和API实现的安全应该由他们来负责。</li>\n</ol>\n<h2 id=\"Communication\"><a href=\"#Communication\" class=\"headerlink\" title=\"Communication\"></a>Communication</h2><p>classes of protocols <em> Internet protocol </em> low-energy protocol</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Zigbee</span><br><span class=\"line\">Z-Wave</span><br><span class=\"line\">luetooth-LE</span><br></pre></td></tr></table></figure>\n<p>Application layer protocols，DNS、HTTP、UPnP、NTP</p>\n<ol>\n<li><p>Attack Vectors</p>\n<ul>\n<li><p>EDNS解析 导致信息泄露</p>\n</li>\n<li><p>用NTP的MITM攻击绕过HSTS</p>\n</li>\n<li><p>UPnP实现时缺少认证，内存破坏漏洞等问题</p>\n</li>\n<li><p>TLS/SSL， TLS 1.0的IV问题，TLS RC4的问题</p>\n</li>\n<li><p>BLE、Zigbee、Z-Wave，协议设计本身的问题</p>\n</li>\n<li><p>LE的重放攻击更容易</p>\n</li>\n</ul>\n</li>\n<li><p>Mitigations </p>\n<ul>\n<li>对于HTTP，UPnP，DNS和NTP协议，放弃使用不安全的协议，使用最新的协议。</li>\n<li>为有实现缺陷的TLS/SSL，升级服务器端和客户端库到最新版本应解决漏洞。</li>\n<li>对于基于LE的通信，第一代Zigbee和Z-Wave协议有严重的缺陷，并且缓解方案有限。供应商可以禁用这些协议。</li>\n<li>最近也有研究者发现通过监控物联网设备的流量，可以侧信道出一些隐私数据。 Apthorpe 等设计了如何在家中构造流量网络来防止旁道攻击。</li>\n</ul>\n</li>\n<li><p>Stakeholders </p>\n<ul>\n<li>互联网服务提供商（ISP）可以看到基于IP的协议的数据包，但它们不是负任何缓解。 对于ISP来说，他们必须提供其相应的义务（这个我理解是比如说Mira DDoS，ISP虽然不能阻止设备发出去的恶意流量，但是他可以ban掉设备访问C&amp;C域名）。</li>\n<li>对于LE协议，供应商可以缓解禁用易受攻击的设备的配对。</li>\n</ul>\n</li>\n</ol>\n<h1 id=\"评估\"><a href=\"#评估\" class=\"headerlink\" title=\"评估\"></a>评估</h1><p>作者对45款比较流行的不同的设备进行了各方面的评估。这些设备主要包括</p>\n<ul>\n<li>appliances</li>\n<li>cameras</li>\n<li>home assistants</li>\n<li>home automation</li>\n<li>media</li>\n<li>network devices</li>\n</ul>\n<p>实验配置的网络环境，包含一个linux machine用于监听所有的流量和一个路由器（包含Wi-Fi热点）。对流量抓包后分析，对device和cloud使用漏扫分析，对app使用自动化审计工具。这里存在几个难点，</p>\n<ul>\n<li>设备自动更新 – 手动关掉</li>\n<li>云平台的分类 – 人工识别，排除CDN</li>\n<li>无线流量分析 – Wireless to wireless，</li>\n<li>iOS应用解密 – 砸壳</li>\n<li>…</li>\n<li></li>\n</ul>\n<p><img src=\"/2019/02/15/SoK-Security-Evaluation-of-Home-Based-IoT-Deployments/3.png\" alt=\"\"></p>\n<p>MobSF(Mobile Security Framework）、Qark，Kryptowire这些针对app的漏洞扫描器。45个设备有42个有app，其中包含41个Android平台，42个iOS平台。24个Over-privileged。15个包含硬编码的API key。17个使用了硬编码的key和IV。 </p>\n<p><img src=\"/2019/02/15/SoK-Security-Evaluation-of-Home-Based-IoT-Deployments/4.png\" alt=\"\"></p>\n<p>Nessus Scanner扫描。45个设备4000个域名。这些域名包括 基于云的服务（950）， 第三方的服务。CDN（1287） 混合，使用了AWS，Azure的服务的厂商（630） ，未知（1288）。</p>\n<p><img src=\"/2019/02/15/SoK-Security-Evaluation-of-Home-Based-IoT-Deployments/5.png\" alt=\"\"></p>\n<p>Nessus Scanner扫描，分析设备的操作系统，服务，漏洞等。在45个设备中发现了84个服务，39个有issue。这些服务主要是SSH，UPnP，HTTP，DNS，Telnet，RTSP。这些issues包括</p>\n<ul>\n<li>错误配置的TLS/SSL, 比如自签名的证书、过期的证书、短的密钥。</li>\n<li>UPnp未授权访问。</li>\n</ul>\n<p><img src=\"/2019/02/15/SoK-Security-Evaluation-of-Home-Based-IoT-Deployments/6.png\" alt=\"\"></p>\n<p>Nessus Monitor，ntop-ng，Wireshark，sslsplit。用sslsplit做MITM。43个D-C，35个A-C，27个A-D（LAN）。IP 通信包括DNS（41）、HTTP（38）、UPnP（21）和私有的协议（5）。</p>\n<p>MITM: D-C(4), A-C(2), A-D(20) Encryption: D-C(40), A-C(24), A-D(7) </p>\n<p><img src=\"/2019/02/15/SoK-Security-Evaluation-of-Home-Based-IoT-Deployments/7.png\" alt=\"\"></p>\n<p>缓解措施</p>\n<ul>\n<li>Device 通过安全信道更新并确保更新内容的完整性。设备在激活前可以检查配置是否正确并安全。设备应该保证只与验证过身份的设备交互。</li>\n<li>Mobile 敏感信息，比如API key应该在安装的时候导出并秘密存起来。密码算法应该尽量使用成熟的第三方库实现。</li>\n<li>Cloud 厂商应该尽量使用商业化的云平台。通过API管理endpoint的配置。不应该再支持不安全的协议。</li>\n<li>Communication 验证endpoint的身份，防止中间人攻击。保护通信协议的完整性。</li>\n</ul>\n<p>​                                                                                                                                                               <strong><em>转载于GoSSIP</em></strong></p>\n","categories":[{"name":"论文","slug":"论文","permalink":"http://yama0xff.com/categories/论文/"},{"name":"IOT","slug":"论文/IOT","permalink":"http://yama0xff.com/categories/论文/IOT/"}],"tags":[{"name":"综述","slug":"综述","permalink":"http://yama0xff.com/tags/综述/"},{"name":"IOT","slug":"IOT","permalink":"http://yama0xff.com/tags/IOT/"},{"name":"S&P'19","slug":"S-P-19","permalink":"http://yama0xff.com/tags/S-P-19/"},{"name":"2019年","slug":"2019年","permalink":"http://yama0xff.com/tags/2019年/"}]},{"title":"Enforcing Unique Code Target Property for Control-Flow Integrity","date":"2019-02-14T13:01:44.000Z","path":"2019/02/14/Enforcing-Unique-Code-Target-Property-for-Control-Flow-Integrity/","text":"Abstract在这篇文章中，作者主要介绍了一种准确率更高的确保CFI的应用方式：Unique Code Target（UCT）。对于每次间接跳转（ICT），作者们设计了一个叫μUCT的系统来确保这一特性的实施。在编译时，μCFI就识别那些可能影响ICT的指令并让程序去记录一些必要的执行环境；在运行时，μCFI在另一个进程中监视程序的运行，并且在一些关键性的指令上使用内存安全地记录着地运行环境来做一些对点分析，判断这些指令的跳转是否符合预期。作者将μCFI这套系统布置到SPEC benchmark和2个服务器程序（nginx和vsftpd）上测试性能和overhead。同时它们还用它来测试了5个真实世界中的案例、1个COOP的poc进行攻击的案例。μCFI在这些测试上表现得都非常好，展现了100%的检测率和仅不到10%的overhead relevant information 作者 Hong Hu, Chenxiong Qian, Carter Yagemann, Simon Pak Ho Chung, Taesoo Kim and Wenke Lee, William R. Harris 单位 Georgia Institute of Technology, Galois Inc 出处 ACM CCS’18 原文地址 https://github.com/wtwofire/database/blob/master/papers/reverse/2018-Enforcing%20Unique%20Code%20Target%20Property%20for%20Control-Flow%20Integrity.pdf 源码地址 发表时间 2018年 简介CFI的健壮性在于它的跳转规则集合：过于严格的规则可能破坏了程序的正常运行，而松散的规则则让攻击者有了可乘之机。一些针对CFI的攻击也体现了普通的静态分析相比于理想CFI的不同：静态分析只是对于每个ICT给出了所有可能的跳转集合；而理想的CFI应是进一步结合当时的context来判断可能的跳转。近年的CFi开始结合了运行时的context来缩小集合范围，但是在一些情况下返回的集合大小仍然过大：如访问一个数组元素，在不知道index的情况下，返回的集合就是数组中的全部元素了。 在本论文中，作者的应用方式可以做到对于一个ICT只返回唯一确定的跳转可能。结合之前的CFI工作，本论文只讨论控制数据来劫持控制流的攻击手段。 那么如何实现UCT的呢？作者收集了一些必要的运行时信息来对控制的数据进行分析，这些信息被作者命名为constrained data。那么收集这些数据有三个问题需要解决： 如何准确判断constrained data 如何高效地收集这些data 收集到这些数据后，如何高效准确地进行对点分析 μCFI对代码进行静态分析，找到其中的constrained data。分析从函数指针开始，继而迭代地寻找那些在计算这些指针时引用的变量，同时还弄了门arbitrary data collection技术来高效记录运行时的constrained data。与此同时，作者们还对收集到的constrained data进行编码，然后应用Intel的硬件支持Processor Trace（PT）技术来高效记录。μCFI在程序运行时作为一个平行的进程运行，从而来解析记录的constrained data。同时，为了高效的分析，作者还构建了部分执行路径来避免在于安全隐患无关的代码上浪费的时间。** 也就是说，最终设计的系统包括一个编译器和一个执行监视器。监视器在每次ICT指令之后进行CFI检查，并且为了保证安全，监视器会与内核交互来在ICT指令之后立即block被监视的程序。其原型是用来针对jmp和call指令的，ret指令的CFI交给了之前的解决方案shadow stack来解决。 Problem样例代码： 1234567891011121314151617181920typedef void (*FP)(char *);void A(char *);void B(char *);void C(char *);void D(char *);void E(char *);void handleReq(int uid, char * input) &#123; FP arr[3] = &#123;&amp;A, &amp;B, &amp;C&#125;; FP fpt = &amp;D; FP fun = NULL; char buf[20]; if (uid &lt; 0 || uid &gt; 2) return; if (uid == 0) &#123; fun = arr[0]; &#125; else &#123; // uid can be 1, 2 fun = arr[uid]; &#125; strcpy(buf, input); // stack buffer overflow (*fun)(buf); // fun is corrupted&#125; 理想情况下，CFI应该保证在(*fun)(buf)被执行时，uid为零时fun=A，为1时fun=B…而不应该被bof改写掉去执行别的内容。当CFI检查到不一致时，中止程序来避免任何可能的伤害。 当前各种CFI的运行结果如下：其中typeCFI/staticCFI均为静态分析法，πCFI和PITTYPAT均为动态分析法，可见只有µCFI能返回唯一确定的执行流预测。 这里给出了作者对于constrained data 的精确定义：它在IDT的跳转目标中有重要作用，但是其既不是一个直接代表函数地址的控制变量，也不是一个会被解引用出函数指针的一个指针。直到IDT真正发生时，它的值甚至才可能从实际的执行路径当中推断出来。而一旦它的值确定，之后的分析就可以在对任何执行路径上都对IDT给出唯一的推断结果。任何具有如上特性的变量都可以成为constrained data，如示例代码中的uid。 System Design在本系统的设计当中，作者将µCFI拆做两部分：静态编译器和动态监视器。在给出源代码的情况下，编译器首先进行静态分析找到constrained data。之后，其将每个基本块编上唯一ID并与constrained data一起记录。 µCFI的静态编译器产生三个结果：一个是生成的二进制文件，一个是用来对点分析的LLVM IR和LLVM IR基本块到对应唯一ID的一个对应表。 然后在程序的执行过程中，µCFI的监视器依靠内核驱动解析来自PT的记录，解码出对应的基本块ID和相应的constrained data。那么有了基本块的ID，监视器就可以确定每个在被执行的基本块并对每个间接跳转的执行进行点对点的分析了。 同时，由于有了constrained data，µCFI也可以为每个ICT生成唯一确定的跳转目标。那么再和PT记录的跳转比较一下，就可以发现是否被劫持了。 constrained data的判断算法分为两部分： 1. 收集所有和间接跳转目标计算的有关的指令 2. 检查这些指令当中的非常量值，这些值也就成为了constrained data 那么关于收集这些指令又分为直接相关和间接相关的指令：直接相关指指令读/写了函数指针；而间接相关指指令为直接相关的指令准备了相关数据。 作者使用迭代的方式寻找这些指令：算法首先寻找代码中所有的敏感数据类型，这些数据类型包括函数指针和包含函数指针的复合变量类型（这里就有一个迭代） 接下来，算法寻找所有的敏感指令，这些指令要么产生了敏感类型的变量值，要么参与了已被确定的敏感指令计算。 那么最后一步，遍历找到的所有敏感指令，然后遍历这当中涉及到的所有操作数：如果某个操作数既不是敏感数据类型又不是常量，那么它就是一个constrained data 1234567891011121314151617181920212223242526Input: G - program to be protectedOutput: constraining data setTS ← ∅ // sensitive type setrepeat for typ ∈ Types(G): if typ is function-pointer type: TS ← TS ∪ &#123;typ&#125; elif typ is composite type: for sTyp ∈ allTypes(typ): if sTyp ∈ TS: TS ← TS ∪ &#123;typ&#125;until no new sensitive type is foundIS ← ∅ // sensitive instruction setrepeat for instr ∈ Instructions(G): if instr has type ∈ TS: IS ← IS ∪ &#123;instr&#125; elif isLoadInst(instr) or isStoreInst(instr): if value ∈ IS: IS ← IS ∪ &#123;pointer&#125; elif isCallInst(instr): if form-arg ∈ IS: IS ← IS ∪ &#123;act-arg&#125; if act-arg ∈ IS: IS ← IS ∪ &#123;form-arg&#125; ... ...until no new sensitive instruction is foundCS ← ∅ // constraining data setfor instr ∈ IS: for oprnd ∈ Operands(instr): if oprnd &lt; IS and ¬isConstant(oprnd): CS ← CS ∪ &#123;oprnd&#125; 那么经过如上的算法分析后，对之前的样例代码，有如下结果： – sensitive type: – void (char) – [3 x void (char)] – sensitive instruction: – FP arr[3] = {&amp;A, &amp;B, &amp;C}; – FP fpt = &D; – FP fun = NULL; – fun = arr[0]; – fun = arr[uid]; – (*fun)(buf); – constraining data: – uid 对Arbitrary Data的收集作者们设计了一套新方法来高效传递执行当中的信息到监视器的方法，来解决朴素PT缺乏non-control信息的缺陷。 在这一步中，µCFI设置了两个函数：write_data(设置在被保护的程序中，用来生成编码的任意数据并dump到PT trace里)和read_data(设置在监视器中，用来恢复出数据用以分析) 那么write_data(av)到底是如何让PT记录任意数据的呢？对于任意数据av，首先将其拆成几个block，每个block占N bits，然后对于每个block中的值，将其加上一个BASE_ADDR，然后call这个值做一个函数调用，就可以让PT记录下这个值了。BASE_ADDR指向一个设计的特殊函数allRet，其中2N个指令全部是ret(0xC3 for Intel CPU)。作者也考虑了这个函数的安全问题，然后给出了证明其安全的两个方面（corrupt av只会导致记录的值变化，同时调用call后面的值也是一直保存在寄存器而不是内存中） 然后编译器就可以在需要audit的constrained data前插入write_data()这个函数来记录当前data的值，就可以对之后的间接跳转合法性进行检查了。 高效的控制流构建µCFI之后就可以在LLVM的IR层上构建动态分析的控制流。然而这还面临两方面的额挑战： 1. 从高度压缩的PT trace当中重建完整的执行路径解析耗时 2. 实际生成的二进制文件指令由于编译器优化可能和LLVM IR层的执行流有很大区别。 作者们所设计的高效准确的IR层控制流重建基于以下他们观察到的三个现象： 1. 不管如何优化，编译总是保持函数本身的高阶功能，这其中就包括如一些内存访问、函数调用这类side-effecting的指令的执行顺序。那么只要IR层和执行代码有相同的这类指令的顺序，那么对其的分析从功能上而言是一样的。 2. 相同基本块中的执行执行顺序是一样的。因此作者们只需要知道IR基本块层面上的控制流就行了 3. 本论文中设计的对点分析不需要完整的控制流，而仅仅需要敏感指令的执行顺序即可。而这些指令占整个程序中的小部分，也因此对局部的敏感指令的控制流就足够了。 那么这部分的构建流程如下：µCFI编译器首先识别LLVM的IR基本块中含有敏感指令的块并标上BBID，然后在编译过程中在这些块的开头插入write_data(BBID)来让PT能够记录当前执行到了哪个基本块。那么监视器通过编译器编译时输出的ID2BB的map就可以判断出当前在执行哪个IR的基本块了。 然后，作者使用一个变量表PTS来记录每个sensitive data的变化，并且当IDT发生时，将当前存在变量fun中的跳转目标和当前存在PTS中的fun进行比较，如果b不一致就abort 那么对之前的样例代码进行添加后如下： 12345678910111213141516171819void handleReq(int uid,char *input) &#123; write_data(ID1); // BBID ID1 FP arr[3] = &#123;&amp;A,&amp;B,&amp;C&#125;; // s-instr FP fpt = &amp;D; // s-instr FP fun = NULL; // s-instr char buf[20]; if (uid &lt; 0 || uid &gt; 2) return; if (uid == 0) &#123; === TRACE ===&gt;&gt; write_data(ID2); // BBID ID2 fun = arr[0]; // s-instr &#125; else &#123; write_data(ID3); // BBID ID3 write_data(uid); // c-data fun = arr[uid]; // s-instr &#125; write_data(ID4); // BBID ID4 strcpy(buf, input); (*fun)(buf); // s-instr&#125; 相应的，在监视器的内部有如下的处理逻辑： 123456789101112131415161718192021// PTS: global points-to table, initialized with NULLwhile (true) &#123;int BBID = read_data();switch(BBID) &#123; case ID1: PTS[arr[0]] = A; PTS[arr[1]] = B; PTS[arr[2]] = C; PTS[fpt] = D; break; case ID2: PTS[fun] = PTS[arr[0]]; break; case ID3: int uid = read_data(); PTS[fun] = PTS[arr[uid]]; break; case ID4: int real_target = getPTPacket(); if (real_target != PTS[fun]) abort(); else continue;&#125;&#125; 但是如果按上述代码这样进行的话需要承担每次ICT进行检查的过高执行overhead，因此µCFI的监视只是随着执行平行地进行CFI的判断，并且在执行敏感地系统调用的时候才会挂起被监视的进程。作者们选择的敏感系统调用包括: mmap, mremap, remap_file_pages, mprotect, execve, execveat, sendmsg, sendmmsg, sendto, and write。 Implementation编译器构建在LLVM 3.6之上。 LLVM进行constrained data的识别和编码，以及BBID编码。作者将监视器实现为一个root用户进程，这使其适用于保护非root进程。 它使用两个线程，一个用于PT跟踪解析，另一个用于点分析和CFI验证。作者使用来自Griffin的PT驱动程序的修改版本进行跟踪管理，其中作者将跟踪写入每个线程的伪代码文件，并为作者的用户空间μCFI监视器设置适当的权限以读取它。 接下来，作者将介绍μCFI系统的几个实现细节，包括减少PT的trace量，与shadow stack整合以及针对lazy type的分析。 减少tracePT允许对trace的函数进行定制，因此作者利用编译器将所有的间接调用转化为了对一个特定函数iCall的直接调用，通过传参进去再跳转来实现间接跳转功能；同理还对所有需要调查的ret指令替换为oneRet函数，其中填充ret指令。那么这样做就可以将PT的trace限定在这两个函数中，从而减少了对特定程序进行trace所需要cover的代码量 整合Shadow StackShadow Stack技术可以在栈上保存当前函数返回地址处的一个固定（或随机）偏移处保存一个返回地址的副本（也就是在栈上保存了两个返回地址值），然后在返回时比较二者是否仍然一致并且（或）将副本的值复制到该函数的返回地址保存处。 那么µCFI就将其整合进自己的系统中，在原有的基础上对LLVM X86的后端和ELF构建函数进行了修改。对后端的修改使得在编译时能在函数开头和末尾添加两条汇编指令，用来保存和恢复返回地址值； 而对构建函数的修改使得在binary loader调用该执行文件时先执行构建函数(ELF constructor functions)，进行shadow stack和两个栈之间的保护页的构建后再将控制权交给原来的程序 Lazy-type的分析技术为了构建变量表PTS，通常需要对复合类型进行扁平化，即将其中的复合类型迭代的代入直至其中不再包含复合类型。但是由于LLVM IR的高度优化特性，这一方法需要的对对象分配的准确定义信息可能不是很容易获得。那么作者在尽可能获得的基础上，设计了Lazy-type：在运行时对对象进行分配的时候，首先置其所含的变量类型为空，那么当这个对象被一个指针所引用时，作者就可以根据其偏移来确定成员的类型了 Evaluation环境设置 64-bit Ubuntu 16.04 system 8-core Intel i7-7740X CPU (4.30GHz frequency) 32 GB RAM 作者分两步编译每个程序。 首先使用wllvm 生成base binary和LLVM IR表示。其次，作者使用μCFI编译器来检测IR并生成受保护的可执行文件。两种编译都采用默认的优化级别和选项，例如，针对SPEC的O2和针对nginx和vsftpd的O1。 作者使用提供的训练数据集来评估SPEC基准。 对于nginx和vsftpd，作者在评估环境中设置服务器，并从同一本地网络中的另一台机器请求不同大小的文件。 作者执行每个文件1000次，以避免意外偏差。 为了测量开销，作者将监视器与受保护的执行文件一起启动，并计算所有进程退出的时间，包括受保护的执行文件，监视器及其子进程。 表3和表4总结了作者的评估结果。 μCFI成功地为测试程序实现了UCT属性，因为它只允许一个有效目标用于所有间接控制流传输（Q1）。 μCFI平均为评估的SPEC基准测试引入7.88％的运行时开销，nginx的运行时开销为4.05％，vsftpd（Q2）的开销不到1％。 这意味着μCFI可以通过强大的安全保障有效地保护这些程序。 所有攻击，包括现实中的攻击，COOP概念证明攻击和synthesized攻击，都会在运行时被阻止（Q3）。 使用μCFI和shadow stack编译的程序运行良好。 组合保护为SPEC基准测试带来了额外的2.07％开销，对nginx和vsftpd（Q4）的额外开销可忽略不计。 Enforcing UCT Property在table 3 中可以看到，µCFI对于SPEC中的所有对象中的ICT均只给出了唯一确定的跳转对象(Allowed Target)，而这应归功于constrained data的作用 Preventing Attack作者还应用μCFI来保护PittyPat [21]中引入的易受COOP攻击的程序[55]。 COOP是一种通过构造C++的对象来利用其虚函数表的图灵完备攻击方法，COOP对粗粒度CFI构成了巨大挑战。 μCFI通过保护所有constrained data来防止COOP攻击，从而允许它准确地跟踪内存中的函数指针。当程序被输入恶意输入时，μCFI成功区分合法和伪造对象以检测攻击。 Overhead MeasurementPerformance Overhead Optimization Possibility PT的PTWrite指令可以直接打印用户数据到PT的TIP包中，μCFI可以利用其来记录BBID和constrained data，进一步提升效率。 Memory Overhead Code Overhead Shadow Stack Integration作者测量μCFI与parallel shadow stack（PSS）保护的兼容性。 作者使用μCFI编译器和PSS编译每个程序，并测量执行的正确性和性能开销。 所有测试程序（包括SPEC基准测试，nginx和vsftpd）都可以很好地与良性输入一起使用，证明了μCFI的强大兼容性。 集成PSS的开销显示在表3中的+stack列中。平均而言，PSS引入2.07％的开销来评估SPEC基准测试，且在对nginx和vsftpd的开销中可忽略不计。 通过展示μCFI与影子堆栈的兼容性，作者澄清了具有各种安全保证的任何替代解决方案如基于随机化的SafeStack [36]和基于硬件的Intel CET技术[33]，可以与μCFI集成以提供未来继续实现更好UCT属性的两个方向。 Discussion在关于未来的工作中，作者提到两点： 1. 验证signal或exception中的CFI，这些与OS有关，在Intel PT中以FUP包形式记载 2. 验证动态加载的代码中的CFI","content":"<h1 id=\"Abstract\"><a href=\"#Abstract\" class=\"headerlink\" title=\"Abstract\"></a>Abstract</h1><p>在这篇文章中，作者主要介绍了一种准确率更高的确保CFI的应用方式：Unique Code Target（UCT）。对于每次间接跳转（ICT），作者们设计了一个叫μUCT的系统来确保这一特性的实施。在编译时，μCFI就识别那些可能影响ICT的指令并让程序去记录一些必要的执行环境；在运行时，μCFI在另一个进程中监视程序的运行，并且在一些关键性的指令上使用内存安全地记录着地运行环境来做一些对点分析，判断这些指令的跳转是否符合预期。作者将μCFI这套系统布置到SPEC benchmark和2个服务器程序（nginx和vsftpd）上测试性能和overhead。同时它们还用它来测试了5个真实世界中的案例、1个<a href=\"https://csdl.computer.org/csdl/proceedings/sp/2015/6949/00/6949a745.pdf\" target=\"_blank\" rel=\"noopener\">COOP</a>的poc进行攻击的案例。μCFI在这些测试上表现得都非常好，展现了100%的检测率和仅不到10%的overhead</p>\n<table>\n<thead>\n<tr>\n<th>relevant information</th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><em>作者</em></td>\n<td>Hong Hu, Chenxiong Qian, Carter Yagemann, Simon Pak Ho Chung, Taesoo Kim and Wenke Lee, William R. Harris</td>\n</tr>\n<tr>\n<td><em>单位</em></td>\n<td>Georgia Institute of Technology, Galois Inc</td>\n</tr>\n<tr>\n<td><em>出处</em></td>\n<td>ACM CCS’18</td>\n</tr>\n<tr>\n<td><em>原文地址</em></td>\n<td><a href=\"https://github.com/wtwofire/database/blob/master/papers/reverse/2018-Enforcing%20Unique%20Code%20Target%20Property%20for%20Control-Flow%20Integrity.pdf\" target=\"_blank\" rel=\"noopener\">https://github.com/wtwofire/database/blob/master/papers/reverse/2018-Enforcing%20Unique%20Code%20Target%20Property%20for%20Control-Flow%20Integrity.pdf</a></td>\n</tr>\n<tr>\n<td><em>源码地址</em></td>\n<td></td>\n</tr>\n<tr>\n<td><em>发表时间</em></td>\n<td>2018年</td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h1><p>CFI的健壮性在于它的跳转规则集合：过于严格的规则可能破坏了程序的正常运行，而松散的规则则让攻击者有了可乘之机。一些针对CFI的攻击也体现了普通的静态分析相比于理想CFI的不同：静态分析只是对于每个ICT给出了所有可能的跳转集合；而理想的CFI应是进一步结合当时的context来判断可能的跳转。近年的CFi开始结合了运行时的context来缩小集合范围，但是在一些情况下返回的集合大小仍然过大：如访问一个数组元素，在不知道index的情况下，返回的集合就是数组中的全部元素了。</p>\n<p>在本论文中，作者的应用方式可以做到对于一个ICT<strong>只返回唯一确定的跳转可能</strong>。结合之前的CFI工作，本论文只讨论控制数据来劫持控制流的攻击手段。</p>\n<p>那么如何实现UCT的呢？作者收集了一些<strong>必要的运行时信息</strong>来对控制的数据进行分析，这些信息被作者命名为<strong>constrained data</strong>。那么收集这些数据有三个问题需要解决： </p>\n<ol>\n<li>如何准确判断constrained data </li>\n<li>如何高效地收集这些data </li>\n<li>收集到这些数据后，如何高效准确地进行对点分析</li>\n</ol>\n<p>μCFI对代码进行静态分析，找到其中的constrained data。<strong>分析从函数指针开始，继而迭代地寻找那些在计算这些指针时引用的变量，同时还弄了门arbitrary data collection技术来高效记录运行时的constrained data。与此同时，作者们还对收集到的constrained data进行编码，然后应用Intel的硬件支持Processor Trace（<a href=\"https://software.intel.com/en-us/blogs/2013/09/18/processor-tracing\" target=\"_blank\" rel=\"noopener\">PT</a>）技术来高效记录。μCFI在程序运行时作为一个平行的进程运行，从而来解析记录的constrained data。同时，为了高效的分析，作者还构建了部分执行路径来避免在于安全隐患无关的代码上浪费的时间。**</strong></p>\n<p>也就是说，最终设计的系统包括<strong>一个编译器</strong>和<strong>一个执行监视器</strong>。监视器在每次ICT指令之后进行CFI检查，并且为了保证安全，监视器会与内核交互来在ICT指令之后立即block被监视的程序。其原型是用来针对jmp和call指令的，ret指令的CFI交给了之前的解决方案shadow stack来解决。</p>\n<h1 id=\"Problem\"><a href=\"#Problem\" class=\"headerlink\" title=\"Problem\"></a>Problem</h1><p>样例代码：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">typedef</span> <span class=\"title\">void</span> <span class=\"params\">(*FP)</span><span class=\"params\">(<span class=\"keyword\">char</span> *)</span></span>;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">A</span><span class=\"params\">(<span class=\"keyword\">char</span> *)</span></span>;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">B</span><span class=\"params\">(<span class=\"keyword\">char</span> *)</span></span>;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">C</span><span class=\"params\">(<span class=\"keyword\">char</span> *)</span></span>;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">D</span><span class=\"params\">(<span class=\"keyword\">char</span> *)</span></span>;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">E</span><span class=\"params\">(<span class=\"keyword\">char</span> *)</span></span>;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">handleReq</span><span class=\"params\">(<span class=\"keyword\">int</span> uid, <span class=\"keyword\">char</span> * input)</span> </span>&#123;</span><br><span class=\"line\">  FP arr[<span class=\"number\">3</span>] = &#123;&amp;A, &amp;B, &amp;C&#125;;</span><br><span class=\"line\">  FP fpt = &amp;D;</span><br><span class=\"line\">  FP fun = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">  <span class=\"keyword\">char</span> buf[<span class=\"number\">20</span>];</span><br><span class=\"line\">  <span class=\"keyword\">if</span> (uid &lt; <span class=\"number\">0</span> || uid &gt; <span class=\"number\">2</span>) <span class=\"keyword\">return</span>;</span><br><span class=\"line\">  <span class=\"keyword\">if</span> (uid == <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">      fun = arr[<span class=\"number\">0</span>];</span><br><span class=\"line\">  &#125; <span class=\"keyword\">else</span> &#123; <span class=\"comment\">// uid can be 1, 2</span></span><br><span class=\"line\">      fun = arr[uid];</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  <span class=\"built_in\">strcpy</span>(buf, input); <span class=\"comment\">// stack buffer overflow</span></span><br><span class=\"line\">  (*fun)(buf); <span class=\"comment\">// fun is corrupted</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>理想情况下，CFI应该保证在<code>(*fun)(buf)</code>被执行时，uid为零时fun=A，为1时fun=B…而不应该被bof改写掉去执行别的内容。当CFI检查到不一致时，中止程序来避免任何可能的伤害。</p>\n<p>当前各种CFI的运行结果如下：其中typeCFI/staticCFI均为静态分析法，πCFI和PITTYPAT均为动态分析法，可见只有µCFI能返回唯一确定的执行流预测。</p>\n<p><img src=\"/2019/02/14/Enforcing-Unique-Code-Target-Property-for-Control-Flow-Integrity/All target sets.png\" alt=\"\"></p>\n<p>这里给出了作者对于constrained data 的精确定义：<strong><em>它在IDT的跳转目标中有重要作用，但是其既不是一个直接代表函数地址的控制变量，也不是一个会被解引用出函数指针的一个指针。直到IDT真正发生时，它的值甚至才可能从实际的执行路径当中推断出来。而一旦它的值确定，之后的分析就可以在对任何执行路径上都对IDT给出唯一的推断结果。</em></strong>任何具有如上特性的变量都可以成为constrained data，如示例代码中的uid。</p>\n<h1 id=\"System-Design\"><a href=\"#System-Design\" class=\"headerlink\" title=\"System Design\"></a>System Design</h1><p>在本系统的设计当中，作者将µCFI拆做两部分：静态编译器和动态监视器。在给出源代码的情况下，编译器首先进行静态分析找到constrained data。之后，其将每个基本块编上唯一ID并与constrained data一起记录。</p>\n<p>µCFI的静态编译器产生三个结果：<strong>一个是生成的二进制文件，一个是用来对点分析的LLVM IR和LLVM IR基本块到对应唯一ID的一个对应表</strong>。 然后在程序的执行过程中，µCFI的监视器依靠内核驱动解析来自PT的记录，解码出对应的基本块ID和相应的constrained data。那么有了基本块的ID，监视器就可以确定每个在被执行的基本块并对每个间接跳转的执行进行点对点的分析了。 同时，由于有了constrained data，µCFI也可以为每个ICT生成唯一确定的跳转目标。那么再和PT记录的跳转比较一下，就可以发现是否被劫持了。</p>\n<p><img src=\"/2019/02/14/Enforcing-Unique-Code-Target-Property-for-Control-Flow-Integrity/μCFI overview.png\" alt=\"\"></p>\n<h2 id=\"constrained-data的判断\"><a href=\"#constrained-data的判断\" class=\"headerlink\" title=\"constrained data的判断\"></a>constrained data的判断</h2><p>算法分为两部分： <strong>1. 收集所有和间接跳转目标计算的有关的指令 2. 检查这些指令当中的非常量值，这些值也就成为了constrained data </strong></p>\n<p>那么关于收集这些指令又分为直接相关和间接相关的指令：<strong>直接相关指指令读/写了函数指针；而间接相关指指令为直接相关的指令准备了相关数据。</strong></p>\n<p>作者使用迭代的方式寻找这些指令：算法首先寻找代码中所有的敏感数据类型，这些数据类型包括函数指针和包含函数指针的复合变量类型（这里就有一个迭代）</p>\n<p>接下来，算法寻找所有的敏感指令，这些指令要么产生了敏感类型的变量值，要么参与了已被确定的敏感指令计算。</p>\n<p>那么最后一步，遍历找到的所有敏感指令，然后遍历这当中涉及到的所有操作数：如果某个操作数既不是敏感数据类型又不是常量，那么它就是一个constrained data</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Input: G - program to be <span class=\"keyword\">protected</span></span><br><span class=\"line\">Output: constraining data <span class=\"built_in\">set</span></span><br><span class=\"line\">TS ← ∅                                           <span class=\"comment\">// sensitive type set</span></span><br><span class=\"line\">repeat</span><br><span class=\"line\">  <span class=\"keyword\">for</span> typ ∈ Types(G):</span><br><span class=\"line\">      <span class=\"keyword\">if</span> typ is function-pointer type: TS ← TS ∪ &#123;typ&#125;</span><br><span class=\"line\">      elif typ is composite type:</span><br><span class=\"line\">          <span class=\"keyword\">for</span> sTyp ∈ allTypes(typ):</span><br><span class=\"line\">              <span class=\"keyword\">if</span> sTyp ∈ TS: TS ← TS ∪ &#123;typ&#125;</span><br><span class=\"line\">until no <span class=\"keyword\">new</span> sensitive type is found</span><br><span class=\"line\">IS ← ∅                                           <span class=\"comment\">// sensitive instruction set</span></span><br><span class=\"line\">repeat</span><br><span class=\"line\">  <span class=\"keyword\">for</span> instr ∈ Instructions(G):</span><br><span class=\"line\">      <span class=\"keyword\">if</span> instr has type ∈ TS: IS ← IS ∪ &#123;instr&#125;</span><br><span class=\"line\">      elif isLoadInst(instr) <span class=\"keyword\">or</span> isStoreInst(instr):</span><br><span class=\"line\">          <span class=\"keyword\">if</span> value ∈ IS: IS ← IS ∪ &#123;pointer&#125;</span><br><span class=\"line\">      elif isCallInst(instr):</span><br><span class=\"line\">          <span class=\"keyword\">if</span> form-arg ∈ IS: IS ← IS ∪ &#123;act-arg&#125;</span><br><span class=\"line\">          <span class=\"keyword\">if</span> act-arg ∈ IS: IS ← IS ∪ &#123;form-arg&#125;</span><br><span class=\"line\">      ... ...</span><br><span class=\"line\">until no <span class=\"keyword\">new</span> sensitive instruction is found</span><br><span class=\"line\">CS ← ∅                                           <span class=\"comment\">// constraining data set</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> instr ∈ IS:</span><br><span class=\"line\">  <span class=\"keyword\">for</span> oprnd ∈ Operands(instr):</span><br><span class=\"line\">      <span class=\"keyword\">if</span> oprnd &lt; IS <span class=\"keyword\">and</span> ¬isConstant(oprnd):</span><br><span class=\"line\">          CS ← CS ∪ &#123;oprnd&#125;</span><br></pre></td></tr></table></figure>\n<p>那么经过如上的算法分析后，对之前的样例代码，有如下结果： – sensitive type: – void (char<em>)</em> – [3 x void (char<em>)</em>] – sensitive instruction: – FP arr[3] = {&amp;A, &amp;B, &amp;C}; – FP fpt = &D; – FP fun = NULL; – fun = arr[0]; – fun = arr[uid]; – (*fun)(buf); – constraining data: – uid</p>\n<h2 id=\"对Arbitrary-Data的收集\"><a href=\"#对Arbitrary-Data的收集\" class=\"headerlink\" title=\"对Arbitrary Data的收集\"></a>对Arbitrary Data的收集</h2><p>作者们设计了一套新方法来高效传递执行当中的信息到监视器的方法，来解决朴素PT缺乏non-control信息的缺陷。</p>\n<p>在这一步中，µCFI设置了两个函数：write_data(设置在被保护的程序中，用来生成编码的任意数据并dump到PT trace里)和read_data(设置在监视器中，用来恢复出数据用以分析)</p>\n<p>那么write_data(av)到底是如何让PT记录任意数据的呢？对于任意数据av，首先将其拆成几个block，每个block占N bits，然后对于每个block中的值，将其加上一个BASE_ADDR，然后call这个值做一个函数调用，就可以让PT记录下这个值了。BASE_ADDR指向一个设计的特殊函数allRet，其中2N个指令全部是ret(0xC3 for Intel CPU)。作者也考虑了这个函数的安全问题，然后给出了证明其安全的两个方面（corrupt av只会导致记录的值变化，同时调用call后面的值也是一直保存在寄存器而不是内存中）</p>\n<p>然后编译器就可以在需要audit的constrained data前插入write_data()这个函数来记录当前data的值，就可以对之后的间接跳转合法性进行检查了。</p>\n<h2 id=\"高效的控制流构建\"><a href=\"#高效的控制流构建\" class=\"headerlink\" title=\"高效的控制流构建\"></a>高效的控制流构建</h2><p>µCFI之后就可以在LLVM的IR层上构建动态分析的控制流。然而这还面临两方面的额挑战： 1. 从高度压缩的PT trace当中重建完整的执行路径解析耗时 2. 实际生成的二进制文件指令由于编译器优化可能和LLVM IR层的执行流有很大区别。</p>\n<p>作者们所设计的高效准确的IR层控制流重建基于以下他们观察到的三个现象： 1. 不管如何优化，编译总是保持函数本身的高阶功能，这其中就包括如一些内存访问、函数调用这类side-effecting的指令的执行顺序。那么只要IR层和执行代码有相同的这类指令的顺序，那么对其的分析从功能上而言是一样的。 2. 相同基本块中的执行执行顺序是一样的。因此作者们只需要知道IR基本块层面上的控制流就行了 3. 本论文中设计的对点分析不需要完整的控制流，而仅仅需要敏感指令的执行顺序即可。而这些指令占整个程序中的小部分，也因此对局部的敏感指令的控制流就足够了。</p>\n<p>那么这部分的构建流程如下：µCFI编译器首先识别LLVM的IR基本块中含有敏感指令的块并标上BBID，然后在编译过程中在这些块的开头插入write_data(BBID)来让PT能够记录当前执行到了哪个基本块。那么监视器通过编译器编译时输出的ID2BB的map就可以判断出当前在执行哪个IR的基本块了。</p>\n<p>然后，作者使用一个变量表PTS来记录每个sensitive data的变化，并且当IDT发生时，将当前存在变量fun中的跳转目标和当前存在PTS中的fun进行比较，如果b不一致就abort</p>\n<p>那么对之前的样例代码进行添加后如下：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">handleReq</span><span class=\"params\">(<span class=\"keyword\">int</span> uid,<span class=\"keyword\">char</span> *input)</span> </span>&#123;</span><br><span class=\"line\">  write_data(ID1); <span class=\"comment\">// BBID ID1</span></span><br><span class=\"line\">  FP arr[<span class=\"number\">3</span>] = &#123;&amp;A,&amp;B,&amp;C&#125;; <span class=\"comment\">// s-instr</span></span><br><span class=\"line\">  FP fpt = &amp;D; <span class=\"comment\">// s-instr</span></span><br><span class=\"line\">  FP fun = <span class=\"literal\">NULL</span>; <span class=\"comment\">// s-instr</span></span><br><span class=\"line\">  <span class=\"keyword\">char</span> buf[<span class=\"number\">20</span>];</span><br><span class=\"line\">  <span class=\"keyword\">if</span> (uid &lt; <span class=\"number\">0</span> || uid &gt; <span class=\"number\">2</span>) <span class=\"keyword\">return</span>;</span><br><span class=\"line\">  <span class=\"keyword\">if</span> (uid == <span class=\"number\">0</span>) &#123; === TRACE ===&gt;&gt;</span><br><span class=\"line\">      write_data(ID2); <span class=\"comment\">// BBID ID2</span></span><br><span class=\"line\">      fun = arr[<span class=\"number\">0</span>]; <span class=\"comment\">// s-instr</span></span><br><span class=\"line\">  &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">      write_data(ID3); <span class=\"comment\">// BBID ID3</span></span><br><span class=\"line\">      write_data(uid); <span class=\"comment\">// c-data</span></span><br><span class=\"line\">      fun = arr[uid]; <span class=\"comment\">// s-instr</span></span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  write_data(ID4); <span class=\"comment\">// BBID ID4</span></span><br><span class=\"line\">  <span class=\"built_in\">strcpy</span>(buf, input);</span><br><span class=\"line\">  (*fun)(buf); <span class=\"comment\">// s-instr</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>相应的，在监视器的内部有如下的处理逻辑：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// PTS: global points-to table, initialized with NULL</span></span><br><span class=\"line\"><span class=\"keyword\">while</span> (<span class=\"literal\">true</span>) &#123;</span><br><span class=\"line\"><span class=\"keyword\">int</span> BBID = read_data();</span><br><span class=\"line\"><span class=\"keyword\">switch</span>(BBID) &#123;</span><br><span class=\"line\">  <span class=\"keyword\">case</span> ID1:</span><br><span class=\"line\">      PTS[arr[<span class=\"number\">0</span>]] = A; PTS[arr[<span class=\"number\">1</span>]] = B;</span><br><span class=\"line\">      PTS[arr[<span class=\"number\">2</span>]] = C; PTS[fpt] = D;</span><br><span class=\"line\">      <span class=\"keyword\">break</span>;</span><br><span class=\"line\">  <span class=\"keyword\">case</span> ID2:</span><br><span class=\"line\">      PTS[fun] = PTS[arr[<span class=\"number\">0</span>]];</span><br><span class=\"line\">      <span class=\"keyword\">break</span>;</span><br><span class=\"line\">  <span class=\"keyword\">case</span> ID3:</span><br><span class=\"line\">      <span class=\"keyword\">int</span> uid = read_data();</span><br><span class=\"line\">      PTS[fun] = PTS[arr[uid]];</span><br><span class=\"line\">      <span class=\"keyword\">break</span>;</span><br><span class=\"line\">  <span class=\"keyword\">case</span> ID4:</span><br><span class=\"line\">      <span class=\"keyword\">int</span> real_target = getPTPacket();</span><br><span class=\"line\">      <span class=\"keyword\">if</span> (real_target != PTS[fun])</span><br><span class=\"line\">          <span class=\"built_in\">abort</span>();</span><br><span class=\"line\">          <span class=\"keyword\">else</span> <span class=\"keyword\">continue</span>;</span><br><span class=\"line\">&#125;&#125;</span><br></pre></td></tr></table></figure>\n<p>但是如果按上述代码这样进行的话需要承担每次ICT进行检查的过高执行overhead，因此µCFI的监视只是随着执行平行地进行CFI的判断，并且在执行敏感地系统调用的时候才会挂起被监视的进程。作者们选择的敏感系统调用包括: <strong>mmap, mremap, remap_file_pages, mprotect, execve, execveat, sendmsg, sendmmsg, sendto, and write。</strong></p>\n<h1 id=\"Implementation\"><a href=\"#Implementation\" class=\"headerlink\" title=\"Implementation\"></a>Implementation</h1><p>编译器构建在LLVM 3.6之上。 LLVM进行constrained data的识别和编码，以及BBID编码。作者将监视器实现为一个root用户进程，这使其适用于保护非root进程。 它使用两个线程，一个用于PT跟踪解析，另一个用于点分析和CFI验证。作者使用来自<a href=\"https://github.com/TJAndHisStudents/Griffin-Trace\" target=\"_blank\" rel=\"noopener\">Griffin</a>的PT驱动程序的修改版本进行跟踪管理，其中作者将跟踪写入每个线程的伪代码文件，并为作者的用户空间μCFI监视器设置适当的权限以读取它。</p>\n<p>接下来，作者将介绍μCFI系统的几个实现细节，包括减少PT的trace量，与shadow stack整合以及针对lazy type的分析。</p>\n<h2 id=\"减少trace\"><a href=\"#减少trace\" class=\"headerlink\" title=\"减少trace\"></a>减少trace</h2><p>PT允许对trace的函数进行定制，因此作者利用编译器将所有的间接调用转化为了对一个特定函数iCall的直接调用，通过传参进去再跳转来实现间接跳转功能；同理还对所有需要调查的ret指令替换为oneRet函数，其中填充ret指令。那么这样做就可以将PT的trace限定在这两个函数中，从而减少了对特定程序进行trace所需要cover的代码量</p>\n<h2 id=\"整合Shadow-Stack\"><a href=\"#整合Shadow-Stack\" class=\"headerlink\" title=\"整合Shadow Stack\"></a>整合Shadow Stack</h2><p>Shadow Stack技术可以在栈上保存当前函数返回地址处的一个固定（或随机）偏移处保存一个返回地址的副本（也就是在栈上保存了两个返回地址值），然后在返回时比较二者是否仍然一致并且（或）将副本的值复制到该函数的返回地址保存处。</p>\n<p>那么µCFI就将其整合进自己的系统中，在原有的基础上对LLVM X86的后端和ELF构建函数进行了修改。对后端的修改使得在编译时能在函数开头和末尾添加两条汇编指令，用来保存和恢复返回地址值； 而对构建函数的修改使得在binary loader调用该执行文件时先执行构建函数(ELF constructor functions)，进行shadow stack和两个栈之间的保护页的构建后再将控制权交给原来的程序</p>\n<h2 id=\"Lazy-type的分析技术\"><a href=\"#Lazy-type的分析技术\" class=\"headerlink\" title=\"Lazy-type的分析技术\"></a>Lazy-type的分析技术</h2><p>为了构建变量表PTS，通常需要对复合类型进行扁平化，即将其中的复合类型迭代的代入直至其中不再包含复合类型。但是由于LLVM IR的高度优化特性，这一方法需要的对对象分配的准确定义信息可能不是很容易获得。那么作者在尽可能获得的基础上，设计了Lazy-type：在运行时对对象进行分配的时候，首先置其所含的变量类型为空，那么当这个对象被一个指针所引用时，作者就可以根据其偏移来确定成员的类型了</p>\n<h1 id=\"Evaluation\"><a href=\"#Evaluation\" class=\"headerlink\" title=\"Evaluation\"></a>Evaluation</h1><p>环境设置 64-bit Ubuntu 16.04 system 8-core Intel i7-7740X CPU (4.30GHz frequency) 32 GB RAM 作者分两步编译每个程序。 首先使用<a href=\"https://github.com/travitch/%20whole-program-llvm.\" target=\"_blank\" rel=\"noopener\">wllvm</a> 生成base binary和LLVM IR表示。其次，作者使用μCFI编译器来检测IR并生成受保护的可执行文件。两种编译都采用默认的优化级别和选项，例如，针对SPEC的O2和针对nginx和vsftpd的O1。 作者使用提供的训练数据集来评估SPEC基准。 对于nginx和vsftpd，作者在评估环境中设置服务器，并从同一本地网络中的另一台机器请求不同大小的文件。 作者执行每个文件1000次，以避免意外偏差。 为了测量开销，作者将监视器与受保护的执行文件一起启动，并计算所有进程退出的时间，包括受保护的执行文件，监视器及其子进程。 </p>\n<p><img src=\"/2019/02/14/Enforcing-Unique-Code-Target-Property-for-Control-Flow-Integrity/evaluation_result.png\" alt=\"\"></p>\n<p><img src=\"/2019/02/14/Enforcing-Unique-Code-Target-Property-for-Control-Flow-Integrity/realworld_exploits_prevention.png\" alt=\"\"></p>\n<p>表3和表4总结了作者的评估结果。 μCFI成功地为测试程序实现了UCT属性，因为它只允许一个有效目标用于所有间接控制流传输（Q1）。 μCFI平均为评估的SPEC基准测试引入7.88％的运行时开销，nginx的运行时开销为4.05％，vsftpd（Q2）的开销不到1％。 这意味着μCFI可以通过强大的安全保障有效地保护这些程序。 所有攻击，包括现实中的攻击，COOP概念证明攻击和synthesized攻击，都会在运行时被阻止（Q3）。 使用μCFI和shadow stack编译的程序运行良好。 组合保护为SPEC基准测试带来了额外的2.07％开销，对nginx和vsftpd（Q4）的额外开销可忽略不计。</p>\n<h2 id=\"Enforcing-UCT-Property\"><a href=\"#Enforcing-UCT-Property\" class=\"headerlink\" title=\"Enforcing UCT Property\"></a>Enforcing UCT Property</h2><p>在table 3 中可以看到，µCFI对于SPEC中的所有对象中的ICT均只给出了唯一确定的跳转对象(Allowed Target)，而这应归功于constrained data的作用</p>\n<h2 id=\"Preventing-Attack\"><a href=\"#Preventing-Attack\" class=\"headerlink\" title=\"Preventing Attack\"></a>Preventing Attack</h2><p>作者还应用μCFI来保护PittyPat [21]中引入的易受COOP攻击的程序[55]。 COOP是一种通过构造C++的对象来利用其虚函数表的图灵完备攻击方法，COOP对粗粒度CFI构成了巨大挑战。 μCFI通过保护所有constrained data来防止COOP攻击，从而允许它准确地跟踪内存中的函数指针。当程序被输入恶意输入时，μCFI成功区分合法和伪造对象以检测攻击。</p>\n<h2 id=\"Overhead-Measurement\"><a href=\"#Overhead-Measurement\" class=\"headerlink\" title=\"Overhead Measurement\"></a>Overhead Measurement</h2><p>Performance Overhead Optimization Possibility  PT的PTWrite指令可以直接打印用户数据到PT的TIP包中，μCFI可以利用其来记录BBID和constrained data，进一步提升效率。 Memory Overhead Code Overhead</p>\n<h2 id=\"Shadow-Stack-Integration\"><a href=\"#Shadow-Stack-Integration\" class=\"headerlink\" title=\"Shadow Stack Integration\"></a>Shadow Stack Integration</h2><p>作者测量μCFI与parallel shadow stack（PSS）保护的兼容性。 作者使用μCFI编译器和PSS编译每个程序，并测量执行的正确性和性能开销。 所有测试程序（包括SPEC基准测试，nginx和vsftpd）都可以很好地与良性输入一起使用，证明了μCFI的强大兼容性。 集成PSS的开销显示在表3中的+stack列中。平均而言，PSS引入2.07％的开销来评估SPEC基准测试，且在对nginx和vsftpd的开销中可忽略不计。 通过展示μCFI与影子堆栈的兼容性，作者澄清了具有各种安全保证的任何替代解决方案如基于随机化的SafeStack [36]和基于硬件的Intel CET技术[33]，可以与μCFI集成以提供未来继续实现更好UCT属性的两个方向。</p>\n<h1 id=\"Discussion\"><a href=\"#Discussion\" class=\"headerlink\" title=\"Discussion\"></a>Discussion</h1><p>在关于未来的工作中，作者提到两点： 1. 验证signal或exception中的CFI，这些与OS有关，在Intel PT中以FUP包形式记载 2. 验证动态加载的代码中的CFI</p>\n","categories":[{"name":"论文","slug":"论文","permalink":"http://yama0xff.com/categories/论文/"},{"name":"软件分析","slug":"论文/软件分析","permalink":"http://yama0xff.com/categories/论文/软件分析/"}],"tags":[{"name":"2018年","slug":"2018年","permalink":"http://yama0xff.com/tags/2018年/"},{"name":"防护","slug":"防护","permalink":"http://yama0xff.com/tags/防护/"},{"name":"CFI","slug":"CFI","permalink":"http://yama0xff.com/tags/CFI/"},{"name":"ACM CCS’18","slug":"ACM-CCS’18","permalink":"http://yama0xff.com/tags/ACM-CCS’18/"}]},{"title":"Using Logic Programming to Recover C++ Classes and Methods From Compiled Executables","date":"2019-02-14T09:36:20.000Z","path":"2019/02/14/Using-Logic-Programming-to-Recover-C-Classes-and-Methods-From-Compiled-Executables/","text":"Abstract 随着计算机硬件的发展，计算机软件也变得越来越庞大、越来越复杂。而为了开发这些复杂的计算机软件，软件工程师们逐渐把方向转向了面向对象 OO（Object Oriented）的编程语言，例如 C++ 等高级开发语言。这些高级的编程语言，对于开发庞大、复杂的应用程序，它可以提供一种高级抽象的框架（Natural Framework），使得面向对象的编程语言更加适用于构造复杂的数据结构 — Class。类可以把相关的数据成员和一组对数据成员进行操作的方法绑定在一起，这样的绑定方式极大的方便了 C++ 代码的维护与管理，使得开发者更容易、更高效地开发复杂的应用程序。虽然类可以给开发者带来极大的便利，但是，万事万物总有两面性，类也一样，它给开发者带来便利的同时，也给软件逆向分析工程师带来了不便，使得分析师在分析 C++ 开发的程序的难度有所提高，特别是在分析恶意程序的时候，分析 C++ 开发的恶意程序变成了一项更高难度的挑战。因此，如何从恶意程序中恢复出代码的高级抽象特性（例如类等），成为了一项值得深究的工作。 relevant information 作者 Edward J. Schwartz, Cory Cohen, Jeff Havrilla, Jeff Gennari, Charles Hines, Michael Duggan 单位 Carnegie Mellon University 出处 ACM CCS’18 原文地址 https://github.com/wtwofire/database/blob/master/papers/reverse/2018-Using%20Logic%20Programming%20to%20Recover%20C%2B%2B%20Classes%20and%20Methods%20From%20Compiled%20Executables.pdf 源码地址 https://github.com/cmu-sei/pharos 发表时间 2018年 提出的方法以及解决的问题 基于上述的背景，作者提出了一种新的二进制分析工具 — OOAnalyzer，用于分析 C++ 所开发出来的程序，特别是针对恶意软件的分析，该工具可以起到很好的辅助作用，极大的方便了软件分析工程师对软件的分析，使得分析师在分析 C++ 程序的时候，可以快速的掌握程序中的相关类之间的关系（比如继承关系等），并且快速了解各个类内部的各个组成部分（例如方法、数据成员、虚函数表（VFTable）、构造函数与析构函数等）。 技术方法 分析 C++ 所开发的应用程序，主要是分析出程序中的数据与方法之间的关系，即从二进制文件中恢复出程序的高级抽象结构 — 类。如果有办法可以很方便的从二进制文件中恢复出程序中类的结构，让分析者能够知道各个类之间的关系，并且知道类中所包含的方法、数据成员、虚函数表（VFTable）、构造函数与析构函数等信息，这就可以使得分析者很容易的分析出该程序所具有的功能与用途，并且快速掌握程序的执行过程，完成程序分析任务。很可惜的是，目前没有一个高效的工具能够实现这样的功能，因此，OOAnalyzer 就诞生了，它的目的就是从二进制文件中恢复出程序中类的结构，尽可能的恢复出每一个类之间的关系，以及各个类所包含的各种信息等。该工具是基于逆向工程师在逆向分析程序的时候所采用的一般步骤和方法，并把这些方法和步骤用代码来实现，使之能够自动化的帮助分析师分析程序，并且还可以实现大规模分析、分析大型应用程序（例如FireFox、MySQL等）等。该工具中所包含的核心方法有： 在二进制代码中识别简单的模式（Patterns）； 基于这些模式，使用逻辑推理并结合相关领域的专业知识，甚至是一些直觉（Intuition）等方法来分析目标程序； 分析过程包括使用一个轻量级的符号执行引擎和一个基于 Prolog 的推理系统，把分析师的分析行为转化为代码的形式，集成在 OOAnalyzer 当中。 图 1： OOAnalyzer 的执行流程 如图 1 所示是 OOAnalyzer 的执行流程，OOAnalyzer 的最终目标就是从一个 C++ 开发的可执行文件中恢复出 C++ 代码的抽象信息（类的相关信息）。对于一个 C++ 开发的可执行文件，OOAnalyzer 首先对它执行 Fact Exporter 操作，生成初始的 Facts（比如函数调用、带对象指针的方法调用、创建和使用对象等行为） — Initial Facts。这里的 Fact Exporter 使用的是一个轻量级的符号分析引擎（Pharos binary analysis framework）来实现语义分析和反汇编等操作。这里得到的 Facts 虽然不是完全正确可信的，但是它是后序操作的基础，它也需要被后序的操作来证实和验证自己。 第一步得到了基础的 Facts 之后，OOAnalyzer 把它当做一个 Fact base，并开始执行基于 Prolog 的推理模块，该模块包含三个核心组成部分：Forward Reasoning、 Hypothetical Reasoning 和 Consistency Checking。其中，Forward Reasoning 内部包含了一系列的规则，这些规则都是基于 Fact base，并且由一些前提条件（Precondition）和结论（Conclusion）组成，通过查找程序，只要找到满足所有前提条件的结构存在，就可以把相应的数据结构归结为某一个特定的结论（比如构造函数等），生成一个对应的 fact（此处称之为 Entity fact，包括方法，虚函数表，类之间的关系，类的大小等），并加入到 Fact base 中，如此来不断的扩大 Fact base。 在 Forward Reasoning 推理过程中可能对某些情况无法做出判断（这种情况称之为：Ambiguous properties），因此需要 Hypothetical Reasoning 来辅助推理分析，这个 Hypothetical Reasoning 也是 OOAnalyzer 的最关键一个部分，有了这个模块，才使得 OOAnalyzer 的分析能力有了非常大的提高（平均错误率从 81% 下降到 21.8%）。OOAnalyzer 通过一些 Hypothetical Reasoning Rules 来猜测（Educated guess）这些不确定的属性（Ambiguous properties），提出一些 Guesses 和 Assumptions， 以使得 OOAnalyzer 在分析的过程中可以不间断的执行下去。 经过前面两步操作之后，OOAnalyzer 已经得到了一个比较完整的 Fact base， 但是在这个 Fact base 中，可能会产生互相冲突的情况（因为 Hypothetical Reasoning 可能会做出错误的假设和猜测），因此，还需要做一个一致性的检查（Consistency Checking），以解决这些不一致的情况。这里的 Consistency Checking 会按照一些特定的规则，当检测到 Inconsistency 的时候，就开始从最近的一个猜测（Last guess）开始回退分析（backtrack）来检测并解决 Fact base 中产生的冲突和不一致的情况，使得最终得到的 Fact base 中的每一个 fact 都不会互相冲突。 当前面的所有步骤都顺利完成，并且没有残留的 Inconsistency 和 Proposed Guess 的时候，OOAnalyzer 就会把这个最终的模型展示给分析者。 实验评估 作者的实验环境是：使用单核的 Intel Xeon E5-2695@2.4Ghz 的 CPU ，并且配置了 256GB 的内存。主要评估 OOAnalyzer 对 C++ 类的识别与类中的方法（包括构造函数、析构函数、虚函数等）的识别，以及 OOAnalyzer 的时间与空间开销。作者评估 OOAnalyzer 所使用的测试集是 27 个 32 位的 PE 可执行程序，包括 18 个 Cleanware 和 9 个 Malware， 在 18 个 Cleanware 中，还包括了两个大型的应用程序： FireFox 和 MySQL。同时，作者使用编辑距离（Edit Distance）来衡量一个方法是否属于某一个具体的类。此外，为了证明测试结果的正确性，作者通过解析每一个程序的 PDB 文件（由 Visual C++ 产生的一个符号文件）来验证。 1. 编辑距离（Edit Distance） 作者在文中使用一组方法来代表一个类，并且使用编辑距离来衡量 OOAnalyzer 产生的类与真正的类之间的距离，编辑距离就是：OOAnalyzer 产生的类通过多少步操作之后才能和真正的类完全一样，这里的操作包括： 把一个方法从一个类移动到另一个类中 向 OOAnalyzer 产生的类中添加一个方法（OOAnalyzer 未能正确识别的方法） 把 OOAnalyzer 产生的类中的一个方法移除（OOAnalyzer 错误的把它当做类的方法） 任意的分割一个类为两个类 合并两个单独的类为一个类 ​ 表 1：OOAnalyzer 产生的类的准确度 如表 1 所示（w/o 表示 Without），是 OOAnalyzer 产生的类的准确度，通过 Edit Distance 来衡量，Edit Distance 越小越好，表明 OOAnalyzer 产生的类越接近真实的类。由图中可知，RTTI（Runtime Type Identification，多态类才有该信息，包括类名称和基类信息等）对 OOAnalyzer 的影响很小，几乎可以忽略不计，而 guess（也就是前文所说的：Hypothetical Reasoning） 对 OOAnalyzer 的影响是极大的，去掉该功能之后（w/o guess），OOAnalyzer 的错误率从 21.8% 直接提升到 81%。 2. 方法属性 类成员包括构造函数、析构函数、虚函数表和虚方法等，而类成员恢复的比例是衡量 OOAnalyzer 的一项最关键的指标，标志着 OOAnalyzer 的性能好坏，如表 2 所示是 OOAnalyzer 在没有 RTTI 信息的情况下，对类成员恢复的召回率（Recall）和精确度（Precision），在表中，蓝色标志表示 Recall 或者 Precision 大于 0.75， 而红色表示 Recall 或者 Precision 小于 0.25。Recal 表示在 Ground True 中 OOAnalyzer 所能检测出来的方法数量，而 Precision 表示 OOAnalyzer 所检测出来的数量中，有多少个是正确的。 从表中可以看出，大部分检测结果都在 80% 以上，只有析构函数的恢复率比较低，表明析构函数比较难于检测和恢复，因为它经常会被编译器所优化。 3. 时间与空间开销 OOAnalyzer 的时间开销在 30 秒到 22.7 个小时之间，平均开销为 2.3 小时， 但中位数（median）为 0.2 小时（因为大部分程序的时间开销都比较小，只有少部分程序的时间开销比较大，导致平均时间开销偏大）。OOAnalyzer 的空间开销在 41.3MB 到 3.5GB 之间，平均为 1.0GB， 中位数为 0.7GB。 优缺点优点： OOAnalyzer 不但可以恢复出具有多态形式的类的相关信息，还可以恢复出非多态类中的相关信息。 OOAnalyzer 不需要依赖于 RTTI 和 VFTable 会恢复类。 OOAnalyzer 对类的构造函数、成员方法和虚函数表的恢复效果非常好，平均准确度达到88% 以上。 OOAnalyzer 是 ObjDigger 的升级版本，它相比于 ObjDigger 的主要优势就在于 Hypothetical Reasoning 模块，该模块极大的减少了 OOAnalyzer 的错误率。 缺点： 由于编译器优化等原因（比如编译器内联某些函数等），可能对优化之后的程序的的分析效果不是很好，甚至是失效。 正常情况下，类中的方法调用都会采用 ecx 寄存器来传递 this 指针，但是，可能会存在很多无法判断的情况，例如，某些编译器可能不是使用 ecx 寄存器来传递对象指针，或者有时候编译器刚好就是用 ecx 寄存器来传递对象指针，但是调用的是一个普通的函数，而不是一个类中的方法等，这时候就会导致 OOAnalyzer 分析不准确。 OOAnalyzer 对析构函数的恢复效果依然不是很好。 OOAnalyzer 对于普通的程序分析效果还不错，但是对于一般的恶意软件，都会使用加壳等方法来保护自己，或者是减少自己的体积，在这种情况下，OOAnalyzer就无法使用了。 如果程序编译的时候开启了 Whole Program Optimization（WPO），则会导致 OOAnalyzer 的规则无法正常工作。 如果在不同的类中出现了相同的方法，则 OOAnalyzer 也可能会误以为它们是同一个类。 对于不可达的函数， OOAnalyzer 也无法执行分析。 由于静态的符号执行本身所具有的缺陷所导致 OOAnalyzer 分析不准确。 六、个人观点 作者在文中介绍的这款工具（OOAnalyzer），是一款功能强大的 C++ 高级语言抽象结构（Class）恢复工具，相比于其它的工具（例如 Lego、SmartDec等）具有很多的优势，例如 OOAnalyzer 不但可以恢复多态类中的信息，而且还可以恢复非多态类中的信息（Lego 则不行），OOAnalyzer 不需要依赖 RTTI 的相关信息（即使有 RTTI 的相关信息，对 OOAnalyzer 的作用也不大）。OOAnalyzer 不但可以恢复 C++ 程序中的各个类之间的关系（例如继承关系），而且还可以恢复各个类内部的相关信息（包括 构造函数、析构函数、虚函数表和虚拟函数等），其中，OOAnalyzer 对虚函数表的恢复效果最佳，准确度达到 99%，但是对于析构函数却略显不足。总之，这对于我们分析 C++ 程序提供了很大的帮助，能够给我们提供很多有用的信息，特别是对于我们逆向一些由 C++ 开发的恶意程序，能够让我们方便的了解到恶意程序内部的构造，可以提高我们的对恶意程序的分析效率。当然，这款工具也有很多可以改进的地方，例如，它对析构函数的识别效果不佳，对于编译器优化之后的程序的分析效果也没有这么理想。通过阅读这篇文章，我们还可以了解到它的过去版本 — ObjDigger，而 OOAnalyzer 就是在 ObjDigger 中添加了 Hypothetical Reasoning 之后形成的。此外，从文章中的相关链接（该项目的Github链接）还可以了解到，该工具只是 Pharos 项目中的一个组成部分，或者说是 Pharos 项目中的一个小插件，就像是 Clang StaticAnalyzer 是 LLVM 项目的一个小插件一样。最后，文章的难点在于 Prolog-Base 推理系统。个人觉得，作者在文章中写的规则说明的不是很到位，或者解释的不是很清楚。 ​ 转载于GoSSIP","content":"<h1 id=\"Abstract\"><a href=\"#Abstract\" class=\"headerlink\" title=\"Abstract\"></a>Abstract</h1><p>  随着计算机硬件的发展，计算机软件也变得越来越庞大、越来越复杂。而为了开发这些复杂的计算机软件，软件工程师们逐渐把方向转向了面向对象 OO（Object Oriented）的编程语言，例如 C++ 等高级开发语言。这些高级的编程语言，对于开发庞大、复杂的应用程序，它可以提供一种高级抽象的框架（Natural Framework），使得面向对象的编程语言更加适用于构造复杂的数据结构 — Class。类可以把相关的数据成员和一组对数据成员进行操作的方法绑定在一起，这样的绑定方式极大的方便了 C++ 代码的维护与管理，使得开发者更容易、更高效地开发复杂的应用程序。虽然类可以给开发者带来极大的便利，但是，万事万物总有两面性，类也一样，它给开发者带来便利的同时，也给软件逆向分析工程师带来了不便，使得分析师在分析 C++ 开发的程序的难度有所提高，特别是在分析恶意程序的时候，分析 C++ 开发的恶意程序变成了一项更高难度的挑战。因此，如何从恶意程序中恢复出代码的高级抽象特性（例如类等），成为了一项值得深究的工作。</p>\n<table>\n<thead>\n<tr>\n<th>relevant information</th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><em>作者</em></td>\n<td>Edward J. Schwartz, Cory Cohen, Jeff Havrilla, Jeff Gennari, Charles Hines, Michael Duggan</td>\n</tr>\n<tr>\n<td><em>单位</em></td>\n<td>Carnegie Mellon University</td>\n</tr>\n<tr>\n<td><em>出处</em></td>\n<td>ACM CCS’18</td>\n</tr>\n<tr>\n<td><em>原文地址</em></td>\n<td><a href=\"https://github.com/wtwofire/database/blob/master/papers/reverse/2018-Using%20Logic%20Programming%20to%20Recover%20C%2B%2B%20Classes%20and%20Methods%20From%20Compiled%20Executables.pdf\" target=\"_blank\" rel=\"noopener\">https://github.com/wtwofire/database/blob/master/papers/reverse/2018-Using%20Logic%20Programming%20to%20Recover%20C%2B%2B%20Classes%20and%20Methods%20From%20Compiled%20Executables.pdf</a></td>\n</tr>\n<tr>\n<td><em>源码地址</em></td>\n<td><a href=\"https://github.com/cmu-sei/pharos\" target=\"_blank\" rel=\"noopener\">https://github.com/cmu-sei/pharos</a></td>\n</tr>\n<tr>\n<td><em>发表时间</em></td>\n<td>2018年</td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"提出的方法以及解决的问题\"><a href=\"#提出的方法以及解决的问题\" class=\"headerlink\" title=\"提出的方法以及解决的问题\"></a>提出的方法以及解决的问题</h1><p>    基于上述的背景，作者提出了一种新的二进制分析工具 — OOAnalyzer，用于分析 C++ 所开发出来的程序，特别是针对恶意软件的分析，该工具可以起到很好的辅助作用，极大的方便了软件分析工程师对软件的分析，使得分析师在分析 C++ 程序的时候，可以快速的掌握程序中的相关类之间的关系（比如继承关系等），并且快速了解各个类内部的各个组成部分（例如方法、数据成员、虚函数表（VFTable）、构造函数与析构函数等）。</p>\n<h1 id=\"技术方法\"><a href=\"#技术方法\" class=\"headerlink\" title=\"技术方法\"></a>技术方法</h1><p>    分析 C++ 所开发的应用程序，主要是分析出程序中的数据与方法之间的关系，即从二进制文件中恢复出程序的高级抽象结构 — 类。如果有办法可以很方便的从二进制文件中恢复出程序中类的结构，让分析者能够知道各个类之间的关系，并且知道类中所包含的方法、数据成员、虚函数表（VFTable）、构造函数与析构函数等信息，这就可以使得分析者很容易的分析出该程序所具有的功能与用途，并且快速掌握程序的执行过程，完成程序分析任务。很可惜的是，目前没有一个高效的工具能够实现这样的功能，因此，OOAnalyzer 就诞生了，它的目的就是从二进制文件中恢复出程序中类的结构，尽可能的恢复出每一个类之间的关系，以及各个类所包含的各种信息等。该工具是基于逆向工程师在逆向分析程序的时候所采用的一般步骤和方法，并把这些方法和步骤用代码来实现，使之能够自动化的帮助分析师分析程序，并且还可以实现大规模分析、分析大型应用程序（例如FireFox、MySQL等）等。该工具中所包含的核心方法有：</p>\n<ul>\n<li>在二进制代码中识别简单的模式（Patterns）；</li>\n<li>基于这些模式，使用逻辑推理并结合相关领域的专业知识，甚至是一些直觉（Intuition）等方法来分析目标程序；</li>\n<li>分析过程包括使用一个轻量级的符号执行引擎和一个基于 Prolog 的推理系统，把分析师的分析行为转化为代码的形式，集成在 OOAnalyzer 当中。</li>\n</ul>\n<p><img src=\"/2019/02/14/Using-Logic-Programming-to-Recover-C-Classes-and-Methods-From-Compiled-Executables/1.png\" alt=\"\"></p>\n<p>                                 图 1： OOAnalyzer 的执行流程</p>\n<p> 如图 1 所示是 OOAnalyzer 的执行流程，OOAnalyzer 的最终目标就是从一个 C++ 开发的可执行文件中恢复出 C++ 代码的抽象信息（类的相关信息）。对于一个 C++ 开发的可执行文件，OOAnalyzer 首先对它执行 Fact Exporter 操作，生成初始的 Facts（比如函数调用、带对象指针的方法调用、创建和使用对象等行为） — Initial Facts。这里的 Fact Exporter 使用的是一个轻量级的符号分析引擎（<a href=\"https://github.com/cmu-sei/pharos\" target=\"_blank\" rel=\"noopener\">Pharos binary analysis framework</a>）来实现语义分析和反汇编等操作。这里得到的 Facts 虽然不是完全正确可信的，但是它是后序操作的基础，它也需要被后序的操作来证实和验证自己。</p>\n<p>    第一步得到了基础的 Facts 之后，OOAnalyzer 把它当做一个 Fact base，并开始执行基于 Prolog 的推理模块，该模块包含三个核心组成部分：Forward Reasoning、 Hypothetical Reasoning 和 Consistency Checking。其中，Forward Reasoning 内部包含了一系列的规则，这些规则都是基于 Fact base，并且由一些<strong>前提条件</strong>（Precondition）和<strong>结论</strong>（Conclusion）组成，通过查找程序，只要找到满足所有前提条件的结构存在，就可以把相应的数据结构归结为某一个特定的结论（比如构造函数等），生成一个对应的 fact（此处称之为 Entity fact，包括方法，虚函数表，类之间的关系，类的大小等），并加入到 Fact base 中，如此来不断的扩大 Fact base。</p>\n<p>    在 Forward Reasoning 推理过程中可能对某些情况无法做出判断（这种情况称之为：Ambiguous properties），因此需要 Hypothetical Reasoning 来辅助推理分析，这个 Hypothetical Reasoning 也是 OOAnalyzer 的最关键一个部分，有了这个模块，才使得 OOAnalyzer 的分析能力有了非常大的提高（平均错误率从 81% 下降到 21.8%）。OOAnalyzer 通过一些 Hypothetical Reasoning Rules 来猜测（Educated guess）这些不确定的属性（Ambiguous properties），提出一些 Guesses 和 Assumptions， 以使得 OOAnalyzer 在分析的过程中可以不间断的执行下去。</p>\n<p>    经过前面两步操作之后，OOAnalyzer 已经得到了一个比较完整的 Fact base， 但是在这个 Fact base 中，可能会产生互相冲突的情况（因为 Hypothetical Reasoning 可能会做出错误的假设和猜测），因此，还需要做一个一致性的检查（Consistency Checking），以解决这些不一致的情况。这里的 Consistency Checking 会按照一些特定的规则，当检测到 Inconsistency 的时候，就开始从最近的一个猜测（Last guess）开始回退分析（backtrack）来检测并解决 Fact base 中产生的冲突和不一致的情况，使得最终得到的 Fact base 中的每一个 fact 都不会互相冲突。</p>\n<p>    当前面的所有步骤都顺利完成，并且没有残留的 Inconsistency 和 Proposed Guess 的时候，OOAnalyzer 就会把这个最终的模型展示给分析者。</p>\n<h1 id=\"实验评估\"><a href=\"#实验评估\" class=\"headerlink\" title=\"实验评估\"></a>实验评估</h1><p>    作者的实验环境是：使用单核的 Intel Xeon <a href=\"mailto:E5-2695@2.4Ghz\" target=\"_blank\" rel=\"noopener\">E5-2695@2.4Ghz</a> 的 CPU ，并且配置了 256GB 的内存。主要评估 OOAnalyzer 对 C++ 类的识别与类中的方法（包括构造函数、析构函数、虚函数等）的识别，以及 OOAnalyzer 的时间与空间开销。作者评估 OOAnalyzer 所使用的测试集是 27 个 32 位的 PE 可执行程序，包括 18 个 Cleanware 和 9 个 Malware， 在 18 个 Cleanware 中，还包括了两个大型的应用程序： FireFox 和 MySQL。同时，作者使用编辑距离（Edit Distance）来衡量一个方法是否属于某一个具体的类。此外，为了证明测试结果的正确性，作者通过解析每一个程序的 PDB 文件（由 Visual C++ 产生的一个符号文件）来验证。</p>\n<h2 id=\"1-编辑距离（Edit-Distance）\"><a href=\"#1-编辑距离（Edit-Distance）\" class=\"headerlink\" title=\"1. 编辑距离（Edit Distance）\"></a>1. 编辑距离（Edit Distance）</h2><p>    作者在文中使用一组方法来代表一个类，并且使用编辑距离来衡量 OOAnalyzer 产生的类与真正的类之间的距离，编辑距离就是：OOAnalyzer 产生的类通过多少步操作之后才能和真正的类完全一样，这里的操作包括：</p>\n<ul>\n<li>把一个方法从一个类移动到另一个类中</li>\n<li>向 OOAnalyzer 产生的类中添加一个方法（OOAnalyzer 未能正确识别的方法）</li>\n<li>把 OOAnalyzer 产生的类中的一个方法移除（OOAnalyzer 错误的把它当做类的方法）</li>\n<li>任意的分割一个类为两个类</li>\n<li>合并两个单独的类为一个类</li>\n</ul>\n<p><img src=\"/2019/02/14/Using-Logic-Programming-to-Recover-C-Classes-and-Methods-From-Compiled-Executables/2.png\" alt=\"\"></p>\n<p>​                              表 1：OOAnalyzer 产生的类的准确度</p>\n<p>如表 1 所示（w/o 表示 Without），是 OOAnalyzer 产生的类的准确度，通过 Edit Distance 来衡量，Edit Distance 越小越好，表明 OOAnalyzer 产生的类越接近真实的类。由图中可知，RTTI（Runtime Type Identification，多态类才有该信息，包括类名称和基类信息等）对 OOAnalyzer 的影响很小，几乎可以忽略不计，而 guess（也就是前文所说的：Hypothetical Reasoning） 对 OOAnalyzer 的影响是极大的，去掉该功能之后（w/o guess），OOAnalyzer 的错误率从 21.8% 直接提升到 81%。</p>\n<h2 id=\"2-方法属性\"><a href=\"#2-方法属性\" class=\"headerlink\" title=\"2. 方法属性\"></a>2. 方法属性</h2><p>    类成员包括构造函数、析构函数、虚函数表和虚方法等，而类成员恢复的比例是衡量 OOAnalyzer 的一项最关键的指标，标志着 OOAnalyzer 的性能好坏，如表 2 所示是 OOAnalyzer 在没有 RTTI 信息的情况下，对类成员恢复的召回率（Recall）和精确度（Precision），在表中，蓝色标志表示 Recall 或者 Precision 大于 0.75， 而红色表示 Recall 或者 Precision 小于 0.25。Recal 表示在 Ground True 中 OOAnalyzer 所能检测出来的方法数量，而 Precision 表示 OOAnalyzer 所检测出来的数量中，有多少个是正确的。 从表中可以看出，大部分检测结果都在 80% 以上，只有析构函数的恢复率比较低，表明析构函数比较难于检测和恢复，因为它经常会被编译器所优化。</p>\n<p><img src=\"/2019/02/14/Using-Logic-Programming-to-Recover-C-Classes-and-Methods-From-Compiled-Executables/3.png\" alt=\"\"></p>\n<h3 id=\"3-时间与空间开销\"><a href=\"#3-时间与空间开销\" class=\"headerlink\" title=\"3. 时间与空间开销\"></a><strong>3. 时间与空间开销</strong></h3><p>    OOAnalyzer 的时间开销在 30 秒到 22.7 个小时之间，平均开销为 2.3 小时， 但中位数（median）为 0.2 小时（因为大部分程序的时间开销都比较小，只有少部分程序的时间开销比较大，导致平均时间开销偏大）。OOAnalyzer 的空间开销在 41.3MB 到 3.5GB 之间，平均为 1.0GB， 中位数为 0.7GB。</p>\n<h1 id=\"优缺点\"><a href=\"#优缺点\" class=\"headerlink\" title=\"优缺点\"></a>优缺点</h1><h2 id=\"优点：\"><a href=\"#优点：\" class=\"headerlink\" title=\"优点：\"></a><strong>优点：</strong></h2><ul>\n<li>OOAnalyzer 不但可以恢复出具有多态形式的类的相关信息，还可以恢复出非多态类中的相关信息。</li>\n<li>OOAnalyzer 不需要依赖于 RTTI 和 VFTable 会恢复类。</li>\n<li>OOAnalyzer 对类的构造函数、成员方法和虚函数表的恢复效果非常好，平均准确度达到88% 以上。</li>\n<li>OOAnalyzer 是 ObjDigger 的升级版本，它相比于 ObjDigger 的主要优势就在于 Hypothetical Reasoning 模块，该模块极大的减少了 OOAnalyzer 的错误率。</li>\n</ul>\n<h2 id=\"缺点：\"><a href=\"#缺点：\" class=\"headerlink\" title=\"缺点：\"></a><strong>缺点：</strong></h2><ul>\n<li>由于编译器优化等原因（比如编译器内联某些函数等），可能对优化之后的程序的的分析效果不是很好，甚至是失效。</li>\n<li>正常情况下，类中的方法调用都会采用 ecx 寄存器来传递 this 指针，但是，可能会存在很多无法判断的情况，例如，某些编译器可能不是使用 ecx 寄存器来传递对象指针，或者有时候编译器刚好就是用 ecx 寄存器来传递对象指针，但是调用的是一个普通的函数，而不是一个类中的方法等，这时候就会导致 OOAnalyzer 分析不准确。</li>\n<li>OOAnalyzer 对析构函数的恢复效果依然不是很好。</li>\n<li>OOAnalyzer 对于普通的程序分析效果还不错，但是对于一般的恶意软件，都会使用加壳等方法来保护自己，或者是减少自己的体积，在这种情况下，OOAnalyzer就无法使用了。</li>\n<li>如果程序编译的时候开启了 Whole Program Optimization（WPO），则会导致 OOAnalyzer 的规则无法正常工作。</li>\n<li>如果在不同的类中出现了相同的方法，则 OOAnalyzer 也可能会误以为它们是同一个类。</li>\n<li>对于不可达的函数， OOAnalyzer 也无法执行分析。</li>\n<li>由于静态的符号执行本身所具有的缺陷所导致 OOAnalyzer 分析不准确。</li>\n</ul>\n<h1 id=\"六、个人观点\"><a href=\"#六、个人观点\" class=\"headerlink\" title=\"六、个人观点\"></a>六、个人观点</h1><p>    作者在文中介绍的这款工具（OOAnalyzer），是一款功能强大的 C++ 高级语言抽象结构（Class）恢复工具，相比于其它的工具（例如 Lego、SmartDec等）具有很多的优势，例如 OOAnalyzer 不但可以恢复多态类中的信息，而且还可以恢复非多态类中的信息（Lego 则不行），OOAnalyzer 不需要依赖 RTTI 的相关信息（即使有 RTTI 的相关信息，对 OOAnalyzer 的作用也不大）。OOAnalyzer 不但可以恢复 C++ 程序中的各个类之间的关系（例如继承关系），而且还可以恢复各个类内部的相关信息（包括 构造函数、析构函数、虚函数表和虚拟函数等），其中，OOAnalyzer 对虚函数表的恢复效果最佳，准确度达到 99%，但是对于析构函数却略显不足。总之，这对于我们分析 C++ 程序提供了很大的帮助，能够给我们提供很多有用的信息，特别是对于我们逆向一些由 C++ 开发的恶意程序，能够让我们方便的了解到恶意程序内部的构造，可以提高我们的对恶意程序的分析效率。当然，这款工具也有很多可以改进的地方，例如，它对析构函数的识别效果不佳，对于编译器优化之后的程序的分析效果也没有这么理想。通过阅读这篇文章，我们还可以了解到它的过去版本 — ObjDigger，而 OOAnalyzer 就是在 ObjDigger 中添加了 Hypothetical Reasoning 之后形成的。此外，从文章中的相关链接（该项目的Github链接）还可以了解到，该工具只是 Pharos 项目中的一个组成部分，或者说是 Pharos 项目中的一个小插件，就像是 Clang StaticAnalyzer 是 LLVM 项目的一个小插件一样。最后，文章的难点在于 Prolog-Base 推理系统。个人觉得，作者在文章中写的规则说明的不是很到位，或者解释的不是很清楚。</p>\n<p>​                                                                                              <strong><em>转载于GoSSIP</em></strong></p>\n","categories":[{"name":"论文","slug":"论文","permalink":"http://yama0xff.com/categories/论文/"},{"name":"软件分析","slug":"论文/软件分析","permalink":"http://yama0xff.com/categories/论文/软件分析/"}],"tags":[{"name":"2018年","slug":"2018年","permalink":"http://yama0xff.com/tags/2018年/"},{"name":"ACM CCS'18","slug":"ACM-CCS-18","permalink":"http://yama0xff.com/tags/ACM-CCS-18/"},{"name":"静态符号执行、","slug":"静态符号执行、","permalink":"http://yama0xff.com/tags/静态符号执行、/"},{"name":"逆向","slug":"逆向","permalink":"http://yama0xff.com/tags/逆向/"},{"name":"二进制分析工具","slug":"二进制分析工具","permalink":"http://yama0xff.com/tags/二进制分析工具/"}]},{"title":"Towards Paving the Way for Large-Scale Windows Malware Analysis: Generic Binary Unpacking With Orders-of-Magnitude Performance Boost","date":"2019-02-14T07:51:11.000Z","path":"2019/02/14/Towards-Paving-the-Way-for-Large-Scale-Windows-Malware-Analysis-Generic-Binary-Unpacking-With-Orders-of-Magnitude-Performance-Boost/","text":"Abstractwindows的软件脱壳本来已经在多年前已经被讨论得非常多了，目前安全学术会议上关于脱壳的论文非常少，然而这篇关于脱壳的论文还能在2018年被CCS所录取，足见他的方法之高效。此前关于脱壳的方法大多是跟踪脱壳时期的内存代码写入执行的变化，从而跟踪被加密代码的解密流程从而追溯到OEP。这也是对于分析脱壳的一个最为直观的方法，在这篇论文里作者提出来通过跟踪IAT(函数导入表)被恢复和引用的情况来追溯OEP，并且达到很理想的效果。作者将这款工具称为BinUnpack。 relevant information 作者 Binlin Cheng , Jiang Ming, Jianming Fu, Guojun Peng, Ting Chen, Xiaosong Zhang , Jean-Yves Marion 单位 Wuhan University , Hubei Normal University, University of Texas at Arlington, University of Electronic Science and Technology of China, LORIA 出处 ACM CCS’18 原文地址 https://github.com/wtwofire/database/blob/master/papers/reverse/2018-Towards%20Paving%20the%20Way%20for%20Large-Scale%20Windows%20Malware%20Analysis%20Generic%20Binary%20Unpacking%20With%20Orders-of-Magnitude%20Performance%20Boost.pdf 源码地址 发表时间 2018年 IAT在脱壳中角色IAT即为PE文件中的函数地址导入表，加壳软件会在对一个软件进行加壳时将IAT抹去，然后在运行解密时通过LoadLibrary和GetProcess两函数或者功能相同的函数再恢复，最后将控制权移交OEP。解密代码为了满足自身需要，通常也有一个自己的IAT，但是与原IAT位置并不在同一内存区域中，通常这个IAT的导入函数个数也要小得多，甚至只有一两个。作者的思路是，一旦某个函数调用是通过原IAT进行的，那么就表明这个时候，原代码已经完成了解密，这个时候往前回溯，即可找到OEP。 Anti-Hook为了跟踪函数的调用情况，hook是必不可少的，然而现在的加壳软件大多会检测函数hook并且存在许多反hook机制，这里记录一下加壳软件中用到的anti-hook方法。 首先Hook分为内核hook与用户层Hook,由于现在恶意软件想要加载内核模块越发困难，所以作者并没有考虑内核hook情况，这篇论文里，作者假设内核是安全的，未被加壳软件所修改。 用户层Hook分为以下几种： Stolen code. 即将所需要调用的函数代码从内存或者直接从文件系统中复制出来单独执行，这样.inlinehooke,iat,eat类型的Hook全部失效。 Child process,process hollowing.将脱壳行为分解到两个进程中进行，这样由于进程地址空间隔离，父进程hook全部失效。 Crash hooking module. 给api函数故意传入错误的参数，如果函数被Hook,则不能正确处理错误而程序崩溃 ，没有被Hook则能正确处理异常。以此可以检测是否被hook。 Integrity check. 使用哈希校验所调用模块的完整性。 Anti-anti-hook作者设计了一个内核用户态混合的dll劫持系统来完成对函数的hook。作者通过逆向Loadlibrary发现，在内核中它最终需要将dll映射到进程的地址空间，而使用的内核函数是LdrMapDll。函数流程如下： 作者修改内核使得NtMapViewOfSection加载定制的Hook版本dll，同时使得返回值变为STATUS_IMAGE_NOT_AT_BASE。这样第16行的NtMapViewOfSection也会被执行，这样定制的dll被加载进内存。另外有些加壳作者并不使用内存映射进行加载dll，而是使用读取文件如readfile读取dll，复制到内存，这样作者同样修改内存中这部分代码，使得加载的dll为定制的dll。 这样做能防住上述的提到的几种方法的anti-hook： Stolen code. 由于被加载时已经是被定制的dll，或者从文件系统读时都是被定制的dll，所以stolen code复制的代码依然是改变后的hook代码。 Child process,process hollowing. 同理，修改内核对于每个进程都生效。 Crash hooking module。这点作者认为正确处理了异常，存疑。 Integrity check。作者说借鉴使用了一种别人的方法，使得读取dll时读到的内容为原dll，执行时执行的是定制的dll，具体方法待研究。 Find OEP 在结合了IAT与dll hijacking之后，寻找OEP的过程可以用上图来进行表示，首先进程加载时，加载的dll，包括系统dll，如Kernel32.dll,user32.dll等都被换成了作者定制的带hook版本。脱壳时一旦检测到某个函数调用来自原IAT，则进行回溯查找OEP及内存dump。由于可能存在加多个壳情况，即可能会更换IAT，但是这个IAT并不属于最开始被加壳的程序而是属于内层壳，这里作者的作法是，当切换IAT时则进行dump和回溯操作。 评估实验环境：laptop with an Intel Core i3-36100 processor (Quad Core,3.70GHz) and 8GB memory, running Windows 7. 作者使用VirusTotal检测结果来作为脱壳效果的检测结果。即对于一个不加壳的恶意软件，VirusTotal检测结果为n，被脱壳的检测结果越接近n则说明脱壳效果越好。 作者利用一款未被加壳的恶意软件hupigon.eyf，并用不同的壳对他进行加密，然后使用CoDisasm, PinDemonium, Arancino, BinUnpack四款脱壳工具进行脱壳。结果送VirusTotal进行检测，并记录脱壳所用到的时间。 从图中可以看到，BinUpack的检测结果要远远高于其他三种脱壳工具。另外脱壳所用的到时间也缩短了一两个数量级。对于同一个软件加多个不同的壳，BinUpack的表现依然很出色，脱壳时间始终小于1s。而面对商业强壳Themida时，BinUnpack表现依然良好，VirusTotal检测结果能达到33，34这个级别，而其他三种壳都没有脱壳成功。 最后作者收集了271095个恶意软件进行测试，依然表现不俗。 评价这篇论文对于脱壳来说实在是一篇不可多得好的好文。我觉得他的主要贡献在于出发点十分新颖，就在大家都认为脱壳方向已经被讨论得差不多的时候，能够另辟蹊径从IAT出发，合理的运用各种已知的成果。最终达到非常好的效果，这是非常难得的。另外关于这篇论文里面所提到的各种关于脱壳方面的知识，对于逆向人员来说也是一个非常不错的参考。对于文章里唯一有点不解的地方在于内核的hook，具体为如何去做这个Hook，要不要载原dll，参数怎么改，能写得更清楚就好了。另外有一点疑惑在于，如果一个壳故意的通过原IAT进行伪造的函数调用，那么，在检测到这种IAT调用时，可能原代码并未解密，那么这种情况我觉得论文里面没有很好的阐述，只是提到只要需要多次检测，但是检测只是发生在IAT切换的时候，伪造调用时发现IAT切换，但是代码并未解密，而后IAT不会切换，那么，何时进行检测呢？ ​ 转载于GoSSIP","content":"<h1 id=\"Abstract\"><a href=\"#Abstract\" class=\"headerlink\" title=\"Abstract\"></a>Abstract</h1><p>windows的软件脱壳本来已经在多年前已经被讨论得非常多了，目前安全学术会议上关于脱壳的论文非常少，然而这篇关于脱壳的论文还能在2018年被CCS所录取，足见他的方法之高效。此前关于脱壳的方法大多是跟踪脱壳时期的内存代码写入执行的变化，从而跟踪被加密代码的解密流程从而追溯到OEP。这也是对于分析脱壳的一个最为直观的方法，<strong><em>在这篇论文里作者提出来通过跟踪IAT(函数导入表)被恢复和引用的情况来追溯OEP，并且达到很理想的效果。作者将这款工具称为BinUnpack。</em></strong></p>\n<table>\n<thead>\n<tr>\n<th>relevant information</th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><em>作者</em></td>\n<td>Binlin Cheng , Jiang Ming, Jianming Fu, Guojun Peng, Ting Chen, Xiaosong Zhang , Jean-Yves Marion</td>\n</tr>\n<tr>\n<td><em>单位</em></td>\n<td>Wuhan University , Hubei Normal University, University of Texas at Arlington, University of Electronic Science and Technology of China, LORIA</td>\n</tr>\n<tr>\n<td><em>出处</em></td>\n<td>ACM CCS’18</td>\n</tr>\n<tr>\n<td><em>原文地址</em></td>\n<td><a href=\"https://github.com/wtwofire/database/blob/master/papers/reverse/2018-Towards%20Paving%20the%20Way%20for%20Large-Scale%20Windows%20Malware%20Analysis%20Generic%20Binary%20Unpacking%20With%20Orders-of-Magnitude%20Performance%20Boost.pdf\" target=\"_blank\" rel=\"noopener\">https://github.com/wtwofire/database/blob/master/papers/reverse/2018-Towards%20Paving%20the%20Way%20for%20Large-Scale%20Windows%20Malware%20Analysis%20Generic%20Binary%20Unpacking%20With%20Orders-of-Magnitude%20Performance%20Boost.pdf</a></td>\n</tr>\n<tr>\n<td><em>源码地址</em></td>\n<td></td>\n</tr>\n<tr>\n<td><em>发表时间</em></td>\n<td>2018年</td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"IAT在脱壳中角色\"><a href=\"#IAT在脱壳中角色\" class=\"headerlink\" title=\"IAT在脱壳中角色\"></a>IAT在脱壳中角色</h1><p>IAT即为PE文件中的函数地址导入表，加壳软件会在对一个软件进行加壳时将IAT抹去，然后在运行解密时通过LoadLibrary和GetProcess两函数或者功能相同的函数再恢复，最后将控制权移交OEP。解密代码为了满足自身需要，通常也有一个自己的IAT，但是与原IAT位置并不在同一内存区域中，通常这个IAT的导入函数个数也要小得多，甚至只有一两个。作者的思路是，一旦某个函数调用是通过原IAT进行的，那么就表明这个时候，原代码已经完成了解密，这个时候往前回溯，即可找到OEP。</p>\n<h1 id=\"Anti-Hook\"><a href=\"#Anti-Hook\" class=\"headerlink\" title=\"Anti-Hook\"></a>Anti-Hook</h1><p>为了跟踪函数的调用情况，hook是必不可少的，然而现在的加壳软件大多会检测函数hook并且存在许多反hook机制，这里记录一下加壳软件中用到的anti-hook方法。</p>\n<p>首先Hook分为内核hook与用户层Hook,由于现在恶意软件想要加载内核模块越发困难，所以作者并没有考虑内核hook情况，这篇论文里，作者假设内核是安全的，未被加壳软件所修改。</p>\n<p>用户层Hook分为以下几种：</p>\n<ol>\n<li>Stolen code. 即将所需要调用的函数代码从内存或者直接从文件系统中复制出来单独执行，这样.inlinehooke,iat,eat类型的Hook全部失效。</li>\n<li>Child process,process hollowing.将脱壳行为分解到两个进程中进行，这样由于进程地址空间隔离，父进程hook全部失效。</li>\n<li>Crash hooking module. 给api函数故意传入错误的参数，如果函数被Hook,则不能正确处理错误而程序崩溃 ，没有被Hook则能正确处理异常。以此可以检测是否被hook。</li>\n<li>Integrity check. 使用哈希校验所调用模块的完整性。</li>\n</ol>\n<h1 id=\"Anti-anti-hook\"><a href=\"#Anti-anti-hook\" class=\"headerlink\" title=\"Anti-anti-hook\"></a>Anti-anti-hook</h1><p>作者设计了一个内核用户态混合的dll劫持系统来完成对函数的hook。作者通过逆向Loadlibrary发现，在内核中它最终需要将dll映射到进程的地址空间，而使用的内核函数是LdrMapDll。函数流程如下：</p>\n<p><img src=\"/2019/02/14/Towards-Paving-the-Way-for-Large-Scale-Windows-Malware-Analysis-Generic-Binary-Unpacking-With-Orders-of-Magnitude-Performance-Boost/1.png\" alt=\"\"></p>\n<p>作者修改内核使得NtMapViewOfSection加载定制的Hook版本dll，同时使得返回值变为STATUS_IMAGE_NOT_AT_BASE。这样第16行的NtMapViewOfSection也会被执行，这样定制的dll被加载进内存。另外有些加壳作者并不使用内存映射进行加载dll，而是使用读取文件如readfile读取dll，复制到内存，这样作者同样修改内存中这部分代码，使得加载的dll为定制的dll。</p>\n<p>这样做能防住上述的提到的几种方法的anti-hook：</p>\n<ol>\n<li>Stolen code. 由于被加载时已经是被定制的dll，或者从文件系统读时都是被定制的dll，所以stolen code复制的代码依然是改变后的hook代码。</li>\n<li>Child process,process hollowing. 同理，修改内核对于每个进程都生效。</li>\n<li>Crash hooking module。这点作者认为正确处理了异常，存疑。</li>\n<li>Integrity check。作者说借鉴使用了一种别人的方法，使得读取dll时读到的内容为原dll，执行时执行的是定制的dll，具体方法待研究。</li>\n</ol>\n<h1 id=\"Find-OEP\"><a href=\"#Find-OEP\" class=\"headerlink\" title=\"Find OEP\"></a>Find OEP</h1><p><img src=\"/2019/02/14/Towards-Paving-the-Way-for-Large-Scale-Windows-Malware-Analysis-Generic-Binary-Unpacking-With-Orders-of-Magnitude-Performance-Boost/2.png\" alt=\"\"></p>\n<p>在结合了IAT与dll hijacking之后，寻找OEP的过程可以用上图来进行表示，首先进程加载时，加载的dll，包括系统dll，如Kernel32.dll,user32.dll等都被换成了作者定制的带hook版本。脱壳时一旦检测到某个函数调用来自原IAT，则进行回溯查找OEP及内存dump。由于可能存在加多个壳情况，即可能会更换IAT，但是这个IAT并不属于最开始被加壳的程序而是属于内层壳，这里作者的作法是，当切换IAT时则进行dump和回溯操作。</p>\n<p><img src=\"/2019/02/14/Towards-Paving-the-Way-for-Large-Scale-Windows-Malware-Analysis-Generic-Binary-Unpacking-With-Orders-of-Magnitude-Performance-Boost/3.png\" alt=\"\"></p>\n<h1 id=\"评估\"><a href=\"#评估\" class=\"headerlink\" title=\"评估\"></a>评估</h1><p>实验环境：laptop with an Intel Core i3-36100 processor (Quad Core,3.70GHz) and 8GB memory, running Windows 7.</p>\n<p>作者使用VirusTotal检测结果来作为脱壳效果的检测结果。即对于一个不加壳的恶意软件，VirusTotal检测结果为n，被脱壳的检测结果越接近n则说明脱壳效果越好。</p>\n<p>作者利用一款未被加壳的恶意软件hupigon.eyf，并用不同的壳对他进行加密，然后使用CoDisasm, PinDemonium, Arancino, BinUnpack四款脱壳工具进行脱壳。结果送VirusTotal进行检测，并记录脱壳所用到的时间。</p>\n<p><img src=\"/2019/02/14/Towards-Paving-the-Way-for-Large-Scale-Windows-Malware-Analysis-Generic-Binary-Unpacking-With-Orders-of-Magnitude-Performance-Boost/4.png\" alt=\"\"></p>\n<p>从图中可以看到，BinUpack的检测结果要远远高于其他三种脱壳工具。另外脱壳所用的到时间也缩短了一两个数量级。对于同一个软件加多个不同的壳，BinUpack的表现依然很出色，脱壳时间始终小于1s。而面对商业强壳Themida时，BinUnpack表现依然良好，VirusTotal检测结果能达到33，34这个级别，而其他三种壳都没有脱壳成功。</p>\n<p>最后作者收集了271095个恶意软件进行测试，依然表现不俗。</p>\n<h1 id=\"评价\"><a href=\"#评价\" class=\"headerlink\" title=\"评价\"></a>评价</h1><p>这篇论文对于脱壳来说实在是一篇不可多得好的好文。我觉得他的主要贡献在于出发点十分新颖，就在大家都认为脱壳方向已经被讨论得差不多的时候，能够另辟蹊径从IAT出发，合理的运用各种已知的成果。最终达到非常好的效果，这是非常难得的。另外关于这篇论文里面所提到的各种关于脱壳方面的知识，对于逆向人员来说也是一个非常不错的参考。对于文章里唯一有点不解的地方在于内核的hook，具体为如何去做这个Hook，要不要载原dll，参数怎么改，能写得更清楚就好了。另外有一点疑惑在于，如果一个壳故意的通过原IAT进行伪造的函数调用，那么，在检测到这种IAT调用时，可能原代码并未解密，那么这种情况我觉得论文里面没有很好的阐述，只是提到只要需要多次检测，但是检测只是发生在IAT切换的时候，伪造调用时发现IAT切换，但是代码并未解密，而后IAT不会切换，那么，何时进行检测呢？</p>\n<p>​                                                                            <strong><em>转载于GoSSIP</em></strong></p>\n","categories":[{"name":"论文","slug":"论文","permalink":"http://yama0xff.com/categories/论文/"},{"name":"软件分析","slug":"论文/软件分析","permalink":"http://yama0xff.com/categories/论文/软件分析/"}],"tags":[{"name":"2018年","slug":"2018年","permalink":"http://yama0xff.com/tags/2018年/"},{"name":"ACM CCS'18","slug":"ACM-CCS-18","permalink":"http://yama0xff.com/tags/ACM-CCS-18/"},{"name":"脱壳","slug":"脱壳","permalink":"http://yama0xff.com/tags/脱壳/"}]},{"title":"HEAPHOPPER: Bringing Bounded Model Checking to Heap Implementation Security","date":"2019-02-14T02:01:28.000Z","path":"2019/02/14/HEAPHOPPER-Bringing-Bounded-Model-Checking-to-Heap-Implementation-Security/","text":"Abstract堆元数据攻击已成为攻击者利用内存损坏漏洞的主要方式之一。虽然堆实现开发人员已经引入了缓解来防止和检测损坏，但攻击者仍然可以解决这些问题。在某种程度上，这是因为这些缓解是在没有原则基础的情况下创建和评估的，因此在许多情况下会导致堆元数据防御的复杂，低效和无效尝试。在本文中，我们提出了HEAPHOPPER，一种基于模型检查和符号执行的自动化方法，用于分析存在内存损坏时堆实现的可利用性。使用HEAPHOPPER，我们能够对不同的，广泛使用的堆实现进行系统分析，找到它们中令人惊讶的弱点。例如，我们的结果显示了ptmalloc中新引入的缓存机制（大多数Linux发行版使用的堆分配器实现）如何显著削弱其安全性。此外，HEAPHOPPER指导我们实施和评估对ptmalloc安全性的改进，用有效防御替代最近无效的缓解特定形式的堆元数据损坏的尝试。 relevant information 作者 Moritz Eckert , Antonio Bianchi, Ruoyu Wang, Yan Shoshitaishvili , Christopher Kruegel , and Giovanni Vigna 单位 University of California, Santa Barbara, The University of Iowa, Arizona State University 出处 USENIX Security‘18 原文地址 https://github.com/wtwofire/database/blob/master/papers/exploitation/2018-HEAPHOPPER%20Bringing%20Bounded%20Model%20Checking%20to%20Heap%20Implementation%20Security.pdf 源码地址 https://github.com/angr/heaphopper 发表时间 2018年 简介作者通过使用符号执行技术，自动化分析堆分配器，根据配置文件定义的情况可以自动生成不同exploitation primitive 的POC 背景当程序逻辑存在漏洞时可以攻击堆分配器拿到程序控制权。为了缓解这些攻击，各大堆分配器都在内部进行了安全检查，然而并没有一个标准能评估加入一个补丁是否能缓解攻击。 以glibc的补丁为例 1234567 /* Take a chunk off a bin list */ #define unlink(AV, P, BK, FD) &#123; \\+ if (__builtin_expect (chunksize(P) != prev_size (next_chunk(P)), 0)) \\+ malloc_printerr (check_action, \"corrupted size vs. prev_size\", P, AV); \\ FD = P-&gt;fd; \\ BK = P-&gt;bk; \\ if (__builtin_expect (FD-&gt;bk != P || BK-&gt;fd != P, 0)) 补丁作者加入了一个对size的检查，然而这可以被轻松的绕过，具体利用见 poison_null_byte.c 因此作者通过符号执行技术对堆的交互进行了建模，从而可以自动化的评估堆分配器在特定情况下达到exploitation primitive的条件。 生成堆交互模型堆事务作者将会修改堆的状态的操作定义为事务，对堆的交互分为两种：直接交互和间接交互 直接交互指分配器功能，如malloc，free 间接交互指修改分配的内存区域，比如overflow malloc(M)HEAPHOPPER 通过传递一个符号化变量对malloc申请的大小进行建模。 一个不可约束的值可能会导致路径爆炸和约束复杂，因此将大小设置为了一个具体的范围，因此符号执行单元将会使用symbolic-but-constrained 变量作为传递给malloc的参数。 通常根据堆分配器不同的执行路径来确定大小，作者开发了一个工具根据libc的执行路径来确定大小选择（然而并没有看见这个工具，源码里面也有提及）。 free(F)如果之前执行过多个malloc事务，HEAPHOPPER将会生成一个不同的序列将其中的每一个作为free事务的参数 overflow(O)在模型中，一个overflow代表一个和堆的间接的交互。作者通过在malloc出的chunk的末尾插入符号内存来实现overflow。和free事务类似，HEAPHOPPER将会为先前分配的chunk创建一个不同的序列作为overflow的目标。和malloc同样的原因，需要限制溢出的长度。在这将会把overflow的大小作为symbolic-but-constrained 处理。HEAPHOPPER 还支持根据不同的场景将overflow的字节设定为特定的范围。 use-after-free (UAF)我们通过将符号内存写入已经free的chunk作为UAF事务。和之前的事务相似，HEAPHOPPER需要为之前free过的chunk创建一个不同的序列，将有限的字节的数据写到内存中。 double-free (DF)double-free被建模为对之前释放过的内存执行free fake-free (FF)fake-free是释放一个假的，攻击者自定义的chunk。它被建模为free一个完全符号化的内存区域。这个符号化区域的大小必须有个限制。如果可能的话，符号执行单元将会自动确定符号区域的值能通过堆分配器的检查。 堆交互模型HEAPHOPPER 将结合之前描述的堆事务生成一个交互列表，每个交互对应着堆模型的一条路径。HEAPHOPPER 通过创建所有可能的事务序列的排列来生成交互列表。 在这一步主要关注如何减少生成的事务序列而不丢失会导致产生exploitation primitives 的事务序列。因此，我们假设至少一次对堆进行了误操作（直接或间接），并且假设对堆的良性使用不会产生任何问题。此外，还排除了只有一个间接交互作为事务序列结束的情况，因为间接交互无法修改堆本身，修改堆本身至少需要一个直接交互。两个会对同一区域放置符号内存的的事务之间必须有影响这片内存的事务。 模型检测识别安全违规行为Overlapping Allocation (OA)HEAPHOPPER 使用 SMT求解程序去判断如下条件是否为真 ∃B : ((A ≤ B)∧(A+sizeof(A) &gt; B))∨((A ≥ B)∧(B+sizeof(B) &gt; A)) A为申请的内存，B为已申请的内存 Non-Heap Allocation (NHA)提前记录堆分配器使用brk和mmap返回的地址，从而确定堆的范围 Arbitrary Write (AW and AWC)在调用malloc，free时通过检测符号内存区域是否有写入来判断是否有AW或AWC。具体来说,我们查询约束求解器检查是否可以指定的写入特定的内存区域。 局限性模型限制当前情况下需要手动指定攻击者可以执行的事务。HEAPHOPPER无法对可能发生但是HEAPHOPPER中没有实现的攻击场景进行推理。之前为了减少符号执行样本的数量加入了一些限制条件，这可能会导致HEAPHOPPER错过一些利用。其次一些攻击需要执行很多事务才能把堆设置为理想的状态","content":"<h1 id=\"Abstract\"><a href=\"#Abstract\" class=\"headerlink\" title=\"Abstract\"></a>Abstract</h1><p>堆元数据攻击已成为攻击者利用内存损坏漏洞的主要方式之一。虽然堆实现开发人员已经引入了缓解来防止和检测损坏，但攻击者仍然可以解决这些问题。在某种程度上，这是因为这些缓解是在没有原则基础的情况下创建和评估的，因此在许多情况下会导致堆元数据防御的复杂，低效和无效尝试。<strong><em>在本文中，我们提出了HEAPHOPPER，一种基于模型检查和符号执行的自动化方法，用于分析存在内存损坏时堆实现的可利用性。</em></strong>使用HEAPHOPPER，我们能够对不同的，广泛使用的堆实现进行系统分析，找到它们中令人惊讶的弱点。例如，我们的结果显示了ptmalloc中新引入的缓存机制（大多数Linux发行版使用的堆分配器实现）如何显著削弱其安全性。此外，HEAPHOPPER指导我们实施和评估对ptmalloc安全性的改进，用有效防御替代最近无效的缓解特定形式的堆元数据损坏的尝试。</p>\n<table>\n<thead>\n<tr>\n<th>relevant information</th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><em>作者</em></td>\n<td>Moritz Eckert , Antonio Bianchi, Ruoyu Wang, Yan Shoshitaishvili , Christopher Kruegel , and Giovanni Vigna</td>\n</tr>\n<tr>\n<td><em>单位</em></td>\n<td>University of California, Santa Barbara, The University of Iowa, Arizona State University</td>\n</tr>\n<tr>\n<td><em>出处</em></td>\n<td>USENIX Security‘18</td>\n</tr>\n<tr>\n<td><em>原文地址</em></td>\n<td><a href=\"https://github.com/wtwofire/database/blob/master/papers/exploitation/2018-HEAPHOPPER%20Bringing%20Bounded%20Model%20Checking%20to%20Heap%20Implementation%20Security.pdf\" target=\"_blank\" rel=\"noopener\">https://github.com/wtwofire/database/blob/master/papers/exploitation/2018-HEAPHOPPER%20Bringing%20Bounded%20Model%20Checking%20to%20Heap%20Implementation%20Security.pdf</a></td>\n</tr>\n<tr>\n<td><em>源码地址</em></td>\n<td><a href=\"https://github.com/angr/heaphopper\" target=\"_blank\" rel=\"noopener\">https://github.com/angr/heaphopper</a></td>\n</tr>\n<tr>\n<td><em>发表时间</em></td>\n<td>2018年</td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h1><p>作者通过使用符号执行技术，自动化分析堆分配器，根据配置文件定义的情况可以自动生成不同exploitation primitive 的POC</p>\n<p><img src=\"/2019/02/14/HEAPHOPPER-Bringing-Bounded-Model-Checking-to-Heap-Implementation-Security/1.png\" alt=\"\"></p>\n<h1 id=\"背景\"><a href=\"#背景\" class=\"headerlink\" title=\"背景\"></a>背景</h1><p>当程序逻辑存在漏洞时可以攻击堆分配器拿到程序控制权。为了缓解这些攻击，各大堆分配器都在内部进行了安全检查，然而并没有一个标准能评估加入一个补丁是否能缓解攻击。</p>\n<p>以glibc的补丁为例</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"> <span class=\"comment\">/* Take a chunk off a bin list */</span></span><br><span class=\"line\"> <span class=\"meta\">#<span class=\"meta-keyword\">define</span> unlink(AV, P, BK, FD) &#123;                                            \\</span></span><br><span class=\"line\">+    <span class=\"keyword\">if</span> (__builtin_expect (chunksize(P) != prev_size (next_chunk(P)), <span class=\"number\">0</span>))      \\</span><br><span class=\"line\">+      malloc_printerr (check_action, <span class=\"string\">\"corrupted size vs. prev_size\"</span>, P, AV);  \\</span><br><span class=\"line\">     FD = P-&gt;fd;                                                                      \\</span><br><span class=\"line\">     BK = P-&gt;bk;                                                                      \\</span><br><span class=\"line\">     <span class=\"keyword\">if</span> (__builtin_expect (FD-&gt;bk != P || BK-&gt;fd != P, <span class=\"number\">0</span>))</span><br></pre></td></tr></table></figure>\n<p>补丁作者加入了一个对size的检查，然而这可以被轻松的绕过，具体利用见</p>\n<p><a href=\"https://github.com/shellphish/how2heap/blob/master/glibc_2.26/poison_null_byte.c\" target=\"_blank\" rel=\"noopener\">poison_null_byte.c</a></p>\n<p>因此作者通过符号执行技术对堆的交互进行了建模，从而可以自动化的评估堆分配器在特定情况下达到exploitation primitive的条件。</p>\n<h1 id=\"生成堆交互模型\"><a href=\"#生成堆交互模型\" class=\"headerlink\" title=\"生成堆交互模型\"></a>生成堆交互模型</h1><h2 id=\"堆事务\"><a href=\"#堆事务\" class=\"headerlink\" title=\"堆事务\"></a>堆事务</h2><p>作者将会修改堆的状态的操作定义为事务，对堆的交互分为两种：直接交互和间接交互</p>\n<p>直接交互指分配器功能，如malloc，free</p>\n<p>间接交互指修改分配的内存区域，比如overflow</p>\n<h3 id=\"malloc-M\"><a href=\"#malloc-M\" class=\"headerlink\" title=\"malloc(M)\"></a>malloc(M)</h3><p>HEAPHOPPER 通过传递一个符号化变量对malloc申请的大小进行建模。</p>\n<p>一个不可约束的值可能会导致路径爆炸和约束复杂，因此将大小设置为了一个具体的范围，因此符号执行单元将会使用symbolic-but-constrained 变量作为传递给malloc的参数。</p>\n<p>通常根据堆分配器不同的执行路径来确定大小，作者开发了一个工具根据libc的执行路径来确定大小选择（然而并没有看见这个工具，源码里面也有提及）。</p>\n<h3 id=\"free-F\"><a href=\"#free-F\" class=\"headerlink\" title=\"free(F)\"></a>free(F)</h3><p>如果之前执行过多个malloc事务，HEAPHOPPER将会生成一个不同的序列将其中的每一个作为free事务的参数</p>\n<h3 id=\"overflow-O\"><a href=\"#overflow-O\" class=\"headerlink\" title=\"overflow(O)\"></a>overflow(O)</h3><p>在模型中，一个overflow代表一个和堆的间接的交互。作者通过在malloc出的chunk的末尾插入符号内存来实现overflow。和free事务类似，HEAPHOPPER将会为先前分配的chunk创建一个不同的序列作为overflow的目标。和malloc同样的原因，需要限制溢出的长度。在这将会把overflow的大小作为symbolic-but-constrained 处理。HEAPHOPPER 还支持根据不同的场景将overflow的字节设定为特定的范围。</p>\n<h3 id=\"use-after-free-UAF\"><a href=\"#use-after-free-UAF\" class=\"headerlink\" title=\"use-after-free (UAF)\"></a>use-after-free (UAF)</h3><p>我们通过将符号内存写入已经free的chunk作为UAF事务。和之前的事务相似，HEAPHOPPER需要为之前free过的chunk创建一个不同的序列，将有限的字节的数据写到内存中。</p>\n<h3 id=\"double-free-DF\"><a href=\"#double-free-DF\" class=\"headerlink\" title=\"double-free (DF)\"></a>double-free (DF)</h3><p>double-free被建模为对之前释放过的内存执行free</p>\n<h3 id=\"fake-free-FF\"><a href=\"#fake-free-FF\" class=\"headerlink\" title=\"fake-free (FF)\"></a>fake-free (FF)</h3><p>fake-free是释放一个假的，攻击者自定义的chunk。它被建模为free一个完全符号化的内存区域。这个符号化区域的大小必须有个限制。如果可能的话，符号执行单元将会自动确定符号区域的值能通过堆分配器的检查。</p>\n<h3 id=\"堆交互模型\"><a href=\"#堆交互模型\" class=\"headerlink\" title=\"堆交互模型\"></a>堆交互模型</h3><p>HEAPHOPPER 将结合之前描述的堆事务生成一个交互列表，每个交互对应着堆模型的一条路径。HEAPHOPPER 通过创建所有可能的事务序列的排列来生成交互列表。</p>\n<p>在这一步主要关注如何减少生成的事务序列而不丢失会导致产生exploitation primitives 的事务序列。因此，我们假设至少一次对堆进行了误操作（直接或间接），并且假设对堆的良性使用不会产生任何问题。此外，还排除了只有一个间接交互作为事务序列结束的情况，因为间接交互无法修改堆本身，修改堆本身至少需要一个直接交互。两个会对同一区域放置符号内存的的事务之间必须有影响这片内存的事务。</p>\n<h1 id=\"模型检测\"><a href=\"#模型检测\" class=\"headerlink\" title=\"模型检测\"></a>模型检测</h1><h2 id=\"识别安全违规行为\"><a href=\"#识别安全违规行为\" class=\"headerlink\" title=\"识别安全违规行为\"></a>识别安全违规行为</h2><h3 id=\"Overlapping-Allocation-OA\"><a href=\"#Overlapping-Allocation-OA\" class=\"headerlink\" title=\"Overlapping Allocation (OA)\"></a>Overlapping Allocation (OA)</h3><p>HEAPHOPPER 使用 SMT求解程序去判断如下条件是否为真</p>\n<p>∃B : ((A ≤ B)∧(A+sizeof(A) &gt; B))∨((A ≥ B)∧(B+sizeof(B) &gt; A))</p>\n<p>A为申请的内存，B为已申请的内存</p>\n<h3 id=\"Non-Heap-Allocation-NHA\"><a href=\"#Non-Heap-Allocation-NHA\" class=\"headerlink\" title=\"Non-Heap Allocation (NHA)\"></a>Non-Heap Allocation (NHA)</h3><p>提前记录堆分配器使用brk和mmap返回的地址，从而确定堆的范围</p>\n<h3 id=\"Arbitrary-Write-AW-and-AWC\"><a href=\"#Arbitrary-Write-AW-and-AWC\" class=\"headerlink\" title=\"Arbitrary Write (AW and AWC)\"></a>Arbitrary Write (AW and AWC)</h3><p>在调用malloc，free时通过检测符号内存区域是否有写入来判断是否有AW或AWC。具体来说,我们查询约束求解器检查是否可以指定的写入特定的内存区域。</p>\n<h1 id=\"局限性\"><a href=\"#局限性\" class=\"headerlink\" title=\"局限性\"></a>局限性</h1><h2 id=\"模型限制\"><a href=\"#模型限制\" class=\"headerlink\" title=\"模型限制\"></a>模型限制</h2><p>当前情况下需要手动指定攻击者可以执行的事务。HEAPHOPPER无法对可能发生但是HEAPHOPPER中没有实现的攻击场景进行推理。之前为了减少符号执行样本的数量加入了一些限制条件，这可能会导致HEAPHOPPER错过一些利用。其次一些攻击需要执行很多事务才能把堆设置为理想的状态</p>\n","categories":[{"name":"论文","slug":"论文","permalink":"http://yama0xff.com/categories/论文/"},{"name":"自动化利用","slug":"论文/自动化利用","permalink":"http://yama0xff.com/categories/论文/自动化利用/"}],"tags":[{"name":"2018年","slug":"2018年","permalink":"http://yama0xff.com/tags/2018年/"},{"name":"exploitation","slug":"exploitation","permalink":"http://yama0xff.com/tags/exploitation/"},{"name":"heap","slug":"heap","permalink":"http://yama0xff.com/tags/heap/"},{"name":"符号执行","slug":"符号执行","permalink":"http://yama0xff.com/tags/符号执行/"},{"name":"USENIX'18","slug":"USENIX-18","permalink":"http://yama0xff.com/tags/USENIX-18/"}]},{"title":"Check It Again: Detecting Lacking-Recheck Bugs in OS Kernels","date":"2019-02-05T11:05:47.000Z","path":"2019/02/05/Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels/","text":"Abstract论文中，作者主要介绍分析操作系统内核中的LRC（lacking-recheck）类型bug。并介绍了自己设计的一个静态分析系统LRSan（在Linux上实现），用于检测操作系统内核中的LRC bug。本文的主要贡献： 1. 定义了LRC bugs，并第一次展示了关于LRC bug的深入研究。 2. 实现一个自动化的LRC bug检测系统（LRSan），基于LLVM，使用在Linux内核上，可以检测内核中的LRC bug。LRSan运用了很多新的程序静态分析技术。结果显示LRSan在Linux内核发现了2808个LRC case，检测耗时为4小时。并且作者会将它开源。 3. 识别Security check（SC）和相关Critical variable（CV）的方法。 4. 发现了Linux内核中的19个新的LRC bug。 relevant information 作者 Wenwen Wang, Kangjie Lu, and Pen-Chung Yew 单位 University of Minnesota 出处 ACM CCS’18 原文地址 源码地址 发表时间 2018年 1. 简介如下图所示是LRC Bug形成的流程。 如下图所示是一个LRC Bug的例子，其中的val就是CV。在第10行中val被进行了security check，但是在第16至19行中val被进行了修改，在第22行中val又被使用了，然而在使用前没有进行recheck。 LRC bug的特点： – 拥有一个check-use chain。即执行路径中有对变量进行安全检查，并在之后对变量进行使用。 – 变量有被修改的可能. 变量在过了前面的security check后，在check-use chain中被修改。 – 缺少recheck。在变量过了安全检查后，如果在使用前又进行了安全检查，那即是在中间被修改了，也是安全的。因此缺少recheck也是LRC bug的成因之一。 作者在文章中还具体符号化定义了Security check、Use、Modification、Lacking recheck。 1.1 Security checkSecurity check需要满足两个条件（作者通过观察总结的规律）才能被认定为是Security check： – 拥有一个条件语句，紧随其后的是两个分支： 12一个分支肯定会返回error code（condition 1）另一个分支有可能不返回error code（condition 2） 1.2 Modification1在执行路径上，通常变量的的security check和使用是比较复杂也可能比较远的，尤其是在处理涉及到用户空间和内核空间的多个变量时，因此LRC Bug在操作系统内核中是很常见的。 对security-checked变量的修改可能由如下一些情况导致： 1. Kernel race：操作系统内核通常为线程进程维护了很多共享的数据结构。通常来说很难保证Security checked variable不被修改。 2. User race：从用户空间抓取数据通常很容易被通过用户空间的多进程来进行修改。 3. Logic errors：一些逻辑问题可能导致线程本身不正确地将security-checked variable给修改了。 4. Semantic errors：例如类型转换和整数溢出的一些语义错误可能导致security-checked variable被修改。 2. LRSan设计LRSan的整个结构和Workflow如下图所示，输入为内核源码编译后的LLVM IR。LRSan预处理时会构建一个全局的call-graph，用来进行inter-procedural analysis，并且标注了error codes。 LRsan设计的4个关键部分： 1. Security check identification 2. Critical variable inference 3. check-use chain construction 4. modification inference。 2.1 Automated Security Check Identification作者将security check认为是一个条件语句（例如if语句）。因此检测Secruity check就是查找这样的条件语句。 搜集所有的error code，构建一个error-code CFG（ECFG），ECFG可以快速地判断出某一个执行路径是否会返回error code。ECFG的示例如下图所示。 通过前面提到的两个判断Security check的条件，来决定找到的条件语句是否是Security check。 2.2 Recursive Critical Variable Inference在前面的步骤中可以得到一个Security check set，通过这个set能直接得到Critcal variable set(CSet)，然后再通过CSet去找到更多的CV，查找的原则是越多越好（更少的假阴性，这里用的是反向的污点分析）。 例如下图，hdr是最先找到的CV，然后又将arg和buf都标记为CV。 查找终止的条件是在寻找的过程中中碰到了hard-to-track values，例如全局变量，堆上的对象，用户空间的对象，这些可能是来自shared data，external source，如果把这些也标记上，会使得查找更加困难。 2.3 Check-Use Chain Construction这一步为CSet中的每个变量构建Check-use chain。Check-use chain可以用一个四元组来表示&lt;SC, CV , Iu , PSet&gt;。 Iu：CV在SC后的第一次使用 PSet：SC后的一系列执行路径（到Iu结束） 构建Check-use chain的方法：污点追踪找到Iu，遍历CFG去收集一系列从SC开始，Iu结束的执行路径，这些执行路径的结果记为PSet。 这里还使用了LLVM里的Alias analysis来寻找一些隐式的use 2.4 Modification Analysis在找到了Check-use chain &lt;SC, CV , I u , PSet&gt;后，这一步的目的是识别潜在的对CV的修改（Check-use chain里找）。 主要检测的修改操作： 1. CV被修改成了一个新的值，通过一个普通的store指令 2. CV被例如memcpy或者copy_from_user等函数进行了修改。 如果找到了这样的修改，LRSan会再进一步检测这次修改之后是否有有critical variable进行recheck。最后将没有recheck的情况就认定为是LRC case。 3. LRSan实现作者基于LLVM 6.0.0实现了LRSan。整个实现中包括两个独立的pass（大约3000行代码）。First pass是用来收集和准备静态分析锁需要的信息，例如构建global CFG，alias results。Second pass是用来进行静态分析检测LRC case的。 作者成功编译了16593个module，只有6个编译失败了。 过滤部分false positive： 1. CV被修改成的是一个常量 2. CV被修改成的是一个可以过Security check的变量 3. mutex-style check 4. 评估4.1 Effectiveness如下图所示是LRSan检测后导出的检测结果。 如下图所示，是LRSan在Linux kernel里找到的19个LRC bug。 4.2 EfficienyLRSan测试时所用的LLVM IR是用Linux-4.17的源码编译的。作者实验时用的host为一个主存32G的Ubuntu16.04，Quad-Core 3.5 GHz Intel Xeon E5-1620 v4处理器，总共用了4个小时。其中超过80%的时间都是用在first pass（例如信息收集），因为first pass需要构建一个全局的CFG，并收集alias-analysis results。first pass实际上只需要运行一次，因此可以对它的结果进行重用，从而节省时间。 5. Limitation5.1 False Positives Checked modification，符号执行来过滤 Satisfiable modification，符号执行来过滤 Uncontrollable modification，污点追踪来过滤 Transient check，作者手工排查 Unconfirmed race：source variable是一个shared variable（例如全局变量），即有可能被其他的线程进程修改，这是作者未来的工作 Other：静态分析的一些缺陷导致的false positives 5.2 False Negatives作者在查找security check时是基于失败后会返回error code，但是也有可能不返回error code。另外编译失败的一些kernel module也可能导致False negatives。","content":"<h1 id=\"Abstract\"><a href=\"#Abstract\" class=\"headerlink\" title=\"Abstract\"></a>Abstract</h1><p>论文中，作者主要介绍分析操作系统内核中的LRC（lacking-recheck）类型bug。并介绍了自己设计的一个静态分析系统LRSan（在Linux上实现），用于检测操作系统内核中的LRC bug。<strong><em>本文的主要贡献： 1. 定义了LRC bugs，并第一次展示了关于LRC bug的深入研究。 2. 实现一个自动化的LRC bug检测系统（LRSan），基于LLVM，使用在Linux内核上，可以检测内核中的LRC bug。LRSan运用了很多新的程序静态分析技术。结果显示LRSan在Linux内核发现了2808个LRC case，检测耗时为4小时。并且作者会将它开源。 3. 识别Security check（SC）和相关Critical variable（CV）的方法。 4. 发现了Linux内核中的19个新的LRC bug。</em></strong></p>\n<table>\n<thead>\n<tr>\n<th>relevant information</th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><em>作者</em></td>\n<td>Wenwen Wang, Kangjie Lu, and Pen-Chung Yew</td>\n</tr>\n<tr>\n<td><em>单位</em></td>\n<td>University of Minnesota</td>\n</tr>\n<tr>\n<td><em>出处</em></td>\n<td>ACM CCS’18</td>\n</tr>\n<tr>\n<td><em>原文地址</em></td>\n<td></td>\n</tr>\n<tr>\n<td><em>源码地址</em></td>\n<td></td>\n</tr>\n<tr>\n<td><em>发表时间</em></td>\n<td>2018年</td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"1-简介\"><a href=\"#1-简介\" class=\"headerlink\" title=\"1. 简介\"></a>1. 简介</h1><p>如下图所示是LRC Bug形成的流程。</p>\n<p><img src=\"/2019/02/05/Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels/E:/github\\hexo\\source\\_posts\\Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels\\1.jpg\" alt=\"\"></p>\n<p>如下图所示是一个LRC Bug的例子，其中的val就是<em>CV</em>。在第10行中val被进行了security check，但是在第16至19行中val被进行了修改，在第22行中val又被使用了，然而在使用前没有进行recheck。</p>\n<p><img src=\"/2019/02/05/Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels/E:/github\\hexo\\source\\_posts\\Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels\\2.jpg\" alt=\"\"></p>\n<p>LRC bug的特点： – 拥有一个check-use chain。即执行路径中有对变量进行安全检查，并在之后对变量进行使用。 – 变量有被修改的可能. 变量在过了前面的security check后，在check-use chain中被修改。 – 缺少recheck。在变量过了安全检查后，如果在使用前又进行了安全检查，那即是在中间被修改了，也是安全的。因此缺少recheck也是LRC bug的成因之一。</p>\n<p>作者在文章中还具体符号化定义了Security check、Use、Modification、Lacking recheck。</p>\n<h2 id=\"1-1-Security-check\"><a href=\"#1-1-Security-check\" class=\"headerlink\" title=\"1.1 Security check\"></a>1.1 Security check</h2><p>Security check需要满足两个条件（作者通过观察总结的规律）才能被认定为是Security check： – 拥有一个条件语句，紧随其后的是两个分支：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">一个分支肯定会返回error code（condition 1）</span><br><span class=\"line\">另一个分支有可能不返回error code（condition 2）</span><br></pre></td></tr></table></figure>\n<h2 id=\"1-2-Modification1\"><a href=\"#1-2-Modification1\" class=\"headerlink\" title=\"1.2 Modification1\"></a>1.2 Modification1</h2><p>在执行路径上，通常变量的的security check和使用是比较复杂也可能比较远的，尤其是在处理涉及到用户空间和内核空间的多个变量时，因此LRC Bug在操作系统内核中是很常见的。</p>\n<p>对security-checked变量的修改可能由如下一些情况导致： 1. Kernel race：操作系统内核通常为线程进程维护了很多共享的数据结构。通常来说很难保证Security checked variable不被修改。 2. User race：从用户空间抓取数据通常很容易被通过用户空间的多进程来进行修改。 3. Logic errors：一些逻辑问题可能导致线程本身不正确地将security-checked variable给修改了。 4. Semantic errors：例如类型转换和整数溢出的一些语义错误可能导致security-checked variable被修改。</p>\n<h1 id=\"2-LRSan设计\"><a href=\"#2-LRSan设计\" class=\"headerlink\" title=\"2. LRSan设计\"></a>2. LRSan设计</h1><p>LRSan的整个结构和Workflow如下图所示，输入为内核源码编译后的LLVM IR。LRSan预处理时会构建一个全局的call-graph，用来进行inter-procedural analysis，并且标注了error codes。</p>\n<p><img src=\"/2019/02/05/Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels/E:/github\\hexo\\source\\_posts\\Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels\\3.jpg\" alt=\"\"></p>\n<p>LRsan设计的4个关键部分： 1. Security check identification 2. Critical variable inference 3. check-use chain construction 4. modification inference。</p>\n<h2 id=\"2-1-Automated-Security-Check-Identification\"><a href=\"#2-1-Automated-Security-Check-Identification\" class=\"headerlink\" title=\"2.1 Automated Security Check Identification\"></a>2.1 Automated Security Check Identification</h2><p>作者将security check认为是一个条件语句（例如if语句）。因此检测Secruity check就是查找这样的条件语句。</p>\n<ol>\n<li>搜集所有的error code，构建一个error-code CFG（ECFG），ECFG可以快速地判断出某一个执行路径是否会返回error code。ECFG的示例如下图所示。</li>\n<li>通过前面提到的两个判断Security check的条件，来决定找到的条件语句是否是Security check。</li>\n</ol>\n<p><img src=\"/2019/02/05/Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels/E:/github\\hexo\\source\\_posts\\Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels\\4.jpg\" alt=\"\"></p>\n<h2 id=\"2-2-Recursive-Critical-Variable-Inference\"><a href=\"#2-2-Recursive-Critical-Variable-Inference\" class=\"headerlink\" title=\"2.2 Recursive Critical Variable Inference\"></a>2.2 Recursive Critical Variable Inference</h2><p>在前面的步骤中可以得到一个Security check set，通过这个set能直接得到Critcal variable set(CSet)，然后再通过CSet去找到更多的<em>CV</em>，查找的原则是越多越好（更少的假阴性，这里用的是反向的污点分析）。</p>\n<p>例如下图，hdr是最先找到的<em>CV</em>，然后又将arg和buf都标记为<em>CV</em>。</p>\n<p><img src=\"/2019/02/05/Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels/E:/github\\hexo\\source\\_posts\\Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels\\8.jpg\" alt=\"\"></p>\n<p>查找终止的条件是在寻找的过程中中碰到了<strong>hard-to-track values</strong>，例如全局变量，堆上的对象，用户空间的对象，这些可能是来自shared data，external source，如果把这些也标记上，会使得查找更加困难。</p>\n<h2 id=\"2-3-Check-Use-Chain-Construction\"><a href=\"#2-3-Check-Use-Chain-Construction\" class=\"headerlink\" title=\"2.3 Check-Use Chain Construction\"></a>2.3 Check-Use Chain Construction</h2><p>这一步为<em>CSet</em>中的每个变量构建<strong>Check-use chain</strong>。<strong>Check-use chain</strong>可以用一个四元组来表示&lt;<em>SC, CV , Iu , PSet</em>&gt;。</p>\n<p><em>Iu</em>：<em>CV</em>在<em>SC</em>后的第一次使用 <em>PSet</em>：<em>SC</em>后的一系列执行路径（到<em>Iu</em>结束）</p>\n<p>构建<strong>Check-use chain</strong>的方法：污点追踪找到<em>Iu</em>，遍历<strong>CFG</strong>去收集一系列从<em>SC</em>开始，<em>Iu</em>结束的执行路径，这些执行路径的结果记为<em>PSet</em>。</p>\n<p>这里还使用了LLVM里的Alias analysis来寻找一些隐式的use</p>\n<h2 id=\"2-4-Modification-Analysis\"><a href=\"#2-4-Modification-Analysis\" class=\"headerlink\" title=\"2.4 Modification Analysis\"></a>2.4 Modification Analysis</h2><p>在找到了<strong>Check-use chain</strong> &lt;<em>SC, CV , I u , PSet</em>&gt;后，这一步的目的是识别潜在的对<em>CV</em>的修改（<strong>Check-use chain</strong>里找）。</p>\n<p>主要检测的修改操作： 1. <em>CV</em>被修改成了一个新的值，通过一个普通的store指令 2. <em>CV</em>被例如memcpy或者copy_from_user等函数进行了修改。</p>\n<p>如果找到了这样的修改，LRSan会再进一步检测这次修改之后是否有有critical variable进行recheck。最后将没有recheck的情况就认定为是LRC case。</p>\n<h1 id=\"3-LRSan实现\"><a href=\"#3-LRSan实现\" class=\"headerlink\" title=\"3. LRSan实现\"></a>3. LRSan实现</h1><p>作者基于LLVM 6.0.0实现了LRSan。整个实现中包括两个独立的pass（大约3000行代码）。First pass是用来收集和准备静态分析锁需要的信息，例如构建global CFG，alias results。Second pass是用来进行静态分析检测LRC case的。</p>\n<p>作者成功编译了16593个module，只有6个编译失败了。</p>\n<p>过滤部分false positive： 1. <em>CV</em>被修改成的是一个常量 2. <em>CV</em>被修改成的是一个可以过Security check的变量 3. mutex-style check</p>\n<h1 id=\"4-评估\"><a href=\"#4-评估\" class=\"headerlink\" title=\"4. 评估\"></a>4. 评估</h1><h2 id=\"4-1-Effectiveness\"><a href=\"#4-1-Effectiveness\" class=\"headerlink\" title=\"4.1 Effectiveness\"></a>4.1 Effectiveness</h2><p>如下图所示是LRSan检测后导出的检测结果。</p>\n<p><img src=\"/2019/02/05/Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels/E:/github\\hexo\\source\\_posts\\Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels\\5.jpg\" alt=\"\"></p>\n<p>如下图所示，是LRSan在Linux kernel里找到的19个LRC bug。</p>\n<p><img src=\"/2019/02/05/Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels/E:/github\\hexo\\source\\_posts\\Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels\\6.jpg\" alt=\"\"></p>\n<h2 id=\"4-2-Efficieny\"><a href=\"#4-2-Efficieny\" class=\"headerlink\" title=\"4.2 Efficieny\"></a>4.2 Efficieny</h2><p>LRSan测试时所用的LLVM IR是用Linux-4.17的源码编译的。作者实验时用的host为一个主存32G的Ubuntu16.04，Quad-Core 3.5 GHz Intel Xeon E5-1620 v4处理器，总共用了4个小时。其中超过80%的时间都是用在first pass（例如信息收集），因为first pass需要构建一个全局的CFG，并收集alias-analysis results。first pass实际上只需要运行一次，因此可以对它的结果进行重用，从而节省时间。</p>\n<h1 id=\"5-Limitation\"><a href=\"#5-Limitation\" class=\"headerlink\" title=\"5. Limitation\"></a>5. Limitation</h1><h2 id=\"5-1-False-Positives\"><a href=\"#5-1-False-Positives\" class=\"headerlink\" title=\"5.1 False Positives\"></a>5.1 False Positives</h2><ol>\n<li>Checked modification，符号执行来过滤</li>\n<li>Satisfiable modification，符号执行来过滤</li>\n<li>Uncontrollable modification，污点追踪来过滤</li>\n<li>Transient check，作者手工排查</li>\n<li>Unconfirmed race：source variable是一个shared variable（例如全局变量），即有可能被其他的线程进程修改，这是作者未来的工作</li>\n<li>Other：静态分析的一些缺陷导致的false positives</li>\n</ol>\n<p><img src=\"/2019/02/05/Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels/E:/github\\hexo\\source\\_posts\\Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels\\7.jpg\" alt=\"\"></p>\n<h2 id=\"5-2-False-Negatives\"><a href=\"#5-2-False-Negatives\" class=\"headerlink\" title=\"5.2 False Negatives\"></a>5.2 False Negatives</h2><p>作者在查找security check时是基于失败后会返回error code，但是也有可能不返回error code。另外编译失败的一些kernel module也可能导致False negatives。</p>\n","categories":[{"name":"论文","slug":"论文","permalink":"http://yama0xff.com/categories/论文/"},{"name":"fuzzing","slug":"论文/fuzzing","permalink":"http://yama0xff.com/categories/论文/fuzzing/"}],"tags":[{"name":"2018年","slug":"2018年","permalink":"http://yama0xff.com/tags/2018年/"},{"name":"ACM CCS'18","slug":"ACM-CCS-18","permalink":"http://yama0xff.com/tags/ACM-CCS-18/"},{"name":"Lacking-Recheck Bugs","slug":"Lacking-Recheck-Bugs","permalink":"http://yama0xff.com/tags/Lacking-Recheck-Bugs/"},{"name":"Kernels","slug":"Kernels","permalink":"http://yama0xff.com/tags/Kernels/"}]},{"title":"Automated Detection Exploitation and Elimination of Double-Fetch Bugs Using Modern CPU Features","date":"2019-02-05T02:50:59.000Z","path":"2019/02/05/Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features/","text":"AbstractDouble-fetch bugs 是一种特殊的条件竞争，在高权限线程的time-of-check和time-of-use之间，低权限线程能够修改共享的内存，导致高权限线程访问的内存产生不一致。本文作者提出了一种检测，利用并消除double-fetch bugs的技术DECAF和Dropit。总体来说，贡献如下：1. 把cache attack与kernel fuzzing结合起来。2. 首个自动化的挖掘double-fetch bugs的方法。3. 利用的成功率高达97%。4.利用Hardware Transactional Memory的特性，消除double-fetch bugs。5.方法对fuzz TEE也有效。 relevant information 作者 Michael Schwarz, Daniel Gruss, Moritz Lipp, Clémentine Maurice, Thomas Schuster, Anders Fogh, Stefan Mangard 单位 Graz University of Technology, CNRS, G DATA Advanced Analytic 出处 AsiaCCS’18 原文地址 源码地址 发表时间 2018年 简介现代操作系统的安全依赖操作系统kernel提供隔离性，在对kernel的攻击中，条件竞争是一个很难解决的问题。Double-fetch bugs 就是一种特殊的条件竞争。kernel两次访问同一块内存，首先检查数据的合法性，第二次就使用它，那在这两者之间，内存可能被修改。 Double Fetches有个明显的特征是要访问两次内存。如果数据在cache中，就从cache中读，如果不在就从主存中读到cache中，基于cache的攻击，比如著名的Flush+Reload攻击，可以利用CPU的这个特性来检测Double Fetches。 Intel TSX的hardware transactional memory特性能够保证当数据被读进transaction后，数据不能被任何transaction之外的操作修改。这种特性被用来实现安全加固，比如在这个场景中就可以天然的防御Double Fetch bugs。 通过Flush+Reload边信道检测double fetches 判断double fetches是否能够被利用 通过hardware transactional memory消除double fetch bugs 检测主要思想是监控cache访问syscall的参数（比如指针，结构体中的指针），筛选出这些指针后，另起一个Flush+Reload线程对这些指针进行监控。 效果如下所示，可以明显的看到两次cache的访问。 多次cache hit的分类影响cache acess pattern的因素 size of data type parameter reuse 检测的概率检测成功的概率取决于两次访问时间的间隔。因为本身Flush+Reload需要把数据从cache中清掉，这要消耗大概200多个CPU周期，这就要保证double fetch的两次访问间隔至少要是Flush+Reload两倍的的时间才行。 TrinityDECAF作者基于trinity这个kernel syscall fuzz框架，实现了 TrinityDECAF，架构如图，基于trinity，为每个syscall的参数实现了一个监控的进程。 利用Flush-Reload or Flush+Flush fuzz策略 参数值改成0 翻转最低有效比特 增加值 参数值改为随机值 消除作者实现了Dropit的库，这个是基于硬件的特性，hardware transactional memory保证了两次内存访问之间不能再对该内存修改。实现起来也很简单，使用Intel TSX的XBEGIN和XEND指令讲存在bug的代码包起来即可。 评估DECAF已知漏洞CVE-2016-6516 可行性 有效性 利用的成功率 在TEE上fuzz 使用dropit和不使用的比较 参考于GoSSIP.","content":"<h1 id=\"Abstract\"><a href=\"#Abstract\" class=\"headerlink\" title=\"Abstract\"></a>Abstract</h1><p>Double-fetch bugs 是一种特殊的条件竞争，在高权限线程的time-of-check和time-of-use之间，低权限线程能够修改共享的内存，导致高权限线程访问的内存产生不一致。本文作者提出了一种检测，利用并消除double-fetch bugs的技术DECAF和Dropit。总体来说，<strong><em>贡献如下：1. 把cache attack与kernel fuzzing结合起来。2. 首个自动化的挖掘double-fetch bugs的方法。3. 利用的成功率高达97%。4.利用Hardware Transactional Memory的特性，消除double-fetch bugs。5.方法对fuzz TEE也有效。</em></strong></p>\n<table>\n<thead>\n<tr>\n<th>relevant information</th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><em>作者</em></td>\n<td>Michael Schwarz, Daniel Gruss, Moritz Lipp, Clémentine Maurice, Thomas Schuster, Anders Fogh, Stefan Mangard</td>\n</tr>\n<tr>\n<td><em>单位</em></td>\n<td>Graz University of Technology, CNRS, G DATA Advanced Analytic</td>\n</tr>\n<tr>\n<td><em>出处</em></td>\n<td>AsiaCCS’18</td>\n</tr>\n<tr>\n<td><em>原文地址</em></td>\n<td></td>\n</tr>\n<tr>\n<td><em>源码地址</em></td>\n<td></td>\n</tr>\n<tr>\n<td><em>发表时间</em></td>\n<td>2018年</td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h1><p>现代操作系统的安全依赖操作系统kernel提供隔离性，在对kernel的攻击中，条件竞争是一个很难解决的问题。Double-fetch bugs 就是一种特殊的条件竞争。kernel两次访问同一块内存，首先检查数据的合法性，第二次就使用它，那在这两者之间，内存可能被修改。 Double Fetches有个明显的特征是要访问两次内存。如果数据在cache中，就从cache中读，如果不在就从主存中读到cache中，基于cache的攻击，比如著名的Flush+Reload攻击，可以利用CPU的这个特性来检测Double Fetches。</p>\n<p>Intel TSX的hardware transactional memory特性能够保证当数据被读进transaction后，数据不能被任何transaction之外的操作修改。这种特性被用来实现安全加固，比如在这个场景中就可以天然的防御Double Fetch bugs。</p>\n<p><img src=\"/2019/02/05/Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features/E:/github\\hexo\\source\\_posts\\Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features\\1.jpg\" alt=\"\"></p>\n<ul>\n<li>通过Flush+Reload边信道检测double fetches</li>\n<li>判断double fetches是否能够被利用</li>\n<li>通过hardware transactional memory消除double fetch bugs</li>\n</ul>\n<h1 id=\"检测\"><a href=\"#检测\" class=\"headerlink\" title=\"检测\"></a>检测</h1><p>主要思想是监控cache访问syscall的参数（比如指针，结构体中的指针），筛选出这些指针后，另起一个Flush+Reload线程对这些指针进行监控。</p>\n<p>效果如下所示，可以明显的看到两次cache的访问。</p>\n<p><img src=\"/2019/02/05/Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features/E:/github\\hexo\\source\\_posts\\Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features\\2.jpg\" alt=\"\"></p>\n<h2 id=\"多次cache-hit的分类\"><a href=\"#多次cache-hit的分类\" class=\"headerlink\" title=\"多次cache hit的分类\"></a>多次cache hit的分类</h2><p>影响cache acess pattern的因素</p>\n<ul>\n<li>size of data type</li>\n<li>parameter reuse</li>\n</ul>\n<h2 id=\"检测的概率\"><a href=\"#检测的概率\" class=\"headerlink\" title=\"检测的概率\"></a>检测的概率</h2><p>检测成功的概率取决于两次访问时间的间隔。因为本身Flush+Reload需要把数据从cache中清掉，这要消耗大概200多个CPU周期，这就要保证double fetch的两次访问间隔至少要是Flush+Reload两倍的的时间才行。 </p>\n<p><img src=\"/2019/02/05/Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features/E:/github\\hexo\\source\\_posts\\Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features\\3.jpg\" alt=\"\"></p>\n<h2 id=\"TrinityDECAF\"><a href=\"#TrinityDECAF\" class=\"headerlink\" title=\"TrinityDECAF\"></a>TrinityDECAF</h2><p>作者基于trinity这个kernel syscall fuzz框架，实现了 TrinityDECAF，架构如图，基于trinity，为每个syscall的参数实现了一个监控的进程。</p>\n<p><img src=\"/2019/02/05/Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features/E:/github\\hexo\\source\\_posts\\Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features\\4.jpg\" alt=\"\"></p>\n<h1 id=\"利用\"><a href=\"#利用\" class=\"headerlink\" title=\"利用\"></a>利用</h1><p>Flush-Reload or Flush+Flush</p>\n<p>fuzz策略</p>\n<ul>\n<li>参数值改成0</li>\n<li>翻转最低有效比特</li>\n<li>增加值</li>\n<li>参数值改为随机值</li>\n</ul>\n<h1 id=\"消除\"><a href=\"#消除\" class=\"headerlink\" title=\"消除\"></a>消除</h1><p>作者实现了Dropit的库，这个是基于硬件的特性，hardware transactional memory保证了两次内存访问之间不能再对该内存修改。实现起来也很简单，使用Intel TSX的XBEGIN和XEND指令讲存在bug的代码包起来即可。</p>\n<p><img src=\"/2019/02/05/Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features/E:/github\\hexo\\source\\_posts\\Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features\\5.jpg\" alt=\"\"></p>\n<h1 id=\"评估\"><a href=\"#评估\" class=\"headerlink\" title=\"评估\"></a>评估</h1><h2 id=\"DECAF\"><a href=\"#DECAF\" class=\"headerlink\" title=\"DECAF\"></a>DECAF</h2><p>已知漏洞CVE-2016-6516 </p>\n<p><img src=\"/2019/02/05/Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features/E:/github\\hexo\\source\\_posts\\Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features\\6.jpg\" alt=\"\"></p>\n<ul>\n<li>可行性</li>\n</ul>\n<p><img src=\"/2019/02/05/Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features/E:/github\\hexo\\source\\_posts\\Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features\\7.jpg\" alt=\"\"></p>\n<ul>\n<li>有效性</li>\n</ul>\n<p><img src=\"/2019/02/05/Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features/E:/github\\hexo\\source\\_posts\\Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features\\8.jpg\" alt=\"\"></p>\n<ul>\n<li>利用的成功率</li>\n</ul>\n<p><img src=\"/2019/02/05/Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features/E:/github\\hexo\\source\\_posts\\Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features\\9.jpg\" alt=\"\"></p>\n<ul>\n<li>在TEE上fuzz</li>\n</ul>\n<p><img src=\"/2019/02/05/Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features/E:/github\\hexo\\source\\_posts\\Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features\\10.jpg\" alt=\"\"></p>\n<ul>\n<li>使用dropit和不使用的比较</li>\n</ul>\n<p><img src=\"/2019/02/05/Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features/E:/github\\hexo\\source\\_posts\\Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features\\11.jpg\" alt=\"\"></p>\n<p>参考于GoSSIP.</p>\n","categories":[{"name":"论文","slug":"论文","permalink":"http://yama0xff.com/categories/论文/"},{"name":"fuzzing","slug":"论文/fuzzing","permalink":"http://yama0xff.com/categories/论文/fuzzing/"}],"tags":[{"name":"Double-Fetch Bugs","slug":"Double-Fetch-Bugs","permalink":"http://yama0xff.com/tags/Double-Fetch-Bugs/"},{"name":"AsiaCCS'18","slug":"AsiaCCS-18","permalink":"http://yama0xff.com/tags/AsiaCCS-18/"},{"name":"2018年","slug":"2018年","permalink":"http://yama0xff.com/tags/2018年/"}]},{"title":"VUzzer: Application-aware Evolutionary Fuzzing","date":"2019-01-29T09:49:47.000Z","path":"2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/","text":"AbstractFuzzing是一种有效的软件测试技术，用于查找错误。考虑到实际应用程序的大小和复杂性，现代模糊器往往是可扩展的，但在探索执行更深层次的错误或者能够在应用程序中深入渗透但不具有可扩展性方面无效。在本文中，我们提出了一种应用程序感知的进化模糊测试策略，它不需要任何有关应用程序或输入格式的先验知识。为了最大化覆盖范围并探索更深入的路径，我们利用基于静态和动态分析的控制和数据流特征来推断应用程序的基本属性。与应用程序无关的方法相比，这可以更快地生成有趣的输入。我们在VUzzer中实现我们的模糊测试策略并在三个不同的数据集上进行评估：DARPA Grand Challenge二进制文件（CGC），一组实际应用程序（二进制输入解析器）和最近发布的LAVA数据集。在所有这些数据集中，通过快速查找几个现有和新的错误，VUzzer产生的结果明显优于最先进的模糊器。 relevant information 作者 Sanjay Rawat, Vivek Jain, Ashish Kumar, Lucian Cojocar,Cristiano Giuffrida and Herbert Bos 单位 Computer Science Institute, Vrije Universiteit Amsterdam;Amsterdam Department of Informatics International Institute of Information Technology, Hyderabad 出处 NDSS ’17 原文地址 https://github.com/wtwofire/database/blob/master/papers/fuzzing/2017-VUzzer%20Application-aware%20Evolutionary%20Fuzzing.pdf 源码地址 https://github.com/vusec/vuzzer 发表时间 2017年 论文简略概括： 其它相关源码地址： 污点分析数据存储结构：https://github.com/lemire/EWAHBoolArray AFLPIN: https://github.com/mothran/aflpin AFLFAST: https://github.com/mboehme/aflfast DECREE: https://github.com/CyberGrandChallenge/cgc-releasedocumentation/blob/master/walk-throughs/pin-for-decree.md 简介在本文中，我们介绍了VUzzer，一个应用程序感知的进化模糊器，它既可扩展又可快速发现执行中的漏洞。与优化输入生成过程以最大速率生成输入的方法相比，我们的工作探索了设计领域的一个新点，我们在前端做更多的工作，产生更少但更好的输入。关键的直觉是我们可以通过基于控制和数据流应用功能的“智能”突变反馈回路来提高通用模糊器的效率，而无需采用可扩展性较低的符号执行。我们展示了我们可以通过在模糊运行期间对应用程序进行轻量级静态和动态分析来提取这些功能。我们的控制流功能允许VUzzer优先考虑深度（并因此感兴趣）路径，并在改变输入时优先考虑频繁（因此无趣）路径的优先级。我们的数据流功能允许VUzzer准确地确定改变这些输入的位置和方式。 由于其应用感知突变策略，VUzzer比现有的模糊器更有效。我们评估了VUzzer在三个不同数据集上的表现：a）DARPA CGC二进制文件[15]，这是一组人工创建的交互式程序，旨在评估错误发现技术; b）一组具有不同复杂程度的Linux程序（djpeg，mpg321，pdf2svg，gif2png，tcpdump，tcptrace）和c）最近发布的来自LAVA团队的二进制文件[17]，许多Linux实用程序都有几个注入的错误。在我们对不同数据集的实验中，我们通过生成数量级较少的输入来表现优于AFL，同时发现更多崩溃。例如，在mpg3211中，我们通过执行23K输入发现300次独特崩溃，而883K输入则通过AFL找到19次独特崩溃。 贡献：我们做出以下贡献： 1）我们表明现代模糊器可以“更智能”而不需要采用符号执行（难以扩展）。我们的应用感知突变策略将AFL等最先进的模糊器的输入生成过程提高了几个数量级。 2）我们提出了几个应用程序特征来支持有意义的输入变异。 3）我们在三个不同的数据集上评估VUzzer，一个实现我们方法的功能齐全的模糊器，并表明它非常有效。 4）为了促进该领域的进一步研究和支持开放科学，我们开放我们VUzzer原型的源代码，可在https://www.vusec.net/projects/fuzzing获得。 总体描述为了解决上一节中提到的挑战，我们提出了VUzzer，一种应用程序感知的进化模糊器。图1概述了其主要组件。 由于VUzzer是一个进化模糊器，因此有一个反馈循环可以帮助从旧的输入中获得新的输入。生成新输入时，VUzzer会根据其在上一轮输入上的执行情况来考虑应用程序的特征。通过考虑这些特性，我们使反馈回路“智能”并帮助模糊器找到具有高频率的非零IG的输入。 1. 特征数据流特征：数据流特征提供有关应用程序中输入数据和计算之间关系的信息。 VUzzer使用诸如污点分析之类的众所周知的技术来提取它们，并使用它们根据输入中某些偏移处的数据类型来推断输入的结构。例如，它通过检测x86 ISA的cmp系列的每个指令来确定分支的字节（“分支约束”），以确定它使用哪些输入字节（偏移）以及它与哪些值进行比较。通过这种方式，VUzzer可以确定哪些偏移对于变异感兴趣以及在这些偏移处使用哪些值（在第I部分中提供问题的部分答案）。 VUzzer现在能够通过更频繁地定位此类偏移并通过在这些偏移处使用预期值来满足分支约束来更明智地进行变异。这样做可以解决魔术字节的问题，而无需使用符号执行。 同样，VUzzer监视lea指令以检查索引操作数是否被污染。如果是这样，它可以确定相应偏移处的值是int类型并相应地改变输入。除了这两个简单但功能强大的特征外，还有许多其他功能。 控制流特征：控制流特征允许VUzzer推断某些执行路径的重要性。例如，图2显示了清单3中代码的简化CFG。执行错误块的输入通常是不感兴趣。因此，识别这样的错误处理块可以加速感兴趣输入的生成。我们将在以下部分中展示如何检测错误处理代码。目前，我们假设我们可以启发式地识别包含错误处理程序的基本块。 另一个例子涉及嵌套块的可达性。到达块F的任何输入更有可能比到达块H的输入更深入到代码中，因为后者不是嵌套的。我们使用控制流特征来对路径进行去优先级和优先级排序。由于枚举应用程序中的所有可能路径是不可行的，我们通过为各个基本块分配权重来实现此度量。具体而言，作为错误处理代码一部分的基本块获得负权重，而难以到达的代码区域中的基本块获得更高权重。 图1显示了单次模糊测试包含几个步骤。 VUzzer期望有效输入的初始池SI，称为种子输入。第一步是执行过程内静态分析以获得一些控制流和数据流特征（第III-B节），然后是主要的进化模糊循环。在本节的其余部分，我们将介绍描述整个过程的所有步骤。 2. 静态分析器在模糊测试过程开始时，我们使用轻量级过程内静态分析来（i）通过扫描应用程序的二进制代码来获得cmp指令的立即值，以及（ii）计算应用程序二进制文件基本块的权重。 应用程序代码中cmp指令中存在的许多立即值通常表示应用程序期望输入在某些偏移处具有许多这些值。例如，清单3中对程序的分析产生了每个基本块的权重列表LBB和包含{0xEF，0xFD，％，@，MAZE}的字节序列的列表Limm。为了确定基本块权重，我们将每个函数的CFG建模为马尔可夫模型，并计算到达函数中每个基本块b的概率pb。然后我们计算每个基本块b的权重wb为1 / pb。因此，到达基本块的概率越低，权重越高。使用该模型，每个基本块的概率和权重显示在图2中的每个节点旁边（参见第IV-A3节）。我们观察到，例如，到达基本块G的概率小于到达基本块F的概率，而基本块F的概率低于基本块H.VUzzer在模糊循环的后续步骤中使用这些列表。 3. 主fuzzing循环我们通过使用算法1中的步骤来描述主fuzzing循环。在主循环开始之前，我们用一组种子输入SI执行应用程序以推断出一组初始的控制流和数据流特征。对于SI中的所有输入，我们运行动态污点分析（DTA）以捕获有效输入的共同特征。具体来说，我们这样做是为了前面提到的魔术字节和错误处理代码检测。使用这些功能，我们生成一个初始输入总体，作为算法1中INITIALIZE步骤的一部分。请注意，我们的魔术字节检测确保这些新输入跨越第一次这样的应用程序检查。由于DTA具有很高的开销，我们在主循环开始后尽可能少地使用它。 输入执行：我们使用上一步中的每个输入执行应用程序，并生成相应的已执行基本块的跟踪。如果任何输入执行以前未见过的的基本块，我们会污染输入并使用DTA通过监视应用程序的数据流功能来推断其结构属性。 适应度计算：在算法1的EVALUATE步骤中，我们计算每个输入的适应度作为执行的基本块的频率的加权和。我们使用权重列表LBB在基本块上分配权重。属于错误处理代码的基本块会产生负权重 - 现在我们仍然假设我们可以识别这些基本块。该适应度计算背后的直觉是为执行具有较高权重的基本块的输入提供高分，从而对相应路径进行优先级排序，同时还执行具有高频率的某些基本块以捕获大循环。例如，让我们考虑两个路径p1和p2，分别由两个输入i1和i2执行，使得p1 = A-&gt; B - &gt; D - &gt;E - &gt;H - &gt;J和p2 = A - &gt;B - &gt;D - &gt;E - &gt;F - &gt;J.为简单起见，让我们假设错误处理基本块J得到权重-1并且每个基本块的执行频率为1.使用图2中的权重，p1和p2的频率的加权和为7 （1 + 1 + 2 + 2 + 2-1）和9（1 + 1 + 2 + 2 + 4-1）。因此，输入i2获得更高的适应度分数，并且将比i1更多地参与生成新输入。该步骤最终生成按其适应度分数降序排列的输入排序列表。 遗传算子和新输入生成：这是我们模糊测试策略中最后也是最重要的功能，包括算法1中的SELECT，RECOMBINE和MUTATE步骤。这些子步骤一起负责生成有趣的输入。在主循环的每次迭代中，我们通过组合和突变SI的输入，所有受污染的输入以及Lf的前n％来生成新一代输入。我们将此集称为ROOT集。 具体来说，我们通过交叉和变异生成新的输入。首先，我们从ROOT中随机选择两个输入（父项）并应用交叉来生成两个新输入（子项）。具有固定概率，这两个输入进一步经历突变。 Mutation使用多个子操作，例如删除，替换和在给定输入中的某些偏移处插入字节。变异运算符利用数据流功能生成新值。例如，在插入或替换字节时，它使用来自Limm的字符来生成不同长度的字节序列。类似地，选择来自当前输入的父项的各种偏移用于突变。因此，如果存在任何魔术字节，它们将在结果输入中的适当偏移处被替换。 这个循环的输入生成一直持续到我们满足终止条件。目前，我们在发现崩溃或VUzzer达到预先配置的代数时终止。 设计与实现1. 实现细节1）动态污点分析（DTA）：DTA是VUzzer的核心，因为它在发展新输入方面发挥着重要作用。这也是将VUzzer与现有模糊器区分开来的技术。 DTA用于监视应用程序内受污染的输入（例如，网络包，文件等）的流动。在程序执行期间，DTA可以确定哪些存储器位置和寄存器依赖于受污染的输入。根据粒度，DTA可以将受污染的值追溯到输入中的各个偏移量。 VUzzer使用DTA跟踪cmp和lea指令中使用的污染输入偏移。对于每个执行的cmp指令cmp op1，op2（op1和op2可以是寄存器，存储器或立即操作数），DTA确定op1和/或op2是否被一组偏移污染。我们的DTA实现能够在字节级别跟踪污点。对于给定的受污染操作数op，DTA为op的每个字节提供污点信息。 2）魔术字节检测：基于我们对具有魔术字节的文件格式的理解，我们假设魔术字节是输入字符串中固定偏移处的固定字节序列。我们已经在几种具有魔术字节的文件格式上验证了这一假设，例如jpeg，gif，pdf，elf和ppm。由于VUzzer是给定应用程序的一些有效输入的可用性，我们在模糊测试开始时在这些输入上使用DTA的结果。由于应用程序期望输入包含魔术字节，因此DTA在cmp指令上的结果将包含对魔术字节的相应检查。 例如，清单3中的代码在输入文件的开头需要一个魔术字节0xFDEF。因此，DTA将捕获两条cmp指令 - cmp reg，0xFD，reg受到偏移0的污染，cmp reg，0xEF，reg受到偏移量1的污染。如果对这个程序我们有一个有效输入的集合，我们可以在所有相应的执行中观察这两条cmp指令。相反，如果对于一组有效输入，我们在所有输入的DTA结果中得到cmpi =（oi; vi），vi是偏移oi的魔术字节的一部分。 在魔术字节检测期间，对于给定的cmpi指令，如果相应的值取决于每个字节的多个偏移，我们不认为这种偏移是魔术字节候选。例如，对于给定的cmp指令，如果DTA检测到|Tji|&gt; 1，我们从魔术字节占位符的任何进一步考虑中排除这些偏移（ÎTji）。这种情况表明相应操作数的值可以从那些偏移ÎTji处的污染值导出。对多个字节的依赖打破了魔术字节是固定（常量）字节序列的假设。我们将所有这些偏移的集合表示为Oother。 3）基本块权重计算：从基于覆盖的fuzzing角度来看，每条可行路径对于遍历都很重要。一个简单的模糊测试策略是花费同等的努力为所有可行路径生成输入。但是，由于存在控制结构，某些路径的可达性可能与其他路径的可达性不同。如果我们有嵌套的控制结构，这种情况就会频繁出现[41]。因此，与其他输入相比，任何运行这种难以触及的代码的输入都应该得到更多奖励。 我们通过为嵌套控制结构中包含的基本块指定更高权重来合并此奖励。由于枚举过程间级别的所有路径都难以缩放，我们的分析在过程间级别，即，我们计算包含在函数内的每个基本块的权重。稍后，我们收集并添加由给定输入执行的路径中所有基本块的权重。通过这种策略，我们通过将几个过程内路径分数拼接在一起来模拟过程间路径的分数。 如果我们认为特定基本块的输入到下一个基本块的转换取决于某个概率，我们可以从控制流图（CFG）中导出一个称为马尔可夫过程的概率模型用于输入行为。马尔可夫过程是一个随机过程，其中给定试验的结果仅取决于过程的当前状态[30]。我们将函数的CFG建模为马尔可夫过程，其中每个基本块具有基于其与其他基本块的连接的概率。 对于给定的基本块，我们为其所有输出边分配相等的概率。因此，如果out（b）表示基本块b的所有输出边缘的集合，则∀eb Î out（b）; prob（eb ）= 1/|out（b）|。基本块b的转移概率（似然）计算如下： 其中prod（b）是b的所有前辈的集合。我们使用定点迭代算法来计算与CFG中的每个基本块相关联的概率。 CFG的root基本块初始化概率为1。通过为每个后备项分配固定概率1来处理循环，从而忽略后备本身的影响（即，我们将循环展平以加速定点计算）。从等式1，每个基本块b的权重由下式给出： 4）错误处理代码检测：如前所述，在模糊测试期间，大多数突变输入将执行最终处于某种错误状态的路径。对这些执行路径进行优先级排序是提高创建有趣输入的机会的关键一步。我们的错误处理检测启发式依赖于有效输入的可用性，这是VUzzer的先决条件。由于我们的错误处理检测取决于应用程序的动态行为，因此它以增量方式检测错误处理基本块。 初始分析：对于每个有效输入iÎSI，我们收集由i执行的基本块的集合BB（i）。设ValidBB表示所有有效输入的所有这些已执行基本块的并集。然后我们创建一组完全随机的输入，表示为TR。对于此集合中的每个输入，我们根据基本块收集其执行跟踪。如果在来自TR的输入的每次执行中存在并且它不存在于ValidBB中，则假定来自这样的一组执行的基本块是错误处理基本块（即，属于错误处理代码）。直觉是因为SI是一组有效输入，所以不会触发错误处理代码。因此，ValidBB将仅包含与有效路径对应的基本块。由于TR是一组完全随机的输入，它们很可能在执行期间被错误处理代码捕获。 我们是一种非常保守的错误处理基本块检测策略，因为如果某些输入被不同的错误处理代码捕获，我们可能会错过几个基本块。尽管如此，请注意，我们永远不会将与有效路径对应的基本块分类为错误处理基本块。更正式的表示如下 EHB就是错误处理基本块集合。 增量分析：我们观察到，由于我们的错误处理检测策略基于应用程序的动态行为，因此在初始分析期间不会触发所有错误处理代码。随着输入的发展，它们会探索更多路径，从而遇到新的错误处理代码。出于这个原因，我们在后来的模糊测试迭代期间启动增量分析。在我们的实验设置中，我们观察到，随着我们进行更多的模糊测试迭代，新的错误处理代码实例的数量减少了。这反映了软件具有有限数量的错误处理代码实例的直觉，这些代码实例在应用程序的不同部分中重用。因此，当我们执行更多迭代时，我们减少运行增量分析的频率。 我们的增量分析背后的直觉是观察到，随着模糊测试的进行，大多数新生成的输入最终会触发一些错误处理代码。在给定的迭代中，让I成为迭代中生成的输入集。让大多数量由|I|的n％量化。我们的（离线）实验表明，n = 90是一个合理的选择。设BB（I）是由I中的输入执行的所有基本块的集合。如果它与来自I的输入少与n％的相关联，且它不在V alidBB集中，则将来自BB（I）的基本块b分类为错误处理基本块。更正式地说，让P（I）表示I的幂集。然后 错误处理基本块的权重计算：在检测到错误处理基本块（EHB）之后，我们希望对包含此类块的路径进行优先级排序。我们通过惩罚相应的输入来实现这一点，以便这些输入参与下一代的机会较少。为此，每个EHB都给出负权重，这会影响相应输入的适合度（见第IV-A5节）。然而，这种策略本身并不充分，因为与输入执行的基本区块总数相比，EHB只是少数，因此这么小的数量将产生微不足道的影响。我们通过定义影响系数μ（可调参数）来解决这个问题，影响系数μ决定单个错误处理基本块可以使多少（非错误处理）基本块无效。直观地，该参数确定，一旦输入进入错误处理代码，任何相应基本块在计算适合度分数时的贡献必须减少因子μ。对于给定的输入i，我们使用以下公式进行重量计算。 其中|BB（i）|是由输入i执行的所有基本块的编号，|EHB（i）|是由i执行的所有错误处理基本块的编号，并且0.1≤μ≤1.0。 5）适应度计算：适应度计算是进化算法最重要的组成部分之一。这对于实现反馈回路至关重要，这为下一步的输入生成提供了动力。一旦产生新的输入，其参与产生新输入的机会取决于其适合度。 VUzzer以两种方式评估输入的适应性。如果输入的执行导致发现新的非EHB基本块，则输入有资格参与下一代。这类似于AFL（额外使用EHB组）。然而，如前所述，这种适应度测量认为所有新发现的路径相等，这是有问题的。输入的重要性（以及因此适应性）取决于其执行的路径的兴趣度，而该路径又取决于相应基本块的权重。因此，我们将输入i的适应度fi定义为捕获所有相应基本块权重的效果的函数。 其中BB（i）是由输入i执行的基本块的集合，Freq（b）是当由i执行时基本块b的执行频率，Wb是基本块b的权重（通过使用等式2），li是输入i的长度，LMAX是输入长度的预配置限制。 LMAX用于解决输入膨胀现象。在遗传算法的说法中，两个适应度标准（即发现新基本块的能力和更高的fi）都对应于探索和开发的概念 - 发现新的基本块表示新的方向（即探索）和较高的fi表示基本块的较高执行频率（以及其他因素）（即，在相同方向上的利用）。 6）输入生成：VUzzer的输入生成由交叉和变异两部分组成，它们不是互斥的，即交叉以固定的概率跟随在变异之后。 交叉：交叉是一种简单的操作，其中从前一代中选择两个父输入，并生成两个新的子输入。 变异：变异是一种更复杂的操作，它涉及若干子操作以将给定的父输入改变为相应的子输入。该过程在以下步骤中详述： 步骤1：从集合Oother中随机选择受污染的偏移量并在这些偏移量处插入字符串。字符串由从集合Limm获得的字节组成。 步骤2：从集合Llea中随机选择偏移量并通过用有趣的整数值（例如0，MAX UINT，负数）替换它们来改变来自步骤1的字符串中的这种偏移量。 步骤3：对于父输入的所有受污染的cmp指令，如果op1 ≠ op2的值，则将步骤2中字符串中受污染偏移的值替换为op2的值，否则将以固定概率替换受污染的值字节由随机字节序列组成。 步骤4：将魔术字节放置在由我们的魔术字节检测器确定的相应偏移处。 2. 实现细节VUzzer的核心功能是在Python 2.7中实现的。一些实现的分析，例如错误处理基本块检测的增量分析，是内存密集型的，因此我们还利用了更新版本（如BitVector3）提供的高效数据结构。 VUzzer内部由两个主要组件组成，包括静态和动态分析，如下面进一步详述。 静态分析：VUzzer在IDA [27]中实现了两种静态分析（常量字符串提取和基本块权重计算）。分析是使用IDAPython [18]用Python编写的。 动态分析：VUzzer在Pin动态分析框架的顶部实现了动态分析（基本块跟踪和DTA）[31]。对于基本块跟踪，我们实现了一个pintool来记录执行期间遇到的每个基本块及其频率。我们的pintool可以根据需要有选择地跟踪某些库执行的基本块。选择性库监控允许我们减少执行跟踪开销并专注于预期的应用程序代码。 我们的DTA实现基于Stamatogiannakis等[46]提出的DataTracker，后者又基于LibDFT [29]。由于LibDFT只能处理32位应用程序，因此当前的VUzzer原型只能用于模糊32位应用程序（也用于我们的评估）。请注意，这不是一个基本限制，事实上，我们正在VUzzer中实现64位支持。任何更新版本将在https://www.vusec.net/projects/fuzzing上提供。 为了使其适合我们的目的，我们还对DataTracker进行了一些更改： 在DataTracker中，与每个内存位置关联的污点标记被建模为元组：&lt;ufd，file_offeset&gt;，即唯一文件描述符和与该描述符关联的文件的偏移量。这些元组中的每一个都是64位长（ufd为32位，file_offset为32位）。每个内存位置都有一组与之关联的元组，以确定偏移量和内存位置受污染的文件。我们将其更改为EWAHBoolArray type，它是一种压缩的bitset数据类型。由于我们只需要来自一个（输入）文件的数据流信息，因此我们修改了DataTracker以仅通过该文件传播污点。因此，在我们的修改版本中，与每个存储器位置相关联的污点标签被建模为仅包含偏移的EWAHBoolArray。因此，我们的实现速度至少快2倍，并且使用的内存比DataTracker少几倍。 我们为cmp系列指令添加了插桩回调，如CMP，CMPSW，CMPSB，CMPSL和lea指令，以捕获计算中涉及的操作数的字节级污点信息。 我们为每个实现的系统调用重写了钩子，并为一些额外的系统调用添加了钩子，例如pread64，dup2，dup3，mmap2等。为了评估我们在DARPA数据集[15]上的性能，我们还实现了基于DECREE的钩子系统调用，与普通的Linux系统调用不同。 crash分类：一旦模糊测试开始产生崩溃，它可能会继续产生更多的崩溃，并且应该有一些机制来区分由于不同的错误（或相同的错误但不同的实例）导致的崩溃。为了确定崩溃的唯一性，VUzzer使用由Molnar等人提出的堆栈散列的变体[37]。在我们的pintool中，我们实现了一个环形缓冲区，用于跟踪最后5个函数调用以及在崩溃之前执行的最后10个基本块。我们计算此缓冲区的哈希值，每次遇到新的崩溃时，我们将新生成的哈希值与旧的哈希值进行比较，以确定报告的崩溃是否是新的唯一崩溃。 评估为了测量我们提出的模糊测量技术的有效性，本节介绍了对VUzzer的评估。为了将VUzzer显示给各种应用程序，我们选择在三个不同的数据集上测试VUzzer A. DARPA CGC二进制文件[15]，B. [43]中使用的二进制格式的杂项应用程序，C.最近的一组错误二进制文件由LAVA [17]生成。 我们在配备32位2核Intel CPU和4 GB RAM的Ubuntu 14.04 LTS系统上进行了实验。对于DARPA CGC数据集，（提供的）环境是具有称为DECREE的自定义OS的VM。我们要强调的是，我们的主要评估目标是展示VUzzer在识别错误（可能深埋在执行中）的效率，其输入比AFL等最先进的模糊器少得多。我们当前的VUzzer原型并不像AFL那样针对快速输入执行进行优化，因此我们不寻求这方面的比较。 A. DARPA CGC数据集作为Cyber Grand Challenge的一部分，DARPA发布了一组二进制文件，这些二进制文件在一个名为DECREE的自定义操作系统中运行。共有131个二进制文件，其中注入了各种类型的错误。但是，由于以下原因，我们无法在所有这些上运行VUzzer： 通过接受来自STDIN的输入，所有二进制文件本质上都是交互式的。一旦启动，其中许多人会提供一个菜单来选择一个动作，包括退出选项。此外，在许多情况下，有多个菜单（在程序的不同状态下）具有不同的退出选项。由于VUzzer需要生成完全随机输入的步骤（错误处理代码检测，第IV-A4节），执行此类输入会使应用程序循环，查找有效选项，包括退出选项。这会导致应用程序永远运行。这是一个接口问题，而不是我们的模糊测试方法的基本限制。 其中一些二进制文件是使用浮点指令编译的，这些指令LibDFT不能处理，因此VUzzer无法获得正确的数据流信息。 由于VUzzer基于Pin [32]，我们按照给定的程序在DECREE5中运行pintools。但是，我们无法使用Pin运行一些二进制文件。 某些二进制文件涉及与其他二进制文件的交互，而VUzzer无法处理这些二进制文件。 在考虑了上面提到的障碍之后，我们总共留下了63个二进制文件。为了与AFL进行比较，我们还运行了AFLPIN，一种基于pintool的AFL实现。 AFLPIN具有与AFL相同的模糊引擎，但是获取执行跟踪的机制不同。我们选择使用AFLPIN代替AFL是为了与SUT具有相同的接口机制，即通过文件描述符0（STDIN）将输入传递给pintool。 VUzzer在29个CGC二进制文件中发现了崩溃，而AFLPIN只发现了23个崩溃。由于每个CGC也附带修补版本，我们通过运行修补程序版本的二进制文件来验证VUzzer发现的每个错误，以避免进一步崩溃。最重要的结果是这两个模糊器中每次崩溃的执行输入数量。我们运行两个模糊器最多6个小时。图4描绘了两个模糊器发现崩溃（总共13个）的情况的执行次数，证明VUzzer与AFL相比可以显着修剪搜索空间。 在对特定二进制NRFIN_00015进行模糊测试时，我们观察到以离散方式计算适应度分数fi的重要性。此二进制文件中的漏洞是循环中缓冲区溢出的典型情况。我们观察到在第18次迭代之后，没有发现新的BB，但是fi保持增加，表明典型的循环执行行为。在第63次迭代（总执行次数13K），我们到达缓冲区的边界。 AFLPIN无法检测到这次崩溃。 我们注意到，我们目前对该数据集的结果是适度的，特别是在Driller [47]报告的结果中。我们进一步调查了结果，发现了一些可能会影响我们当前VUzzer原型在CGC上的性能的特性。 在多个二进制文件中，只有通过执行给定菜单中的一组非常特定的操作才能达到错误状态。例如，在CROMU_00001应用程序中，必须执行以下操作：登录A - &gt;向用户B发送许多消息 - &gt;登录B - &gt;检查消息。目前，VUzzer无法重复序列。 有效输入的概念很模糊。回想一下，我们使用每个CGC二进制文件以XML文件形式提供的整个会话作为一个输入。因此，基本上没有无效输入的概念。因此，我们无法充分利用VUzzer的全部功能。 与上述相关的是有趣的抵消问题。由于CGC二进制文件是交互式的，因此输入本质上是一个探索应用程序状态的序列，它可能因输入而异。例如，其中一个二进制文件允许用户加载文件。处理文件时会触发该错误。相应的文件加载菜单可以出现在输入中的任何位置，因此文件中的偏移量与输入中加载的位置相关，因此很难自动推理偏移量。 鉴于上述问题，我们认为VUzzer不适合交互式程序，主要是因为它与这些程序的接口机制不佳。 B. LAVA数据集在最近的一篇论文中，Dolan-Gavitt等人。开发了一种注入难以触及的故障的技术，并创建了一些Linux实用程序的错误版本[17]，用于测试基于模糊测试和符号执行的错误查找解决方案。我们使用LAVA-M数据集[17]来评估VUzzer。该数据集由4个Linux实用程序-base64，who，uniq和md5sum组成，每个注入多个故障（每个实用程序使用相同的二进制文件）。 LAVA论文报告了在这些有缺陷的应用程序上评估基于覆盖的模糊器（FUZZER），符号执行和基于SAT的方法（SES）的结果。 为了提高可读性，我们重申表II中原始LAVA论文的结果。表II中的最后一列显示了VUzzer产生的结果。显示的数字是VUzzer识别的唯一错误。在md5sum的情况下，我们无法运行VUzzer，因为它在第一轮输入生成时崩溃，而不允许程序解析更多任何输入。 LAVA二进制文件中的每个注入故障都有一个ID，并且在每个二进制文件由于该故障而崩溃之前，ID将打印在标准输出上。这使我们能够精确识别VUzzer触发的故障。表III报告了VUzzer为每个LAVA二进制文件触发的故障的ID。 我们的LAVA数据集结果中出现了一些有趣的点。大多数LAVA注入的断层都是基于人工注入的路径条件，如lava到达特定路径并触发bug。由于其数据流功能，VUzzer非常好地捕获了这一点。例如，在base64模糊测试期间，我们了解到前四个字节应该是’val或lav’以跟随特定路径。类似地，我们发现最后几个字节应包含以下任何值以采用不同的路径：las [，lat\\x1b，Wsal等。应该注意，LAVA注入的大多数路径约束都是多字节约束。这种约束对于AFL在执行中更深入地造成了严重的问题（如[16]中所述）。另一个有趣的观点是VUzzer对who的表现。 LAVA文件中使用的模糊器甚至找不到一个bug，而VUzzer发现了几个独特的崩溃。 总体而言，在两个人工数据集中，VUzzer报告了令人鼓舞的结果，尽管正如预期的那样，它确实与DARPA CGC数据集中的交互式程序相悖。我们现在继续在实际程序中评估VUzzerz，这些程序也被其他模糊器考虑过。 C. 各种应用程序（VA）数据集我们使用真实世界程序的数据集（djpeg / eog，tcpdump，tcptrace，pdf2svg，mpg321，gif2png）来评估VUzzer的性能。Rebert等人还对这些程序进行了评估，以报告几个错误[43]，因此我们将这些程序纳入我们的评估中，用于比较目的。对于这些程序中的每一个，我们在Ubuntu 14.04中使用vanilla发行版。我们注意到，通过评估这些实用程序，我们还针对一些著名的库，如libpcap，libjpeg，libpoppler和libpng。每个程序最多24小时模糊。为了突出VUzzer的性能，我们还在这些应用程序上运行了AFL。表IV显示了在VA数据集上运行VUzzer和AFL的结果，VUzzer在发现的唯一崩溃次数和触发此类崩溃所需的输入数量方面明显优于AFL。 图5详细描述了24小时内崩溃的分布情况。每个图的x轴显示每2小时采样的累计崩溃总和。如图所示，对于几乎所有应用程序，VUzzer在后续的模糊测试中不断发现崩溃，而AFL在几次初始迭代后很快就耗尽了精力。这是因为在后期阶段，AFL无法找到新的（更深的）路径，而VUzzer能够在探索新路径时学习分支约束，因此能够在模糊测试的后期阶段发现崩溃。图5中另一个有趣的注意事项是，与AFL相比，VUzzer不仅能够以更少的输入找到崩溃，而且还可以在更短的时间内完成（参见图5中垂直线的位置）。我们想再次说明我们还没有优化VUzzer来实现快速输入。我们认为存在多种提高VUzzer执行速度的技术，例如，在单个模糊迭代中使用类似AFL的fork服务器，或者在多个核心或机器上分配并发模糊工作者。 D. Crash - Triage分析Fuzzers倾向于产生大量崩溃。修复与崩溃相关的每个错误都是一个耗时但有利可图的过程。提供给软件开发人员的唯一信息是应用程序的版本号和崩溃本身。当然，错误修补工作投入到更多（安全性）关键的错误中。 ！Exploitable [19]是CERT提出的一种工具，它建立在GDB之上，并使用启发式方法来评估由bug引起的崩溃的可利用性。启发式算法基于崩溃位置，内存操作（读取或写入）以及应用程序触发的信号。虽然这种分析不合理，但它简单，快速，并提供了崩溃严重程度的提示。我们使用！Exploitable工具对VUzzer在此数据集上发现的崩溃进行排名。表五列出了我们的结果。 如表中所示，由于！Exploitable工具的简单性，大多数情况都被标记为未知。没有一个案例被标记为可能可利用。最后，VUzzer在tcptrace中发现的每次崩溃似乎都是可利用的。我们调查了tcptrace中的一个崩溃，并且有一种看似明显的方法来利用它：漏洞是对堆缓冲区的越界写入。写入的边界和数据受到污染（即，受攻击者控制）。 了进一步分析VUzzer发现的错误的质量，我们测量了crash与所涉及的库之间的距离（如果有的话）。位于库中的错误可能会包含在使用该库的任何应用程序中，因此这些错误具有高优先级。我们还需要记住，这些是未知的错误，因此其中许多可能是0-day。当我们发现大量独特崩溃时，尽早报告最重要的崩溃是一个优先事项，因此我们依靠自动分析来估计错误的严重性。简而言之，如果库中发生崩溃，那么报告就是一个严重的错误。但是，有时在用户应用程序中会出现错误，但错误的真正原因在于应用程序使用的库。因此，当在应用程序代码中观察到崩溃时，我们还测量距上一次库调用的距离。 崩溃与库之间的距离由两个指标衡量。首先，我们计算崩溃和最后一次库调用之间执行的指令数。直觉是最终导致崩溃的计算（及其副作用）可能源于库调用。其次，我们计算崩溃和最后一次库调用之间的堆栈帧数。作为一个例子，使用驻留在主应用程序中的输出函数钩子的库（例如 tcpdump，tcptrace，mpg321）被这种启发式方法所覆盖。表VI列出了我们的分析结果。 mpg321中的所有崩溃都发生在（libid3tag）库中。发行版维护者对libid3tag库进行了大量修补（补丁级别为10）。这表明该库已知包含许多错误。 gif2png总是在应用程序内部崩溃。高数据的指标均证实了这一点。 pdf2svg大部分时间都在libpoppler中崩溃。堆栈帧距离为3，因为信号从Linux的vdso通过标准库路由。 tcpdump和tcptrace使用相同的（libpcap）库，但由于tcpdump显示网络流的内容，因此它与库的距离更远。 基于上述分析，我们认为VUzzer报告的许多崩溃事件都发现了0-day漏洞，我们目前正在向开源社区进行负责任的披露。表七提供了迄今为止我们分析和报告的一些错误的信息。 相关工作在前面的部分中，我们已经强调了VUzzer和AFL之类的状态模糊器之间的一些主要区别。在本节中，我们调查了最近在模糊测试领域的其他研究工作。这使我们能够突出显示与现有工作相关的一些功能和差异。 A. 基于搜索的进化输入生成使用进化算法进行输入生成是软件工程中一个经过深入探索的研究领域[7]，[34]。已经尝试使用进化算法进行输入生成以发现应用程序中的漏洞[25]，[42]，[45]。不同之处在于，这些方法假定应用程序的先验知识集中在导致程序易受攻击部分的路径上。这个属性使这些方法更接近定向模糊测试，因此，我们的模糊测试策略大大偏离它们。与VUzzer不同，与AFL类似，这些方法使用的反馈循环不会尝试将应用程序行为与输入结构相关联以增强输入生成。 B. Whitebox模糊测试方法Whitebox模糊测试是通过考虑应用程序的属性来提高传统随机模糊测试性能的最早尝试之一。有许多方法可以使模糊测试更有效，例如，通过应用符号执行和动态污点分析来解决分支约束[20] - [24]，[26]。虽然VUzzer在很多方面都与这些方法不同，但根本的区别仍然是符号执行的使用。与VUzzer类似，Ganesh等人提出的BuzzFuzz [20]利用动态污点分析，但用途完全不同。BuzzFuzz是一个定向模糊器，因此，它不会尝试学习每条路径的约束。它使用污点分析来检测影响代码中危险点的字节，如库调用参数，并在输入中改变这些字节以触发异常行为。大多数这些方法还需要源代码的可用性来执行分析。 C. Blackbox / Graybox模糊测试方法尽管简单且完全与应用程序无关，但Blackbox模糊器，如Peach [1]，Sulley [39]和Radamsa [40]已经发现了实际应用程序中的错误。但是，在整篇论文中，我们已经讨论了这种模糊器的局限性。 最近，基于符号和模仿执行的模糊测试方法在“智能”模糊测试领域占主导地位[12]，[38]，[47]，[51]。 Mayhem [12]是CMU的一个系统，用于自动查找二进制代码中可利用的错误，它使用多种程序分析技术（包括符号执行）来推理给定输入的应用程序行为。这与VUzzer的思想相似。但是，由于VUzzer的目标与Mayhem的目标不同，VUzzer不需要重量级的程序分析技术，而是通过应用基于轻量级程序分析的启发式方法来推断输入的重要属性。同样，Driller [47]使用混合的concolic执行技术[33]通过解决分支约束来进行更深入的路径探索来辅助模糊测试。在[28]中，Kargen’等提出一种不同的方法来生成模糊输入。对于正在测试的给定应用程序，他们的方法通过注入影响输出的故障来修改另一个输入生成器应用程序。使用此策略，错误程序生成变异输入。但是，目前尚不清楚这些突变输入是否确实会影响应用程序消耗这些输入的方式。 TaintScope [49] - 校验和感知模糊器 - 使用污点分析来推断校验和处理代码，这进一步有助于模糊旁路校验和检查。在模糊测试时，VUzzer也可以从这种（补充）技术中受益。在最近的一项工作[8]（与我们的工作同时进行）中，AFLFAST的作者提出了一种基于马尔可夫模型的技术来识别低频路径，以便将模糊测试的重点放在该方向上。部分由VUzzer使用的启发式算法是对由最大输入数量执行的路径进行优先级排序。 VUzzer的错误处理基本块检测技术与此类似，虽然权重很轻。 VUzzer应用其他数据和控制流功能来加速输入生成。 还有其他一些技术来增强模糊测试[11]，[43]，[51]。 VUzzer还可以通过多种方式从这些方法中受益。例如，种子选择[43]可以帮助VUzzer从一组良好的种子输入开始。 结论本文认为，模糊测试的关键优势在于实现轻量级，可扩展的错误查找技术，并且应用重量级和不可扩展的技术（如基于符号执行的方法）不是提高基于覆盖fuzzing的性能的最终解决方案。在研究了几种现有的通用（黑/灰盒）模糊器（包括最先进的AFL模糊器）后，我们注意到它们往往与应用程序无关，这使得它们在发现根深蒂固的错误方面效率较低。应用程序不可知策略的关键限制是它们无法更快地生成有趣的输入。我们通过模糊化应用程序感知测试过程来解决这个问题。 我们利用应用程序的控制和数据流特征来推断输入的几个有趣属性。控制流特征允许我们对某些路径进行优先级排序和优先级排序，从而使输入生成成为受控过程。我们通过为基本块分配权重并为输入实现权重感知适应性策略来实现这一点。 通过使用动态污点分析，我们还监控应用程序的多个数据流特征，使我们能够推断输入的结构属性。例如，这为我们提供了有关输入中的哪些偏移在几个分支条件下使用，哪些值用作分支约束等的信息。我们在反馈循环中使用这些属性来生成新输入。 我们在一个名为VUzzer的开源原型中实现了我们的模糊测试技术，并在几个应用程序上对其进行了评估。我们还将其性能与AFL的性能进行了比较，结果表明，在几乎所有测试案例中，与AFL相比，VUzzer能够在少于一个数量级的输入下发现错误。这具体表明，通过分析应用行为来推断输入属性是一种可行且可扩展的策略，可以提高模糊性能，并为该领域的未来研究提供有希望的方向。","content":"<h1 id=\"Abstract\"><a href=\"#Abstract\" class=\"headerlink\" title=\"Abstract\"></a>Abstract</h1><p>Fuzzing是一种有效的软件测试技术，用于查找错误。考虑到实际应用程序的大小和复杂性，现代模糊器往往是可扩展的，但在探索执行更深层次的错误或者能够在应用程序中深入渗透但不具有可扩展性方面无效。在本文中，我们提出了一种应用程序感知的进化模糊测试策略，它不需要任何有关应用程序或输入格式的先验知识。<strong>为了最大化覆盖范围并探索更深入的路径，我们利用基于静态和动态分析的控制和数据流特征来推断应用程序的基本属性。</strong>与应用程序无关的方法相比，这可以更快地生成有趣的输入。我们在VUzzer中实现我们的模糊测试策略并在三个不同的数据集上进行评估：DARPA Grand Challenge二进制文件（CGC），一组实际应用程序（二进制输入解析器）和最近发布的LAVA数据集。在所有这些数据集中，通过快速查找几个现有和新的错误，VUzzer产生的结果明显优于最先进的模糊器。</p>\n<table>\n<thead>\n<tr>\n<th>relevant information</th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><em>作者</em></td>\n<td>Sanjay Rawat, Vivek Jain, Ashish Kumar, Lucian Cojocar,Cristiano Giuffrida and Herbert Bos</td>\n</tr>\n<tr>\n<td><em>单位</em></td>\n<td>Computer Science Institute, Vrije Universiteit Amsterdam;Amsterdam Department of Informatics  International Institute of Information Technology, Hyderabad</td>\n</tr>\n<tr>\n<td><em>出处</em></td>\n<td>NDSS ’17</td>\n</tr>\n<tr>\n<td><em>原文地址</em></td>\n<td><a href=\"https://github.com/wtwofire/database/blob/master/papers/fuzzing/2017-VUzzer%20Application-aware%20Evolutionary%20Fuzzing.pdf\" target=\"_blank\" rel=\"noopener\">https://github.com/wtwofire/database/blob/master/papers/fuzzing/2017-VUzzer%20Application-aware%20Evolutionary%20Fuzzing.pdf</a></td>\n</tr>\n<tr>\n<td><em>源码地址</em></td>\n<td><a href=\"https://github.com/vusec/vuzzer\" target=\"_blank\" rel=\"noopener\">https://github.com/vusec/vuzzer</a></td>\n</tr>\n<tr>\n<td><em>发表时间</em></td>\n<td>2017年</td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"论文简略概括：\"><a href=\"#论文简略概括：\" class=\"headerlink\" title=\"论文简略概括：\"></a>论文简略概括：</h1><p><img src=\"/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/17.png\" alt=\"\"></p>\n<p><strong><em>其它相关源码地址：</em></strong></p>\n<p>污点分析数据存储结构：<a href=\"https://github.com/lemire/EWAHBoolArray\" target=\"_blank\" rel=\"noopener\">https://github.com/lemire/EWAHBoolArray</a></p>\n<p>AFLPIN: <a href=\"https://github.com/mothran/aflpin\" target=\"_blank\" rel=\"noopener\">https://github.com/mothran/aflpin</a></p>\n<p>AFLFAST: <a href=\"https://github.com/mboehme/aflfast\" target=\"_blank\" rel=\"noopener\">https://github.com/mboehme/aflfast</a></p>\n<p>DECREE: <a href=\"https://github.com/CyberGrandChallenge/cgc-releasedocumentation/blob/master/walk-throughs/pin-for-decree.md\" target=\"_blank\" rel=\"noopener\">https://github.com/CyberGrandChallenge/cgc-releasedocumentation/blob/master/walk-throughs/pin-for-decree.md</a></p>\n<h1 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h1><p>在本文中，我们介绍了VUzzer，一个应用程序感知的进化模糊器，它既可扩展又可快速发现执行中的漏洞。与优化输入生成过程以最大速率生成输入的方法相比，我们的工作探索了设计领域的一个新点，我们在前端做更多的工作，产生更少但更好的输入。关键的直觉是我们可以通过基于控制和数据流应用功能的“智能”突变反馈回路来提高通用模糊器的效率，而无需采用可扩展性较低的符号执行。我们展示了我们可以通过在模糊运行期间对应用程序进行轻量级静态和动态分析来提取这些功能。我们的控制流功能允许VUzzer优先考虑深度（并因此感兴趣）路径，并在改变输入时优先考虑频繁（因此无趣）路径的优先级。我们的数据流功能允许VUzzer准确地确定改变这些输入的位置和方式。</p>\n<p>由于其应用感知突变策略，VUzzer比现有的模糊器更有效。我们评估了VUzzer在三个不同数据集上的表现：a）DARPA CGC二进制文件[15]，这是一组人工创建的交互式程序，旨在评估错误发现技术; b）一组具有不同复杂程度的Linux程序（djpeg，mpg321，pdf2svg，gif2png，tcpdump，tcptrace）和c）最近发布的来自LAVA团队的二进制文件[17]，许多Linux实用程序都有几个注入的错误。在我们对不同数据集的实验中，我们通过生成数量级较少的输入来表现优于AFL，同时发现更多崩溃。例如，在mpg3211中，我们通过执行23K输入发现300次独特崩溃，而883K输入则通过AFL找到19次独特崩溃。</p>\n<p>贡献：我们做出以下贡献：</p>\n<p>1）我们表明现代模糊器可以“更智能”而不需要采用符号执行（难以扩展）。我们的应用感知突变策略将AFL等最先进的模糊器的输入生成过程提高了几个数量级。</p>\n<p>2）我们提出了几个应用程序特征来支持有意义的输入变异。</p>\n<p>3）我们在三个不同的数据集上评估VUzzer，一个实现我们方法的功能齐全的模糊器，并表明它非常有效。</p>\n<p>4）为了促进该领域的进一步研究和支持开放科学，我们开放我们VUzzer原型的源代码，可在<a href=\"https://www.vusec.net/projects/fuzzing获得。\" target=\"_blank\" rel=\"noopener\">https://www.vusec.net/projects/fuzzing获得。</a></p>\n<h1 id=\"总体描述\"><a href=\"#总体描述\" class=\"headerlink\" title=\"总体描述\"></a>总体描述</h1><p>为了解决上一节中提到的挑战，我们提出了VUzzer，一种应用程序感知的进化模糊器。图1概述了其主要组件。</p>\n<p>由于VUzzer是一个进化模糊器，因此有一个反馈循环可以帮助从旧的输入中获得新的输入。生成新输入时，VUzzer会根据其在上一轮输入上的执行情况来考虑应用程序的特征。通过考虑这些特性，我们使反馈回路“智能”并帮助模糊器找到具有高频率的非零IG的输入。</p>\n<p><img src=\"/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/1.png\" alt=\"\"></p>\n<h2 id=\"1-特征\"><a href=\"#1-特征\" class=\"headerlink\" title=\"1. 特征\"></a>1. 特征</h2><p><strong>数据流特征</strong>：数据流特征提供有关应用程序中输入数据和计算之间关系的信息。 VUzzer使用诸如污点分析之类的众所周知的技术来提取它们，并使用它们根据输入中某些偏移处的数据类型来推断输入的结构。例如，它通过检测x86 ISA的cmp系列的每个指令来确定分支的字节（“分支约束”），以确定它使用哪些输入字节（偏移）以及它与哪些值进行比较。通过这种方式，VUzzer可以确定哪些偏移对于变异感兴趣以及在这些偏移处使用哪些值（在第I部分中提供问题的部分答案）。 VUzzer现在能够通过更频繁地定位此类偏移并通过在这些偏移处使用预期值来满足分支约束来更明智地进行变异。这样做可以解决魔术字节的问题，而无需使用符号执行。</p>\n<p>同样，VUzzer监视lea指令以检查索引操作数是否被污染。如果是这样，它可以确定相应偏移处的值是int类型并相应地改变输入。除了这两个简单但功能强大的特征外，还有许多其他功能。</p>\n<p><strong>控制流特征</strong>：控制流特征允许VUzzer推断某些执行路径的重要性。例如，图2显示了清单3中代码的简化CFG。执行错误块的输入通常是不感兴趣。因此，识别这样的错误处理块可以加速感兴趣输入的生成。我们将在以下部分中展示如何检测错误处理代码。目前，我们假设我们可以启发式地识别包含错误处理程序的基本块。</p>\n<p>另一个例子涉及嵌套块的可达性。到达块F的任何输入更有可能比到达块H的输入更深入到代码中，因为后者不是嵌套的。我们使用控制流特征来对路径进行去优先级和优先级排序。由于枚举应用程序中的所有可能路径是不可行的，我们通过为各个基本块分配权重来实现此度量。具体而言，作为错误处理代码一部分的基本块获得负权重，而难以到达的代码区域中的基本块获得更高权重。</p>\n<p><img src=\"/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/2.png\" alt=\"\"></p>\n<p>图1显示了单次模糊测试包含几个步骤。 VUzzer期望有效输入的初始池SI，称为种子输入。第一步是执行过程内静态分析以获得一些控制流和数据流特征（第III-B节），然后是主要的进化模糊循环。在本节的其余部分，我们将介绍描述整个过程的所有步骤。</p>\n<h2 id=\"2-静态分析器\"><a href=\"#2-静态分析器\" class=\"headerlink\" title=\"2.  静态分析器\"></a>2.  静态分析器</h2><p>在模糊测试过程开始时，我们使用轻量级过程内静态分析来（i）通过扫描应用程序的二进制代码来获得cmp指令的立即值，以及（ii）计算应用程序二进制文件基本块的权重。</p>\n<p>应用程序代码中cmp指令中存在的许多立即值通常表示应用程序期望输入在某些偏移处具有许多这些值。例如，清单3中对程序的分析产生了每个基本块的权重列表LBB和包含{0xEF，0xFD，％，@，MAZE}的字节序列的列表Limm。为了确定基本块权重，我们将每个函数的CFG建模为马尔可夫模型，并计算到达函数中每个基本块b的概率pb。然后我们计算每个基本块b的权重wb为1 / pb。因此，到达基本块的概率越低，权重越高。使用该模型，每个基本块的概率和权重显示在图2中的每个节点旁边（参见第IV-A3节）。我们观察到，例如，到达基本块G的概率小于到达基本块F的概率，而基本块F的概率低于基本块H.VUzzer在模糊循环的后续步骤中使用这些列表。</p>\n<h2 id=\"3-主fuzzing循环\"><a href=\"#3-主fuzzing循环\" class=\"headerlink\" title=\"3.  主fuzzing循环\"></a>3.  主fuzzing循环</h2><p>我们通过使用算法1中的步骤来描述主fuzzing循环。在主循环开始之前，我们用一组种子输入SI执行应用程序以推断出一组初始的控制流和数据流特征。对于SI中的所有输入，我们运行动态污点分析（DTA）以捕获有效输入的共同特征。具体来说，我们这样做是为了前面提到的魔术字节和错误处理代码检测。使用这些功能，我们生成一个初始输入总体，作为算法1中INITIALIZE步骤的一部分。请注意，我们的魔术字节检测确保这些新输入跨越第一次这样的应用程序检查。由于DTA具有很高的开销，我们在主循环开始后尽可能少地使用它。</p>\n<p><strong>输入执行</strong>：我们使用上一步中的每个输入执行应用程序，并生成相应的已执行基本块的跟踪。如果任何输入执行以前未见过的的基本块，我们会污染输入并使用DTA通过监视应用程序的数据流功能来推断其结构属性。</p>\n<p><strong>适应度计算</strong>：在算法1的EVALUATE步骤中，我们计算每个输入的适应度作为执行的基本块的频率的加权和。我们使用权重列表LBB在基本块上分配权重。属于错误处理代码的基本块会产生负权重 - 现在我们仍然假设我们可以识别这些基本块。该适应度计算背后的直觉是为执行具有较高权重的基本块的输入提供高分，从而对相应路径进行优先级排序，同时还执行具有高频率的某些基本块以捕获大循环。例如，让我们考虑两个路径p1和p2，分别由两个输入i1和i2执行，使得p1 = A-&gt; B - &gt; D - &gt;E - &gt;H - &gt;J和p2 = A - &gt;B - &gt;D - &gt;E - &gt;F - &gt;J.为简单起见，让我们假设错误处理基本块J得到权重-1并且每个基本块的执行频率为1.使用图2中的权重，p1和p2的频率的加权和为7 （1 + 1 + 2 + 2 + 2-1）和9（1 + 1 + 2 + 2 + 4-1）。因此，输入i2获得更高的适应度分数，并且将比i1更多地参与生成新输入。该步骤最终生成按其适应度分数降序排列的输入排序列表。</p>\n<p><strong>遗传算子和新输入生成</strong>：这是我们模糊测试策略中最后也是最重要的功能，包括算法1中的SELECT，RECOMBINE和MUTATE步骤。这些子步骤一起负责生成有趣的输入。在主循环的每次迭代中，我们通过组合和突变SI的输入，所有受污染的输入以及Lf的前n％来生成新一代输入。我们将此集称为ROOT集。</p>\n<p>具体来说，我们通过交叉和变异生成新的输入。首先，我们从ROOT中随机选择两个输入（父项）并应用交叉来生成两个新输入（子项）。具有固定概率，这两个输入进一步经历突变。 Mutation使用多个子操作，例如删除，替换和在给定输入中的某些偏移处插入字节。变异运算符利用数据流功能生成新值。例如，在插入或替换字节时，它使用来自Limm的字符来生成不同长度的字节序列。类似地，选择来自当前输入的父项的各种偏移用于突变。因此，如果存在任何魔术字节，它们将在结果输入中的适当偏移处被替换。</p>\n<p>这个循环的输入生成一直持续到我们满足终止条件。目前，我们在发现崩溃或VUzzer达到预先配置的代数时终止。</p>\n<h1 id=\"设计与实现\"><a href=\"#设计与实现\" class=\"headerlink\" title=\"设计与实现\"></a>设计与实现</h1><h2 id=\"1-实现细节\"><a href=\"#1-实现细节\" class=\"headerlink\" title=\"1. 实现细节\"></a>1. 实现细节</h2><p><strong>1）动态污点分析（DTA）</strong>：DTA是VUzzer的核心，因为它在发展新输入方面发挥着重要作用。这也是将VUzzer与现有模糊器区分开来的技术。 DTA用于监视应用程序内受污染的输入（例如，网络包，文件等）的流动。在程序执行期间，DTA可以确定哪些存储器位置和寄存器依赖于受污染的输入。根据粒度，DTA可以将受污染的值追溯到输入中的各个偏移量。 VUzzer使用DTA跟踪cmp和lea指令中使用的污染输入偏移。对于每个执行的cmp指令cmp op1，op2（op1和op2可以是寄存器，存储器或立即操作数），DTA确定op1和/或op2是否被一组偏移污染。我们的DTA实现能够在字节级别跟踪污点。对于给定的受污染操作数op，DTA为op的每个字节提供污点信息。</p>\n<p><strong>2）魔术字节检测</strong>：基于我们对具有魔术字节的文件格式的理解，我们假设魔术字节是输入字符串中固定偏移处的固定字节序列。我们已经在几种具有魔术字节的文件格式上验证了这一假设，例如jpeg，gif，pdf，elf和ppm。由于VUzzer是给定应用程序的一些有效输入的可用性，我们在模糊测试开始时在这些输入上使用DTA的结果。由于应用程序期望输入包含魔术字节，因此DTA在cmp指令上的结果将包含对魔术字节的相应检查。</p>\n<p>例如，清单3中的代码在输入文件的开头需要一个魔术字节0xFDEF。因此，DTA将捕获两条cmp指令 - cmp reg，0xFD，reg受到偏移0的污染，cmp reg，0xEF，reg受到偏移量1的污染。如果对这个程序我们有一个有效输入的集合，我们可以在所有相应的执行中观察这两条cmp指令。相反，如果对于一组有效输入，我们在所有输入的DTA结果中得到cmpi =（oi; vi），vi是偏移oi的魔术字节的一部分。</p>\n<p>在魔术字节检测期间，对于给定的cmpi指令，如果相应的值取决于每个字节的多个偏移，我们不认为这种偏移是魔术字节候选。例如，对于给定的cmp指令，如果DTA检测到|Tji|&gt; 1，我们从魔术字节占位符的任何进一步考虑中排除这些偏移（ÎTji）。这种情况表明相应操作数的值可以从那些偏移ÎTji处的污染值导出。对多个字节的依赖打破了魔术字节是固定（常量）字节序列的假设。我们将所有这些偏移的集合表示为Oother。</p>\n<p><strong>3）基本块权重计算</strong>：从基于覆盖的fuzzing角度来看，每条可行路径对于遍历都很重要。一个简单的模糊测试策略是花费同等的努力为所有可行路径生成输入。但是，由于存在控制结构，某些路径的可达性可能与其他路径的可达性不同。如果我们有嵌套的控制结构，这种情况就会频繁出现[41]。因此，与其他输入相比，任何运行这种难以触及的代码的输入都应该得到更多奖励。</p>\n<p>我们通过为嵌套控制结构中包含的基本块指定更高权重来合并此奖励。由于枚举过程间级别的所有路径都难以缩放，我们的分析在过程间级别，即，我们计算包含在函数内的每个基本块的权重。稍后，我们收集并添加由给定输入执行的路径中所有基本块的权重。通过这种策略，我们通过将几个过程内路径分数拼接在一起来模拟过程间路径的分数。</p>\n<p>如果我们认为特定基本块的输入到下一个基本块的转换取决于某个概率，我们可以从控制流图（CFG）中导出一个称为马尔可夫过程的概率模型用于输入行为。马尔可夫过程是一个随机过程，其中给定试验的结果仅取决于过程的当前状态[30]。我们将函数的CFG建模为马尔可夫过程，其中每个基本块具有基于其与其他基本块的连接的概率。</p>\n<p>对于给定的基本块，我们为其所有输出边分配相等的概率。因此，如果out（b）表示基本块b的所有输出边缘的集合，则∀eb <em> Î out（b）; prob（eb </em>）= 1/|out（b）|。基本块b的转移概率（似然）计算如下：</p>\n<p><img src=\"/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/11.png\" alt=\"\"></p>\n<p>其中prod（b）是b的所有前辈的集合。我们使用定点迭代算法来计算与CFG中的每个基本块相关联的概率。 CFG的root基本块初始化概率为1。通过为每个后备项分配固定概率1来处理循环，从而忽略后备本身的影响（即，我们将循环展平以加速定点计算）。从等式1，每个基本块b的权重由下式给出：</p>\n<p><img src=\"/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/12.png\" alt=\"\"></p>\n<p><strong>4）错误处理代码检测</strong>：如前所述，在模糊测试期间，大多数突变输入将执行最终处于某种错误状态的路径。对这些执行路径进行优先级排序是提高创建有趣输入的机会的关键一步。我们的错误处理检测启发式依赖于有效输入的可用性，这是VUzzer的先决条件。由于我们的错误处理检测取决于应用程序的动态行为，因此它以增量方式检测错误处理基本块。</p>\n<p><strong><em>初始分析</em></strong>：对于每个有效输入iÎSI，我们收集由i执行的基本块的集合BB（i）。设ValidBB表示所有有效输入的所有这些已执行基本块的并集。然后我们创建一组完全随机的输入，表示为TR。对于此集合中的每个输入，我们根据基本块收集其执行跟踪。如果在来自TR的输入的每次执行中存在并且它不存在于ValidBB中，则假定来自这样的一组执行的基本块是错误处理基本块（即，属于错误处理代码）。直觉是因为SI是一组有效输入，所以不会触发错误处理代码。因此，ValidBB将仅包含与有效路径对应的基本块。由于TR是一组完全随机的输入，它们很可能在执行期间被错误处理代码捕获。</p>\n<p>我们是一种非常保守的错误处理基本块检测策略，因为如果某些输入被不同的错误处理代码捕获，我们可能会错过几个基本块。尽管如此，请注意，我们永远不会将与有效路径对应的基本块分类为错误处理基本块。更正式的表示如下</p>\n<p><img src=\"/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/13.png\" alt=\"\"></p>\n<p>EHB就是错误处理基本块集合。</p>\n<p><strong><em>增量分析</em></strong>：我们观察到，由于我们的错误处理检测策略基于应用程序的动态行为，因此在初始分析期间不会触发所有错误处理代码。随着输入的发展，它们会探索更多路径，从而遇到新的错误处理代码。出于这个原因，我们在后来的模糊测试迭代期间启动增量分析。在我们的实验设置中，我们观察到，随着我们进行更多的模糊测试迭代，新的错误处理代码实例的数量减少了。这反映了软件具有有限数量的错误处理代码实例的直觉，这些代码实例在应用程序的不同部分中重用。因此，当我们执行更多迭代时，我们减少运行增量分析的频率。</p>\n<p>我们的增量分析背后的直觉是观察到，随着模糊测试的进行，大多数新生成的输入最终会触发一些错误处理代码。在给定的迭代中，让I成为迭代中生成的输入集。让大多数量由|I|的n％量化。我们的（离线）实验表明，n = 90是一个合理的选择。设BB（I）是由I中的输入执行的所有基本块的集合。如果它与来自I的输入少与n％的相关联，且它不在V alidBB集中，则将来自BB（I）的基本块b分类为错误处理基本块。更正式地说，让P（I）表示I的幂集。然后</p>\n<p><img src=\"/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/14.png\" alt=\"\"></p>\n<p><strong><em>错误处理基本块的权重计算</em></strong>：在检测到错误处理基本块（EHB）之后，我们希望对包含此类块的路径进行优先级排序。我们通过惩罚相应的输入来实现这一点，以便这些输入参与下一代的机会较少。为此，每个EHB都给出负权重，这会影响相应输入的适合度（见第IV-A5节）。然而，这种策略本身并不充分，因为与输入执行的基本区块总数相比，EHB只是少数，因此这么小的数量将产生微不足道的影响。我们通过定义影响系数μ（可调参数）来解决这个问题，影响系数μ决定单个错误处理基本块可以使多少（非错误处理）基本块无效。直观地，该参数确定，一旦输入进入错误处理代码，任何相应基本块在计算适合度分数时的贡献必须减少因子μ。对于给定的输入i，我们使用以下公式进行重量计算。</p>\n<p><img src=\"/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/15.png\" alt=\"\"></p>\n<p>其中|BB（i）|是由输入i执行的所有基本块的编号，|EHB（i）|是由i执行的所有错误处理基本块的编号，并且0.1≤μ≤1.0。</p>\n<p><strong>5）适应度计算</strong>：适应度计算是进化算法最重要的组成部分之一。这对于实现反馈回路至关重要，这为下一步的输入生成提供了动力。一旦产生新的输入，其参与产生新输入的机会取决于其适合度。</p>\n<p>VUzzer以两种方式评估输入的适应性。如果输入的执行导致发现新的非EHB基本块，则输入有资格参与下一代。这类似于AFL（额外使用EHB组）。然而，如前所述，这种适应度测量认为所有新发现的路径相等，这是有问题的。输入的重要性（以及因此适应性）取决于其执行的路径的兴趣度，而该路径又取决于相应基本块的权重。因此，我们将输入i的适应度fi定义为捕获所有相应基本块权重的效果的函数。</p>\n<p><img src=\"/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/16.png\" alt=\"\"></p>\n<p>其中BB（i）是由输入i执行的基本块的集合，Freq（b）是当由i执行时基本块b的执行频率，Wb是基本块b的权重（通过使用等式2），li是输入i的长度，LMAX是输入长度的预配置限制。 LMAX用于解决输入膨胀现象。在遗传算法的说法中，两个适应度标准（即发现新基本块的能力和更高的fi）都对应于探索和开发的概念 - 发现新的基本块表示新的方向（即探索）和较高的fi表示基本块的较高执行频率（以及其他因素）（即，在相同方向上的利用）。</p>\n<p><strong>6）输入生成</strong>：VUzzer的输入生成由交叉和变异两部分组成，它们不是互斥的，即交叉以固定的概率跟随在变异之后。</p>\n<p>交叉：交叉是一种简单的操作，其中从前一代中选择两个父输入，并生成两个新的子输入。</p>\n<p>变异：变异是一种更复杂的操作，它涉及若干子操作以将给定的父输入改变为相应的子输入。该过程在以下步骤中详述：</p>\n<ul>\n<li><p>步骤1：从集合Oother中随机选择受污染的偏移量并在这些偏移量处插入字符串。字符串由从集合Limm获得的字节组成。</p>\n</li>\n<li><p>步骤2：从集合Llea中随机选择偏移量并通过用有趣的整数值（例如0，MAX UINT，负数）替换它们来改变来自步骤1的字符串中的这种偏移量。</p>\n</li>\n<li><p>步骤3：对于父输入的所有受污染的cmp指令，如果op1 ≠ op2的值，则将步骤2中字符串中受污染偏移的值替换为op2的值，否则将以固定概率替换受污染的值字节由随机字节序列组成。</p>\n</li>\n<li><p>步骤4：将魔术字节放置在由我们的魔术字节检测器确定的相应偏移处。</p>\n</li>\n</ul>\n<h2 id=\"2-实现细节\"><a href=\"#2-实现细节\" class=\"headerlink\" title=\"2. 实现细节\"></a>2. 实现细节</h2><p>VUzzer的核心功能是在<strong><em>Python 2.7</em></strong>中实现的。一些实现的分析，例如错误处理基本块检测的增量分析，是内存密集型的，因此我们还利用了更新版本（如<strong><em>BitVector3</em></strong>）提供的高效数据结构。 VUzzer内部由两个主要组件组成，包括静态和动态分析，如下面进一步详述。</p>\n<p><strong>静态分析</strong>：VUzzer在IDA [27]中实现了两种静态分析（常量字符串提取和基本块权重计算）。分析是使用IDAPython [18]用Python编写的。</p>\n<p><strong>动态分析</strong>：VUzzer在Pin动态分析框架的顶部实现了动态分析（基本块跟踪和DTA）[31]。对于基本块跟踪，我们实现了一个pintool来记录执行期间遇到的每个基本块及其频率。我们的pintool可以根据需要有选择地跟踪某些库执行的基本块。选择性库监控允许我们减少执行跟踪开销并专注于预期的应用程序代码。</p>\n<p>我们的DTA实现基于Stamatogiannakis等[46]提出的<strong><em>DataTracker</em></strong>，后者又基于LibDFT [29]。由于LibDFT只能处理32位应用程序，因此当前的VUzzer原型只能用于模糊32位应用程序（也用于我们的评估）。请注意，这不是一个基本限制，事实上，我们正在VUzzer中实现64位支持。任何更新版本将在<a href=\"https://www.vusec.net/projects/fuzzing上提供。\" target=\"_blank\" rel=\"noopener\">https://www.vusec.net/projects/fuzzing上提供。</a></p>\n<p>为了使其适合我们的目的，我们还对DataTracker进行了一些更改：</p>\n<ul>\n<li><p>在DataTracker中，与每个内存位置关联的污点标记被建模为元组：&lt;ufd，file_offeset&gt;，即唯一文件描述符和与该描述符关联的文件的偏移量。这些元组中的每一个都是64位长（ufd为32位，file_offset为32位）。每个内存位置都有一组与之关联的元组，以确定偏移量和内存位置受污染的文件。我们将其更改为<strong>EWAHBoolArray type</strong>，它是一种压缩的bitset数据类型。由于我们只需要来自一个（输入）文件的数据流信息，因此我们修改了DataTracker以仅通过该文件传播污点。因此，在我们的修改版本中，与每个存储器位置相关联的污点标签被建模为仅包含偏移的EWAHBoolArray。因此，我们的实现速度至少快2倍，并且使用的内存比DataTracker少几倍。</p>\n</li>\n<li><p>我们为cmp系列指令添加了插桩回调，如CMP，CMPSW，CMPSB，CMPSL和lea指令，以捕获计算中涉及的操作数的字节级污点信息。</p>\n</li>\n<li><p>我们为每个实现的系统调用重写了钩子，并为一些额外的系统调用添加了钩子，例如pread64，dup2，dup3，mmap2等。为了评估我们在DARPA数据集[15]上的性能，我们还实现了基于DECREE的钩子系统调用，与普通的Linux系统调用不同。</p>\n</li>\n</ul>\n<p><strong>crash分类</strong>：一旦模糊测试开始产生崩溃，它可能会继续产生更多的崩溃，并且应该有一些机制来区分由于不同的错误（或相同的错误但不同的实例）导致的崩溃。为了确定崩溃的唯一性，<strong>VUzzer使用由Molnar等人提出的堆栈散列的变体[37]</strong>。在我们的pintool中，我们实现了一个环形缓冲区，用于跟踪最后5个函数调用以及在崩溃之前执行的最后10个基本块。我们计算此缓冲区的哈希值，每次遇到新的崩溃时，我们将新生成的哈希值与旧的哈希值进行比较，以确定报告的崩溃是否是新的唯一崩溃。</p>\n<h1 id=\"评估\"><a href=\"#评估\" class=\"headerlink\" title=\"评估\"></a>评估</h1><p>为了测量我们提出的模糊测量技术的有效性，本节介绍了对VUzzer的评估。为了将VUzzer显示给各种应用程序，我们选择在三个不同的数据集上测试VUzzer A. DARPA CGC二进制文件[15]，B. [43]中使用的二进制格式的杂项应用程序，C.最近的一组错误二进制文件由LAVA [17]生成。</p>\n<p>我们在配备32位2核Intel CPU和4 GB RAM的Ubuntu 14.04 LTS系统上进行了实验。对于DARPA CGC数据集，（提供的）环境是具有称为DECREE的自定义OS的VM。我们要强调的是，我们的主要评估目标是展示VUzzer在识别错误（可能深埋在执行中）的效率，其输入比AFL等最先进的模糊器少得多。我们当前的VUzzer原型并不像AFL那样针对快速输入执行进行优化，因此我们不寻求这方面的比较。</p>\n<h2 id=\"A-DARPA-CGC数据集\"><a href=\"#A-DARPA-CGC数据集\" class=\"headerlink\" title=\"A.  DARPA CGC数据集\"></a>A.  DARPA CGC数据集</h2><p>作为Cyber Grand Challenge的一部分，DARPA发布了一组二进制文件，这些二进制文件在一个名为DECREE的自定义操作系统中运行。共有131个二进制文件，其中注入了各种类型的错误。但是，由于以下原因，我们无法在所有这些上运行VUzzer：</p>\n<ul>\n<li><p>通过接受来自STDIN的输入，所有二进制文件本质上都是交互式的。一旦启动，其中许多人会提供一个菜单来选择一个动作，包括退出选项。此外，在许多情况下，有多个菜单（在程序的不同状态下）具有不同的退出选项。由于VUzzer需要生成完全随机输入的步骤（错误处理代码检测，第IV-A4节），执行此类输入会使应用程序循环，查找有效选项，包括退出选项。这会导致应用程序永远运行。这是一个接口问题，而不是我们的模糊测试方法的基本限制。</p>\n</li>\n<li><p>其中一些二进制文件是使用浮点指令编译的，这些指令LibDFT不能处理，因此VUzzer无法获得正确的数据流信息。</p>\n</li>\n<li><p>由于VUzzer基于Pin [32]，我们按照给定的程序在DECREE5中运行pintools。但是，我们无法使用Pin运行一些二进制文件。</p>\n</li>\n<li><p>某些二进制文件涉及与其他二进制文件的交互，而VUzzer无法处理这些二进制文件。 </p>\n</li>\n</ul>\n<p>在考虑了上面提到的障碍之后，我们总共留下了63个二进制文件。为了与AFL进行比较，我们还运行了AFLPIN，一种基于pintool的AFL实现。 AFLPIN具有与AFL相同的模糊引擎，但是获取执行跟踪的机制不同。我们选择使用AFLPIN代替AFL是为了与SUT具有相同的接口机制，即通过文件描述符0（STDIN）将输入传递给pintool。</p>\n<p>VUzzer在29个CGC二进制文件中发现了崩溃，而AFLPIN只发现了23个崩溃。由于每个CGC也附带修补版本，我们通过运行修补程序版本的二进制文件来验证VUzzer发现的每个错误，以避免进一步崩溃。最重要的结果是这两个模糊器中每次崩溃的执行输入数量。我们运行两个模糊器最多6个小时。图4描绘了两个模糊器发现崩溃（总共13个）的情况的执行次数，证明VUzzer与AFL相比可以显着修剪搜索空间。</p>\n<p>在对特定二进制NRFIN_00015进行模糊测试时，我们观察到以离散方式计算适应度分数fi的重要性。此二进制文件中的漏洞是循环中缓冲区溢出的典型情况。我们观察到在第18次迭代之后，没有发现新的BB，但是fi保持增加，表明典型的循环执行行为。在第63次迭代（总执行次数13K），我们到达缓冲区的边界。 AFLPIN无法检测到这次崩溃。</p>\n<p>我们注意到，我们目前对该数据集的结果是适度的，特别是在Driller [47]报告的结果中。我们进一步调查了结果，发现了一些可能会影响我们当前VUzzer原型在CGC上的性能的特性。</p>\n<ul>\n<li><p>在多个二进制文件中，只有通过执行给定菜单中的一组非常特定的操作才能达到错误状态。例如，在CROMU_00001应用程序中，必须执行以下操作：登录A - &gt;向用户B发送许多消息 - &gt;登录B - &gt;检查消息。目前，VUzzer无法重复序列。</p>\n</li>\n<li><p>有效输入的概念很模糊。回想一下，我们使用每个CGC二进制文件以XML文件形式提供的整个会话作为一个输入。因此，基本上没有无效输入的概念。因此，我们无法充分利用VUzzer的全部功能。</p>\n</li>\n<li><p>与上述相关的是有趣的抵消问题。由于CGC二进制文件是交互式的，因此输入本质上是一个探索应用程序状态的序列，它可能因输入而异。例如，其中一个二进制文件允许用户加载文件。处理文件时会触发该错误。相应的文件加载菜单可以出现在输入中的任何位置，因此文件中的偏移量与输入中加载的位置相关，因此很难自动推理偏移量。</p>\n</li>\n</ul>\n<p>鉴于上述问题，我们认为VUzzer不适合交互式程序，主要是因为它与这些程序的接口机制不佳。</p>\n<p><img src=\"/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/3.png\" alt=\"\"></p>\n<h2 id=\"B-LAVA数据集\"><a href=\"#B-LAVA数据集\" class=\"headerlink\" title=\"B.  LAVA数据集\"></a>B.  LAVA数据集</h2><p>在最近的一篇论文中，Dolan-Gavitt等人。开发了一种注入难以触及的故障的技术，并创建了一些Linux实用程序的错误版本[17]，用于测试基于模糊测试和符号执行的错误查找解决方案。我们使用LAVA-M数据集[17]来评估VUzzer。该数据集由4个Linux实用程序-base64，who，uniq和md5sum组成，每个注入多个故障（每个实用程序使用相同的二进制文件）。 LAVA论文报告了在这些有缺陷的应用程序上评估基于覆盖的模糊器（FUZZER），符号执行和基于SAT的方法（SES）的结果。</p>\n<p>为了提高可读性，我们重申表II中原始LAVA论文的结果。表II中的最后一列显示了VUzzer产生的结果。显示的数字是VUzzer识别的唯一错误。在md5sum的情况下，我们无法运行VUzzer，因为它在第一轮输入生成时崩溃，而不允许程序解析更多任何输入。 LAVA二进制文件中的每个注入故障都有一个ID，并且在每个二进制文件由于该故障而崩溃之前，ID将打印在标准输出上。这使我们能够精确识别VUzzer触发的故障。表III报告了VUzzer为每个LAVA二进制文件触发的故障的ID。</p>\n<p><img src=\"/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/4.png\" alt=\"\"></p>\n<p>我们的LAVA数据集结果中出现了一些有趣的点。大多数LAVA注入的断层都是基于人工注入的路径条件，如lava到达特定路径并触发bug。由于其数据流功能，VUzzer非常好地捕获了这一点。例如，在base64模糊测试期间，我们了解到前四个字节应该是’val或lav’以跟随特定路径。类似地，我们发现最后几个字节应包含以下任何值以采用不同的路径：las [，lat\\x1b，Wsal等。应该注意，LAVA注入的大多数路径约束都是多字节约束。这种约束对于AFL在执行中更深入地造成了严重的问题（如[16]中所述）。另一个有趣的观点是VUzzer对who的表现。 LAVA文件中使用的模糊器甚至找不到一个bug，而VUzzer发现了几个独特的崩溃。</p>\n<p><img src=\"/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/5.png\" alt=\"\"></p>\n<p>总体而言，在两个人工数据集中，VUzzer报告了令人鼓舞的结果，尽管正如预期的那样，它确实与DARPA CGC数据集中的交互式程序相悖。我们现在继续在实际程序中评估VUzzerz，这些程序也被其他模糊器考虑过。</p>\n<h2 id=\"C-各种应用程序（VA）数据集\"><a href=\"#C-各种应用程序（VA）数据集\" class=\"headerlink\" title=\"C.  各种应用程序（VA）数据集\"></a>C.  各种应用程序（VA）数据集</h2><p>我们使用真实世界程序的数据集（djpeg / eog，tcpdump，tcptrace，pdf2svg，mpg321，gif2png）来评估VUzzer的性能。Rebert等人还对这些程序进行了评估，以报告几个错误[43]，因此我们将这些程序纳入我们的评估中，用于比较目的。对于这些程序中的每一个，我们在Ubuntu 14.04中使用vanilla发行版。我们注意到，通过评估这些实用程序，我们还针对一些著名的库，如libpcap，libjpeg，libpoppler和libpng。每个程序最多24小时模糊。为了突出VUzzer的性能，我们还在这些应用程序上运行了AFL。表IV显示了在VA数据集上运行VUzzer和AFL的结果，VUzzer在发现的唯一崩溃次数和触发此类崩溃所需的输入数量方面明显优于AFL。</p>\n<p><img src=\"/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/6.png\" alt=\"\"></p>\n<p>图5详细描述了24小时内崩溃的分布情况。每个图的x轴显示每2小时采样的累计崩溃总和。如图所示，对于几乎所有应用程序，VUzzer在后续的模糊测试中不断发现崩溃，而AFL在几次初始迭代后很快就耗尽了精力。这是因为在后期阶段，AFL无法找到新的（更深的）路径，而VUzzer能够在探索新路径时学习分支约束，因此能够在模糊测试的后期阶段发现崩溃。图5中另一个有趣的注意事项是，与AFL相比，VUzzer不仅能够以更少的输入找到崩溃，而且还可以在更短的时间内完成（参见图5中垂直线的位置）。我们想再次说明我们还没有优化VUzzer来实现快速输入。我们认为存在多种提高VUzzer执行速度的技术，例如，在单个模糊迭代中使用类似AFL的fork服务器，或者在多个核心或机器上分配并发模糊工作者。</p>\n<p><img src=\"/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/7.png\" alt=\"\"></p>\n<h2 id=\"D-Crash-Triage分析\"><a href=\"#D-Crash-Triage分析\" class=\"headerlink\" title=\"D.  Crash - Triage分析\"></a>D.  Crash - Triage分析</h2><p>Fuzzers倾向于产生大量崩溃。修复与崩溃相关的每个错误都是一个耗时但有利可图的过程。提供给软件开发人员的唯一信息是应用程序的版本号和崩溃本身。当然，错误修补工作投入到更多（安全性）关键的错误中。</p>\n<p>！Exploitable [19]是CERT提出的一种工具，它建立在GDB之上，并使用启发式方法来评估由bug引起的崩溃的可利用性。启发式算法基于崩溃位置，内存操作（读取或写入）以及应用程序触发的信号。虽然这种分析不合理，但它简单，快速，并提供了崩溃严重程度的提示。我们使用！Exploitable工具对VUzzer在此数据集上发现的崩溃进行排名。表五列出了我们的结果。</p>\n<p>如表中所示，由于！Exploitable工具的简单性，大多数情况都被标记为未知。没有一个案例被标记为可能可利用。最后，VUzzer在tcptrace中发现的每次崩溃似乎都是可利用的。我们调查了tcptrace中的一个崩溃，并且有一种看似明显的方法来利用它：漏洞是对堆缓冲区的越界写入。写入的边界和数据受到污染（即，受攻击者控制）。</p>\n<p><img src=\"/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/8.png\" alt=\"\"></p>\n<p>了进一步分析VUzzer发现的错误的质量，我们测量了crash与所涉及的库之间的距离（如果有的话）。位于库中的错误可能会包含在使用该库的任何应用程序中，因此这些错误具有高优先级。我们还需要记住，这些是未知的错误，因此其中许多可能是0-day。当我们发现大量独特崩溃时，尽早报告最重要的崩溃是一个优先事项，因此我们依靠自动分析来估计错误的严重性。简而言之，如果库中发生崩溃，那么报告就是一个严重的错误。但是，有时在用户应用程序中会出现错误，但错误的真正原因在于应用程序使用的库。因此，当在应用程序代码中观察到崩溃时，我们还测量距上一次库调用的距离。</p>\n<p>崩溃与库之间的距离由两个指标衡量。首先，我们计算崩溃和最后一次库调用之间执行的指令数。直觉是最终导致崩溃的计算（及其副作用）可能源于库调用。其次，我们计算崩溃和最后一次库调用之间的堆栈帧数。作为一个例子，使用驻留在主应用程序中的输出函数钩子的库（例如 tcpdump，tcptrace，mpg321）被这种启发式方法所覆盖。表VI列出了我们的分析结果。</p>\n<p><img src=\"/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/9.png\" alt=\"\"></p>\n<p>mpg321中的所有崩溃都发生在（libid3tag）库中。发行版维护者对libid3tag库进行了大量修补（补丁级别为10）。这表明该库已知包含许多错误。 gif2png总是在应用程序内部崩溃。高数据的指标均证实了这一点。 pdf2svg大部分时间都在libpoppler中崩溃。堆栈帧距离为3，因为信号从Linux的vdso通过标准库路由。 tcpdump和tcptrace使用相同的（libpcap）库，但由于tcpdump显示网络流的内容，因此它与库的距离更远。</p>\n<p>基于上述分析，我们认为VUzzer报告的许多崩溃事件都发现了0-day漏洞，我们目前正在向开源社区进行负责任的披露。表七提供了迄今为止我们分析和报告的一些错误的信息。</p>\n<p><img src=\"/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/10.png\" alt=\"\"></p>\n<h1 id=\"相关工作\"><a href=\"#相关工作\" class=\"headerlink\" title=\"相关工作\"></a>相关工作</h1><p>在前面的部分中，我们已经强调了VUzzer和AFL之类的状态模糊器之间的一些主要区别。在本节中，我们调查了最近在模糊测试领域的其他研究工作。这使我们能够突出显示与现有工作相关的一些功能和差异。</p>\n<h2 id=\"A-基于搜索的进化输入生成\"><a href=\"#A-基于搜索的进化输入生成\" class=\"headerlink\" title=\"A.  基于搜索的进化输入生成\"></a>A.  基于搜索的进化输入生成</h2><p>使用进化算法进行输入生成是软件工程中一个经过深入探索的研究领域[7]，[34]。已经尝试使用进化算法进行输入生成以发现应用程序中的漏洞[25]，[42]，[45]。不同之处在于，这些方法假定应用程序的先验知识集中在导致程序易受攻击部分的路径上。这个属性使这些方法更接近定向模糊测试，因此，我们的模糊测试策略大大偏离它们。与VUzzer不同，与AFL类似，这些方法使用的反馈循环不会尝试将应用程序行为与输入结构相关联以增强输入生成。</p>\n<h2 id=\"B-Whitebox模糊测试方法\"><a href=\"#B-Whitebox模糊测试方法\" class=\"headerlink\" title=\"B.   Whitebox模糊测试方法\"></a>B.   Whitebox模糊测试方法</h2><p>Whitebox模糊测试是通过考虑应用程序的属性来提高传统随机模糊测试性能的最早尝试之一。有许多方法可以使模糊测试更有效，例如，通过应用符号执行和动态污点分析来解决分支约束[20] - [24]，[26]。虽然VUzzer在很多方面都与这些方法不同，但根本的区别仍然是符号执行的使用。与VUzzer类似，Ganesh等人提出的BuzzFuzz [20]利用动态污点分析，但用途完全不同。BuzzFuzz是一个定向模糊器，因此，它不会尝试学习每条路径的约束。它使用污点分析来检测影响代码中危险点的字节，如库调用参数，并在输入中改变这些字节以触发异常行为。大多数这些方法还需要源代码的可用性来执行分析。</p>\n<h2 id=\"C-Blackbox-Graybox模糊测试方法\"><a href=\"#C-Blackbox-Graybox模糊测试方法\" class=\"headerlink\" title=\"C.  Blackbox / Graybox模糊测试方法\"></a>C.  Blackbox / Graybox模糊测试方法</h2><p>尽管简单且完全与应用程序无关，但Blackbox模糊器，如Peach [1]，Sulley [39]和Radamsa [40]已经发现了实际应用程序中的错误。但是，在整篇论文中，我们已经讨论了这种模糊器的局限性。</p>\n<p>最近，基于符号和模仿执行的模糊测试方法在“智能”模糊测试领域占主导地位[12]，[38]，[47]，[51]。 Mayhem [12]是CMU的一个系统，用于自动查找二进制代码中可利用的错误，它使用多种程序分析技术（包括符号执行）来推理给定输入的应用程序行为。这与VUzzer的思想相似。但是，由于VUzzer的目标与Mayhem的目标不同，VUzzer不需要重量级的程序分析技术，而是通过应用基于轻量级程序分析的启发式方法来推断输入的重要属性。同样，Driller [47]使用混合的concolic执行技术[33]通过解决分支约束来进行更深入的路径探索来辅助模糊测试。在[28]中，Kargen’等提出一种不同的方法来生成模糊输入。对于正在测试的给定应用程序，他们的方法通过注入影响输出的故障来修改另一个输入生成器应用程序。使用此策略，错误程序生成变异输入。但是，目前尚不清楚这些突变输入是否确实会影响应用程序消耗这些输入的方式。 TaintScope [49] - 校验和感知模糊器 - 使用污点分析来推断校验和处理代码，这进一步有助于模糊旁路校验和检查。在模糊测试时，VUzzer也可以从这种（补充）技术中受益。在最近的一项工作[8]（与我们的工作同时进行）中，AFLFAST的作者提出了一种基于马尔可夫模型的技术来识别低频路径，以便将模糊测试的重点放在该方向上。部分由VUzzer使用的启发式算法是对由最大输入数量执行的路径进行优先级排序。 VUzzer的错误处理基本块检测技术与此类似，虽然权重很轻。 VUzzer应用其他数据和控制流功能来加速输入生成。</p>\n<p>还有其他一些技术来增强模糊测试[11]，[43]，[51]。 VUzzer还可以通过多种方式从这些方法中受益。例如，种子选择[43]可以帮助VUzzer从一组良好的种子输入开始。</p>\n<h1 id=\"结论\"><a href=\"#结论\" class=\"headerlink\" title=\"结论\"></a>结论</h1><p>本文认为，模糊测试的关键优势在于实现轻量级，可扩展的错误查找技术，并且应用重量级和不可扩展的技术（如基于符号执行的方法）不是提高基于覆盖fuzzing的性能的最终解决方案。在研究了几种现有的通用（黑/灰盒）模糊器（包括最先进的AFL模糊器）后，我们注意到它们往往与应用程序无关，这使得它们在发现根深蒂固的错误方面效率较低。应用程序不可知策略的关键限制是它们无法更快地生成有趣的输入。我们通过模糊化应用程序感知测试过程来解决这个问题。</p>\n<p>我们利用应用程序的控制和数据流特征来推断输入的几个有趣属性。控制流特征允许我们对某些路径进行优先级排序和优先级排序，从而使输入生成成为受控过程。我们通过为基本块分配权重并为输入实现权重感知适应性策略来实现这一点。</p>\n<p>通过使用动态污点分析，我们还监控应用程序的多个数据流特征，使我们能够推断输入的结构属性。例如，这为我们提供了有关输入中的哪些偏移在几个分支条件下使用，哪些值用作分支约束等的信息。我们在反馈循环中使用这些属性来生成新输入。</p>\n<p>我们在一个名为VUzzer的开源原型中实现了我们的模糊测试技术，并在几个应用程序上对其进行了评估。我们还将其性能与AFL的性能进行了比较，结果表明，在几乎所有测试案例中，与AFL相比，VUzzer能够在少于一个数量级的输入下发现错误。这具体表明，通过分析应用行为来推断输入属性是一种可行且可扩展的策略，可以提高模糊性能，并为该领域的未来研究提供有希望的方向。</p>\n","categories":[{"name":"论文","slug":"论文","permalink":"http://yama0xff.com/categories/论文/"},{"name":"fuzzing","slug":"论文/fuzzing","permalink":"http://yama0xff.com/categories/论文/fuzzing/"}],"tags":[{"name":"fuzzing","slug":"fuzzing","permalink":"http://yama0xff.com/tags/fuzzing/"},{"name":"2017年","slug":"2017年","permalink":"http://yama0xff.com/tags/2017年/"},{"name":"污点分析","slug":"污点分析","permalink":"http://yama0xff.com/tags/污点分析/"},{"name":"LAVA","slug":"LAVA","permalink":"http://yama0xff.com/tags/LAVA/"},{"name":"pin","slug":"pin","permalink":"http://yama0xff.com/tags/pin/"},{"name":"静态分析","slug":"静态分析","permalink":"http://yama0xff.com/tags/静态分析/"},{"name":"动态分析","slug":"动态分析","permalink":"http://yama0xff.com/tags/动态分析/"},{"name":"CFG","slug":"CFG","permalink":"http://yama0xff.com/tags/CFG/"},{"name":"NDSS'17","slug":"NDSS-17","permalink":"http://yama0xff.com/tags/NDSS-17/"}]},{"title":"NAR-Miner Discovering Negative Association Rules from Code","date":"2019-01-28T09:18:28.000Z","path":"2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/","text":"Abstract从基于数据挖掘技术的源代码推断编程规则已被证明对检测软件错误是有效的。现有研究侧重于以A⇒B的形式发现积极规则，表明当操作A出现时，操作B也应该在这里。不幸的是，负面规则（A⇒¬B），表明程序元素之间的相互抑制或冲突关系，没有得到应有的重视。事实上，违反这些负面规则也会导致严重的错误。在本文中，我们提出了一种名为NAR-Miner的新方法，可以从大规模系统中自动提取负关联编程规则，并检测它们的违规行为来发现bug。然而，挖掘负面规则面临着比挖掘正面规则更严重的规则爆炸问题。大多数获得的负面规则都是无趣的，并且可能导致不可接受的错误警报。为了解决这个问题，我们设计了一个语义约束的挖掘算法，将规则挖掘集中在具有强语义关系的元素上。此外，我们引入信息熵来排列候选负面规则并突出有趣的规则。因此，我们有效地缓解了规则爆炸问题。我们实现NAR-Miner并将其应用于Linux内核（v4.12-rc6）。实验表明，不感兴趣的规则大大减少，检测到的17个违规行为已被确认为真正的错误并被内核社区修补。我们还将NAR-Miner应用于PostgreSQL，OpenSSL和FFmpeg，并发现了六个真正的错误。 relevant information 作者 Pan Bian, Bin Liang,/Wenchang Shi,Jianjun Huang,Yan Cai 单位 School of Information, Renmin University of China; Key Laboratory of DEKE, Renmin University of China Beijing, China; State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences Beijing, China 出处 原文地址 https://github.com/wtwofire/database/blob/master/papers/mine/2018-NAR-Miner%20Discovering%20Negative%20Association%20Rules%20from%20Code.pdf 源码地址 发表时间 2018年 1. 引言静态错误/漏洞检测技术通常需要一些先验知识（即检测规则或漏洞签名）[9,13,17,19]。近年来，已经广泛证明了关于bug /漏洞检测的代码挖掘方法是非常有效的[1,4,6,7,14,20,25-27,29,30,36,38,44,47， 49,51-53,57,60]。这些方法自动从程序源代码中提取隐式编程规则，并进一步检测违反这些规则的错误或漏洞。通常，在代码挖掘期间，程序源代码首先被转换为项集[6,25,26,49]，图[7,34,57]或其他形式。接下来，将数据挖掘算法应用于变换后的格式以提取模式（例如，频繁项目集或子图）并推断编程规则。最后一步是检测违反推断规则的行为。例如，PR-Miner [25]和AntMiner [26]从Linux内核挖掘频繁项目集以提取关联规则（作为检测规则）并检测到许多未知错误。 这些现有研究的基本思想是利用统计数据来编制程序元素，并附带源代码的关系。这种关系表现为积极的编程模式。也就是说，在目标项目中，一些程序元素经常一起出现（达到给定的阈值）或者它们之间存在某种联系。例如，PR-Miner [25]和AntMiner [26]都以A⇒B的形式提取正关联规则，表明在函数内，当程序元素A出现时，元素B也应该出现。因此，如果函数实现违反规则（即，包含A而不包括B），则预期潜在的错误。已经提出了类似的技术来检测潜在的对象滥用错误[53]和控制结构之后缺少的程序元素[7]，已经推断出API的正确使用[60]。所有这些方法都针对一组具有相互支持关系的邻接程序元素，即积极关联。 然而，在实践中我们观察到一些隐式编程模式以A⇒¬B的形式表现为负关联。也就是说，当A出现时，B不应出现，反之亦然。从这个意义上说，否定规则反映了A和B之间的相互抑制或冲突关系。违反负面规则也可能导致严重的错误。通常不可能手动识别项目中的所有否定规则，尤其是像Linux内核这样的大规模规则。但据我们所知，现有方法没有可以自动从源代码中提取负面规则以进行错误检测。最先进的基于挖掘的解决方案只能提取积极的编程规则。与指示频繁模式的积极规则相比，否定规则通常更隐含，相应的错误更隐蔽。例如，图1中的错误已存在于Linux内核中超过10年（即，在Linux-2.6.4或更早版本中提供）。因此，开发一种自动提取隐式否定编程规则以检测相关错误和漏洞的有效方法既具有挑战性又迫切。 在本文中，我们提出NAR-Miner解决上述问题。最重要的想法是通过不频繁的模式挖掘来推断有趣的负关联规则，并进一步将相应的违规行为检测为潜在的程序错误。基本上，由于负面规则的性质[56]，直接挖掘不常见的模式以提取负面规则将产生大量规则。我们称之为规则爆炸问题。这些规则中的大多数对于错误检测都是无趣的，即它们不包含任何真实的应用程序逻辑，并且违反它们不会导致错误或程序质量问题。因此，基于这些不感兴趣的规则的检测结果将产生不可接受的误报。例如，直接将现有的负规则挖掘算法[43,46,61]应用于Linux内核将提取多达数十万条规则和数百万条违规行为。在有限的人力资源下进行人工审计变得不可能。为了解决规则爆炸问题，我们提出了一种语义约束的负关联编程规则挖掘算法，以避免尽可能地产生过多的不感兴趣的规则。此外，我们利用信息熵来识别易于导致不感兴趣的规则的一般函数。这一步有助于进一步遏制可能不感兴趣的规则。因此，NAR-Miner可以有效地缓解规则爆炸问题并获得理想的有趣规则来检测潜在的错误。 我们实现了NAR-Miner的原型，并首先在Linux内核（v4.12-rc6）上进行评估。实验表明，基于语义约束的负规则挖掘和基于信息熵的规则过滤在减少不感兴趣的规则数量方面表现良好。也就是说，它减少了46％的无趣规则（即，在200个排名靠前的负面规则中从198到107）。特别是，它在排名前50位的负面规则中实现了62％的真正正面率。NAR-Miner报告了违反排名最高的200条规则的356条违规行为。我们手动检查结果并发现23个可疑错误和数十个质量问题。我们向Linux内核维护者报告可疑错误。其中17个已被确认为真正的错误，相应的补丁已合并到最新版本（例如，v4.16）。我们进一步将NAR-Miner应用于PostgreSQL v10.3，OpenSSL v1.1.1和FFmpeg v3.4.2。从排名靠前的规则和违规行为中，我们手动识别出六个可疑错误，所有这些错误都由相应的维护人员进行了确认和修复 本文的主要贡献如下： 据我们所知，我们的工作是第一个专注于从源代码中提取负面编程规则以检测错误的工作。它扩展了基于挖掘的错误检测技术的能力。 我们提出了一种通过在规则挖掘中引入程序语义并使用信息熵来识别一般函数来缓解规则爆炸问题的方法，该方法可以有效地提取用于错误检测的理想的有趣负编程规则。 我们针对真实世界的大型软件项目实现了NAR-Miner原型。我们将该工具应用于四个大型系统（即Linux内核，PostgreSQL，OpenSSL和FFmpeg）并引发相当多的错误，其中23个已被确认。 2.动机示例我们使用来自Linux内核（v4.12-rc6）的简化代码片段来激励我们的方法。在图1中，函数lapbeth_new_device在第5行调用alloc_netdev为网络设备分配一块内存。然后在第8行，在内联函数中调用netdev_priv以获取私有数据的起始地址并将其存储到变量lapbeth。如图1所示，lapbeth指向先前分配的内存中的位置。如果设备注册在第11行失败，则将释放设备的内存块。由变量ndev指向的已分配内存在第21行首先释放，然后在第23行释放私有数据。从代码片段突出显示从内存分配到空闲的执行序列中的关键操作，并相应地描述相应的内存状态。我们使用红色水平线来描述通过free_netdev和kfree的蓝色垂直线释放内存。通过图示，可以很容易地看出代码中存在双重错误。 传统的静态检测方法难以在大规模系统（例如Linux内核）中发现此错误和其他类似错误，因为所需的错误模式或规则是特定于应用程序并且难以收集。现有的基于挖掘的方法也无法报告错误。例如，最先进的方法AntMiner [26]提取正关联规则并检查违规。在Linux内核中，我们发现在对alloc_netdev的90次调用中，共有77次出现{alloc_netdev，free_netdev}（85.6％）。并且在533个调用实例中只有一次调用free_netdev后跟kfree（0.2％）。 AntMiner将{alloc_netdev}⇒{free_netdev}视为一个正规则，最小置信度阈值为85％[26]。但是，图1中的代码同时调用alloc_netdev和free_netdev，因此是对规则的支持，而不是违反。因此，上述错误未被发现。此外，由于低信任度（0.2％«85％），AntMiner不会将{free_netdev}⇒{kfree}视为有效规则（即，以最小置信度阈值来消除）。因此，AntMiner无法将“kfree跟随free_netdev”报告为错误。 从上面的分析中，通过分析元素之间的伴随关系来检测图1中的错误是非常困难甚至是不可能的。实质上，与bug密切相关的两个程序元素（即free_netdev和kfree）是负相关的。通过统计分析可以发现这种知识。具体来说，我们发现在大多数情况下（大约99.8％）在Linux内核中，free_netdev后面没有kfree，我们了解到开发人员大多都知道在free_netdev之后调用kfree可能是不必要的或导致严重问题的情况。受此启发，相对少量的配对事件可被视为异常。 我们利用不频繁的项集挖掘算法来推断负关联规则并应用规则来检测它们的违规（例如，图1中的那个）。在挖掘和检测期间，我们还考虑了程序语义（例如，数据流信息）。在我们的示例中，kfree与free_netdev共享数据，并且它们的外观一起被视为不常见的模式。因此，我们推断出一个负面规则{free_netdev}⇒¬{kfree}。将规则应用于我们的示例可发现相应的错误（表2中的错误12＃） 3.我们的方法3.1概述我们提出了NAR-Miner，目标是检测程序包含一些操作（例如两个函数调用）的错误，这些操作被认为不会出现在一起，该方法不需要任何先验知识。NAR-Miner的高层理念是采用数据挖掘技术从源代码中推断出负关联规则并检测其违规行为。 图2显示了NAR-Miner的概述。它首先为挖掘阶段准备数据。与大多数基于挖掘的方法类似[6,25,26,49,60]，我们仅从每个单独的函数中提取编程规则，即在程序内，以避免过于复杂的分析。识别每个函数内的程序元素及其语义关系并将其转换为事务，然后将其存储在数据库（称为事务数据库）中。接下来，它从数据库中挖掘频繁且不频繁的项集，它们表示程序元素集。然后，它从挖掘的项集中推断出负关联规则，并利用函数的置信度和熵自动对规则进行排序。最后，它检测违反推断规则的情况，并将排名最高的规则报告为审计的潜在错误。 3.2挑战以前的研究[43,46,61]表明只有少数表现出负相关关系很有意思的模式。他们通过计算支持和信任来识别有趣规则的技术不能直接用于代码挖掘。构造有趣的负关联规则的程序元素应该在它们的语义中相互压制，而不是偶尔出现在一起。我们的实证研究表明，直接应用Wu等人提出的算法。 [56]从Linux内核中提取的事务数据库生成183,712个负关联规则（参见§4.2.2），而其中99％在采样分析中不感兴趣。报告的违规行为多达309,689起，这使得人工审核变得不可能。我们称之为规则爆炸问题，并将其视为提取负关联规则的主要挑战。我们将以下两个方面归结为规则爆炸的根本原因。 现有的负关联规则挖掘方法[43,45,56,61]主要针对购物篮，医学诊断，蛋白质序列等。对于这类数据，来自挖掘单位的任何两个元素（例如，购物收据）除属于同一单位外，没有任何特定关系。换句话说，挖掘单元的元素是同类的。然而，在程序元素之间，通常存在各种语义关系，例如数据依赖性。忽略这样的关系可能会导致许多不感兴趣的规则由语义上独立的元素组成，这些元素实际上并没有相互抑制，而是偶尔出现在一起。 大型项目通常包含一定数量的通用API，几乎可用于所有编程环境，例如Linux中的printk和isalpha。它们可能巧合地与其他操作配对以形成关联规则。即使考虑到挖掘期间的强语义关系（例如，数据依赖性），这些API仍然可能导致许多负面无趣的规则。实际上，API越普遍，它与其他操作的相互抑制就越少。 基于以上见解，我们如下缓解规则爆炸问题。 （1）考虑到如上所述的程序元素的本质，我们将规则挖掘集中在具有强语义关系（例如，数据依赖性）的程序元素上，以尽可能地减少不感兴趣的规则。 （2）我们使用信息熵来衡量API的普遍性，并用它来排列挖掘的候选负面规则。涉及高普遍性API的不感兴趣规则将被排除在最终审计之外。 3.3数据准备NAR-Miner将程序元素转换为事务并将它们存储到数据库中。在本文中，我们关注两种程序元素：函数调用和条件检查，因为许多错误是由函数或条件错误引起的[1,6,21,26,33,38,47,57]。如前所述，我们的目标是从事务中提取负关联规则，其元素具有强大的语义关系。如果它们之间存在数据关联，我们定义两个元素以具有强大的语义关系，包括数据依赖性和数据共享[7]。详细地说，给定两个语句s1和s2，如果s2使用s1中定义的值（即数据依赖），或者它们都出现在同一个执行路径上并使用相同的非常量值（即数据共享），我们说他们在语义上有很强的相关性。程序元素的语义关系通过数据流分析[3,15]来识别。 NAR-Miner的预处理器建立在GCC（v4.8.2）前端之上，该前端以SSA形式[12]提供控制流图和中间表示，用于数据流分析。图3（a）显示了一段代码，图3（b）显示了相应SSA形式的中间表示。 NAR-Miner可以判断is_valid，foo和bar是依赖于第2行的read2的数据。由于is_valid和foo在同一个执行路径中，因此它们具有数据共享关系。因为foo和bar之间没有路径，所以它们不被认为是语义相关的。 为了简化挖掘阶段，然后将中间表示转换为事务数据库。每个函数定义都映射到一个事务。事务由两部分组成：程序元素和这些元素之间的一组语义关系。在转储到数据库之前，每个程序元素都被规范化。函数调用用不带参数的函数名表示;如果条件语句中的变量保留某些函数的返回值，或者在其他情况下保留其数据类型，则使用“RET”重命名，如许多挖掘方法[6,7,25,26,57,58]中所做的那样。例如，图3中的条件表达式归一化为“RET == 0”。两个程序元素之间的语义关系表示为事务中的元组。例如，元组（foo，is_valid）表示函数foo和is_valid具有一些语义关系。图3（c）显示了代码片段的语义关系，其中节点表示程序元素，边缘表示关系（黑线表示数据依赖性、红线表示数据共享）。 我们将每个程序元素映射到一个唯一的整数，因此挖掘被应用于整数集以提高性能，因为大量的字符串等价比较是耗时的。 3.4提取频繁和不频繁的项集很少调用的程序元素总是很少与其他程序元素一起出现，并且会导致大量的负面模式。然而，这些模式在统计学中毫无意义[56]。因此，我们专注于挖掘负面模式，这些模式的元素经常单独出现但很少发生在一起。对于负关联规则A⇒¬B，其前因（即A）和后续（即B）是频繁的，但它们的组合（即（A∪B））是不频繁的。在本节中，我们将提出我们的算法来提取有趣的频繁和不频繁的项集，并将在下一节中解释如何生成否定规则。 提取频繁和不频繁项集的现有算法仅依赖于事务数据库中项集的出现[43,46,61]。他们都没有考虑元素之间的语义关系。直接将它们应用于§3.3中生成的数据库将导致大量无趣的规则。据我们所知，没有不常见的项集挖掘算法可以直接应用于我们的工作中。为了解决这个问题，我们设计了一个语义约束的挖掘算法，该算法侧重于提取与语义相关的强项集。强语义相关项集中的元素在语义上都彼此相关，例如，具有数据依赖性或数据共享关系。 我们基于众所周知的Apriori算法[2]设计我们的算法，该算法应用自下而上的方法通过将较小的频繁项目集合在一起来生成相对较大的候选项集。自下而上方法背后的原则是Apriori属性：频繁项集的任何子集也是频繁的。在我们的例子中，强语义相关项集的任何子集也与强语义相关，因为子集中的任何两个元素必须在语义上相关。因此，强大的语义相关项集也符合Apriori属性，可以自下而上的方式挖掘。 算法1中显示了我们挖掘频繁和不频繁的强语义相关项集的算法。除了事务数据库，它还要求用户指定两个参数：最小频率支持mfs和最大频率支持mis。如果项集的支持大于或等于mf s，则认为项集是频繁的，如果项集的支持小于或等于mis，则项集是不频繁的。算法的输出是所有频繁项目集（FI）和感兴趣的不频繁项目集（IIs）。 在开始时，算法扫描事务数据库以找出所有频繁的1项集（第3行）。然后它试图从频繁的（k-1）-itemsets（第4~14行）中发现频繁且不频繁的k-项集。 k项目集包含k个项目。首先，它通过连接频繁（k-1）-项来生成感兴趣的候选k项集（参见第5行）。如果它们具有k-2个共同项，则可以连接两个（k-1）-itemsets。假设两个可连接（k-1）-itemsets是{i1，…，ik-2，ik-1}和{i1，…，ik-2，ik}，则连接结果是k-itemset {i1，…，ik-2，ik-1，ik}。其次，该算法利用Apriori属性来修剪具有不频繁子项集的k项集（第6行）。之后，调用函数count_support来计算每个k-itemset的支持（第8行）。如果项目集的支持不小于mfs，则将项目集插入Lk（第10行），即一组频繁的k项目集;否则，如果它的支持不大于mis，则将其插入不频繁的k项集Nk集（第12行）。应该注意，支持为0的项集自然会被忽略。 Lk和Nk分别与FI和IIs（第15行）合并。然后，频繁项目集Lk用于生成更大的项集Lk + 1和Nk + 1。当Lk对于某个k为空时，算法终止，并输出收集的频繁/不频繁项集（第17行）。 函数count_support扫描数据库以计算项集I的支持（第19~27行）。如果事务支持I（第23行），计数器将增加1。当且仅当它包含I中的所有项目以及所包含项目之间的所有可能关系时（表示为关系（I）），事务支持I。例如，图3中的事务支持itemset {foo，is_valid}，因为它不仅包括两个项foo和is_valid，还包括它们之间的语义关系，即元组（foo，is_valid）。但是，事务不支持itemset {foo，bar}，因为它不包含元组（foo，bar）。 为了挖掘像{kfree}⇒¬{kfree}这样的规则，我们还提取了像{g，g}这样的2项集，其中g经常被调用，但是在同一函数中它的两个调用实例在语义上很少相关。这有助于NAR-Miner找到表2中的错误14＃（参见§4.2.3）。 3.5生成负关联规则负关联规则A⇒¬B意味着两个频繁项集A和B很少出现在同一事务中。也就是说，（A∪B）很少见。事实上，规则的前因和后果实际上是不常见的项目集的不相交分区。一种直接的负关联规则生成方法是从不频繁的项集I中找出所有对，如&lt;A，B&gt;，其中A∪B= I且A∩B=∅。它使用规则A⇒¬B的统一来确定其不频繁。这种说法的定义如下： 其中，支持（A∪¬B）是支持A∪¬B，支持A但不支持A∪B的事务数量。因此，我们有支持（A∪¬B）=支持（A）-支持（A∪B）=支持（A）-支持（I），其中I =A∪B。因此，等式1可以改写为： 从具有n个元素（n≥2）的不频繁项集I中，通过直接应用上述方法可以生成最多2个（n-1）个负关联规则。但是，对它们的违反是完全相同的，即支持项目集I的事务。因此，在面向错误检测的应用程序中仅跟踪它们中的一个就足够了。注意，从编程的角度来看，规则A⇒¬B意味着B中的元素不应出现在包含A的上下文中。如果反转规则B⇒¬A不感兴趣，则其违规总是误报，因为存在B并不意味着拒绝A.受此启发，在几乎所有情况下，如果我们期望支持不频繁项集I的事务成为真正的错误，那么从I派生的所有负关联规则应该是有趣的。因此，我们可以选择具有最低置信度的规则来表示这些规则。将置信度作为衡量标准，其他规则如果有趣则会很有趣。 实际编程中的逻辑通常非常复杂。一些挖掘的规则可能不适用于编程实践。根据它们检测到的违规通常是误报。一般方法是对挖掘的规则进行排名，使得有趣的规则排名最高，而无趣的规则排在最低位。现有工作主要根据他们的置信度对规则进行排名（高信任规则排名最高）。然而，这种信任仅反映了几个有限元素之间的（负/正）相关性。实际上，编程规则的有趣性也与其元素是否集中在某些上下文有关。也就是说，如果元素的调用上下文趋向于更加同类，则由它组成的规则更可能是有趣的。否则，如果元素在非常不同的上下文中使用，则它更通用，并且更可能与各种元素一起出现。在本文中，我们使用一般性来表明元素的上下文有多不同。一般而言，规则由具有高一般性的元素组成，更可能是无趣的元素。 我们引入信息熵来定量测量元素的一般性。对于程序元素g的调用实例，我们通过g依赖的元素和依赖于g的元素两个来描述它的上下文。我们在g的所有调用实例中提取这些元素并将它们放入包中。包的信息熵反映了调用实例的不同，可以用来衡量g的一般性。包的信息熵（表示为H（g））可以通过等式3计算: 其中pi是包中第i个元素的频率; N是g的调用实例数。项集的熵是每个元素的熵的总和。 根据每个程序元素的一般性，负关联规则R的兴趣度可以测量为： 其中H（gi）是元素gi的信息熵。 我们在算法2中形成了生成负关联规则的方法。该算法将§3.4中提取的频繁项集FI和不频繁项集II以及用户指定的阈值min_conf作为输入。它返回负关联规则NARs的集合。它首先为具有最低置信度的每个不频繁项集I生成代表性规则（第3~5行）。从等式2可以看出，A的支持越小，A⇒¬B的置信度就越低。因此，我们选择支持最小的I子集来生成代表性规则。然后，计算规则的置信度（第6行）并根据阈值min_conf（第7行）进行检查。信息熵用于衡量潜在有趣规则的兴趣（第10行）。最后，负关联规则按其兴趣的降序排序。 3.6检测违规行为违反负关联规则R：A⇒¬B的是那些支持项集A∪B的事务。直接的方法是直接扫描数据库以找出包含项集A和B的所有事务。但是，这样的枚举方法这非常耗时，特别是对于拥有数十万事务的数据库而言。为了加快检测过程，我们采用了PR-Miner [25]中使用的技巧。在生成频繁且不频繁的项目集时，NAR-Miner还会收集支持它们的事务。我们使用支持者（I）来指示支持项集I的所有事务。然后，违反负关联规则R的集合恰好是支持者（A∪B）。 4.评估4.1实验设置我们将NAR-Miner实现为原型系统，以检测大规模C程序中的错误。我们在众所周知的Linux内核（v4.12-rc6）上评估NAR-Miner。 Linux内核已被广泛用作基于挖掘的错误检测方法的评估目标（TOE）[6,14,20,20,22,24-26,30,42,46-48,57,60]。选择Linux内核作为我们的目标的主要原因是我们想要通过检测以前工作中找不到的一些真正的错误来检查我们方法的有效性。 Linux-v4.12-rc6是实验时的最新版本。它包含24,919个C和19,295个标题文件，包括376,680个函数和15,501,651行代码（LoC）。 为了验证NAR-Miner是否可以应用于其他系统中的错误检测，我们还从不同的域中选择了三种流行的大型C系统：PostgreSQL v10.3，OpenSSL v1.1.1和FFmpeg v3.4.2。 PostgreSQL是一个开源数据库，OpenSSL是一个用于安全通信的库，FFmpeg是一个用于编码/解码多媒体文件的框架。许多错误检测方法选择它们作为评估的目标[19,20,25,35,57]。 NAR-Miner需要指定三个参数：（1）频繁项集的最小支持阈值（即mfs），（2）不频繁项集的最大支持阈值（即mis），以及（3）有趣的负面规则最小置信度阈值（即min_conf）。通常，如果项目集是具有较高支持的频繁项目集或具有较低支持的不频繁项目集，则项目集将更有趣。此外，较高的最低限度可以进一步消除无趣的负面规则。实际上，不同的参数设置可能导致无法报告某些实际错误或产生过多的错误警报。用户可以保守地或积极地根据检测策略调整这些参数。为了确定合理的参数，我们进行了[6,25,26,49,60]中的实证研究。具体而言，通过抽样分析，当排名前10位的负面规则中有一半以上是有趣的规则时，参数设置被认为是可接受的。在这项研究中，我们将mf设置为15，将mis设置为5，将min_conf设置为85％。在我们的实验中，默认参数设置适用于四种不同的TOE（参见§4.2和§4.3）。 4.2检测Linux内核中的错误4.2.1预处理源代码NAR-Miner花了大约77分钟来解析内核源代码并将其转换为事务数据库。在所有函数定义中，有333,248个函数包含一些程序元素（即函数调用或条件检查）。转换后，每个函数定义都映射到数据库中的事务。该数据库包括227,246个不同的元素，其中每个元素对应于函数调用或条件检查。其中，6,203个频繁出现在多个事务中。 4.2.2挖掘负面规则的有效性为了评估包含语义约束规则挖掘和基于信息熵的规则排序的方法的有效性，我们进行了三个实验：NAR-Miner–，NARMiner-，NAR-Miner。每个实验中采用的方法解释如下： NAR-Miner–：挖掘算法不考虑项目之间的语义关系，挖掘的规则根据其对应性进行排序; NAR-Miner-：基于NAR-Miner–，项目之间的语义关系被用作约束来消除弱语义相关项集; NAR-Miner：基于NAR-Miner-，我们引入信息熵来衡量负关联编程规则的趣味性。该实验评估了NAR-Miner的全部功能。 我们在表1中显示了实验结果，包括频繁项目集（#FI），不频繁项目集（#IIs）的数量，推断的负关联规则的数量，检测到的违规数量以及挖掘，排名和检测的时间成本（时间）很快。 比较NAR-Miner–和NAR-Miner-或NAR-Miner的结果，我们观察到采用语义约束的挖掘减少了一个数量级的规则和违规总数（＃All列减少约88％） ）。规则爆炸问题在很大程度上得到了缓解。 由于时间有限，我们在每个实验中手动检查200个排名靠前的负关联规则。这些规则按照他们在NAR-Miner–和NAR-Miner-中的可信度排名，而他们在NAR-Miner中的兴趣则排名靠前。负关联规则如果真的很有意义则标记为“True”，违反它会导致错误或质量问题。例如，{free_netdev}⇒¬{kfree}是一个有趣的（“True”）规则，因为违反它将导致潜在的双重释放错误，例如§2中讨论的错误。在NAR-Miner中，前200条规则中只有2条被认为是有趣的规则。换句话说，其中99％导致违规检测的错误警报。这种有趣规则率低的主要原因是由这些规则组成的程序元素通常在语义上彼此独立。对于下面的例子，虽然在NAR-Miner中排名第一，并且具有99.96％的置信度，但规则{static_key_false}⇒¬{atomic_read}是无趣的，因为这两个函数将完全独立的变量作为包含他们的程序中的实际参数，他们并没有真正压制对方。 引入语义约束的挖掘将NAR-Miner-中的误报率降低到90.5％，然而，这仍然太高而不能在实践中被接受。虽然推断规则具有语义相关的所有程序元素，但是一些元素非常通用，并且可以在违规不会导致错误的各种上下文中使用。例如，函数iowrite32是在它们一起出现时依赖于readl的数据，在Linux内核中只出现一次，并且推断出规则{iowrite32}⇒¬{readl}。该规则在NAR-Miner-中排名第8位，并且在99.64％的情况下排名第一，但仍然无趣，因为这两种功能都以各种方式使用，并且它们的组合不会导致任何错误。 NAR-Miner使用信息熵来测量函数的一般性。 iowrite32和readl分别为5.9和4.6。规则{iowrite32}⇒¬{readl}的有趣性是9.5％，小到足以排名低。以这种方式，大多数不感兴趣的规则被分配低兴趣度值并因此被排在底部，同时潜在有趣的规则被分配具有相对高的兴趣度值并且在顶部排名。在NAR-Miner中，前200个负面规则中有93个标记为“真”，几乎是NAR-Miner-中数字的5倍。特别是，在前50个中有31个“真正的”负规则。真阳性率为62％。也就是说，我们可以在不到两次手动审计中找到一个有趣的规则，这在实际的错误检测中是可以接受的，而不是针对Linux内核等真实的大型系统。 我们还检查了违反前200条推断规则的情况。从表1中的Violations和#Bugs列中，我们观察到更多报告的违规和由于应用基于语义约束的挖掘和基于信息熵的排序而导致的错误，这最终增强了NAR-Miner的能力，使其能够推断出更多有趣的规则（列#True和TP Rate） 4.2.3检测违规行为 针对NAR-Miner提取的21,166个负关联规则，检测到37,453个违规。我们根据规则的排名手动检查报告的负关联规则及其违规。为了从检测中获得最大的收益，我们选择排名靠前的规则进行审核，因为违反这些规则更可能是真正的错误。我们在一个人一天内检查了200个排名靠前的负面关联规则和相应的356个违规行为（参见表1中的最后一行）。 我们发现了23个可疑错误和数十个程序质量问题，例如冗余条件检查和计算。由于Linux内核维护者经常忽略质量问题，我们只向Linux内核维护者提交23个可疑错误的补丁。到目前为止，这些补丁中有17个已经被内核维护者所认可和接受。 表2中列出了确认的bugs，其中包含错误（函数），违反的规则（违规规则）以及三个实验中的规则排名。最后一列显示了这些bug的补丁ID和我们在PatchWork站点上的补丁。在这些发现的bug中，六个（2＃，3＃，8＃，12＃，13＃和14＃）在内核2.6中出现，两个（3＃和12＃）甚至潜伏了10年以上。 这些bug总共违反了12个负关联规则。如果按照排名进行排名，则只有其中一个在前200条规则范围内（NAR-Miner-列中为12＃）。但是使用信息熵对规则进行排名会使所有这些规则都进入前200名（NAR-Miner）。这一观察结果表明，将信息熵引入排名对于突出有趣的规则非常有用。我们还观察到这些规则中只有2个是在NAR-Miner–中提取的（“NA”表示没有命中），其他规则都缺失。例如，缺少规则{free_netdev}⇒¬{kfree}（12＃），因为有106个函数同时调用free_netdev和kfree。在不考虑语义关系的情况下，项集{free_netdev，kfree}的支持是106，这远远高于预定阈值mis = 5。 因此，它不会被视为不常见的项目集，因此无法推断出负关联规则。然而，凭借语义约束的挖掘和信息熵，NAR-Miner成功地推断出规则并发现相应的错误（图1）。因此，我们声称语义约束的挖掘不仅可以帮助减少误报，还可以减少误报。 4.2.4与基于正规则挖掘的方法的比较在实践中，违反负规则的某些错误也可能违反相应的积极规则。因此，应该通过基于负面和正面规则挖掘的方法来检测这样的错误。我们调查是否会发生这种情况。我们选择表2中的17个错误作为基线，进行另一个实验，从§4.2.2中挖掘出的266,449个频繁项目集中使用与NAR-Miner相同的mfs和min_conf设置来推断出正关联规则，然后检测违规规则，如[25]和[26]中所做的那样。手动检查显示检测到17个错误中的3个（表2中的2＃，3＃和15＃），而其他14个错误（约82.4％）丢失。然后，我们使用语义约束的挖掘来增强基于正规则挖掘的方法，即考虑程序元素之间的数据关系。发现了另外两个错误（5＃和14＃），但仍有12个错误（约70.6％）未被发现。因此，我们声称虽然语义约束的挖掘能够帮助基于正规则挖掘的方法检测更多错误，但基于负规则挖掘的方法可以专门发现许多基于正规则挖掘的方法无法实现的错误。 4.3检测其他系统中的bugNAR-Miner进一步应用于PostgreSQL v10.3，OpenSSL v1.1.1和FFmpeg v3.4.2。 NAR-Miner分别从PostgreSQL，OpenSSL和FFmpeg中提取了690,382和335个负面规则。我们在§4.2中手动检查排名靠前的负面规则（不超过50个）及其在每个系统中的违规行为。因此，我们确定了六次违规（每个目标两次），并将其报告给相应的社区。到目前为止，所有六个可疑错误都被相应的系统维护人员修复了。有关详细信息，请参阅邮件列表[41]中PostgreSQL的错误报告，ID为＃15104和＃15105，OpenSSL来自问题列表[40]，ID为＃5567和＃5568，以及来自邮件列表的FFmpeg [39] ID为＃7074和＃7075。实验证明NAR-Miner不限于特定的目标系统（例如，Linux内核），而是可以用于在各种大规模C系统中发现真正的错误。 4.4案例研究在本节中，我们将说明NAR-Miner的能力与基于肯定关联规则（PAR）挖掘的方法在PostgreSQL中的＃15105问题上进行比较。 在PostgreSQL中，函数OpenTransientFile分配一个文件描述符并将其存储到全局维护的已分配文件列表中。返回描述符必须与CloseTransientFile一起释放，它会在关闭之前从列表中删除描述符。直接使用close会使列表保留已发布的描述符，并可能导致释放后使用的错误。从统计上来说，在PostgreSQL v10.3中，OpenTransientFile在28个函数中被调用。在27个函数中，其返回值传递给CloseTransientFile，但在1函数中，其返回值直接传递给close，从而产生负关联规则{OpenTransientFile}⇒¬{close}和正关联规则{OpenTransientFile}⇒{ CloseTransientFile}具有相同的96.4％的置信度。 图4显示了函数dsm_impl_mmap，该函数错误地将在第4行用OpenTransientFile分配的文件名描述符fd传递给沿路径的第12行关闭。它违反了上述负面规则，因此被NAR-Miner报告。但是，从伴随分析的角度来看，因为在某些路径上，fd在第8和第16行正确传递给CloseTransientFile，这符合上述正规则的要求。因此，有缺陷的代码确实是支持而不是违反规则。我们通过用CloseTransientFile（fd）替换第12行来解决这个问题，如图4所示。修补程序已经被维护者接受了 5.讨论和限制负面规则与正面规则。在本文中，我们主要基于负关联规则而不是正关联规则来检测错误。但是，这两种方法没有必要的矛盾。由于他们专注于不同类型的编程规则，因此它们可以相互补充。从错误检测的角度来看，我们的方法能够提取负面的编程规则并检测基于挖掘正关联规则的方法无法揭示的错误，反之亦然。理论上，两种方法的组合可以表现出更好的检测性能（更少的漏报率）。 此外，与挖掘积极规则相比，挖掘负面规则通常伴随着产生更多无趣的规则，导致大量的误报。在这种情况下，同一程序的积极规则可以帮助减少它们。例如，如果一段代码违反了否定规则但满足了正规则，则相应的负面规则的违反不太可能成为真正的错误。我们可以降低其排名以避免这种违规行为。类似地，基于正规则的错误检测也可能面临相同的挑战（即，报告误报）。因此，在这种情况下，一个直截了当的问题是，这两种方法是否有助于减少误报？我们将在未来进一步研究。 规则爆炸。实质上，负关联规则挖掘中的规则爆炸问题无法完全解决。在本文中，我们采用了一种相对直接的方法。具体来说，我们利用元素之间的语义关系来消除挖掘过程中绝大多数不感兴趣的规则，然后使用信息熵来衡量规则的有趣性，以便进一步突出显示潜在的有趣规则。但是，可能存在多种解决方案。例如，我们可以进一步量化程序元素之间的语义关系的强度，以重新改善挖掘结果。除了数据依赖和数据共享关系之外，还可以利用其他关系，例如控制流关系。这些潜在的改进可以进一步缓解规则爆炸问题，从而降低手动审计效率。这也是我们未来的工作之一。 挖掘算法。在本文中，我们采用项集挖掘算法来提取负编程规则。实际上，对于某些类型的编程规则，其他形式的表示和挖掘算法可能更合适。例如，使用序列来表示顺序敏感的编程逻辑[1,29,53,55]比使用项目集更合适。然而，基于序列的算法在发现对顺序不敏感的编程逻辑方面具有较差的鲁棒性。如果我们能够有效地确定编程模式是否对顺序敏感，则可以采用目标算法来挖掘相关规则。这将是我们未来的工作之一。 6.相关工作程序分析已被广泛而成功地用于错误发布。例如，模型检查可以使用目标系统的模型和规范自动验证有限状态系统的正确性属性[10]。由于为目标系统编写模型的成本很高，因此开发实验级模型检查器并在系统代码中发现实际错误[32,59]。研究人员还利用程序分析来检测违反特定规则的行为。通常，向工具提供一组编程规则，其静态地或动态地检查目标系统是否违反给定规则。 Pasareanu和Rungta开发了SPF，通过将符号执行引入到模型检查中来生成Java程序的测试用例[37]。恩格勒等人。提出了使用系统特定编译器扩展[13]静态检查系统规则的技术，而FindBugs作为独立工具运行，以检查Java字节码中错误模式的出现[11]。 Livshits和Lams [28]将用户提供的漏洞规范转换为静态分析器，并使用它们来检测用Java编写的Web应用程序中的漏洞，例如SQL注入和跨站点脚本。此外，Molnar等人。利用动态测试生成来检查二进制程序中的整数错误，检查特定断言的违规情况[31]。尽管它们在解决错误方面取得了成功，但这些方法在很大程度上取决于系统的模型或错误的模式，例如高级API语义[50]，我们称之为先验知识。没有这种知识，他们就无法发现错误。相反，我们的工作会自动发现知识，然后根据收集的知识检测错误。 还提供了可以从目标系统自动提取知识的技术。 Engler等人提出的先驱工作。采用统计分析来推断给定规则模板的时间规则，检测错误而不指定具体规则[14]。 Kremenek等人使用因子图通过结合不同的信息来源推断程序的规范[22]。这两种方法仅限于推断具有预定模板的规则和必须由用户提供的特定知识。一些方法依赖于挖掘规则中的某些领域知识，并且专门用于推断关键API [1,16,36,49,53,55]或安全敏感函数[47,58]的规则。它们还要求用户提供领域知识以促进挖掘过程。但是，NAR-Miner在根据程序中包含的关联规则（隐式）提取规则时不需要用户提供先验知识。 最近，研究人员利用数据挖掘算法从真实的大型系统中提取更多一般规则[4,7,8,21,23-25,27,29,30,33,34,44,54,58]。这些基于挖掘的技术背后的首要思想是：在大多数情况下，程序是正确的，因此任何异常都可能是错误。通常，这些方法首先推断出来自目标系统的频繁出现的模式，并将这些模式视为开发人员在编码时应遵循的（隐式）规则。然后，他们发现任何违反这些规则的行为都是潜在的错误。推断的模式可以是正面的也可以是负面的。例如，PR-Miner [25]和AntMiner [26]提取了强制关联规则，强制配对表面的程序行为。Chang等通过从程序控制流中挖掘频繁关联的子图并检查偶发违规来检测缺失的代码结构[7]。 Yun等。根据不同API之间挖掘的语义正关联规则推断出API的正确用法[60]。与这些方法不同，NAR-Miner专注于从源代码中挖掘负关联规则，并检测违反这些规则的错误。也可以从动态执行跟踪中提取类似的规则。Beschastnikh等开发了Synoptic，从系统执行日志中生成时间系统不变量[5]。 Wang等人开发了Bugram，它使用n-gram语言模型来测量令牌序列的概率，并将低概率序列视为异常，即潜在的错误[52]。Bugram还可以检测由相互抑制的程序元素共同引起的某些错误。但是，由于序列窗口的大小有限，Bugram很难捕获涉及长距离程序元素的错误。 挖掘负关联规则已应用于购物篮，蛋白质序列和金融数据等数据[18]。对于这样的数据，两个元素之间的关系比对关系贡献不同强度的程序元素的关系简单得多。Wu等人提出了算法，以有效和高效地挖掘大型数据库中的负关联规则[56]。Zhou和Yau提出了一种组合算法来挖掘有趣的关联规则，减少了大量的否定规则[61]。NAR-Miner也可以采用这些算法作为基本挖掘算法，但需要处理程序语义以减少不感兴趣的规则。 7.结论数据挖掘技术已广泛用于推断编程规则，然后根据规则检测软件错误。现有方法已经证明，正关联规则（表明相关的程序元素必须一起出现）对于通过检查违规来检测错误是有用的。然而，拒绝所涉及的程序元素的共同出现的负关联规则大多被忽略。我们提出NAR-Miner从源代码中挖掘负关联规则。我们引入程序语义来指导挖掘阶段。我们还利用函数熵对候选规则进行排名并突出显示有趣的规则。通过这种方式，NAR-Miner显着减少了不感兴趣的规则的数量，并在一定程度上缓解了规则爆炸问题。我们在四个流行的大型系统上评估原型，并发现了相当多的错误，其中一些已被维护者所困扰。","content":"<h1 id=\"Abstract\"><a href=\"#Abstract\" class=\"headerlink\" title=\"Abstract\"></a>Abstract</h1><p>从基于数据挖掘技术的源代码推断编程规则已被证明对检测软件错误是有效的。现有研究侧重于以A⇒B的形式发现积极规则，表明当操作A出现时，操作B也应该在这里。不幸的是，负面规则（A⇒¬B），表明程序元素之间的相互抑制或冲突关系，没有得到应有的重视。事实上，违反这些负面规则也会导致严重的错误。在本文中，我们提出了一种名为NAR-Miner的新方法，可以从大规模系统中自动提取负关联编程规则，并检测它们的违规行为来发现bug。然而，挖掘负面规则面临着比挖掘正面规则更严重的规则爆炸问题。大多数获得的负面规则都是无趣的，并且可能导致不可接受的错误警报。<strong>为了解决这个问题，我们设计了一个语义约束的挖掘算法，将规则挖掘集中在具有强语义关系的元素上。此外，我们引入信息熵来排列候选负面规则并突出有趣的规则</strong>。因此，我们有效地缓解了规则爆炸问题。我们实现NAR-Miner并将其应用于Linux内核（v4.12-rc6）。实验表明，不感兴趣的规则大大减少，检测到的17个违规行为已被确认为真正的错误并被内核社区修补。我们还将NAR-Miner应用于PostgreSQL，OpenSSL和FFmpeg，并发现了六个真正的错误。</p>\n<table>\n<thead>\n<tr>\n<th>relevant information</th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><em>作者</em></td>\n<td>Pan Bian, Bin Liang,/Wenchang Shi,Jianjun Huang,Yan Cai</td>\n</tr>\n<tr>\n<td><em>单位</em></td>\n<td>School of Information, Renmin University of China; Key Laboratory of DEKE, Renmin University of China Beijing, China; State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences Beijing, China</td>\n</tr>\n<tr>\n<td><em>出处</em></td>\n<td></td>\n</tr>\n<tr>\n<td><em>原文地址</em></td>\n<td><a href=\"https://github.com/wtwofire/database/blob/master/papers/mine/2018-NAR-Miner%20Discovering%20Negative%20Association%20Rules%20from%20Code.pdf\" target=\"_blank\" rel=\"noopener\">https://github.com/wtwofire/database/blob/master/papers/mine/2018-NAR-Miner%20Discovering%20Negative%20Association%20Rules%20from%20Code.pdf</a></td>\n</tr>\n<tr>\n<td><em>源码地址</em></td>\n<td></td>\n</tr>\n<tr>\n<td><em>发表时间</em></td>\n<td>2018年</td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"1-引言\"><a href=\"#1-引言\" class=\"headerlink\" title=\"1. 引言\"></a>1. 引言</h1><p>静态错误/漏洞检测技术通常需要一些先验知识（即检测规则或漏洞签名）[9,13,17,19]。近年来，已经广泛证明了关于bug /漏洞检测的代码挖掘方法是非常有效的[1,4,6,7,14,20,25-27,29,30,36,38,44,47， 49,51-53,57,60]。这些方法自动从程序源代码中提取隐式编程规则，并进一步检测违反这些规则的错误或漏洞。通常，在代码挖掘期间，程序源代码首先被转换为项集[6,25,26,49]，图[7,34,57]或其他形式。接下来，将数据挖掘算法应用于变换后的格式以提取模式（例如，频繁项目集或子图）并推断编程规则。最后一步是检测违反推断规则的行为。例如，PR-Miner [25]和AntMiner [26]从Linux内核挖掘频繁项目集以提取关联规则（作为检测规则）并检测到许多未知错误。</p>\n<p>这些现有研究的基本思想是利用统计数据来编制程序元素，并附带源代码的关系。这种关系表现为积极的编程模式。也就是说，在目标项目中，一些程序元素经常一起出现（达到给定的阈值）或者它们之间存在某种联系。例如，PR-Miner [25]和AntMiner [26]都以A⇒B的形式提取正关联规则，表明在函数内，当程序元素A出现时，元素B也应该出现。因此，如果函数实现违反规则（即，包含A而不包括B），则预期潜在的错误。已经提出了类似的技术来检测潜在的对象滥用错误[53]和控制结构之后缺少的程序元素[7]，已经推断出API的正确使用[60]。所有这些方法都针对一组具有相互支持关系的邻接程序元素，即积极关联。</p>\n<p>然而，在实践中我们观察到一些隐式编程模式以A⇒¬B的形式表现为负关联。也就是说，当A出现时，B不应出现，反之亦然。从这个意义上说，否定规则反映了A和B之间的相互抑制或冲突关系。违反负面规则也可能导致严重的错误。通常不可能手动识别项目中的所有否定规则，尤其是像Linux内核这样的大规模规则。但据我们所知，现有方法没有可以自动从源代码中提取负面规则以进行错误检测。最先进的基于挖掘的解决方案只能提取积极的编程规则。与指示频繁模式的积极规则相比，否定规则通常更隐含，相应的错误更隐蔽。例如，图1中的错误已存在于Linux内核中超过10年（即，在Linux-2.6.4或更早版本中提供）。因此，开发一种自动提取隐式否定编程规则以检测相关错误和漏洞的有效方法既具有挑战性又迫切。</p>\n<p>在本文中，我们提出NAR-Miner解决上述问题。最重要的想法是通过不频繁的模式挖掘来推断有趣的负关联规则，并进一步将相应的违规行为检测为潜在的程序错误。基本上，由于负面规则的性质[56]，直接挖掘不常见的模式以提取负面规则将产生大量规则。我们称之为规则爆炸问题。这些规则中的大多数对于错误检测都是无趣的，即它们不包含任何真实的应用程序逻辑，并且违反它们不会导致错误或程序质量问题。因此，基于这些不感兴趣的规则的检测结果将产生不可接受的误报。例如，直接将现有的负规则挖掘算法[43,46,61]应用于Linux内核将提取多达数十万条规则和数百万条违规行为。在有限的人力资源下进行人工审计变得不可能。为了解决规则爆炸问题，我们提出了一种语义约束的负关联编程规则挖掘算法，以避免尽可能地产生过多的不感兴趣的规则。此外，我们利用信息熵来识别易于导致不感兴趣的规则的一般函数。这一步有助于进一步遏制可能不感兴趣的规则。因此，NAR-Miner可以有效地缓解规则爆炸问题并获得理想的有趣规则来检测潜在的错误。</p>\n<p>我们实现了NAR-Miner的原型，并首先在Linux内核（v4.12-rc6）上进行评估。实验表明，基于语义约束的负规则挖掘和基于信息熵的规则过滤在减少不感兴趣的规则数量方面表现良好。也就是说，它减少了46％的无趣规则（即，在200个排名靠前的负面规则中从198到107）。特别是，它在排名前50位的负面规则中实现了62％的真正正面率。NAR-Miner报告了违反排名最高的200条规则的356条违规行为。我们手动检查结果并发现23个可疑错误和数十个质量问题。我们向Linux内核维护者报告可疑错误。其中17个已被确认为真正的错误，相应的补丁已合并到最新版本（例如，v4.16）。我们进一步将NAR-Miner应用于PostgreSQL v10.3，OpenSSL v1.1.1和FFmpeg v3.4.2。从排名靠前的规则和违规行为中，我们手动识别出六个可疑错误，所有这些错误都由相应的维护人员进行了确认和修复</p>\n<p>本文的主要贡献如下：</p>\n<ul>\n<li><p>据我们所知，我们的工作是第一个专注于从源代码中提取负面编程规则以检测错误的工作。它扩展了基于挖掘的错误检测技术的能力。</p>\n</li>\n<li><p>我们提出了一种通过在规则挖掘中引入程序语义并使用信息熵来识别一般函数来缓解规则爆炸问题的方法，该方法可以有效地提取用于错误检测的理想的有趣负编程规则。</p>\n</li>\n<li><p>我们针对真实世界的大型软件项目实现了NAR-Miner原型。我们将该工具应用于四个大型系统（即Linux内核，PostgreSQL，OpenSSL和FFmpeg）并引发相当多的错误，其中23个已被确认。</p>\n</li>\n</ul>\n<h1 id=\"2-动机示例\"><a href=\"#2-动机示例\" class=\"headerlink\" title=\"2.动机示例\"></a>2.动机示例</h1><p>我们使用来自Linux内核（v4.12-rc6）的简化代码片段来激励我们的方法。在图1中，函数lapbeth_new_device在第5行调用alloc_netdev为网络设备分配一块内存。然后在第8行，在内联函数中调用netdev_priv以获取私有数据的起始地址并将其存储到变量lapbeth。如图1所示，lapbeth指向先前分配的内存中的位置。如果设备注册在第11行失败，则将释放设备的内存块。由变量ndev指向的已分配内存在第21行首先释放，然后在第23行释放私有数据。从代码片段突出显示从内存分配到空闲的执行序列中的关键操作，并相应地描述相应的内存状态。我们使用红色水平线来描述通过free_netdev和kfree的蓝色垂直线释放内存。通过图示，可以很容易地看出代码中存在双重错误。</p>\n<p><img src=\"/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/1.png\" alt=\"\"></p>\n<p>传统的静态检测方法难以在大规模系统（例如Linux内核）中发现此错误和其他类似错误，因为所需的错误模式或规则是特定于应用程序并且难以收集。现有的基于挖掘的方法也无法报告错误。例如，最先进的方法AntMiner [26]提取正关联规则并检查违规。在Linux内核中，我们发现在对alloc_netdev的90次调用中，共有77次出现{alloc_netdev，free_netdev}（85.6％）。并且在533个调用实例中只有一次调用free_netdev后跟kfree（0.2％）。 AntMiner将{alloc_netdev}⇒{free_netdev}视为一个正规则，最小置信度阈值为85％[26]。但是，图1中的代码同时调用alloc_netdev和free_netdev，因此是对规则的支持，而不是违反。因此，上述错误未被发现。此外，由于低信任度（0.2％«85％），AntMiner不会将{free_netdev}⇒{kfree}视为有效规则（即，以最小置信度阈值来消除）。因此，AntMiner无法将“kfree跟随free_netdev”报告为错误。</p>\n<p>从上面的分析中，通过分析元素之间的伴随关系来检测图1中的错误是非常困难甚至是不可能的。实质上，与bug密切相关的两个程序元素（即free_netdev和kfree）是负相关的。通过统计分析可以发现这种知识。具体来说，我们发现在大多数情况下（大约99.8％）在Linux内核中，free_netdev后面没有kfree，我们了解到开发人员大多都知道在free_netdev之后调用kfree可能是不必要的或导致严重问题的情况。受此启发，相对少量的配对事件可被视为异常。</p>\n<p>我们利用不频繁的项集挖掘算法来推断负关联规则并应用规则来检测它们的违规（例如，图1中的那个）。在挖掘和检测期间，我们还考虑了程序语义（例如，数据流信息）。在我们的示例中，kfree与free_netdev共享数据，并且它们的外观一起被视为不常见的模式。因此，我们推断出一个负面规则{free_netdev}⇒¬{kfree}。将规则应用于我们的示例可发现相应的错误（表2中的错误12＃）</p>\n<h1 id=\"3-我们的方法\"><a href=\"#3-我们的方法\" class=\"headerlink\" title=\"3.我们的方法\"></a>3.我们的方法</h1><h2 id=\"3-1概述\"><a href=\"#3-1概述\" class=\"headerlink\" title=\"3.1概述\"></a>3.1概述</h2><p>我们提出了NAR-Miner，目标是检测程序包含一些操作（例如两个函数调用）的错误，这些操作被认为不会出现在一起，该方法不需要任何先验知识。NAR-Miner的高层理念是采用数据挖掘技术从源代码中推断出负关联规则并检测其违规行为。</p>\n<p>图2显示了NAR-Miner的概述。它首先为挖掘阶段准备数据。与大多数基于挖掘的方法类似[6,25,26,49,60]，我们仅从每个单独的函数中提取编程规则，即在程序内，以避免过于复杂的分析。识别每个函数内的程序元素及其语义关系并将其转换为事务，然后将其存储在数据库（称为事务数据库）中。接下来，它从数据库中挖掘频繁且不频繁的项集，它们表示程序元素集。然后，它从挖掘的项集中推断出负关联规则，并利用函数的置信度和熵自动对规则进行排序。最后，它检测违反推断规则的情况，并将排名最高的规则报告为审计的潜在错误。</p>\n<p><img src=\"/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/2.png\" alt=\"\"></p>\n<h2 id=\"3-2挑战\"><a href=\"#3-2挑战\" class=\"headerlink\" title=\"3.2挑战\"></a>3.2挑战</h2><p>以前的研究[43,46,61]表明只有少数表现出负相关关系很有意思的模式。他们通过计算支持和信任来识别有趣规则的技术不能直接用于代码挖掘。构造有趣的负关联规则的程序元素应该在它们的语义中相互压制，而不是偶尔出现在一起。我们的实证研究表明，直接应用Wu等人提出的算法。 [56]从Linux内核中提取的事务数据库生成183,712个负关联规则（参见§4.2.2），而其中99％在采样分析中不感兴趣。报告的违规行为多达309,689起，这使得人工审核变得不可能。我们称之为规则爆炸问题，并将其视为提取负关联规则的主要挑战。我们将以下两个方面归结为规则爆炸的根本原因。</p>\n<ol>\n<li><p>现有的负关联规则挖掘方法[43,45,56,61]主要针对购物篮，医学诊断，蛋白质序列等。对于这类数据，来自挖掘单位的任何两个元素（例如，购物收据）除属于同一单位外，没有任何特定关系。换句话说，挖掘单元的元素是同类的。然而，在程序元素之间，通常存在各种语义关系，例如数据依赖性。忽略这样的关系可能会导致许多不感兴趣的规则由语义上独立的元素组成，这些元素实际上并没有相互抑制，而是偶尔出现在一起。</p>\n</li>\n<li><p>大型项目通常包含一定数量的通用API，几乎可用于所有编程环境，例如Linux中的printk和isalpha。它们可能巧合地与其他操作配对以形成关联规则。即使考虑到挖掘期间的强语义关系（例如，数据依赖性），这些API仍然可能导致许多负面无趣的规则。实际上，API越普遍，它与其他操作的相互抑制就越少。</p>\n</li>\n</ol>\n<p>基于以上见解，我们如下缓解规则爆炸问题。 （1）考虑到如上所述的程序元素的本质，我们将规则挖掘集中在具有强语义关系（例如，数据依赖性）的程序元素上，以尽可能地减少不感兴趣的规则。 （2）我们使用信息熵来衡量API的普遍性，并用它来排列挖掘的候选负面规则。涉及高普遍性API的不感兴趣规则将被排除在最终审计之外。</p>\n<h2 id=\"3-3数据准备\"><a href=\"#3-3数据准备\" class=\"headerlink\" title=\"3.3数据准备\"></a>3.3数据准备</h2><p>NAR-Miner将程序元素转换为事务并将它们存储到数据库中。在本文中，我们关注两种程序元素：函数调用和条件检查，因为许多错误是由函数或条件错误引起的[1,6,21,26,33,38,47,57]。如前所述，我们的目标是从事务中提取负关联规则，其元素具有强大的语义关系。如果它们之间存在数据关联，我们定义两个元素以具有强大的语义关系，包括数据依赖性和数据共享[7]。详细地说，给定两个语句s1和s2，如果s2使用s1中定义的值（即数据依赖），或者它们都出现在同一个执行路径上并使用相同的非常量值（即数据共享），我们说他们在语义上有很强的相关性。程序元素的语义关系通过数据流分析[3,15]来识别。</p>\n<p>NAR-Miner的预处理器建立在GCC（v4.8.2）前端之上，该前端以SSA形式[12]提供控制流图和中间表示，用于数据流分析。图3（a）显示了一段代码，图3（b）显示了相应SSA形式的中间表示。 NAR-Miner可以判断is_valid，foo和bar是依赖于第2行的read2的数据。由于is_valid和foo在同一个执行路径中，因此它们具有数据共享关系。因为foo和bar之间没有路径，所以它们不被认为是语义相关的。</p>\n<p>为了简化挖掘阶段，然后将中间表示转换为事务数据库。每个函数定义都映射到一个事务。事务由两部分组成：程序元素和这些元素之间的一组语义关系。在转储到数据库之前，每个程序元素都被规范化。函数调用用不带参数的函数名表示;如果条件语句中的变量保留某些函数的返回值，或者在其他情况下保留其数据类型，则使用“RET”重命名，如许多挖掘方法[6,7,25,26,57,58]中所做的那样。例如，图3中的条件表达式归一化为“RET == 0”。两个程序元素之间的语义关系表示为事务中的元组。例如，元组（foo，is_valid）表示函数foo和is_valid具有一些语义关系。图3（c）显示了代码片段的语义关系，其中节点表示程序元素，边缘表示关系（黑线表示数据依赖性、红线表示数据共享）。</p>\n<p>我们将每个程序元素映射到一个唯一的整数，因此挖掘被应用于整数集以提高性能，因为大量的字符串等价比较是耗时的。</p>\n<p><img src=\"/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/3.png\" alt=\"\"></p>\n<h2 id=\"3-4提取频繁和不频繁的项集\"><a href=\"#3-4提取频繁和不频繁的项集\" class=\"headerlink\" title=\"3.4提取频繁和不频繁的项集\"></a>3.4提取频繁和不频繁的项集</h2><p>很少调用的程序元素总是很少与其他程序元素一起出现，并且会导致大量的负面模式。然而，这些模式在统计学中毫无意义[56]。因此，我们专注于挖掘负面模式，这些模式的元素经常单独出现但很少发生在一起。对于负关联规则A⇒¬B，其前因（即A）和后续（即B）是频繁的，但它们的组合（即（A∪B））是不频繁的。在本节中，我们将提出我们的算法来提取有趣的频繁和不频繁的项集，并将在下一节中解释如何生成否定规则。</p>\n<p>提取频繁和不频繁项集的现有算法仅依赖于事务数据库中项集的出现[43,46,61]。他们都没有考虑元素之间的语义关系。直接将它们应用于§3.3中生成的数据库将导致大量无趣的规则。据我们所知，没有不常见的项集挖掘算法可以直接应用于我们的工作中。为了解决这个问题，我们设计了一个语义约束的挖掘算法，该算法侧重于提取与语义相关的强项集。强语义相关项集中的元素在语义上都彼此相关，例如，具有数据依赖性或数据共享关系。</p>\n<p>我们基于众所周知的Apriori算法[2]设计我们的算法，该算法应用自下而上的方法通过将较小的频繁项目集合在一起来生成相对较大的候选项集。自下而上方法背后的原则是Apriori属性：频繁项集的任何子集也是频繁的。在我们的例子中，强语义相关项集的任何子集也与强语义相关，因为子集中的任何两个元素必须在语义上相关。因此，强大的语义相关项集也符合Apriori属性，可以自下而上的方式挖掘。</p>\n<p>算法1中显示了我们挖掘频繁和不频繁的强语义相关项集的算法。除了事务数据库，它还要求用户指定两个参数：最小频率支持mfs和最大频率支持mis。如果项集的支持大于或等于mf s，则认为项集是频繁的，如果项集的支持小于或等于mis，则项集是不频繁的。算法的输出是所有频繁项目集（FI）和感兴趣的不频繁项目集（IIs）。</p>\n<p><img src=\"/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/4.png\" alt=\"\"></p>\n<p>在开始时，算法扫描事务数据库以找出所有频繁的1项集（第3行）。然后它试图从频繁的（k-1）-itemsets（第4~14行）中发现频繁且不频繁的k-项集。 k项目集包含k个项目。首先，它通过连接频繁（k-1）-项来生成感兴趣的候选k项集（参见第5行）。如果它们具有k-2个共同项，则可以连接两个（k-1）-itemsets。假设两个可连接（k-1）-itemsets是{i1，…，ik-2，ik-1}和{i1，…，ik-2，ik}，则连接结果是k-itemset {i1，…，ik-2，ik-1，ik}。其次，该算法利用Apriori属性来修剪具有不频繁子项集的k项集（第6行）。之后，调用函数count_support来计算每个k-itemset的支持（第8行）。如果项目集的支持不小于mfs，则将项目集插入Lk（第10行），即一组频繁的k项目集;否则，如果它的支持不大于mis，则将其插入不频繁的k项集Nk集（第12行）。应该注意，支持为0的项集自然会被忽略。 Lk和Nk分别与FI和IIs（第15行）合并。然后，频繁项目集Lk用于生成更大的项集Lk + 1和Nk + 1。当Lk对于某个k为空时，算法终止，并输出收集的频繁/不频繁项集（第17行）。</p>\n<p>函数count_support扫描数据库以计算项集I的支持（第19~27行）。如果事务支持I（第23行），计数器将增加1。当且仅当它包含I中的所有项目以及所包含项目之间的所有可能关系时（表示为关系（I）），事务支持I。例如，图3中的事务支持itemset {foo，is_valid}，因为它不仅包括两个项foo和is_valid，还包括它们之间的语义关系，即元组（foo，is_valid）。但是，事务不支持itemset {foo，bar}，因为它不包含元组（foo，bar）。</p>\n<p>为了挖掘像{kfree}⇒¬{kfree}这样的规则，我们还提取了像{g，g}这样的2项集，其中g经常被调用，但是在同一函数中它的两个调用实例在语义上很少相关。这有助于NAR-Miner找到表2中的错误14＃（参见§4.2.3）。</p>\n<h2 id=\"3-5生成负关联规则\"><a href=\"#3-5生成负关联规则\" class=\"headerlink\" title=\"3.5生成负关联规则\"></a>3.5生成负关联规则</h2><p>负关联规则A⇒¬B意味着两个频繁项集A和B很少出现在同一事务中。也就是说，（A∪B）很少见。事实上，规则的前因和后果实际上是不常见的项目集的不相交分区。一种直接的负关联规则生成方法是从不频繁的项集I中找出所有对，如&lt;A，B&gt;，其中A∪B= I且A∩B=∅。它使用规则A⇒¬B的统一来确定其不频繁。这种说法的定义如下：</p>\n<p><img src=\"/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/5.png\" alt=\"\"></p>\n<p>其中，支持（A∪¬B）是支持A∪¬B，支持A但不支持A∪B的事务数量。因此，我们有支持（A∪¬B）=支持（A）-支持（A∪B）=支持（A）-支持（I），其中I =A∪B。因此，等式1可以改写为：</p>\n<p><img src=\"/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/6.png\" alt=\"\"></p>\n<p>从具有n个元素（n≥2）的不频繁项集I中，通过直接应用上述方法可以生成最多2个（n-1）个负关联规则。但是，对它们的违反是完全相同的，即支持项目集I的事务。因此，在面向错误检测的应用程序中仅跟踪它们中的一个就足够了。注意，从编程的角度来看，规则A⇒¬B意味着B中的元素不应出现在包含A的上下文中。如果反转规则B⇒¬A不感兴趣，则其违规总是误报，因为存在B并不意味着拒绝A.受此启发，在几乎所有情况下，如果我们期望支持不频繁项集I的事务成为真正的错误，那么从I派生的所有负关联规则应该是有趣的。因此，我们可以选择具有最低置信度的规则来表示这些规则。将置信度作为衡量标准，其他规则如果有趣则会很有趣。</p>\n<p>实际编程中的逻辑通常非常复杂。一些挖掘的规则可能不适用于编程实践。根据它们检测到的违规通常是误报。一般方法是对挖掘的规则进行排名，使得有趣的规则排名最高，而无趣的规则排在最低位。现有工作主要根据他们的置信度对规则进行排名（高信任规则排名最高）。然而，这种信任仅反映了几个有限元素之间的（负/正）相关性。实际上，编程规则的有趣性也与其元素是否集中在某些上下文有关。也就是说，如果元素的调用上下文趋向于更加同类，则由它组成的规则更可能是有趣的。否则，如果元素在非常不同的上下文中使用，则它更通用，并且更可能与各种元素一起出现。在本文中，我们使用一般性来表明元素的上下文有多不同。一般而言，规则由具有高一般性的元素组成，更可能是无趣的元素。</p>\n<p>我们引入信息熵来定量测量元素的一般性。对于程序元素g的调用实例，我们通过g依赖的元素和依赖于g的元素两个来描述它的上下文。我们在g的所有调用实例中提取这些元素并将它们放入包中。包的信息熵反映了调用实例的不同，可以用来衡量g的一般性。包的信息熵（表示为H（g））可以通过等式3计算:</p>\n<p><img src=\"/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/8.png\" alt=\"\"></p>\n<p>其中pi是包中第i个元素的频率; N是g的调用实例数。项集的熵是每个元素的熵的总和。</p>\n<p>根据每个程序元素的一般性，负关联规则R的兴趣度可以测量为：</p>\n<p><img src=\"/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/10.png\" alt=\"\"></p>\n<p>其中H（gi）是元素gi的信息熵。</p>\n<p>我们在算法2中形成了生成负关联规则的方法。该算法将§3.4中提取的频繁项集FI和不频繁项集II以及用户指定的阈值min_conf作为输入。它返回负关联规则NARs的集合。它首先为具有最低置信度的每个不频繁项集I生成代表性规则（第3~5行）。从等式2可以看出，A的支持越小，A⇒¬B的置信度就越低。因此，我们选择支持最小的I子集来生成代表性规则。然后，计算规则的置信度（第6行）并根据阈值min_conf（第7行）进行检查。信息熵用于衡量潜在有趣规则的兴趣（第10行）。最后，负关联规则按其兴趣的降序排序。</p>\n<p><img src=\"/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/11.png\" alt=\"\"></p>\n<h2 id=\"3-6检测违规行为\"><a href=\"#3-6检测违规行为\" class=\"headerlink\" title=\"3.6检测违规行为\"></a>3.6检测违规行为</h2><p>违反负关联规则R：A⇒¬B的是那些支持项集A∪B的事务。直接的方法是直接扫描数据库以找出包含项集A和B的所有事务。但是，这样的枚举方法这非常耗时，特别是对于拥有数十万事务的数据库而言。为了加快检测过程，我们采用了PR-Miner [25]中使用的技巧。在生成频繁且不频繁的项目集时，NAR-Miner还会收集支持它们的事务。我们使用支持者（I）来指示支持项集I的所有事务。然后，违反负关联规则R的集合恰好是支持者（A∪B）。</p>\n<h1 id=\"4-评估\"><a href=\"#4-评估\" class=\"headerlink\" title=\"4.评估\"></a>4.评估</h1><h2 id=\"4-1实验设置\"><a href=\"#4-1实验设置\" class=\"headerlink\" title=\"4.1实验设置\"></a>4.1实验设置</h2><p>我们将NAR-Miner实现为原型系统，以检测大规模C程序中的错误。我们在众所周知的Linux内核（v4.12-rc6）上评估NAR-Miner。 Linux内核已被广泛用作基于挖掘的错误检测方法的评估目标（TOE）[6,14,20,20,22,24-26,30,42,46-48,57,60]。选择Linux内核作为我们的目标的主要原因是我们想要通过检测以前工作中找不到的一些真正的错误来检查我们方法的有效性。 Linux-v4.12-rc6是实验时的最新版本。它包含24,919个C和19,295个标题文件，包括376,680个函数和15,501,651行代码（LoC）。</p>\n<p>为了验证NAR-Miner是否可以应用于其他系统中的错误检测，我们还从不同的域中选择了三种流行的大型C系统：PostgreSQL v10.3，OpenSSL v1.1.1和FFmpeg v3.4.2。 PostgreSQL是一个开源数据库，OpenSSL是一个用于安全通信的库，FFmpeg是一个用于编码/解码多媒体文件的框架。许多错误检测方法选择它们作为评估的目标[19,20,25,35,57]。</p>\n<p>NAR-Miner需要指定三个参数：（1）频繁项集的最小支持阈值（即mfs），（2）不频繁项集的最大支持阈值（即mis），以及（3）有趣的负面规则最小置信度阈值（即min_conf）。通常，如果项目集是具有较高支持的频繁项目集或具有较低支持的不频繁项目集，则项目集将更有趣。此外，较高的最低限度可以进一步消除无趣的负面规则。实际上，不同的参数设置可能导致无法报告某些实际错误或产生过多的错误警报。用户可以保守地或积极地根据检测策略调整这些参数。为了确定合理的参数，我们进行了[6,25,26,49,60]中的实证研究。具体而言，通过抽样分析，当排名前10位的负面规则中有一半以上是有趣的规则时，参数设置被认为是可接受的。在这项研究中，我们将mf设置为15，将mis设置为5，将min_conf设置为85％。在我们的实验中，默认参数设置适用于四种不同的TOE（参见§4.2和§4.3）。</p>\n<h2 id=\"4-2检测Linux内核中的错误\"><a href=\"#4-2检测Linux内核中的错误\" class=\"headerlink\" title=\"4.2检测Linux内核中的错误\"></a>4.2检测Linux内核中的错误</h2><h3 id=\"4-2-1预处理源代码\"><a href=\"#4-2-1预处理源代码\" class=\"headerlink\" title=\"4.2.1预处理源代码\"></a>4.2.1预处理源代码</h3><p>NAR-Miner花了大约77分钟来解析内核源代码并将其转换为事务数据库。在所有函数定义中，有333,248个函数包含一些程序元素（即函数调用或条件检查）。转换后，每个函数定义都映射到数据库中的事务。该数据库包括227,246个不同的元素，其中每个元素对应于函数调用或条件检查。其中，6,203个频繁出现在多个事务中。</p>\n<h3 id=\"4-2-2挖掘负面规则的有效性\"><a href=\"#4-2-2挖掘负面规则的有效性\" class=\"headerlink\" title=\"4.2.2挖掘负面规则的有效性\"></a>4.2.2挖掘负面规则的有效性</h3><p>为了评估包含语义约束规则挖掘和基于信息熵的规则排序的方法的有效性，我们进行了三个实验：NAR-Miner–，NARMiner-，NAR-Miner。每个实验中采用的方法解释如下：</p>\n<ol>\n<li><p>NAR-Miner–：挖掘算法不考虑项目之间的语义关系，挖掘的规则根据其对应性进行排序;</p>\n</li>\n<li><p>NAR-Miner-：基于NAR-Miner–，项目之间的语义关系被用作约束来消除弱语义相关项集;</p>\n</li>\n<li><p>NAR-Miner：基于NAR-Miner-，我们引入信息熵来衡量负关联编程规则的趣味性。该实验评估了NAR-Miner的全部功能。</p>\n</li>\n</ol>\n<p>我们在表1中显示了实验结果，包括频繁项目集（#FI），不频繁项目集（#IIs）的数量，推断的负关联规则的数量，检测到的违规数量以及挖掘，排名和检测的时间成本（时间）很快。</p>\n<p>比较NAR-Miner–和NAR-Miner-或NAR-Miner的结果，我们观察到采用语义约束的挖掘减少了一个数量级的规则和违规总数（＃All列减少约88％） ）。规则爆炸问题在很大程度上得到了缓解。</p>\n<p>由于时间有限，我们在每个实验中手动检查200个排名靠前的负关联规则。这些规则按照他们在NAR-Miner–和NAR-Miner-中的可信度排名，而他们在NAR-Miner中的兴趣则排名靠前。负关联规则如果真的很有意义则标记为“True”，违反它会导致错误或质量问题。例如，{free_netdev}⇒¬{kfree}是一个有趣的（“True”）规则，因为违反它将导致潜在的双重释放错误，例如§2中讨论的错误。在NAR-Miner中，前200条规则中只有2条被认为是有趣的规则。换句话说，其中99％导致违规检测的错误警报。这种有趣规则率低的主要原因是由这些规则组成的程序元素通常在语义上彼此独立。对于下面的例子，虽然在NAR-Miner中排名第一，并且具有99.96％的置信度，但规则{static_key_false}⇒¬{atomic_read}是无趣的，因为这两个函数将完全独立的变量作为包含他们的程序中的实际参数，他们并没有真正压制对方。</p>\n<p><img src=\"/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/12.png\" alt=\"\"></p>\n<p>引入语义约束的挖掘将NAR-Miner-中的误报率降低到90.5％，然而，这仍然太高而不能在实践中被接受。虽然推断规则具有语义相关的所有程序元素，但是一些元素非常通用，并且可以在违规不会导致错误的各种上下文中使用。例如，函数iowrite32是在它们一起出现时依赖于readl的数据，在Linux内核中只出现一次，并且推断出规则{iowrite32}⇒¬{readl}。该规则在NAR-Miner-中排名第8位，并且在99.64％的情况下排名第一，但仍然无趣，因为这两种功能都以各种方式使用，并且它们的组合不会导致任何错误。</p>\n<p>NAR-Miner使用信息熵来测量函数的一般性。 iowrite32和readl分别为5.9和4.6。规则{iowrite32}⇒¬{readl}的有趣性是9.5％，小到足以排名低。以这种方式，大多数不感兴趣的规则被分配低兴趣度值并因此被排在底部，同时潜在有趣的规则被分配具有相对高的兴趣度值并且在顶部排名。在NAR-Miner中，前200个负面规则中有93个标记为“真”，几乎是NAR-Miner-中数字的5倍。特别是，在前50个中有31个“真正的”负规则。真阳性率为62％。也就是说，我们可以在不到两次手动审计中找到一个有趣的规则，这在实际的错误检测中是可以接受的，而不是针对Linux内核等真实的大型系统。</p>\n<p>我们还检查了违反前200条推断规则的情况。从表1中的Violations和#Bugs列中，我们观察到更多报告的违规和由于应用基于语义约束的挖掘和基于信息熵的排序而导致的错误，这最终增强了NAR-Miner的能力，使其能够推断出更多有趣的规则（列#True和TP Rate）</p>\n<p><img src=\"/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/13.png\" alt=\"\"></p>\n<p>4.2.3检测违规行为</p>\n<p>针对NAR-Miner提取的21,166个负关联规则，检测到37,453个违规。我们根据规则的排名手动检查报告的负关联规则及其违规。为了从检测中获得最大的收益，我们选择排名靠前的规则进行审核，因为违反这些规则更可能是真正的错误。我们在一个人一天内检查了200个排名靠前的负面关联规则和相应的356个违规行为（参见表1中的最后一行）。</p>\n<p>我们发现了23个可疑错误和数十个程序质量问题，例如冗余条件检查和计算。由于Linux内核维护者经常忽略质量问题，我们只向Linux内核维护者提交23个可疑错误的补丁。到目前为止，这些补丁中有17个已经被内核维护者所认可和接受。</p>\n<p>表2中列出了确认的bugs，其中包含错误（函数），违反的规则（违规规则）以及三个实验中的规则排名。最后一列显示了这些bug的补丁ID和我们在PatchWork站点上的补丁。在这些发现的bug中，六个（2＃，3＃，8＃，12＃，13＃和14＃）在内核2.6中出现，两个（3＃和12＃）甚至潜伏了10年以上。</p>\n<p><img src=\"/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/14.png\" alt=\"\"></p>\n<p>这些bug总共违反了12个负关联规则。如果按照排名进行排名，则只有其中一个在前200条规则范围内（NAR-Miner-列中为12＃）。但是使用信息熵对规则进行排名会使所有这些规则都进入前200名（NAR-Miner）。这一观察结果表明，将信息熵引入排名对于突出有趣的规则非常有用。我们还观察到这些规则中只有2个是在NAR-Miner–中提取的（“NA”表示没有命中），其他规则都缺失。例如，缺少规则{free_netdev}⇒¬{kfree}（12＃），因为有106个函数同时调用free_netdev和kfree。在不考虑语义关系的情况下，项集{free_netdev，kfree}的支持是106，这远远高于预定阈值mis = 5。</p>\n<p>因此，它不会被视为不常见的项目集，因此无法推断出负关联规则。然而，凭借语义约束的挖掘和信息熵，NAR-Miner成功地推断出规则并发现相应的错误（图1）。因此，我们声称语义约束的挖掘不仅可以帮助减少误报，还可以减少误报。</p>\n<h3 id=\"4-2-4与基于正规则挖掘的方法的比较\"><a href=\"#4-2-4与基于正规则挖掘的方法的比较\" class=\"headerlink\" title=\"4.2.4与基于正规则挖掘的方法的比较\"></a>4.2.4与基于正规则挖掘的方法的比较</h3><p>在实践中，违反负规则的某些错误也可能违反相应的积极规则。因此，应该通过基于负面和正面规则挖掘的方法来检测这样的错误。我们调查是否会发生这种情况。我们选择表2中的17个错误作为基线，进行另一个实验，从§4.2.2中挖掘出的266,449个频繁项目集中使用与NAR-Miner相同的mfs和min_conf设置来推断出正关联规则，然后检测违规规则，如[25]和[26]中所做的那样。手动检查显示检测到17个错误中的3个（表2中的2＃，3＃和15＃），而其他14个错误（约82.4％）丢失。然后，我们使用语义约束的挖掘来增强基于正规则挖掘的方法，即考虑程序元素之间的数据关系。发现了另外两个错误（5＃和14＃），但仍有12个错误（约70.6％）未被发现。因此，我们声称虽然语义约束的挖掘能够帮助基于正规则挖掘的方法检测更多错误，但基于负规则挖掘的方法可以专门发现许多基于正规则挖掘的方法无法实现的错误。</p>\n<h2 id=\"4-3检测其他系统中的bug\"><a href=\"#4-3检测其他系统中的bug\" class=\"headerlink\" title=\"4.3检测其他系统中的bug\"></a>4.3检测其他系统中的bug</h2><p>NAR-Miner进一步应用于PostgreSQL v10.3，OpenSSL v1.1.1和FFmpeg v3.4.2。 NAR-Miner分别从PostgreSQL，OpenSSL和FFmpeg中提取了690,382和335个负面规则。我们在§4.2中手动检查排名靠前的负面规则（不超过50个）及其在每个系统中的违规行为。因此，我们确定了六次违规（每个目标两次），并将其报告给相应的社区。到目前为止，所有六个可疑错误都被相应的系统维护人员修复了。有关详细信息，请参阅邮件列表[41]中PostgreSQL的错误报告，ID为＃15104和＃15105，OpenSSL来自问题列表[40]，ID为＃5567和＃5568，以及来自邮件列表的FFmpeg [39] ID为＃7074和＃7075。实验证明NAR-Miner不限于特定的目标系统（例如，Linux内核），而是可以用于在各种大规模C系统中发现真正的错误。</p>\n<h2 id=\"4-4案例研究\"><a href=\"#4-4案例研究\" class=\"headerlink\" title=\"4.4案例研究\"></a>4.4案例研究</h2><p>在本节中，我们将说明NAR-Miner的能力与基于肯定关联规则（PAR）挖掘的方法在PostgreSQL中的＃15105问题上进行比较。</p>\n<p>在PostgreSQL中，函数OpenTransientFile分配一个文件描述符并将其存储到全局维护的已分配文件列表中。返回描述符必须与CloseTransientFile一起释放，它会在关闭之前从列表中删除描述符。直接使用close会使列表保留已发布的描述符，并可能导致释放后使用的错误。从统计上来说，在PostgreSQL v10.3中，OpenTransientFile在28个函数中被调用。在27个函数中，其返回值传递给CloseTransientFile，但在1函数中，其返回值直接传递给close，从而产生负关联规则{OpenTransientFile}⇒¬{close}和正关联规则{OpenTransientFile}⇒{ CloseTransientFile}具有相同的96.4％的置信度。</p>\n<p>图4显示了函数dsm_impl_mmap，该函数错误地将在第4行用OpenTransientFile分配的文件名描述符fd传递给沿路径的第12行关闭。它违反了上述负面规则，因此被NAR-Miner报告。但是，从伴随分析的角度来看，因为在某些路径上，fd在第8和第16行正确传递给CloseTransientFile，这符合上述正规则的要求。因此，有缺陷的代码确实是支持而不是违反规则。我们通过用CloseTransientFile（fd）替换第12行来解决这个问题，如图4所示。修补程序已经被维护者接受了</p>\n<p><img src=\"/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/15.png\" alt=\"\"></p>\n<h1 id=\"5-讨论和限制\"><a href=\"#5-讨论和限制\" class=\"headerlink\" title=\"5.讨论和限制\"></a>5.讨论和限制</h1><p><strong>负面规则与正面规则</strong>。在本文中，我们主要基于负关联规则而不是正关联规则来检测错误。但是，这两种方法没有必要的矛盾。由于他们专注于不同类型的编程规则，因此它们可以相互补充。从错误检测的角度来看，我们的方法能够提取负面的编程规则并检测基于挖掘正关联规则的方法无法揭示的错误，反之亦然。理论上，两种方法的组合可以表现出更好的检测性能（更少的漏报率）。</p>\n<p>此外，与挖掘积极规则相比，挖掘负面规则通常伴随着产生更多无趣的规则，导致大量的误报。在这种情况下，同一程序的积极规则可以帮助减少它们。例如，如果一段代码违反了否定规则但满足了正规则，则相应的负面规则的违反不太可能成为真正的错误。我们可以降低其排名以避免这种违规行为。类似地，基于正规则的错误检测也可能面临相同的挑战（即，报告误报）。因此，在这种情况下，一个直截了当的问题是，这两种方法是否有助于减少误报？我们将在未来进一步研究。</p>\n<p><strong>规则爆炸</strong>。实质上，负关联规则挖掘中的规则爆炸问题无法完全解决。在本文中，我们采用了一种相对直接的方法。具体来说，我们利用元素之间的语义关系来消除挖掘过程中绝大多数不感兴趣的规则，然后使用信息熵来衡量规则的有趣性，以便进一步突出显示潜在的有趣规则。但是，可能存在多种解决方案。例如，我们可以进一步量化程序元素之间的语义关系的强度，以重新改善挖掘结果。除了数据依赖和数据共享关系之外，还可以利用其他关系，例如控制流关系。这些潜在的改进可以进一步缓解规则爆炸问题，从而降低手动审计效率。这也是我们未来的工作之一。</p>\n<p><strong>挖掘算法</strong>。在本文中，我们采用项集挖掘算法来提取负编程规则。实际上，对于某些类型的编程规则，其他形式的表示和挖掘算法可能更合适。例如，使用序列来表示顺序敏感的编程逻辑[1,29,53,55]比使用项目集更合适。然而，基于序列的算法在发现对顺序不敏感的编程逻辑方面具有较差的鲁棒性。如果我们能够有效地确定编程模式是否对顺序敏感，则可以采用目标算法来挖掘相关规则。这将是我们未来的工作之一。</p>\n<h1 id=\"6-相关工作\"><a href=\"#6-相关工作\" class=\"headerlink\" title=\"6.相关工作\"></a>6.相关工作</h1><p>程序分析已被广泛而成功地用于错误发布。例如，模型检查可以使用目标系统的模型和规范自动验证有限状态系统的正确性属性[10]。由于为目标系统编写模型的成本很高，因此开发实验级模型检查器并在系统代码中发现实际错误[32,59]。研究人员还利用程序分析来检测违反特定规则的行为。通常，向工具提供一组编程规则，其静态地或动态地检查目标系统是否违反给定规则。 Pasareanu和Rungta开发了SPF，通过将符号执行引入到模型检查中来生成Java程序的测试用例[37]。恩格勒等人。提出了使用系统特定编译器扩展[13]静态检查系统规则的技术，而FindBugs作为独立工具运行，以检查Java字节码中错误模式的出现[11]。 Livshits和Lams [28]将用户提供的漏洞规范转换为静态分析器，并使用它们来检测用Java编写的Web应用程序中的漏洞，例如SQL注入和跨站点脚本。此外，Molnar等人。利用动态测试生成来检查二进制程序中的整数错误，检查特定断言的违规情况[31]。尽管它们在解决错误方面取得了成功，但这些方法在很大程度上取决于系统的模型或错误的模式，例如高级API语义[50]，我们称之为先验知识。没有这种知识，他们就无法发现错误。相反，我们的工作会自动发现知识，然后根据收集的知识检测错误。</p>\n<p>还提供了可以从目标系统自动提取知识的技术。 Engler等人提出的先驱工作。采用统计分析来推断给定规则模板的时间规则，检测错误而不指定具体规则[14]。 Kremenek等人使用因子图通过结合不同的信息来源推断程序的规范[22]。这两种方法仅限于推断具有预定模板的规则和必须由用户提供的特定知识。一些方法依赖于挖掘规则中的某些领域知识，并且专门用于推断关键API [1,16,36,49,53,55]或安全敏感函数[47,58]的规则。它们还要求用户提供领域知识以促进挖掘过程。但是，NAR-Miner在根据程序中包含的关联规则（隐式）提取规则时不需要用户提供先验知识。</p>\n<p>最近，研究人员利用数据挖掘算法从真实的大型系统中提取更多一般规则[4,7,8,21,23-25,27,29,30,33,34,44,54,58]。这些基于挖掘的技术背后的首要思想是：在大多数情况下，程序是正确的，因此任何异常都可能是错误。通常，这些方法首先推断出来自目标系统的频繁出现的模式，并将这些模式视为开发人员在编码时应遵循的（隐式）规则。然后，他们发现任何违反这些规则的行为都是潜在的错误。推断的模式可以是正面的也可以是负面的。例如，PR-Miner [25]和AntMiner [26]提取了强制关联规则，强制配对表面的程序行为。Chang等通过从程序控制流中挖掘频繁关联的子图并检查偶发违规来检测缺失的代码结构[7]。 Yun等。根据不同API之间挖掘的语义正关联规则推断出API的正确用法[60]。与这些方法不同，NAR-Miner专注于从源代码中挖掘负关联规则，并检测违反这些规则的错误。也可以从动态执行跟踪中提取类似的规则。Beschastnikh等开发了Synoptic，从系统执行日志中生成时间系统不变量[5]。</p>\n<p>Wang等人开发了Bugram，它使用n-gram语言模型来测量令牌序列的概率，并将低概率序列视为异常，即潜在的错误[52]。Bugram还可以检测由相互抑制的程序元素共同引起的某些错误。但是，由于序列窗口的大小有限，Bugram很难捕获涉及长距离程序元素的错误。</p>\n<p>挖掘负关联规则已应用于购物篮，蛋白质序列和金融数据等数据[18]。对于这样的数据，两个元素之间的关系比对关系贡献不同强度的程序元素的关系简单得多。Wu等人提出了算法，以有效和高效地挖掘大型数据库中的负关联规则[56]。Zhou和Yau提出了一种组合算法来挖掘有趣的关联规则，减少了大量的否定规则[61]。NAR-Miner也可以采用这些算法作为基本挖掘算法，但需要处理程序语义以减少不感兴趣的规则。</p>\n<h1 id=\"7-结论\"><a href=\"#7-结论\" class=\"headerlink\" title=\"7.结论\"></a>7.结论</h1><p>数据挖掘技术已广泛用于推断编程规则，然后根据规则检测软件错误。现有方法已经证明，正关联规则（表明相关的程序元素必须一起出现）对于通过检查违规来检测错误是有用的。然而，拒绝所涉及的程序元素的共同出现的负关联规则大多被忽略。我们提出NAR-Miner从源代码中挖掘负关联规则。我们引入程序语义来指导挖掘阶段。我们还利用函数熵对候选规则进行排名并突出显示有趣的规则。通过这种方式，NAR-Miner显着减少了不感兴趣的规则的数量，并在一定程度上缓解了规则爆炸问题。我们在四个流行的大型系统上评估原型，并发现了相当多的错误，其中一些已被维护者所困扰。</p>\n","categories":[{"name":"论文","slug":"论文","permalink":"http://yama0xff.com/categories/论文/"},{"name":"数据挖掘","slug":"论文/数据挖掘","permalink":"http://yama0xff.com/categories/论文/数据挖掘/"}],"tags":[{"name":"2018年","slug":"2018年","permalink":"http://yama0xff.com/tags/2018年/"},{"name":"数据挖掘","slug":"数据挖掘","permalink":"http://yama0xff.com/tags/数据挖掘/"},{"name":"漏洞检测","slug":"漏洞检测","permalink":"http://yama0xff.com/tags/漏洞检测/"},{"name":"源代码","slug":"源代码","permalink":"http://yama0xff.com/tags/源代码/"}]},{"title":"Superset Disassembly: Statically Rewriting X86 Binaries Without Heuristics Disassembly","date":"2019-01-27T07:33:23.000Z","path":"2019/01/27/Superset-Disassembly-Statically-Rewriting-X86-Binaries-Without-Heuristics-Disassembly/","text":"Abstract静态代码重写是系统安全应用的一项核心技术，它的使用场景包括性能分析，优化和软件错误定位等。之前的许多静态二进制程序重写方法，例如CCFIR, PITTSFIELD, Google’s Native Client, BinCFI, UROBOROS等，在保证重写正确时，提出了有关二进制程序的许多假定，例如完全正确的反汇编，编译器要求，调试符号等等，给实际应用在Commercial off-the-shelf（COTS）二进制程序上制造了困难。作者提供了multiverse，一个新的二进制程序重写器，它不基于上述的任何假定并能够重写intel x86 COTS程序。在COTS二进制程序重写中，存在着两大挑战： （1）如何反汇编二进制代码并包含所有合法指令 （2）如何重新汇编重写后的指令并保留原程序的语义。multiverse使用了两种技术分别解决这两大挑战：（1）superset disassembly：通过对所有offset起始的地址进行反汇编获得合法代码的superset。 （2）instruction rewriter：通过替换控制流转移指令，中转到一个映射表，能够将原程序中所有的指令重定位到任意其他位置。 relevant information 作者 Erick Bauman，Zhiqiang Lin，Kevin W. Hamlen 单位：University of Texas at Dallas. 单位 University of Texas at Dallas 出处 NDSS’18 原文地址 https://github.com/wtwofire/database/blob/master/papers/reverse/2018-Superset%20Disassembly%EF%BC%9AStatically%20Rewriting%20x86%20Binaries%20Without%20Heuristics.pdf 源码地址 https://github.com/utds3lab/multiverse 发表时间 2018年 背景与概述作者的目的是为了发展一种二进制转化方法，改善现有二进制程序转化方法的实用性和通用性。为了表达简洁，也因为x86的程序更少开源。同时之前的许多代码转化方法也以x86程序为目标，作者的方法集中与主流编译器编译的linux 32位x86程序，同时不适用dlopen等动态载入库和自修改代码。 挑战在编写一个通用的二进制程序重写器时存在着许多挑战： C1：识别和重定位静态内存地址 编译后的二进制程序代码包含许多固定地址，很多指向全局变量。代码重写在移动这些目标时，必须同时更新它们的引用。在反汇编代码中和地址段中识别这些地址常量是非常困难的，因为整数值和这些地址常量在语法上并没有明显的区别。 C2：处理动态计算的内存地址在程序中还存在许多动态计算的内存地址。由于地址计算方式比较复杂，生成间接控制流转换表(iCFT)非常困难。重映射iCFT对于二进制程序重写是一个核心挑战。 C3：区分代码和数据代码和数据在二进制文件中没有语法上的区别，在现代处理器中，为了优化性能，许多数据被放在代码段中。这给反汇编带来一些困难。 C4：作为参数的函数指针作为函数指针的参数如果在目标函数中没有正确识别并且更新到改写后的地址，那么重写后的程序在执行时很可能会调用已经被之前的函数地址，令执行失败。同时，识别函数地址也非常困难。 C5：处理位置无关代码主流编译器生成了许多位置无关代码。这些代码会根据自身地址和相对位置寻找其他的执行代码。如果改变了它们的相对位置，那么在执行时就有可能失败。 核心想法基于之前的二进制重写方法，作者系统化了下面的这些想法来针对性地解决上面的挑战 S1：保持原有数据空间的完好无损保持程序中数据段原有的位置和内容，这个方法之前也被用在许多二进制重写器中，例如SECONDWRITE和BINCFI S2：创建一个从原有代码空间到新的重写代码空间的映射作者在这个映射中忽略常用的地址计算中 基址+偏移 的方法，只考虑最后获得的最终地址，并将这个地址与重写后的代码地址进行对应。作者对于原有地址空间中的每个代码段地址都找到了一个映射，这样就简单的解决了动态计算的内存地址问题。 S3：暴力反汇编所有可能的代码为了解决反汇编可能存在缺失的问题，作者对于从代码段开始的每个偏移，都进行了反汇编直到遇上非法指令，或者已经反汇编过的地址。原程序中执行的所有代码必定是暴力反汇编获得的代码的子集。 S4：重写所有用户级别的代码通过重写所有用户级别的代码，可以在函数指针被调用处利用原程序与重写程序之间的地址映射，将指向原程序地址空间的函数指针映射到重写后的地址空间。 S5：重写所有call指令以解决pic代码 在查看了x86指令集后，所有的pic代码计算方式在32位x86指令集中，都使用call指令来获得当前地址，作者改写了所有call指令，令其push一个未重写时的地址在栈上，被利用于计算地址时，即可以获得原有计算应得的地址，再由iCFT进行统一处理。 系统Overview基于上面的想法，作者实现了multiverse，正如下面的图片中显示，multiverse系统包含两个分开的步骤，映射和重写： 在映射阶段，superset disassembler是用下面所示的算法对代码段开始的每个offset进行反汇编，删除重复的代码并在尾部设置一个跳转指令。可以注意的是，在反汇编中，作者删除了从非法指令向前到最后一条控制转移指令的代码内容： multiverse修改了反汇编获得的代码中占位符长度过短的jcc，jmp指令，因为它们原来的指令很可能长度不够填充新的跳转地址。在这之后，即可以确定所有重写后的指令长度和位置，此时所有的跳转指令依旧包含着占位符地址。 在重写阶段，multiverse根据重写后的地址位置和原程序地址创建一个本地代码的映射表。映射表的键值是原程序中的内存地址，值则对应着新的代码空间中的地址。 对于重写程序中的直接跳转，multiverse根据映射表将其修改为新的地址。 对于间接跳转，multiverse将其中转到一个搜索映射表的函数中。函数的输入，跳转目标处于原程序的代码空间中。这个函数通过对应映射表找到新代码空间中的对应地址，并执行跳转。 对于外部函数或地址的跳转。由于这些地址在本地映射表中对应。如下图所示，映射函数将在全局映射表中寻找它所处的代码文件并在其对应的映射表中寻找对应地址。 为了处理位置无关代码和函数指针，multiverse对于所有的call和ret指令都进行了修改。 通过这样的方式，重写后的代码可以任意的安排指令和基本块位置。 最终multiverse利用重写后的代码生成一个新的elf文件。 实现作者基于许多python库，包括python-capstone，pyelftools,pwntools实现了multiverse，包含超过3000行python代码和超过150行汇编代码。同时，基于重写所处的Linux环境，作者对于动态加载器和VDSO进行了特殊处理。 测试作者使用了所有的SPECint 2006 benchmark程序，共12个，作为测试程序集。测试的机器使用一台ubuntu 14.04.1 lts，Intel i7-2600 cpu，4GB RAM。 有效性作者执行了multiverse重写后的所有程序，并和未重写的版本进行对应，所有重写后的程序都正确的执行完毕，输出和未重写的版本同样的结果。 下表描述了重写后的程序的详细信息： 有趣的是，对于代码段，所有重写后的程序的代码段长度大约都是原程序的4-5倍，这很可能与x86指令的平均长度有关。同时，表中所有的.newtext段长度都没有包括大约4MB的全局映射表大小，对于代码段长度较小的case，例如429.mcf，这导致了较大的size overhead。 开销作者在原来的benchmark程序和重写后的程序上运行了10遍，以对程序重写后的性能进行一个衡量，结果如下表所示： 对于大部分的测试程序来说，时间overhead不超过100%，平均的性能overhead为60.42%。对于471.omnetpp 和 483.xalancbmk，性能损耗较高，这两个程序使用c++语言编写，对类函数和库函数的频繁调用在重写时带来了大量的性能损耗。 接着作者比较了不同优化措施对性能带来的影响，例如只不重写外部函数库，或者对回调函数进行特殊处理，对位置无关代码进行特殊处理。结果如下图所示： 可以发现，通过对位置无关代码进行特殊处理（假设程序只使用get_pc_thunk函数），可以获得巨大的性能提升。 作者测试了使用multiverse进行插桩带来的性能开销，并和常用的工具pin进行了比较，两者都执行对于指令数统计的插桩。 在大部分情况下，使用multiverse在程序重写中静态进行插桩带来的性能消耗比使用pin来的低，在以下情况下，由于pin对于插桩内部代码进行分析，使用pin的插桩性能损耗稍微好一些。 最后，作者测试了使用multiverse作为安全应用工具的性能，作者使用multiverse编写了一个shadow stack，并与用pin编写的工具相比较。使用multiverse编写的具有巨大的性能优势。 总结作者通过使用了superset disassemble和 instruction rewriter两项技术，开发了multiverse系统，提供了一个不依赖启发式分析的二进制软件重写工具，并且通过对比，证明这个工具在安全应用的性能上，和当前主流的二进制插桩框架PIN相比更有优势。 论文翻译内容转载至GoSSIP.","content":"<h1 id=\"Abstract\"><a href=\"#Abstract\" class=\"headerlink\" title=\"Abstract\"></a>Abstract</h1><p>静态代码重写是系统安全应用的一项核心技术，它的使用场景包括性能分析，优化和软件错误定位等。之前的许多静态二进制程序重写方法，例如CCFIR, PITTSFIELD, Google’s Native Client, BinCFI, UROBOROS等，在保证重写正确时，提出了有关二进制程序的许多假定，例如完全正确的反汇编，编译器要求，调试符号等等，给实际应用在Commercial off-the-shelf（COTS）二进制程序上制造了困难。作者提供了<code>multiverse</code>，一个新的二进制程序重写器，它不基于上述的任何假定并能够重写intel x86 COTS程序。在COTS二进制程序重写中，存在着两大挑战： （1）如何反汇编二进制代码并包含所有合法指令 （2）如何重新汇编重写后的指令并保留原程序的语义。<strong><code>multiverse</code>使用了两种技术分别解决这两大挑战：（1）superset disassembly：通过对所有offset起始的地址进行反汇编获得合法代码的superset。 （2）instruction rewriter：通过替换控制流转移指令，中转到一个映射表，能够将原程序中所有的指令重定位到任意其他位置。</strong></p>\n<table>\n<thead>\n<tr>\n<th>relevant information</th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><em>作者</em></td>\n<td>Erick Bauman，Zhiqiang Lin，Kevin W. Hamlen 单位：University of Texas at Dallas.</td>\n</tr>\n<tr>\n<td><em>单位</em></td>\n<td>University of Texas at Dallas</td>\n</tr>\n<tr>\n<td><em>出处</em></td>\n<td>NDSS’18</td>\n</tr>\n<tr>\n<td><em>原文地址</em></td>\n<td><a href=\"https://github.com/wtwofire/database/blob/master/papers/reverse/2018-Superset%20Disassembly%EF%BC%9AStatically%20Rewriting%20x86%20Binaries%20Without%20Heuristics.pdf\" target=\"_blank\" rel=\"noopener\">https://github.com/wtwofire/database/blob/master/papers/reverse/2018-Superset%20Disassembly%EF%BC%9AStatically%20Rewriting%20x86%20Binaries%20Without%20Heuristics.pdf</a></td>\n</tr>\n<tr>\n<td><em>源码地址</em></td>\n<td><a href=\"https://github.com/utds3lab/multiverse\" target=\"_blank\" rel=\"noopener\">https://github.com/utds3lab/multiverse</a></td>\n</tr>\n<tr>\n<td><em>发表时间</em></td>\n<td>2018年</td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"背景与概述\"><a href=\"#背景与概述\" class=\"headerlink\" title=\"背景与概述\"></a>背景与概述</h1><p>作者的目的是为了发展一种二进制转化方法，改善现有二进制程序转化方法的实用性和通用性。为了表达简洁，也因为x86的程序更少开源。同时之前的许多代码转化方法也以x86程序为目标，作者的方法集中与主流编译器编译的linux 32位x86程序，同时不适用dlopen等动态载入库和自修改代码。</p>\n<h2 id=\"挑战\"><a href=\"#挑战\" class=\"headerlink\" title=\"挑战\"></a>挑战</h2><p>在编写一个通用的二进制程序重写器时存在着许多挑战：</p>\n<p><strong>C1</strong>：识别和重定位静态内存地址 编译后的二进制程序代码包含许多固定地址，很多指向全局变量。代码重写在移动这些目标时，必须同时更新它们的引用。在反汇编代码中和地址段中识别这些地址常量是非常困难的，因为整数值和这些地址常量在语法上并没有明显的区别。</p>\n<p><strong>C2</strong>：处理动态计算的内存地址<br>在程序中还存在许多动态计算的内存地址。由于地址计算方式比较复杂，生成间接控制流转换表(iCFT)非常困难。重映射iCFT对于二进制程序重写是一个核心挑战。</p>\n<p><strong>C3</strong>：区分代码和数据<br>代码和数据在二进制文件中没有语法上的区别，在现代处理器中，为了优化性能，许多数据被放在代码段中。这给反汇编带来一些困难。</p>\n<p><strong>C4</strong>：作为参数的函数指针<br>作为函数指针的参数如果在目标函数中没有正确识别并且更新到改写后的地址，那么重写后的程序在执行时很可能会调用已经被之前的函数地址，令执行失败。同时，识别函数地址也非常困难。</p>\n<p><strong>C5</strong>：处理位置无关代码<br>主流编译器生成了许多位置无关代码。这些代码会根据自身地址和相对位置寻找其他的执行代码。如果改变了它们的相对位置，那么在执行时就有可能失败。</p>\n<h2 id=\"核心想法\"><a href=\"#核心想法\" class=\"headerlink\" title=\"核心想法\"></a>核心想法</h2><p>基于之前的二进制重写方法，作者系统化了下面的这些想法来针对性地解决上面的挑战</p>\n<p><strong>S1</strong>：保持原有数据空间的完好无损<br>保持程序中数据段原有的位置和内容，这个方法之前也被用在许多二进制重写器中，例如SECONDWRITE和BINCFI</p>\n<p><strong>S2</strong>：创建一个从原有代码空间到新的重写代码空间的映射<br>作者在这个映射中忽略常用的地址计算中 基址+偏移 的方法，只考虑最后获得的最终地址，并将这个地址与重写后的代码地址进行对应。作者对于原有地址空间中的每个代码段地址都找到了一个映射，这样就简单的解决了动态计算的内存地址问题。</p>\n<p><strong>S3</strong>：暴力反汇编所有可能的代码<br>为了解决反汇编可能存在缺失的问题，作者对于从代码段开始的每个偏移，都进行了反汇编直到遇上非法指令，或者已经反汇编过的地址。原程序中执行的所有代码必定是暴力反汇编获得的代码的子集。</p>\n<p><strong>S4</strong>：重写所有用户级别的代码<br>通过重写所有用户级别的代码，可以在函数指针被调用处利用原程序与重写程序之间的地址映射，将指向原程序地址空间的函数指针映射到重写后的地址空间。</p>\n<p><strong>S5</strong>：重写所有call指令以解决pic代码 在查看了x86指令集后，所有的pic代码计算方式在32位x86指令集中，都使用call指令来获得当前地址，作者改写了所有call指令，令其push一个未重写时的地址在栈上，被利用于计算地址时，即可以获得原有计算应得的地址，再由iCFT进行统一处理。</p>\n<h2 id=\"系统Overview\"><a href=\"#系统Overview\" class=\"headerlink\" title=\"系统Overview\"></a>系统Overview</h2><p>基于上面的想法，作者实现了<code>multiverse</code>，正如下面的图片中显示，<code>multiverse</code>系统包含两个分开的步骤，映射和重写：</p>\n<p><img src=\"/2019/01/27/Superset-Disassembly-Statically-Rewriting-X86-Binaries-Without-Heuristics-Disassembly/1.png\" alt=\"图片1\"></p>\n<p>在映射阶段，superset disassembler是用下面所示的算法对代码段开始的每个offset进行反汇编，删除重复的代码并在尾部设置一个跳转指令。可以注意的是，在反汇编中，作者删除了从非法指令向前到最后一条控制转移指令的代码内容：</p>\n<p><img src=\"/2019/01/27/Superset-Disassembly-Statically-Rewriting-X86-Binaries-Without-Heuristics-Disassembly/2.png\" alt=\"图2\"></p>\n<p><code>multiverse</code>修改了反汇编获得的代码中占位符长度过短的jcc，jmp指令，因为它们原来的指令很可能长度不够填充新的跳转地址。在这之后，即可以确定所有重写后的指令长度和位置，此时所有的跳转指令依旧包含着占位符地址。</p>\n<p>在重写阶段，<code>multiverse</code>根据重写后的地址位置和原程序地址创建一个本地代码的映射表。映射表的键值是原程序中的内存地址，值则对应着新的代码空间中的地址。 对于重写程序中的直接跳转，<code>multiverse</code>根据映射表将其修改为新的地址。 对于间接跳转，<code>multiverse</code>将其中转到一个搜索映射表的函数中。函数的输入，跳转目标处于原程序的代码空间中。这个函数通过对应映射表找到新代码空间中的对应地址，并执行跳转。 对于外部函数或地址的跳转。由于这些地址在本地映射表中对应。如下图所示，映射函数将在全局映射表中寻找它所处的代码文件并在其对应的映射表中寻找对应地址。</p>\n<p><img src=\"/2019/01/27/Superset-Disassembly-Statically-Rewriting-X86-Binaries-Without-Heuristics-Disassembly/3.png\" alt=\"图3\"></p>\n<p>为了处理位置无关代码和函数指针，<code>multiverse</code>对于所有的call和ret指令都进行了修改。 通过这样的方式，重写后的代码可以任意的安排指令和基本块位置。 最终<code>multiverse</code>利用重写后的代码生成一个新的elf文件。</p>\n<h1 id=\"实现\"><a href=\"#实现\" class=\"headerlink\" title=\"实现\"></a>实现</h1><p>作者基于许多python库，包括python-capstone，pyelftools,pwntools实现了<code>multiverse</code>，包含超过3000行python代码和超过150行汇编代码。同时，基于重写所处的Linux环境，作者对于动态加载器和VDSO进行了特殊处理。</p>\n<h1 id=\"测试\"><a href=\"#测试\" class=\"headerlink\" title=\"测试\"></a>测试</h1><p>作者使用了所有的SPECint 2006 benchmark程序，共12个，作为测试程序集。测试的机器使用一台ubuntu 14.04.1 lts，Intel i7-2600 cpu，4GB RAM。</p>\n<h2 id=\"有效性\"><a href=\"#有效性\" class=\"headerlink\" title=\"有效性\"></a>有效性</h2><p>作者执行了<code>multiverse</code>重写后的所有程序，并和未重写的版本进行对应，所有重写后的程序都正确的执行完毕，输出和未重写的版本同样的结果。</p>\n<p>下表描述了重写后的程序的详细信息：</p>\n<p><img src=\"/2019/01/27/Superset-Disassembly-Statically-Rewriting-X86-Binaries-Without-Heuristics-Disassembly/4.png\" alt=\"图4\"></p>\n<p>有趣的是，对于代码段，所有重写后的程序的代码段长度大约都是原程序的4-5倍，这很可能与x86指令的平均长度有关。同时，表中所有的.newtext段长度都没有包括大约4MB的全局映射表大小，对于代码段长度较小的case，例如429.mcf，这导致了较大的size overhead。</p>\n<h2 id=\"开销\"><a href=\"#开销\" class=\"headerlink\" title=\"开销\"></a>开销</h2><p>作者在原来的benchmark程序和重写后的程序上运行了10遍，以对程序重写后的性能进行一个衡量，结果如下表所示：</p>\n<p><img src=\"/2019/01/27/Superset-Disassembly-Statically-Rewriting-X86-Binaries-Without-Heuristics-Disassembly/5.png\" alt=\"图5\"></p>\n<p>对于大部分的测试程序来说，时间overhead不超过100%，平均的性能overhead为60.42%。对于471.omnetpp 和 483.xalancbmk，性能损耗较高，这两个程序使用c++语言编写，对类函数和库函数的频繁调用在重写时带来了大量的性能损耗。</p>\n<p>接着作者比较了不同优化措施对性能带来的影响，例如只不重写外部函数库，或者对回调函数进行特殊处理，对位置无关代码进行特殊处理。结果如下图所示：</p>\n<p><img src=\"/2019/01/27/Superset-Disassembly-Statically-Rewriting-X86-Binaries-Without-Heuristics-Disassembly/6.png\" alt=\"图6\"></p>\n<p>可以发现，通过对位置无关代码进行特殊处理（假设程序只使用get_pc_thunk函数），可以获得巨大的性能提升。</p>\n<p>作者测试了使用<code>multiverse</code>进行插桩带来的性能开销，并和常用的工具pin进行了比较，两者都执行对于指令数统计的插桩。</p>\n<p><img src=\"/2019/01/27/Superset-Disassembly-Statically-Rewriting-X86-Binaries-Without-Heuristics-Disassembly/7.png\" alt=\"图7\"></p>\n<p>在大部分情况下，使用<code>multiverse</code>在程序重写中静态进行插桩带来的性能消耗比使用pin来的低，在以下情况下，由于pin对于插桩内部代码进行分析，使用pin的插桩性能损耗稍微好一些。</p>\n<p>最后，作者测试了使用<code>multiverse</code>作为安全应用工具的性能，作者使用<code>multiverse</code>编写了一个shadow stack，并与用pin编写的工具相比较。使用<code>multiverse</code>编写的具有巨大的性能优势。</p>\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>作者通过使用了superset disassemble和 instruction rewriter两项技术，开发了<code>multiverse</code>系统，提供了一个不依赖启发式分析的二进制软件重写工具，并且通过对比，证明这个工具在安全应用的性能上，和当前主流的二进制插桩框架PIN相比更有优势。</p>\n<hr>\n<p><em>论文翻译内容转载至GoSSIP.</em></p>\n","categories":[{"name":"论文","slug":"论文","permalink":"http://yama0xff.com/categories/论文/"},{"name":"软件分析","slug":"论文/软件分析","permalink":"http://yama0xff.com/categories/论文/软件分析/"}],"tags":[{"name":"2018年","slug":"2018年","permalink":"http://yama0xff.com/tags/2018年/"},{"name":"二进制反汇编","slug":"二进制反汇编","permalink":"http://yama0xff.com/tags/二进制反汇编/"},{"name":"静态重写技术","slug":"静态重写技术","permalink":"http://yama0xff.com/tags/静态重写技术/"},{"name":"NDSS'18","slug":"NDSS-18","permalink":"http://yama0xff.com/tags/NDSS-18/"}]},{"title":"Angora: Efficient Fuzzing by Principled Search","date":"2019-01-25T08:31:20.000Z","path":"2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/","text":"Abstract​ Fuzzing是一种用于查找软件错误的流行技术。然而，最先进的模糊器的性能还有很多不足之处。基于符号执行的模糊器产生高质量输入但运行缓慢，而基于随机变异的模糊器运行速度快但难以产生高质量输入。我们提出了一种新的基于突变的模糊器Angora，它的性能远远超过了最先进的模糊器。Angora的主要目标是通过解决路径约束来增加分支覆盖率而无需符号执行。为了有效地解决路径约束，我们引入了几个关键技术：可扩展的字节级污点跟踪，上下文敏感的分支计数，基于梯度下降的搜索和输入长度探索。在LAVA-M数据集上，Angora发现了几乎所有注入的错误，发现了比我们比较的任何其他模糊器更多的错误，并且发现错误是程序中第二好的模糊器的8倍。Angora还发现了LAVA作者注射但却无法触发的103个错误。我们还在八个流行的，成熟的开源程序上测试了Angora。Angora分别在file，jhead，nm，objdump和size中发现了6,52,29,40和48个新错误。我们测量了Angora的覆盖范围，并评估了其关键技术如何促成其令人印象深刻的性能。 relevant information 作者 Peng Chen, Hao Chen 单位 ShanghaiTech University, University of California, Davis 出处 IEEE S&amp;P’18 原文地址 https://github.com/wtwofire/database/blob/master/papers/fuzzing/2018Angora%20Efficient%20Fuzzing%20by%20Principled%20Search.pdf 源码地址 https://github.com/AngoraFuzzer/Angora 发表时间 2018年 1 简介​ Fuzzing是一种用于查找软件错误的流行技术。基于覆盖的模糊器面临着如何创建输入以探索程序状态的关键挑战。一些模糊器使用符号执行来解决路径约束[5,8]，但符号执行很慢，无法有效地解决许多类型的约束[6]。为了避免这些问题，AFL不使用符号执行或任何重量级程序分析[1]。它对程序进行插桩，以观察哪些输入探索新的程序分支，并将这些输入作为进一步变异的种子。 AFL在程序执行时产生很低的开销，但是它创建的大多数输入都是无效的（即，它们无法探索新的程序状态），因为它盲目地改变输入而不利用程序中的数据流。几个模糊器为AFL添加了启发式算法来解决简单的判断，例如“魔术字节”[25,19]，但它们无法解决其他路径约束。 ​ 我们设计并实现了一个名为Angora的模糊器，它通过解决路径约束而不使用符号执行来探索程序的状态。Angora跟踪未探测的分支并尝试解决这些分支上的路径约束。我们引入了以下技术来有效地解决路径约束。 上下文敏感的分支覆盖。 AFL使用上下文敏感分支覆盖来近似程序状态。我们的经验表明，为分支覆盖添加上下文使Angora能够更普遍地探索程序状态（第3.2节）。 可扩展的字节级污点跟踪。大多数路径约束仅依赖于输入中的几个字节。通过跟踪哪些输入字节流入每个路径约束，Angora只改变这些字节而不是整个输入，因此大大减少了探索空间（第3.3节）。 基于梯度下降搜索。当改变输入以满足路径约束时，Angora避免了符号执行，这是昂贵的并且不能解决许多类型的约束。相反，Angora使用机器学习中流行的梯度下降算法来解决路径约束（第3.4节）。 类型和形状推断。输入中的许多字节共同用作程序中的单个值，例如，在程序中用作32位有符号整数的输入中的四个字节的组。为了允许梯度下降有效搜索，Angora定位上述组并推断其类型（第3.5节）。 输入长度探索。只有当输入的长度超过某个阈值时，程序才可以探索某些状态，但是符号执行和梯度下降都不能告诉模糊器何时增加输入的长度。 Angora检测输入长度何时可能影响路径约束，然后充分增加输入长度（第3.6节）。 ​ Angora大大超过了最先进的模糊器。表1比较了Angora与其他模糊器在LAVA-M数据集上发现的漏洞[9]。Angora在数据集中的每个程序中发现了更多错误。特别是，Angora发现了1541个漏洞，是第二个最好的模糊器Steelix发现的漏洞数量的8倍。此外，Angora发现了LAVA作者注射但却无法触发的103个错误。我们还在八个流行的，成熟的开源程序上测试了Angora。Angora分别在file，jhead，nm，objdump和size中发现了6,52,29,40和48个新错误（表5）。我们测量了Angora的覆盖范围，并评估了其关键技术如何促成其令人印象深刻的性能。 2 背景：AFL​ 模糊测试是一种自动测试技术，用于查找错误。 American Fuzzy Lop（AFL）[1]是一种基于突变的灰盒模糊器。 AFL采用轻量级编译时插桩和遗传算法来自动发现可能触发目标程序中新内部状态的测试用例。作为基于覆盖率的模糊器，AFL生成输入以遍历程序中的不同路径来触发错误。 2.1 分支覆盖范围​ AFL通过一组分支来测量路径。在每次运行期间，AFL计算每个分支执行的次数。它将分支表示为元组（lprev; lcur），其中lprev和lcur分别是条件语句之前和之后的基本块的ID。AFL通过使用轻量级检测获取分支覆盖率信息。在编译时在每个分支点注入插桩。对于每次运行，AFL分配路径跟踪表以计算每个条件语句的每个分支执行的次数。表的索引是分支的散列，h（lprev; lcur），其中h是散列函数。 ​ AFL还在不同的运行中保留全局分支覆盖表。每个条目都包含一个8位向量，用于记录分支在不同运行中执行的次数。该向量b中的每个位表示一个范围：b0,……,b7分别代表范围[1]，[2]，[3]，[4; 7]，[8; 15]，[16; 31]，[32; 127]，[128; ∞）。例如，如果设置了b3，则表示存在执行此分支执行4到7次的运行，包括。 ​ AFL比较路径跟踪表和分支覆盖表，以启发式方式确定新输入是否触发程序的新内部状态。如果发生以下任一情况，输入将触发新的内部状态： 程序执行新分支，即路径跟踪表具有此分支的条目，但分支覆盖表没有此分支的条目。 存在一个分支，其中当前运行中执行的此分支的次数n与先前的任何运行不同。 AFL通过检查表示n的范围的位是否被设置在分支覆盖表中的相应位向量中来近似地确定这一点。 2.2 变异策略​ AFL随机应用以下变异[3]。 位或字节翻转。 尝试设置“有趣”的字节，单字或双字。 将小整数加到或减去字节，单字或双字。 完全随机的单字节集。 块删除，通过覆盖或插入来复制块，或块memset。 在随机位置拼接两个不同的输入文件。 3 设计3.1 概述​ AFL和其他类似的fuzzer使用分支覆盖作为度量。但是，在计算分支覆盖范围时，它们没有考虑调用上下文。我们的经验表明，没有上下文，分支覆盖将无法充分探索程序状态。因此，我们建议使用上下文敏感分支覆盖作为覆盖度量（第3.2节）。 ​ 算法1显示了Angora的两个阶段：插桩和fuzzing循环。在fuzzing循环的每次迭代期间，Angora选择一个未探测的分支并搜索探索该分支的输入。我们介绍了以下关键技术，以有效地找到输入。 对于大多数条件语句，其判断仅受输入中的几个字节的影响，因此改变整个输入将是徒劳的。因此，在探索分支时，Angora会确定哪些输入字节流入相应的判断，并专注于仅改变这些字节（第3.3节）。 确定要改变的输入字节后，Angora需要决定如何改变它们。使用基于随机或启发式的突变不能有效地找到令人满意的值。相反，我们将分支上的路径约束视为输入上黑盒函数的约束，并且我们调整梯度下降算法来解决约束（第3.4节）。 在梯度下降期间，我们在其参数上评估blackbox函数，其中一些参数由多个字节组成。例如，当输入中的四个连续字节总是作为整数流一起用于条件语句时，我们应该将这四个字节视为函数的单个参数而不是四个独立参数。为了实现这一目标，我们需要推断输入中的哪些字节统一用作单个值以及值的类型是什么（第3.5节）。 仅仅改变输入中的字节是不够的。只有在输入超过阈值后才会触发一些错误，但这会在决定输入长度时产生两难。如果输入太短，则可能不会触发某些错误。但如果输入太长，程序可能运行得太慢。大多数模糊器使用临时方法改变输入的长度。相比之下，Angora使用代码检测程序，该代码检测较长输入何时可以探索新分支并确定所需的最小长度（第3.6节）。 ​ 图1显示了fuzzing条件语句的步骤图。图2中的程序演示了这些步骤。 字节级污点跟踪：当使用字节级污点跟踪对第2行的条件语句进行模糊测试时，Angora确定字节1024-1031流入此表达式，因此它仅改变这些字节。 基于梯度下降的搜索算法：Angora需要分别找到在第2行上运行条件语句的两个分支的输入。Angora将条件语句中的表达式视为输入x上的函数f（x），并使用梯度下降来找到两个输入x和x’，使得f（x）&gt; 0且f（x’）≤0。 形状和类型推断：f（x）是向量x上的函数。在梯度下降期间，Angora分别计算f的每个分量的f的偏导数，因此它必须确定每个分量及其类型。在第2行，Angora确定x由两个组件组成，每个组件由输入中的四个字节组成，并具有32位有符号整数类型。 输入长度探索：除非输入至少有1032个字节，否则main不会调用foo。我们不是盲目地尝试更长的输入，而是检测从输入读取的常用函数，并确定更长的输入是否会探索新的状态。例如，如果初始输入短于1024字节，则第12行上的条件语句将执行true分支。 ​ 由于fread的返回值与1024进行比较，因此Angora知道只有至少1024字节长的输入才能探索错误分支。类似地，第16行和第19行的检测指示Angora将输入扩展到至少1032个字节以执行函数foo。 3.2 上下文敏感的分支计数​ 第2节描述了AFL的分支覆盖表。它的设计有几个优点。首先，它节省空间。分支数量与程序大小呈线性关系。其次，使用范围来计算分支执行在关于不同执行计数是否指示了程序新的内部状态提供了良好启发。当执行计数很小（例如，小于4）时，计数的任何变化都是显着的。然而，当执行计数很大（例如，大于32）时，变化必须足够大以被认为是重要的。 ​ 但这种设计有局限性。由于AFL的分支对上下文不敏感，因此它们无法区分不同上下文中同一分支的执行，这可能会忽略程序新的内部状态。图3说明了这个问题。考虑第3行分支的覆盖范围。在第一次运行期间，程序采用输入“10”。当它在第19行调用f（）时，它在第4行执行true分支。之后，当它在第21行调用f（）时，它在第10行执行false分支。由于AFL对分支的定义是上下文不敏感的，它认为两个分支都已执行。之后，当程序采用新输入“01”时，AFL认为此输入不会触发新的内部状态，因为第4行和第10行的分支都在上一次运行中执行。但实际上这个新输入触发了一个新的内部状态，因为当输入[2] == 1时它将导致第6行崩溃。 ​ 我们将上下文合并到分支的定义中。我们将分支定义为元组（lprev, lcur, context），其中l prev和lcur分别是条件语句之前和之后的基本块的ID，context是h（stack）其中h是散列函数，并且stack包含调用堆栈的状态。例如，让图3中的程序首先在输入10上运行。在它从第19行进入f（）之后，它将执行分支（l3; l4; [l19]）。然后，在从第21行进入f（）之后，它将执行分支（l3; l10; [l21]）。相反，当程序在输入“01”上执行时，它将执行分支（l3; l10; [l19]），然后执行（l3; l4; [l21]）。通过将调用上下文合并到分支的定义中，Angora可以检测到第二次运行会触发新的内部状态，这将在改变输入时[2]时导致第6行产生carsh。 ​ 向分支添加上下文会增加独特分支的数量，这在发生深度递归时可能会很明显。我们当前的实现通过选择用于计算调用堆栈的散列的特定函数h来缓解该问题，其中h计算堆栈上所有调用位置的ID的xor。当Angora插桩程序时，它会为每个调用点分配一个随机ID。因此，当函数f递归调用自身时，无论Angora将同一调用站点的ID推送到调用堆栈多少次，h（堆栈）最多输出两个唯一值，在函数f中这最多会使独特分支的数量增加一倍。我们对现实世界程序的评估表明，在结合上下文后，独特分支的数量增加了多达7.21倍（表7），以换取改进代码覆盖的好处（图7）。 3.3 字节级别的污点跟踪​ Angora的目标是创建执行未开发分支的输入。当它尝试执行未探测的分支时，它必须知道输入中的哪些字节偏移影响分支的谓词。因此，Angora需要字节级别的污点跟踪。然而，污点跟踪是昂贵的，尤其是在单独跟踪每个字节时，因此AFL避免了它。我们的主要观点是，在大多数程序运行中都不需要进行污点跟踪。一旦我们对输入运行了污点跟踪（图1中的步骤1），我们就可以记录哪些字节偏移流入每个条件语句。然后，当我们改变这些字节时，我们可以在没有污点跟踪的情况下运行程序。这通过其许多突变来分摊一个输入上的污点跟踪成本，这使得Angora具有与AFL类似的输入执行吞吐量（第5.6节）。 ​ Angora将程序中的每个变量x与污点标签tx相关联，污点标签tx表示输入中可能流入x的字节偏移量。污点标签的数据结构对其内存占用量有很大影响。一个简单的实现是将每个污点标签表示为位向量，其中每个位i表示输入中的第i个字节。然而，由于该位向量的大小在输入的大小上线性增长，因此该数据结构对于大输入将是禁止的，但是在某些程序中找到错误需要大量输入。 ​ 为了减少污点标签的大小，我们可以将位向量存储在表中，并使用表中的索引作为污点标签。只要表中条目数的对数远小于最长位向量的长度（通常是这种情况），我们就可以大大减小污点标签的大小。 ​ 但是，这种数据结构带来了新的挑战。污点标签必须支持以下操作： INSERT（b）：插入位向量b并返回其标签。 FIND（t）：返回污点标签t的位向量。 UNION（tx; ty）：返回污点标签，表示污点标签tx和ty的位向量的并集。 ​ FIND代价很低，但UNION很高。 UNION采取以下步骤。首先，它找到两个标签的位向量并计算它们的联合u。这一步代价很低。接下来，它搜索表以确定u是否已存在。如果没有，它会增加u。但如何高效搜索？线性搜索会很昂贵。或者，我们可以构建一个位向量的哈希集，但是如果它们中有很多并且每个位向量都很长，那么计算哈希码和存储哈希集的空间就会花费很多时间。由于UNION是我们在算术表达式中跟踪污染数据时的常见操作，因此它必须是高效的。注意，我们不能使用UNION-FIND数据结构，因为矢量不是不相交的，即两个不同的位矢量可能在同一位置具有1。 ​ 我们提出了一种新的数据结构，用于存储位向量,允许有效INSERT，FIND和UNION。对于每个位向量，数据结构使用无符号整数为其分配唯一标签。当程序插入新的位向量时，数据结构会为其分配下一个可用的无符号整数。 ​ 数据结构包含两个组件。 二叉树将位向量映射到其标签。每个位向量b由级别为|b|的唯一树节点vb表示，其中|b|是b的长度。 vb存储b的标签。要从根到达vb，检查b0,b1…顺序。如果bi为0，则转到左边的子节点;否则，去右边的子节点。每个节点都包含一个指向其父节点的后向指针，以允许我们从vb开始检索位向量。 查找表将标签映射到其位向量。标签是该表的索引，相应的条目指向表示该标签的位向量的树节点。 ​ 在该数据结构中，树中的所有叶子表示位向量，并且没有内部节点表示位向量。但是，树中的许多节点可能是不必要的。例如，如果向量x00 在树中但没有向量x0 [01] 1 [01] 在树中，其中x是任何位序列，那么就不必在节点之后存储任何节点表示x，因为x只有一个是叶子的结点，而这个叶子代表x00 。这里我们使用正则表达式的通用符号，其中x *表示x重复零次或多次，[xy]表示x或y。这个观察允许我们在将一个向量插入树中时修剪向量，如下所示： 删除向量的所有尾随0。 跟踪向量中的位，从第一位到最后一位，遍历树。 如果位为0，请跟随左节点 否则，请跟随右节点。 如果节点不存在，请创建它。 将向量的标签存储在我们访问的最后一个节点中。 ​ 算法2详细描述了这种插入操作。 ​ 算法3和算法4分别描述了FIND和UNION操作。请注意，当我们创建节点时，最初它不包含标签。稍后，如果此节点是我们插入位向量时访问的最后一个节点，我们将位向量的标签存储在此节点中。通过此优化，此树具有以下属性： 每个叶节点都包含一个标签。 内部节点可能包含标签。我们可能会在没有标签的内部节点中存储标签，但我们永远不会在任何内部节点中替换标签。 ​ 该数据结构极大地减少了用于存储位向量的存储器占用。设每个位向量的长度为n，并设有l个位向量。如果我们天真地将所有位向量存储在查找表中，则需要O（nl）空间。但是，在我们的数据结构中，树中的节点数是O（l）。每个节点可以存储最多一个索引到查找表。由于查找表具有l个条目并且每个条目是指针并且因此具有固定大小，因此查找表的大小是O（l），并且查找表的每个索引具有O（log 1）位。因此，总空间要求为O（l·log l）。 3.4 基于梯度下降的搜索算法​ 字节级污点跟踪发现输入流中的哪些字节偏移成为条件语句。但是如何改变输入以运行未探索的分支语句？大多数模糊测试者随机地或使用粗略的启发式方法改变输入，但这些策略不太可能快速找到合适的输入值。相比之下，我们将此视为搜索问题，并利用机器学习中的搜索算法。我们在实现中使用了梯度下降，但其他搜索算法也可能有效。 ​ 在这种方法中，我们将用于执行分支断定看作黑盒函数f（x）的约束，其中x是输入中流入判断的值的向量，并且f（）捕获计算在从程序开始到此判断的路径。 f（x）有三种类型的约束： f（x）&lt;0。 f（x）&lt;= 0。 f（x）== 0。 ​ 表2显示我们可以将所有形式的比较转换为上述三种类型的约束。如果条件语句的判断包含逻辑运算符&amp;&amp;或||，则Angora会将语句拆分为多个条件语句。例如，它将（a &amp;&amp; b）{s} else {t}拆分为if（a）{if（b）{s} else {t}} else {t}。 ​ 算法5显示了搜索算法。从初始x0开始，找到x使得f（x）满足约束。请注意，为了满足每种类型的约束，我们需要最小化f（x），并且我们使用梯度下降来实现此目的。 ​ 梯度下降找到函数f（x）的最小值。该方法是迭代的。每次迭代都从x开始，计算∇xf（x）（x处的f（x）的梯度），并将x更新为x-ε∇xf（x），其中ε是学习率。 ​ 在训练神经网络时，研究人员使用梯度下降来找到一组最小化训练误差的权重。然而，梯度下降的问题在于它有时可能会陷入局部最小值，而不是全局最小值。幸运的是，这在模糊测试中通常不是问题，因为我们只需要找到足够好的输入x而不是全局最优x。例如，如果约束是f（x）&lt;0，那么我们只需要找到一个x，其中f（x）&lt;0而不是f（x）是全局最小值。 然而，当将梯度下降应用于模糊时，我们面临着独特的挑战。梯度下降需要计算梯度∇xf（x）。在神经网络中，我们可以用分析形式编写∇xf（x）。然而，在模糊测试中，我们没有f（x）的分析形式。其次，在神经网络中，f（x）是连续函数，因为x包含网络的权重，但在模糊中f（x）通常是离散函数。这是因为典型程序中的大多数变量都是离散的，因此x中的大多数元素都是离散的。 ​ 我们使用数值近似解决了这些问题。 f（x）的梯度是唯一的矢量场，其每个点x处的任意单位矢量v的点积是f沿v的方向导数。我们用δf(x) /δ（xi）= f（x+δv i）-f（x））/δ逼近每个方向导数其中δ是小的正值（例如，1），vi是第i维的单位矢量。为了计算每个方向导数，我们需要运行程序两次，一次使用原始输入x，一次使用扰动输入x + δvi。在第二次运行中，程序可能无法到达计算f（x +δvi）的程序点，因为程序在较早的条件语句中采用了不同的分支。当发生这种情况时，我们将δ设置为小的负值（例如，-1）并尝试再次计算f（x +δvi）。如果成功，我们会根据它计算方向导数。否则，我们将导数设置为零，指示梯度下降不要在此方向上移动x。计算梯度的时间与矢量x的长度成比例，因为Angora分别计算每个方向导数。第3.5节将描述如何通过合并在程序中用作单个值的连续字节来减少x的长度。 ​ 理论上，梯度下降可以解决任何约束。实际上，梯度下降可以解决约束的速度取决于数学函数的复杂性。 如果f（x）是单调的或凸的，那么即使f（x）具有复杂的分析形式，梯度下降也可以快速找到解。例如，考虑约束f（x）&lt;0，其中f（x）使用一些多项式系列近似log（x）。由于复杂的分析形式，符号执行很难解决这种约束。但是，梯度很容易解决，因为f（x）是单调的。 如果梯度下降的局部最小值满足约束，则查找解决方案也很快。 如果局部最小值不满足约束条件，则Angora必须随机走到另一个值x并从那里开始递减渐变，希望找到满足约束的另一个局部最小值。 ​ 请注意，Angora不会生成f（x）的分析形式，而是运行程序来计算f（x）。 3.5形状和类型推断​ 天真地，我们可以让输入中的x中的每个元素成一个字节流入到判断处。但是，由于类型不匹配，这会导致梯度下降问题。例如，让程序将输入中的四个连续字节b3b2b1b0视为整数，并让xi表示该整数值。当计算f（x +δvi）时，我们应该将δ加到这个整数。但是如果我们天真地将每个字节b3，b2，b1，b0分配给x中的不同元素，那么我们将在每个字节上计算f（x +δvi），但这是不合适的。 ​ 程序将这些字节组合为单个值并仅使用表达式中的组合值，因此当我们向除最低有效字节之外的任何字节添加小的δ时，我们将显着更改此组合值，这将导致计算的偏导数是一个不正确的真实值的近似。 ​ 为了避免这个问题，我们必须确定（1）输入中的哪些字节总是一起用作程序中的单个值，以及（2）值的类型是什么。我们称第一个问题为形状推理，第二个问题类型推断，并在动态污点分析过程中解决它们。 ​ 对于形状推断，最初输入中的所有字节都是独立的。在污点分析期间，当指令将输入字节序列读入变量，其中序列的大小与基本类型的大小匹配（例如，1,2,4,8字节）时，Angora将这些字节标记为属于相同的值。当冲突发生时，Angora使用最小的尺寸。对于类型推断，Angora依赖于对值进行操作的指令的语义。例如，如果指令对有符号整数进行操作，则Angora将相应的操作数推断为有符号整数。当相同的值同时用作有符号和无符号类型时，Angora将其视为无符号类型。请注意，当Angora无法推断出值的精确大小和类型时，这并不能防止梯度下降找到解决方案 - 搜索只需要更长的时间。 3.6 输入长度探索​ 与大多数其他模糊器一样，Angora开始使用尽可能小的输入进行模糊测试。但是，仅当输入长于阈值时才执行某些分支。这给模糊器带来了两难境地。如果模糊器使用太短的输入，则无法探索这些分支。但如果它使用太长的输入，程序可能运行缓慢甚至内存不足。大多数工具使用临时方法尝试不同长度的输入。相比之下，Angora只有在这样做才能探索新的分支时才会增加输入长度。 ​ 在污点跟踪期间，Angora将类似read的函数调用中的目标内存与输入中的相应字节偏移相关联。它还使用特殊标签标记来自读取调用的返回值。如果在条件语句中使用返回值并且不满足约束，则Angora会增加输入长度，以便读取调用可以获取它请求的所有字节。例如，在图2中，如果第12行的条件语句为false，则Angora会扩展输入长度，以便fread可以读取它请求的所有1024个字节。我们的标准并非详尽无遗，因为程序可以消耗输入并以我们未预料到的方式检查其长度，但是一旦我们发现它们就很容易将这些标准添加到Angora。 4 实现4.1 插桩​ 对于每个要模糊的程序，Angora通过使用LLVM Pass [18]检测程序来生成相应的可执行文件。 插桩收集条件语句的基本信息，并通过污点分析将条件语句链接到其对应的输入字节偏移。在每个输入上，Angora只运行此步骤一次（而不是在改变此输入时）。 记录执行跟踪以识别新输入。 在运行时支持上下文（第3.2节）。 在判定中收集表达式值（第3.4节）。 ​ 为了支持3.3节中描述的可扩展字节级污点跟踪，我们通过扩展DataFlowSanitizer（DFSan）[21]为Angora实现了污点跟踪。我们为FIND和UNION操作实现了缓存设施，显着加快了污点跟踪。 ​ Angora依赖于LLVM 4.0.0（包括DFSan）。它的LLVM pass包含820行C ++代码，不包括DFSan，运行时有1950行C ++代码，包括用于存储污点标签的数据结构以及用于污染输入和跟踪条件语句的钩子。 ​ 除了具有两个分支的if语句之外，LLVM IR还支持switch语句，这可能会引入多个分支。在我们的实现中，为方便起见，Angora将每个switch语句转换为if语句序列。 ​ Angora识别libc函数，用于在条件语句中出现时比较字符串和数组。 ​ 例如，Angora将“strcmp（x，y）”转换为“x strcmp y”，其中strcmp是Angora理解的特殊比较运算符。 4.2 Fuzzer​ 我们以4488行Rust代码中实现了Angora。我们使用fork server [30]和CPU绑定等技术优化了Angora。 5 评估​ 我们分三个步骤评估了Angora。首先，我们将Angora的性能与其他最先进的模糊器进行了比较。然后，我们测量了Angora的测试覆盖率及其在现实世界程序中发现未知错误的能力。最后，我们评估了它的关键新颖特征。 ​ 我们在64位Ubuntu 16.04 LTS的Intel Xeon E5-2630 v3和256 GB内存的服务器上运行了所有实验。尽管Angora可以同时对多个内核上的程序进行模糊处理，但我们将其配置为在评估期间仅在一个内核上模糊该程序，以将其性能与其他模糊器进行比较。我们对每个实验进行了五次运行并报告了平均性能。 5.1 Angora与其他模糊器进行比较​ 比较模糊器的最终指标是它们发现错误的能力。一个好的测试集应该包含具有实际错误的真实程序。 LAVA是一种通过在程序源代码中注入大量实际错误来生成真实语料库的技术[9]。作者通过在每个程序中注入多个错误来创建语料库 LAVA-M。 LAVA-M由四个GNU coreutils程序组成：uniq，base64，md5sum和who。每个注入的bug都有一个唯一的ID，在触发bug时会打印出来。 ​ 我们将Angora与以下最先进的模糊器进行了比较： FUZZER（基于覆盖的模糊器）和SES（符号执行和SAT求解）。 LAVA的作者将它们都运行了5个小时[9]。 VUzzer：使用“魔术字节”策略的模糊器[25]。它的作者报告了LAVA-M程序中发现的错误数量，但没有报告运行时间。 Steelix：一个模糊器在LAVAM上表现优于VUzzer [19]。作者通过运行模糊器5小时报告了LAVA-M程序中发现的错误数量。[11] AFL 2.51b：撰写本文时的最新版AFL。我们运行AFL五个小时，我们为AFL提供了一个CPU核心，用于对每个程序进行模糊测试。 Angora：我们使用与AFL相同的设置（每个程序一个CPU核心）。 ​ 表1比较了所有模糊器发现的错误。AFL表现最差，在所有程序中总共发现了10个错误。 VUzzer的作者无法在md5sum上运行它，因为LAVA作者错误地修改了md5sum，导致它在所有输入上崩溃。我们向LAVA作者证实了这个问题并修复了它。 Steelix是第二个最好的模糊器，它发现了base64中几乎所有的错误，但是在uniq中28个中只有7个注入了错误，57个md5sum注入了错误中的28个，2136个中有194个注入了错误。Angora大大超过了Steelix，发现了uniq，base64和md5sum中的所有错误，并且2136中的1443个注入了错误。 ​ LAVA为每个注入的bug分配一个唯一的ID，该ID在触发错误时打印。文件验证的错误列出了LAVA作者在创建LAVA时能够触发的所有注入错误。Angora不仅发现了uniq，base64，md5sum中列出的所有错误以及大多数列出的错误，还列出了103个未列出的错误（LAVA作者注入但无法触发的错误）。表3显示了这些未列出的错误的ID。表4显示了Angora发现的列出和未列出的错误的细分。 ​ 图4显示了Angora在who中随着时间的推移发现的错误累积数量。我们没有显示其他模糊器的结果，因为他们发现who没有错误。图4显示，最初Angora很快发现了错误，在不到五分钟内发现了1000个错误。然后发现速度减慢，但在总共2136个列出的错误中，它仅在45分钟内发现超过1500个错误。 ​ 我们接下来解释为什么Angora发现了比下一个最好的模糊器更多的错误。首先，LAVA使用“魔术字节”来保护包含错误的分支，但是一些魔术字节不是直接从输入复制而是从输入计算。由于VUzzer和Steelix的“魔术字节”策略只能将魔术字节直接复制到输入，因此该策略无法创建探索这些分支的输入。相比之下，Angora跟踪流入判定的输入字节偏移，然后通过梯度下降而不是假设“魔术字节”或输入与判定之间的任何其他特殊关系来改变这些偏移，因此Angora可以找到探索这些的输入分支机构。其次，VUzzer盲目地尝试“魔术字节”策略，一旦魔术字节中的一个与随机突变后的输入中的字节匹配，Steelix就会关注“魔术字节”策略。相比之下，Angora安排其所有计算能力来解决未探测分支上的路径约束，因此它可以覆盖更多分支，因此可以快速找到LAVA-M中的大部分注入错误。 5.2 在未修改的真实程序中评估Angora​ Angora在LAVA上的表现令人印象深刻，不仅发现了大部分列出的错误，还发现了许多未列出的错误。然而，它的怀疑论者可能会争辩说这些bug是人为注入的。为了解决这个问题，我们使用最新版本评估了八个流行的开源程序。由于这些成熟的，受欢迎的程序已经过广泛测试，我们预计它们几乎没有残留物崩溃的错误。因此，除了测量发现的新错误的数量外，我们还测量了Angora对这些程序的报道。我们使用了gcov，它记录了输入中程序中执行的所有行和分支[14]。我们将由Angora生成的每个输入馈送到用gcov编译的程序以获得累积代码覆盖率，并且afl-cov3允许我们自动执行此操作。我们还在这些程序上运行AFL进行比较。表5显示了使用一个CPU内核运行Angora和AFL五小时后的结果。我们通过AFL的afl-cmin -C命令重复删除了崩溃。 ​ 表5显示Angora在线路覆盖范围，分支覆盖范围以及每个程序发现崩溃时表现优于AFL。在文件，jhead，nm，objdump和大小中，AFL发现了0,19,12,4,6个独特的崩溃，而Angora分别发现了6,52,29,40和48个独特的崩溃。对比度在jhead最为突出，Angora的线路覆盖率提高了127.4％，分支覆盖率提高了144.0％。 ​ 图5比较了Angora和AFL随时间的累积线和分支覆盖率。它表明Angora在任何时候都覆盖了比AFL更多的线和分支。Angora优越覆盖的原因在于它可以探索复杂条件语句的两个分支。例如，图6显示了文件中的这样一个语句，其中Angora成功地探索了两个分支，但AFL无法探索真正的分支。在接下来的部分中，我们将评估Angora的每个关键特性如何有助于其卓越的性能。 5.3上下文相关的分支计数 ​ 5.3.1 性能。 3.2节介绍了上下文相关分支计数。我们相信在不同的函数调用上下文中区分相同的分支会发现更多的错误。为了评估这个假设，我们分别使用上下文相关的分支计数和上下文不相关的分支计数来运行Angora。表6显示Angora发现6个错误具有上下文相关的分支计数，但在上下文不相关中它没有错误。图7显示从30分钟开始到模糊测试，Angora始终覆盖更多具有上下文相关分支计数的累积行。我们发现了几个真实世界的例子，其中上下文相关的分支计数允许Angora探索更多路径。例如，图8显示了程序文件中readelf.c文件中的代码片段。函数getu32在多个上下文中调用，它根据swap参数返回不同的结果。如果没有上下文相关的分支计数，Angora将无法在所有调用上下文中探索条件语句的两个分支。 ​ 5.3.2 哈希碰撞。与AFL类似，Angora将分支计数存储在哈希表中。当Angora在计算分支覆盖率时合并调用上下文时，它会在哈希表中插入更多的唯一分支，因此我们必须增加哈希表的大小以保持较低的冲突率。 ​ 我们评估了5.2节中描述的真实世界程序中有多少独特的分支上下文相关性。 AFL的作者观察到，唯一分支（没有上下文）的数量通常在2k到10k之间，而具有216个bucket的哈希表应该足以满足常见情况[30]。表7显示合并上下文相关度将唯一分支的数量增加了至多8倍，这要求我们将散列表的大小增加8倍以具有相同的预期散列冲突率。默认情况下，Angora在其哈希表中分配220个bucket，这是AFL中哈希表的16倍，对大多数程序来说应该足够了。虽然在不再适合缓存时增加哈希表可能是有害的，但不像AFL那样遍历哈希表以查找新路径并优先处理覆盖许多基本块的输入，对于每个输入，Angora只遍历哈希表一次找到新的路径。因此，Angora受哈希表大小增长的影响较小，如第5.6节中的执行速度所示。 5.4 基于梯度下降的搜索第3.4节描述了如何使用梯度下降来解决条件语句中的约束。我们将梯度下降与另外两种策略进行了比较：随机变异，VUzzer的魔术字节加随机变异。为了排除测量中的其他变量，我们确保三种策略接收相同的输入：我们收集了AFL在5.2节中生成的输入，并将它们作为模糊的唯一输入提供给Angora。我们分别使用上述三种策略运行Angora两小时。 ​ 表8显示梯度下降解决了比所有程序中的其他两个策略更多的约束。如第5.1节的最后一段所述，“魔术字节”策略无法解决其值未直接从输入复制的约束。例如，图6中的变量descsz用于程序中的许多约束，但它不是直接从输入复制的，因此“魔术字节”策略没有帮助。 5.5 输入长度探测​ 第3.6节描述了当Angora观察到路径约束可能取决于长度时，按需增加输入的长度，而AFL和相关的模糊器随机增加输入长度。我们基于两个标准比较了这两种策略： 策略增加输入长度的次数是多少？在这个战略创造的投入中，有多少是有用的？如果输入直接或在某些突变后探索新分支，则输入有用。 这些有用输入的平均长度是多少？ ​ 我们分别用我们提出的策略和随机策略运行Angora五小时。表9显示Angora的策略将输入长度增加了大约两个数量级，比随机策略少了几个数量级，但它在所有情况下都发现了更有用的输入，除了两个：在readpng它发现总共46个中有用输入少3个，并且在jhead上，既没有策略发现任何有用的输入，因为jhead只解析图像的标题，因此不受图像数据长度的影响。表9还显示，虽然Angora的策略产生了更多有用的输入，但它在每个测试程序上平均产生较短的输入。较短的输入使许多程序运行得更快。该评估表明，Angora的战略比随机战略产生更高质量的投入。 5.6 执行速度 Angora的污染追踪代价很高。然而，Angora为每个输入运行一次污染跟踪，然后改变输入并多次运行程序而没有污点跟踪，因此一次性成本是摊销的。由于分支计数主导了没有污点跟踪的插桩代码的运行时间，因此Angora插桩程序的运行速度与其AFL插桩版本的运行速度大致相同。表10显示AFL以比Angora略高的速率执行输入。然而，由于Angora产生更高质量的输入，更有可能探索新的分支，Angora有更好的覆盖范围，并发现明显更多的错误，如前所示。 6 相关工作6.1种子输入优先级​ 基于突变的fuzzer的一个重要优化是明智地选择种子输入。雷伯特等人[26]制定并推理了种子选择调度问题。他们基于PeachFuzzer设计并评估了六种不同的种子选择算法[23]。算法使用不同的特征来最小化种子输入集，例如执行时间和文件大小。结果表明，种子选择算法采用的启发式方法比完全随机抽样方法表现更好。 AFLFast [4]观察到大多数模糊测试都使用了相同的几条“高频”路径。他们使用马尔可夫链来识别“低频”路径。 AFLFast优先考虑包含此类路径的输入。VUzzer [25]使用控制流功能来建模路径，以优先考虑路径难以到达的输入。此外，VUzzer检测到错误处理基本块，并优先考虑不包含这些基本块的有效输入。相比之下，Angora选择其路径包含具有未探索分支的条件语句的输入。这是一种更为通用的策略，在探索高频路径后，它会自动指示Angora专注于低频路径。 6.2 基于污点的模糊测试​ 污点跟踪有很多用途，例如分析恶意软件行为[24]，检测和防止信息泄漏[10,29]和调试软件[22,12]。它也可以用于模糊测试。基于污点的模糊器分析应用程序如何处理输入以确定应修改输入的哪个部分。其中一些模糊器[13,2,17]旨在将输入文件中安全敏感代码中使用的值定位，然后对输入文件的这些部分进行模糊处理以触发崩溃。例如，BuzzFuzz [13]使用污点定位来查找哪些输入字节由他们定义的“攻击点”处理。 Dowser [17]认为可能导致缓冲区溢出的代码是安全敏感代码。换句话说，这些模糊器旨在利用可到达路径中的错误。Woo等人。提到了在探索与利用之间的权衡[32]。Angora可以结合这些技术来开发探索的路径。 Taintscope [31]使用污点分析来推断校验和处理代码，并通过控制流程更改绕过这些检查，因为通过改变输入很难满足这些检查。 ​ VUzzer [25]是一个应用程序感知模糊器，它使用污点分析来定位输入文件中“魔术字节”的位置，然后将这些魔术字节分配给输入中的固定位置。 VUzzer只有在连续出现在输入中时才能找到魔术字节。 Steelix [19]通过学习魔术字节位于输入中的程序状态以及如何有效地改变输入以匹配魔术字节来改进VUzzer。相比之下，Angora应用字节级污点跟踪来获取流入每个条件语句的输入中的字节偏移，然后改变这些字节以满足未探测分支的条件，因此Angora可以有效地找到更多类型的值。魔术字节，例如，非连续魔术字节或魔术字节，不是直接从输入复制而是从输入计算。此外，VUzzer使用压缩的位设置数据结构来表示污点标签，其中每个位对应于输入中的唯一字节偏移。因此，对于具有复杂输入字节偏移模式的值，污点标签的大小很大，因为它们无法有效压缩。相比之下，Angora将字节偏移存储在树中，并将索引作为污染标签用于树中，因此无论标签中有多少输入字节偏移，污点标签的大小都是常量。例如，当几个值的污点标签具有相同的字节偏移时，VUzzer会在每个污点标签中重复存储这些字节偏移，但Angora只在树中存储这些字节偏移一次，从而大大减少了内存消耗。 ​ Angora有效表示污点标签的数据结构类似于简化有序二元决策图（roBDD）。 roBDD用于表示动态切片[33]和数据谱系[20]，但据我们所知，Angora是第一个使用这种想法有效地表示污点标签的。 6.3 符号辅助模糊测试​ 动态符号执行为目标应用程序提供了高度语义洞察力。由于这些技术知道如何触发所需的程序状态，因此它们可用于直接查找程序中的漏洞。符号执行实现的经典方法以最大化代码覆盖率以查找崩溃[5,8]。但路径爆炸和约束求解的挑战使符号执行难以扩展[6,27]。一些工具试图通过将其与模糊测试[15,16,7,28]相结合来缓解这一障碍。 DART [15]和SAGE [16]使用动态符号执行引擎来修改模糊测试中的输入。 SYMFUZZ [7]利用对执行跟踪的符号分析来检测输入中位置之间的依赖关系，然后使用此依赖关系来计算最佳突变率以指导模糊测试。 Driller [28]只有在AFL模糊不清时才使用动态符号执行。但是，它们都继承了符号执行的可伸缩性问题。相比之下，Angora不使用符号执行，并且可以有效地在大型程序上找到许多错误。 7 结论​ 我们设计并实现了Angora，这是一种强大的基于突变的模糊器，可以产生高质量的输入，这得益于以下关键技术：可扩展的字节级污点跟踪，上下文敏感的分支计数，基于梯度下降的搜索算法，形状和类型推断和输入长度探索。Angora在很大程度上超越了其他最先进的模糊器。它发现了比LAVA-M上的其他模糊器明显更多的错误，发现了当他们准备数据集时LAVA作者无法触发的103个错误，以及8个流行的，成熟的开源程序中总共175个新错误。我们的评估显示，Angora将模糊测试的标准提升到了一个新的水平。","content":"<h1 id=\"Abstract\"><a href=\"#Abstract\" class=\"headerlink\" title=\"Abstract\"></a>Abstract</h1><p>​    Fuzzing是一种用于查找软件错误的流行技术。然而，最先进的模糊器的性能还有很多不足之处。基于符号执行的模糊器产生高质量输入但运行缓慢，而基于随机变异的模糊器运行速度快但难以产生高质量输入。我们提出了一种新的基于突变的模糊器Angora，它的性能远远超过了最先进的模糊器。Angora的主要目标是通过解决路径约束来增加分支覆盖率而无需符号执行。<strong>为了有效地解决路径约束，我们引入了几个关键技术：可扩展的字节级污点跟踪，上下文敏感的分支计数，基于梯度下降的搜索和输入长度探索</strong>。在LAVA-M数据集上，Angora发现了几乎所有注入的错误，发现了比我们比较的任何其他模糊器更多的错误，并且发现错误是程序中第二好的模糊器的8倍。Angora还发现了LAVA作者注射但却无法触发的103个错误。我们还在八个流行的，成熟的开源程序上测试了Angora。Angora分别在file，jhead，nm，objdump和size中发现了6,52,29,40和48个新错误。我们测量了Angora的覆盖范围，并评估了其关键技术如何促成其令人印象深刻的性能。</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">relevant information</th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\"><em>作者</em></td>\n<td>Peng Chen, Hao Chen</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><em>单位</em></td>\n<td>ShanghaiTech University, University of California, Davis</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><em>出处</em></td>\n<td>IEEE S&amp;P’18</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><em>原文地址</em></td>\n<td><a href=\"https://github.com/wtwofire/database/blob/master/papers/fuzzing/2018Angora%20Efficient%20Fuzzing%20by%20Principled%20Search.pdf\" target=\"_blank\" rel=\"noopener\">https://github.com/wtwofire/database/blob/master/papers/fuzzing/2018Angora%20Efficient%20Fuzzing%20by%20Principled%20Search.pdf</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><em>源码地址</em></td>\n<td><a href=\"https://github.com/AngoraFuzzer/Angora\" target=\"_blank\" rel=\"noopener\">https://github.com/AngoraFuzzer/Angora</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><em>发表时间</em></td>\n<td>2018年</td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"1-简介\"><a href=\"#1-简介\" class=\"headerlink\" title=\"1 简介\"></a>1 简介</h1><p>​    Fuzzing是一种用于查找软件错误的流行技术。基于覆盖的模糊器面临着如何创建输入以探索程序状态的关键挑战。一些模糊器使用符号执行来解决路径约束[5,8]，但符号执行很慢，无法有效地解决许多类型的约束[6]。为了避免这些问题，AFL不使用符号执行或任何重量级程序分析[1]。它对程序进行插桩，以观察哪些输入探索新的程序分支，并将这些输入作为进一步变异的种子。 AFL在程序执行时产生很低的开销，但是它创建的大多数输入都是无效的（即，它们无法探索新的程序状态），因为它盲目地改变输入而不利用程序中的数据流。几个模糊器为AFL添加了启发式算法来解决简单的判断，例如“魔术字节”[25,19]，但它们无法解决其他路径约束。</p>\n<p>​    我们设计并实现了一个名为Angora的模糊器，它通过解决路径约束而不使用符号执行来探索程序的状态。Angora跟踪未探测的分支并尝试解决这些分支上的路径约束。我们引入了以下技术来有效地解决路径约束。</p>\n<ul>\n<li><p>上下文敏感的分支覆盖。 AFL使用上下文敏感分支覆盖来近似程序状态。我们的经验表明，为分支覆盖添加上下文使Angora能够更普遍地探索程序状态（第3.2节）。</p>\n</li>\n<li><p>可扩展的字节级污点跟踪。大多数路径约束仅依赖于输入中的几个字节。通过跟踪哪些输入字节流入每个路径约束，Angora只改变这些字节而不是整个输入，因此大大减少了探索空间（第3.3节）。</p>\n</li>\n<li><p>基于梯度下降搜索。当改变输入以满足路径约束时，Angora避免了符号执行，这是昂贵的并且不能解决许多类型的约束。相反，Angora使用机器学习中流行的梯度下降算法来解决路径约束（第3.4节）。</p>\n</li>\n<li><p>类型和形状推断。输入中的许多字节共同用作程序中的单个值，例如，在程序中用作32位有符号整数的输入中的四个字节的组。为了允许梯度下降有效搜索，Angora定位上述组并推断其类型（第3.5节）。</p>\n</li>\n<li><p>输入长度探索。只有当输入的长度超过某个阈值时，程序才可以探索某些状态，但是符号执行和梯度下降都不能告诉模糊器何时增加输入的长度。 Angora检测输入长度何时可能影响路径约束，然后充分增加输入长度（第3.6节）。</p>\n</li>\n</ul>\n<p>​        Angora大大超过了最先进的模糊器。表1比较了Angora与其他模糊器在LAVA-M数据集上发现的漏洞[9]。Angora在数据集中的每个程序中发现了更多错误。特别是，Angora发现了1541个漏洞，是第二个最好的模糊器Steelix发现的漏洞数量的8倍。此外，Angora发现了LAVA作者注射但却无法触发的103个错误。我们还在八个流行的，成熟的开源程序上测试了Angora。Angora分别在file，jhead，nm，objdump和size中发现了6,52,29,40和48个新错误（表5）。我们测量了Angora的覆盖范围，并评估了其关键技术如何促成其令人印象深刻的性能。</p>\n<p><img src=\"/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/p1.png\" alt=\"p1\"></p>\n<h1 id=\"2-背景：AFL\"><a href=\"#2-背景：AFL\" class=\"headerlink\" title=\"2 背景：AFL\"></a>2 背景：AFL</h1><p>​    模糊测试是一种自动测试技术，用于查找错误。 American Fuzzy Lop（AFL）[1]是一种基于突变的灰盒模糊器。 AFL采用轻量级编译时插桩和遗传算法来自动发现可能触发目标程序中新内部状态的测试用例。作为基于覆盖率的模糊器，AFL生成输入以遍历程序中的不同路径来触发错误。</p>\n<h2 id=\"2-1-分支覆盖范围\"><a href=\"#2-1-分支覆盖范围\" class=\"headerlink\" title=\"2.1 分支覆盖范围\"></a>2.1 分支覆盖范围</h2><p>​    AFL通过一组分支来测量路径。在每次运行期间，AFL计算每个分支执行的次数。它将分支表示为元组（lprev; lcur），其中lprev和lcur分别是条件语句之前和之后的基本块的ID。AFL通过使用轻量级检测获取分支覆盖率信息。在编译时在每个分支点注入插桩。对于每次运行，AFL分配路径跟踪表以计算每个条件语句的每个分支执行的次数。表的索引是分支的散列，h（lprev; lcur），其中h是散列函数。</p>\n<p>​    AFL还在不同的运行中保留全局分支覆盖表。每个条目都包含一个8位向量，用于记录分支在不同运行中执行的次数。该向量b中的每个位表示一个范围：b0,……,b7分别代表范围[1]，[2]，[3]，[4; 7]，[8; 15]，[16; 31]，[32; 127]，[128; ∞）。例如，如果设置了b3，则表示存在执行此分支执行4到7次的运行，包括。</p>\n<p>​    AFL比较路径跟踪表和分支覆盖表，以启发式方式确定新输入是否触发程序的新内部状态。如果发生以下任一情况，输入将触发新的内部状态：</p>\n<ul>\n<li><p>程序执行新分支，即路径跟踪表具有此分支的条目，但分支覆盖表没有此分支的条目。</p>\n</li>\n<li><p>存在一个分支，其中当前运行中执行的此分支的次数n与先前的任何运行不同。 AFL通过检查表示n的范围的位是否被设置在分支覆盖表中的相应位向量中来近似地确定这一点。</p>\n</li>\n</ul>\n<h2 id=\"2-2-变异策略\"><a href=\"#2-2-变异策略\" class=\"headerlink\" title=\"2.2 变异策略\"></a>2.2 变异策略</h2><p>​    AFL随机应用以下变异[3]。</p>\n<ul>\n<li><p>位或字节翻转。</p>\n</li>\n<li><p>尝试设置“有趣”的字节，单字或双字。</p>\n</li>\n<li><p>将小整数加到或减去字节，单字或双字。</p>\n</li>\n<li><p>完全随机的单字节集。</p>\n</li>\n<li><p>块删除，通过覆盖或插入来复制块，或块memset。</p>\n</li>\n<li><p>在随机位置拼接两个不同的输入文件。</p>\n</li>\n</ul>\n<h1 id=\"3-设计\"><a href=\"#3-设计\" class=\"headerlink\" title=\"3 设计\"></a>3 设计</h1><h2 id=\"3-1-概述\"><a href=\"#3-1-概述\" class=\"headerlink\" title=\"3.1 概述\"></a>3.1 概述</h2><p>​    AFL和其他类似的fuzzer使用分支覆盖作为度量。但是，在计算分支覆盖范围时，它们没有考虑调用上下文。我们的经验表明，没有上下文，分支覆盖将无法充分探索程序状态。因此，我们建议使用上下文敏感分支覆盖作为覆盖度量（第3.2节）。</p>\n<p>​    算法1显示了Angora的两个阶段：插桩和fuzzing循环。在fuzzing循环的每次迭代期间，Angora选择一个未探测的分支并搜索探索该分支的输入。我们介绍了以下关键技术，以有效地找到输入。</p>\n<ul>\n<li><p>对于大多数条件语句，其判断仅受输入中的几个字节的影响，因此改变整个输入将是徒劳的。因此，在探索分支时，Angora会确定哪些输入字节流入相应的判断，并专注于仅改变这些字节（第3.3节）。</p>\n</li>\n<li><p>确定要改变的输入字节后，Angora需要决定如何改变它们。使用基于随机或启发式的突变不能有效地找到令人满意的值。相反，我们将分支上的路径约束视为输入上黑盒函数的约束，并且我们调整梯度下降算法来解决约束（第3.4节）。</p>\n</li>\n<li><p>在梯度下降期间，我们在其参数上评估blackbox函数，其中一些参数由多个字节组成。例如，当输入中的四个连续字节总是作为整数流一起用于条件语句时，我们应该将这四个字节视为函数的单个参数而不是四个独立参数。为了实现这一目标，我们需要推断输入中的哪些字节统一用作单个值以及值的类型是什么（第3.5节）。</p>\n</li>\n<li><p>仅仅改变输入中的字节是不够的。只有在输入超过阈值后才会触发一些错误，但这会在决定输入长度时产生两难。如果输入太短，则可能不会触发某些错误。但如果输入太长，程序可能运行得太慢。大多数模糊器使用临时方法改变输入的长度。相比之下，Angora使用代码检测程序，该代码检测较长输入何时可以探索新分支并确定所需的最小长度（第3.6节）。</p>\n</li>\n</ul>\n<p><img src=\"/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/图2.png\" alt=\"图2\"></p>\n<p>​    图1显示了fuzzing条件语句的步骤图。图2中的程序演示了这些步骤。</p>\n<ul>\n<li><p>字节级污点跟踪：当使用字节级污点跟踪对第2行的条件语句进行模糊测试时，Angora确定字节1024-1031流入此表达式，因此它仅改变这些字节。</p>\n</li>\n<li><p>基于梯度下降的搜索算法：Angora需要分别找到在第2行上运行条件语句的两个分支的输入。Angora将条件语句中的表达式视为输入x上的函数f（x），并使用梯度下降来找到两个输入x和x’，使得f（x）&gt; 0且f（x’）≤0。</p>\n</li>\n<li><p>形状和类型推断：f（x）是向量x上的函数。在梯度下降期间，Angora分别计算f的每个分量的f的偏导数，因此它必须确定每个分量及其类型。在第2行，Angora确定x由两个组件组成，每个组件由输入中的四个字节组成，并具有32位有符号整数类型。</p>\n</li>\n<li><p>输入长度探索：除非输入至少有1032个字节，否则main不会调用foo。我们不是盲目地尝试更长的输入，而是检测从输入读取的常用函数，并确定更长的输入是否会探索新的状态。例如，如果初始输入短于1024字节，则第12行上的条件语句将执行true分支。</p>\n</li>\n</ul>\n<p>​       由于fread的返回值与1024进行比较，因此Angora知道只有至少1024字节长的输入才能探索错误分支。类似地，第16行和第19行的检测指示Angora将输入扩展到至少1032个字节以执行函数foo。</p>\n<p><img src=\"/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/图3.png\" alt=\"图3\"></p>\n<p><img src=\"/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/图4.png\" alt=\"图4\"></p>\n<h2 id=\"3-2-上下文敏感的分支计数\"><a href=\"#3-2-上下文敏感的分支计数\" class=\"headerlink\" title=\"3.2 上下文敏感的分支计数\"></a>3.2 上下文敏感的分支计数</h2><p>​    第2节描述了AFL的分支覆盖表。它的设计有几个优点。首先，它节省空间。分支数量与程序大小呈线性关系。其次，使用范围来计算分支执行在关于不同执行计数是否指示了程序新的内部状态提供了良好启发。当执行计数很小（例如，小于4）时，计数的任何变化都是显着的。然而，当执行计数很大（例如，大于32）时，变化必须足够大以被认为是重要的。</p>\n<p>​    但这种设计有局限性。由于AFL的分支对上下文不敏感，因此它们无法区分不同上下文中同一分支的执行，这可能会忽略程序新的内部状态。图3说明了这个问题。考虑第3行分支的覆盖范围。在第一次运行期间，程序采用输入“10”。当它在第19行调用f（）时，它在第4行执行true分支。之后，当它在第21行调用f（）时，它在第10行执行false分支。由于AFL对分支的定义是上下文不敏感的，它认为两个分支都已执行。之后，当程序采用新输入“01”时，AFL认为此输入不会触发新的内部状态，因为第4行和第10行的分支都在上一次运行中执行。但实际上这个新输入触发了一个新的内部状态，因为当输入[2] == 1时它将导致第6行崩溃。</p>\n<p>​    我们将上下文合并到分支的定义中。我们将分支定义为元组（lprev, lcur, context），其中l prev和lcur分别是条件语句之前和之后的基本块的ID，context是h（stack）其中h是散列函数，并且stack包含调用堆栈的状态。例如，让图3中的程序首先在输入10上运行。在它从第19行进入f（）之后，它将执行分支（l3; l4; [l19]）。然后，在从第21行进入f（）之后，它将执行分支（l3; l10; [l21]）。相反，当程序在输入“01”上执行时，它将执行分支（l3; l10; [l19]），然后执行（l3; l4; [l21]）。通过将调用上下文合并到分支的定义中，Angora可以检测到第二次运行会触发新的内部状态，这将在改变输入时[2]时导致第6行产生carsh。</p>\n<p>​    向分支添加上下文会增加独特分支的数量，这在发生深度递归时可能会很明显。我们当前的实现通过选择用于计算调用堆栈的散列的特定函数h来缓解该问题，其中h计算堆栈上所有调用位置的ID的xor。当Angora插桩程序时，它会为每个调用点分配一个随机ID。因此，当函数f递归调用自身时，无论Angora将同一调用站点的ID推送到调用堆栈多少次，h（堆栈）最多输出两个唯一值，在函数f中这最多会使独特分支的数量增加一倍。我们对现实世界程序的评估表明，在结合上下文后，独特分支的数量增加了多达7.21倍（表7），以换取改进代码覆盖的好处（图7）。</p>\n<h2 id=\"3-3-字节级别的污点跟踪\"><a href=\"#3-3-字节级别的污点跟踪\" class=\"headerlink\" title=\"3.3 字节级别的污点跟踪\"></a>3.3 字节级别的污点跟踪</h2><p>​    Angora的目标是创建执行未开发分支的输入。当它尝试执行未探测的分支时，它必须知道输入中的哪些字节偏移影响分支的谓词。因此，Angora需要字节级别的污点跟踪。然而，污点跟踪是昂贵的，尤其是在单独跟踪每个字节时，因此AFL避免了它。我们的主要观点是，在大多数程序运行中都不需要进行污点跟踪。一旦我们对输入运行了污点跟踪（图1中的步骤1），我们就可以记录哪些字节偏移流入每个条件语句。然后，当我们改变这些字节时，我们可以在没有污点跟踪的情况下运行程序。这通过其许多突变来分摊一个输入上的污点跟踪成本，这使得Angora具有与AFL类似的输入执行吞吐量（第5.6节）。</p>\n<p>​    Angora将程序中的每个变量x与污点标签tx相关联，污点标签tx表示输入中可能流入x的字节偏移量。污点标签的数据结构对其内存占用量有很大影响。一个简单的实现是将每个污点标签表示为位向量，其中每个位i表示输入中的第i个字节。然而，由于该位向量的大小在输入的大小上线性增长，因此该数据结构对于大输入将是禁止的，但是在某些程序中找到错误需要大量输入。</p>\n<p>​    为了减少污点标签的大小，我们可以将位向量存储在表中，并使用表中的索引作为污点标签。只要表中条目数的对数远小于最长位向量的长度（通常是这种情况），我们就可以大大减小污点标签的大小。</p>\n<p>​    但是，这种数据结构带来了新的挑战。污点标签必须支持以下操作：</p>\n<ul>\n<li><p>INSERT（b）：插入位向量b并返回其标签。</p>\n</li>\n<li><p>FIND（t）：返回污点标签t的位向量。</p>\n</li>\n<li><p>UNION（tx; ty）：返回污点标签，表示污点标签tx和ty的位向量的并集。</p>\n</li>\n</ul>\n<p>​       FIND代价很低，但UNION很高。 UNION采取以下步骤。首先，它找到两个标签的位向量并计算它们的联合u。这一步代价很低。接下来，它搜索表以确定u是否已存在。如果没有，它会增加u。但如何高效搜索？线性搜索会很昂贵。或者，我们可以构建一个位向量的哈希集，但是如果它们中有很多并且每个位向量都很长，那么计算哈希码和存储哈希集的空间就会花费很多时间。由于UNION是我们在算术表达式中跟踪污染数据时的常见操作，因此它必须是高效的。注意，我们不能使用UNION-FIND数据结构，因为矢量不是不相交的，即两个不同的位矢量可能在同一位置具有1。</p>\n<p>​    我们提出了一种新的数据结构，用于存储位向量,允许有效INSERT，FIND和UNION。对于每个位向量，数据结构使用无符号整数为其分配唯一标签。当程序插入新的位向量时，数据结构会为其分配下一个可用的无符号整数。</p>\n<p>​    数据结构包含两个组件。</p>\n<ul>\n<li><p>二叉树将位向量映射到其标签。每个位向量b由级别为|b|的唯一树节点vb表示，其中|b|是b的长度。 vb存储b的标签。要从根到达vb，检查b0,b1…顺序。如果bi为0，则转到左边的子节点;否则，去右边的子节点。每个节点都包含一个指向其父节点的后向指针，以允许我们从vb开始检索位向量。</p>\n</li>\n<li><p>查找表将标签映射到其位向量。标签是该表的索引，相应的条目指向表示该标签的位向量的树节点。</p>\n</li>\n</ul>\n<p>​       在该数据结构中，树中的所有叶子表示位向量，并且没有内部节点表示位向量。但是，树中的许多节点可能是不必要的。例如，如果向量x00 <em>在树中但没有向量x0 [01] </em> 1 [01] <em>在树中，其中x是任何位序列，那么就不必在节点之后存储任何节点表示x，因为x只有一个是叶子的结点，而这个叶子代表x00 </em>。这里我们使用正则表达式的通用符号，其中x *表示x重复零次或多次，[xy]表示x或y。这个观察允许我们在将一个向量插入树中时修剪向量，如下所示：</p>\n<ol>\n<li><p>删除向量的所有尾随0。</p>\n</li>\n<li><p>跟踪向量中的位，从第一位到最后一位，遍历树。</p>\n</li>\n</ol>\n<ul>\n<li><p>如果位为0，请跟随左节点</p>\n</li>\n<li><p>否则，请跟随右节点。</p>\n</li>\n<li><p>如果节点不存在，请创建它。</p>\n</li>\n</ul>\n<ol start=\"3\">\n<li>将向量的标签存储在我们访问的最后一个节点中。</li>\n</ol>\n<p>​       算法2详细描述了这种插入操作。</p>\n<p>​    算法3和算法4分别描述了FIND和UNION操作。请注意，当我们创建节点时，最初它不包含标签。稍后，如果此节点是我们插入位向量时访问的最后一个节点，我们将位向量的标签存储在此节点中。通过此优化，此树具有以下属性：</p>\n<ul>\n<li><p>每个叶节点都包含一个标签。</p>\n</li>\n<li><p>内部节点可能包含标签。我们可能会在没有标签的内部节点中存储标签，但我们永远不会在任何内部节点中替换标签。</p>\n</li>\n</ul>\n<p>​        该数据结构极大地减少了用于存储位向量的存储器占用。设每个位向量的长度为n，并设有l个位向量。如果我们天真地将所有位向量存储在查找表中，则需要O（nl）空间。但是，在我们的数据结构中，树中的节点数是O（l）。每个节点可以存储最多一个索引到查找表。由于查找表具有l个条目并且每个条目是指针并且因此具有固定大小，因此查找表的大小是O（l），并且查找表的每个索引具有O（log 1）位。因此，总空间要求为O（l·log l）。</p>\n<p><img src=\"/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/图5.jpg\" alt=\"图5\"></p>\n<h2 id=\"3-4-基于梯度下降的搜索算法\"><a href=\"#3-4-基于梯度下降的搜索算法\" class=\"headerlink\" title=\"3.4 基于梯度下降的搜索算法\"></a>3.4 基于梯度下降的搜索算法</h2><p>​    字节级污点跟踪发现输入流中的哪些字节偏移成为条件语句。但是如何改变输入以运行未探索的分支语句？大多数模糊测试者随机地或使用粗略的启发式方法改变输入，但这些策略不太可能快速找到合适的输入值。相比之下，我们将此视为搜索问题，并利用机器学习中的搜索算法。我们在实现中使用了梯度下降，但其他搜索算法也可能有效。</p>\n<p>​    在这种方法中，我们将用于执行分支断定看作黑盒函数f（x）的约束，其中x是输入中流入判断的值的向量，并且f（）捕获计算在从程序开始到此判断的路径。 f（x）有三种类型的约束：</p>\n<ol>\n<li><p>f（x）&lt;0。</p>\n</li>\n<li><p>f（x）&lt;= 0。</p>\n</li>\n<li><p>f（x）== 0。</p>\n</li>\n</ol>\n<p>​       表2显示我们可以将所有形式的比较转换为上述三种类型的约束。如果条件语句的判断包含逻辑运算符&amp;&amp;或||，则Angora会将语句拆分为多个条件语句。例如，它将（a &amp;&amp; b）{s} else {t}拆分为if（a）{if（b）{s} else {t}} else {t}。</p>\n<p>​    算法5显示了搜索算法。从初始x0开始，找到x使得f（x）满足约束。请注意，为了满足每种类型的约束，我们需要最小化f（x），并且我们使用梯度下降来实现此目的。</p>\n<p>​    梯度下降找到函数f（x）的最小值。该方法是迭代的。每次迭代都从x开始，计算∇xf（x）（x处的f（x）的梯度），并将x更新为x-ε∇xf（x），其中ε是学习率。</p>\n<p>​    在训练神经网络时，研究人员使用梯度下降来找到一组最小化训练误差的权重。然而，梯度下降的问题在于它有时可能会陷入局部最小值，而不是全局最小值。幸运的是，这在模糊测试中通常不是问题，因为我们只需要找到足够好的输入x而不是全局最优x。例如，如果约束是f（x）&lt;0，那么我们只需要找到一个x，其中f（x）&lt;0而不是f（x）是全局最小值。</p>\n<p>然而，当将梯度下降应用于模糊时，我们面临着独特的挑战。梯度下降需要计算梯度∇xf（x）。在神经网络中，我们可以用分析形式编写∇xf（x）。然而，在模糊测试中，我们没有f（x）的分析形式。其次，在神经网络中，f（x）是连续函数，因为x包含网络的权重，但在模糊中f（x）通常是离散函数。这是因为典型程序中的大多数变量都是离散的，因此x中的大多数元素都是离散的。</p>\n<p>​    我们使用数值近似解决了这些问题。 f（x）的梯度是唯一的矢量场，其每个点x处的任意单位矢量v的点积是f沿v的方向导数。我们用δf(x) /δ（xi）= f（x+δv i）-f（x））/δ逼近每个方向导数其中δ是小的正值（例如，1），vi是第i维的单位矢量。为了计算每个方向导数，我们需要运行程序两次，一次使用原始输入x，一次使用扰动输入x + δvi。在第二次运行中，程序可能无法到达计算f（x +δvi）的程序点，因为程序在较早的条件语句中采用了不同的分支。当发生这种情况时，我们将δ设置为小的负值（例如，-1）并尝试再次计算f（x +δvi）。如果成功，我们会根据它计算方向导数。否则，我们将导数设置为零，指示梯度下降不要在此方向上移动x。计算梯度的时间与矢量x的长度成比例，因为Angora分别计算每个方向导数。第3.5节将描述如何通过合并在程序中用作单个值的连续字节来减少x的长度。</p>\n<p>​    理论上，梯度下降可以解决任何约束。实际上，梯度下降可以解决约束的速度取决于数学函数的复杂性。</p>\n<ul>\n<li><p>如果f（x）是单调的或凸的，那么即使f（x）具有复杂的分析形式，梯度下降也可以快速找到解。例如，考虑约束f（x）&lt;0，其中f（x）使用一些多项式系列近似log（x）。由于复杂的分析形式，符号执行很难解决这种约束。但是，梯度很容易解决，因为f（x）是单调的。</p>\n</li>\n<li><p>如果梯度下降的局部最小值满足约束，则查找解决方案也很快。</p>\n</li>\n<li><p>如果局部最小值不满足约束条件，则Angora必须随机走到另一个值x并从那里开始递减渐变，希望找到满足约束的另一个局部最小值。</p>\n</li>\n</ul>\n<p>​       请注意，Angora不会生成f（x）的分析形式，而是运行程序来计算f（x）。</p>\n<p><img src=\"/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/图6.png\" alt=\"图6\"></p>\n<h2 id=\"3-5形状和类型推断\"><a href=\"#3-5形状和类型推断\" class=\"headerlink\" title=\"3.5形状和类型推断\"></a>3.5形状和类型推断</h2><p>​    天真地，我们可以让输入中的x中的每个元素成一个字节流入到判断处。但是，由于类型不匹配，这会导致梯度下降问题。例如，让程序将输入中的四个连续字节b3b2b1b0视为整数，并让xi表示该整数值。当计算f（x +δvi）时，我们应该将δ加到这个整数。但是如果我们天真地将每个字节b3，b2，b1，b0分配给x中的不同元素，那么我们将在每个字节上计算f（x +δvi），但这是不合适的。</p>\n<p>​    程序将这些字节组合为单个值并仅使用表达式中的组合值，因此当我们向除最低有效字节之外的任何字节添加小的δ时，我们将显着更改此组合值，这将导致计算的偏导数是一个不正确的真实值的近似。</p>\n<p>​    为了避免这个问题，我们必须确定（1）输入中的哪些字节总是一起用作程序中的单个值，以及（2）值的类型是什么。我们称第一个问题为形状推理，第二个问题类型推断，并在动态污点分析过程中解决它们。</p>\n<p>​    对于形状推断，最初输入中的所有字节都是独立的。在污点分析期间，当指令将输入字节序列读入变量，其中序列的大小与基本类型的大小匹配（例如，1,2,4,8字节）时，Angora将这些字节标记为属于相同的值。当冲突发生时，Angora使用最小的尺寸。对于类型推断，Angora依赖于对值进行操作的指令的语义。例如，如果指令对有符号整数进行操作，则Angora将相应的操作数推断为有符号整数。当相同的值同时用作有符号和无符号类型时，Angora将其视为无符号类型。请注意，当Angora无法推断出值的精确大小和类型时，这并不能防止梯度下降找到解决方案 - 搜索只需要更长的时间。</p>\n<p><img src=\"/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/图7.png\" alt=\"图7\"></p>\n<h2 id=\"3-6-输入长度探索\"><a href=\"#3-6-输入长度探索\" class=\"headerlink\" title=\"3.6 输入长度探索\"></a>3.6 输入长度探索</h2><p>​    与大多数其他模糊器一样，Angora开始使用尽可能小的输入进行模糊测试。但是，仅当输入长于阈值时才执行某些分支。这给模糊器带来了两难境地。如果模糊器使用太短的输入，则无法探索这些分支。但如果它使用太长的输入，程序可能运行缓慢甚至内存不足。大多数工具使用临时方法尝试不同长度的输入。相比之下，Angora只有在这样做才能探索新的分支时才会增加输入长度。</p>\n<p>​    在污点跟踪期间，Angora将类似read的函数调用中的目标内存与输入中的相应字节偏移相关联。它还使用特殊标签标记来自读取调用的返回值。如果在条件语句中使用返回值并且不满足约束，则Angora会增加输入长度，以便读取调用可以获取它请求的所有字节。例如，在图2中，如果第12行的条件语句为false，则Angora会扩展输入长度，以便fread可以读取它请求的所有1024个字节。我们的标准并非详尽无遗，因为程序可以消耗输入并以我们未预料到的方式检查其长度，但是一旦我们发现它们就很容易将这些标准添加到Angora。</p>\n<h1 id=\"4-实现\"><a href=\"#4-实现\" class=\"headerlink\" title=\"4  实现\"></a>4  实现</h1><h2 id=\"4-1-插桩\"><a href=\"#4-1-插桩\" class=\"headerlink\" title=\"4.1 插桩\"></a>4.1 插桩</h2><p>​    对于每个要模糊的程序，Angora通过使用LLVM Pass [18]检测程序来生成相应的可执行文件。</p>\n<ul>\n<li><p>插桩收集条件语句的基本信息，并通过污点分析将条件语句链接到其对应的输入字节偏移。在每个输入上，Angora只运行此步骤一次（而不是在改变此输入时）。</p>\n</li>\n<li><p>记录执行跟踪以识别新输入。</p>\n</li>\n<li><p>在运行时支持上下文（第3.2节）。</p>\n</li>\n<li><p>在判定中收集表达式值（第3.4节）。</p>\n</li>\n</ul>\n<p>​       为了支持3.3节中描述的可扩展字节级污点跟踪，我们通过扩展DataFlowSanitizer（DFSan）[21]为Angora实现了污点跟踪。我们为FIND和UNION操作实现了缓存设施，显着加快了污点跟踪。</p>\n<p>​    Angora依赖于LLVM 4.0.0（包括DFSan）。它的LLVM pass包含820行C ++代码，不包括DFSan，运行时有1950行C ++代码，包括用于存储污点标签的数据结构以及用于污染输入和跟踪条件语句的钩子。</p>\n<p>​    除了具有两个分支的if语句之外，LLVM IR还支持switch语句，这可能会引入多个分支。在我们的实现中，为方便起见，Angora将每个switch语句转换为if语句序列。</p>\n<p>​    Angora识别libc函数，用于在条件语句中出现时比较字符串和数组。</p>\n<p>​    例如，Angora将“strcmp（x，y）”转换为“x strcmp y”，其中strcmp是Angora理解的特殊比较运算符。</p>\n<h2 id=\"4-2-Fuzzer\"><a href=\"#4-2-Fuzzer\" class=\"headerlink\" title=\"4.2 Fuzzer\"></a>4.2 Fuzzer</h2><p>​    我们以4488行Rust代码中实现了Angora。我们使用fork server [30]和CPU绑定等技术优化了Angora。</p>\n<h1 id=\"5-评估\"><a href=\"#5-评估\" class=\"headerlink\" title=\"5 评估\"></a>5 评估</h1><p>​    我们分三个步骤评估了Angora。首先，我们将Angora的性能与其他最先进的模糊器进行了比较。然后，我们测量了Angora的测试覆盖率及其在现实世界程序中发现未知错误的能力。最后，我们评估了它的关键新颖特征。</p>\n<p>​    我们在64位Ubuntu 16.04 LTS的Intel Xeon E5-2630 v3和256 GB内存的服务器上运行了所有实验。尽管Angora可以同时对多个内核上的程序进行模糊处理，但我们将其配置为在评估期间仅在一个内核上模糊该程序，以将其性能与其他模糊器进行比较。我们对每个实验进行了五次运行并报告了平均性能。</p>\n<h2 id=\"5-1-Angora与其他模糊器进行比较\"><a href=\"#5-1-Angora与其他模糊器进行比较\" class=\"headerlink\" title=\"5.1 Angora与其他模糊器进行比较\"></a>5.1 Angora与其他模糊器进行比较</h2><p>​    比较模糊器的最终指标是它们发现错误的能力。一个好的测试集应该包含具有实际错误的真实程序。 LAVA是一种通过在程序源代码中注入大量实际错误来生成真实语料库的技术[9]。作者通过在每个程序中注入多个错误来创建语料库 LAVA-M。 LAVA-M由四个GNU coreutils程序组成：uniq，base64，md5sum和who。每个注入的bug都有一个唯一的ID，在触发bug时会打印出来。</p>\n<p>​    我们将Angora与以下最先进的模糊器进行了比较：</p>\n<ul>\n<li><p>FUZZER（基于覆盖的模糊器）和SES（符号执行和SAT求解）。 LAVA的作者将它们都运行了5个小时[9]。</p>\n</li>\n<li><p>VUzzer：使用“魔术字节”策略的模糊器[25]。它的作者报告了LAVA-M程序中发现的错误数量，但没有报告运行时间。</p>\n</li>\n<li><p>Steelix：一个模糊器在LAVAM上表现优于VUzzer [19]。作者通过运行模糊器5小时报告了LAVA-M程序中发现的错误数量。[11]</p>\n</li>\n<li><p>AFL 2.51b：撰写本文时的最新版AFL。我们运行AFL五个小时，我们为AFL提供了一个CPU核心，用于对每个程序进行模糊测试。</p>\n</li>\n<li><p>Angora：我们使用与AFL相同的设置（每个程序一个CPU核心）。</p>\n</li>\n</ul>\n<p>​       表1比较了所有模糊器发现的错误。AFL表现最差，在所有程序中总共发现了10个错误。 VUzzer的作者无法在md5sum上运行它，因为LAVA作者错误地修改了md5sum，导致它在所有输入上崩溃。我们向LAVA作者证实了这个问题并修复了它。 Steelix是第二个最好的模糊器，它发现了base64中几乎所有的错误，但是在uniq中28个中只有7个注入了错误，57个md5sum注入了错误中的28个，2136个中有194个注入了错误。Angora大大超过了Steelix，发现了uniq，base64和md5sum中的所有错误，并且2136中的1443个注入了错误。</p>\n<p>​    LAVA为每个注入的bug分配一个唯一的ID，该ID在触发错误时打印。文件验证的错误列出了LAVA作者在创建LAVA时能够触发的所有注入错误。Angora不仅发现了uniq，base64，md5sum中列出的所有错误以及大多数列出的错误，还列出了103个未列出的错误（LAVA作者注入但无法触发的错误）。表3显示了这些未列出的错误的ID。表4显示了Angora发现的列出和未列出的错误的细分。</p>\n<p><img src=\"/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/图8.png\" alt=\"图8\"></p>\n<p>​    图4显示了Angora在who中随着时间的推移发现的错误累积数量。我们没有显示其他模糊器的结果，因为他们发现who没有错误。图4显示，最初Angora很快发现了错误，在不到五分钟内发现了1000个错误。然后发现速度减慢，但在总共2136个列出的错误中，它仅在45分钟内发现超过1500个错误。</p>\n<p>​    我们接下来解释为什么Angora发现了比下一个最好的模糊器更多的错误。首先，LAVA使用“魔术字节”来保护包含错误的分支，但是一些魔术字节不是直接从输入复制而是从输入计算。由于VUzzer和Steelix的“魔术字节”策略只能将魔术字节直接复制到输入，因此该策略无法创建探索这些分支的输入。相比之下，Angora跟踪流入判定的输入字节偏移，然后通过梯度下降而不是假设“魔术字节”或输入与判定之间的任何其他特殊关系来改变这些偏移，因此Angora可以找到探索这些的输入分支机构。其次，VUzzer盲目地尝试“魔术字节”策略，一旦魔术字节中的一个与随机突变后的输入中的字节匹配，Steelix就会关注“魔术字节”策略。相比之下，Angora安排其所有计算能力来解决未探测分支上的路径约束，因此它可以覆盖更多分支，因此可以快速找到LAVA-M中的大部分注入错误。</p>\n<p><img src=\"/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/图9.png\" alt=\"图9\"></p>\n<h2 id=\"5-2-在未修改的真实程序中评估Angora\"><a href=\"#5-2-在未修改的真实程序中评估Angora\" class=\"headerlink\" title=\"5.2 在未修改的真实程序中评估Angora\"></a>5.2 在未修改的真实程序中评估Angora</h2><p>​    Angora在LAVA上的表现令人印象深刻，不仅发现了大部分列出的错误，还发现了许多未列出的错误。然而，它的怀疑论者可能会争辩说这些bug是人为注入的。为了解决这个问题，我们使用最新版本评估了八个流行的开源程序。由于这些成熟的，受欢迎的程序已经过广泛测试，我们预计它们几乎没有残留物崩溃的错误。因此，除了测量发现的新错误的数量外，我们还测量了Angora对这些程序的报道。我们使用了gcov，它记录了输入中程序中执行的所有行和分支[14]。我们将由Angora生成的每个输入馈送到用gcov编译的程序以获得累积代码覆盖率，并且afl-cov3允许我们自动执行此操作。我们还在这些程序上运行AFL进行比较。表5显示了使用一个CPU内核运行Angora和AFL五小时后的结果。我们通过AFL的afl-cmin -C命令重复删除了崩溃。</p>\n<p>​    表5显示Angora在线路覆盖范围，分支覆盖范围以及每个程序发现崩溃时表现优于AFL。在文件，jhead，nm，objdump和大小中，AFL发现了0,19,12,4,6个独特的崩溃，而Angora分别发现了6,52,29,40和48个独特的崩溃。对比度在jhead最为突出，Angora的线路覆盖率提高了127.4％，分支覆盖率提高了144.0％。</p>\n<p>​    图5比较了Angora和AFL随时间的累积线和分支覆盖率。它表明Angora在任何时候都覆盖了比AFL更多的线和分支。Angora优越覆盖的原因在于它可以探索复杂条件语句的两个分支。例如，图6显示了文件中的这样一个语句，其中Angora成功地探索了两个分支，但AFL无法探索真正的分支。在接下来的部分中，我们将评估Angora的每个关键特性如何有助于其卓越的性能。</p>\n<p><img src=\"/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/图10.png\" alt=\"图10\"></p>\n<p><img src=\"/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/图11.png\" alt=\"图11\"></p>\n<p>5.3上下文相关的分支计数</p>\n<p>​    <strong>5.3.1</strong> <strong>性能</strong>。 3.2节介绍了上下文相关分支计数。我们相信在不同的函数调用上下文中区分相同的分支会发现更多的错误。为了评估这个假设，我们分别使用上下文相关的分支计数和上下文不相关的分支计数来运行Angora。表6显示Angora发现6个错误具有上下文相关的分支计数，但在上下文不相关中它没有错误。图7显示从30分钟开始到模糊测试，Angora始终覆盖更多具有上下文相关分支计数的累积行。我们发现了几个真实世界的例子，其中上下文相关的分支计数允许Angora探索更多路径。例如，图8显示了程序文件中readelf.c文件中的代码片段。函数getu32在多个上下文中调用，它根据swap参数返回不同的结果。如果没有上下文相关的分支计数，Angora将无法在所有调用上下文中探索条件语句的两个分支。</p>\n<p>​    <strong>5.3.2</strong> <strong>哈希碰撞</strong>。与AFL类似，Angora将分支计数存储在哈希表中。当Angora在计算分支覆盖率时合并调用上下文时，它会在哈希表中插入更多的唯一分支，因此我们必须增加哈希表的大小以保持较低的冲突率。</p>\n<p>​    我们评估了5.2节中描述的真实世界程序中有多少独特的分支上下文相关性。 AFL的作者观察到，唯一分支（没有上下文）的数量通常在2k到10k之间，而具有216个bucket的哈希表应该足以满足常见情况[30]。表7显示合并上下文相关度将唯一分支的数量增加了至多8倍，这要求我们将散列表的大小增加8倍以具有相同的预期散列冲突率。默认情况下，Angora在其哈希表中分配220个bucket，这是AFL中哈希表的16倍，对大多数程序来说应该足够了。虽然在不再适合缓存时增加哈希表可能是有害的，但不像AFL那样遍历哈希表以查找新路径并优先处理覆盖许多基本块的输入，对于每个输入，Angora只遍历哈希表一次找到新的路径。因此，Angora受哈希表大小增长的影响较小，如第5.6节中的执行速度所示。</p>\n<p><img src=\"/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/图12.png\" alt=\"图12\"></p>\n<h2 id=\"5-4-基于梯度下降的搜索\"><a href=\"#5-4-基于梯度下降的搜索\" class=\"headerlink\" title=\"5.4 基于梯度下降的搜索\"></a>5.4 基于梯度下降的搜索</h2><pre><code>第3.4节描述了如何使用梯度下降来解决条件语句中的约束。我们将梯度下降与另外两种策略进行了比较：随机变异，VUzzer的魔术字节加随机变异。为了排除测量中的其他变量，我们确保三种策略接收相同的输入：我们收集了AFL在5.2节中生成的输入，并将它们作为模糊的唯一输入提供给Angora。我们分别使用上述三种策略运行Angora两小时。\n</code></pre><p>​    表8显示梯度下降解决了比所有程序中的其他两个策略更多的约束。如第5.1节的最后一段所述，“魔术字节”策略无法解决其值未直接从输入复制的约束。例如，图6中的变量descsz用于程序中的许多约束，但它不是直接从输入复制的，因此“魔术字节”策略没有帮助。</p>\n<h2 id=\"5-5-输入长度探测\"><a href=\"#5-5-输入长度探测\" class=\"headerlink\" title=\"5.5  输入长度探测\"></a>5.5  输入长度探测</h2><p>​    第3.6节描述了当Angora观察到路径约束可能取决于长度时，按需增加输入的长度，而AFL和相关的模糊器随机增加输入长度。我们基于两个标准比较了这两种策略：</p>\n<ul>\n<li><p>策略增加输入长度的次数是多少？在这个战略创造的投入中，有多少是有用的？如果输入直接或在某些突变后探索新分支，则输入有用。</p>\n</li>\n<li><p>这些有用输入的平均长度是多少？</p>\n</li>\n</ul>\n<p>​       我们分别用我们提出的策略和随机策略运行Angora五小时。表9显示Angora的策略将输入长度增加了大约两个数量级，比随机策略少了几个数量级，但它在所有情况下都发现了更有用的输入，除了两个：在readpng它发现总共46个中有用输入少3个，并且在jhead上，既没有策略发现任何有用的输入，因为jhead只解析图像的标题，因此不受图像数据长度的影响。表9还显示，虽然Angora的策略产生了更多有用的输入，但它在每个测试程序上平均产生较短的输入。较短的输入使许多程序运行得更快。该评估表明，Angora的战略比随机战略产生更高质量的投入。</p>\n<p><img src=\"/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/图13.png\" alt=\"图13\"></p>\n<p>5.6 执行速度</p>\n<p>Angora的污染追踪代价很高。然而，Angora为每个输入运行一次污染跟踪，然后改变输入并多次运行程序而没有污点跟踪，因此一次性成本是摊销的。由于分支计数主导了没有污点跟踪的插桩代码的运行时间，因此Angora插桩程序的运行速度与其AFL插桩版本的运行速度大致相同。表10显示AFL以比Angora略高的速率执行输入。然而，由于Angora产生更高质量的输入，更有可能探索新的分支，Angora有更好的覆盖范围，并发现明显更多的错误，如前所示。</p>\n<p><img src=\"file:///C:\\Users\\admin\\AppData\\Local\\Temp\\msohtmlclip1\\01\\clip_image002.jpg\" alt=\"img\"></p>\n<h1 id=\"6-相关工作\"><a href=\"#6-相关工作\" class=\"headerlink\" title=\"6 相关工作\"></a>6 相关工作</h1><h2 id=\"6-1种子输入优先级\"><a href=\"#6-1种子输入优先级\" class=\"headerlink\" title=\"6.1种子输入优先级\"></a>6.1种子输入优先级</h2><p>​    基于突变的fuzzer的一个重要优化是明智地选择种子输入。雷伯特等人[26]制定并推理了种子选择调度问题。他们基于PeachFuzzer设计并评估了六种不同的种子选择算法[23]。算法使用不同的特征来最小化种子输入集，例如执行时间和文件大小。结果表明，种子选择算法采用的启发式方法比完全随机抽样方法表现更好。 AFLFast [4]观察到大多数模糊测试都使用了相同的几条“高频”路径。他们使用马尔可夫链来识别“低频”路径。 AFLFast优先考虑包含此类路径的输入。VUzzer [25]使用控制流功能来建模路径，以优先考虑路径难以到达的输入。此外，VUzzer检测到错误处理基本块，并优先考虑不包含这些基本块的有效输入。相比之下，Angora选择其路径包含具有未探索分支的条件语句的输入。这是一种更为通用的策略，在探索高频路径后，它会自动指示Angora专注于低频路径。</p>\n<h2 id=\"6-2-基于污点的模糊测试\"><a href=\"#6-2-基于污点的模糊测试\" class=\"headerlink\" title=\"6.2 基于污点的模糊测试\"></a>6.2 基于污点的模糊测试</h2><p>​    污点跟踪有很多用途，例如分析恶意软件行为[24]，检测和防止信息泄漏[10,29]和调试软件[22,12]。它也可以用于模糊测试。基于污点的模糊器分析应用程序如何处理输入以确定应修改输入的哪个部分。其中一些模糊器[13,2,17]旨在将输入文件中安全敏感代码中使用的值定位，然后对输入文件的这些部分进行模糊处理以触发崩溃。例如，BuzzFuzz [13]使用污点定位来查找哪些输入字节由他们定义的“攻击点”处理。 Dowser [17]认为可能导致缓冲区溢出的代码是安全敏感代码。换句话说，这些模糊器旨在利用可到达路径中的错误。Woo等人。提到了在探索与利用之间的权衡[32]。Angora可以结合这些技术来开发探索的路径。 Taintscope [31]使用污点分析来推断校验和处理代码，并通过控制流程更改绕过这些检查，因为通过改变输入很难满足这些检查。</p>\n<p>​    VUzzer [25]是一个应用程序感知模糊器，它使用污点分析来定位输入文件中“魔术字节”的位置，然后将这些魔术字节分配给输入中的固定位置。 VUzzer只有在连续出现在输入中时才能找到魔术字节。 Steelix [19]通过学习魔术字节位于输入中的程序状态以及如何有效地改变输入以匹配魔术字节来改进VUzzer。相比之下，Angora应用字节级污点跟踪来获取流入每个条件语句的输入中的字节偏移，然后改变这些字节以满足未探测分支的条件，因此Angora可以有效地找到更多类型的值。魔术字节，例如，非连续魔术字节或魔术字节，不是直接从输入复制而是从输入计算。此外，VUzzer使用压缩的位设置数据结构来表示污点标签，其中每个位对应于输入中的唯一字节偏移。因此，对于具有复杂输入字节偏移模式的值，污点标签的大小很大，因为它们无法有效压缩。相比之下，Angora将字节偏移存储在树中，并将索引作为污染标签用于树中，因此无论标签中有多少输入字节偏移，污点标签的大小都是常量。例如，当几个值的污点标签具有相同的字节偏移时，VUzzer会在每个污点标签中重复存储这些字节偏移，但Angora只在树中存储这些字节偏移一次，从而大大减少了内存消耗。</p>\n<p>​    Angora有效表示污点标签的数据结构类似于简化有序二元决策图（roBDD）。 roBDD用于表示动态切片[33]和数据谱系[20]，但据我们所知，Angora是第一个使用这种想法有效地表示污点标签的。</p>\n<h2 id=\"6-3-符号辅助模糊测试\"><a href=\"#6-3-符号辅助模糊测试\" class=\"headerlink\" title=\"6.3 符号辅助模糊测试\"></a>6.3 符号辅助模糊测试</h2><p>​    动态符号执行为目标应用程序提供了高度语义洞察力。由于这些技术知道如何触发所需的程序状态，因此它们可用于直接查找程序中的漏洞。符号执行实现的经典方法以最大化代码覆盖率以查找崩溃[5,8]。但路径爆炸和约束求解的挑战使符号执行难以扩展[6,27]。一些工具试图通过将其与模糊测试[15,16,7,28]相结合来缓解这一障碍。 DART [15]和SAGE [16]使用动态符号执行引擎来修改模糊测试中的输入。 SYMFUZZ [7]利用对执行跟踪的符号分析来检测输入中位置之间的依赖关系，然后使用此依赖关系来计算最佳突变率以指导模糊测试。 Driller [28]只有在AFL模糊不清时才使用动态符号执行。但是，它们都继承了符号执行的可伸缩性问题。相比之下，Angora不使用符号执行，并且可以有效地在大型程序上找到许多错误。</p>\n<h1 id=\"7-结论\"><a href=\"#7-结论\" class=\"headerlink\" title=\"7 结论\"></a>7 结论</h1><p>​    我们设计并实现了Angora，这是一种强大的基于突变的模糊器，可以产生高质量的输入，这得益于以下关键技术：可扩展的字节级污点跟踪，上下文敏感的分支计数，基于梯度下降的搜索算法，形状和类型推断和输入长度探索。Angora在很大程度上超越了其他最先进的模糊器。它发现了比LAVA-M上的其他模糊器明显更多的错误，发现了当他们准备数据集时LAVA作者无法触发的103个错误，以及8个流行的，成熟的开源程序中总共175个新错误。我们的评估显示，Angora将模糊测试的标准提升到了一个新的水平。</p>\n","categories":[{"name":"论文","slug":"论文","permalink":"http://yama0xff.com/categories/论文/"},{"name":"fuzzing","slug":"论文/fuzzing","permalink":"http://yama0xff.com/categories/论文/fuzzing/"}],"tags":[{"name":"2018年","slug":"2018年","permalink":"http://yama0xff.com/tags/2018年/"},{"name":"fuzzing","slug":"fuzzing","permalink":"http://yama0xff.com/tags/fuzzing/"},{"name":"污点分析","slug":"污点分析","permalink":"http://yama0xff.com/tags/污点分析/"},{"name":"LAVA","slug":"LAVA","permalink":"http://yama0xff.com/tags/LAVA/"},{"name":"梯度下降算法","slug":"梯度下降算法","permalink":"http://yama0xff.com/tags/梯度下降算法/"},{"name":"S&P'18","slug":"S-P-18","permalink":"http://yama0xff.com/tags/S-P-18/"},{"name":"LLVM","slug":"LLVM","permalink":"http://yama0xff.com/tags/LLVM/"}]}]