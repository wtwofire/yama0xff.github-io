<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>yama0xff&#39;s blog</title>
  
  <subtitle>CYBERSECURITY  BETWEEN 0 AND 1</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yama0xff.com/"/>
  <updated>2019-01-28T09:37:45.346Z</updated>
  <id>http://yama0xff.com/</id>
  
  <author>
    <name>yama0xff</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>NAR-Miner Discovering Negative Association Rules from Code</title>
    <link href="http://yama0xff.com/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/"/>
    <id>http://yama0xff.com/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/</id>
    <published>2019-01-28T09:18:28.000Z</published>
    <updated>2019-01-28T09:37:45.346Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>从基于数据挖掘技术的源代码推断编程规则已被证明对检测软件错误是有效的。现有研究侧重于以A⇒B的形式发现积极规则，表明当操作A出现时，操作B也应该在这里。不幸的是，负面规则（A⇒¬B），表明程序元素之间的相互抑制或冲突关系，没有得到应有的重视。事实上，违反这些负面规则也会导致严重的错误。</p><p>在本文中，我们提出了一种名为NAR-Miner的新方法，可以从大规模系统中自动提取负关联编程规则，并检测它们的违规行为来发现bug。然而，挖掘负面规则面临着比挖掘正面规则更严重的规则爆炸问题。大多数获得的负面规则都是无趣的，并且可能导致不可接受的错误警报。为了解决这个问题，我们设计了一个语义约束的挖掘算法，将规则挖掘集中在具有强语义关系的元素上。此外，我们引入信息熵来排列候选负面规则并突出有趣的规则。因此，我们有效地缓解了规则爆炸问题。我们实现NAR-Miner并将其应用于Linux内核（v4.12-rc6）。实验表明，不感兴趣的规则大大减少，检测到的17个违规行为已被确认为真正的错误并被内核社区修补。我们还将NAR-Miner应用于PostgreSQL，OpenSSL和FFmpeg，并发现了六个真正的错误。</p><table><thead><tr><th><strong>论文相关信息：</strong></th></tr></thead><tbody><tr><td><em>作者</em>：Pan Bian, Bin Liang,/Wenchang Shi,Jianjun Huang,Yan Cai</td></tr><tr><td><em>单位</em>：School of Information, Renmin University of China; Key Laboratory of DEKE, Renmin University of China Beijing, China; State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences</td></tr></tbody></table><p>Beijing, China |<br>| <em>出处</em>：                                                     |<br>| <em>原文地址</em>：<a href="https://github.com/wtwofire/database/blob/master/papers/mine/2018-NAR-Miner%20Discovering%20Negative%20Association%20Rules%20from%20Code.pdf" target="_blank" rel="noopener">https://github.com/wtwofire/database/blob/master/papers/mine/2018-NAR-Miner%20Discovering%20Negative%20Association%20Rules%20from%20Code.pdf</a> |<br>| <em>源码地址</em>：                                                 |<br>| <em>发表时间</em>：2018年                                           |</p><h1 id="1-引言"><a href="#1-引言" class="headerlink" title="1. 引言"></a>1. 引言</h1><p>静态错误/漏洞检测技术通常需要一些先验知识（即检测规则或漏洞签名）[9,13,17,19]。近年来，已经广泛证明了关于bug /漏洞检测的代码挖掘方法是非常有效的[1,4,6,7,14,20,25-27,29,30,36,38,44,47， 49,51-53,57,60]。这些方法自动从程序源代码中提取隐式编程规则，并进一步检测违反这些规则的错误或漏洞。通常，在代码挖掘期间，程序源代码首先被转换为项集[6,25,26,49]，图[7,34,57]或其他形式。接下来，将数据挖掘算法应用于变换后的格式以提取模式（例如，频繁项目集或子图）并推断编程规则。最后一步是检测违反推断规则的行为。例如，PR-Miner [25]和AntMiner [26]从Linux内核挖掘频繁项目集以提取关联规则（作为检测规则）并检测到许多未知错误。</p><p>这些现有研究的基本思想是利用统计数据来编制程序元素，并附带源代码的关系。这种关系表现为积极的编程模式。也就是说，在目标项目中，一些程序元素经常一起出现（达到给定的阈值）或者它们之间存在某种联系。例如，PR-Miner [25]和AntMiner [26]都以A⇒B的形式提取正关联规则，表明在函数内，当程序元素A出现时，元素B也应该出现。因此，如果函数实现违反规则（即，包含A而不包括B），则预期潜在的错误。已经提出了类似的技术来检测潜在的对象滥用错误[53]和控制结构之后缺少的程序元素[7]，已经推断出API的正确使用[60]。所有这些方法都针对一组具有相互支持关系的邻接程序元素，即积极关联。</p><p>然而，在实践中我们观察到一些隐式编程模式以A⇒¬B的形式表现为负关联。也就是说，当A出现时，B不应出现，反之亦然。从这个意义上说，否定规则反映了A和B之间的相互抑制或冲突关系。违反负面规则也可能导致严重的错误。通常不可能手动识别项目中的所有否定规则，尤其是像Linux内核这样的大规模规则。但据我们所知，现有方法没有可以自动从源代码中提取负面规则以进行错误检测。最先进的基于挖掘的解决方案只能提取积极的编程规则。与指示频繁模式的积极规则相比，否定规则通常更隐含，相应的错误更隐蔽。例如，图1中的错误已存在于Linux内核中超过10年（即，在Linux-2.6.4或更早版本中提供）。因此，开发一种自动提取隐式否定编程规则以检测相关错误和漏洞的有效方法既具有挑战性又迫切。</p><p>在本文中，我们提出NAR-Miner解决上述问题。最重要的想法是通过不频繁的模式挖掘来推断有趣的负关联规则，并进一步将相应的违规行为检测为潜在的程序错误。基本上，由于负面规则的性质[56]，直接挖掘不常见的模式以提取负面规则将产生大量规则。我们称之为规则爆炸问题。这些规则中的大多数对于错误检测都是无趣的，即它们不包含任何真实的应用程序逻辑，并且违反它们不会导致错误或程序质量问题。因此，基于这些不感兴趣的规则的检测结果将产生不可接受的误报。例如，直接将现有的负规则挖掘算法[43,46,61]应用于Linux内核将提取多达数十万条规则和数百万条违规行为。在有限的人力资源下进行人工审计变得不可能。为了解决规则爆炸问题，我们提出了一种语义约束的负关联编程规则挖掘算法，以避免尽可能地产生过多的不感兴趣的规则。此外，我们利用信息熵来识别易于导致不感兴趣的规则的一般函数。这一步有助于进一步遏制可能不感兴趣的规则。因此，NAR-Miner可以有效地缓解规则爆炸问题并获得理想的有趣规则来检测潜在的错误。</p><p>我们实现了NAR-Miner的原型，并首先在Linux内核（v4.12-rc6）上进行评估。实验表明，基于语义约束的负规则挖掘和基于信息熵的规则过滤在减少不感兴趣的规则数量方面表现良好。也就是说，它减少了46％的无趣规则（即，在200个排名靠前的负面规则中从198到107）。特别是，它在排名前50位的负面规则中实现了62％的真正正面率。NAR-Miner报告了违反排名最高的200条规则的356条违规行为。我们手动检查结果并发现23个可疑错误和数十个质量问题。我们向Linux内核维护者报告可疑错误。其中17个已被确认为真正的错误，相应的补丁已合并到最新版本（例如，v4.16）。我们进一步将NAR-Miner应用于PostgreSQL v10.3，OpenSSL v1.1.1和FFmpeg v3.4.2。从排名靠前的规则和违规行为中，我们手动识别出六个可疑错误，所有这些错误都由相应的维护人员进行了确认和修复</p><p>本文的主要贡献如下：</p><ul><li><p>据我们所知，我们的工作是第一个专注于从源代码中提取负面编程规则以检测错误的工作。它扩展了基于挖掘的错误检测技术的能力。</p></li><li><p>我们提出了一种通过在规则挖掘中引入程序语义并使用信息熵来识别一般函数来缓解规则爆炸问题的方法，该方法可以有效地提取用于错误检测的理想的有趣负编程规则。</p></li><li><p>我们针对真实世界的大型软件项目实现了NAR-Miner原型。我们将该工具应用于四个大型系统（即Linux内核，PostgreSQL，OpenSSL和FFmpeg）并引发相当多的错误，其中23个已被确认。</p></li></ul><h1 id="2-动机示例"><a href="#2-动机示例" class="headerlink" title="2.动机示例"></a>2.动机示例</h1><p>我们使用来自Linux内核（v4.12-rc6）的简化代码片段来激励我们的方法。在图1中，函数lapbeth_new_device在第5行调用alloc_netdev为网络设备分配一块内存。然后在第8行，在内联函数中调用netdev_priv以获取私有数据的起始地址并将其存储到变量lapbeth。如图1所示，lapbeth指向先前分配的内存中的位置。如果设备注册在第11行失败，则将释放设备的内存块。由变量ndev指向的已分配内存在第21行首先释放，然后在第23行释放私有数据。从代码片段突出显示从内存分配到空闲的执行序列中的关键操作，并相应地描述相应的内存状态。我们使用红色水平线来描述通过free_netdev和kfree的蓝色垂直线释放内存。通过图示，可以很容易地看出代码中存在双重错误。</p><p><img src="/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/1.png" alt=""></p><p>传统的静态检测方法难以在大规模系统（例如Linux内核）中发现此错误和其他类似错误，因为所需的错误模式或规则是特定于应用程序并且难以收集。现有的基于挖掘的方法也无法报告错误。例如，最先进的方法AntMiner [26]提取正关联规则并检查违规。在Linux内核中，我们发现在对alloc_netdev的90次调用中，共有77次出现{alloc_netdev，free_netdev}（85.6％）。并且在533个调用实例中只有一次调用free_netdev后跟kfree（0.2％）。 AntMiner将{alloc_netdev}⇒{free_netdev}视为一个正规则，最小置信度阈值为85％[26]。但是，图1中的代码同时调用alloc_netdev和free_netdev，因此是对规则的支持，而不是违反。因此，上述错误未被发现。此外，由于低信任度（0.2％«85％），AntMiner不会将{free_netdev}⇒{kfree}视为有效规则（即，以最小置信度阈值来消除）。因此，AntMiner无法将“kfree跟随free_netdev”报告为错误。</p><p>从上面的分析中，通过分析元素之间的伴随关系来检测图1中的错误是非常困难甚至是不可能的。实质上，与bug密切相关的两个程序元素（即free_netdev和kfree）是负相关的。通过统计分析可以发现这种知识。具体来说，我们发现在大多数情况下（大约99.8％）在Linux内核中，free_netdev后面没有kfree，我们了解到开发人员大多都知道在free_netdev之后调用kfree可能是不必要的或导致严重问题的情况。受此启发，相对少量的配对事件可被视为异常。</p><p>我们利用不频繁的项集挖掘算法来推断负关联规则并应用规则来检测它们的违规（例如，图1中的那个）。在挖掘和检测期间，我们还考虑了程序语义（例如，数据流信息）。在我们的示例中，kfree与free_netdev共享数据，并且它们的外观一起被视为不常见的模式。因此，我们推断出一个负面规则{free_netdev}⇒¬{kfree}。将规则应用于我们的示例可发现相应的错误（表2中的错误12＃）</p><h1 id="3-我们的方法"><a href="#3-我们的方法" class="headerlink" title="3.我们的方法"></a>3.我们的方法</h1><h2 id="3-1概述"><a href="#3-1概述" class="headerlink" title="3.1概述"></a>3.1概述</h2><p>我们提出了NAR-Miner，目标是检测程序包含一些操作（例如两个函数调用）的错误，这些操作被认为不会出现在一起，该方法不需要任何先验知识。NAR-Miner的高层理念是采用数据挖掘技术从源代码中推断出负关联规则并检测其违规行为。</p><p>图2显示了NAR-Miner的概述。它首先为挖掘阶段准备数据。与大多数基于挖掘的方法类似[6,25,26,49,60]，我们仅从每个单独的函数中提取编程规则，即在程序内，以避免过于复杂的分析。识别每个函数内的程序元素及其语义关系并将其转换为事务，然后将其存储在数据库（称为事务数据库）中。接下来，它从数据库中挖掘频繁且不频繁的项集，它们表示程序元素集。然后，它从挖掘的项集中推断出负关联规则，并利用函数的置信度和熵自动对规则进行排序。最后，它检测违反推断规则的情况，并将排名最高的规则报告为审计的潜在错误。</p><p><img src="/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/2.png" alt=""></p><h2 id="3-2挑战"><a href="#3-2挑战" class="headerlink" title="3.2挑战"></a>3.2挑战</h2><p>以前的研究[43,46,61]表明只有少数表现出负相关关系很有意思的模式。他们通过计算支持和信任来识别有趣规则的技术不能直接用于代码挖掘。构造有趣的负关联规则的程序元素应该在它们的语义中相互压制，而不是偶尔出现在一起。我们的实证研究表明，直接应用Wu等人提出的算法。 [56]从Linux内核中提取的事务数据库生成183,712个负关联规则（参见§4.2.2），而其中99％在采样分析中不感兴趣。报告的违规行为多达309,689起，这使得人工审核变得不可能。我们称之为规则爆炸问题，并将其视为提取负关联规则的主要挑战。我们将以下两个方面归结为规则爆炸的根本原因。</p><ol><li><p>现有的负关联规则挖掘方法[43,45,56,61]主要针对购物篮，医学诊断，蛋白质序列等。对于这类数据，来自挖掘单位的任何两个元素（例如，购物收据）除属于同一单位外，没有任何特定关系。换句话说，挖掘单元的元素是同类的。然而，在程序元素之间，通常存在各种语义关系，例如数据依赖性。忽略这样的关系可能会导致许多不感兴趣的规则由语义上独立的元素组成，这些元素实际上并没有相互抑制，而是偶尔出现在一起。</p></li><li><p>大型项目通常包含一定数量的通用API，几乎可用于所有编程环境，例如Linux中的printk和isalpha。它们可能巧合地与其他操作配对以形成关联规则。即使考虑到挖掘期间的强语义关系（例如，数据依赖性），这些API仍然可能导致许多负面无趣的规则。实际上，API越普遍，它与其他操作的相互抑制就越少。</p></li></ol><p>基于以上见解，我们如下缓解规则爆炸问题。 （1）考虑到如上所述的程序元素的本质，我们将规则挖掘集中在具有强语义关系（例如，数据依赖性）的程序元素上，以尽可能地减少不感兴趣的规则。 （2）我们使用信息熵来衡量API的普遍性，并用它来排列挖掘的候选负面规则。涉及高普遍性API的不感兴趣规则将被排除在最终审计之外。</p><h2 id="3-3数据准备"><a href="#3-3数据准备" class="headerlink" title="3.3数据准备"></a>3.3数据准备</h2><p>NAR-Miner将程序元素转换为事务并将它们存储到数据库中。在本文中，我们关注两种程序元素：函数调用和条件检查，因为许多错误是由函数或条件错误引起的[1,6,21,26,33,38,47,57]。如前所述，我们的目标是从事务中提取负关联规则，其元素具有强大的语义关系。如果它们之间存在数据关联，我们定义两个元素以具有强大的语义关系，包括数据依赖性和数据共享[7]。详细地说，给定两个语句s1和s2，如果s2使用s1中定义的值（即数据依赖），或者它们都出现在同一个执行路径上并使用相同的非常量值（即数据共享），我们说他们在语义上有很强的相关性。程序元素的语义关系通过数据流分析[3,15]来识别。</p><p>NAR-Miner的预处理器建立在GCC（v4.8.2）前端之上，该前端以SSA形式[12]提供控制流图和中间表示，用于数据流分析。图3（a）显示了一段代码，图3（b）显示了相应SSA形式的中间表示。 NAR-Miner可以判断is_valid，foo和bar是依赖于第2行的read2的数据。由于is_valid和foo在同一个执行路径中，因此它们具有数据共享关系。因为foo和bar之间没有路径，所以它们不被认为是语义相关的。</p><p>为了简化挖掘阶段，然后将中间表示转换为事务数据库。每个函数定义都映射到一个事务。事务由两部分组成：程序元素和这些元素之间的一组语义关系。在转储到数据库之前，每个程序元素都被规范化。函数调用用不带参数的函数名表示;如果条件语句中的变量保留某些函数的返回值，或者在其他情况下保留其数据类型，则使用“RET”重命名，如许多挖掘方法[6,7,25,26,57,58]中所做的那样。例如，图3中的条件表达式归一化为“RET == 0”。两个程序元素之间的语义关系表示为事务中的元组。例如，元组（foo，is_valid）表示函数foo和is_valid具有一些语义关系。图3（c）显示了代码片段的语义关系，其中节点表示程序元素，边缘表示关系（黑线表示数据依赖性、红线表示数据共享）。</p><p>我们将每个程序元素映射到一个唯一的整数，因此挖掘被应用于整数集以提高性能，因为大量的字符串等价比较是耗时的。</p><p><img src="/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/3.png" alt=""></p><h2 id="3-4提取频繁和不频繁的项集"><a href="#3-4提取频繁和不频繁的项集" class="headerlink" title="3.4提取频繁和不频繁的项集"></a>3.4提取频繁和不频繁的项集</h2><p>很少调用的程序元素总是很少与其他程序元素一起出现，并且会导致大量的负面模式。然而，这些模式在统计学中毫无意义[56]。因此，我们专注于挖掘负面模式，这些模式的元素经常单独出现但很少发生在一起。对于负关联规则A⇒¬B，其前因（即A）和后续（即B）是频繁的，但它们的组合（即（A∪B））是不频繁的。在本节中，我们将提出我们的算法来提取有趣的频繁和不频繁的项集，并将在下一节中解释如何生成否定规则。</p><p>提取频繁和不频繁项集的现有算法仅依赖于事务数据库中项集的出现[43,46,61]。他们都没有考虑元素之间的语义关系。直接将它们应用于§3.3中生成的数据库将导致大量无趣的规则。据我们所知，没有不常见的项集挖掘算法可以直接应用于我们的工作中。为了解决这个问题，我们设计了一个语义约束的挖掘算法，该算法侧重于提取与语义相关的强项集。强语义相关项集中的元素在语义上都彼此相关，例如，具有数据依赖性或数据共享关系。</p><p>我们基于众所周知的Apriori算法[2]设计我们的算法，该算法应用自下而上的方法通过将较小的频繁项目集合在一起来生成相对较大的候选项集。自下而上方法背后的原则是Apriori属性：频繁项集的任何子集也是频繁的。在我们的例子中，强语义相关项集的任何子集也与强语义相关，因为子集中的任何两个元素必须在语义上相关。因此，强大的语义相关项集也符合Apriori属性，可以自下而上的方式挖掘。</p><p>算法1中显示了我们挖掘频繁和不频繁的强语义相关项集的算法。除了事务数据库，它还要求用户指定两个参数：最小频率支持mfs和最大频率支持mis。如果项集的支持大于或等于mf s，则认为项集是频繁的，如果项集的支持小于或等于mis，则项集是不频繁的。算法的输出是所有频繁项目集（FI）和感兴趣的不频繁项目集（IIs）。</p><p><img src="/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/4.png" alt=""></p><p>在开始时，算法扫描事务数据库以找出所有频繁的1项集（第3行）。然后它试图从频繁的（k-1）-itemsets（第4~14行）中发现频繁且不频繁的k-项集。 k项目集包含k个项目。首先，它通过连接频繁（k-1）-项来生成感兴趣的候选k项集（参见第5行）。如果它们具有k-2个共同项，则可以连接两个（k-1）-itemsets。假设两个可连接（k-1）-itemsets是{i1，…，ik-2，ik-1}和{i1，…，ik-2，ik}，则连接结果是k-itemset {i1，…，ik-2，ik-1，ik}。其次，该算法利用Apriori属性来修剪具有不频繁子项集的k项集（第6行）。之后，调用函数count_support来计算每个k-itemset的支持（第8行）。如果项目集的支持不小于mfs，则将项目集插入Lk（第10行），即一组频繁的k项目集;否则，如果它的支持不大于mis，则将其插入不频繁的k项集Nk集（第12行）。应该注意，支持为0的项集自然会被忽略。 Lk和Nk分别与FI和IIs（第15行）合并。然后，频繁项目集Lk用于生成更大的项集Lk + 1和Nk + 1。当Lk对于某个k为空时，算法终止，并输出收集的频繁/不频繁项集（第17行）。</p><p>函数count_support扫描数据库以计算项集I的支持（第19~27行）。如果事务支持I（第23行），计数器将增加1。当且仅当它包含I中的所有项目以及所包含项目之间的所有可能关系时（表示为关系（I）），事务支持I。例如，图3中的事务支持itemset {foo，is_valid}，因为它不仅包括两个项foo和is_valid，还包括它们之间的语义关系，即元组（foo，is_valid）。但是，事务不支持itemset {foo，bar}，因为它不包含元组（foo，bar）。</p><p>为了挖掘像{kfree}⇒¬{kfree}这样的规则，我们还提取了像{g，g}这样的2项集，其中g经常被调用，但是在同一函数中它的两个调用实例在语义上很少相关。这有助于NAR-Miner找到表2中的错误14＃（参见§4.2.3）。</p><h2 id="3-5生成负关联规则"><a href="#3-5生成负关联规则" class="headerlink" title="3.5生成负关联规则"></a>3.5生成负关联规则</h2><p>负关联规则A⇒¬B意味着两个频繁项集A和B很少出现在同一事务中。也就是说，（A∪B）很少见。事实上，规则的前因和后果实际上是不常见的项目集的不相交分区。一种直接的负关联规则生成方法是从不频繁的项集I中找出所有对，如&lt;A，B&gt;，其中A∪B= I且A∩B=∅。它使用规则A⇒¬B的统一来确定其不频繁。这种说法的定义如下：</p><p><img src="/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/5.png" alt=""></p><p>其中，支持（A∪¬B）是支持A∪¬B，支持A但不支持A∪B的事务数量。因此，我们有支持（A∪¬B）=支持（A）-支持（A∪B）=支持（A）-支持（I），其中I =A∪B。因此，等式1可以改写为：</p><p><img src="/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/6.png" alt=""></p><p>从具有n个元素（n≥2）的不频繁项集I中，通过直接应用上述方法可以生成最多2个（n-1）个负关联规则。但是，对它们的违反是完全相同的，即支持项目集I的事务。因此，在面向错误检测的应用程序中仅跟踪它们中的一个就足够了。注意，从编程的角度来看，规则A⇒¬B意味着B中的元素不应出现在包含A的上下文中。如果反转规则B⇒¬A不感兴趣，则其违规总是误报，因为存在B并不意味着拒绝A.受此启发，在几乎所有情况下，如果我们期望支持不频繁项集I的事务成为真正的错误，那么从I派生的所有负关联规则应该是有趣的。因此，我们可以选择具有最低置信度的规则来表示这些规则。将置信度作为衡量标准，其他规则如果有趣则会很有趣。</p><p>实际编程中的逻辑通常非常复杂。一些挖掘的规则可能不适用于编程实践。根据它们检测到的违规通常是误报。一般方法是对挖掘的规则进行排名，使得有趣的规则排名最高，而无趣的规则排在最低位。现有工作主要根据他们的置信度对规则进行排名（高信任规则排名最高）。然而，这种信任仅反映了几个有限元素之间的（负/正）相关性。实际上，编程规则的有趣性也与其元素是否集中在某些上下文有关。也就是说，如果元素的调用上下文趋向于更加同类，则由它组成的规则更可能是有趣的。否则，如果元素在非常不同的上下文中使用，则它更通用，并且更可能与各种元素一起出现。在本文中，我们使用一般性来表明元素的上下文有多不同。一般而言，规则由具有高一般性的元素组成，更可能是无趣的元素。</p><p>我们引入信息熵来定量测量元素的一般性。对于程序元素g的调用实例，我们通过g依赖的元素和依赖于g的元素两个来描述它的上下文。我们在g的所有调用实例中提取这些元素并将它们放入包中。包的信息熵反映了调用实例的不同，可以用来衡量g的一般性。包的信息熵（表示为H（g））可以通过等式3计算:</p><p><img src="/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/8.png" alt=""></p><p>其中pi是包中第i个元素的频率; N是g的调用实例数。项集的熵是每个元素的熵的总和。</p><p>根据每个程序元素的一般性，负关联规则R的兴趣度可以测量为：</p><p><img src="/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/10.png" alt=""></p><p>其中H（gi）是元素gi的信息熵。</p><p>我们在算法2中形成了生成负关联规则的方法。该算法将§3.4中提取的频繁项集FI和不频繁项集II以及用户指定的阈值min_conf作为输入。它返回负关联规则NARs的集合。它首先为具有最低置信度的每个不频繁项集I生成代表性规则（第3~5行）。从等式2可以看出，A的支持越小，A⇒¬B的置信度就越低。因此，我们选择支持最小的I子集来生成代表性规则。然后，计算规则的置信度（第6行）并根据阈值min_conf（第7行）进行检查。信息熵用于衡量潜在有趣规则的兴趣（第10行）。最后，负关联规则按其兴趣的降序排序。</p><p><img src="/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/11.png" alt=""></p><h2 id="3-6检测违规行为"><a href="#3-6检测违规行为" class="headerlink" title="3.6检测违规行为"></a>3.6检测违规行为</h2><p>违反负关联规则R：A⇒¬B的是那些支持项集A∪B的事务。直接的方法是直接扫描数据库以找出包含项集A和B的所有事务。但是，这样的枚举方法这非常耗时，特别是对于拥有数十万事务的数据库而言。为了加快检测过程，我们采用了PR-Miner [25]中使用的技巧。在生成频繁且不频繁的项目集时，NAR-Miner还会收集支持它们的事务。我们使用支持者（I）来指示支持项集I的所有事务。然后，违反负关联规则R的集合恰好是支持者（A∪B）。</p><h1 id="4-评估"><a href="#4-评估" class="headerlink" title="4.评估"></a>4.评估</h1><h2 id="4-1实验设置"><a href="#4-1实验设置" class="headerlink" title="4.1实验设置"></a>4.1实验设置</h2><p>我们将NAR-Miner实现为原型系统，以检测大规模C程序中的错误。我们在众所周知的Linux内核（v4.12-rc6）上评估NAR-Miner。 Linux内核已被广泛用作基于挖掘的错误检测方法的评估目标（TOE）[6,14,20,20,22,24-26,30,42,46-48,57,60]。选择Linux内核作为我们的目标的主要原因是我们想要通过检测以前工作中找不到的一些真正的错误来检查我们方法的有效性。 Linux-v4.12-rc6是实验时的最新版本。它包含24,919个C和19,295个标题文件，包括376,680个函数和15,501,651行代码（LoC）。</p><p>为了验证NAR-Miner是否可以应用于其他系统中的错误检测，我们还从不同的域中选择了三种流行的大型C系统：PostgreSQL v10.3，OpenSSL v1.1.1和FFmpeg v3.4.2。 PostgreSQL是一个开源数据库，OpenSSL是一个用于安全通信的库，FFmpeg是一个用于编码/解码多媒体文件的框架。许多错误检测方法选择它们作为评估的目标[19,20,25,35,57]。</p><p>NAR-Miner需要指定三个参数：（1）频繁项集的最小支持阈值（即mfs），（2）不频繁项集的最大支持阈值（即mis），以及（3）有趣的负面规则最小置信度阈值（即min_conf）。通常，如果项目集是具有较高支持的频繁项目集或具有较低支持的不频繁项目集，则项目集将更有趣。此外，较高的最低限度可以进一步消除无趣的负面规则。实际上，不同的参数设置可能导致无法报告某些实际错误或产生过多的错误警报。用户可以保守地或积极地根据检测策略调整这些参数。为了确定合理的参数，我们进行了[6,25,26,49,60]中的实证研究。具体而言，通过抽样分析，当排名前10位的负面规则中有一半以上是有趣的规则时，参数设置被认为是可接受的。在这项研究中，我们将mf设置为15，将mis设置为5，将min_conf设置为85％。在我们的实验中，默认参数设置适用于四种不同的TOE（参见§4.2和§4.3）。</p><h2 id="4-2检测Linux内核中的错误"><a href="#4-2检测Linux内核中的错误" class="headerlink" title="4.2检测Linux内核中的错误"></a>4.2检测Linux内核中的错误</h2><h3 id="4-2-1预处理源代码"><a href="#4-2-1预处理源代码" class="headerlink" title="4.2.1预处理源代码"></a>4.2.1预处理源代码</h3><p>NAR-Miner花了大约77分钟来解析内核源代码并将其转换为事务数据库。在所有函数定义中，有333,248个函数包含一些程序元素（即函数调用或条件检查）。转换后，每个函数定义都映射到数据库中的事务。该数据库包括227,246个不同的元素，其中每个元素对应于函数调用或条件检查。其中，6,203个频繁出现在多个事务中。</p><h3 id="4-2-2挖掘负面规则的有效性"><a href="#4-2-2挖掘负面规则的有效性" class="headerlink" title="4.2.2挖掘负面规则的有效性"></a>4.2.2挖掘负面规则的有效性</h3><p>为了评估包含语义约束规则挖掘和基于信息熵的规则排序的方法的有效性，我们进行了三个实验：NAR-Miner–，NARMiner-，NAR-Miner。每个实验中采用的方法解释如下：</p><ol><li><p>NAR-Miner–：挖掘算法不考虑项目之间的语义关系，挖掘的规则根据其对应性进行排序;</p></li><li><p>NAR-Miner-：基于NAR-Miner–，项目之间的语义关系被用作约束来消除弱语义相关项集;</p></li><li><p>NAR-Miner：基于NAR-Miner-，我们引入信息熵来衡量负关联编程规则的趣味性。该实验评估了NAR-Miner的全部功能。</p></li></ol><p>我们在表1中显示了实验结果，包括频繁项目集（#FI），不频繁项目集（#IIs）的数量，推断的负关联规则的数量，检测到的违规数量以及挖掘，排名和检测的时间成本（时间）很快。</p><p>比较NAR-Miner–和NAR-Miner-或NAR-Miner的结果，我们观察到采用语义约束的挖掘减少了一个数量级的规则和违规总数（＃All列减少约88％） ）。规则爆炸问题在很大程度上得到了缓解。</p><p>由于时间有限，我们在每个实验中手动检查200个排名靠前的负关联规则。这些规则按照他们在NAR-Miner–和NAR-Miner-中的可信度排名，而他们在NAR-Miner中的兴趣则排名靠前。负关联规则如果真的很有意义则标记为“True”，违反它会导致错误或质量问题。例如，{free_netdev}⇒¬{kfree}是一个有趣的（“True”）规则，因为违反它将导致潜在的双重释放错误，例如§2中讨论的错误。在NAR-Miner中，前200条规则中只有2条被认为是有趣的规则。换句话说，其中99％导致违规检测的错误警报。这种有趣规则率低的主要原因是由这些规则组成的程序元素通常在语义上彼此独立。对于下面的例子，虽然在NAR-Miner中排名第一，并且具有99.96％的置信度，但规则{static_key_false}⇒¬{atomic_read}是无趣的，因为这两个函数将完全独立的变量作为包含他们的程序中的实际参数，他们并没有真正压制对方。</p><p><img src="/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/12.png" alt=""></p><p>引入语义约束的挖掘将NAR-Miner-中的误报率降低到90.5％，然而，这仍然太高而不能在实践中被接受。虽然推断规则具有语义相关的所有程序元素，但是一些元素非常通用，并且可以在违规不会导致错误的各种上下文中使用。例如，函数iowrite32是在它们一起出现时依赖于readl的数据，在Linux内核中只出现一次，并且推断出规则{iowrite32}⇒¬{readl}。该规则在NAR-Miner-中排名第8位，并且在99.64％的情况下排名第一，但仍然无趣，因为这两种功能都以各种方式使用，并且它们的组合不会导致任何错误。</p><p>NAR-Miner使用信息熵来测量函数的一般性。 iowrite32和readl分别为5.9和4.6。规则{iowrite32}⇒¬{readl}的有趣性是9.5％，小到足以排名低。以这种方式，大多数不感兴趣的规则被分配低兴趣度值并因此被排在底部，同时潜在有趣的规则被分配具有相对高的兴趣度值并且在顶部排名。在NAR-Miner中，前200个负面规则中有93个标记为“真”，几乎是NAR-Miner-中数字的5倍。特别是，在前50个中有31个“真正的”负规则。真阳性率为62％。也就是说，我们可以在不到两次手动审计中找到一个有趣的规则，这在实际的错误检测中是可以接受的，而不是针对Linux内核等真实的大型系统。</p><p>我们还检查了违反前200条推断规则的情况。从表1中的Violations和#Bugs列中，我们观察到更多报告的违规和由于应用基于语义约束的挖掘和基于信息熵的排序而导致的错误，这最终增强了NAR-Miner的能力，使其能够推断出更多有趣的规则（列#True和TP Rate）</p><p><img src="/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/13.png" alt=""></p><p>4.2.3检测违规行为</p><p>针对NAR-Miner提取的21,166个负关联规则，检测到37,453个违规。我们根据规则的排名手动检查报告的负关联规则及其违规。为了从检测中获得最大的收益，我们选择排名靠前的规则进行审核，因为违反这些规则更可能是真正的错误。我们在一个人一天内检查了200个排名靠前的负面关联规则和相应的356个违规行为（参见表1中的最后一行）。</p><p>我们发现了23个可疑错误和数十个程序质量问题，例如冗余条件检查和计算。由于Linux内核维护者经常忽略质量问题，我们只向Linux内核维护者提交23个可疑错误的补丁。到目前为止，这些补丁中有17个已经被内核维护者所认可和接受。</p><p>表2中列出了确认的bugs，其中包含错误（函数），违反的规则（违规规则）以及三个实验中的规则排名。最后一列显示了这些bug的补丁ID和我们在PatchWork站点上的补丁。在这些发现的bug中，六个（2＃，3＃，8＃，12＃，13＃和14＃）在内核2.6中出现，两个（3＃和12＃）甚至潜伏了10年以上。</p><p><img src="/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/14.png" alt=""></p><p>这些bug总共违反了12个负关联规则。如果按照排名进行排名，则只有其中一个在前200条规则范围内（NAR-Miner-列中为12＃）。但是使用信息熵对规则进行排名会使所有这些规则都进入前200名（NAR-Miner）。这一观察结果表明，将信息熵引入排名对于突出有趣的规则非常有用。我们还观察到这些规则中只有2个是在NAR-Miner–中提取的（“NA”表示没有命中），其他规则都缺失。例如，缺少规则{free_netdev}⇒¬{kfree}（12＃），因为有106个函数同时调用free_netdev和kfree。在不考虑语义关系的情况下，项集{free_netdev，kfree}的支持是106，这远远高于预定阈值mis = 5。</p><p>因此，它不会被视为不常见的项目集，因此无法推断出负关联规则。然而，凭借语义约束的挖掘和信息熵，NAR-Miner成功地推断出规则并发现相应的错误（图1）。因此，我们声称语义约束的挖掘不仅可以帮助减少误报，还可以减少误报。</p><h3 id="4-2-4与基于正规则挖掘的方法的比较"><a href="#4-2-4与基于正规则挖掘的方法的比较" class="headerlink" title="4.2.4与基于正规则挖掘的方法的比较"></a>4.2.4与基于正规则挖掘的方法的比较</h3><p>在实践中，违反负规则的某些错误也可能违反相应的积极规则。因此，应该通过基于负面和正面规则挖掘的方法来检测这样的错误。我们调查是否会发生这种情况。我们选择表2中的17个错误作为基线，进行另一个实验，从§4.2.2中挖掘出的266,449个频繁项目集中使用与NAR-Miner相同的mfs和min_conf设置来推断出正关联规则，然后检测违规规则，如[25]和[26]中所做的那样。手动检查显示检测到17个错误中的3个（表2中的2＃，3＃和15＃），而其他14个错误（约82.4％）丢失。然后，我们使用语义约束的挖掘来增强基于正规则挖掘的方法，即考虑程序元素之间的数据关系。发现了另外两个错误（5＃和14＃），但仍有12个错误（约70.6％）未被发现。因此，我们声称虽然语义约束的挖掘能够帮助基于正规则挖掘的方法检测更多错误，但基于负规则挖掘的方法可以专门发现许多基于正规则挖掘的方法无法实现的错误。</p><h2 id="4-3检测其他系统中的bug"><a href="#4-3检测其他系统中的bug" class="headerlink" title="4.3检测其他系统中的bug"></a>4.3检测其他系统中的bug</h2><p>NAR-Miner进一步应用于PostgreSQL v10.3，OpenSSL v1.1.1和FFmpeg v3.4.2。 NAR-Miner分别从PostgreSQL，OpenSSL和FFmpeg中提取了690,382和335个负面规则。我们在§4.2中手动检查排名靠前的负面规则（不超过50个）及其在每个系统中的违规行为。因此，我们确定了六次违规（每个目标两次），并将其报告给相应的社区。到目前为止，所有六个可疑错误都被相应的系统维护人员修复了。有关详细信息，请参阅邮件列表[41]中PostgreSQL的错误报告，ID为＃15104和＃15105，OpenSSL来自问题列表[40]，ID为＃5567和＃5568，以及来自邮件列表的FFmpeg [39] ID为＃7074和＃7075。实验证明NAR-Miner不限于特定的目标系统（例如，Linux内核），而是可以用于在各种大规模C系统中发现真正的错误。</p><h2 id="4-4案例研究"><a href="#4-4案例研究" class="headerlink" title="4.4案例研究"></a>4.4案例研究</h2><p>在本节中，我们将说明NAR-Miner的能力与基于肯定关联规则（PAR）挖掘的方法在PostgreSQL中的＃15105问题上进行比较。</p><p>在PostgreSQL中，函数OpenTransientFile分配一个文件描述符并将其存储到全局维护的已分配文件列表中。返回描述符必须与CloseTransientFile一起释放，它会在关闭之前从列表中删除描述符。直接使用close会使列表保留已发布的描述符，并可能导致释放后使用的错误。从统计上来说，在PostgreSQL v10.3中，OpenTransientFile在28个函数中被调用。在27个函数中，其返回值传递给CloseTransientFile，但在1函数中，其返回值直接传递给close，从而产生负关联规则{OpenTransientFile}⇒¬{close}和正关联规则{OpenTransientFile}⇒{ CloseTransientFile}具有相同的96.4％的置信度。</p><p>图4显示了函数dsm_impl_mmap，该函数错误地将在第4行用OpenTransientFile分配的文件名描述符fd传递给沿路径的第12行关闭。它违反了上述负面规则，因此被NAR-Miner报告。但是，从伴随分析的角度来看，因为在某些路径上，fd在第8和第16行正确传递给CloseTransientFile，这符合上述正规则的要求。因此，有缺陷的代码确实是支持而不是违反规则。我们通过用CloseTransientFile（fd）替换第12行来解决这个问题，如图4所示。修补程序已经被维护者接受了</p><p><img src="/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/15.png" alt=""></p><h1 id="5-讨论和限制"><a href="#5-讨论和限制" class="headerlink" title="5.讨论和限制"></a>5.讨论和限制</h1><p><strong>负面规则与正面规则</strong>。在本文中，我们主要基于负关联规则而不是正关联规则来检测错误。但是，这两种方法没有必要的矛盾。由于他们专注于不同类型的编程规则，因此它们可以相互补充。从错误检测的角度来看，我们的方法能够提取负面的编程规则并检测基于挖掘正关联规则的方法无法揭示的错误，反之亦然。理论上，两种方法的组合可以表现出更好的检测性能（更少的漏报率）。</p><p>此外，与挖掘积极规则相比，挖掘负面规则通常伴随着产生更多无趣的规则，导致大量的误报。在这种情况下，同一程序的积极规则可以帮助减少它们。例如，如果一段代码违反了否定规则但满足了正规则，则相应的负面规则的违反不太可能成为真正的错误。我们可以降低其排名以避免这种违规行为。类似地，基于正规则的错误检测也可能面临相同的挑战（即，报告误报）。因此，在这种情况下，一个直截了当的问题是，这两种方法是否有助于减少误报？我们将在未来进一步研究。</p><p><strong>规则爆炸</strong>。实质上，负关联规则挖掘中的规则爆炸问题无法完全解决。在本文中，我们采用了一种相对直接的方法。具体来说，我们利用元素之间的语义关系来消除挖掘过程中绝大多数不感兴趣的规则，然后使用信息熵来衡量规则的有趣性，以便进一步突出显示潜在的有趣规则。但是，可能存在多种解决方案。例如，我们可以进一步量化程序元素之间的语义关系的强度，以重新改善挖掘结果。除了数据依赖和数据共享关系之外，还可以利用其他关系，例如控制流关系。这些潜在的改进可以进一步缓解规则爆炸问题，从而降低手动审计效率。这也是我们未来的工作之一。</p><p><strong>挖掘算法</strong>。在本文中，我们采用项集挖掘算法来提取负编程规则。实际上，对于某些类型的编程规则，其他形式的表示和挖掘算法可能更合适。例如，使用序列来表示顺序敏感的编程逻辑[1,29,53,55]比使用项目集更合适。然而，基于序列的算法在发现对顺序不敏感的编程逻辑方面具有较差的鲁棒性。如果我们能够有效地确定编程模式是否对顺序敏感，则可以采用目标算法来挖掘相关规则。这将是我们未来的工作之一。</p><h1 id="6-相关工作"><a href="#6-相关工作" class="headerlink" title="6.相关工作"></a>6.相关工作</h1><p>程序分析已被广泛而成功地用于错误发布。例如，模型检查可以使用目标系统的模型和规范自动验证有限状态系统的正确性属性[10]。由于为目标系统编写模型的成本很高，因此开发实验级模型检查器并在系统代码中发现实际错误[32,59]。研究人员还利用程序分析来检测违反特定规则的行为。通常，向工具提供一组编程规则，其静态地或动态地检查目标系统是否违反给定规则。 Pasareanu和Rungta开发了SPF，通过将符号执行引入到模型检查中来生成Java程序的测试用例[37]。恩格勒等人。提出了使用系统特定编译器扩展[13]静态检查系统规则的技术，而FindBugs作为独立工具运行，以检查Java字节码中错误模式的出现[11]。 Livshits和Lams [28]将用户提供的漏洞规范转换为静态分析器，并使用它们来检测用Java编写的Web应用程序中的漏洞，例如SQL注入和跨站点脚本。此外，Molnar等人。利用动态测试生成来检查二进制程序中的整数错误，检查特定断言的违规情况[31]。尽管它们在解决错误方面取得了成功，但这些方法在很大程度上取决于系统的模型或错误的模式，例如高级API语义[50]，我们称之为先验知识。没有这种知识，他们就无法发现错误。相反，我们的工作会自动发现知识，然后根据收集的知识检测错误。</p><p>还提供了可以从目标系统自动提取知识的技术。 Engler等人提出的先驱工作。采用统计分析来推断给定规则模板的时间规则，检测错误而不指定具体规则[14]。 Kremenek等人使用因子图通过结合不同的信息来源推断程序的规范[22]。这两种方法仅限于推断具有预定模板的规则和必须由用户提供的特定知识。一些方法依赖于挖掘规则中的某些领域知识，并且专门用于推断关键API [1,16,36,49,53,55]或安全敏感函数[47,58]的规则。它们还要求用户提供领域知识以促进挖掘过程。但是，NAR-Miner在根据程序中包含的关联规则（隐式）提取规则时不需要用户提供先验知识。</p><p>最近，研究人员利用数据挖掘算法从真实的大型系统中提取更多一般规则[4,7,8,21,23-25,27,29,30,33,34,44,54,58]。这些基于挖掘的技术背后的首要思想是：在大多数情况下，程序是正确的，因此任何异常都可能是错误。通常，这些方法首先推断出来自目标系统的频繁出现的模式，并将这些模式视为开发人员在编码时应遵循的（隐式）规则。然后，他们发现任何违反这些规则的行为都是潜在的错误。推断的模式可以是正面的也可以是负面的。例如，PR-Miner [25]和AntMiner [26]提取了强制关联规则，强制配对表面的程序行为。Chang等通过从程序控制流中挖掘频繁关联的子图并检查偶发违规来检测缺失的代码结构[7]。 Yun等。根据不同API之间挖掘的语义正关联规则推断出API的正确用法[60]。与这些方法不同，NAR-Miner专注于从源代码中挖掘负关联规则，并检测违反这些规则的错误。也可以从动态执行跟踪中提取类似的规则。Beschastnikh等开发了Synoptic，从系统执行日志中生成时间系统不变量[5]。</p><p>Wang等人开发了Bugram，它使用n-gram语言模型来测量令牌序列的概率，并将低概率序列视为异常，即潜在的错误[52]。Bugram还可以检测由相互抑制的程序元素共同引起的某些错误。但是，由于序列窗口的大小有限，Bugram很难捕获涉及长距离程序元素的错误。</p><p>挖掘负关联规则已应用于购物篮，蛋白质序列和金融数据等数据[18]。对于这样的数据，两个元素之间的关系比对关系贡献不同强度的程序元素的关系简单得多。Wu等人提出了算法，以有效和高效地挖掘大型数据库中的负关联规则[56]。Zhou和Yau提出了一种组合算法来挖掘有趣的关联规则，减少了大量的否定规则[61]。NAR-Miner也可以采用这些算法作为基本挖掘算法，但需要处理程序语义以减少不感兴趣的规则。</p><h1 id="7-结论"><a href="#7-结论" class="headerlink" title="7.结论"></a>7.结论</h1><p>数据挖掘技术已广泛用于推断编程规则，然后根据规则检测软件错误。现有方法已经证明，正关联规则（表明相关的程序元素必须一起出现）对于通过检查违规来检测错误是有用的。然而，拒绝所涉及的程序元素的共同出现的负关联规则大多被忽略。我们提出NAR-Miner从源代码中挖掘负关联规则。我们引入程序语义来指导挖掘阶段。我们还利用函数熵对候选规则进行排名并突出显示有趣的规则。通过这种方式，NAR-Miner显着减少了不感兴趣的规则的数量，并在一定程度上缓解了规则爆炸问题。我们在四个流行的大型系统上评估原型，并发现了相当多的错误，其中一些已被维护者所困扰。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h1&gt;&lt;p&gt;从基于数据挖掘技术的源代码推断编程规则已被证明对检测软件错误是有效的。现有研究侧重于以A⇒B
      
    
    </summary>
    
      <category term="论文" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/"/>
    
      <category term="数据挖掘" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"/>
    
    
      <category term="2018年" scheme="http://yama0xff.com/tags/2018%E5%B9%B4/"/>
    
      <category term="数据挖掘" scheme="http://yama0xff.com/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"/>
    
      <category term="漏洞检测" scheme="http://yama0xff.com/tags/%E6%BC%8F%E6%B4%9E%E6%A3%80%E6%B5%8B/"/>
    
      <category term="源代码" scheme="http://yama0xff.com/tags/%E6%BA%90%E4%BB%A3%E7%A0%81/"/>
    
  </entry>
  
  <entry>
    <title>Superset Disassembly: Statically Rewriting X86 Binaries Without Heuristics Disassembly</title>
    <link href="http://yama0xff.com/2019/01/27/Superset-Disassembly-Statically-Rewriting-X86-Binaries-Without-Heuristics-Disassembly/"/>
    <id>http://yama0xff.com/2019/01/27/Superset-Disassembly-Statically-Rewriting-X86-Binaries-Without-Heuristics-Disassembly/</id>
    <published>2019-01-27T07:33:23.000Z</published>
    <updated>2019-01-28T09:17:13.234Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>静态代码重写是系统安全应用的一项核心技术，它的使用场景包括性能分析，优化和软件错误定位等。之前的许多静态二进制程序重写方法，例如CCFIR, PITTSFIELD, Google’s Native Client, BinCFI, UROBOROS等，在保证重写正确时，提出了有关二进制程序的许多假定，例如完全正确的反汇编，编译器要求，调试符号等等，给实际应用在Commercial off-the-shelf（COTS）二进制程序上制造了困难。作者提供了<code>multiverse</code>，一个新的二进制程序重写器，它不基于上述的任何假定并能够重写intel x86 COTS程序。在COTS二进制程序重写中，存在着两大挑战： （1）如何反汇编二进制代码并包含所有合法指令 （2）如何重新汇编重写后的指令并保留原程序的语义。<strong><code>multiverse</code>使用了两种技术分别解决这两大挑战：（1）superset disassembly：通过对所有offset起始的地址进行反汇编获得合法代码的superset。 （2）instruction rewriter：通过替换控制流转移指令，中转到一个映射表，能够将原程序中所有的指令重定位到任意其他位置。</strong></p><table><thead><tr><th><strong>论文相关信息：</strong></th></tr></thead><tbody><tr><td><em>作者</em>：Erick Bauman，Zhiqiang Lin，Kevin W. Hamlen 单位：University of Texas at Dallas.</td></tr><tr><td><em>单位</em>：University of Texas at Dallas</td></tr><tr><td><em>出处</em>：NDSS’18</td></tr><tr><td><em>原文地址</em>： <a href="https://github.com/wtwofire/database/blob/master/papers/reverse/2018-Superset%20Disassembly%EF%BC%9AStatically%20Rewriting%20x86%20Binaries%20Without%20Heuristics.pdf" target="_blank" rel="noopener">https://github.com/wtwofire/database/blob/master/papers/reverse/2018-Superset%20Disassembly%EF%BC%9AStatically%20Rewriting%20x86%20Binaries%20Without%20Heuristics.pdf</a></td></tr><tr><td><em>源码地址</em>：<a href="https://github.com/utds3lab/multiverse" target="_blank" rel="noopener">https://github.com/utds3lab/multiverse</a></td></tr><tr><td><em>发表时间</em>：2018年</td></tr></tbody></table><h1 id="背景与概述"><a href="#背景与概述" class="headerlink" title="背景与概述"></a>背景与概述</h1><p>作者的目的是为了发展一种二进制转化方法，改善现有二进制程序转化方法的实用性和通用性。为了表达简洁，也因为x86的程序更少开源。同时之前的许多代码转化方法也以x86程序为目标，作者的方法集中与主流编译器编译的linux 32位x86程序，同时不适用dlopen等动态载入库和自修改代码。</p><h2 id="挑战"><a href="#挑战" class="headerlink" title="挑战"></a>挑战</h2><p>在编写一个通用的二进制程序重写器时存在着许多挑战：</p><p><strong>C1</strong>：识别和重定位静态内存地址 编译后的二进制程序代码包含许多固定地址，很多指向全局变量。代码重写在移动这些目标时，必须同时更新它们的引用。在反汇编代码中和地址段中识别这些地址常量是非常困难的，因为整数值和这些地址常量在语法上并没有明显的区别。</p><p><strong>C2</strong>：处理动态计算的内存地址<br>在程序中还存在许多动态计算的内存地址。由于地址计算方式比较复杂，生成间接控制流转换表(iCFT)非常困难。重映射iCFT对于二进制程序重写是一个核心挑战。</p><p><strong>C3</strong>：区分代码和数据<br>代码和数据在二进制文件中没有语法上的区别，在现代处理器中，为了优化性能，许多数据被放在代码段中。这给反汇编带来一些困难。</p><p><strong>C4</strong>：作为参数的函数指针<br>作为函数指针的参数如果在目标函数中没有正确识别并且更新到改写后的地址，那么重写后的程序在执行时很可能会调用已经被之前的函数地址，令执行失败。同时，识别函数地址也非常困难。</p><p><strong>C5</strong>：处理位置无关代码<br>主流编译器生成了许多位置无关代码。这些代码会根据自身地址和相对位置寻找其他的执行代码。如果改变了它们的相对位置，那么在执行时就有可能失败。</p><h2 id="核心想法"><a href="#核心想法" class="headerlink" title="核心想法"></a>核心想法</h2><p>基于之前的二进制重写方法，作者系统化了下面的这些想法来针对性地解决上面的挑战</p><p><strong>S1</strong>：保持原有数据空间的完好无损<br>保持程序中数据段原有的位置和内容，这个方法之前也被用在许多二进制重写器中，例如SECONDWRITE和BINCFI</p><p><strong>S2</strong>：创建一个从原有代码空间到新的重写代码空间的映射<br>作者在这个映射中忽略常用的地址计算中 基址+偏移 的方法，只考虑最后获得的最终地址，并将这个地址与重写后的代码地址进行对应。作者对于原有地址空间中的每个代码段地址都找到了一个映射，这样就简单的解决了动态计算的内存地址问题。</p><p><strong>S3</strong>：暴力反汇编所有可能的代码<br>为了解决反汇编可能存在缺失的问题，作者对于从代码段开始的每个偏移，都进行了反汇编直到遇上非法指令，或者已经反汇编过的地址。原程序中执行的所有代码必定是暴力反汇编获得的代码的子集。</p><p><strong>S4</strong>：重写所有用户级别的代码<br>通过重写所有用户级别的代码，可以在函数指针被调用处利用原程序与重写程序之间的地址映射，将指向原程序地址空间的函数指针映射到重写后的地址空间。</p><p><strong>S5</strong>：重写所有call指令以解决pic代码 在查看了x86指令集后，所有的pic代码计算方式在32位x86指令集中，都使用call指令来获得当前地址，作者改写了所有call指令，令其push一个未重写时的地址在栈上，被利用于计算地址时，即可以获得原有计算应得的地址，再由iCFT进行统一处理。</p><h2 id="系统Overview"><a href="#系统Overview" class="headerlink" title="系统Overview"></a>系统Overview</h2><p>基于上面的想法，作者实现了<code>multiverse</code>，正如下面的图片中显示，<code>multiverse</code>系统包含两个分开的步骤，映射和重写：</p><p><img src="/2019/01/27/Superset-Disassembly-Statically-Rewriting-X86-Binaries-Without-Heuristics-Disassembly/1.png" alt="图片1"></p><p>在映射阶段，superset disassembler是用下面所示的算法对代码段开始的每个offset进行反汇编，删除重复的代码并在尾部设置一个跳转指令。可以注意的是，在反汇编中，作者删除了从非法指令向前到最后一条控制转移指令的代码内容：</p><p><img src="/2019/01/27/Superset-Disassembly-Statically-Rewriting-X86-Binaries-Without-Heuristics-Disassembly/2.png" alt="图2"></p><p><code>multiverse</code>修改了反汇编获得的代码中占位符长度过短的jcc，jmp指令，因为它们原来的指令很可能长度不够填充新的跳转地址。在这之后，即可以确定所有重写后的指令长度和位置，此时所有的跳转指令依旧包含着占位符地址。</p><p>在重写阶段，<code>multiverse</code>根据重写后的地址位置和原程序地址创建一个本地代码的映射表。映射表的键值是原程序中的内存地址，值则对应着新的代码空间中的地址。 对于重写程序中的直接跳转，<code>multiverse</code>根据映射表将其修改为新的地址。 对于间接跳转，<code>multiverse</code>将其中转到一个搜索映射表的函数中。函数的输入，跳转目标处于原程序的代码空间中。这个函数通过对应映射表找到新代码空间中的对应地址，并执行跳转。 对于外部函数或地址的跳转。由于这些地址在本地映射表中对应。如下图所示，映射函数将在全局映射表中寻找它所处的代码文件并在其对应的映射表中寻找对应地址。</p><p><img src="/2019/01/27/Superset-Disassembly-Statically-Rewriting-X86-Binaries-Without-Heuristics-Disassembly/3.png" alt="图3"></p><p>为了处理位置无关代码和函数指针，<code>multiverse</code>对于所有的call和ret指令都进行了修改。 通过这样的方式，重写后的代码可以任意的安排指令和基本块位置。 最终<code>multiverse</code>利用重写后的代码生成一个新的elf文件。</p><h1 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h1><p>作者基于许多python库，包括python-capstone，pyelftools,pwntools实现了<code>multiverse</code>，包含超过3000行python代码和超过150行汇编代码。同时，基于重写所处的Linux环境，作者对于动态加载器和VDSO进行了特殊处理。</p><h1 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h1><p>作者使用了所有的SPECint 2006 benchmark程序，共12个，作为测试程序集。测试的机器使用一台ubuntu 14.04.1 lts，Intel i7-2600 cpu，4GB RAM。</p><h2 id="有效性"><a href="#有效性" class="headerlink" title="有效性"></a>有效性</h2><p>作者执行了<code>multiverse</code>重写后的所有程序，并和未重写的版本进行对应，所有重写后的程序都正确的执行完毕，输出和未重写的版本同样的结果。</p><p>下表描述了重写后的程序的详细信息：</p><p><img src="/2019/01/27/Superset-Disassembly-Statically-Rewriting-X86-Binaries-Without-Heuristics-Disassembly/4.png" alt="图4"></p><p>有趣的是，对于代码段，所有重写后的程序的代码段长度大约都是原程序的4-5倍，这很可能与x86指令的平均长度有关。同时，表中所有的.newtext段长度都没有包括大约4MB的全局映射表大小，对于代码段长度较小的case，例如429.mcf，这导致了较大的size overhead。</p><h2 id="开销"><a href="#开销" class="headerlink" title="开销"></a>开销</h2><p>作者在原来的benchmark程序和重写后的程序上运行了10遍，以对程序重写后的性能进行一个衡量，结果如下表所示：</p><p><img src="/2019/01/27/Superset-Disassembly-Statically-Rewriting-X86-Binaries-Without-Heuristics-Disassembly/5.png" alt="图5"></p><p>对于大部分的测试程序来说，时间overhead不超过100%，平均的性能overhead为60.42%。对于471.omnetpp 和 483.xalancbmk，性能损耗较高，这两个程序使用c++语言编写，对类函数和库函数的频繁调用在重写时带来了大量的性能损耗。</p><p>接着作者比较了不同优化措施对性能带来的影响，例如只不重写外部函数库，或者对回调函数进行特殊处理，对位置无关代码进行特殊处理。结果如下图所示：</p><p><img src="/2019/01/27/Superset-Disassembly-Statically-Rewriting-X86-Binaries-Without-Heuristics-Disassembly/6.png" alt="图6"></p><p>可以发现，通过对位置无关代码进行特殊处理（假设程序只使用get_pc_thunk函数），可以获得巨大的性能提升。</p><p>作者测试了使用<code>multiverse</code>进行插桩带来的性能开销，并和常用的工具pin进行了比较，两者都执行对于指令数统计的插桩。</p><p><img src="/2019/01/27/Superset-Disassembly-Statically-Rewriting-X86-Binaries-Without-Heuristics-Disassembly/7.png" alt="图7"></p><p>在大部分情况下，使用<code>multiverse</code>在程序重写中静态进行插桩带来的性能消耗比使用pin来的低，在以下情况下，由于pin对于插桩内部代码进行分析，使用pin的插桩性能损耗稍微好一些。</p><p>最后，作者测试了使用<code>multiverse</code>作为安全应用工具的性能，作者使用<code>multiverse</code>编写了一个shadow stack，并与用pin编写的工具相比较。使用<code>multiverse</code>编写的具有巨大的性能优势。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>作者通过使用了superset disassemble和 instruction rewriter两项技术，开发了<code>multiverse</code>系统，提供了一个不依赖启发式分析的二进制软件重写工具，并且通过对比，证明这个工具在安全应用的性能上，和当前主流的二进制插桩框架PIN相比更有优势。</p><hr><p><em>论文翻译内容转载至GoSSIP.</em></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h1&gt;&lt;p&gt;静态代码重写是系统安全应用的一项核心技术，它的使用场景包括性能分析，优化和软件错误定位等。之
      
    
    </summary>
    
      <category term="论文" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/"/>
    
      <category term="软件分析" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90/"/>
    
    
      <category term="二进制反汇编" scheme="http://yama0xff.com/tags/%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%8F%8D%E6%B1%87%E7%BC%96/"/>
    
      <category term="静态重写技术" scheme="http://yama0xff.com/tags/%E9%9D%99%E6%80%81%E9%87%8D%E5%86%99%E6%8A%80%E6%9C%AF/"/>
    
      <category term="2018年" scheme="http://yama0xff.com/tags/2018%E5%B9%B4/"/>
    
      <category term="NDSS’18" scheme="http://yama0xff.com/tags/NDSS%E2%80%9918/"/>
    
  </entry>
  
  <entry>
    <title>Angora: Efficient Fuzzing by Principled Search</title>
    <link href="http://yama0xff.com/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/"/>
    <id>http://yama0xff.com/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/</id>
    <published>2019-01-25T08:31:20.000Z</published>
    <updated>2019-01-28T09:16:17.049Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>​    Fuzzing是一种用于查找软件错误的流行技术。然而，最先进的模糊器的性能还有很多不足之处。基于符号执行的模糊器产生高质量输入但运行缓慢，而基于随机变异的模糊器运行速度快但难以产生高质量输入。我们提出了一种新的基于突变的模糊器Angora，它的性能远远超过了最先进的模糊器。Angora的主要目标是通过解决路径约束来增加分支覆盖率而无需符号执行。<strong>为了有效地解决路径约束，我们引入了几个关键技术：可扩展的字节级污点跟踪，上下文敏感的分支计数，基于梯度下降的搜索和输入长度探索</strong>。在LAVA-M数据集上，Angora发现了几乎所有注入的错误，发现了比我们比较的任何其他模糊器更多的错误，并且发现错误是程序中第二好的模糊器的8倍。Angora还发现了LAVA作者注射但却无法触发的103个错误。我们还在八个流行的，成熟的开源程序上测试了Angora。Angora分别在file，jhead，nm，objdump和size中发现了6,52,29,40和48个新错误。我们测量了Angora的覆盖范围，并评估了其关键技术如何促成其令人印象深刻的性能。</p><table><thead><tr><th style="text-align:left"><strong>论文相关信息：</strong></th></tr></thead><tbody><tr><td style="text-align:left"><em>作者</em>： Peng Chen, Hao Chen</td></tr><tr><td style="text-align:left"><em>单位</em>：ShanghaiTech University, University of California, Davis</td></tr><tr><td style="text-align:left"><em>出处</em>：IEEE S&amp;P’18</td></tr><tr><td style="text-align:left"><em>原文地址</em>：<a href="https://github.com/wtwofire/database/blob/master/papers/fuzzing/2018Angora%20Efficient%20Fuzzing%20by%20Principled%20Search.pdf" target="_blank" rel="noopener">https://github.com/wtwofire/database/blob/master/papers/fuzzing/2018Angora%20Efficient%20Fuzzing%20by%20Principled%20Search.pdf</a></td></tr><tr><td style="text-align:left"><em>源码地址</em>：<a href="https://github.com/AngoraFuzzer/Angora" target="_blank" rel="noopener">https://github.com/AngoraFuzzer/Angora</a></td></tr><tr><td style="text-align:left"><em>发表时间</em>：2018年</td></tr></tbody></table><h1 id="1-简介"><a href="#1-简介" class="headerlink" title="1 简介"></a>1 简介</h1><p>​    Fuzzing是一种用于查找软件错误的流行技术。基于覆盖的模糊器面临着如何创建输入以探索程序状态的关键挑战。一些模糊器使用符号执行来解决路径约束[5,8]，但符号执行很慢，无法有效地解决许多类型的约束[6]。为了避免这些问题，AFL不使用符号执行或任何重量级程序分析[1]。它对程序进行插桩，以观察哪些输入探索新的程序分支，并将这些输入作为进一步变异的种子。 AFL在程序执行时产生很低的开销，但是它创建的大多数输入都是无效的（即，它们无法探索新的程序状态），因为它盲目地改变输入而不利用程序中的数据流。几个模糊器为AFL添加了启发式算法来解决简单的判断，例如“魔术字节”[25,19]，但它们无法解决其他路径约束。</p><p>​    我们设计并实现了一个名为Angora的模糊器，它通过解决路径约束而不使用符号执行来探索程序的状态。Angora跟踪未探测的分支并尝试解决这些分支上的路径约束。我们引入了以下技术来有效地解决路径约束。</p><ul><li><p>上下文敏感的分支覆盖。 AFL使用上下文敏感分支覆盖来近似程序状态。我们的经验表明，为分支覆盖添加上下文使Angora能够更普遍地探索程序状态（第3.2节）。</p></li><li><p>可扩展的字节级污点跟踪。大多数路径约束仅依赖于输入中的几个字节。通过跟踪哪些输入字节流入每个路径约束，Angora只改变这些字节而不是整个输入，因此大大减少了探索空间（第3.3节）。</p></li><li><p>基于梯度下降搜索。当改变输入以满足路径约束时，Angora避免了符号执行，这是昂贵的并且不能解决许多类型的约束。相反，Angora使用机器学习中流行的梯度下降算法来解决路径约束（第3.4节）。</p></li><li><p>类型和形状推断。输入中的许多字节共同用作程序中的单个值，例如，在程序中用作32位有符号整数的输入中的四个字节的组。为了允许梯度下降有效搜索，Angora定位上述组并推断其类型（第3.5节）。</p></li><li><p>输入长度探索。只有当输入的长度超过某个阈值时，程序才可以探索某些状态，但是符号执行和梯度下降都不能告诉模糊器何时增加输入的长度。 Angora检测输入长度何时可能影响路径约束，然后充分增加输入长度（第3.6节）。</p></li></ul><p>​        Angora大大超过了最先进的模糊器。表1比较了Angora与其他模糊器在LAVA-M数据集上发现的漏洞[9]。Angora在数据集中的每个程序中发现了更多错误。特别是，Angora发现了1541个漏洞，是第二个最好的模糊器Steelix发现的漏洞数量的8倍。此外，Angora发现了LAVA作者注射但却无法触发的103个错误。我们还在八个流行的，成熟的开源程序上测试了Angora。Angora分别在file，jhead，nm，objdump和size中发现了6,52,29,40和48个新错误（表5）。我们测量了Angora的覆盖范围，并评估了其关键技术如何促成其令人印象深刻的性能。</p><p><img src="/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/p1.png" alt="p1"></p><h1 id="2-背景：AFL"><a href="#2-背景：AFL" class="headerlink" title="2 背景：AFL"></a>2 背景：AFL</h1><p>​    模糊测试是一种自动测试技术，用于查找错误。 American Fuzzy Lop（AFL）[1]是一种基于突变的灰盒模糊器。 AFL采用轻量级编译时插桩和遗传算法来自动发现可能触发目标程序中新内部状态的测试用例。作为基于覆盖率的模糊器，AFL生成输入以遍历程序中的不同路径来触发错误。</p><h2 id="2-1-分支覆盖范围"><a href="#2-1-分支覆盖范围" class="headerlink" title="2.1 分支覆盖范围"></a>2.1 分支覆盖范围</h2><p>​    AFL通过一组分支来测量路径。在每次运行期间，AFL计算每个分支执行的次数。它将分支表示为元组（lprev; lcur），其中lprev和lcur分别是条件语句之前和之后的基本块的ID。AFL通过使用轻量级检测获取分支覆盖率信息。在编译时在每个分支点注入插桩。对于每次运行，AFL分配路径跟踪表以计算每个条件语句的每个分支执行的次数。表的索引是分支的散列，h（lprev; lcur），其中h是散列函数。</p><p>​    AFL还在不同的运行中保留全局分支覆盖表。每个条目都包含一个8位向量，用于记录分支在不同运行中执行的次数。该向量b中的每个位表示一个范围：b0,……,b7分别代表范围[1]，[2]，[3]，[4; 7]，[8; 15]，[16; 31]，[32; 127]，[128; ∞）。例如，如果设置了b3，则表示存在执行此分支执行4到7次的运行，包括。</p><p>​    AFL比较路径跟踪表和分支覆盖表，以启发式方式确定新输入是否触发程序的新内部状态。如果发生以下任一情况，输入将触发新的内部状态：</p><ul><li><p>程序执行新分支，即路径跟踪表具有此分支的条目，但分支覆盖表没有此分支的条目。</p></li><li><p>存在一个分支，其中当前运行中执行的此分支的次数n与先前的任何运行不同。 AFL通过检查表示n的范围的位是否被设置在分支覆盖表中的相应位向量中来近似地确定这一点。</p></li></ul><h2 id="2-2-变异策略"><a href="#2-2-变异策略" class="headerlink" title="2.2 变异策略"></a>2.2 变异策略</h2><p>​    AFL随机应用以下变异[3]。</p><ul><li><p>位或字节翻转。</p></li><li><p>尝试设置“有趣”的字节，单字或双字。</p></li><li><p>将小整数加到或减去字节，单字或双字。</p></li><li><p>完全随机的单字节集。</p></li><li><p>块删除，通过覆盖或插入来复制块，或块memset。</p></li><li><p>在随机位置拼接两个不同的输入文件。</p></li></ul><h1 id="3-设计"><a href="#3-设计" class="headerlink" title="3 设计"></a>3 设计</h1><h2 id="3-1-概述"><a href="#3-1-概述" class="headerlink" title="3.1 概述"></a>3.1 概述</h2><p>​    AFL和其他类似的fuzzer使用分支覆盖作为度量。但是，在计算分支覆盖范围时，它们没有考虑调用上下文。我们的经验表明，没有上下文，分支覆盖将无法充分探索程序状态。因此，我们建议使用上下文敏感分支覆盖作为覆盖度量（第3.2节）。</p><p>​    算法1显示了Angora的两个阶段：插桩和fuzzing循环。在fuzzing循环的每次迭代期间，Angora选择一个未探测的分支并搜索探索该分支的输入。我们介绍了以下关键技术，以有效地找到输入。</p><ul><li><p>对于大多数条件语句，其判断仅受输入中的几个字节的影响，因此改变整个输入将是徒劳的。因此，在探索分支时，Angora会确定哪些输入字节流入相应的判断，并专注于仅改变这些字节（第3.3节）。</p></li><li><p>确定要改变的输入字节后，Angora需要决定如何改变它们。使用基于随机或启发式的突变不能有效地找到令人满意的值。相反，我们将分支上的路径约束视为输入上黑盒函数的约束，并且我们调整梯度下降算法来解决约束（第3.4节）。</p></li><li><p>在梯度下降期间，我们在其参数上评估blackbox函数，其中一些参数由多个字节组成。例如，当输入中的四个连续字节总是作为整数流一起用于条件语句时，我们应该将这四个字节视为函数的单个参数而不是四个独立参数。为了实现这一目标，我们需要推断输入中的哪些字节统一用作单个值以及值的类型是什么（第3.5节）。</p></li><li><p>仅仅改变输入中的字节是不够的。只有在输入超过阈值后才会触发一些错误，但这会在决定输入长度时产生两难。如果输入太短，则可能不会触发某些错误。但如果输入太长，程序可能运行得太慢。大多数模糊器使用临时方法改变输入的长度。相比之下，Angora使用代码检测程序，该代码检测较长输入何时可以探索新分支并确定所需的最小长度（第3.6节）。</p></li></ul><p><img src="/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/图2.png" alt="图2"></p><p>​    图1显示了fuzzing条件语句的步骤图。图2中的程序演示了这些步骤。</p><ul><li><p>字节级污点跟踪：当使用字节级污点跟踪对第2行的条件语句进行模糊测试时，Angora确定字节1024-1031流入此表达式，因此它仅改变这些字节。</p></li><li><p>基于梯度下降的搜索算法：Angora需要分别找到在第2行上运行条件语句的两个分支的输入。Angora将条件语句中的表达式视为输入x上的函数f（x），并使用梯度下降来找到两个输入x和x’，使得f（x）&gt; 0且f（x’）≤0。</p></li><li><p>形状和类型推断：f（x）是向量x上的函数。在梯度下降期间，Angora分别计算f的每个分量的f的偏导数，因此它必须确定每个分量及其类型。在第2行，Angora确定x由两个组件组成，每个组件由输入中的四个字节组成，并具有32位有符号整数类型。</p></li><li><p>输入长度探索：除非输入至少有1032个字节，否则main不会调用foo。我们不是盲目地尝试更长的输入，而是检测从输入读取的常用函数，并确定更长的输入是否会探索新的状态。例如，如果初始输入短于1024字节，则第12行上的条件语句将执行true分支。</p></li></ul><p>​       由于fread的返回值与1024进行比较，因此Angora知道只有至少1024字节长的输入才能探索错误分支。类似地，第16行和第19行的检测指示Angora将输入扩展到至少1032个字节以执行函数foo。</p><p><img src="/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/图3.png" alt="图3"></p><p><img src="/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/图4.png" alt="图4"></p><h2 id="3-2-上下文敏感的分支计数"><a href="#3-2-上下文敏感的分支计数" class="headerlink" title="3.2 上下文敏感的分支计数"></a>3.2 上下文敏感的分支计数</h2><p>​    第2节描述了AFL的分支覆盖表。它的设计有几个优点。首先，它节省空间。分支数量与程序大小呈线性关系。其次，使用范围来计算分支执行在关于不同执行计数是否指示了程序新的内部状态提供了良好启发。当执行计数很小（例如，小于4）时，计数的任何变化都是显着的。然而，当执行计数很大（例如，大于32）时，变化必须足够大以被认为是重要的。</p><p>​    但这种设计有局限性。由于AFL的分支对上下文不敏感，因此它们无法区分不同上下文中同一分支的执行，这可能会忽略程序新的内部状态。图3说明了这个问题。考虑第3行分支的覆盖范围。在第一次运行期间，程序采用输入“10”。当它在第19行调用f（）时，它在第4行执行true分支。之后，当它在第21行调用f（）时，它在第10行执行false分支。由于AFL对分支的定义是上下文不敏感的，它认为两个分支都已执行。之后，当程序采用新输入“01”时，AFL认为此输入不会触发新的内部状态，因为第4行和第10行的分支都在上一次运行中执行。但实际上这个新输入触发了一个新的内部状态，因为当输入[2] == 1时它将导致第6行崩溃。</p><p>​    我们将上下文合并到分支的定义中。我们将分支定义为元组（lprev, lcur, context），其中l prev和lcur分别是条件语句之前和之后的基本块的ID，context是h（stack）其中h是散列函数，并且stack包含调用堆栈的状态。例如，让图3中的程序首先在输入10上运行。在它从第19行进入f（）之后，它将执行分支（l3; l4; [l19]）。然后，在从第21行进入f（）之后，它将执行分支（l3; l10; [l21]）。相反，当程序在输入“01”上执行时，它将执行分支（l3; l10; [l19]），然后执行（l3; l4; [l21]）。通过将调用上下文合并到分支的定义中，Angora可以检测到第二次运行会触发新的内部状态，这将在改变输入时[2]时导致第6行产生carsh。</p><p>​    向分支添加上下文会增加独特分支的数量，这在发生深度递归时可能会很明显。我们当前的实现通过选择用于计算调用堆栈的散列的特定函数h来缓解该问题，其中h计算堆栈上所有调用位置的ID的xor。当Angora插桩程序时，它会为每个调用点分配一个随机ID。因此，当函数f递归调用自身时，无论Angora将同一调用站点的ID推送到调用堆栈多少次，h（堆栈）最多输出两个唯一值，在函数f中这最多会使独特分支的数量增加一倍。我们对现实世界程序的评估表明，在结合上下文后，独特分支的数量增加了多达7.21倍（表7），以换取改进代码覆盖的好处（图7）。</p><h2 id="3-3-字节级别的污点跟踪"><a href="#3-3-字节级别的污点跟踪" class="headerlink" title="3.3 字节级别的污点跟踪"></a>3.3 字节级别的污点跟踪</h2><p>​    Angora的目标是创建执行未开发分支的输入。当它尝试执行未探测的分支时，它必须知道输入中的哪些字节偏移影响分支的谓词。因此，Angora需要字节级别的污点跟踪。然而，污点跟踪是昂贵的，尤其是在单独跟踪每个字节时，因此AFL避免了它。我们的主要观点是，在大多数程序运行中都不需要进行污点跟踪。一旦我们对输入运行了污点跟踪（图1中的步骤1），我们就可以记录哪些字节偏移流入每个条件语句。然后，当我们改变这些字节时，我们可以在没有污点跟踪的情况下运行程序。这通过其许多突变来分摊一个输入上的污点跟踪成本，这使得Angora具有与AFL类似的输入执行吞吐量（第5.6节）。</p><p>​    Angora将程序中的每个变量x与污点标签tx相关联，污点标签tx表示输入中可能流入x的字节偏移量。污点标签的数据结构对其内存占用量有很大影响。一个简单的实现是将每个污点标签表示为位向量，其中每个位i表示输入中的第i个字节。然而，由于该位向量的大小在输入的大小上线性增长，因此该数据结构对于大输入将是禁止的，但是在某些程序中找到错误需要大量输入。</p><p>​    为了减少污点标签的大小，我们可以将位向量存储在表中，并使用表中的索引作为污点标签。只要表中条目数的对数远小于最长位向量的长度（通常是这种情况），我们就可以大大减小污点标签的大小。</p><p>​    但是，这种数据结构带来了新的挑战。污点标签必须支持以下操作：</p><ul><li><p>INSERT（b）：插入位向量b并返回其标签。</p></li><li><p>FIND（t）：返回污点标签t的位向量。</p></li><li><p>UNION（tx; ty）：返回污点标签，表示污点标签tx和ty的位向量的并集。</p></li></ul><p>​       FIND代价很低，但UNION很高。 UNION采取以下步骤。首先，它找到两个标签的位向量并计算它们的联合u。这一步代价很低。接下来，它搜索表以确定u是否已存在。如果没有，它会增加u。但如何高效搜索？线性搜索会很昂贵。或者，我们可以构建一个位向量的哈希集，但是如果它们中有很多并且每个位向量都很长，那么计算哈希码和存储哈希集的空间就会花费很多时间。由于UNION是我们在算术表达式中跟踪污染数据时的常见操作，因此它必须是高效的。注意，我们不能使用UNION-FIND数据结构，因为矢量不是不相交的，即两个不同的位矢量可能在同一位置具有1。</p><p>​    我们提出了一种新的数据结构，用于存储位向量,允许有效INSERT，FIND和UNION。对于每个位向量，数据结构使用无符号整数为其分配唯一标签。当程序插入新的位向量时，数据结构会为其分配下一个可用的无符号整数。</p><p>​    数据结构包含两个组件。</p><ul><li><p>二叉树将位向量映射到其标签。每个位向量b由级别为|b|的唯一树节点vb表示，其中|b|是b的长度。 vb存储b的标签。要从根到达vb，检查b0,b1…顺序。如果bi为0，则转到左边的子节点;否则，去右边的子节点。每个节点都包含一个指向其父节点的后向指针，以允许我们从vb开始检索位向量。</p></li><li><p>查找表将标签映射到其位向量。标签是该表的索引，相应的条目指向表示该标签的位向量的树节点。</p></li></ul><p>​       在该数据结构中，树中的所有叶子表示位向量，并且没有内部节点表示位向量。但是，树中的许多节点可能是不必要的。例如，如果向量x00 <em>在树中但没有向量x0 [01] </em> 1 [01] <em>在树中，其中x是任何位序列，那么就不必在节点之后存储任何节点表示x，因为x只有一个是叶子的结点，而这个叶子代表x00 </em>。这里我们使用正则表达式的通用符号，其中x *表示x重复零次或多次，[xy]表示x或y。这个观察允许我们在将一个向量插入树中时修剪向量，如下所示：</p><ol><li><p>删除向量的所有尾随0。</p></li><li><p>跟踪向量中的位，从第一位到最后一位，遍历树。</p></li></ol><ul><li><p>如果位为0，请跟随左节点</p></li><li><p>否则，请跟随右节点。</p></li><li><p>如果节点不存在，请创建它。</p></li></ul><ol start="3"><li>将向量的标签存储在我们访问的最后一个节点中。</li></ol><p>​       算法2详细描述了这种插入操作。</p><p>​    算法3和算法4分别描述了FIND和UNION操作。请注意，当我们创建节点时，最初它不包含标签。稍后，如果此节点是我们插入位向量时访问的最后一个节点，我们将位向量的标签存储在此节点中。通过此优化，此树具有以下属性：</p><ul><li><p>每个叶节点都包含一个标签。</p></li><li><p>内部节点可能包含标签。我们可能会在没有标签的内部节点中存储标签，但我们永远不会在任何内部节点中替换标签。</p></li></ul><p>​        该数据结构极大地减少了用于存储位向量的存储器占用。设每个位向量的长度为n，并设有l个位向量。如果我们天真地将所有位向量存储在查找表中，则需要O（nl）空间。但是，在我们的数据结构中，树中的节点数是O（l）。每个节点可以存储最多一个索引到查找表。由于查找表具有l个条目并且每个条目是指针并且因此具有固定大小，因此查找表的大小是O（l），并且查找表的每个索引具有O（log 1）位。因此，总空间要求为O（l·log l）。</p><p><img src="/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/图5.jpg" alt="图5"></p><h2 id="3-4-基于梯度下降的搜索算法"><a href="#3-4-基于梯度下降的搜索算法" class="headerlink" title="3.4 基于梯度下降的搜索算法"></a>3.4 基于梯度下降的搜索算法</h2><p>​    字节级污点跟踪发现输入流中的哪些字节偏移成为条件语句。但是如何改变输入以运行未探索的分支语句？大多数模糊测试者随机地或使用粗略的启发式方法改变输入，但这些策略不太可能快速找到合适的输入值。相比之下，我们将此视为搜索问题，并利用机器学习中的搜索算法。我们在实现中使用了梯度下降，但其他搜索算法也可能有效。</p><p>​    在这种方法中，我们将用于执行分支断定看作黑盒函数f（x）的约束，其中x是输入中流入判断的值的向量，并且f（）捕获计算在从程序开始到此判断的路径。 f（x）有三种类型的约束：</p><ol><li><p>f（x）&lt;0。</p></li><li><p>f（x）&lt;= 0。</p></li><li><p>f（x）== 0。</p></li></ol><p>​       表2显示我们可以将所有形式的比较转换为上述三种类型的约束。如果条件语句的判断包含逻辑运算符&amp;&amp;或||，则Angora会将语句拆分为多个条件语句。例如，它将（a &amp;&amp; b）{s} else {t}拆分为if（a）{if（b）{s} else {t}} else {t}。</p><p>​    算法5显示了搜索算法。从初始x0开始，找到x使得f（x）满足约束。请注意，为了满足每种类型的约束，我们需要最小化f（x），并且我们使用梯度下降来实现此目的。</p><p>​    梯度下降找到函数f（x）的最小值。该方法是迭代的。每次迭代都从x开始，计算∇xf（x）（x处的f（x）的梯度），并将x更新为x-ε∇xf（x），其中ε是学习率。</p><p>​    在训练神经网络时，研究人员使用梯度下降来找到一组最小化训练误差的权重。然而，梯度下降的问题在于它有时可能会陷入局部最小值，而不是全局最小值。幸运的是，这在模糊测试中通常不是问题，因为我们只需要找到足够好的输入x而不是全局最优x。例如，如果约束是f（x）&lt;0，那么我们只需要找到一个x，其中f（x）&lt;0而不是f（x）是全局最小值。</p><p>然而，当将梯度下降应用于模糊时，我们面临着独特的挑战。梯度下降需要计算梯度∇xf（x）。在神经网络中，我们可以用分析形式编写∇xf（x）。然而，在模糊测试中，我们没有f（x）的分析形式。其次，在神经网络中，f（x）是连续函数，因为x包含网络的权重，但在模糊中f（x）通常是离散函数。这是因为典型程序中的大多数变量都是离散的，因此x中的大多数元素都是离散的。</p><p>​    我们使用数值近似解决了这些问题。 f（x）的梯度是唯一的矢量场，其每个点x处的任意单位矢量v的点积是f沿v的方向导数。我们用δf(x) /δ（xi）= f（x+δv i）-f（x））/δ逼近每个方向导数其中δ是小的正值（例如，1），vi是第i维的单位矢量。为了计算每个方向导数，我们需要运行程序两次，一次使用原始输入x，一次使用扰动输入x + δvi。在第二次运行中，程序可能无法到达计算f（x +δvi）的程序点，因为程序在较早的条件语句中采用了不同的分支。当发生这种情况时，我们将δ设置为小的负值（例如，-1）并尝试再次计算f（x +δvi）。如果成功，我们会根据它计算方向导数。否则，我们将导数设置为零，指示梯度下降不要在此方向上移动x。计算梯度的时间与矢量x的长度成比例，因为Angora分别计算每个方向导数。第3.5节将描述如何通过合并在程序中用作单个值的连续字节来减少x的长度。</p><p>​    理论上，梯度下降可以解决任何约束。实际上，梯度下降可以解决约束的速度取决于数学函数的复杂性。</p><ul><li><p>如果f（x）是单调的或凸的，那么即使f（x）具有复杂的分析形式，梯度下降也可以快速找到解。例如，考虑约束f（x）&lt;0，其中f（x）使用一些多项式系列近似log（x）。由于复杂的分析形式，符号执行很难解决这种约束。但是，梯度很容易解决，因为f（x）是单调的。</p></li><li><p>如果梯度下降的局部最小值满足约束，则查找解决方案也很快。</p></li><li><p>如果局部最小值不满足约束条件，则Angora必须随机走到另一个值x并从那里开始递减渐变，希望找到满足约束的另一个局部最小值。</p></li></ul><p>​       请注意，Angora不会生成f（x）的分析形式，而是运行程序来计算f（x）。</p><p><img src="/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/图6.png" alt="图6"></p><h2 id="3-5形状和类型推断"><a href="#3-5形状和类型推断" class="headerlink" title="3.5形状和类型推断"></a>3.5形状和类型推断</h2><p>​    天真地，我们可以让输入中的x中的每个元素成一个字节流入到判断处。但是，由于类型不匹配，这会导致梯度下降问题。例如，让程序将输入中的四个连续字节b3b2b1b0视为整数，并让xi表示该整数值。当计算f（x +δvi）时，我们应该将δ加到这个整数。但是如果我们天真地将每个字节b3，b2，b1，b0分配给x中的不同元素，那么我们将在每个字节上计算f（x +δvi），但这是不合适的。</p><p>​    程序将这些字节组合为单个值并仅使用表达式中的组合值，因此当我们向除最低有效字节之外的任何字节添加小的δ时，我们将显着更改此组合值，这将导致计算的偏导数是一个不正确的真实值的近似。</p><p>​    为了避免这个问题，我们必须确定（1）输入中的哪些字节总是一起用作程序中的单个值，以及（2）值的类型是什么。我们称第一个问题为形状推理，第二个问题类型推断，并在动态污点分析过程中解决它们。</p><p>​    对于形状推断，最初输入中的所有字节都是独立的。在污点分析期间，当指令将输入字节序列读入变量，其中序列的大小与基本类型的大小匹配（例如，1,2,4,8字节）时，Angora将这些字节标记为属于相同的值。当冲突发生时，Angora使用最小的尺寸。对于类型推断，Angora依赖于对值进行操作的指令的语义。例如，如果指令对有符号整数进行操作，则Angora将相应的操作数推断为有符号整数。当相同的值同时用作有符号和无符号类型时，Angora将其视为无符号类型。请注意，当Angora无法推断出值的精确大小和类型时，这并不能防止梯度下降找到解决方案 - 搜索只需要更长的时间。</p><p><img src="/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/图7.png" alt="图7"></p><h2 id="3-6-输入长度探索"><a href="#3-6-输入长度探索" class="headerlink" title="3.6 输入长度探索"></a>3.6 输入长度探索</h2><p>​    与大多数其他模糊器一样，Angora开始使用尽可能小的输入进行模糊测试。但是，仅当输入长于阈值时才执行某些分支。这给模糊器带来了两难境地。如果模糊器使用太短的输入，则无法探索这些分支。但如果它使用太长的输入，程序可能运行缓慢甚至内存不足。大多数工具使用临时方法尝试不同长度的输入。相比之下，Angora只有在这样做才能探索新的分支时才会增加输入长度。</p><p>​    在污点跟踪期间，Angora将类似read的函数调用中的目标内存与输入中的相应字节偏移相关联。它还使用特殊标签标记来自读取调用的返回值。如果在条件语句中使用返回值并且不满足约束，则Angora会增加输入长度，以便读取调用可以获取它请求的所有字节。例如，在图2中，如果第12行的条件语句为false，则Angora会扩展输入长度，以便fread可以读取它请求的所有1024个字节。我们的标准并非详尽无遗，因为程序可以消耗输入并以我们未预料到的方式检查其长度，但是一旦我们发现它们就很容易将这些标准添加到Angora。</p><h1 id="4-实现"><a href="#4-实现" class="headerlink" title="4  实现"></a>4  实现</h1><h2 id="4-1-插桩"><a href="#4-1-插桩" class="headerlink" title="4.1 插桩"></a>4.1 插桩</h2><p>​    对于每个要模糊的程序，Angora通过使用LLVM Pass [18]检测程序来生成相应的可执行文件。</p><ul><li><p>插桩收集条件语句的基本信息，并通过污点分析将条件语句链接到其对应的输入字节偏移。在每个输入上，Angora只运行此步骤一次（而不是在改变此输入时）。</p></li><li><p>记录执行跟踪以识别新输入。</p></li><li><p>在运行时支持上下文（第3.2节）。</p></li><li><p>在判定中收集表达式值（第3.4节）。</p></li></ul><p>​       为了支持3.3节中描述的可扩展字节级污点跟踪，我们通过扩展DataFlowSanitizer（DFSan）[21]为Angora实现了污点跟踪。我们为FIND和UNION操作实现了缓存设施，显着加快了污点跟踪。</p><p>​    Angora依赖于LLVM 4.0.0（包括DFSan）。它的LLVM pass包含820行C ++代码，不包括DFSan，运行时有1950行C ++代码，包括用于存储污点标签的数据结构以及用于污染输入和跟踪条件语句的钩子。</p><p>​    除了具有两个分支的if语句之外，LLVM IR还支持switch语句，这可能会引入多个分支。在我们的实现中，为方便起见，Angora将每个switch语句转换为if语句序列。</p><p>​    Angora识别libc函数，用于在条件语句中出现时比较字符串和数组。</p><p>​    例如，Angora将“strcmp（x，y）”转换为“x strcmp y”，其中strcmp是Angora理解的特殊比较运算符。</p><h2 id="4-2-Fuzzer"><a href="#4-2-Fuzzer" class="headerlink" title="4.2 Fuzzer"></a>4.2 Fuzzer</h2><p>​    我们以4488行Rust代码中实现了Angora。我们使用fork server [30]和CPU绑定等技术优化了Angora。</p><h1 id="5-评估"><a href="#5-评估" class="headerlink" title="5 评估"></a>5 评估</h1><p>​    我们分三个步骤评估了Angora。首先，我们将Angora的性能与其他最先进的模糊器进行了比较。然后，我们测量了Angora的测试覆盖率及其在现实世界程序中发现未知错误的能力。最后，我们评估了它的关键新颖特征。</p><p>​    我们在64位Ubuntu 16.04 LTS的Intel Xeon E5-2630 v3和256 GB内存的服务器上运行了所有实验。尽管Angora可以同时对多个内核上的程序进行模糊处理，但我们将其配置为在评估期间仅在一个内核上模糊该程序，以将其性能与其他模糊器进行比较。我们对每个实验进行了五次运行并报告了平均性能。</p><h2 id="5-1-Angora与其他模糊器进行比较"><a href="#5-1-Angora与其他模糊器进行比较" class="headerlink" title="5.1 Angora与其他模糊器进行比较"></a>5.1 Angora与其他模糊器进行比较</h2><p>​    比较模糊器的最终指标是它们发现错误的能力。一个好的测试集应该包含具有实际错误的真实程序。 LAVA是一种通过在程序源代码中注入大量实际错误来生成真实语料库的技术[9]。作者通过在每个程序中注入多个错误来创建语料库 LAVA-M。 LAVA-M由四个GNU coreutils程序组成：uniq，base64，md5sum和who。每个注入的bug都有一个唯一的ID，在触发bug时会打印出来。</p><p>​    我们将Angora与以下最先进的模糊器进行了比较：</p><ul><li><p>FUZZER（基于覆盖的模糊器）和SES（符号执行和SAT求解）。 LAVA的作者将它们都运行了5个小时[9]。</p></li><li><p>VUzzer：使用“魔术字节”策略的模糊器[25]。它的作者报告了LAVA-M程序中发现的错误数量，但没有报告运行时间。</p></li><li><p>Steelix：一个模糊器在LAVAM上表现优于VUzzer [19]。作者通过运行模糊器5小时报告了LAVA-M程序中发现的错误数量。[11]</p></li><li><p>AFL 2.51b：撰写本文时的最新版AFL。我们运行AFL五个小时，我们为AFL提供了一个CPU核心，用于对每个程序进行模糊测试。</p></li><li><p>Angora：我们使用与AFL相同的设置（每个程序一个CPU核心）。</p></li></ul><p>​       表1比较了所有模糊器发现的错误。AFL表现最差，在所有程序中总共发现了10个错误。 VUzzer的作者无法在md5sum上运行它，因为LAVA作者错误地修改了md5sum，导致它在所有输入上崩溃。我们向LAVA作者证实了这个问题并修复了它。 Steelix是第二个最好的模糊器，它发现了base64中几乎所有的错误，但是在uniq中28个中只有7个注入了错误，57个md5sum注入了错误中的28个，2136个中有194个注入了错误。Angora大大超过了Steelix，发现了uniq，base64和md5sum中的所有错误，并且2136中的1443个注入了错误。</p><p>​    LAVA为每个注入的bug分配一个唯一的ID，该ID在触发错误时打印。文件验证的错误列出了LAVA作者在创建LAVA时能够触发的所有注入错误。Angora不仅发现了uniq，base64，md5sum中列出的所有错误以及大多数列出的错误，还列出了103个未列出的错误（LAVA作者注入但无法触发的错误）。表3显示了这些未列出的错误的ID。表4显示了Angora发现的列出和未列出的错误的细分。</p><p><img src="/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/图8.png" alt="图8"></p><p>​    图4显示了Angora在who中随着时间的推移发现的错误累积数量。我们没有显示其他模糊器的结果，因为他们发现who没有错误。图4显示，最初Angora很快发现了错误，在不到五分钟内发现了1000个错误。然后发现速度减慢，但在总共2136个列出的错误中，它仅在45分钟内发现超过1500个错误。</p><p>​    我们接下来解释为什么Angora发现了比下一个最好的模糊器更多的错误。首先，LAVA使用“魔术字节”来保护包含错误的分支，但是一些魔术字节不是直接从输入复制而是从输入计算。由于VUzzer和Steelix的“魔术字节”策略只能将魔术字节直接复制到输入，因此该策略无法创建探索这些分支的输入。相比之下，Angora跟踪流入判定的输入字节偏移，然后通过梯度下降而不是假设“魔术字节”或输入与判定之间的任何其他特殊关系来改变这些偏移，因此Angora可以找到探索这些的输入分支机构。其次，VUzzer盲目地尝试“魔术字节”策略，一旦魔术字节中的一个与随机突变后的输入中的字节匹配，Steelix就会关注“魔术字节”策略。相比之下，Angora安排其所有计算能力来解决未探测分支上的路径约束，因此它可以覆盖更多分支，因此可以快速找到LAVA-M中的大部分注入错误。</p><p><img src="/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/图9.png" alt="图9"></p><h2 id="5-2-在未修改的真实程序中评估Angora"><a href="#5-2-在未修改的真实程序中评估Angora" class="headerlink" title="5.2 在未修改的真实程序中评估Angora"></a>5.2 在未修改的真实程序中评估Angora</h2><p>​    Angora在LAVA上的表现令人印象深刻，不仅发现了大部分列出的错误，还发现了许多未列出的错误。然而，它的怀疑论者可能会争辩说这些bug是人为注入的。为了解决这个问题，我们使用最新版本评估了八个流行的开源程序。由于这些成熟的，受欢迎的程序已经过广泛测试，我们预计它们几乎没有残留物崩溃的错误。因此，除了测量发现的新错误的数量外，我们还测量了Angora对这些程序的报道。我们使用了gcov，它记录了输入中程序中执行的所有行和分支[14]。我们将由Angora生成的每个输入馈送到用gcov编译的程序以获得累积代码覆盖率，并且afl-cov3允许我们自动执行此操作。我们还在这些程序上运行AFL进行比较。表5显示了使用一个CPU内核运行Angora和AFL五小时后的结果。我们通过AFL的afl-cmin -C命令重复删除了崩溃。</p><p>​    表5显示Angora在线路覆盖范围，分支覆盖范围以及每个程序发现崩溃时表现优于AFL。在文件，jhead，nm，objdump和大小中，AFL发现了0,19,12,4,6个独特的崩溃，而Angora分别发现了6,52,29,40和48个独特的崩溃。对比度在jhead最为突出，Angora的线路覆盖率提高了127.4％，分支覆盖率提高了144.0％。</p><p>​    图5比较了Angora和AFL随时间的累积线和分支覆盖率。它表明Angora在任何时候都覆盖了比AFL更多的线和分支。Angora优越覆盖的原因在于它可以探索复杂条件语句的两个分支。例如，图6显示了文件中的这样一个语句，其中Angora成功地探索了两个分支，但AFL无法探索真正的分支。在接下来的部分中，我们将评估Angora的每个关键特性如何有助于其卓越的性能。</p><p><img src="/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/图10.png" alt="图10"></p><p><img src="/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/图11.png" alt="图11"></p><p>5.3上下文相关的分支计数</p><p>​    <strong>5.3.1</strong> <strong>性能</strong>。 3.2节介绍了上下文相关分支计数。我们相信在不同的函数调用上下文中区分相同的分支会发现更多的错误。为了评估这个假设，我们分别使用上下文相关的分支计数和上下文不相关的分支计数来运行Angora。表6显示Angora发现6个错误具有上下文相关的分支计数，但在上下文不相关中它没有错误。图7显示从30分钟开始到模糊测试，Angora始终覆盖更多具有上下文相关分支计数的累积行。我们发现了几个真实世界的例子，其中上下文相关的分支计数允许Angora探索更多路径。例如，图8显示了程序文件中readelf.c文件中的代码片段。函数getu32在多个上下文中调用，它根据swap参数返回不同的结果。如果没有上下文相关的分支计数，Angora将无法在所有调用上下文中探索条件语句的两个分支。</p><p>​    <strong>5.3.2</strong> <strong>哈希碰撞</strong>。与AFL类似，Angora将分支计数存储在哈希表中。当Angora在计算分支覆盖率时合并调用上下文时，它会在哈希表中插入更多的唯一分支，因此我们必须增加哈希表的大小以保持较低的冲突率。</p><p>​    我们评估了5.2节中描述的真实世界程序中有多少独特的分支上下文相关性。 AFL的作者观察到，唯一分支（没有上下文）的数量通常在2k到10k之间，而具有216个bucket的哈希表应该足以满足常见情况[30]。表7显示合并上下文相关度将唯一分支的数量增加了至多8倍，这要求我们将散列表的大小增加8倍以具有相同的预期散列冲突率。默认情况下，Angora在其哈希表中分配220个bucket，这是AFL中哈希表的16倍，对大多数程序来说应该足够了。虽然在不再适合缓存时增加哈希表可能是有害的，但不像AFL那样遍历哈希表以查找新路径并优先处理覆盖许多基本块的输入，对于每个输入，Angora只遍历哈希表一次找到新的路径。因此，Angora受哈希表大小增长的影响较小，如第5.6节中的执行速度所示。</p><p><img src="/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/图12.png" alt="图12"></p><h2 id="5-4-基于梯度下降的搜索"><a href="#5-4-基于梯度下降的搜索" class="headerlink" title="5.4 基于梯度下降的搜索"></a>5.4 基于梯度下降的搜索</h2><pre><code>第3.4节描述了如何使用梯度下降来解决条件语句中的约束。我们将梯度下降与另外两种策略进行了比较：随机变异，VUzzer的魔术字节加随机变异。为了排除测量中的其他变量，我们确保三种策略接收相同的输入：我们收集了AFL在5.2节中生成的输入，并将它们作为模糊的唯一输入提供给Angora。我们分别使用上述三种策略运行Angora两小时。</code></pre><p>​    表8显示梯度下降解决了比所有程序中的其他两个策略更多的约束。如第5.1节的最后一段所述，“魔术字节”策略无法解决其值未直接从输入复制的约束。例如，图6中的变量descsz用于程序中的许多约束，但它不是直接从输入复制的，因此“魔术字节”策略没有帮助。</p><h2 id="5-5-输入长度探测"><a href="#5-5-输入长度探测" class="headerlink" title="5.5  输入长度探测"></a>5.5  输入长度探测</h2><p>​    第3.6节描述了当Angora观察到路径约束可能取决于长度时，按需增加输入的长度，而AFL和相关的模糊器随机增加输入长度。我们基于两个标准比较了这两种策略：</p><ul><li><p>策略增加输入长度的次数是多少？在这个战略创造的投入中，有多少是有用的？如果输入直接或在某些突变后探索新分支，则输入有用。</p></li><li><p>这些有用输入的平均长度是多少？</p></li></ul><p>​       我们分别用我们提出的策略和随机策略运行Angora五小时。表9显示Angora的策略将输入长度增加了大约两个数量级，比随机策略少了几个数量级，但它在所有情况下都发现了更有用的输入，除了两个：在readpng它发现总共46个中有用输入少3个，并且在jhead上，既没有策略发现任何有用的输入，因为jhead只解析图像的标题，因此不受图像数据长度的影响。表9还显示，虽然Angora的策略产生了更多有用的输入，但它在每个测试程序上平均产生较短的输入。较短的输入使许多程序运行得更快。该评估表明，Angora的战略比随机战略产生更高质量的投入。</p><p><img src="/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/图13.png" alt="图13"></p><p>5.6 执行速度</p><p>Angora的污染追踪代价很高。然而，Angora为每个输入运行一次污染跟踪，然后改变输入并多次运行程序而没有污点跟踪，因此一次性成本是摊销的。由于分支计数主导了没有污点跟踪的插桩代码的运行时间，因此Angora插桩程序的运行速度与其AFL插桩版本的运行速度大致相同。表10显示AFL以比Angora略高的速率执行输入。然而，由于Angora产生更高质量的输入，更有可能探索新的分支，Angora有更好的覆盖范围，并发现明显更多的错误，如前所示。</p><p><img src="file:///C:\Users\admin\AppData\Local\Temp\msohtmlclip1\01\clip_image002.jpg" alt="img"></p><h1 id="6-相关工作"><a href="#6-相关工作" class="headerlink" title="6 相关工作"></a>6 相关工作</h1><h2 id="6-1种子输入优先级"><a href="#6-1种子输入优先级" class="headerlink" title="6.1种子输入优先级"></a>6.1种子输入优先级</h2><p>​    基于突变的fuzzer的一个重要优化是明智地选择种子输入。雷伯特等人[26]制定并推理了种子选择调度问题。他们基于PeachFuzzer设计并评估了六种不同的种子选择算法[23]。算法使用不同的特征来最小化种子输入集，例如执行时间和文件大小。结果表明，种子选择算法采用的启发式方法比完全随机抽样方法表现更好。 AFLFast [4]观察到大多数模糊测试都使用了相同的几条“高频”路径。他们使用马尔可夫链来识别“低频”路径。 AFLFast优先考虑包含此类路径的输入。VUzzer [25]使用控制流功能来建模路径，以优先考虑路径难以到达的输入。此外，VUzzer检测到错误处理基本块，并优先考虑不包含这些基本块的有效输入。相比之下，Angora选择其路径包含具有未探索分支的条件语句的输入。这是一种更为通用的策略，在探索高频路径后，它会自动指示Angora专注于低频路径。</p><h2 id="6-2-基于污点的模糊测试"><a href="#6-2-基于污点的模糊测试" class="headerlink" title="6.2 基于污点的模糊测试"></a>6.2 基于污点的模糊测试</h2><p>​    污点跟踪有很多用途，例如分析恶意软件行为[24]，检测和防止信息泄漏[10,29]和调试软件[22,12]。它也可以用于模糊测试。基于污点的模糊器分析应用程序如何处理输入以确定应修改输入的哪个部分。其中一些模糊器[13,2,17]旨在将输入文件中安全敏感代码中使用的值定位，然后对输入文件的这些部分进行模糊处理以触发崩溃。例如，BuzzFuzz [13]使用污点定位来查找哪些输入字节由他们定义的“攻击点”处理。 Dowser [17]认为可能导致缓冲区溢出的代码是安全敏感代码。换句话说，这些模糊器旨在利用可到达路径中的错误。Woo等人。提到了在探索与利用之间的权衡[32]。Angora可以结合这些技术来开发探索的路径。 Taintscope [31]使用污点分析来推断校验和处理代码，并通过控制流程更改绕过这些检查，因为通过改变输入很难满足这些检查。</p><p>​    VUzzer [25]是一个应用程序感知模糊器，它使用污点分析来定位输入文件中“魔术字节”的位置，然后将这些魔术字节分配给输入中的固定位置。 VUzzer只有在连续出现在输入中时才能找到魔术字节。 Steelix [19]通过学习魔术字节位于输入中的程序状态以及如何有效地改变输入以匹配魔术字节来改进VUzzer。相比之下，Angora应用字节级污点跟踪来获取流入每个条件语句的输入中的字节偏移，然后改变这些字节以满足未探测分支的条件，因此Angora可以有效地找到更多类型的值。魔术字节，例如，非连续魔术字节或魔术字节，不是直接从输入复制而是从输入计算。此外，VUzzer使用压缩的位设置数据结构来表示污点标签，其中每个位对应于输入中的唯一字节偏移。因此，对于具有复杂输入字节偏移模式的值，污点标签的大小很大，因为它们无法有效压缩。相比之下，Angora将字节偏移存储在树中，并将索引作为污染标签用于树中，因此无论标签中有多少输入字节偏移，污点标签的大小都是常量。例如，当几个值的污点标签具有相同的字节偏移时，VUzzer会在每个污点标签中重复存储这些字节偏移，但Angora只在树中存储这些字节偏移一次，从而大大减少了内存消耗。</p><p>​    Angora有效表示污点标签的数据结构类似于简化有序二元决策图（roBDD）。 roBDD用于表示动态切片[33]和数据谱系[20]，但据我们所知，Angora是第一个使用这种想法有效地表示污点标签的。</p><h2 id="6-3-符号辅助模糊测试"><a href="#6-3-符号辅助模糊测试" class="headerlink" title="6.3 符号辅助模糊测试"></a>6.3 符号辅助模糊测试</h2><p>​    动态符号执行为目标应用程序提供了高度语义洞察力。由于这些技术知道如何触发所需的程序状态，因此它们可用于直接查找程序中的漏洞。符号执行实现的经典方法以最大化代码覆盖率以查找崩溃[5,8]。但路径爆炸和约束求解的挑战使符号执行难以扩展[6,27]。一些工具试图通过将其与模糊测试[15,16,7,28]相结合来缓解这一障碍。 DART [15]和SAGE [16]使用动态符号执行引擎来修改模糊测试中的输入。 SYMFUZZ [7]利用对执行跟踪的符号分析来检测输入中位置之间的依赖关系，然后使用此依赖关系来计算最佳突变率以指导模糊测试。 Driller [28]只有在AFL模糊不清时才使用动态符号执行。但是，它们都继承了符号执行的可伸缩性问题。相比之下，Angora不使用符号执行，并且可以有效地在大型程序上找到许多错误。</p><h1 id="7-结论"><a href="#7-结论" class="headerlink" title="7 结论"></a>7 结论</h1><p>​    我们设计并实现了Angora，这是一种强大的基于突变的模糊器，可以产生高质量的输入，这得益于以下关键技术：可扩展的字节级污点跟踪，上下文敏感的分支计数，基于梯度下降的搜索算法，形状和类型推断和输入长度探索。Angora在很大程度上超越了其他最先进的模糊器。它发现了比LAVA-M上的其他模糊器明显更多的错误，发现了当他们准备数据集时LAVA作者无法触发的103个错误，以及8个流行的，成熟的开源程序中总共175个新错误。我们的评估显示，Angora将模糊测试的标准提升到了一个新的水平。</p><h1 id="8-致谢"><a href="#8-致谢" class="headerlink" title="8 致谢"></a>8 致谢</h1><p>​    我们感谢Dongyu Meng在整个项目中的有益讨论以及对本文草稿的审阅。由于匿名审稿人的详细反馈，该文件得到了很大改善。</p><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>[1]  American fuzzy lop. URL: <a href="http://lcamtuf.coredump.cx/afl/" target="_blank" rel="noopener">http://lcamtuf.coredump.cx/afl/</a>.</p><p>[2]   Sofia Bekrar et al. “A taint based approach for smart fuzzing”. In: IEEE International Conference on Software Testing, Verification and Validation (ICST). 2012, pp. 818–825.</p><p>[3]  Binary fuzzing strategies: what works, what doesn’t. URL: <a href="https://lcamtuf.blogspot.sg/2014/08/binaryfuzzing-strategies-what-works.html" target="_blank" rel="noopener">https://lcamtuf.blogspot.sg/2014/08/binaryfuzzing-strategies-what-works.html</a>.</p><p>[4]  Marcel Bhme, Van-Thuan Pham, and Abhik Roychoudhury. “Coverage-based greybox fuzzing as markov chain”. In: Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security. 2016, pp. 1032–1043.</p><p>[5]  Cristian Cadar, Daniel Dunbar, and Dawson R Engler. “KLEE: unassisted and automatic generation of highCoverage tests for complex systems programs.” In: OSDI. Vol. 8. 2008, pp. 209–224.</p><p>[6]  Cristian Cadar and Koushik Sen. “Symbolic execution for software testing: three decades later”. In: Communications of the ACM 56.2 (2013), pp. 82–90.</p><p>[7]  Sang Kil Cha, Maverick Woo, and David Brumley. “Program-adaptive mutational fuzzing”. In: Security and Privacy (SP), 2015 IEEE Symposium on. 2015, pp. 725–741.</p><p>[8]   Sang Kil Cha et al. “Unleashing mayhem on binary code”. In: Security and Privacy (SP), 2012 IEEE Symposium on. 2012, pp. 380–394.</p><p>[9]  Brendan Dolan-Gavitt et al. “LAVA: large-scale automated vulnerability addition”. In: Security and Privacy (SP), 2016 IEEE Symposium on. 2016, pp. 110–121.</p><p>[10]  William Enck et al. “TaintDroid: an information-flow tracking system for realtime privacy monitoring on smartphones”. In: ACM Transactions on Computer Systems (TOCS) 32.2 (2014), p. 5.</p><p>[11]  Fuzzing with AFL is an art. URL: http : / / moyix . blogspot . com / 2016 / 07 / fuzzing - with - afl - is - an -art.html.</p><p>[12]  Malay Ganai, Dongyoon Lee, and Aarti Gupta. “DTAM: dynamic taint analysis of multi-threaded programs for relevancy”. In: Proceedings of the ACM SIGSOFT 20th International Symposium on the Foundations of Software Engineering. 2012, p. 46.</p><p>[13]  Vijay Ganesh, Tim Leek, and Martin Rinard. “Taintbased directed whitebox fuzzing”. In: Proceedings of the 31st International Conference on Software Engineering. 2009, pp. 474–484.</p><p>[14]  gcov - a test coverage program. URL: <a href="https://gcc.gnu" target="_blank" rel="noopener">https://gcc.gnu</a>. org/onlinedocs/gcc/Gcov.html#Gcov.</p><p>[15]  Patrice Godefroid, Nils Klarlund, and Koushik Sen. “DART: directed automated random testing”. In: ACM SIGPLAN Notices. Vol. 40. 6. 2005, pp. 213– 223.</p><p>[16]  Patrice Godefroid, Michael Y Levin, and David A Molnar. “Automated whitebox fuzz testing.” In: NDSS. Vol. 8. 2008, pp. 151–166.</p><p>[17]  Istvan Haller et al. “Dowsing for overflows: a guided fuzzer to find buffer boundary violations.” In: USENIX security. 2013, pp. 49–64.</p><p>[18]  Chris Lattner and Vikram Adve. “LLVM: a compilation framework for lifelong program analysis and transformation”. In: CGO. San Jose, CA, USA, Mar. 2004, pp. 75–88.</p><p>[19]  Yuekang Li et al. “Steelix: program-state based binary fuzzing”. In: Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering. 2017, pp. 627–637.</p><p>[20]  Zhiqiang Lin, Xiangyu Zhang, and Dongyan Xu. “Convicting exploitable software vulnerabilities: an efficient input provenance based approach”. In: Dependable Systems and Networks With FTCS and DCC, 2008. DSN 2008. IEEE International Conference on. 2008, pp. 247–256.</p><p>[21]  LLVM dataFlowSanitizer. URL: https:// clang.llvm. org/docs/DataFlowSanitizer.html.</p><p>[22]  Wes Masri, Andy Podgurski, and David Leon. “Detecting and debugging insecure information flows”. In: Software Reliability Engineering, 2004. ISSRE 2004. 15th International Symposium on. 2004, pp. 198–209.</p><p>[23]  Peach fuzzer. URL: <a href="http://www.peachfuzzer.com/" target="_blank" rel="noopener">http://www.peachfuzzer.com/</a>.</p><p>[24]  Georgios Portokalidis, Asia Slowinska, and HerbertBos. “Argos: an emulator for fingerprinting zeroday attacks for advertised honeypots with automatic signature generation”. In: ACM SIGOPS Operating Systems Review. Vol. 40. 4. 2006, pp. 15–27.</p><p>[25]  Sanjay Rawat et al. “VUzzer: application-aware evolutionary fuzzing”. In: NDSS. Feb. 2017.</p><p>[26]  Alexandre Rebert et al. “Optimizing seed selection for fuzzing”. In: 2014.</p><p>[27]  Yan Shoshitaishvili et al. “SOK:(State of) the art of war: offensive techniques in binary analysis”. In: Security and Privacy (SP), 2016 IEEE Symposium on. 2016, pp. 138–157.</p><p>[28]  Nick Stephens et al. “Driller: augmenting fuzzing through selective symbolic execution”. In: Proceedings of the Network and Distributed System Security Symposium. 2016.</p><p>[29]  Mingshen Sun, Tao Wei, and John Lui. “Taintart: a practical multi-level information-flow tracking system for android runtime”. In: Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security. 2016, pp. 331–342.</p><p>[30] Technical ”whitepaper” for afl-fuzz. URL: <a href="http://lcamtuf.coredump.cx/afl/technical%20details.txt" target="_blank" rel="noopener">http://lcamtuf.coredump.cx/afl/technical details.txt</a>.</p><p>[31] Tielei Wang et al. “TaintScope: a checksum-aware directed fuzzing tool for automatic software vulnerability detection”. In: Security and privacy (SP), 2010 IEEE symposium on. 2010, pp. 497–512.</p><p>[32] Maverick Woo et al. “Scheduling black-box mutational fuzzing”. In: Proceedings of the 2013 ACMSIGSAC conference on Computer &amp; communications security. 2013, pp. 511–522.</p><p>[33]  Xiangyu Zhang, Rajiv Gupta, and Youtao Zhang. “Efficient forward computation of dynamic slices using reduced ordered binary decision diagrams”. In: Proceedings of the 26th International Conference on Software Engineering. 2004, pp. 502–511.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h1&gt;&lt;p&gt;​    Fuzzing是一种用于查找软件错误的流行技术。然而，最先进的模糊器的性能还有很多
      
    
    </summary>
    
      <category term="论文" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/"/>
    
      <category term="fuzzing" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/fuzzing/"/>
    
    
      <category term="2018年" scheme="http://yama0xff.com/tags/2018%E5%B9%B4/"/>
    
      <category term="fuzzing" scheme="http://yama0xff.com/tags/fuzzing/"/>
    
      <category term="污点分析" scheme="http://yama0xff.com/tags/%E6%B1%A1%E7%82%B9%E5%88%86%E6%9E%90/"/>
    
      <category term="LAVA" scheme="http://yama0xff.com/tags/LAVA/"/>
    
      <category term="梯度下降算法" scheme="http://yama0xff.com/tags/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95/"/>
    
      <category term="S&amp;P&#39;18" scheme="http://yama0xff.com/tags/S-P-18/"/>
    
      <category term="LLVM" scheme="http://yama0xff.com/tags/LLVM/"/>
    
  </entry>
  
</feed>
