<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>yama0xff&#39;s blog</title>
  
  <subtitle>CYBERSECURITY  BETWEEN 0 AND 1</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yama0xff.com/"/>
  <updated>2019-04-04T08:14:12.803Z</updated>
  <id>http://yama0xff.com/</id>
  
  <author>
    <name>yama0xff</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>如何做科研</title>
    <link href="http://yama0xff.com/2019/04/04/%E5%A6%82%E4%BD%95%E5%81%9A%E7%A7%91%E7%A0%94/"/>
    <id>http://yama0xff.com/2019/04/04/如何做科研/</id>
    <published>2019-04-04T06:32:22.000Z</published>
    <updated>2019-04-04T08:14:12.803Z</updated>
    
    <content type="html"><![CDATA[<p>内容主要分为四个部分：1.科学研究的内涵与外延。2.科学研究的方法与手段。3.博士生如何开展科学工作。4.其它。该内容为上课中从王俊峰教授PPT中记录而来。主要介绍了博士生在读博期间如何做科研的相关问题。</p><h1 id="1-科学研究的内涵与外延"><a href="#1-科学研究的内涵与外延" class="headerlink" title="1. 科学研究的内涵与外延"></a>1. 科学研究的内涵与外延</h1><h2 id="1-1-对科学研究的认识"><a href="#1-1-对科学研究的认识" class="headerlink" title="1.1 对科学研究的认识"></a>1.1 对科学研究的认识</h2><h4 id="相当普遍的看法"><a href="#相当普遍的看法" class="headerlink" title="相当普遍的看法"></a>相当普遍的看法</h4><ul><li>开发一个软/硬件系统或平台</li><li>解决一个有难度的理论问题</li><li>发表了高水平的学术论文</li><li>发表了很多篇SCI/EI/ISTP检索的论文</li><li>申请了软件登记、发明专利、提交了标准或草案</li><li>升职或获得学位</li></ul><h4 id="上述看法都是片面的"><a href="#上述看法都是片面的" class="headerlink" title="上述看法都是片面的"></a>上述看法都是片面的</h4><ul><li>不是发论文、争名利、混学位</li></ul><h4 id="启发性的观点"><a href="#启发性的观点" class="headerlink" title="启发性的观点"></a>启发性的观点</h4><ul><li>是<strong>发现问题，解决问题</strong>的过程</li><li>是<strong>要做创新的工作</strong></li><li>科学研究是<strong>多样性的</strong>，没有固定的模式</li></ul><h4 id="更客观的观点"><a href="#更客观的观点" class="headerlink" title="更客观的观点"></a>更客观的观点</h4><ul><li>科学研究是对未知的客观事件认知的过程，加深人类对客观世界的理解，扩展人类对客观事件的利用、改造和适应的能力。</li></ul><h2 id="1-2-科学研究的目的和意义"><a href="#1-2-科学研究的目的和意义" class="headerlink" title="1.2 科学研究的目的和意义"></a>1.2 科学研究的目的和意义</h2><h4 id="解决实际存在的问题（第一阶段）"><a href="#解决实际存在的问题（第一阶段）" class="headerlink" title="解决实际存在的问题（第一阶段）"></a>解决实际存在的问题（第一阶段）</h4><ul><li>发现需求和问题是进行科学研究的前提条件</li><li>利用、改造和适应客观世界</li></ul><h4 id="探索未知的领域（第二阶段）"><a href="#探索未知的领域（第二阶段）" class="headerlink" title="探索未知的领域（第二阶段）"></a>探索未知的领域（第二阶段）</h4><ul><li>从未知到已知</li></ul><h2 id="1-3-科学研究成果"><a href="#1-3-科学研究成果" class="headerlink" title="1.3 科学研究成果"></a>1.3 科学研究成果</h2><h4 id="主要研究成果"><a href="#主要研究成果" class="headerlink" title="主要研究成果"></a>主要研究成果</h4><ul><li>最有价值的是思想</li><li>思想的交流</li></ul><h4 id="研究成果的载体"><a href="#研究成果的载体" class="headerlink" title="研究成果的载体"></a>研究成果的载体</h4><ul><li>学术论文、研究报告、专著、专利、奖励</li><li>只能从一个侧面反映所获得研究成果和思想体会</li></ul><h4 id="现状"><a href="#现状" class="headerlink" title="现状"></a>现状</h4><ul><li>学术论文是研究成果的主要窄体</li><li>学术论文是获得博士学位的前提条件</li></ul><hr><h1 id="2-科学研究的方法与手段"><a href="#2-科学研究的方法与手段" class="headerlink" title="2. 科学研究的方法与手段"></a>2. 科学研究的方法与手段</h1><h2 id="2-1-科学研究的一般过程-–-提出问题"><a href="#2-1-科学研究的一般过程-–-提出问题" class="headerlink" title="2.1 科学研究的一般过程 – 提出问题"></a>2.1 科学研究的一般过程 – 提出问题</h2><h4 id="发现问题"><a href="#发现问题" class="headerlink" title="发现问题"></a>发现问题</h4><ul><li>科研工作中发现问题是最重要的步骤</li><li>问题或需求驱动研究</li><li>一流高手提问题、二流高手解问题、三流高手做习题</li></ul><h4 id="如何发现问题"><a href="#如何发现问题" class="headerlink" title="如何发现问题"></a>如何发现问题</h4><ul><li>在打的研究方向上需要经验</li><li>那些已清除定义的问题，往往研究空间很小，且难度也大</li><li>从实际工作中发现问题，从综述中凝练问题，从前人工作不总中挖掘问题</li></ul><h4 id="问题的抽象"><a href="#问题的抽象" class="headerlink" title="问题的抽象"></a>问题的抽象</h4><ul><li>不能<strong>只见树木，不见森林</strong>，<strong>跳出问题看问题</strong></li></ul><h2 id="2-2-科学研究的一般过程-–-分析问题"><a href="#2-2-科学研究的一般过程-–-分析问题" class="headerlink" title="2.2 科学研究的一般过程 – 分析问题"></a>2.2 科学研究的一般过程 – 分析问题</h2><h4 id="在解决问题之前，需要对问题有准确的定义"><a href="#在解决问题之前，需要对问题有准确的定义" class="headerlink" title="在解决问题之前，需要对问题有准确的定义"></a>在解决问题之前，需要对问题有准确的定义</h4><ul><li>理清问题的来龙去脉</li><li>给出问题的清晰定义，深入理解问题</li><li>问题的分析要“言之有理”，“言之有物”</li></ul><h4 id="“分而治之”的分析方法"><a href="#“分而治之”的分析方法" class="headerlink" title="“分而治之”的分析方法"></a>“分而治之”的分析方法</h4><ul><li>将无从下手的大问题分解成具体的小问题</li><li>“细分”与“专业化”是科学研究的重要发展</li><li>在“细分”的过程中发现研究的机会</li></ul><h4 id="注意联系的思想"><a href="#注意联系的思想" class="headerlink" title="注意联系的思想"></a>注意联系的思想</h4><ul><li>注意学科交叉、方法借鉴</li></ul><h4 id="注意问题背后的假设与场景"><a href="#注意问题背后的假设与场景" class="headerlink" title="注意问题背后的假设与场景"></a>注意问题背后的假设与场景</h4><ul><li>假设与场景往往是问题存在的基石和前提条件</li><li>假设与场景的变化往往是影响问题的内涵，产生新的问题</li></ul><h4 id="问题的分析是个迭代的过程"><a href="#问题的分析是个迭代的过程" class="headerlink" title="问题的分析是个迭代的过程"></a>问题的分析是个迭代的过程</h4><h2 id="2-3-科学研究的一般过程-–-解决问题"><a href="#2-3-科学研究的一般过程-–-解决问题" class="headerlink" title="2.3 科学研究的一般过程 – 解决问题"></a>2.3 科学研究的一般过程 – 解决问题</h2><h4 id="分清主次，抓住重点"><a href="#分清主次，抓住重点" class="headerlink" title="分清主次，抓住重点"></a>分清主次，抓住重点</h4><ul><li>人的精力是有限的，不可能解决所有问题，彻底解决一个问题的可能性也不大</li><li>列出所有涉及的问题，按重要程度进行排序</li><li>列出正在解决问题所设计的关键技术，逐个攻关</li><li>博士生研究工作应是系统的，研究的问题应是相关的</li></ul><h4 id="先解决简单问题，积累经验后再解决复杂问题"><a href="#先解决简单问题，积累经验后再解决复杂问题" class="headerlink" title="先解决简单问题，积累经验后再解决复杂问题"></a>先解决简单问题，积累经验后再解决复杂问题</h4><ul><li>解决同样的问题，往往有很多思路，不应满足于一种思路</li><li>解决同样的问题，不同的思路或方法往往存在折中，找一种完美的方法对博士生来说可能是危险的</li><li>针对一种解决问题的思路，往往鱼与熊掌不可兼得</li></ul><h1 id="3-博士生如何开展科学工作"><a href="#3-博士生如何开展科学工作" class="headerlink" title="3. 博士生如何开展科学工作"></a>3. 博士生如何开展科学工作</h1><h2 id="3-1-博士生培养一般过程"><a href="#3-1-博士生培养一般过程" class="headerlink" title="3.1 博士生培养一般过程"></a>3.1 博士生培养一般过程</h2><table><thead><tr><th>阶段</th><th>事情</th><th>时间流程（月，总共3年）</th></tr></thead><tbody><tr><td>1</td><td>课程</td><td>10个月</td></tr><tr><td>2</td><td>选课</td><td></td></tr><tr><td>3</td><td>文献调研</td><td></td></tr><tr><td>4</td><td>科研设计</td><td></td></tr><tr><td>5</td><td>开题报告</td><td>15个月</td></tr><tr><td>6</td><td>科研工作</td><td></td></tr><tr><td>7</td><td>中期检查</td><td></td></tr><tr><td>8</td><td>整理资料</td><td></td></tr><tr><td>9</td><td>撰写论文</td><td>31个月</td></tr><tr><td>10</td><td>论文答辩</td><td>33个月</td></tr><tr><td>11</td><td>学位委员会审议</td><td></td></tr><tr><td>12</td><td>授予学位</td><td>34个月</td></tr></tbody></table><h2 id="3-2-博士生的心态"><a href="#3-2-博士生的心态" class="headerlink" title="3.2 博士生的心态"></a>3.2 博士生的心态</h2><h4 id="典型心态"><a href="#典型心态" class="headerlink" title="典型心态"></a>典型心态</h4><ul><li>茫然型：两眼一抹黑</li><li>躁动型：有感兴趣的研究方向，但无从下手</li><li>试探型：在做具体工作，不知能否做出成果</li><li>春风得意型：取得部分研究成果</li><li>失落型</li></ul><h4 id="古今之成大事业、大学问者，必经过三种之境界"><a href="#古今之成大事业、大学问者，必经过三种之境界" class="headerlink" title="古今之成大事业、大学问者，必经过三种之境界"></a>古今之成大事业、大学问者，必经过三种之境界</h4><ul><li>昨夜西风凋碧树，独上高楼，望尽天涯路。（晏殊）</li><li>衣带渐宽终不悔，为伊消得人憔悴。（柳永）</li><li>众里寻他千百度，蓦然回首，那人却在，灯火阑珊处。（辛弃疾）</li></ul><h2 id="3-3-如何选题-–-课题的来源"><a href="#3-3-如何选题-–-课题的来源" class="headerlink" title="3.3 如何选题 – 课题的来源"></a>3.3 如何选题 – 课题的来源</h2><h4 id="导师的项目"><a href="#导师的项目" class="headerlink" title="导师的项目"></a>导师的项目</h4><ul><li>科研项目：重点研发计划，NSFC，国防预研基金</li><li>开发项目：重大工程装备项目</li><li>横向委托：企业委托的一般开发项目</li></ul><h4 id="个人兴趣"><a href="#个人兴趣" class="headerlink" title="个人兴趣"></a>个人兴趣</h4><ul><li>通过个人工作积累，提炼出研究方向</li><li>延续硕士期间工作</li><li>突发灵感的研究方向，奇思妙想</li></ul><h4 id="跟风"><a href="#跟风" class="headerlink" title="跟风"></a>跟风</h4><ul><li>人做亦做</li><li>无病呻吟</li></ul><h4 id="3-4-如何定题"><a href="#3-4-如何定题" class="headerlink" title="3.4 如何定题"></a>3.4 如何定题</h4><ul><li>导师的科研项目：一般选题比较先进，有较大可能在较短时间内有做出成果，认可度高</li><li>导师的重大开发项目：应结合国家或行业重大应用提炼问题，有较大可能在短期内得到应用推广，认可程度高</li><li>通过个人积累或延续前期工作，也有望在较短时间内做出程度，认可程度较高</li><li>横向委托项目：一般不宜作为博士生的选题方向，采用成熟的技术，不侧重与理论或技术上创新，风险较大</li><li>跟风选题：认可程度高，具体方向需要提炼，风险大</li><li>突发灵感的选题：看运气</li></ul><h2 id="3-5-如何查资料-–-SCI、EI、ISTP"><a href="#3-5-如何查资料-–-SCI、EI、ISTP" class="headerlink" title="3.5 如何查资料 – SCI、EI、ISTP"></a>3.5 如何查资料 – SCI、EI、ISTP</h2><ul><li>科学引文索引：SCI, Science Citation Index</li><li>工程索引：EI, Engineering Index</li><li>科技会议论文集索引：ISTP, Index to Scientific &amp; Technical PRoceedings</li></ul><h4 id="国内电子信息类"><a href="#国内电子信息类" class="headerlink" title="国内电子信息类"></a>国内电子信息类</h4><ul><li>中国科学E辑</li><li>中国科学E辑，英文版</li><li>JCST</li><li>电子学报英文版</li><li>计算机学报英文版</li><li>软件学报</li><li>计算机研究与发展</li><li>通信学报</li><li>系统工程与电子学英文版</li><li>航空学报英文版</li><li>几个高校学报</li></ul><h4 id="重要的外文全文数据库"><a href="#重要的外文全文数据库" class="headerlink" title="重要的外文全文数据库"></a>重要的外文全文数据库</h4><ul><li>ACM(美国计算机学会)Digital Library</li><li>IEL (IEEE/IEE E;ectronic Library)</li><li>Elsevier SDOS</li><li>Springer- Link</li><li>Kluwer Online Journals</li><li>Wiley InrerScience</li><li>WorldSciNet</li><li>ISI Web of Science//档次稍微低点</li><li>EI Village//档次稍微低点</li><li>PQDD·B（博硕士论文网络数据库）//档次稍微低点</li></ul><h4 id="好的习惯"><a href="#好的习惯" class="headerlink" title="好的习惯"></a>好的习惯</h4><ul><li>建立本领域主流期刊、重要会议、主要科研团队和知名专家数据库</li><li>订阅期刊目录（Table of Contents）邮件列表</li><li>定期浏览主流刊物主页，了解感兴趣研究论文摘要</li><li>关注本领域主要国际会议的Conference Program</li><li>定期了解主流科研团队和专家的科研进展，科研重点，Survey或Keynote Speech、</li></ul><h2 id="3-6-如何阅读文献-–-自上而下的方法"><a href="#3-6-如何阅读文献-–-自上而下的方法" class="headerlink" title="3.6 如何阅读文献 – 自上而下的方法"></a>3.6 如何阅读文献 – 自上而下的方法</h2><h4 id="阅读文献的两种目的"><a href="#阅读文献的两种目的" class="headerlink" title="阅读文献的两种目的"></a>阅读文献的两种目的</h4><ul><li>已有具体研究问题，通过阅读文献找到解决方法</li><li>无具体研究问题，通过阅读文献来找问题</li></ul><h4 id="从Survey-Review-the-State-of-the-Art-Tutorial入手"><a href="#从Survey-Review-the-State-of-the-Art-Tutorial入手" class="headerlink" title="从Survey , Review, the State of the Art, Tutorial入手"></a>从Survey , Review, the State of the Art, Tutorial入手</h4><ul><li>Google、Google Scholar</li><li>IEEE COMM Survey &amp;Tutorial</li><li>期刊或会议中Related Work</li></ul><h4 id="泛读为主"><a href="#泛读为主" class="headerlink" title="泛读为主"></a>泛读为主</h4><ul><li>侧重于摘要、前言与结论</li></ul><h4 id="广度优先"><a href="#广度优先" class="headerlink" title="广度优先"></a>广度优先</h4><ul><li>针对一个具体问题，看20-30篇密切相关的文献</li><li>论文太多，无法聚焦</li><li>针对3-5篇文献，精度，深度优先</li></ul><h4 id="带着问题看文献"><a href="#带着问题看文献" class="headerlink" title="带着问题看文献"></a>带着问题看文献</h4><ul><li>能解决自己所遇到的问题？</li><li>哪些问题不能解决？</li><li>…</li></ul><h4 id="挑剔的眼光看文献"><a href="#挑剔的眼光看文献" class="headerlink" title="挑剔的眼光看文献"></a>挑剔的眼光看文献</h4><ul><li>在新的应用背景下的自适应新如何？</li><li>方法或技术效率如何？</li></ul><h2 id="3-7-开展具体研究工作"><a href="#3-7-开展具体研究工作" class="headerlink" title="3.7 开展具体研究工作"></a>3.7 开展具体研究工作</h2><ul><li>因学科领域不同而不同</li><li>因人而异</li><li>研究过程本身无统一标准</li><li>研究过程无优劣之分</li></ul><h1 id="4-其它"><a href="#4-其它" class="headerlink" title="4. 其它"></a>4. 其它</h1><h2 id="4-1-朴素的博士生科研工作观"><a href="#4-1-朴素的博士生科研工作观" class="headerlink" title="4.1 朴素的博士生科研工作观"></a>4.1 朴素的博士生科研工作观</h2><ul><li>要踏踏实实，勤勤恳恳，甚至默默无闻；不要指望做明星</li><li>要循序渐进，一步登天可能性不大</li><li>要学会从事本领域科研工作的基本技能，先做实干家，在做指挥家</li><li>不要经常师徒去颠覆经典理论，时间有限，又开创新理论可能时先与导师沟通</li><li>不要在自己的研究成果中严厉地批评他人的成果，更不能人生攻击，就事论事，宜委婉</li><li>不要挑剔所从事的科研项目优劣，导师也在探索过程中，博士生是科研的主力军</li><li>不以物喜，不以己悲（范仲淹）</li></ul><h2 id="4-2-数学基础很重要？"><a href="#4-2-数学基础很重要？" class="headerlink" title="4.2 数学基础很重要？"></a>4.2 数学基础很重要？</h2><ul><li>数学基础和能力比较重要</li><li>数学基础不是影响博士生研究工作质量的主要因素，更不是罪关键因素</li><li>时间有限，不要无的放矢的学数学</li><li>带着问题补充相关的数学基础</li><li>对论文中所采用的新颖数学方法要有敏感、博闻</li><li>经常泛读相关的数学书</li></ul><h2 id="4-3-英语很重要？"><a href="#4-3-英语很重要？" class="headerlink" title="4.3 英语很重要？"></a>4.3 英语很重要？</h2><ul><li>英语基础和写作能力比较重要</li><li>时间有限，不要无的放矢的学英语</li><li>通过阅读专业文献学英语</li><li>英语写作要学会模范，但不是抄袭</li><li>不要以应对英语写作的方式写英文报告或论文</li><li>不要卖弄英语文发，少使用长句，不使用生僻词</li></ul><h2 id="4-4-基本技能要掌握"><a href="#4-4-基本技能要掌握" class="headerlink" title="4.4 基本技能要掌握"></a>4.4 基本技能要掌握</h2><ul><li>至少要精通word,有条件学习LaTex</li><li>至少要使用好一种绘图工具</li><li>至少要使用好一种仿真工具（计算机网络领域，其它未知）</li></ul><h2 id="4-5-结束语"><a href="#4-5-结束语" class="headerlink" title="4.5 结束语"></a>4.5 结束语</h2><ul><li>博士生阶段做什么具体课题是次要的，重要的是一种训练过程和思考问题的方法</li><li>博士生阶段是最艰苦的阶段之一，是最值得怀恋的经历之一</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;内容主要分为四个部分：1.科学研究的内涵与外延。2.科学研究的方法与手段。3.博士生如何开展科学工作。4.其它。该内容为上课中从王俊峰教授PPT中记录而来。主要介绍了博士生在读博期间如何做科研的相关问题。&lt;/p&gt;
&lt;h1 id=&quot;1-科学研究的内涵与外延&quot;&gt;&lt;a href=
      
    
    </summary>
    
      <category term="科研" scheme="http://yama0xff.com/categories/%E7%A7%91%E7%A0%94/"/>
    
    
      <category term="科研" scheme="http://yama0xff.com/tags/%E7%A7%91%E7%A0%94/"/>
    
  </entry>
  
  <entry>
    <title>A Review of Machine Learning in Software Vulnerability Research</title>
    <link href="http://yama0xff.com/2019/04/03/A-Review-of-Machine-Learning-in-Software-Vulnerability-Research/"/>
    <id>http://yama0xff.com/2019/04/03/A-Review-of-Machine-Learning-in-Software-Vulnerability-Research/</id>
    <published>2019-04-03T08:16:36.000Z</published>
    <updated>2019-04-03T14:12:22.021Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>搜索和识别计算机软件中的漏洞具有悠久而丰富的历史，可用于预防或恶意目的。在本文中，我们研究了机器学习（ML）技术在软件漏洞研究（SVR）中的应用，讨论了以前和当前的工作，以说明学术界和工业界如何利用ML。我们发现，主要关注的不仅仅是发现新方法，而是通过简化和自动化流程来帮助SVR从业者。考虑到已经证明的各种应用，我们相信ML将在未来继续为SVR提供帮助，因为探索了新的使用领域，并且可以使用改进的算法来增强现有功能。</p><table><thead><tr><th>relevant information</th><th></th></tr></thead><tbody><tr><td><em>作者</em></td><td>Tamas Abraham  and Olivier de Vel</td></tr><tr><td><em>单位</em></td><td>Cyber and Electronic Warfare Division  Principal Scientist<br>Defence Science and Technology Group</td></tr><tr><td><em>出处</em></td><td></td></tr><tr><td><em>原文地址</em></td><td></td></tr><tr><td><em>源码地址</em></td><td></td></tr><tr><td><em>发表时间</em></td></tr></tbody></table><h1 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h1><p>创建计算机软件是一个非常重要的复杂过程，通常会产生包含一些缺陷和脆弱点的代码。大型代码库的验证可能很困难，或者有时由于成本而被忽略，导致操作系统由于它们表现出来的意外和不良行为而可能崩溃或被操纵。虽然软件安全性错误的严重程度是可变的，但有些可能会非常严重，以至于被利用导致生产力损失，知识产权损失甚至物理损坏来对用户造成严重伤害。 Dowd等人[30]将术语软件错误中能被用于恶意目的的子类称为漏洞， 虽然在特定环境中实际利用漏洞可能并非总是可能，或者也不适合攻击者的目标。解决易受攻击软件引起的问题的方法已经在软件漏洞研究（SVR）中创建了研究。<br>对影响计算机系统的漏洞的研究不仅限于软件。但是，我们在本文中的重点是基于软件的漏洞，我们不考虑硬件或系统架构。软件本身可以作为源代码或二进制文件进行分析，提供多种途径来发现漏洞。软件漏洞的研究过程可以定期分为发现，分析和利用的过程，并将缓解作为预防活动[73]。每个阶段探讨了处理漏洞的不同方面，通常需要代码审计员等从业者的长期和费力的投入。自动化在许多SVR活动中起着重要作用，然而目前通过人工解释发现了大多数漏洞。越来越多的机器学习（ML）技术被整合到SVR过程中，以进一步减少对手动交互的需求。成功应用后，ML算法可以引导用户找到最可能的解决方案，并可能发现以前未知的漏洞。本文的目的是对利用机器学习的SVR内部的目录进行编目，以突出当前事业的状态，并确定可能在未来做出进一步贡献的可能领域。</p><h1 id="2-背景"><a href="#2-背景" class="headerlink" title="2. 背景"></a>2. 背景</h1><p>本文的重点是机器学习在软件漏洞研究中的应用。为了进行讨论，我们分别介绍了两个领域和一些一般细节。在审查各个出版物时，后续章节将根据需要提供进一步的详情。接下来是对这两个研究领域的简单概述，在这个阶段，没有强调它们之间的任何联系。</p><h2 id="2-1-软件漏洞研究"><a href="#2-1-软件漏洞研究" class="headerlink" title="2.1 软件漏洞研究"></a>2.1 软件漏洞研究</h2><p>对软件漏洞进行分类不是一项简单的任务。特定漏洞所属的类别通常在分析软件错误期间显示。有时，在漏洞发现过程中可以预期某种类型，因为某些技术隐含地针对有限范围的漏洞类型。<strong>扫描程序</strong>等工具会查找错误的结构，例如过时的库函数以及代码中的其他与安全相关的错误。<strong>模糊测试</strong>是为软件可执行文件提供异常输入以引起意外行为（如崩溃或内存泄漏）的过程，然后可以在相应的源代码中进行调查。全面的<strong>手动代码审查</strong>也可用于发现错误，但它们可能是其他漏洞发现方法的昂贵替代方案。<strong>格式校验</strong>提供了正确性的数学证明，如果不成功，则可以指出问题。然而，由于复杂性和成本，它通常限于小代码段或算法。<strong>符号执行</strong>是一种分析通过程序分支遍历变量值（输入）的技术，是另一种发现方法，尽管它可能遭受诸如路径爆炸之类的扩展问题。</p><p>源代码中的一些错误可能很容易组合，尽管某些漏洞仅与其他因素（例如它们部署在其上的平台）结合使用，因此可能难以进行初始分类。计算机体系结构，操作系统，计算机语言的多样性以及语言特定错误的存在使分析更加复杂化。我们使用Dowd等人的书中给出的分类法 [30]作为定义软件漏洞类型的指南。语言特定问题包括：</p><ul><li><p>内存损坏，例如缓冲区（堆栈，off-by-one，堆，全局和静态数据）</p></li><li><p>算术边界条件（如数字上溢和下溢）</p></li><li><p>类型转换错误（有符号/无符号，符号扩展，截断，比较）</p></li><li><p>操作符误用（sizeof（），移位，模数，除法）</p></li><li><p>指针算术错误</p></li><li>其他错误（评估顺序逻辑，结构填充，优先级，宏/预处理器，拼写错误）</li></ul><p>其他漏洞更复杂。问题类别包括实际应用程序中存在的问题类别，例如与操作系统或应用程序平台相关的问题类别，即使基础问题可能由更简单的错误（如内存损坏或指针错误）引起：</p><ul><li><p>字符串和元字符漏洞</p></li><li><p>特定于操作系统的漏洞（特权问题，文件权限问题，竞争条件，进程，IPC，线程，环境和信令问题）</p></li><li><p>平台漏洞（SQL注入，跨站点脚本（XSS） ），跨站点请求伪造（CSRF），文件包含和访问，shell调用，配置，访问控制和授权？aws）</p></li></ul><p>对漏洞进行分类的另一种方法是从攻击角度出发。例如，Open Web Application Security Project [3]提供了一个攻击类型列表，并定期编译一系列顶级当代漏洞[1]，并非所有漏洞都与源代码或二进制文件有关。在那些注入攻击（代码，SQL，HTML脚本，远程文件和shell）和控制流劫持，如溢出（buffer，整数，字符串格式）和堆喷射类似于我们上面列出的那些。像Bletsch这样的其他作者提供类似的分类，讨论如何通过代码重用（面向返回的编程（ROP），返回到libc（RILC），面向跳转的编程（JOP））来利用漏洞[80]。 。</p><p>随着软件中的漏洞被发现，它们通常与更广泛的社区共享。The Common Vulnerabilities and Exposures  （CVE）是一个公知的信息安全漏洞和风险的库 [4]，目前由MITRE组织维护。漏洞通常附加一个分数来描述其严重性，通用漏洞评分系统（CVSS）[40]是最常用的评分标准之一。提供对CVE，分数和其他相关信息的访问的服务包括诸如开源漏洞数据库（OSVDB）和美国国家漏洞数据库（NVD）之类的数据库。和允许对新发现的漏洞进行实时更新的API（如VulnDB和vFeed）。根据不同类别中发现的漏洞数量，每年都会根据流行漏洞编制统计数据，尽管每种类型的攻击频率和严重程度之间可能没有相关性。例如，Price和Kouns [46]列出了跨站点脚本，SQL注入，跨站点请求伪造，文件包含，拒绝服务和过度攻击，这是2014年根据OSVDB最常见的滥用行为。</p><p>减轻软件漏洞影响的方法也产生了各种策略和解决方案。尽管可能无法实现完全错误预防，但软件生产商仍希望尽量减少其产品包含漏洞的可能性。这些包括在开发周期中的全面测试和修复错误，在软件发布后提供数据，以及在安全编程语言中编写代码。在Vanegue [82]中列出了在软件发布之前可以使用的漏洞发现技术列表，例如软件测试，模糊测试和程序验证（定理证明，抽象解释，模型检查）。使用抽象语法树（AST），控制流图（CFG），程序依赖图（PDG）和代码属性图（CPG）等图形建模代码执行可以帮助识别开发过程中的问题。 OS和硬件制造商也提供了软件发布后使用的其他缓解技术。数据执行保护（DEP）/不执行（NX），地址空间布局随机化（ASLR），指令集随机化（ISR），运行时检查（金丝雀，LibSafe），程序引导，控制流完整性（CFI），数据流完整性（DFI）和控制流锁定是当前使用的一些技术，参见[80]。用于执行各种发现任务的软件工具随时可用，包括商业和开源[87]。</p><p>程序分析是分析软件行为问题的核心。从理论上讲，软件错误的识别是不可判定的，即在一般情况下不可能编写程序来表示和计算另一个程序的所有可能的执行[67]。在实践中，某些程序行为可能会被忽略，因为它们与当前分析无关。然而，这可能导致在近似下 - 排除可能有效的行为，并且过度近似–包含可能但无效的行为–增加复杂性和资源需求。图1将一些程序分析技术组织到一个图表中，突出显示了各个方法的样式和自动化级别。静态分析在不执行程序的情况下进行，可以提供良好的代码覆盖率和所有可能执行的原因，但无法分析可执行环境，例如操作系统和硬件。另一方面，动态分析是在程序执行期间进行的，或者通过检测程序来分析行为。但是，它只能推断观察到的执行路径而不是所有可能的程序路径。</p><p><img src="/2019/04/03/A-Review-of-Machine-Learning-in-Software-Vulnerability-Research/1.jpg" alt=""></p><h2 id="2-2-机器学习"><a href="#2-2-机器学习" class="headerlink" title="2.2 机器学习"></a>2.2 机器学习</h2><p>在本节中，我们简要概述了机器学习概念，并重点介绍了我们在本文后面讨论的出版物中遇到的一些相关技术。<br>存在许多不同的分类法用于分类ML技术。为方便起见，我们使用Barber [13]的书作为本节的参考源，除非给出了具体的参考。</p><p>机器学习领域关注数据的自动化探索，产生可用于预测的描述性模型。通常，认识到两种主要的学习方式：<strong>监督学习</strong>从标记数据源构建其模型并关注预测的准确性，而<strong>无监督学习</strong>则集中于从未标记数据提供紧凑描述。除了这两种主要风格外，还可以观察到几种变化。<strong>异常检测</strong>会查找与建模模型不同的数据中的异常值。随着新数据的出现，<strong>在线学习</strong>能够不断更新模型。<strong>主动学习</strong>可以通过要求来自当前模型无法有效描述的环境区域的更多数据来构建更好的模型。<strong>强化学习</strong>能够以反复试验的方式与环境互动，以创建根据某种形式的奖励进行优化的模型。最后，<strong>半监督学习</strong>利用标记和未标记的数据，使用一种类型的数据来改进可以仅从其他类型的数据创建的模型。</p><p>多年来，在上述学习方式中已经提出并开发了大量算法。监督学习主要使用多种类型的分类器中的一种来预测数据点所属的组（类）。这是一种离散学习形式，因为输出仅限于一组值。当结果需要在一个值范围内时（即它是一个连续变量），回归就是使用的技术。最简单的分类算法之一是K-最近邻（kNN）算法，它通过查看其K个最近邻居的标签并选择最常见的邻居来确定数据点的类标签，例如基于实例学习使用数据集中的示例而不是使用从中构建的模型来决定类的决策。 NaïveBayes分类器是一种概率算法，它假设描述数据的变量之间具有条件独立性，以简化生成模型的构建。点的类标签是通过使用贝叶斯规则给出不同标签的数据的概率及其条件概率来估计的。其他分类技术对数据进行线性模型，并根据与已知示例计算的决策边界相对应的数据点的位置确定类成员资格。逻辑回归是一种分类算法，它使用最大似然函数来近似属于类的数据点的概率。线性支持向量机（SVM）产生超平面以分离类，使得平面每侧上的最近点之间的距离最大化。</p><p>决策树分类器将顺序决策过程建模为特殊图形，每个节点用作特征测试，以便给定特征的不同值沿着不同的分支布置。树的叶子决定了类型成员资格。从任何特定的示例数据集中，可以构建许多不同的树，并且通常使用来自单个数据集的多个树的组合来构建更好的模型。随机森林是决策树的集合，旨在提供对作为单个树创建的模型的改进预测。图表在表示用作分类器的各种形式的神经网络（NN）[14]中也很突出。神经网络按节点层组织，包含输入层和输出层，其间有隐藏层。每个节点对应于一个函数，该函数使用分配给节点连接边的权重将其输入值映射到单个输出值。 NN分类的流行变体包括多层感知器（MLP）前馈神经网络，卷积神经网络和长期短期记忆复现神经网络。神经网络也是深度学习的核心，深度学习是一种机器学习范式，它也关注数据表示的学习。</p><p>无监督学习通常与聚类分析相关联，即基于相似性的定义将数据组织成组。这些可以包括基于数据分布的统计方法，例如使用期望最大化（EM）来构建高斯混合模型（GMM）。利用数据连接的算法是层次聚类的示例，或者是自下而上构建的，即从每个数据点开始作为集群然后是合并操作，或者自上而下，从单个集群开始并根据某种策略进行拆分。基于质心的聚类通过确定选定数量的聚类中心并将每个数据点分配给最近的聚类中心来识别聚类。另一方面，基于密度的聚类根据某个距离测量的阈值找到彼此接近的点集群，并且如果它们不满足这些要求，则可以将数据保留为未分配的噪声。Associations [5]是受市场数据分析启发的规则。它们代表了if…then构造描述数据中以某种最小所需频率出现的强模式。找到频繁项目集或特征值比其他项目更频繁地出现，可以揭示数据的趋势。顺序模式挖掘是一种具有相同目标的学习活动，但随着时间的推移分析数据，利用数据点的时间顺序来构建模型。遗传算法也是规则发现算法，它通过将交叉和变异算子应用于初始数据集并评估后续世代的精度直到满足某些终止条件来模拟自然选择。</p><p>学习通常先于预处理过程，然后是模型评估等任务。一些预处理包括特征提取，以及数据中噪声和错误的处理。特征选择和降维旨在识别与学习任务相关的特征并降低复杂性以便改进由学习算法生成的模型。有监督和无监督的学习者都可以从这个过程中受益。一些重要的例子包括主成分分析（PCA），线性判别分析（LDA），非负矩阵因子分解（NMF）和奇异值分解（SVD）。采样以减少数据大小和平衡输入数据可以提高算法的效率和性能。使用套袋和增强等集成方法可以提高单个学习算法的预测性能。出于评估目的，可以使用性能评估方法来评估算法的有效性。在二进制分类中，可以使用若干概念来描述预测条件与数据点的实际条件之间的关系。真阳性（TP）或命中，是正确预测的阳性实例。假阳性（FP）是错误预测为阳性的阴性实例。对于真阴性和假阴性，存在类似的定义。真阳性率（TPR）或算法的召回是所有阳性实例的真阳性率。精度是TP与TP和FP之和的比率，表示在预测正实例时所犯错误的数量。算法的准确性是所有数据点上正确识别的实例（TP加TN）的比率。存在许多模型评估方法，例如ROC分析[31]。结合起来，它们不仅可以提供算法评估，还可以确定其他学习策略，例如不同的特征选择方法或参数优化。</p><p>机器学习已应用于众多研究领域。可以与检查计算机程序相关的一个是自然语言处理（NLP），这是一个关注语言建模，解析和语音识别等任务的领域。可用于文档分类的一些值得注意的技术包括Latent Dirichlet Allocation（LDA）和Latent Semantic Indexing（LSI），它们都将文本建模为主题集合。</p><h1 id="3-机器学习在软件漏洞中的研究"><a href="#3-机器学习在软件漏洞中的研究" class="headerlink" title="3.机器学习在软件漏洞中的研究"></a>3.机器学习在软件漏洞中的研究</h1><p>机器学习可以为软件漏洞研究等复杂的研究领域带来许多好处。它可用于模拟代码的语法和语义，并推断代码模式以分析大型代码库，协助代码审计和代码理解，同时实现可容忍的误报率。随着SVR流程复杂性的增加，对SVR从业者可用的自动化水平的需求也在增加。结果，提出了用于发现和预防目的的分析软件的新方法。其中一些是特别的。其他人使用来自其他科学领域的现成技术，包括统计学，机器学习和数据挖掘。在接下来的部分中，我们将讨论利用主要机器学习的现有工作，根据基于内容相似性的松散分组来组织它们。</p><p>我们首先指出一小部分最近的论文，这些论文考虑在更广泛的层面上解决软件漏洞问题。例如，Avgerinos等 [11]承认在广泛使用的大型软件项目中存在软件错误，例如Firefox浏览器和Linux内核，一些已知，但其他可能仍未被发现。由于在关键软件中发现了如此多的错误，作者提出了以下问题：“我们应该尝试优先修复哪些错误？”，“我们可以确定哪些是可利用的？” Jimenez等 [41]可能表明未来可能的方式。他们分析过去已知的漏洞（在本例中为Android）并建立一个分类，列出导致软件漏洞的问题，漏洞所在代码中位置的特征，这些位置的复杂性以及漏洞的复杂性。创建公共数据集，如VDiscovery [34]收集测试用例的结果，并可用于促进进一步的研究是另一项有希望的举措，众包试的寻找bug的想法这个模型由zhao等人描述[93]。</p><h2 id="3-1-源代码分析"><a href="#3-1-源代码分析" class="headerlink" title="3.1 源代码分析"></a>3.1 源代码分析</h2><p>如前所述，减少SVR人类从业者的手动任务量是许多提议方法的主要目标。自动化的例子包括Parfait [26]，一个用于发现C / C ++代码中的错误的框架。 Parfa的每个bug类型都设计有多层，用于速度和可扩展性的程序分析。该解决方案背后的理念是采用更简单的分析来预测某些类型的错误，然后转向计算量更大的错误，以实现最佳的覆盖率和精度。另一个平台Mélange[74]也分享了同样的理念，同时也分析了C和C ++代码。 Mélange执行数据和控制流分析，并生成错误报告，以解释发现的错误，以帮助解决必要的问题。在执行阶段进行分析，包含局部和全局，后者按需使用以验证局部分析的结果。另一个例子是SZZ算法[88]，它被开发用于自动识别诱导修复的代码提交，并且可以被研究人员用来验证软件度量或模型以预测故障组件，这是防止bug的重要活动。</p><p>然而，这些方法是向自动化迈进并不一定依赖于机器学习技术的示例。以下类别详细说明了它们的用途。</p><h3 id="3-1-1-编码实践"><a href="#3-1-1-编码实践" class="headerlink" title="3.1.1 编码实践"></a>3.1.1 编码实践</h3><p>用于代码分析的机器学习的早期用途之一是PR-Miner [50]，数据挖掘技术的应用，为源代码构建一组编程规则。它从大型代码库（如Linux，PostgreSQL和Apache HTTP Server）生成频繁的项目集，以自动生成隐式编程规则，然后可以使用其他算法检查违规。对结果进行排序并按照假设的严重程度提供给分析师，以确定它们是否构成实际错误。这个过程很快，作者认为它能够识别比使用用户定义模板的类似工具更复杂的违规行为（例如，包含两个以上的规则组件）。 AutoISES [77]是一种类似的工具，它通过从源代码推断安全规范来检测漏洞，而不是要求手动提供这些漏洞。规范的推断仍然受到与安全编码实践相关的概念的指导，但现在根据代码中观察到的证据提取规则，并且违规被提供用于手动验证。 Linux内核和Xen用作测试用例，对于84个提取规则，发现了8个新漏洞。</p><p>协助开发人员正确使用应用程序编程接口（API）方法一直是一些论文的焦点，通常受到缺乏足够可用文档的启发。<br>UP-Miner工具[83]采用了几种数据挖掘方法，例如聚类和频繁闭合序列挖掘，以创建频繁的API使用模式。它还包含新的度量标准，以优化所得模式的简洁性和覆盖范围，然后将其作为概率图提供给用户以供检查和理解。与Microsoft开发人员合作对大型Microsoft代码库进行的测试证实了该方法的实用性。Nguyen等人详细介绍了另一个有趣的贡献 [59]。他们研究API前置条件，这些条件需要在调用之前通过API方法的参数来满足。他们开发了一个系统，该系统找到调用API的客户端方法，计算每个调用站点的控制依赖关系，然后挖掘用于访问这些调用站点的条件，最终推断出每个API的前提条件。使用SourceForge和Apache项目对Java Development Kit进行的大规模评估确定了书面规范中缺少的一些先决条件。此外，结果可用于识别不满足源代码中的前提条件的编码错误。本文还对早期API挖掘文献中的参考文献进行了很好的收集。</p><p>VCCFinder [62]是一个工具，它将有关代码中的漏洞的知识与有关对存储库的commits的元数据相结合，以识别可能存在漏洞的软件代码commits。为两种源类型的每个提交生成的一系列功能与已知的漏洞贡献提交案例的功能相匹配？ （VCC），从CVE的提交数据中识别，以确定新提交是否可能是漏洞的来源。为此目的构建了两级SVM。对66个GitHub项目的测试表明，与现有工具相比，误报率（FPR）大大降低，同时保持了类似的真阳性率。虽然成功识别VCC可以大大减少检查安全性的代码量，但是从业者仍然需要重要的专业知识和审核它们的手册。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h1&gt;&lt;p&gt;搜索和识别计算机软件中的漏洞具有悠久而丰富的历史，可用于预防或恶意目的。在本文中，我们研究了
      
    
    </summary>
    
      <category term="论文" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/"/>
    
      <category term="fuzzing" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/fuzzing/"/>
    
      <category term="综述" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/fuzzing/%E7%BB%BC%E8%BF%B0/"/>
    
    
      <category term="综述" scheme="http://yama0xff.com/tags/%E7%BB%BC%E8%BF%B0/"/>
    
      <category term="2017年" scheme="http://yama0xff.com/tags/2017%E5%B9%B4/"/>
    
  </entry>
  
  <entry>
    <title>Sofware Vulnerability Analysis and Discovery Using Machine-Learning and Data-Mining Techniques: A Survey</title>
    <link href="http://yama0xff.com/2019/04/02/Sofware-Vulnerability-Analysis-and-Discovery-Using-Machine-Learning-and-Data-Mining-Techniques-A-Survey/"/>
    <id>http://yama0xff.com/2019/04/02/Sofware-Vulnerability-Analysis-and-Discovery-Using-Machine-Learning-and-Data-Mining-Techniques-A-Survey/</id>
    <published>2019-04-02T13:50:44.000Z</published>
    <updated>2019-04-03T04:06:36.364Z</updated>
    
    <content type="html"><![CDATA[<p><strong>由于其中主要内容都是关于数据挖掘技术在源代码漏洞和分析中的使用总结，涉及到使用机器学习方法的较少，所以未翻译阅读完，后续再继续翻译。</strong></p><h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>软件安全漏洞是计算机安全领域的关键问题之一。由于其潜在的高严重性影响，在过去几十年中已经提出了许多不同的方法来减轻软件漏洞的损害。机器学习和数据挖掘技术也是解决该问题的众多方法之一。在本文中，我们对利用机器学习和数据挖掘技术的软件漏洞分析和发现的许多不同工作进行了广泛的回顾。我们回顾了这个领域中不同类别的工作，讨论了优点和缺点，并指出了挑战和一些未知的领域。</p><table><thead><tr><th>relevant information</th><th></th></tr></thead><tbody><tr><td><em>作者</em></td><td>SEYED MOHAMMAD GHAFFARIAN；HAMID REZA SHAHRIARI</td></tr><tr><td><em>单位</em></td><td>Amirkabir University of Technology</td></tr><tr><td><em>出处</em></td><td>ACM Comput. Surv</td></tr><tr><td><em>原文地址</em></td><td><a href="https://dl.acm.org/citation.cfm?id=3092566" target="_blank" rel="noopener">https://dl.acm.org/citation.cfm?id=3092566</a></td></tr><tr><td><em>源码地址</em></td><td></td></tr><tr><td><em>发表时间</em></td><td>2017年</td></tr></tbody></table><h1 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h1><p>如今，计算机软件无处不在，现代人类生活在很大程度上依赖于各种各样的软件。在不同的平台上运行不同形式的计算机软件，从手持移动设备上的简单应用程序到复杂的分布式企业软件系统。这些软件采用多种不同的方法生成，基于各种各样的技术，每种技术都有自己的优点和局限。这个庞大的关键行业以及计算机安全领域的一个重要问题是软件安全漏洞问题。在这个问题上引用行业专家的话：</p><blockquote><p>“In the context of software security, vulnerabilities are specifc ﬂaws or oversights<br>in a piece of software that allow attackers to do something malicious: expose or alter<br>sensitive information, disrupt or destroy a system, or take control of a computer system<br>or program.” Dowd et al. (2007) </p></blockquote><p>软件漏洞所带来的威胁的严重程度不同取决于开发复杂性和攻击面等因素（Nayak等人，2014）。在过去的二十年中，存在大量的例子和事件，其中软件漏洞给公司和个人带来了重大损害。为了强调这个问题的重要性，我们近年来提到了一些例子。一个突出的例子是流行浏览器插件中的漏洞情况，这些漏洞威胁到数百万互联网用户的安全和隐私（例如，Adobe Flash Player（US-CERT 2015; Adobe Security Bulletin 2015）和Oracle Java（US-CERT 2013） ）。此外，流行和基础开源软件中的漏洞也威胁到全球数千家公司及其客户的安全（例如Heartbleed（Codenomicon 2014）ShellShock（赛门铁克安全响应2014）和Apache Commons（Breen 2015） ）。</p><p>上述示例只是每年报告的大量漏洞中的一小部分。由于这个问题的重要性，学术界和软件行业的研究人员已经研究了许多不同的缓解方法。 Shahriar和Zulkernine（2012）提出了一项针对缓解计划安全漏洞的不同方法的广泛调查，包括测试，静态分析和混合分析，以及1994年至2010年期间发布的安全编程，程序转换和修补方法。</p><p>除了在Shahriar和Zulkernine（2012）中审查的众所周知且经过深入研究的方法之外，还存在一种不同的方法，这些方法利用来自数据科学和人工智能（AI）的技术来解决软件漏洞分析和发现。 Shahriar和Zulkernine（2012）忽略了这类有趣的方法，但在接下来的几年中（从2011年开始），研究界越来越关注这一方法。</p><p>在本文中，我们针对利用数据挖掘和机器学习技术的软件漏洞分析和发现的这类方法提出了分类评论。首先，我们确定了软件漏洞分析和发现的问题，并简要介绍了在这个领域的传统方法。我们还简要介绍了机器学习和数据挖掘技术以及它们使用背后的动机。之后，我们将分别回顾利用机器学习和数据挖掘技术解决软件漏洞分析和发现问题的许多不同工作。我们为这类作品提出了不同的类别，并讨论了它们的优点和局限性。最后，我们在结束本文时讨论了在这个领域的挑战，并指出了一些未知的领域，以激发这一新兴研究领域的未来工作。</p><h1 id="2-背景：软件漏洞分析和发现"><a href="#2-背景：软件漏洞分析和发现" class="headerlink" title="2.背景：软件漏洞分析和发现"></a>2.背景：软件漏洞分析和发现</h1><h2 id="2-1-定义"><a href="#2-1-定义" class="headerlink" title="2.1 定义"></a>2.1 定义</h2><p>我们首先说明软件安全漏洞的定义。在他关于软件漏洞分析问题的博士论文中，Ivan Krsul将软件漏洞定义为：</p><blockquote><p>“an instance of an error in the specifcation, development, or confguration of software<br>such that its execution can violate the security policy.” (Krsul 1998) </p></blockquote><p>差不多十年之后，Ozment承认Krsul的定义，但建议稍作修改：</p><blockquote><p>“A software vulnerability is an instance of a mistake in the specifcation, development,<br>or confguration of software such that its execution can violate the explicit or implicit<br>security policy.” Ozment (2007) </p></blockquote><p>Ozment将单词error更改为mistake，并引用IEEE标准术语软件工程术语（IEEE Standards 1990）来证明这一点。如前所述，行业专家提供了类似的定义：</p><blockquote><p>“In the context of software security, vulnerabilities are specifc ﬂaws or oversights<br>in a piece of software that allow attackers to do something malicious: expose or alter<br>sensitive information, disrupt or destroy a system, or take control of a computer system<br>or program.” Dowd et al. (2007) </p></blockquote><p>从上述定义可以看出，不同的关键术语用于定义软件漏洞。为了澄清这些术语并选择最合适的术语，我们参考IEEE标准软件工程术语表（IEEE标准1990）。我们查找四个关键术语的定义：“error”，“fault”，“failure”和”mistake”根据IEEE标准（1990），<strong>error</strong>的定义是：“计算的，观察的或测量的值或条件与真实的，规定的或理论上正确的值或条件之间的差异”（IEEE标准1990）。<strong>fault</strong>是：“计算机程序中的步骤，过程或数据定义不正确”（IEEE标准1990）。<strong>faults</strong>也称为flaws或bugs。<strong>failure</strong>是：“系统或组件无法在规定的性能要求下执行其所需的功能”（IEEE标准1990）。最后，<strong>mistake</strong>是：“产生错误结果的人为行为”（IEEE标准1990）。这些术语的关系的总结和澄清是“区分人类行为（mistake），其表现（硬件或软件faults），故障结果（failure）以及结果的数量不正确（error）“（IEEE标准1990）。</p><p>从这些定义可以清楚地看出，用于定义软件漏洞的合适关键术语是“fault”（也是flaw或bug）。更确切地说：</p><blockquote><p>A software vulnerability is an instance of a flaw, caused by a mistake in the design, development, or configuration of software such that it can be exploited to violate some explicit or implicit security policy.</p></blockquote><p>软件漏洞的原因是人为错误，其表现形式是flaw（fault或bug）。执行faulty 状态的软件不一定违反安全策略;直到某些特制数据（漏洞利用代码）或某些具有某些条件的随机数据到达有缺陷的语句，此时，其执行可能违反某些安全策略（利用导致安全性失败）。</p><p>其他人已经承认将软件漏洞定义为faults，并将mistake定义为其原因。 Ozment指出“由于开发错误导致的漏洞是一个fault”（Ozment 2007），但他区分了开发错误导致的漏洞，以及设计或配置错误导致的漏洞;但没有提供这种差异的解释。 Dowd等人。还说：</p><blockquote><p>“In general, software vulnerabilities can be thought of as a subset of the larger phenomenon of software bugs. Security vulnerabilities are bugs that pack an extra hidden surprise: A malicious user can leverage them to launch attacks against the software and supporting systems.” Dowd et al. (2007)</p></blockquote><h2 id="2-2-健全性，完整性和不可判定性"><a href="#2-2-健全性，完整性和不可判定性" class="headerlink" title="2.2 健全性，完整性和不可判定性"></a>2.2 健全性，完整性和不可判定性</h2><p>程序漏洞分析是确定给定程序是否包含已知安全漏洞（根据安全策略）的问题。基于图灵停止问题和赖斯定理的不可判定性，可以证明许多程序分析问题在一般情况下也是不可判定的（Landi 1992; Reps 2000）。对于从业者来说，不可判断性意味着不存在对问题的完整解决方案。</p><p>在数学逻辑中，如果系统不能批准无效参数，则证明系统是合理的。如果所有有效参数都可以被系统批准，则证明系统是完整的。通过推论，一个完整的证据系统是一个可以批准所有有效论证并反驳所有无效论证的系统（Xie et al.2005）。</p><p>在软件安全的背景下，如果漏洞分析系统从未批准易受攻击的程序（没有漏掉漏洞），那么它就是健全的。如果可以批准所有安全程序（没有虚假漏洞），则漏洞分析系统是完整的。根据推论，健全且完整的漏洞分析系统可以批准所有安全程序并拒绝所有易受攻击的程序（没有错过漏洞且没有漏洞）（Xie et al.2005）。如前所述，已知这种完善和完整的系统是不存在的（Jhala和Majumdar，2009）。</p><p>除了漏洞分析之外，更实用的系统是程序漏洞发现（或漏洞报告）系统。与批准或不批准给定程序的安全性（即二进制输出）的漏洞分析系统相比，程序漏洞发现系统报告给定的每个漏洞的更详细信息（例如类型，位置等）程序。这是软件行业更有用和理想的系统，它可以帮助开发人员和工程师更轻松地检测和修复漏洞。同样，众所周知，一个完善的软件漏洞发现系统（一个不报告漏洞，报告所有实际漏洞的系统）是不存在的。</p><h2 id="2-3传统方法"><a href="#2-3传统方法" class="headerlink" title="2.3传统方法"></a>2.3传统方法</h2><p>尽管软件漏洞分析和发现问题具有不可判定的性质，但由于该问题的重要性，学术界和软件行业的从业者已经研究和提出了大量的方法。提出的方法都不可避免地是近似解;他们都缺乏健全性或完整性，或两者兼而有之。因此，与以前的工作相比，所有研究工作都试图提出一种改进的方法，涉及软件漏洞分析和发现过程的特定方面;例如，漏洞覆盖率，发现精度，运行时效率等。</p><p>Shahriar和Zulkernine（2012）提出了对缓解程序安全漏洞的不同方法的广泛审查，包括在1994年至2010年期间的程序漏洞分析和发现方法。所有程序分析方法可分为三大类：</p><ul><li><strong>静态分析</strong>：根据源代码分析给定程序，无需执行。这些方法利用广义抽象来分析程序的属性，因此静态分析方法最健全的（即没有错过的漏洞，但可能会报告错误的漏洞）。泛化越准确，报告的漏洞就越少。在实践中，必须在分析精度和计算效率之间进行交易。</li><li><strong>动态分析</strong>：通过使用特定的输入数据执行并监视其运行时行为来分析给定程序。在这种方法中，一组输入测试用例用于分析程序的属性，并且由于通常存在无限可能的输入和运行时状态，因此动态分析系统无法分析整个程序的行为。因此，动态分析系统是最完整性的（即，批准所有安全程序而不报告虚假漏洞），但它们不可能是健全的，因为它可能会遗漏一些隐藏在看不见的程序状态中的漏洞。动态分析方法存在实际缺点，即对给定程序的工作运行时的环境要求，以及在分析大型复杂软件时处理所有输入测试用例所需的长时间和高成本。然而，动态分析方法在软件行业中得到了极大的应用。<ul><li><strong>混合分析</strong>：使用静态分析和动态分析技术的混合分析给定程序。基于先前关于静态和动态分析方法的讨论可能存在误解，混合分析方法可能是完整的和健全的（因此，违反了问题的不可判定性）。不幸的是，事实并非如此，虽然混合分析方法可以从静态和动态分析的优势中获益，但它们也受到两种方法的局限性的影响。混合分析方法可以是利用动态分析来识别错误漏洞的静态分析系统，也可以是利用静态分析技术来指导测试用例选择和分析过程的动态分析方法。</li></ul></li></ul><p>但应注意，并非所有静态分析系统都是健全的，并非所有动态分析系统都是完整的。在众多不同的漏洞发现方法中，有些在软件行业中更为成熟;亦即</p><ul><li>Software Penetration Testing: a manual software security testing approach, carried out  by a team of security experts (also referred to as white-hat hackers) (Arkin et al. 2005; Bishop<br>2007).                                                       </li><li>Fuzz-Testing: also known as random-testing, where well-formed input data are randomly  mutated and fed to the program under test at large, while monitoring for failures (Godefroid   2007; Godefroid et al. 2012).                                </li><li>Static Data-Flow Analysis: also known as “Tainted Data-ﬂow Analysis,” it is a static program analysis approach where untrusted data from input sources is marked as tainted and  its ﬂow to sensitive program statements known as sinks is tracked as a potential indicator  of vulnerability (Evans and Larochelle 2002; Larus et al. 2004; Ayewah et al. 2008; Bessey  et al. 2010).                                                </li></ul><h1 id="3-使用机器学习和数据挖掘技术"><a href="#3-使用机器学习和数据挖掘技术" class="headerlink" title="3.使用机器学习和数据挖掘技术"></a>3.使用机器学习和数据挖掘技术</h1><p>除了上述方法之外，还有一类不同的工作利用数据科学和人工智能（AI）的技术来解决软件漏洞分析和发现的问题。在Shahriar和Zulkernine（2012）的评论中忽略了这一类有趣的方法，而在接下来的几年（从2011年起），研究界越来越关注这一方法。<br>人工智能技术中的机器学习技术在许多不同的应用领域都被证明是有效的（Russell和Norvig 2009）。对于计算机安全和隐私领域也是如此，许多不同的应用程序已经使用这些技术解决（例如，垃圾邮件过滤（Guzella和Caminhas 2009; Caruana和Li 2012）和入侵检测系统（Garcia-Teodoro等。 2009; Zhou et al.2010），仅举几例）。</p><p>正如Arthur Samuel在他的开创性工作中所定义的那样，机器学习是开发计算技术和算法的研究，使计算机系统能够在没有明确编程的情况下获得新的能力（Samuel，1959）。数据挖掘是从大量数据中提取知识的计算过程，包括以下几个步骤：数据提取和收集，数据清理和集成，数据选择和转换，知识挖掘以及最终可视化和通信（Han et al.2011） 。机器学习算法和技术经常用于数据挖掘的过程中，用于预处理，模式识别和生成预测模型。</p><p>机器学习技术可大致分为三种主要方法：（1）监督学习：学习系统基于一组标记的训练样例推断出所需的功能/模型，其中每个例子由输入数据（通常是矢量）和所需的相应输出值（标签）。 （2）无监督学习：在没有标记训练数据的情况下，学习系统的目标是识别给定数据集中的模式和结构。 （3）强化学习：学习系统通过与动态环境的交互来接受奖励和惩罚，通过训练来达到某个目标。</p><h2 id="3-1希望和恐惧"><a href="#3-1希望和恐惧" class="headerlink" title="3.1希望和恐惧"></a>3.1希望和恐惧</h2><p>尽管机器学习技术在安全应用中的应用可以追溯到几十年，但近年来机器学习和数据挖掘技术的进步和能力以及它们解决许多困难应用问题的成功案例促使研究人员更加彻底调查这些技术的有效利用，以解决计算机安全和隐私领域的难题。例如，Carl Landwehr分享了他对此事的看法如下：</p><blockquote><p>“在他们的早期，计算机安全和人工智能似乎没有太多可说的对…安全研究人员的目的是解决他们认为防漏的计算基础设施或设计基础设施的漏洞……但是多年来，这两个地方的距离越来越近，特别是在攻击旨在模拟合法行为的地方……我们可能会想象系统会对他们处理的数据有一定程度的自我意识。反射系统（可以参考和修改自己的行为的系统）的概念起源于AI社区……想象一下，一个管道系统包含一个可以检测初期泄漏的智能管道系统。包含智能管道模拟的网络基础设施将引起极大兴趣。“Landwehr（2008）</p></blockquote><p>其他研究人员强调了人工智能技术在计算机安全和隐私领域获得解决复杂问题的重要作用。例如，Tyugu（2011）指出：“很明显，只有在使用人工智能方法时才能成功解决许多网络防御问题。”Heinl（2014）提出了类似的观点。</p><p>另一方面，安全社区也担心使用人工智能技术。例如，尽管在基于异常的入侵检测系统的研究中发表了大量研究，但是之前的一些研究表明这些系统很少部署在入侵检测行业（Sommer和Paxson 2010）。其他研究也对网络入侵检测的异常检测范例提出了挑战（Gates和Taylor 2006）。这些研究的结果强调了这样一个事实，即在计算机安全和隐私领域有效使用AI技术并非易事，需要对这些技术的特性有充分的了解（Sommer和Paxson 2010）。为了获得最佳结果，应该定制机器学习和数据挖掘技术以适应安全问题的特征。在这件事上，莫瑞尔说：</p><blockquote><p>“尽管过去已经完成了一些工作，但AI并没有在当今的网络安全中发挥核心作用，网络安全并不像人工智能那样强烈追求人工智能的发展领域，而其他人…… AI技术是围绕应用程序开发的。网络安全从未成为人工智能集中的一个领域……人工智能已经取得了很多成就，并且有许多与网络安全相关的知识，许多适合网络安全的新技术可以从人工智能中的现有技术中获得启发。“Morel（ 2011）</p></blockquote><p>为此，应该研究针对计算机安全问题量身定制的机器学习技术。</p><h2 id="3-2-以前工作的分类"><a href="#3-2-以前工作的分类" class="headerlink" title="3.2 以前工作的分类"></a>3.2 以前工作的分类</h2><p>在软件漏洞分析和发现的过程中，许多研究在前几年发表研究机器学习和数据挖掘技术的使用，我们在本文中对此进行了广泛的综述。我们将审查的工作分为四大类，总结如下，并将其区分如下：</p><ul><li><p>（1）基于软件度量的漏洞预测模型：大量研究利用（主要是监督的）机器学习方法构建基于众所周知的软件度量作为特征集的预测模型，然后使用该模型根据测量的软件工程指标评估软件工件的漏洞状态。</p></li><li><p>（2）异常检测方法：这类工作利用无监督学习方法从软件源代码中自动提取正常模型或挖掘规则，并将漏洞检测为多数正常和规则的异常行为。</p></li><li><p>（3）漏洞代码模式识别：这类工作利用（主要是监督的）机器学习方法从许多漏洞代码示例中提取漏洞代码段的模式，然后使用模式匹配技术来检测和定位软件中的漏洞源代码。</p></li><li><p>（4）杂项方法：一些值得注意的近期着作，利用AI和数据科学的技术进行软件漏洞分析和发现，这些技术不属于任何上述类别，也不构成一个连贯的类别。</p></li></ul><p>提议分类背后的基本原理是双重的：首先，我们区分分析程序语法和语义的工作，而不区分程序语法和语义。大多数不分析程序语法和语义的工作使用软件工程指标进行漏洞预测。另一方面，在基于分析程序语法和语义的大量研究中，我们观察到两种主要方法：漏洞代码模式识别和异常检测方法。图1直观地总结了分类方案。</p><p>虽然其他标准也可用于分类目的（例如：监督与非监督学习范式，不同的学习和挖掘技术，特征表示方案等），但它们不能创建先前作品的语义连贯类别。我们认为，拟议的分类结果会产生更有意义的研究家族，从而可以更好地比较各种方法，因此我们认为这是对有史以来研究的有组织调查的合适选择。</p><p><img src="/2019/04/02/Sofware-Vulnerability-Analysis-and-Discovery-Using-Machine-Learning-and-Data-Mining-Techniques-A-Survey/1.jpg" alt=""></p><h1 id="4基于软件度量的漏洞预测"><a href="#4基于软件度量的漏洞预测" class="headerlink" title="4基于软件度量的漏洞预测"></a>4基于软件度量的漏洞预测</h1><p>我们在本文中讨论的第一类方法是“漏洞预测模型”，它利用数据挖掘，机器学习和统计分析技术来预测易受攻击的软件工件（源代码文件，面向对象的类，二进制组件，等）基于通用软件工程指标。这些方法的主要思想来自于软件工程领域的软件质量和可靠性保证，其中软件测试和验证的有限资源需要一个指导模型来实现更有效的软件测试计划。为此，已经研究并在工业中使用“故障预测模型”（或“缺陷预测模型”）（Khoshgoftaar等人1997）。故障预测模型是基于从软件项目收集的历史数据训练的计算模型，并提供更可能包含故障的软件工件列表以优先考虑软件测试。历史数据基于不同的软件工程指标，例如源代码大小，复杂性，代码流失和开发人员活动指标（Kaner和Bond 2004）。根据IEEE标准软件工程术语表，术语“度量”被定义为“系统，组件或过程拥有给定属性的程度的定量度量”（1990）。在调查文章中回顾的软件工程领域的故障预测模型的主题上进行了广泛的研究和发表（Catal和Diri 2009; Malhotra 2015）。</p><p>基于与故障预测模型类似的动机，在软件工程领域中提出了漏洞预测模型。检测和缓解安全漏洞需要经过安全思维培训的专家进行人工分析（Heelan 2011）;然而，软件质量和可靠性保证团队的资源有限，需要引导他们进行更有效，更有效的安全审计和测试。基于漏洞是一种特定类型的故障这一事实，已经在业界和学术界提出并研究了漏洞预测模型。与故障预测模型类似，脆弱性预测模型也基于各种软件度量建立，并且不包含程序分析方法（即，分析某些属性的程序源代码）。在下文中，我们将回顾一下这个领域的一些最新作品。</p><h2 id="4-1最近工作总结"><a href="#4-1最近工作总结" class="headerlink" title="4.1最近工作总结"></a>4.1最近工作总结</h2><p>Zimmermann 等人（2010）研究了基于先前用于缺陷预测的研究中使用的经典度量来预测专有商业产品（Microsoft Windows Vista）的二进制模块中存在漏洞的可能性。作为第一个分析，他们使用Spearman的秩相关性计算度量与每个二进制的漏洞数量之间的相关性。结果表明，经典度量与漏洞数量具有统计上的显着相关性;但是，效果很小。另一项分析是评估这些指标的预测能力。作者使用二元Logistic回归分析了经典指标（流失，复杂性，覆盖，依赖和组织）的五组。模型评估采用十倍交叉验证和计算精度以及召回值。作者报告说，大多数指标预测的漏洞具有平均精度（低误报率）;然而，召回率非常低（错误的假阴性或错过的漏洞）并且覆盖率指标未能产生任何有意义的结果。结果包括精度低于67％，召回率低于21％。</p><p>Meneely和Williams（2010）研究了开发者活动指标和软件漏洞之间的关系。正在研究的开发人员活动指标包括：更改源文件的不同开发人员数量，向文件提交的提交数量，以及在贡献网络中包含文件的测序路径数量。作者对三个开源软件项目进行了研究。每个研究中收集的数据集包括一个标签，表明源代码文件是否已修补，以及版本控制日志中的开发人员活动指标。使用统计相关性分析，作者报告发现每个指标与漏洞数量存在显着的显着相关性;但相关性各不相同，并不是很强。作者使用贝叶斯网络作为预测模型，通过十倍交叉验证生成训练和验证集。据作者说，分析表明开发人员活动可以用来预测脆弱的人群;然而，精确度和召回率值令人失望（精确度在12％-29％之间，召回率在32％-56％之间）。</p><p>Doyle和Walden（2011）分析了2006年至2008年间14个最广泛使用的开源Web应用程序中的软件度量和漏洞之间的关系，例如WordPress和Mediawiki。作者使用静态分析工具（例如，Fortify源代码分析器，PHP CodeSni等等）来测量这些应用程序的源代码库中的各种度量，包括静态分析漏洞密度（SAVD），源代码大小，圈复杂度，嵌套复杂性，以及作者提出的另一个名为安全资源指标（SRI）的指标。为了预测，Spearman的等级相关性是在SAVD和其他指标之间计算的。结果表明，没有一个度量标准适用于区分高漏洞Web应用程序和低漏洞Web应用程序;然而，每个函数的平均圈复杂度是几个应用程序的有效预测器，特别是当与SRI分数结合使用时，将应用程序分类为高安全性和低安全性焦点应用程序。由于静态分析工具可能会产生很高的误报，作者手动审查了两个选定的Web应用程序的一个工具（Fortify SCA）的报告，其误报率为18％;得出结论认为假阳性率是可以接受的，对有效性没有威胁。</p><p>Shin和Williams（2013）研究了基于复杂性和代码流失度量的传统故障预测模型是否可用于漏洞预测。为此，作者使用18个复杂度指标，5个代码流失度量标准和故障历史度量标准对Mozilla Firefox进行了实证研究。测试了几种分类技术来预测故障和脆弱的人群;作者声称所有技术的结果都相似。虽然故障源代码的数量是脆弱源数量的7倍，但故障预测模型和漏洞预测模型在漏洞预测方面表现相似;召回率约为83％，精确度约为11％。基于这些结果，作者得出结论，基于传统度量的故障预测模型也可用于脆弱性预测;然而，未来的研究需要提高精确度（减少误报），同时保持高召回率</p><p>在同一作者的另一个工作中，Shin和Williams（2011）研究了使用执行复杂度指标作为软件漏洞的指标。这组作者说，这项研究背后的动机是基于安全专家的直觉，安全专家经常假设“软件复杂性是软件安全的敌人。”为此，作者对两个开源项目进行了实证案例研究，比较执行复杂性和静态复杂性指标对漏洞检测的有效性。总共，本研究收集了23个复杂度指标。作者对指标进行了判别和预测分析。对于判别分析，作者使用Welch的t检验来比较弱势文件与中性文件的度量值的均值。结果显示，其中一个项目的23个指标中有20个表现出统计上显着的判别力;但是，这仅适用于其他项目的大约一半指标，包括没有执行复杂性指标。为了评估指标的预测能力，作者使用Logistic回归进行了二元分类，并进行了十倍的交叉验证。为了解释许多指标中的冗余信息，作者基于信息增益排名执行了特征空间缩减。另一个问题是大多数（中立的人）和少数群体（弱势群体）之间的严重失衡，作者通过随机抽样多数阶层来解决这个问题。最终结果是，对于所有三组指标（代码，依赖关系，所有组合），召回率是公平的（67％-81％），但精确度令人失望（8％-12％）。总之，结果表明这些指标没有静态显着的判别力，预测能力不可靠。</p><p>Shin等人（2011）对复杂性，代码流失和开发人员活动（CCD）指标是否可用于漏洞预测进行了更广泛的研究。为此，作者对两个开源项目进行了实证案例研究。本研究共分析了28个CCD软件指标，包括14个复杂度指标，3个代码流失指标和11个开发人员活动指标。为了评估指标的判别能力，作者使用了Welch的t检验，其中两个项目的28个指标中至少有24个支持检验假设。为了评估指标的预测能力，作者测试了几种分类技术，但它们只呈现了一种分类结果，因为所有技术都提供了类似的性能。为了验证模型的预测能力，作者进行了下一次发布验证，其中有几个版本可供使用，交叉验证只有一个版本可用。评估了单变量和多变量预测假设。基于从故障预测文献中找到的平均值，作者选择阈值至少为70％用于回忆，并且最多25％用于假阳性率以支持预测假设。 28个单变量模型中只有2个，以及使用基于发展历史的指标的4个多变量模型中的3个预测了两个项目的高召回率和低误报率的脆弱性。作者得出结论，与本研究中收集的代码复杂度指标相比，开发历史指标是更强的漏洞指标。</p><p>Moshtari等人（2013）提到了先前关于脆弱性预测模型的研究的三个主要局限性，因此他们提出了一种新方法，通过解决先前研究的局限性，基于复杂性度量来预测软件中的脆弱位置。作者提出了一种半自动分析框架来检测软件漏洞，并将其输出用作漏洞信息，而不是报告的漏洞，作者声称这些漏洞提供了有关软件漏洞的更完整信息。与之前仅研究项目内漏洞预测的研究不同，本研究基于从开源项目收集的数据调查了项目内和项目间的漏洞预测。各种分类技术用于实验。在fle级别粒度下测量了一组11个单元复杂度度量和4个耦合度量。在Mozilla Firefox上进行的项目内预测的报告结果对于各种分类技术而言令人印象深刻（召回率高于90％，误报率低于10％）。作者声称，更完整的漏洞信息有助于这种改进，并通过将提出的方法与Shin等人之前的工作的复制进行比较来证明其声称的合理性。 （2011年）。在随机选择的五个项目版本上进行跨项目实验，其中一个项目被视为测试数据，模型在另外四个项目上进行了培训。根据报告的F2测量，跨项目预测的最佳模型实现了约70％的检测率，约26％的误报。</p><p>Moshtari等人。 （2013）提到了先前关于脆弱性预测模型的研究的三个主要局限性，因此他们提出了一种新方法，通过解决先前研究的局限性，基于复杂性度量来预测软件中的脆弱位置。作者提出了一种半自动分析框架来检测软件漏洞，并将其输出用作漏洞信息，而不是报告的漏洞，作者声称这些漏洞提供了有关软件漏洞的更完整信息。与之前仅研究项目内漏洞预测的研究不同，本研究基于从开源项目收集的数据调查了项目内和项目间的漏洞预测。各种分类技术用于实验。在fle级别粒度下测量了一组11个单元复杂度度量和4个耦合度量。在Mozilla Firefox上进行的项目内预测的报告结果对于各种分类技术而言令人印象深刻（召回率高于90％，误报率低于10％）。作者声称，更完整的漏洞信息有助于这种改进，并通过将提出的方法与Shin等人之前的工作的复制进行比较来证明其声称的合理性。 （2011年）。在随机选择的五个项目版本上进行跨项目实验，其中一个项目被视为测试数据，模型在另外四个项目上进行了培训。根据报告的F2测量，跨项目预测的最佳模型实现了约70％的检测率，约26％的误报。 </p><p>Meneely等人（2013）通过将Apache HTTPD Web服务器中的65个以上漏洞追溯到最初贡献易受攻击代码的版本控制提交，探讨了漏洞贡献提交（VCC）的属性。作者手动发现了124个VCC，跨越17年，他们使用统计分析技术根据代码流失和开发人员活动指标进行分析。根据这项探索性研究的结果，他们提出了几个方面：（1）代码流失度量标准与VCC在经验上相关，其方式是更大的提交可能会引入漏洞; （2）承诺更多的开发人员更有可能成为VCC; （3）由新开发商提交给来源，更有可能是VCC。</p><p>Bosu等人（2014）进行了类似的实证研究，他们分析了来自10个开源项目的260,000多个代码审查请求，使用三阶段半自动化流程识别了400多个易受攻击的代码更改。他们的目标是确定漏洞代码更改的特征，并确定可能引入漏洞的开发人员的特征。一些关键的因素包括：（1）经验不足的贡献者的变化显然更有可能引入漏洞; （2）漏洞可能性随着变化的大小而增加（更多行改变）; （3）与修改后的文件相比，新文件不太可能包含漏洞。</p><p>Perl等人（2015）研究了使用代码存储库中包含的元数据以及代码度量来识别漏洞贡献提交的效果。作者声称软件逐渐增长，大多数开源项目都使用版本控制系统，因此，提交是检查漏洞的自然单位。有了这个动机，作者编译了一个包含来自66个C / C ++ GitHub项目的170,860个提交的数据集，其中包括映射到相关CVE ID的640个漏洞贡献提交（VCC）。作者选择了一组代码流失和开发人员活动指标，以及来自不同范围（项目，作者，提交和文件夹）的GitHub元数据，并为收集的数据集提取这些功能。基于该数据集，作者评估了他们提出的名为VCCFinder的系统，该系统使用支持向量机（SVM）分类器来识别来自中立提交的VCC。为了评估，该系统在2010年底之前接受了数据培训，并根据2011年至2014年报告的CVE进行了测试。作者将他们提出的系统的结果与FlawFinder静态分析工具的结果进行了比较。在相同的召回水平（召回率= 24％），FlawFinder的精度仅达到1％，而VCCFinder达到60％的精度，产生的误报率要低得多。上述数据集由作者公开发表，作为对研究界的贡献。</p><p>Walden等人（2014）进行了一项研究，以比较基于软件度量与文本挖掘技术预测漏洞软件组件的性能。为此，作者首先构建了一个手工策划的漏洞数据集，这些数据集来自三个大型流行的开源PHP Web应用程序（Drupal，Moodle，PhpMyAdmin），包含223个漏洞。该数据集作为贡献提供给研究界。对于基于软件度量的漏洞预测，为该研究选择了一组12个代码复杂度度量。对于文本挖掘，每个PHP源文件都是第一个标记化的，不必要的标记被删除或转换（注释，标点符号，字符串和数字文字等），并计算最终标记的频率。众所周知的“词袋”技术用于从每个PHP源文本的文本标记构造数字特征向量。基于先前的漏洞预测研究经验，作者选择随机森林模型作为主要分类算法。对于模型评估，作者使用分层三重交叉验证。作者还通过对多数类（非易受攻击代码）执行随机欠采样来解决不平衡类数据的问题。根据作者的各种实验，基于文本挖掘的预测技术平均表现更好（即，更高的召回率和精确度），并且差异在统计上是显着的。作者还测试了跨项目漏洞预测，但两种方法的跨项目预测性能普遍较差。由于作者没有考虑应用程序之间数据的不均等分布，因此预计跨项目预测表现不佳。</p><p>Morrison等人（2015）指出，虽然微软团队采用了缺陷预测模型，但漏洞预测模型（VPM）并非如此。为了解释这种差异，作者尝试复制Zimmermann等人提出的VPM。 （2010）有两个较新版本的Microsoft Windows操作系统。作者将二进制水平预测精度提高了约75％，并且召回率约为20％;然而，二进制文件通常对于实际检查来说非常大，并且工程师首选源级别预测。因此，作者为源流水平粒度建立了相同的模型，其精度低于50％，召回率低于20％。基于这些结果，作者得出结论：“必须通过安全特定指标来”重新调整VPM以实现可操作的性能。“</p><p>Younis等人。 （2016）尝试识别包含更可能被利用的漏洞的代码的属性。为此，作者收集了来自Linux内核和Apache HTTPD Web服务器项目的183个漏洞，其中包括82个可利用的漏洞。作者从四个不同的类别中选择八个软件度量来表征这些漏洞，并使用Welch的t检验来检验每个度量的判别力。指标的判别力的结果是混合的;一些指标在统计上具有显着的判别力，而其他指标则没有。作者还研究了是否存在可用作可利用漏洞预测因子的指标组合，其中测试了三种不同的特征选择方法和四种不同的分类算法。表现最佳的模型是具有包装子集选择方法的随机森林分类，其实现了84％的F-度量。</p><h2 id="4-2讨论"><a href="#4-2讨论" class="headerlink" title="4.2讨论"></a>4.2讨论</h2><p>在前一小节中，我们回顾了基于软件度量的脆弱性预测模型的最新研究。表1列出了本节所述所有文章的摘要，其中我们指定了每项工作的主要差异因素。</p><p><img src="/2019/04/02/Sofware-Vulnerability-Analysis-and-Discovery-Using-Machine-Learning-and-Data-Mining-Techniques-A-Survey/2.jpg" alt=""></p><p>人们可能会质疑基于软件工程指标来预测软件漏洞存在的基本决策，作为混淆症状和原因的一个例子（Zeller etal. 2011 ）。一些研究（例如，Walden等人（2014）强调了这种批评，这些研究表明，与基于某些软件度量的脆弱性预测模型相比，软件源代码的基本文本挖掘可以在预测性能方面产生更好的结果;尽管如此，这种实证研究不能推广到所有软件项目和所有软件指标。另一方面，Tang等人最近的一项研究（2015）批评了Walden等人的结论（2014），因为他们没有考虑影响代码检查的单个组件的大小;因此，他们比较了这两种预测模型在易受影响的漏洞预测背景下的预测能力，并得出结论，这两种指标的表现相似。</p><p>使用软件度量进行漏洞预测的一个理由是，这些度量标准通常很容易获得，或者很容易在软件工程项目中获得。此外，软件故障/缺陷预测模型已经在一些软件项目中使用，而构建漏洞预测模型不需要额外的专业知识。另一方面，这些系统的目的是仅作为更好地规划和分配软件工程团队资源的指导模型。因此，基于软件度量的漏洞预测模型是工业界和学术界的一系列研究。</p><p>基于上面回顾的上述工作，很明显，基于软件指标的漏洞预测模型尚未成熟。从以往研究的回顾中可以得出一些结论，包括挑战和可能的未来工作： </p><ul><li><p>脆弱性预测模型的统计挑战是由数据集中的漏洞很少而且稀疏的事实引入的。在数据挖掘和机器学习的过程中，这个问题被称为不平衡类数据，它可以极大地阻碍机器学习算法的性能，并且有解决该问题的实践（Domingos 2012）。本节中回顾的一些先前的工作已经解决了不平衡类数据问题，并且对大多数类进行了随机欠采样。这是一个重要的问题，任何利用机器学习和数据挖掘技术的研究都不应忽视这一问题。</p><ul><li>与之前的大多数研究相比，Moshtari等人（2013）使用半自动化框架进行漏洞检测，他们使用这种框架代替通过公共咨询和漏洞数据库（例如NVD）提供的信息。与之前的作品相比，他们获得了显着更高的召回率和精确度值（即使在跨项目设置中）。这可能是一种很有前景的方法，未来的研究也可以用来收集更完整的漏洞信息并获得更好的结果。</li><li>漏洞预测模型领域中的跨项目研究很少，因此是未来工作的一个领域。特别是与缺陷预测模型相比，跨项目漏洞预测的研究非常不足。跨项目预测引入了额外的挑战，这些挑战源于训练和测试集中的数据分布可能显着变化并且阻碍传统机器学习和统计分析技术的性能。这一挑战在机器学习研究中被称为“归纳转移”（或“转移学习”）技术（Pan and Yang 2010），它们的使用已经在软件缺陷预测研究中得到了研究（Ma et al.2012 ; Nam et al.2013）。这些研究可以成为未来跨项目脆弱性预测模型研究的基础。</li><li>基于软件指标的漏洞预测研究中的大多数研究报告结果不佳。一个可能的结论是传统的软件度量标准不适合软件漏洞。 Morrison等人明确讨论了这一结论（2015年）。从此以后，确定安全特定指标，例如Doyle和Walden（2011）提出的安全资源指标（SRI）是未来研究的另一个领域。</li><li>这个领域的未知领域正在使用深度学习方法进行漏洞预测。深度学习是机器学习研究中新出现的一个主题，它在几个应用领域取得了巨大成就，并且越来越受到研究人员和从业者的关注（LeCun等人，2015）。Yang等人（2015）提出了一项关于应用深度学习方法进行即时软件缺陷预测的研究。这是脆弱性预测模型的未来研究的另一个有希望的领域。</li></ul></li></ul><h1 id="5异常检测方法"><a href="#5异常检测方法" class="headerlink" title="5异常检测方法"></a>5异常检测方法</h1><p>在本节中，我们将回顾一类使用机器学习和数据挖掘技术进行软件漏洞分析和发现的异常检测方法。异常检测是指数据中的模式不符合正常和预期行为的问题;通常被称为anomalies或outliers（Chandola等，2009）。在许多不同的研究领域和应用领域中已经广泛研究了这个问题;包括软件缺陷和漏洞发现领域。</p><p>在软件质量保证的背景下，异常检测方法旨在通过使源代码中的位置不符合应用程序编程接口（API）的通常或预期代码模式来识别软件缺陷。这种API使用模式的简单示例是malloc和free的函数调用对，或者lock和unlock。除了这些简单的众所周知的模式之外，每个API都有自己的规则和模式份额，这些规则和模式也很复杂，而且记录不完善。不符合API的预期规则和使用模式可能导致软件缺陷，也可能导致软件漏洞。</p><p>异常检测方法应用于软件质量保证的另一个领域是检测被忽视的条件或缺少检查。缺少检查是许多软件缺陷和漏洞的根源。这些检查可大致分为两类：（1）正确使用API所需的检查; （2）检查实现程序逻辑。这两种类型都可能导致软件缺陷或软件漏洞。第一种类型的示例是检查用作API函数调用的参数的输入数据的正确类型或值。缺少这样的检查可能导致软件崩溃，未定义或不期望的行为（例如，除以零）。失败也可能产生安全后果（例如，流量溢出，SQL注入等）。在访问资源对象时，缺少第二种类型的示例来检查主题的权限或权限。同样，这些逻辑缺陷可能具有安全性后果，从而导致安全逻辑漏洞（例如，机密性和完整性访问控制）。</p><p>已经提出异常检测方法用于检测不正确的API使用模式和丢失检查。这些方法的一个重要方面是自动提取正常行为，换句话说，自动提取规范，规则和模式，然后将其用作检测异常行为的基础。自动提取正常行为对于这些方法的适用性和成功性至关重要，而如果人类用户提供正常行为或规范，则会极大地妨碍该方法的效率，因为：（1）编写规范是艰巨而乏味的任务; （2）人为错误可导致不准确的指定，导致不正确的结果。</p><p>在下文中，我们按时间顺序回顾和总结以前的工作，从过去十年的早期工作开始，到近年来在软件缺陷和漏洞检测的异常检测方法中的最新工作。请注意，一些经过审核的工作侧重于安全漏洞，而其他漏洞则没有;但我们仍在审查这些工作，因为所提出的方法并非专门针对非安全性缺陷。</p><h2 id="5-1-最近工作总结"><a href="#5-1-最近工作总结" class="headerlink" title="5.1 最近工作总结"></a>5.1 最近工作总结</h2><p>已经提出异常检测方法用于检测不正确的API使用模式和丢失检查。这些方法的一个重要方面是自动提取正常行为，换句话说，自动提取规范，规则和模式，然后将其用作检测异常行为的基础。自动提取正常行为对于这些方法的适用性和成功性至关重要，而如果人类用户提供正常行为或规范，则会极大地妨碍该方法的效率，因为：（1）编写规范是艰巨而乏味的任务; （2）人为错误可导致不准确的指定，导致不正确的结果。</p><p>在下文中，我们按时间顺序回顾和总结以前的工作，从过去十年的早期工作开始，到近年来在软件缺陷和漏洞检测的异常检测方法中的最新工作。请注意，一些经过审核的工作侧重于安全漏洞，而其他漏洞则没有;但我们仍在审查这些工作，因为所提出的方法并非专门针对非安全性缺陷。</p><p>Engler 等人（2001）指出，解决程序错误的一个主要障碍是知道系统必须遵守的正确性规则，这些规则通常是无证的或以临时方式指定的。为了解决这个问题，他们演示了一种自动提取程序源代码隐含的程序员beliefs的技术。为此，他们讨论了错误作为异常行为的概念，并提出了一种方法，通过为源代码定制“规则模板”来提取程序员的beliefs（例如，规则模板“<a>必须与之配对的函数调用 <b>“）。提取了两种类型的规则：（1）Must-beliefs 和（2）May-beliefs。Must-beliefs 是某些众所周知的编程规则（例如，“指针解引用意味着程序员必须相信指针是非空的”）。 May-belief是一些代码特征表明beliefs的情况，但可能是巧合。为了区分有效的May-beliefs 和巧合，使用称为Z-排名的统计分析技术来发现这些beliefs的违规（或错误），以对错误进行排序和分类。为了评估，作者检查了复杂软件系统上的各种规则模板，例如Linux和OpenBSD项目。结果显示不同情景下的假阳性率不同，从4％到57％不等。作者还使用众所周知的安全漏洞规则测试安全检查程序，导致Linux和OpenBSD中出现35个安全漏洞。</b></a></p><p>Livshits和Zimmermann（2005）提出了一个名为DynaMine的工具，它根据高度相关的方法调用分析修订历史中的源代码校验，以自动提取特定于应用程序的编码模式。 DynaMine分析增量变化，这有助于实现更精确的结果。所提出的方法首先预处理已插入的方法调用的软件修订历史，并将该信息存储在要挖掘的数据库中。挖掘方法基于经典先验算法的修改版本，其使用一组项目作为其输入并且在项目之间产生频繁的项目集和强关联规则。这些修改改进了算法的运行时间，并允许该方法进行扩展以分析大型软件系统。此外，作者将几种排名策略应用于算法挖掘的模式。提取的模式被呈现给用户以进行评估。在用户选择模式之后，使用动态分析工具进一步验证所选模式并检测违规。该方法在两个大型Java项目上进行了评估。据作者称，拟议的挖掘方法发现了56种以前未知的，高度应用程序特定的模式。根据实验结果，56个（57％）模式中有32个在运行时被击中，其中32个（66％）模式中的21个被认为是非常有效的模式。此外，发现超过260种模式违规，但作者没有评估假阳性率。</p><p>Li和Zhou（2005）断言程序通常遵循许多隐式和未记录的编程规则，这些规则违反了这些规则，不知情的程序员很容易引入缺陷。作者提出了一种名为PR-Miner的方法，用于从大型源代码中提取隐式编程规则，而无需事先了解软件，也不需要程序员的大量工作。 PRMiner旨在以一般形式（没有fxed模板）提取编程规则，包含不同类型的多个元素，如函数，变量和数据类型。总之，PR-Miner首先解析和预处理程序源代码，删除不必要的元素，如关键字，常量数据值等，并根据数据将结构中的函数和数据中的局部变量重命名为相似的名称类型。在预处理之后，所有程序元素被散列为数字，并且函数定义被映射到函数内的所有元素的一组数字散列值，作为行插入到项集数据库中。使用频繁项集挖掘算法（即FPclose）挖掘该数据库，以找出一起出现的频繁程序元素。这些频繁的程序元素集称为编程模式。有效的规则生成算法用于从频繁的编程模式中提取编程规则。编程规则用于检测违规，这是基于在大多数情况下通常遵循编程规则并且很少发生违规的想法。对三个大型开源项目进行评估。结果表明，PR-Miner在这些软件项目中发现了数以千计的规则，作者无法对所有这些规则进行验证，只讨论了一些样本。 PR-Miner还报告了许多违规行为，作者设法仅手动评估前60位报告，揭示假阳性率很高（73％-90％之间）。</p><p>Wasylkowski等（2007）重申这样一个事实，即与对象交互通常需要遵循模型或协议，这些模型或协议并不总是记录在案，并且违规可能导致缺陷。为了自动提取典型的对象使用模型，作者提出了在程序源代码中挖掘方法调用的序列，然后将其用作偏差作为缺陷候选者。首先，从Java字节码中提取对象使用模型，Java字节码是具有匿名状态的fnite状态自动机，以及作为状态转换的可行方法调用。使用每个单一方法的过程内静态分析来提取该模型。然后，使用对封闭模式的频繁项集挖掘，从使用模型中挖掘方法调用的时间属性（例如，“方法next（）可以在hasNext（）之前”）。这些频繁的模式表示正常的对象使用，并用于训练分类器以识别对这些模式的违反，这些模式被视为可能的缺陷位置。此外，作者还引入了一个缺陷指标，该指标根据几个因素对异常进行排序。提出的方法是作为一个名为JADET（用于Java异常检测器）的工具实现的。评估是在fve流行的开源Java程序上进行的。根据报告的结果，在所有5个项目中JADET检测到的前77个异常中，有40个（52％）误报，5个缺陷，5个代码smells和27个提示。</p><p>Acharya等（2007）指出以前的方法无法在API使用模式中捕获一些有用的排序信息，特别是当跨不同的进程涉及多个API时。作者提出了一种从API客户端代码中提取“频繁部分规则”的自动方法。该方法包括四个主要步骤，并基于一些名为MAPO的作者的先前工作（Xie和Pei 2006）。在第一步中，采用下推模型检查（PDMC）过程来提取与API相关的进程间控制流敏感的静态迹线。在第二步中，在给定的跟踪上使用算法来分离不同的使用场景，因此可以单独挖掘每个场景。在第三步中，名为FRECPO的方法用于从每个静态执行跟踪中提取的一组场景中挖掘“频繁闭合的部分规则”（FCPO）。 FCPO可能不是通用模式，只能针对分析的客户端代码进行指定。为了解决这个问题，引入了一个名为Mine-Verify的算法，该算法使用两个随机拆分的不相交的客户端集来验证模式。为了评估，该框架应用于X11 UNIX窗口系统的72个客户端程序。对于每个实验，随机选择36个客户作为挖掘客户端，其余36个客户端用作验证客户端。作者没有对他们的实验结果进行评估，而是仅对一个例子进行评估;为此，通过该方法成功检测到6种已知模式中的5种，并且仅报告了一种错误模式。</p><p>Chang等 （2008）通过对Firefox项目的版本1.0和1.5中的bug fxes进行初步研究，强调忽略条件作为一种难以解决的缺陷类别的重要性，该项目显示167个选定的错误中有109个（65％）涉及一个或多个被忽视的条件。为此，作者提出了一种方法，将数据挖掘技术与静态程序分析相结合，以提取代码库中的隐式条件规则，并将被忽视的条件作为规则违规进行检测。因此，程序由“系统依赖图（SDG）”表示，作为修改的“过程依赖图（PDG）”的集合，称为“增强PDG”（EPDG）。 EPDG增加了所谓的“共享数据依赖边缘”（SDDE），它链接在控制流路径中使用相同变量定义的程序元素。潜在规则由EPDG minors代表，可以将其视为EPDG的子图，其中一些路径已经收缩到边缘。 “启发式最大频繁子图挖掘（HMFSM）”算法用于在EPDG子图的“近传递闭包（NTC）”的数据库中找到重复的图minors。在提取和确认有效规则之后，使用启发式图匹配算法搜索NTC图数据库的规则违反（忽略条件）。为了评估，作者通过在四个开源项目中应用该方法进行了实验。在所有四个项目中，该方法检测到超过1200个候选规则，平均不到25％的检测规则无效（没有语义意义）。启发式图匹配算法在fnding规则实例中完全成功，具有100％的精度，但违规检测的结果并不令人印象深刻，其中所有四个项目中79％的报告违规都是误报。作者声称“大约一半的误报是由语义上等同的陈述给出了不同的标签”，并提出了改善未来工作情况的一些建议。</p><p>Thummalapenta和Xie（2009）提出了一种新方法来降低自动挖掘编程规则的误报率。为此，他们引入了“替代模式”的概念，其中API调用的各种频繁模式被一起考虑。例如，替代模式可以是P1或P2形式，其中P1和P2都是频繁的，P2是P1的语义替代。误报的另一个原因是不平衡的替代模式，其中P1和P2是语义上有效的替代方案，但P1是高频率的，而P2在整个代码库中并不常见。这些不平衡的替代方案表示为“P1或P2”，使用传统的挖掘技术更具挑战性。提出了一种称为“Alattin”的方法，其包括称为“ImMiner”的新挖掘算法，其使用迭代挖掘策略来挖掘平衡和不平衡模式以及用于检测被忽略条件的技术。首先，Alattin在源代码中提取重用的API，并将它们提供给代码搜索引擎以收集其他相关的代码示例。在收集的数据库上执行频繁的项集挖掘以提取频繁的模式。然后，对于每个频繁模式，输入数据库被分成两个负数据库和正数据库，其中否定数据库包括不符合模式的所有模式候选者，而肯定数据库包括所有符合候选者。频繁的项目集挖掘再次应用于否定数据库以构建不平衡的替代模式。然后使用这些挖掘的模式来检测方法调用站点处的违规。为了检测被忽略的条件，Alattin提取围绕API调用站点的所有条件检查。由于每个挖掘模式都包含多个备选方案，因此只有在呼叫站点不满足任何备选方案时，Alattin才会报告违规行为。出于评估的目的，对6个Java库执行了经验实验，其中总共144个模式被挖掘，运行时间约为1小时。作者手动评估了144种模式中的90种，其中75种（83％）是真实规则，7种是部分规则，8种（9％）是错误规则。与类似方法相比，对相同文库进行违规检测的实验导致假阳性减少28％。</p><p>Gruska等（2010）研究了跨项目异常检测的可能性。为此，作者引入了一种轻量级，与语言无关的解析器，适用于分析用几种语言编写的程序，语法类似（包括C，C ++，Java和PHP）。由于所提出的方法基于程序结构和函数调用，因此可以忽略源代码中存在的许多细节，并且解析器仅解析源代码的选定部分;这就是使解析器轻量级和语言无关的原因。解析过程包括几个步骤，包括创建令牌，识别结构和提取函数调用。类似于抽象语法树（AST）的专门设计的通用抽象表示用于存储由解析器提取的信息。抽象表示用于创建函数模型，这些函数模型是有限状态机，其中状态表示代码中的位置，转换是函数调用。此模型用于在特定函数中提取所有可能的函数调用序列以及其他相关信息，例如被调用函数的名称，参数数量，参数，返回值和目标。然后，将每个函数模型转换为一组时间属性，表示函数调用之间的值的流动。这是通过使用作者之前的工作中的JADET工具来实现的（Wasylkowski等人，2007）。扩展JADET工具以支持上述模型，并用于从功能模型中挖掘频繁的时间属性。概念分析方法用于异常检测，类似于JADET工具中使用的方法。最后，在呈现给用户之前对检测到的异常进行排序和过滤。为了进行评估，开发了6000多个开源Linux项目，以提取1600万个临时属性，反映正常的API使用情况。作者从分布中随机选择了20个项目，并应用了异常检测。从总共138个检测到的异常中，只有前25％是由作者手动评估的，这导致仅4个缺陷，7个代码异味和39个（78％）误报。作者还将其分析系统作为基于网络的服务提供给checkmycode.org，该服务目前已停止服务，截至2011年底。</p><p>Yamaguchi等人 （2013）提出了一个名为Chucky的系统，用于自动检测源代码中的缺失检查，旨在协助手动代码审计。 Chucky将机器学习技术与静态程序分析相结合，以确定缺失的检查。作者在源代码中区分了两种类型的安全检查：（1）检查实现安全逻辑（例如，访问控制）; （2）检查确保安全的API使用（例如，检查大小）。 Chucky采用了一个五步程序，为审核员选择的每个源和接收器执行。分析从基于岛语法的强大解析开始，其中为每个函数定义提取条件，赋值和API符号。其次，基于函数中API符号的相似性，使用最近邻和词袋技术来执行邻域发现。第三，执行轻量污染以仅确定与目标源或接收器相关联的那些检查。第四，基于受污染的条件将所有函数及其邻居嵌入向量空间中。最后，通过首先计算所有嵌入相邻向量的质心作为正态性模型来执行异常检测，然后基于其向量与其邻域的正常模型的距离计算每个函数的异常分数。基于异常分数对最终结果进行排序并呈现给用户。进行定性和定量评估以证明该方法的有效性，他们分析了几个开源项目代码中缺失的检查。作者报告说，Chucky在所有项目中都发现了几张丢失的支票，其中几乎所有前10名都报告了每项功能的异常，其中包含缺陷或安全漏洞。此外，在本研究过程中还使用Chucky发现了12个先前未知的漏洞（即0-day）。</p><h2 id="5-2-讨论"><a href="#5-2-讨论" class="headerlink" title="5.2 讨论"></a>5.2 讨论</h2><p>在上一小节中，我们回顾并总结了异常检测领域的一些研究，以发现软件缺陷和漏洞为异常行为。表2中还列出了本节中所有文章的概览，其中我们指定了每项工作的主要差异因素。</p><p><img src="/2019/04/02/Sofware-Vulnerability-Analysis-and-Discovery-Using-Machine-Learning-and-Data-Mining-Techniques-A-Survey/3.jpg" alt=""></p><p>如前所述，异常检测方法可用于解决由于API使用不当导致的技术软件漏洞，以及由于忽略条件或缺少检查而导致的逻辑漏洞。需要注意的一个重要事实是，此过程可以由工具自动执行，而无需指定安全策略或安全性规范。我们认为，这是异常检测方法最有希望的方面。但是，软件缺陷和漏洞发现的异常检测方法存在局限性：</p><ul><li>异常检测方法仅适用于成熟的软件系统。此限制是因为基本假设缺少检查或不正确的API使用是罕见事件，并且应用于安全对象的大多数条件以及软件项目中的API使用都是正确的。这种假设在成熟的软件项目中主要适用。</li><li>在代码库中必须经常进行条件检查或API使用，以便通过挖掘算法将其检测为模式。罕见的检查或API使用不太可能作为模式被挖掘，因此无法检测到偏差。所有利用频繁项集挖掘方法的工作都受此限制（例如，Li和Zhou（2005），Wasylkowski等（2007年），和Gruska等人（2010））。</li><li><p>有时，异常检测方法无法指定缺陷或漏洞的类型，因为这些方法只能说明给定代码不符合任何正常规则或模式，并且可能违反任何规则或模式。当然，可能存在实例明显违反单个规则或模式而不是任何其他实例的情况，在这种情况下，系统可以指定缺陷的类型甚至修复。</p></li><li><p>先前方法的高假阳性率表明这些系统尚不可靠，输出需要仔细的人工审核，这限制了异常检测系统的可用性。从高假阳性率中得到的一些值得注意的工作包括（Li和Zhou 2005; Wasylkowski等人2007; Chang等人2008）。</p></li></ul><p>异常检测方法的局限性并不仅限于软件缺陷和漏洞发现领域，许多其他应用领域也存在这些缺点。异常检测范式在网络入侵检测领域受到挑战;例如盖茨和泰勒（Gates and Taylor，2006）提出了一个具有挑衅性的讨论，他们质疑研究人员通常做出的一些假设。Sommer和Paxson（2010）还提供了关于采用异常检测方法进行网络入侵检测的挑战的讨论。 Chandola等人提供了关于不同应用领域中异常检测系统的挑战和不同方面的更一般性讨论（2009年）。</p><p>很明显，在使用异常检测的漏洞发现方面仍有进一步发展的空间。从先前研究的回顾中得出的一些可能的未来工作如下： </p><ul><li><p>先前关于缺陷和脆弱性发现的异常检测的工作中的普遍问题是高假阳性率。分析工具输出中的高误报率使其用户压倒无效。通过降低假阳性率来提高准确性对于未来的工作非常重要。 Thummalapenta和Xie（2009）的工作是这方面研究的一个例子，它提供了有趣的贡献。</p><ul><li>像Chucky（Yamaguchi等人，2013）这样以安全为重点的方法存在的一个问题是无法区分安全相关的异常（漏洞异常）和非漏洞的异常。这些方法可以成功地解决缺少检查和不正确的API使用缺陷，但并非所有这些缺陷都是安全漏洞。未来的工作可以提出新方法来帮助区分缺陷和安全漏洞，使结果与安全分析师更相关并提高可用性。</li><li>Graphs是丰富的表示，广泛用于程序分析，软件测试和软件漏洞发现领域。 Chang等（2008）研究了使用图挖掘和图匹配技术来发现软件中的缺失检查缺陷。如前所述，这项工作在提取规则和匹配实例方面取得了可喜的成果，但却产生了很高的误报率。最近的一项调查由Akoglu等人发表（2015），回顾了基于图的异常检测和描述的最新进展。在未来的工作中可以进一步研究用于漏洞发现的基于图的异常检测领域。</li></ul></li></ul><h1 id="6漏洞代码模式识别"><a href="#6漏洞代码模式识别" class="headerlink" title="6漏洞代码模式识别"></a>6漏洞代码模式识别</h1><h2 id="6-1最近工作总结"><a href="#6-1最近工作总结" class="headerlink" title="6.1最近工作总结"></a>6.1最近工作总结</h2><h2 id="6-2讨论"><a href="#6-2讨论" class="headerlink" title="6.2讨论"></a>6.2讨论</h2><h1 id="7其他方法"><a href="#7其他方法" class="headerlink" title="7其他方法"></a>7其他方法</h1><h1 id="8应用技术分析"><a href="#8应用技术分析" class="headerlink" title="8应用技术分析"></a>8应用技术分析</h1><h2 id="8-1特征工程和表示"><a href="#8-1特征工程和表示" class="headerlink" title="8.1特征工程和表示"></a>8.1特征工程和表示</h2><h2 id="8-2模型构建"><a href="#8-2模型构建" class="headerlink" title="8.2模型构建"></a>8.2模型构建</h2><h2 id="8-3模型评估"><a href="#8-3模型评估" class="headerlink" title="8.3模型评估"></a>8.3模型评估</h2><h1 id="9结论和未来工作"><a href="#9结论和未来工作" class="headerlink" title="9结论和未来工作"></a>9结论和未来工作</h1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;由于其中主要内容都是关于数据挖掘技术在源代码漏洞和分析中的使用总结，涉及到使用机器学习方法的较少，所以未翻译阅读完，后续再继续翻译。&lt;/strong&gt;&lt;/p&gt;
&lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;head
      
    
    </summary>
    
      <category term="论文" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/"/>
    
      <category term="数据挖掘" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"/>
    
      <category term="综述" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/%E7%BB%BC%E8%BF%B0/"/>
    
    
      <category term="综述" scheme="http://yama0xff.com/tags/%E7%BB%BC%E8%BF%B0/"/>
    
      <category term="2017年" scheme="http://yama0xff.com/tags/2017%E5%B9%B4/"/>
    
      <category term="数据挖掘" scheme="http://yama0xff.com/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"/>
    
  </entry>
  
  <entry>
    <title>A Survey on Source Code Review Using Machine Learning</title>
    <link href="http://yama0xff.com/2019/04/02/A-Survey-on-Source-Code-Review-Using-Machine-Learning/"/>
    <id>http://yama0xff.com/2019/04/02/A-Survey-on-Source-Code-Review-Using-Machine-Learning/</id>
    <published>2019-04-02T12:14:25.000Z</published>
    <updated>2019-04-02T13:49:23.662Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>源代码审查充分限制了软件系统的安全性。可伸缩性和精度对于代码审查工具的部署非常重要。但是，传统工具只能通过繁琐的大规模源代码审查来自动检测一些高误报和漏报的安全漏洞。各种脆弱点和漏洞在源代码中显示出特定的特征。机器学习系统建立了源代码的特征矩阵作为输入，包括变量，函数和文件，通过区分或生成方法生成ad-hoc标签，以自动和智能地查看源代码。无论编程语言如何，源代码本质上都是文本信息。安全和易受攻击的函数都可以从源代码凸出。幸运的是，已经开发了各种机器学习方法来学习和检测智能源代码安全审查中的脆弱点和漏洞。代码语义和句法特征的组合有助于在源代码审查期间对假阳性和假阴性的优化。在本文中，我们使用机器学习方法对与智能源代码安全性审查相关的文献进行了回顾。它说明了在源代码安全审查中接近ML的主要证据。我们相信机器学习及其分支机构将在源代码审查中脱颖而出。</p><table><thead><tr><th>relevant information</th><th></th></tr></thead><tbody><tr><td><em>作者</em></td><td>Wang Xiaomeng, Zhang Tao, Xin Wei,Hou Changyu</td></tr><tr><td><em>单位</em></td><td>China Information Technology Security Evaluation Center Beijing, China;China anhua technology Limited company Beijing, China</td></tr><tr><td><em>出处</em></td><td>2018 3rd International Conference on Information Systems Engineering</td></tr><tr><td><em>原文地址</em></td><td><a href="https://ieeexplore.ieee.org/document/8614720" target="_blank" rel="noopener">https://ieeexplore.ieee.org/document/8614720</a></td></tr><tr><td><em>源码地址</em></td><td></td></tr><tr><td><em>发表时间</em></td><td>2018年</td></tr></tbody></table><h1 id="I-介绍"><a href="#I-介绍" class="headerlink" title="I. 介绍"></a>I. 介绍</h1><p>​        本文介绍了机器学习（ML）在源代码审查中文献综述的研究成果。代码审查目标是发现错误，安全漏洞和违反程序规范。代码错误，弱点或漏洞在软件中很普遍，并且可能导致各种安全问题，包括死锁，信息泄露或系统崩溃，更严重的是，一些黑客攻击[1]。WannaCry勒索软件攻击是2017年5月WannaCry勒索软件发起的全球网络攻击[2]。该攻击于2017年5月12日星期五开始[3] [4]，据报道，在一天之内，已有150多个国家的230,000多台计算机受到感染。 [5] [6]英国国家健康服务（NHS）的部分地区受到感染，导致其在袭击期间仅在紧急情况下运行一些服务，西班牙的TelefónicaFedEx和Deutsche Bahn以及许多其他世界各国和公司[7]。中国的一些Windows操作系统已经被感染，而校园网用户已经是第一个遭受严重破坏的用户。大量的实验室数据和毕业设计已被锁定。一些大型企业的应用系统和数据库文件在加密后无法正常运行。这些袭击威胁到企业，政府和消费者，随着黑客犯罪对全球经济的年度成本增加，费率和成本也在增加。2017年，估计全球安全市场将超过1200亿[1]。因此，检测到更早的漏洞或错误，软件系统将更好。作为软件安全保护最重要的部分之一，源代码审查已经服务了数十年，并且已经通过ML和数据挖掘将更多智能方法植入到挖掘代码漏洞中。</p><p>​        在过去的十年中，ML在代码审查中得以蓬勃发展[8] [9] [10] [11]。本文描述和讨论了ML算法和应用的最新技术。机器学习已经在源代码安全任务中得到应用，例如代码推荐，源代码错误检测和代码检索。传统的机器学习系统利用手动特征工程来进行代码错误检测，这是标签只能临时的用于特定项目。随着机器学习的核心扩展，深度学习方法能够通过很少的手动操作捕获复杂的自下而上功能。深度学习可以智能地提取错误的代码特征，将程序特征与查询的特征匹配，并预测下一个可能代码的概率[1]。源代码最终是文本信息，主要涉及深度学习中的自然语言（NLP）研究。不幸的是，考虑到编程语言和自然语言之间的结构差异，现有的NLP算法对于代码表示是不合适的。为了提取适用的特征表示，需要整理现有方案和改进策略的缺陷[12]。</p><p>​        在本文中，我们从以下几个方面对源代码审查进行了详尽的概述：第二节简要介绍了经典的源代码分析(SCA)，包括典型的验证方法和进程流程。第三节说明了现有的机器学习SCA方法，如传统的机器学习方法和深度学习应用在源代码审查中。第四部分总结了整篇论文的一些结论，说明了存在的问题，并展示了一些未来的工作，并承认了本文的贡献者。</p><h1 id="II-经典的静态代码分析"><a href="#II-经典的静态代码分析" class="headerlink" title="II 经典的静态代码分析"></a>II 经典的静态代码分析</h1><p>​        静态代码分析（SCA）通常作为代码审查的一部分执行，并在安全开发生命周期（SDL）的实施阶段执行。 SCA的程序。 SCA通常是指通过使用数据流分析，污点分析，符号执行等技术的工具来试图发现“静态”（非运行）源代码中可能存在的漏洞。<br>​        假阳性和假阴性揭示了SCA的局限性。在分析与闭源组件或外部系统交互的应用程序时，可能会报告误报结果，因为如果没有源代码，则无法跟踪外部系统中的数据流，从而确保数据的完整性和安全性。静态代码分析工具的使用也可能由于工具不会报告漏洞导致漏报。如果在外部组件中发现新漏洞，或者分析工具不了解运行时环境以及是否已安全配置，则可能会发生这种情况。<br>​        以前的工作已经证明，经典SCA能够预测源代码漏洞，尽管有时会出现不可接受的误报和漏报。最近，人工智能，尤其是机器学习及其相关分支，对SCA的学术对话产生了重大影响，下一部分将对此进行研究。</p><p><img src="/2019/04/02/A-Survey-on-Source-Code-Review-Using-Machine-Learning/1.jpg" alt=""><br>图1.经典SCA的草图。从易受攻击的代码中提取的功能揭示了漏洞规则。模型构建有助于对程序进行建模。经典SCA探索数据流，符号执行，污点分析，模型检查和定理证明来审查源代码。审核结果需要通过认证和分类。最终，建立了漏洞收集。</p><h1 id="III-机器学习SCA"><a href="#III-机器学习SCA" class="headerlink" title="III 机器学习SCA"></a>III 机器学习SCA</h1><p>​        在过去十年中，ML在基于特征表示的智能代码审查中蓬勃发展。 ML任务可以分为传统的机器学习，深度学习和强化学习，如图2所示。传统的机器学习包括监督学习和无监督学习。对于监督学习，计算机将显示示例输入及其所需标签，目标是学习将输入映射到输出的一般规则或功能。然而，对于无监督学习，没有给学习算法赋予标签，使其自己在其输入中找到结构。无监督学习可以是特征学习过程。</p><p>​        深度学习使用多层非线性处理单元级联进行特征提取和转换[13]。每个连续层使用前一层的输出作为输入，以有监督和/或无监督的方式学习，学习对应于不同抽象级别的多个级别的表示，并利用某种形式的梯度下降通过反向传播进行训练[14] 。它们还可以包括在深度生成模型中逐层组织的潜在变量，例如Deep Belief Networks  和Deep Boltzmann Machines 中的节点。相比之下，强化学习似乎更加智能，计算机程序与必须执行某个目标的动态环境相互作用。该程序在奖励和惩罚方面提供反馈，因为它在问题空间中导航。这些输入来自在线或离线源代码存档。</p><p><img src="/2019/04/02/A-Survey-on-Source-Code-Review-Using-Machine-Learning/2.jpg" alt=""></p><p>图2.源代码在ML，DL和RL的审查项目中占主导地位。数据集和知识库管理ML和DL中静态分析的数据空间。虽然提取预处理和特征表示表面和潜在特征作为ML和DL训练的输入。 DL采用复杂的多层结构，如深度神经网络，与ML中的不同，利用简单的神经网络。 ML和DL都生成一个模型来预测它所属的输入源代码片。 RL提出了一些区别。源代码在预处理和特征表示中组装。结果输出到RL闭环，通过奖励和状态在环境行动的条件下实现目标。环境向知识库提供反馈，直到实现目标</p><h2 id="A-传统机器学习SCA"><a href="#A-传统机器学习SCA" class="headerlink" title="A.传统机器学习SCA"></a>A.传统机器学习SCA</h2><p>​        Internet上有各种源代码存档。这些档案通常由应用程序类别和各种编程语言组成。但是，手动组织源代码存储库并不是一件容易的事，因为它们会迅速增长到非常大的规模。用于归档源代码自动分类的机器学习方法被演示为11个应用主题和10种编程语言。对于局部分类，近年来来自Ibiblio和Sourceforge档案的C和C ++程序主导了研究。支持向量机（SVM）分类器在给定编程语言或特定类别的程序的示例上进行训练。源代码可以准确地自动分类为主题类别，并且可以被识别为特定的编程语言。群集假设和信息理论的基本假设被用来发现软件系统中语义连贯的主题[15]。生成主题的有用性通过人工判断凭经验验证。此外，一个案例研究表明，报告了在分析代码演变时所提出的方法的操作。与传统的主题建模技术相比，这种提出的方法产生了稳定，可解释和更具表现力的主题，而无需进行广泛的参数校准。仍然缺少在有限时间预算内进行OS规模计划评估的方法。 [3] <strong>VDiscovery</strong>，收集了轻量级的静态和动态功能，以预测测试用例是否可能包含ML上的软件漏洞。在静态级别，比较程序切片之间的相似性可能是个好主意。智能手机用户面临着一个安全困境：他们安装的许多应用程序都依赖于隐私敏感的数据，尽管它们可能来自可靠性难以判断的开发人员。研究人员已经使用越来越复杂的静态和动态分析工具解决了这个问题，以帮助评估应用程序如何使用私有用户数据[16]。<strong>SUSI</strong>提出一种新颖的机器学习指导方法，用于直接从任何Android API的代码中识别源和目的。给定一组手工注释的源和接收器，SUSI识别整个API中的其他源和接收器。为了提供更细粒度的信息，SUSI进一步对源和目的[17]进行了分类。输入验证不充分导致许多漏洞，因此省略或缺少检查可以找到发现安全漏洞的宝贵线索。 <strong>Chucky</strong>能够实时准确地识别丢失的校验，最终使我们能够发现其中两个项目中12个以前未知的漏洞[18]。由于算法密集型特性或对潜在大规模数据的应用，机器学习系统是独特的，因此值得特别考虑。进行实证研究以分析机器学习系统中的错误并报告错误类别与错误严重性之间的关系[19]。</p><h2 id="B-深度学习SCA"><a href="#B-深度学习SCA" class="headerlink" title="B. 深度学习SCA"></a>B. 深度学习SCA</h2><p>​        最近，深度学习极大地影响了SCA的审查。卷积神经网络（CNN）已经在处理各种NLP任务中获得了普及。特别是对于文本分类，深度学习模型取得了显着成果[1] [16] [18] [20]。所提出的模型使用字嵌入层，接着是具有多个滤波器的卷积层，最大池化层，最后是softmax层。采用非静态和随机初始化的嵌入层，因此从头开始训练载体。最常见的ML任务依赖于代表代码特征的手动特征设计。不幸的是，所有这些都在检索源代码的语义和句法解释方面遇到了挑战，这是构建准确预测模型的重要能力[1]。卷积网络能够进行恶意软件分类和分析。实现了由卷积和前馈神经构造组成的神经网络。该体系结构体现了一种分层特征提取方法，该方法将n-gram指令的卷积与从可移植可执行文件（PE）的头部派生的特征的简单矢量化相结合。评估结果表明，我们的方法优于基线方法，例如简单的前馈神经网络和支持向量机，因为它在精度和召回率方面达到了93％，即使在数据混淆的情况下也是如此[20]。</p><p>​        一种新兴的方法是将软件代码视为一种文本形式，并利用（NLP）技术自动提取特征。以前的工作使用BOW将源代码文件表示为与频率相关的代码令牌的集合。这些术语是用作其脆弱性预测模型的预测变量的特征。</p><p>​        经典NLP技术与深度学习结合使用被用于检测、分类非NLP应用和报告与人为约束语言（如编程语言及其编译对应语言）中发现的漏洞或不良编码实践相关的弱点[21]。在我们的结果中将NLP方法与信号处理方法进行比较和对比。它显示了用C，C ++和JAVA编写的开源软件的特定测试用例的有希望的结果。</p><p>​        源代码实际上是文本信息。机器学习中深度学习模型的最新进展为软件度量和BOW代表软件代码提供了强有力的替代方案。最广泛使用的深度学习模型之一是长期短期记忆（LSTM）[22]，这是一种特殊的递归神经网络，在学习文本和语音等顺序数据中的长期依赖性方面非常有效。 LSTM在许多应用中表现出突破性的性能，例如机器翻译，视频分析和速度识别[1]。一些研究人员提出了一种新颖的基于深度学习的方法来自动学习用于预测软件代码中的漏洞的功能，利用LSTM捕获源代码中的长的上下文关系，其中相关的代码元素分散得很远。建立了强大的深度长期短期记忆（LSTM）模型，以同步自动学习代码的语义和句法特征。同时，RNN编码器 - 解码器用于为给定的API相关自然语言查询生成API使用序列[23]。它可能涉及其他软件工程问题，如代码搜索和错误本地化。代码克隆检测也是软件维护和SCA的一个重要问题[24]。所提出的代码分析工具利用深度学习的优势，并自动将词汇层面挖掘的模式与句法层面挖掘的模式联系起来。</p><h1 id="IV-结论和未来工作"><a href="#IV-结论和未来工作" class="headerlink" title="IV 结论和未来工作"></a>IV 结论和未来工作</h1><p>本文代表了源代码审查中机器学习（ML）文献综述的研究成果。 ML和一些分支提出了一些新的想法来实现分类器，回归和代理来预测源代码漏洞，具有较低的误报和漏报。幸运的是，深度处理安全网络以随着数据量的增加自动调整和调整连接的能力将改善学习过程。特别是，这将允许我们自动化和使用网络专门从事某些领域。通过深入学习，安全系统可以通过尝试数十亿种组合并进行数百万次观察来自动学习。针对特定类别的问题，这是非常有希望的，但它不是一个灵丹妙药。仅仅因为一项技术使用深度学习并不意味着其他传统的AI和机器学习方法并不具有更高的价值或实用性。人工智能是一种多用途技术，我们可以在安全和其他行业中工作，学习，迭代和改进。不幸的是，没有找到通过强化学习来审查源代码的论文。主要原因是在审查过程中没有建立动态交互，但是，提出了将静态和动态方法结合起来测量源代码的有希望的方法。</p><p>最重要的是，漏洞数据规模不足仍然是一个挑战。跨文件，跨版本和跨项目需要占主导地位，因为对象大多不存在于训练集中。 ML，DL和RL的评论在源代码分析研究中一直走在前列。</p><h1 id="个人观点"><a href="#个人观点" class="headerlink" title="个人观点"></a>个人观点</h1><p>关于源代码漏洞发现总结的较少，所列举文献大多为关于机器学习和深度学习。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h1&gt;&lt;p&gt;源代码审查充分限制了软件系统的安全性。可伸缩性和精度对于代码审查工具的部署非常重要。但是，传
      
    
    </summary>
    
      <category term="论文" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/"/>
    
      <category term="fuzzing" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/fuzzing/"/>
    
      <category term="综述" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/fuzzing/%E7%BB%BC%E8%BF%B0/"/>
    
    
      <category term="2018年" scheme="http://yama0xff.com/tags/2018%E5%B9%B4/"/>
    
      <category term="fuzzing" scheme="http://yama0xff.com/tags/fuzzing/"/>
    
      <category term="综述" scheme="http://yama0xff.com/tags/%E7%BB%BC%E8%BF%B0/"/>
    
  </entry>
  
  <entry>
    <title>From automation to intelligence: Survey of research on vulnerability discovery techniques</title>
    <link href="http://yama0xff.com/2019/04/02/From-automation-to-intelligence-Survey-of-research-on-vulnerability-discovery-techniques/"/>
    <id>http://yama0xff.com/2019/04/02/From-automation-to-intelligence-Survey-of-research-on-vulnerability-discovery-techniques/</id>
    <published>2019-04-02T02:08:03.000Z</published>
    <updated>2019-04-02T03:15:25.137Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>近年来，随着软件规模和复杂度的日益增加，软件漏洞挖掘技术正逐渐向高度自动化和智能化演变，该文从传统漏洞挖掘技术和基于学习的智能化漏洞挖掘技术两方面深入调研和分析了相关的研究进展。首先，从静态和动态挖掘技术2方面详细介绍了传统漏洞挖掘技术的研究现状，涉及的技术包括模型检测、二进制比对、模糊测试、符号执行以及漏洞可利用性分析等，并分析了各项技术存在的问题，提出当前的研究难点是实现漏洞挖掘全自动化。然后，介绍了机器学习和深度学习技术在漏洞挖掘领域的应用，具体应用场景包括二进制函数识别、函数相似性检测、测试输入生成、路径约束求解等，并提出了其存在的机器学习算法不够健壮安全、算法选择依靠经验、数据样本不足、特征选择依赖专家知识等问题。最后，对未来研究工作进行了展望，提出应该围绕提高漏洞挖掘的精度和效率、提高自动化和智能化的程度这2方面展开工作。</p><table><thead><tr><th>relevant information</th><th></th></tr></thead><tbody><tr><td><em>作者</em></td><td>邹权臣，张涛，吴润浦, 马金鑫, 李美聪, 陈晨,侯长玉</td></tr><tr><td><em>单位</em></td><td>中国信息安全测评中心,空军工程大学 信息与导航学院,北京邮电大学 网络空间安全学院,北京中测安华科技有限公司</td></tr><tr><td><em>出处</em></td><td>清华大学学报</td></tr><tr><td><em>原文地址</em></td><td><a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#outline_anchor_17" target="_blank" rel="noopener">http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#outline_anchor_17</a></td></tr><tr><td><em>源码地址</em></td><td></td></tr><tr><td><em>发表时间</em></td><td>2018年</td></tr></tbody></table><h1 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h1><p>漏洞信息的不对称性已经成为导致网络战争中的实力对比悬殊的关键因素。从早年爆发的蠕虫王、冲击波、震荡波病毒，到近年来爆发的WannaCry病毒，都借助了软件或系统的安全漏洞进行传播。另外，高级的网络攻击(如APT攻击)甚至会基于多个漏洞交叉、组合使用，目的是绕过防火墙、杀毒软件、入侵检测系统等，摧毁隔离网的安全性，突破核心网络节点而进入内网，进行后续的渗透攻击(如窃取、修改、加密重要数据，摧毁核心设施等)。特别是未公开的0day漏洞常常被当成秘密的终极武器使用，有时候甚至能起到决定性的作用。</p><p>鉴于软件漏洞在网络攻防中的重要性，各大软件厂商及高校、科研院所的研究人员对漏洞挖掘技术展开了大量的研究。当前，常用的漏洞挖掘技术包括模型检测、模糊测试、符号执行、二进制比对等，这些传统的漏洞挖掘技术在理论研究上已经比较成熟，并已从各类软件中挖掘出大量漏洞。其中大部分的技术如模糊测试、符号执行等都已基本实现自动化，可以在不需要或较少的人工干预的前提下，针对被测试程序和输入数据的不同特点，借助各种程序动、静态分析技术，寻找分析深度和分析效率之间的平衡点，缓解代码覆盖率低、扩展性差等问题；目的是提高漏洞挖掘的效率，实现在更短的时间内发现更多或更深层次的漏洞。</p><p>机器学习、深度学习的研究进展带动了其在软件漏洞挖掘领域的应用，目前已经开展了一些探索性的工作，如二进制函数相似性识别、函数相似性检测、测试输入生成、路径约束求解等，这些应用为解决传统漏洞挖掘技术的瓶颈问题提供了新的思路，也使得软件漏洞挖掘逐渐变得智能化。随着机器学习、深度学习研究的爆炸式发展，以及这方面研究积累的数据集的增多，将可能成为软件漏洞挖掘技术发展的关键点之一。</p><p>本文以近年来软件漏洞挖掘技术所呈现出的自动化和智能化的趋势作为切入点，介绍了传统漏洞挖掘技术和基于学习的智能化漏洞挖掘技术的研究进展。首先，本文从静态和动态漏洞挖掘两方面对传统的漏洞挖掘技术进行了分类分析，指出了各自的优势和面临的问题；并介绍了漏洞可利用性分析以及自动化漏洞挖掘(如CGC大赛)的研究进展，指出漏洞挖掘的全自动化是当前研究的难点问题。然后，对基于学习的智能化软件漏洞挖掘技术进行了分类，并深入分析了二进制函数识别、函数相似性检测等不同应用场景的研究工作，归纳总结了其面临的机器学习算法不够健壮安全、算法选择依靠经验、数据样本不足、特征选择依赖专家知识等四大问题。最后进行了总结和展望，指出未来应在提高漏洞挖掘的精度和效率，以及自动化和智能化方面展开研究。</p><h1 id="2-传统漏洞挖掘技术"><a href="#2-传统漏洞挖掘技术" class="headerlink" title="2.传统漏洞挖掘技术"></a>2.传统漏洞挖掘技术</h1><p>传统的漏洞挖掘技术主要可分为静态和动态漏洞挖掘技术，漏洞可利用性分析也已经成为漏洞挖掘的重要环节，如[图 1]所示</p><p><img src="/2019/04/02/From-automation-to-intelligence-Survey-of-research-on-vulnerability-discovery-techniques/1.jpg" alt=""></p><h2 id="2-1-静态漏洞挖掘"><a href="#2-1-静态漏洞挖掘" class="headerlink" title="2.1 静态漏洞挖掘"></a>2.1 静态漏洞挖掘</h2><p>静态漏洞挖掘是指在不运行目标程序的前提下分析目标程序(源代码或二进制)的词法、语法和语义等，并结合程序的数据流、控制流信息，通过类型推导、安全规则检查、模型检测等技术挖掘程序中的漏洞。静态漏洞挖掘是常用的软件测试技术，在软件测试中占有非常重要的地位。具有代表性的静态漏洞挖掘工具有面向C/C++源码的Cppcheck[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b1" target="_blank" rel="noopener">1</a>]、FlawFinder[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b2" target="_blank" rel="noopener">2</a>], 面向PHP源码的RIPS[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b3" target="_blank" rel="noopener">3</a>], 面向JAVA源码的FindBugs[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b4" target="_blank" rel="noopener">4</a>]，以及能支持多种类型目标对象的著名商业化漏洞检测工具VeraCode[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b5" target="_blank" rel="noopener">5</a>]、Fortify[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b6" target="_blank" rel="noopener">6</a>]、Coverity[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b7" target="_blank" rel="noopener">7</a>]、Checkmarx[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b8" target="_blank" rel="noopener">8</a>]等。另外，LLVM[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b9" target="_blank" rel="noopener">9</a>]、Clang[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b10" target="_blank" rel="noopener">10</a>]等编译器也提供了大量的静态检测功能，能在编译阶段实现对源代码的安全性检查。</p><p>针对目标程序的不同形式，采用的静态分析技术也不尽相同。本节将按源代码和二进制2种目标程序分别介绍静态漏洞挖掘技术的研究现状。</p><p>面向源代码的漏洞挖掘主要采用基于中间表示的分析和基于逻辑推理的分析技术[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b11" target="_blank" rel="noopener">11</a>]。其中，基于中间表示的分析技术主要包括数据流分析、控制流分析、污点分析、符号执行等。Pixy[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b12" target="_blank" rel="noopener">12</a>]采用了取值分析、污点分析、指针别名分析等静态分析技术实现对PHP源码中的SQL注入和跨站脚本等漏洞的检测。Prefix[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b13" target="_blank" rel="noopener">13</a>]采用了静态符号执行技术模拟执行C/C++源码程序，并采用约束求解对程序中的部分路径进行检测。Melange[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b14" target="_blank" rel="noopener">14</a>]采用数据流分析的框架，通过对程序进行数据流、控制流等复杂分析检测安全相关的漏洞，并支持对大型C/C++源码程序的分析。K-Miner[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b15" target="_blank" rel="noopener">15</a>]利用内核代码中高度标准化的接口实现了可扩展性良好的指针分析以及全局的上下文敏感的分析技术，支持对空指针引用、指针释放后重引用(use-after-free, UAF)、指针重释放(double free)、双重检查锁定(double-checked lock)等内存崩溃漏洞的检测。基于逻辑推理的分析技术主要是指模型检测，如MOPS[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b16" target="_blank" rel="noopener">16</a>]、BLAST[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b17" target="_blank" rel="noopener">17</a>]、SLAM[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b18" target="_blank" rel="noopener">18</a>]是典型的面向C程序的模型检测工具，其基本思路是将程序结构抽象为状态机(布尔程序)，然后基于归纳的安全属性对状态机进行遍历，检测其中存在的漏洞。</p><p>面向二进制程序的静态漏洞的挖掘技术由于缺少源代码中的结构化信息，面临着值集分析(vaule-set analysis，VSA)[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b19" target="_blank" rel="noopener">19</a>]与控制流恢复[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b20" target="_blank" rel="noopener">20</a>-<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b25" target="_blank" rel="noopener">25</a>]不精确的问题。当前，二进制静态漏洞挖掘技术主要包括基于模式匹配和基于补丁比对的技术。其中，在基于模式匹配的漏洞挖掘技术方面，GUEB[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b26" target="_blank" rel="noopener">26</a>]提出了二进制程序中UAF漏洞模式，并基于此模式挖掘出了ProFTPD程序中的漏洞。具体而言，首先抽象出二进制函数中的内存模型，然后采用VSA分析技术追踪堆分配和释放指令相关的操作变量，并基于此建立UAF模式。LoongChecker[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b27" target="_blank" rel="noopener">27</a>]使用了称为半仿真的二进制静态漏洞挖掘技术。通过VSA分析和数据依赖分析(data dependence analysis，DDA)技术实现对变量地址的追踪和数据流依赖分析，并采用污点分析技术检测潜在的漏洞。Saluki[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b28" target="_blank" rel="noopener">28</a>]使用了路径敏感和上下文敏感的数据依赖分析，并采用完备的逻辑系统推理检测程序中的漏洞。在基于补丁比对的漏洞挖掘技术方面，PVDF[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b29" target="_blank" rel="noopener">29</a>]以二进制漏洞程序(带有权限提升漏洞)和补丁作为输入，从比对中提取多维属性描述的漏洞语义信息，并应用于后续的模糊测试中。BinHunt[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b30" target="_blank" rel="noopener">30</a>]通过对二进制程序和带补丁的二进制程序间的比对提取漏洞相关的语义信息。具体而言，就是把二进制程序翻译成中间表示，并在此基础上构建控制流图，基于控制流图对比程序间的差异，提取相关的约束，然后采用符号执行技术进行验证，以此找出补丁对应的漏洞。</p><p>静态漏洞挖掘技术直接对目标程序进行分析，不需要构造程序的执行环境，能提取较为完整的控制流等信息，可能发现动态漏洞挖掘技术难以发现的漏洞。但是，一方面，由于静态漏洞挖掘技术往往依赖于人工构造的漏洞模式，对先验知识依赖性较大；另一方面，因为无法获得程序实际动态运行过程中的上下文信息，静态漏洞挖掘技术具有精度低、误报率高的缺陷。</p><h2 id="2-2-动态漏洞挖掘"><a href="#2-2-动态漏洞挖掘" class="headerlink" title="2.2 动态漏洞挖掘"></a>2.2 动态漏洞挖掘</h2><p>动态漏洞挖掘技术是指在实际执行程序的基础上采用的分析技术，常用的动态漏洞挖掘技术包括模糊测试、符号执行等。</p><h3 id="2-2-1-模糊测试"><a href="#2-2-1-模糊测试" class="headerlink" title="2.2.1 模糊测试"></a>2.2.1 模糊测试</h3><p>模糊测试(fuzzing)是一种自动化或者半自动化的软件测试技术，通过构造随机的、非预期的畸形数据作为程序的输入，并监控程序执行过程中可能产生的异常，之后将这些异常作为分析的起点，确定漏洞的可利用性。模糊测试技术可扩展性好，能对大型商业软件进行测试，是当前最有效的用于挖掘通用程序漏洞的分析技术，已经被广泛用于如微软、谷歌和Adobe等主流软件公司的软件产品测试和安全审计，也是当前安全公司和研究人员用于挖掘漏洞的主要方法之一。</p><p>按程序内部结构分析的量级轻重程度分，模糊测试技术主要可以分为白盒、黑盒、灰盒模糊测试。其中，白盒模糊测试是在对被测试程程序内部结构、逻辑进行系统性分析的基础上进行测试；黑盒模糊测试把程序当成黑盒处理，不对程序内部进行分析；灰盒模糊测试介于黑盒和白盒模糊测试之间，在对程序进行轻量级分析的基础上进行测试。按样本生成方式划分，模糊测试的测试输入可分为基于变异和基于生成2种方式。其中，基于变异的模糊测试在修改已知测试输入的基础上生成新的测试用例，而基于生成的模糊测试则是直接在已知输入样本格式的基础上生成新的测试输入。</p><p>根据不同的研究侧重点，本文分别介绍基于变异的模糊测试、基于生成的模糊测试和其他优化策略。</p><h4 id="1-基于变异的模糊测试。"><a href="#1-基于变异的模糊测试。" class="headerlink" title="1) 基于变异的模糊测试。"></a>1) 基于变异的模糊测试。</h4><p>在基于变异的模糊测试方面，研究人员借助程序执行环境信息和程序分析技术，有导向性地辅助、引导模糊测试的变异，具有代表性的工作有AFL[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b31" target="_blank" rel="noopener">31</a>]、VUzzer[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b32" target="_blank" rel="noopener">32</a>]、Honggfuzz[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b33" target="_blank" rel="noopener">33</a>]、libFuzzer[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b34" target="_blank" rel="noopener">34</a>]、Steelix[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b35" target="_blank" rel="noopener">35</a>]、T-Fuzz[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b36" target="_blank" rel="noopener">36</a>]、AFLFast[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b37" target="_blank" rel="noopener">37</a>]、AFLGo[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b38" target="_blank" rel="noopener">38</a>]、Driller[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b39" target="_blank" rel="noopener">39</a>]等。</p><ul><li><strong>a) 代码覆盖率制导</strong></li></ul><p>AFL[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b31" target="_blank" rel="noopener">31</a>]使用进化算法(evolutionary algorithms)生成测试输入，在正常输入的基础上，通过简单的反馈回路的方式评估测试输入的质量。AFL会保留任何能触发新路径的测试输入，并对其进行变异及检查能否触发崩溃。AFL已经在Mozilla Firefox、FFmpeg、OpenSSL等软件中发现了大量的漏洞。但AFL也存在较大的缺陷：首先，变异的位置以及变异的方式是盲目的，缺少更进一步的筛选和变异策略，依赖这种方式很难发现深层次的漏洞；其次，通过哈希函数检测分支覆盖筛选种子的方式具有较高的误报率，其哈希位图(bitmap)只有64 kB大小，导致普遍存在哈希碰撞的情况，进而导致其分支覆盖统计存在漏报，进而影响种子筛选，间接影响了代码覆盖率的增长。CollFuzz[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b40" target="_blank" rel="noopener">40</a>]采用静态控制流图信息作为辅助，并设计了能避免哈希碰撞的基本块ID分配策略，从而实现比AFL更精确的分支覆盖检测。</p><ul><li><strong>b) 污点分析辅助</strong></li></ul><p>BuzzFuzz[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b41" target="_blank" rel="noopener">41</a>]使用动态污点分析技术自动定位影响程序脆弱点的测试输入中的字段，然后保留其他语法部分内容，只对这些字段进行变异。这样既能通过语法检查，也能有针对性地进行变异，提高漏洞挖掘的效率。TaintScope[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b42" target="_blank" rel="noopener">42</a>]使用污点分析技术推断程序中与校验和处理相关的代码，以此帮助模糊测试工具绕过校验和检查。</p><ul><li><strong>c) 符号执行制导</strong></li></ul><p>Driller[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b39" target="_blank" rel="noopener">39</a>]采用模糊测试和符号执行交替探索程序执行路径，解决模糊测试陷入代码覆盖率增长慢的情况，这样能引导模糊测试探索到程序更深层次的节点，也能直接避免符号执行可能带来的路径爆炸问题。但文[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b39" target="_blank" rel="noopener">39</a>]和[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b43" target="_blank" rel="noopener">43</a>]等的实验结果表明，使用符号执行对模糊测试中部分路径约束求解时，仍然有很大一部分路径出现求解失败的情况(文[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b39" target="_blank" rel="noopener">39</a>]实验中有41个测试程序陷入了较浅路径，使用符号执行对其求解时只有13个程序能够生成新的测试输入)。因此，基于符号执行增强的模糊测试技术仍然会受限于符号执行中的约束求解问题，符号执行的引入可能会弱化模糊测试本身的可扩展性。</p><ul><li><strong>d) 控制流和数据流信息制导</strong></li></ul><p>VUzzer[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b32" target="_blank" rel="noopener">32</a>]在“轻量级”的动、静态分析基础上提取了程序的控制流和数据流信息引导变异。具体而言，VUzzer先在静态控制流分析基础上计算基本块的权重，然后在动态执行时筛选权重更高即路径更深的执行路径对应的测试输入为种子文件，并用动态污点分析定位变异点。相比AFL、Driller，VUzzer有更好的种子筛选、路径探索策略以及污染点定位、变异策略，能定向引导探索更深的执行路径，并定点变异。在DARPA CGC和LAVA测试集以及部分常用应用程序上，VUzzer都取得了更好的效果(用更少的测试输入挖掘出了更多的漏洞)。Steelix[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b35" target="_blank" rel="noopener">35</a>]采用了轻量级的静态分析和二进制插桩技术提取代码覆盖率信息和魔术字节(magic byte)比较信息等作为程序状态信息引导变异。这种方式能在较小的开销下定位魔术字节在测试输入中的位置，进而辅助模糊测试工具更高效地生成能通过魔术字节检验的测试输入。</p><h4 id="2-基于生成的模糊测试。"><a href="#2-基于生成的模糊测试。" class="headerlink" title="2) 基于生成的模糊测试。"></a>2) 基于生成的模糊测试。</h4><p>基于生成的模糊测试主要基于模型或者语法生成能满足程序语法和语义检查的测试输入，常用于高度结构化的测试输入生成。</p><ul><li><strong>a) 基于模型的模糊测试</strong></li></ul><p>Peach[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b44" target="_blank" rel="noopener">44</a>]、Spike[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b45" target="_blank" rel="noopener">45</a>]是典型的基于模型的模糊测试工具(Peach也具有基于变异进行模糊测试的功能)，通过对输入格式定制编写数据模型(data model)和状态模型(state model)的方式指定输入数据的类型和依赖关系, 并结合变异策略生成测试输入。其中Peach通过编写配置文件实现对样本格式的约束，而Spike需要利用提供的编程接口来对样本格式进行约束。Pham等[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b46" target="_blank" rel="noopener">46</a>]结合输入模型和符号执行技术生成测试输入，使用符号执行鉴别输入格式约束能有效保证输入的合法性。</p><ul><li><strong>b) 基于语法的模糊测试</strong></li></ul><p>CSmith[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b47" target="_blank" rel="noopener">47</a>]根据C语言语法生成C程序源码，实现对C编译器的模糊测试。在C源码生成方面，CSmith随机选取符合生成规则和语法规则的C程序，这种方法能避免因未定义和未声明而导致编译报错的情况出现。LangFuzz[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b48" target="_blank" rel="noopener">48</a>]基于语法学习测试集中的代码片段，并进行片段重组生成新的测试输入。在测试输入集选择上，LangFuzz假设基于问题测试集重组生成的测试输入比随机收集的测试输入更有可能触发程序缺陷。IFuzzer[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b49" target="_blank" rel="noopener">49</a>]使用上下文无关的语言语法作为输入，并使用语法生成解析树，然后从测试集中抽取代码片段，并使用遗传进化算法对代码片段重组生成新的测试输入。Jsfunfuzz[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b50" target="_blank" rel="noopener">50</a>]使用了历史漏洞知识和硬编码规则生成测试输入，以Mozilla浏览器中的Javascript解释器为测试目标，发现了1 800多个缺陷。Dewey等[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b51" target="_blank" rel="noopener">51</a>]使用了称为约束逻辑编程(constraint logic programming, CLP)的技术生成测试输入。通过指定句法特征和语义行为，CLP能生成满足语法和语义合法性的测试输入。</p><h4 id="3-其他优化策略。"><a href="#3-其他优化策略。" class="headerlink" title="3) 其他优化策略。"></a>3) 其他优化策略。</h4><p>除了上述进展外，还有一些重要研究侧重于种子筛选策略优化[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b37" target="_blank" rel="noopener">37</a>-<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b38" target="_blank" rel="noopener">38</a>, <a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b52" target="_blank" rel="noopener">52</a>-<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b55" target="_blank" rel="noopener">55</a>]和调度策略优化[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b37" target="_blank" rel="noopener">37</a>-<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b38" target="_blank" rel="noopener">38</a>]。Rebert等[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b53" target="_blank" rel="noopener">53</a>]把种子筛选问题转化成整数线性规划问题，并以挖掘更多漏洞为目标提出了多种种子筛选策略。AFLFast[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b37" target="_blank" rel="noopener">37</a>]采用了把模糊测试问题建模为Markov模型，并采用特定的策略引导AFL优先选择低频路径和变异频率较低的文件作为种子文件进行变异，以此在相同的测试时间内探索更多的路径。AFLGo[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b38" target="_blank" rel="noopener">38</a>]采用了模拟退火(simulated annealing，SA)算法对能逼近特定目标位置的测试输入分配更高的能量，并优先选取高能量种子文件进行变异。AFLGo的实验结果表明，这种导向型灰盒模糊测试(directed greybox fuzzing，DFG)比符号执行引导的白盒模糊测试和非导向型模糊测试具有更好的性能、更高的代码覆盖率并可挖掘出更多的漏洞。</p><p>总体而言，模糊测试是当前挖掘漏洞最有效的方法，比其他漏洞挖掘技术更能应对复杂的程序，具有可扩展性好的优势。但在大规模漏洞分析测试中，模糊测试方法仍然依赖于种子输入的质量，依赖于对测试输入对象格式的深度理解和定制，存在测试冗余、测试攻击面模糊、测试路径盲目性较高等问题。另外，目前模糊测试也存在整体测试时间长、生成单个测试用例漏洞触发能力弱的问题。</p><h3 id="2-2-2-符号执行"><a href="#2-2-2-符号执行" class="headerlink" title="2.2.2 符号执行"></a>2.2.2 符号执行</h3><p>符号执行于20世纪70年代被提出[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b56" target="_blank" rel="noopener">56</a>-<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b59" target="_blank" rel="noopener">59</a>]，是一种能够系统性探索程序执行路径的程序分析技术，通过对程序执行过程中的被污染的分支条件及其相关变量的收集和翻译，生成路径约束条件，然后使用可满足模理论(SMT)求解器进行求解, 判断路径的可达性以及生成相应的测试输入。通过这种方式产生的测试输入与执行路径之间具有一对一的关系，能够避免冗余测试输入的产生，进而能有效解决模糊测试冗余测试用例过多导致的代码覆盖率增长慢的问题。</p><p>符号执行技术应用已经被学术和工业界应用在漏洞挖掘领域。自从符号执行特别是动态符号执行技术被提出以来，已经有很多相关的工具被应用到实际的软件测试当中，如SAGE[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b60" target="_blank" rel="noopener">60</a>]、S2E[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b61" target="_blank" rel="noopener">61</a>]、Mayhem[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b62" target="_blank" rel="noopener">62</a>]、KLEE[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b63" target="_blank" rel="noopener">63</a>]、Triton[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b64" target="_blank" rel="noopener">64</a>]、angr[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b65" target="_blank" rel="noopener">65</a>-<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b66" target="_blank" rel="noopener">66</a>]等。其中SAGE已经被应用到了微软内部的日常开发安全测试中，每天有上百台机器同时在运行此工具，并发现了Windows 7系统中三分之一的漏洞[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b60" target="_blank" rel="noopener">60</a>]。MergePoint[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b67" target="_blank" rel="noopener">67</a>]已经在Debian系统下发现上百个可利用漏洞。</p><p>虽然符号执行相比其他程序测试和分析技术有诸多的优势，但就当前的形势而言，要大规模应用到工业领域仍然还有很多问题需要解决。符号执行概念提出至今已有40多年，而现代符号执行技术特别是动态符号执行技术的提出也有10多年之久，但至今符号执行仍然难以在主流的软件测试和漏洞挖掘中占据主导地位，归因于以下尚待解决的难题。</p><h4 id="1-路径爆炸-path-explosion-问题。"><a href="#1-路径爆炸-path-explosion-问题。" class="headerlink" title="1) 路径爆炸(path explosion)问题。"></a>1) 路径爆炸(path explosion)问题。</h4><p>路径爆炸又称为状态爆炸(state explosion)，是指在程序运行过程中路径数随着分支条件的增多而出现指数级增长的情况。由于路径爆炸问题的存在，在大型复杂的程序中，符号执行容易出现代码覆盖率增长慢的问题，很难在合理有限的时间内遍历程序的所有执行路径。为了缓解这一问题，研究人员采用了具有制导性的启发式搜索以及状态空间简化等操作减少对冗余状态的探索。</p><p>启发式搜索(search heuristics)是一种以特定目标优先的路径搜索策略。符号执行过程中对路径的探索可以看成是对符号执行树的探索，在执行树中，从根节点到叶子节点的一条路径代表程序实际执行中的一条路径，而其中的分支节点则表示程序实际执行中的分支条件。大部分启发式技术都专注于避免因陷入某部分相似路径而导致代码覆盖率低增长的情况，以期获得更高的代码和路径覆盖。KLEE[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b63" target="_blank" rel="noopener">63</a>]中提出结合随机路径选择(random path selection)和覆盖优化搜索(coverage-optimized search)的混合搜索算法，2种路径选择方法交叉使用探索执行路径既能达到高代码覆盖率的目的，又能防止某种算法陷入困境导致路径探索无法进行。Ma等[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b68" target="_blank" rel="noopener">68</a>]提出了以指定行代码可达性(line reachability)为目标的搜索策略。以程序中某行或多行代码为目标，找出能够驱动程序执行这些代码的实际输入问题称为代码行可达性问题。Godefroid等[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b60" target="_blank" rel="noopener">60</a>]提出了代搜索(generational search)算法，在每一代新生成的路径约束中，对所有分支条件取反，然后能选择覆盖新代码块最多的测试输入作为新的种子输入。</p><p>状态空间简化通过相似路径合并、冗余路径删减的方式达到减少路径探测的目的。除了启发式探索程序执行路径之外，研究人员还提出了利用程序分析和软件验证等技术减少精简路径的措施来缓解路径爆炸问题。Godefroid等[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b69" target="_blank" rel="noopener">69</a>]采用了函数摘要的方式，对重用的函数提取约束组合(摘要)，实现对函数路径的组合执行，避免了多次重复符号执行带来的开销。Ramos等[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b70" target="_blank" rel="noopener">70</a>]提出的限定约束的符号执行(under-constrainted symbolic execution)采用了直接面向独立函数的符号执行技术，此技术限定了符号执行的范围，用精确度换取可扩展性的方式来提升符号执行的性能。Veritesting[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b67" target="_blank" rel="noopener">67</a>]采用了静态符号执行技术增强动态符号执行技术，实现路径合并和冗余路径删减。Boonstoppel等[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b71" target="_blank" rel="noopener">71</a>]提出了RWSet，从状态变量的相似性鉴别冗余性，如果当前状态的变量跟之前的路径变量一样，则会停止对当前状态的探索。</p><h4 id="2-约束求解问题。"><a href="#2-约束求解问题。" class="headerlink" title="2) 约束求解问题。"></a>2) 约束求解问题。</h4><p>约束求解问题是动态符号执行遇到的另一个瓶颈问题。在动态符号执行中，对路径约束条件可达性的判定以及相应测试输入生成都需要频繁地调用SMT求解器进行求解；而约束求解本身又是一个NP完全(NP-complete)问题，在最差的情况下求解NP完全问题的复杂度为指数级。频繁调用加上高的求解难度直接导致约束求解消耗了符号执行系统中的大部分资源。</p><p>当前约束求解问题可以归结为求解能力和求解效率问题。求解能力问题是指当前求解器对复杂约束条件处理能力的不足。例如对于浮点数运算、非线性运算等一些复杂运算的约束，求解器都不能很好地处理。而求解效率问题是指对于含有大量的约束条件的路径约束，求解器的性能会随着约束条件数量的增长而逐渐下降。这使得符号执行对大型程序进行分析时整体性能下降，从而影响其可扩展性。</p><p>针对约束求解的两大问题，研究人员提出了很多约束求解性能优化措施，主要可分为内部优化和外部优化。求解器内部优化是指通过优化求解器本身对约束条件处理能力和效率来提高符号执行的性能，虽然近年来这方面的研究已经取得了比较大的突破[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b72" target="_blank" rel="noopener">72</a>-<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b76" target="_blank" rel="noopener">76</a>]，但仍然严重依赖于可满足模理论以及NP完全问题的研究进展。求解器外部优化主要是指在调用约束求解器对路径约束求解之前的优化，是通过减少甚至避免符号查询的工作来增加符号执行性能的措施。例如，CUTE[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b77" target="_blank" rel="noopener">77</a>]和KLEE[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b63" target="_blank" rel="noopener">63</a>]采用了如表达式重写、符号值的实际替换、不相关约束的删除以及约束缓存等一系列措施，对路径约束进行精简和结果重用。而近年来在这方面的研究又有了不小的突破，包括Green[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b78" target="_blank" rel="noopener">78</a>]、Recal[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b79" target="_blank" rel="noopener">79</a>]、GeenTrie[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b80" target="_blank" rel="noopener">80</a>]、Memoise[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b81" target="_blank" rel="noopener">81</a>]等，这些工具的提出主要侧重于解决优化符号执行结果切分、标准化命名、约束式逻辑转化、求解结果的缓存、搜索和重用的效率问题。有关这些工具的实验结果表明：路径约束的精简能减轻约束求解的负担，而约束求解结果的缓存和重复使用能在同一程序的不同路径以及不同程序的不同路径间的约束求解问题上极大地减少对求解器的调用。</p><h4 id="3-其他问题。"><a href="#3-其他问题。" class="headerlink" title="3) 其他问题。"></a>3) 其他问题。</h4><p>除了上述2个问题之外，符号执行还面临着内存建模[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b62" target="_blank" rel="noopener">62</a>, <a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b65" target="_blank" rel="noopener">65</a>-<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b66" target="_blank" rel="noopener">66</a>]、环境交互[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b61" target="_blank" rel="noopener">61</a>, <a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b63" target="_blank" rel="noopener">63</a>, <a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b82" target="_blank" rel="noopener">82</a>-<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b83" target="_blank" rel="noopener">83</a>]、并行计算[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b67" target="_blank" rel="noopener">67</a>, <a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b84" target="_blank" rel="noopener">84</a>]等问题。</p><p>总体而言，基于符号执行的漏洞挖掘技术依赖于约束求解器的求解能力和效率，并受限于程序状态爆炸问题。另外，它在主动漏洞挖掘方面还依赖于在对程序进行分析的基础上构造预置条件(漏洞约束)。符号执行应用于大型程序是一个多种性能优化措施并行且不断地对性能调优的过程，虽然研究人员提出了一系列性能优化措施来改善符号执行的可扩展性，但当前业界和学术界普遍认为，单独使用符号执行技术对大型程序进行漏洞挖掘仍然比较困难。</p><h2 id="2-3-漏洞可利用性分析"><a href="#2-3-漏洞可利用性分析" class="headerlink" title="2.3 漏洞可利用性分析"></a>2.3 漏洞可利用性分析</h2><p>在漏洞可利用性判定方面，现有的一些工具如!exploitable[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b85" target="_blank" rel="noopener">85</a>]、gdb-exploitable[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b86" target="_blank" rel="noopener">86</a>]、ASan[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b87" target="_blank" rel="noopener">87</a>]等，已经可以对漏洞挖掘过程中的异常或崩溃的可利用性进行初步分类。例如，!exploitable对崩溃按可利用(exploitable)、高可利用(probably exploitable)、不可利用(probably not exploitable)、未知(unknown)进行评级划分，并提供了哈希去重功能。但上述工具具有误报率高的缺陷，实际验证的时候仍然需要具有丰富漏洞挖掘和分析经验的专家进行手工逆向分析、调试进行审核确认，并编写利用漏洞的验证程序。在崩溃样本量较大时，这种方式低效而且对分析人员具有较高要求。</p><p>在自动化漏洞利用生成方面，APEG [<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b88" target="_blank" rel="noopener">88</a>]使用了基于补丁对比的漏洞利用生成技术，该技术基于补丁定位漏洞位置，并采用切分技术(slicing technique)生成从输入源至漏洞点的路径约束，但APEG只适用于单检查点修补的补丁。Heelan等[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b89" target="_blank" rel="noopener">89</a>]提出了自动化提取控制流劫持的漏洞利用技术，但该技术只在提供崩溃输入和已知漏洞(如栈溢出覆盖EIP指针)的前提下适用。AGE[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b83" target="_blank" rel="noopener">83</a>]、Mayhem[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b90" target="_blank" rel="noopener">90</a>]采用预置条件的符号执行(pre-conditioned symbolic execution)技术寻找可利用的漏洞路径，并自动生成利用代码。但该技术只支持对栈溢出、格式化字符串等部分漏洞的检测；另外，其自动化生成的漏洞利用程序不支持绕过编译器或OS对抗机制如ASLR(address space layout randomization)、DEP(data execution prevention)、CFI(control-flow integrity)等。FlowStitch[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b91" target="_blank" rel="noopener">91</a>]采用了称为数据流缝合(data-flow stitching)的面向数据流的自动化漏洞利用生成技术，该技术在不改变程序控制流的情况下，利用已知的内存错误修改数据流中关键变量的方式构建漏洞利用程序。FlowStitch从已知漏洞程序中发现了多个未知的漏洞利用方式，自动生成的所有利用程序都能通过CFI和DEP, 并有部分能绕过ASLR, 进而实现信息泄露或权限提升。但该方案仍然依赖于已知的内存错误和相应的测试输入。</p><p>总体而言，漏洞可利用性判定、漏洞利用程序生成是制约实现漏洞挖掘自动化的主要瓶颈之一。</p><h2 id="2-4-自动化漏洞挖掘"><a href="#2-4-自动化漏洞挖掘" class="headerlink" title="2.4 自动化漏洞挖掘"></a>2.4 自动化漏洞挖掘</h2><p>2016年8月，美国国防部高等研究计划署(DARPA)举办了网络超级挑战赛(cyber grand challenge，CGC)大赛的决赛。参赛团队研发的网络推理系统(cyber reasoning system，CRS)具备自动化挖掘漏洞、自动部署补丁和进行系统防御的能力，可以快速有效地应对新的攻击，降低从攻击出现到防御生效之间的时间差，实现网络安全攻防系统的全自动化。CGC大赛提供了一个自动化的攻防比赛平台，所设置的科学的评测体系可以比较全面地评估CRS系统的自动化网络推理能力，也为以后的自动化、智能化网络攻防研究指明了方向。此外，大赛提供的赛题还成为后续研究的测试集，用于评估平台、工具的漏洞挖掘能力和性能，在关于VUzzer[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b32" target="_blank" rel="noopener">32</a>]、Steelix[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b35" target="_blank" rel="noopener">35</a>]、Driller[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b40" target="_blank" rel="noopener">40</a>]等的文献中都被采用。</p><p>但CGC大赛仍然有比较大的局限性。首先，比赛环境与真实环境有差别。为了简化比赛环境，增加可控性，为比赛定制开发的DECREE(DARPA experimental cybersecurity research evaluation environment)系统只提供了7个系统调用；其次，CRS系统漏洞挖掘能力有限，只能挖掘一些简单程序的低级漏洞，对于浏览器等比较复杂的大型程序还不能很好地分析和处理；最后，自动化、智能化能力有限，在大赛中各参赛队伍使用的仍然是传统的模糊测试、符号执行等技术，并结合预设的漏洞模式、攻击模式进行部署，没有使用机器学习、深度学习技术，缺乏自我学习的能力。CGC大赛离实现高度自动化甚至是智能化漏洞挖掘还有比较大的差距。</p><p>综上所述，模型检测、二进制比对、模糊测试、符号执行等传统技术是当前漏洞挖掘的主要手段，漏洞可利用性分析仍然依赖人工参与，以CGC大赛为代表的自动化漏洞挖掘研究离现实应用有比较大的差距，实现漏洞挖掘全自动化是当前研究的难点问题。</p><h1 id="3-基于学习的智能化漏洞挖掘技术"><a href="#3-基于学习的智能化漏洞挖掘技术" class="headerlink" title="3 基于学习的智能化漏洞挖掘技术"></a>3 基于学习的智能化漏洞挖掘技术</h1><p>机器学习、深度学习[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b92" target="_blank" rel="noopener">92</a>]已经广泛应用于图像识别、语音识别、自然语言处理、医学自动诊断、搜索引擎广告推送等众多的领域，并取得了大量突破性进展。在网络安全领域，也已经应用于恶意软件检测、垃圾邮件和网络钓鱼分类、账户异常检测和日志分析等场景。</p><p>受益于上述的研究进展，研究人员在近年来也开始采用机器学习技术缓解软件漏洞挖掘领域的一些瓶颈问题。通过采用现有的机器学习、深度学习等技术，帮助相应的漏洞挖掘工具、系统在海量的漏洞相关的数据中提取经验和知识，然后根据训练生成的模型对新的样本进行分类、预测，提高对软件漏洞挖掘的精度和效率。</p><h2 id="3-1-应用场景"><a href="#3-1-应用场景" class="headerlink" title="3.1 应用场景"></a>3.1 应用场景</h2><p>近年来已经有智能化漏洞挖掘技术研究基于机器学习、深度学习技术展开，如<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#Table1" target="_blank" rel="noopener">表 1</a>所示。从应用场景看，涉及了二进制程序函数识别、函数相似性检测、测试输入生成、测试输入筛选、路径约束求解等领域；从使用的机器学习算法看，这些工作中分别采用了逻辑回归、随机森林、长短时记忆网络(LSTM)、强化学习等多种机器学习、深度学习的算法；从发表年份看，这方面的研究成果从2014年开始发表在信息安全顶级会议上，自2017年以来其数量逐渐上升，并已经成为当前信息安全研究领域的热点。</p><p><img src="/2019/04/02/From-automation-to-intelligence-Survey-of-research-on-vulnerability-discovery-techniques/2.jpg" alt=""></p><h3 id="3-1-1-二进制程序函数识别"><a href="#3-1-1-二进制程序函数识别" class="headerlink" title="3.1.1 二进制程序函数识别"></a>3.1.1 二进制程序函数识别</h3><p>二进制程序函数识别是二进制分析的基础，对于软件漏洞分析与修复，甚至恶意软件检测、协议逆向等都至关重要。由于二进制代码缺少高级语言程序中的信息，函数的识别往往比较困难，现有的反汇编分析工具具有识别正确率低的缺陷。Bao等[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b93" target="_blank" rel="noopener">93</a>]提出了ByteWeight方案，采用机器学习算法实现对二进制程序函数的识别。具体而言，首先采用加权前缀树(weighted prefix tree)学习函数的签名，并通过签名匹配二进制片段的方式识别函数。其中，树中每个节点与二进制中的字节或指令相对应，而从根节点到某个既定节点的路径代表了可能的字节或指令序列，权重则表示了对数据集采用简单线性扫描算法学习到的字节或指令序列的置信度。在鉴别函数的同时，ByteWeight采用值集分析(value set analysis, VSA)和增量控制流恢复算法实现对函数边界的识别。此种方案可以获得比IDA Pro和BAP工具[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b94" target="_blank" rel="noopener">94</a>]更高的准确率。Shin等[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b95" target="_blank" rel="noopener">95</a>]用循环神经网络算法改进了ByteWeight的性能，在模型训练时间上有了数量级上的提升，并取得了更高的准确率。</p><h3 id="3-1-2-函数相似性检测"><a href="#3-1-2-函数相似性检测" class="headerlink" title="3.1.2 函数相似性检测"></a>3.1.2 函数相似性检测</h3><p>现代应用程序中，直接调用第三方函数可以节约开发成本、提高开发效率，是被广泛接受的开发惯例。但这种方式容易导致供应链安全风险，一旦被调用函数存在漏洞，则调用这一函数的程序也可能存在漏洞。通过函数相似性检测技术可以实现对不同程序间的同源性漏洞的检测，但当前基于图的相似度匹配的方法具有计算量大、准确率低的缺陷。Xu等[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b97" target="_blank" rel="noopener">97</a>]提出了Gemini方案，Gemini把函数控制流图CFG简化为带节点属性(数字特征)的控制流图(ACFG)，然后用Structure2vec算法转化为数字向量，使用Siamese网络架构训练，实现相似的函数距离近的目标，最后通过计算函数向量距离实现函数相似性的检测。Gemini能应用到跨平台的二进制函数相似性检测，并取得了比其他基于图相似性匹配的工具(如Genius[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b98" target="_blank" rel="noopener">98</a>])更高的准确率和检测效率。</p><h3 id="3-1-3-测试输入生成"><a href="#3-1-3-测试输入生成" class="headerlink" title="3.1.3 测试输入生成"></a>3.1.3 测试输入生成</h3><p>在软件漏洞挖掘中，构造代码覆盖率高或脆弱性导向型的测试输入能提高漏洞挖掘的效率和针对性。利用机器学习技术可以对海量测试样本进行分析、学习，并利用生成模型指导生成更高质量的测试输入样本。Godefroid等[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b99" target="_blank" rel="noopener">99</a>]首次把模糊测试中的高结构化样本生成问题转换成了NLP领域的文本生成问题，采用了Char-RNN(recurrent neural network)模型实现对PDF文件格式中的obj语法的学习，并用训练好的模型生成具有多样性的obj对象和PDF文件。She等[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b100" target="_blank" rel="noopener">100</a>]提出了采用深度神经网络指导模糊测试输入生成的方案Neuzz。Neuzz采用了CNN(convolutional neural network)学习连续可微的神经程序(neural program)，用来近似模拟目标程序中的实际逻辑，然后通过对学习好的神经程序求梯度的方式指导测试输入生成，以此取得对目标程序更高的分支覆盖。与AFL相比，Neuzz在6个不同的常用程序中多发现了70倍的分支，并多发现了36个缺陷。Bottinger等[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b101" target="_blank" rel="noopener">101</a>]提出了深度强化学习增强的模糊测试技术，借助Markov模型把模糊测试问题转化成强化学习问题，并利用Q-learning算法优化预定义的奖励函数。实验结果表明，使用深度强化学习增强的模糊测试技术比随机变异能取得更高的代码覆盖率。Nichols等[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b102" target="_blank" rel="noopener">102</a>]提出了生成对抗网络(GAN)增强模糊测试技术。该方案不依赖于大数据量的样本训练，并能比AFL的随机变异和基于LSTM模型引导的变异更高效地发现更多的路径。</p><h3 id="3-1-4-测试输入筛选"><a href="#3-1-4-测试输入筛选" class="headerlink" title="3.1.4 测试输入筛选"></a>3.1.4 测试输入筛选</h3><p>动态漏洞挖掘依赖于测试输入的实际运行来检测是否能触发崩溃或漏洞，当有海量样本需要被执行测试时，会非常耗时且低效。测试样本筛选的目的是从海量样本中选择更有可能触发新路径或触发漏洞的测试输入。使用机器学习技术通过对大量的测试样本进行处理，从而决定哪些应该被进一步分析，尽可能准确地对样本进行标记，然后再用于寻找安全漏洞。Rajpal等[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b103" target="_blank" rel="noopener">103</a>]使用LSTM、序列到序列(Seq2seq)等神经网络学习模糊测试过程中的历史变异样本及代码覆盖率等数据，训练出能指导对输入文件进行定向变异的模型。实验结果表明，使用这种方法能获得比随机变异更高的代码覆盖率。但文[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b103" target="_blank" rel="noopener">103</a>]中采用的热力图生成模型仅仅依赖于基础样本以及能带来代码覆盖率增长的变异样本，训练生成的模型并没有记录测试输入与变异点、变异方法、代码覆盖增长情况之间的关联信息，基于这种模型生成的热力图不能精确标注记录测试输入中变异点与代码覆盖之间的关联性，因此热力图可能带有误标注和漏标注。此外，Spieker等[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b104" target="_blank" rel="noopener">104</a>]还提出了采用强化学习的算法优先筛选漏洞导向型的测试用例，应用在持续集成(continuous integration, CI)及回归测试(regression test)中。</p><p>2.1.5 路径约束求解</p><p>模糊测试，特别是代码覆盖率制导的模糊测试(如AFL)，侧重于筛选可以覆盖新路径的样本为种子文件，但对种子文件变异时并没有充分利用程序数据流等信息指导变异，这使得变异盲目低效，生成样本冗余。现有的一些启发式优化工作如Steelix[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b35" target="_blank" rel="noopener">35</a>]能够对魔术字节跟踪定位，但无法对其他路径约束求解。具备路径约束求解能力是符号执行比模糊测试等漏洞挖掘技术更先进的体现，也使得符号执行在理论上具备了系统性探索程序执行路径的能力。但复杂程序中的路径爆炸问题带来的对SMT求解器的频繁调用，以及SMT求解器本身的能力和效率的不足，使得约束求解占用了符号执行中主要的性能开销，约束求解问题也成为符号执行中面临的主要瓶颈问题之一。Chen等[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b105" target="_blank" rel="noopener">105</a>]提出了Angora，采用污点追踪测试输入中影响条件分支的字节，然后使用梯度下降的方式对变异后生成的路径约束进行求解。这种方式避免了符号执行调用SMT求解器可能带来的开销以及复杂约束不可解的问题，但梯度下降对目标函数不可导或存在不可导点时，仍然会出现求解困难的问题。</p><h3 id="3-1-6-漏洞程序筛选"><a href="#3-1-6-漏洞程序筛选" class="headerlink" title="3.1.6 漏洞程序筛选"></a>3.1.6 漏洞程序筛选</h3><p>传统的漏洞挖掘技术如模糊测试、符号执行等已经成功地从各类软件中发现了大量的漏洞，但当被测试程序复杂且数量庞大的时候，使用这些技术挖掘漏洞显得效率低下。VDiscover[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b106" target="_blank" rel="noopener">106</a>]采用机器学习技术从大量的程序中快速筛选更有可能带有漏洞的程序。具体而言，VDiscover收集程序中的标准C库函数调用序列及其参数的动态值作为静态和动态特征，并对其做标注，然后采用带监督的机器学习算法(如随机森林，逻辑回归等)训练模型，当有新的被测试程序需要分类的时候，训练好的模型可以直接对提取的相应特征进行预判和标注。</p><p>VDiscover首次验证了采用机器学习技术筛选漏洞程序的可行性，但其采用人工定义和提取特征的方法具有较大的局限性。漏洞成因复杂，VDiscover提取的程序静态特征和动态特征并不能精确地表征各种类型的漏洞, 这可能造成较高的误报和漏报。另外，采用机器学习直接对漏洞程序进行预测的方式无法生成测试用例来动态验证漏洞。</p><h3 id="3-1-7-源代码漏洞点预测"><a href="#3-1-7-源代码漏洞点预测" class="headerlink" title="3.1.7 源代码漏洞点预测"></a>3.1.7 源代码漏洞点预测</h3><p>传统静态漏洞挖掘技术中，依赖于人工定义漏洞模式的检测方式经常会导致较高的漏报率。Li等[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b107" target="_blank" rel="noopener">107</a>]提出了VulDeePecker方案，采用BLSTM算法对C/C++源代码中的漏洞点进行预测。鉴于传统的漏洞分类过细导致难以抽象提取为特征的问题，其设计了能覆盖多种漏洞类型的特征，这种方式不以函数为粒度，只考虑数据流保留语义上关联的代码行作为代码小部件(code gadgets)对程序进行表征，然后转换成向量作为深度学习的输入。但VulDeePecker方案中，代码小部件转换成向量的过程存在较大的信息丢失问题；另外，该方案只支持对缓冲区溢出和资源管理相关的漏洞的检测。</p><h3 id="3-1-8-其他"><a href="#3-1-8-其他" class="headerlink" title="3.1.8 其他"></a>3.1.8 其他</h3><p>此外，机器学习还应用于模糊测试参数配置预测[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b108" target="_blank" rel="noopener">108</a>]和漏洞可利用性分析[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b109" target="_blank" rel="noopener">109</a>-<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b110" target="_blank" rel="noopener">110</a>]等场景中。</p><h2 id="3-2-面临的问题"><a href="#3-2-面临的问题" class="headerlink" title="3.2 面临的问题"></a>3.2 面临的问题</h2><h3 id="3-2-1-机器学习的局限性"><a href="#3-2-1-机器学习的局限性" class="headerlink" title="3.2.1 机器学习的局限性"></a>3.2.1 机器学习的局限性</h3><p>虽然以机器学习为代表的人工智能技术取得了非常瞩目的进展，但其本身也面临着巨大的挑战。基于机器学习的漏洞挖掘技术受限于算法本身的能力，也受限于算法本身的安全性和健壮性。</p><p>当前的机器学习技术并没有解决人工智能的核心问题，不是通向人工智能的最佳途径[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b111" target="_blank" rel="noopener">111</a>]。传统的机器学习技术需要人工设计、构建特征，然后转换成向量作为机器学习算法的输入，不具备对原始数据自动提取特征的能力，严重依赖于专家知识。深度学习具有在高维数据中自动提取特征的能力，并已经取得了广泛应用，但其仍然面临着持续学习、数据饥饿、可解释性等问题[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b111" target="_blank" rel="noopener">111</a>-<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b112" target="_blank" rel="noopener">112</a>]。</p><p>另外，当前的机器学习算法的安全性和健壮性问题也逐渐暴露出来。一方面，常用机器学习工具存在漏洞。Stevens等[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b113" target="_blank" rel="noopener">113</a>]利用模糊测试方法挖掘出了OpenCVScikit-Learn、NumPy等常用的机器学习软件的库文件中的堆溢出等漏洞，这些漏洞能导致Dos攻击或任意代码执行，或直接修改分类判定结果。另一方面，机器学习算法本身的健壮性问题容易导致对抗式攻击(adversarial attack)[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b114" target="_blank" rel="noopener">114</a>-<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b119" target="_blank" rel="noopener">119</a>]。对抗式攻击又称为对抗性训练或对抗性机器学习，通过在数据集中注入被污染的数据而欺骗模型做出错误的判断。此外，健壮性问题还容易导致污染攻击[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b120" target="_blank" rel="noopener">120</a>-<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b122" target="_blank" rel="noopener">122</a>]，逃逸攻击[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b123" target="_blank" rel="noopener">123</a>-<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b126" target="_blank" rel="noopener">126</a>]、模型倒置攻击[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b127" target="_blank" rel="noopener">127</a>-<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b128" target="_blank" rel="noopener">128</a>]，模型(参数)提取攻击[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b129" target="_blank" rel="noopener">129</a>-<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b131" target="_blank" rel="noopener">131</a>]等，这类攻击通常具有较高的隐蔽性。</p><h3 id="3-2-2-算法选择"><a href="#3-2-2-算法选择" class="headerlink" title="3.2.2 算法选择"></a>3.2.2 算法选择</h3><p>机器学习、深度学习虽然已经在图像识别、自然语言处理等领域已经有比较成熟的应用，但在漏洞挖掘领域，不同的应用场景下可能只适用于部分机器学习算法，甚至同一场景中，选择不同的适用算法也会导致结果的显著差异。但现有的研究工作大部分只凭经验选取了部分机器学习算法，并未对各类算法性能进行较系统性的比对。如在文[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b103" target="_blank" rel="noopener">103</a>, <a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b107" target="_blank" rel="noopener">107</a>]中采用了LSTM等循环神经网络算法实现可变长序列预测和文本生成，但当前CNN已经可以取得比LSTM更好的性能[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b132" target="_blank" rel="noopener">132</a>-<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b133" target="_blank" rel="noopener">133</a>]。其次，还要考虑根据数据量大小的问题，如果数据量小，人工指定规则的传统机器学习可能会有更好地性能。深度学习虽然能自动对各种简单的特征学习并组合成更加复杂的特征，在特征提取上比传统的机器学习算法具有更大的优势，但深度学习更适合大数据量的学习。另外，对同一种算法的不同参数配置也能产生不同的模型，需要在对模型进行评估的基础上选择泛化误差小的模型。</p><h3 id="3-2-3-数据收集"><a href="#3-2-3-数据收集" class="headerlink" title="3.2.3 数据收集"></a>3.2.3 数据收集</h3><p>机器学习、深度学习需要大量的样本，特别是深度学习在数据量不足时容易导致过拟合的问题。目前，在现有工作中针对不同应用场景和学习任务，收集的样本对象包括了二进制程序、PDF文件、C/C++源码、IOT固件等，这些数据的收集方式参差不齐，如模糊测试生成、符号执行生成、人工编译生成、网络爬虫等。对于常用的文件格式如DOC、PDF、SWF等，采用网络爬虫获取测试输入集是比较常用的方法。爬取方式可按特定文件扩展名(后缀)为筛选条件进行下载，或者按特定魔术字节或其他签名的方式下载，爬取的结果很容易就能达到TB数量级(如Skyfire[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b133" target="_blank" rel="noopener">133</a>])。但对于其他数据如崩溃样本、漏洞程序等，因其具有稀缺性，存在收集困难的问题。当前缺少通用的、认可度较高的漏洞相关的数据集可供基于机器学习、深度学习的技术进行训练和测试。</p><p>收集漏洞相关的大数据集能为基于机器学习的智能化漏洞挖掘和分析提供学习素材，也关系到训练模型的效果。构建面向机器学习的大规模漏洞数据集对后续的研究将起到至关重要的作用，应当成为未来研究的重点问题之一。</p><h3 id="3-2-4-特征选择"><a href="#3-2-4-特征选择" class="headerlink" title="3.2.4 特征选择"></a>3.2.4 特征选择</h3><p>传统机器学习算法分类、预测的准确性既与数据量的大小有关，也依赖于从数据中提取的特征。在漏洞挖掘中，程序结构和执行信息与漏洞并没有直接的关联性，如何从程序中筛选出漏洞相关的显著特征、摒弃非显著特征，需要结合机器学习算法、程序执行环境及漏洞产生原理等多方面考虑。例如在二进制程序中，静态特征可以从调用图、控制流图、数据流图等获取(同时要考虑图信息获取不精确的问题)，动态特征可以通过插桩执行跟踪(trace)实际函数调用以及调用参数的方式捕获。另外，还要考虑动、静态特征提取时带来的开销和可扩展性问题。如在二进制程序中，对目标程序建立各种基于图的结构计算量较大，动态特征提取则依赖于实际执行插桩跟踪测试程序，而插桩特别是动态插桩会带来比较大的开销，甚至会影响程序实际执行时的内存空间布局。</p><p>综上所述，探索基于学习的漏洞挖掘技术，研究机器学习算法对软件漏洞挖掘中的不同应用场景的适用性，借助机器学习的分类、预测能力甚至深度学习的自动特征提取能力来缓解、突破传统技术的瓶颈问题，是当前智能化漏洞挖掘研究的热点和难点。</p><h1 id="4-结论与展望"><a href="#4-结论与展望" class="headerlink" title="4 结论与展望"></a>4 结论与展望</h1><p>本文分析了传统漏洞挖掘技术及基于学习的智能化漏洞挖掘技术的研究进展，针对这些技术呈现出的自动化、智能化的趋势及面临的问题进行了深入的调研分析、归类和总结。</p><p>下一步的研究应从以下2点展开：</p><ul><li><strong>1) 提高漏洞挖掘的效率与精度</strong></li></ul><p>漏洞挖掘是计算密集型的工作，与软件的规模和复杂度、硬件系统性能、采用的分析技术都有非常大的关联性，在研究实践中往往需要根据这些影响因素动态调整程序分析策略，在分析效率与分析深度之间取得较好的平衡和折中。一方面，需要研究轻量级分析技术、启发式状态空间探测技术(如脆弱路径筛选、低频路径筛选等)，在较小的开销内增强漏洞挖掘的导向性。另一方面，需要研究高效的规模化、并行化分析方法。漏洞挖掘在算法、分析数据存储和处理方面都有显著特征，现有的技术对大型复杂程序分析效率低下，没有充分利用高性能硬件设备提供的并行处理能力。探索规模化、并行化漏洞挖掘技术，增强对异构化计算资源的利用率，能很好应对大型复杂软件快速分析的需求。</p><ul><li><strong>2) 提高漏洞挖掘的自动化与智能化</strong></li></ul><p>在自动化方面，研究不依赖或较少依赖于人工参与的漏洞挖掘技术如漏洞利用程序自动生成、高结构化测试输入生成等仍然是当前研究的难点，这对实现全自动的漏洞挖掘甚至网络攻防都有重要的推进作用。在智能化方面，需要研究机器学习(如深度学习、强化学习、生成对抗网络等)在漏洞挖掘领域的应用。适用场景还应包括脆弱路径筛选、高结构化输入生成、约束求解配置预测等。基于机器学习的漏洞挖掘技术为解决传统漏洞挖掘技术的一些瓶颈问题提供了新途径，既能提升漏洞挖掘的自动化程度，也能提高漏洞挖掘的效率和精度。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h1&gt;&lt;p&gt;近年来，随着软件规模和复杂度的日益增加，软件漏洞挖掘技术正逐渐向高度自动化和智能化演变，该文
      
    
    </summary>
    
      <category term="论文" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/"/>
    
      <category term="fuzzing" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/fuzzing/"/>
    
      <category term="综述" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/fuzzing/%E7%BB%BC%E8%BF%B0/"/>
    
    
      <category term="2018年" scheme="http://yama0xff.com/tags/2018%E5%B9%B4/"/>
    
      <category term="综述" scheme="http://yama0xff.com/tags/%E7%BB%BC%E8%BF%B0/"/>
    
      <category term="Fuzzing" scheme="http://yama0xff.com/tags/Fuzzing/"/>
    
  </entry>
  
  <entry>
    <title>Fuzzing: Art, Science, and Engineering</title>
    <link href="http://yama0xff.com/2019/03/20/Fuzzing-Art-Science-and-Engineering/"/>
    <id>http://yama0xff.com/2019/03/20/Fuzzing-Art-Science-and-Engineering/</id>
    <published>2019-03-20T09:02:30.000Z</published>
    <updated>2019-03-28T01:19:43.406Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>在当今可用的众多软件漏洞发现技术中，模糊测试由于其概念简单，部署的低屏障以及发现现实世界软件漏洞的大量经验证据而一直非常受欢迎。虽然近年来研究人员和从业人员都为改进模糊测试投入了大量不同的努力，但这项工作的激增也使得难以获得全面和一致的模糊测试观点。为了帮助保存并使大量的模糊测量文献保持连贯性，本文提出了一种统一的，通用的模糊测试模型以及当前模糊文献的分类。我们通过调查相关文献和艺术，科学和工程方面的创新，有条不紊地探索模型模糊器的每个阶段的设计决策，使现代模糊器有效。</p><table><thead><tr><th>relevant information</th><th></th></tr></thead><tbody><tr><td><em>作者</em></td><td>VALENTIN J.M. MANÈS，HYUNGSEOK HAN,CHOONGWOO HAN,SANG KIL CHA∗,MANUEL EGELE,EDWARD J. SCHWARTZ,MAVERICK WOO,</td></tr><tr><td><em>单位</em></td><td></td></tr><tr><td><em>出处</em></td><td>CSUR‘19</td></tr><tr><td><em>原文地址</em></td><td><a href="https://github.com/wtwofire/database/blob/master/papers/fuzzing/Review/2019-fuzzing%EF%BC%9A%20Art%2C%20Science%2C%20and%20Engineering.pdf" target="_blank" rel="noopener">https://github.com/wtwofire/database/blob/master/papers/fuzzing/Review/2019-fuzzing%EF%BC%9A%20Art%2C%20Science%2C%20and%20Engineering.pdf</a></td></tr><tr><td><em>源码地址</em></td><td></td></tr><tr><td><em>发表时间</em></td><td>2019</td></tr></tbody></table><h1 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h1><p>自从20世纪90年代初引入[139]以来，模糊测试一直是发现软件安全漏洞的最广泛部署的技术之一。在高级别，模糊测试指的是重复运行程序和构造的输入的过程，该输入可能在语法上或语义上不正确。在实践中，攻击者通常在诸如漏洞利用生成和渗透测试的场景中部署模糊测试[20,102]; 2016年DARPA网络大挑战赛（CGC）的几支队伍也在他们的网络推理系统中使用模糊测试[9,33,87,184]。在这些活动的推动下，防御者开始使用模糊测试来试图在攻击者发现漏洞之前发现漏洞。例如，Adobe [1]，Cisco [2]，Google [5,14,55]和Microsoft [8,34]等知名厂商都将模糊测试作为其安全开发实践的一部分。最近，安全审计员[217]和开源开发人员[4]也开始使用模糊测试来衡量商品软件包的安全性，并为最终用户提供一些合适的保证形式。</p><p>模糊社区非常有活力。在撰写本文时，仅GitHub就拥有了超过一千个与模糊测试相关的公共存储库[80]。正如我们将要展示的那样，文献中还包含大量的模糊器（参见第7页的图1），并且越来越多的模糊测试研究出现在主要安全会议上（例如[33,48,164,165,199,206] ]）。此外，博客圈中充满了许多模糊测试的成功故事，其中一些还包含了我们认为是<a href="https://goo.gl/37GYKN" target="_blank" rel="noopener">精华</a>的东西，这些精华在文献中占有一席之地。</p><p>不幸的是，研究人员和从业人员在模糊测试方面的工作激增也带来了阻碍进展的警告信号。例如，一些模糊器的描述不会超出其源代码和手册页。因此，随着时间的推移，很容易忘记这些模糊测试中的设计决策和潜在的重要调整。此外，各种模糊器使用的术语中存在可观察到的碎片。例如，虽然AFL [211]使用术语“测试用例最小化”来指代减小崩溃输入大小的技术，但同样的技术在funfuzz中也被称为“测试用例减少”[143]。虽然BFF [45]包含一种称为“崩溃最小化”的技术，听起来非常相似，但崩溃最小化的目的实际上是最小化崩溃输入和原始种子文件之间不同的位数，而不是减少崩溃输入的大小。我们认为这种分散使得难以发现和传播 fuzzing 知识，从长远来看，这可能严重阻碍 fuzzing 研究的进展。</p><p>基于我们的研究和我们在模糊测试方面的个人经验，本文作者认为现在是整合和提炼模糊测试大量进展的黄金时间，其中许多是在2007-2008 [73,187,189]年出版的三本关于该主题的贸易书籍之后发生的 。我们注意到Li等人同时进行了调查。 [125]侧重于基于覆盖的模糊测试的最新进展，但我们的目标是提供有关该领域近期发展的综合研究。为此，我们将首先使用§2来展示我们的模糊术语和统一的模糊测试模型。坚持本文的目的，选择我们的模糊术语来密切反映当前的主要用法，我们的模型模糊器（算法1，第4页）旨在适应大量的模糊测试任务，如分类在目前的模糊文献（图1，第7页）。通过这种设置，我们将在§3-§7中有条不紊地探索模型模糊器的每个阶段，并在表1中详细介绍主要模糊器（第9页）。<br>在每个阶段，我们将调查相关文献来解释设计选择，讨论重要的权衡，并突出许多奇妙的工程努力，帮助使现代模糊器有效地完成他们的任务。</p><h1 id="2-系统化，分类和测试程序"><a href="#2-系统化，分类和测试程序" class="headerlink" title="2. 系统化，分类和测试程序"></a>2. 系统化，分类和测试程序</h1><p>术语“fuzz”最初由Miller等人创造。在1990年，它指的是“生成一个由目标程序消耗的随机字符流”的程序[139，p.4]。从那时起，模糊的概念及其动作 - “fuzzing” - 出现在各种各样的语境中，包括动态符号执行[84,207]，基于语法的测试用例生成[82,98,196]，权限测试[21,74]，行为测试[114,163,205]，表示依赖性测试[113]，函数检测[208]，健壮性评估[204]，漏洞利用开发[104]，GUI测试[181]，签名生成[66]和渗透测试[75,145]。为了使大量的模糊测试文献中的知识系统化，让我们首先提出从当前使用中提取的模糊测试术语。</p><h2 id="2-1-Fuzzing-amp-Fuzzing-Testing"><a href="#2-1-Fuzzing-amp-Fuzzing-Testing" class="headerlink" title="2.1 Fuzzing &amp; Fuzzing Testing"></a>2.1 Fuzzing &amp; Fuzzing Testing</h2><p>直观地说，fuzzing是使用“模糊输入”运行被测程序（PUT）的行为。Honoring Miller等人，我们认为模糊输入是PUT可能不期望的输入，即PUT可能错误处理的输入并且触发PUT开发者无意识的行为。为了捕捉这个想法，我们将术语fuzzing定义如下。</p><blockquote><p><strong>定义2.1（fuzzing）</strong>。模糊测试是使用从输入空间（“模糊输入空间”）采样的输入执行PUT，该输入空间突出了PUT的预期的输入空间。</p></blockquote><p>三个评论是有序的。首先，尽管通常看到模糊输入空间包含预期的输入空间，但这不是必需的 - 前者包含d的输入不在后者中就足够了。其次，在实践中，模糊测试几乎肯定会进行多次迭代;因此，在上面写“重复执行”仍然很准确。第三，抽样过程不一定是随机的，我们将在§5中看到.</p><p>Fuzz testing是一种利用fuzzing的软件测试技术。为了区别于其他人并尊重我们认为最突出的目标，我们认为它有一个特定的目标，即找到与安全相关的错误，其中包括程序崩溃。此外，我们还定义了fuzzer和fuzz campaign，这两者都是模糊测试中的常用术语。</p><blockquote><p><strong>定义2.2（Fuzz Testing）</strong>。Fuzz Testing是使用fuzzing，其目标是测试PUT违反安全策略的地方。<br><strong>定义2.3（Fuzzer）</strong>。Fuzzer是一种在PUT上执行fuzz testing的程序。<br><strong>定义2.4（Fuzz Campaign）</strong>。Fuzz Campaign是一个在有特定安全策略的PUT上的特定执行的Fuzzer。</p></blockquote><p>通过fuzzing campaign运行PUT的目的是找到违反所需安全策略的错误[23]。例如，早期fuzzer使用的安全策略仅测试生成的输入 - 测试用例 - 是否使PUT崩溃。但是，fuzz testing 实际上可用于测试任何可执行的安全策略，即EMenforceable [171]。决定执行是否违反安全策略的具体机制称为<strong>bug oracle</strong>。</p><blockquote><p><strong>定义2.5（Bug Oracle）</strong>。 bug oracle是一个程序，可能作为fuzzer的一部分，用于确定PUT的给定执行是否违反特定的安全策略。</p></blockquote><p> 我们将fuzzer实现的算法简称为<strong>“fuzz algorithm”</strong>。几乎所有 fuzz algorithm都依赖于PUT之外的一些参数（路径）。参数的每个具体设置都是<strong>fuzz configuration：</strong></p><blockquote><p><strong>定义2.6（Fuzz Configuration）</strong>。fuzz algorithm的fuzz configuration包括控制fuzz algorithm的参数值。</p></blockquote><p>Fuzz configuration通常被写为元组。请注意，fuzz configuration中的值类型取决于fuzz algorithm的类型。例如，将随机字节流发送到PUT [139]的fuzz algorithm具有简单的配置空间{（PUT）}。另一方面，复杂的fuzzer包含接受一组配置并随时间推移设置的算法 - 这包括添加和删除配置。例如，CERT BFF [45]在活动过程中改变了突变率和种子（在第5.2节中定义），因此其配置空间为{(PUT，s1，r1)，(PUT，s2，r2）,. … }。最后，对于每个配置，我们还允许fuzzer存储一些数据。例如，覆盖引导的模糊器可以存储每个配置的获得的覆盖范围。</p><h2 id="2-2-Paper-Selection-Criteria"><a href="#2-2-Paper-Selection-Criteria" class="headerlink" title="2.2 Paper Selection Criteria"></a>2.2 Paper Selection Criteria</h2><p>为了达到明确的范围，我们选择在2008年1月至2018年5月的4个主要安全会议和3个主要软件工程会议的最后一个议程中包括所有关于模糊测试的出版物。按字母顺序排列，前者包括（i）ACM会议计算机和通信安全（<code>CCS</code>），（ii）IEEE安全和隐私（<code>S＆P</code>）研讨会，（iii）网络和分布式系统安全研讨会（<code>NDSS</code>），以及（iv）USENIX安全研讨会（<code>USEC</code>）;后者包括（i）ACM国际软件工程基础研讨会（<code>FSE</code>），（ii）IEEE / ACM自动软件工程国际会议（<code>ASE</code>），以及（iii）国际软件工程会议（<code>ICSE</code>）。对于出现在其他场所或媒介中的作品，我们根据自己对其相关性的判断将它们包括在内。</p><p>正如§2.1中所提到的，fuzz testing与软件测试的区别仅在于它与安全相关。尽管瞄准安全漏洞并不意味着除了在理论上使用bug oracle之外的测试过程中存在差异，但所使用的技术在实践中通常会有所不同。在设计测试工具时，我们经常假设源代码的存在和PUT的知识。与fuzzer相比，这些假设通常会将工具的开发推向不同的形状。尽管如此，这两个领域仍然彼此纠缠不清。因此，当我们自己的判断力不足以区分它们时，我们遵循一个简单的经验法则：如果出版物中没有出现fuzz这个词，我们就不包括它。</p><h2 id="2-3-Fuzz-Testing-Algorithm"><a href="#2-3-Fuzz-Testing-Algorithm" class="headerlink" title="2.3 Fuzz Testing Algorithm"></a>2.3 Fuzz Testing Algorithm</h2><p>我们提出了一种用于fuzz testing的通用算法，算法1，我们想象它已经在模型fuzzer中实现。它足以适应现有的模糊测试技术，包括§2.4中定义的黑色，灰色和白盒模糊测试。算法1将一组fuzz configurations C和一个超时 t_limit 作为输入，并输出一组发现的错误B.它由两部分组成。第一部分是预处理功能，它在fuzz campaign开始时执行。第二部分是循环内的一系列五个函数：<strong>Schedule，InputGen，InputEval，ConfUpdate和Continue</strong>。此循环的每次执行都称为<strong>fuzz iteration</strong>，并且在单个测试用例上执行InputEval称为<strong>fuzz run</strong>。请注意，一些模糊器不会实现所有五个功能。例如，为了模拟Radamsa [95]，我们让ConfUpdate简单地返回C，即它不会更新C.</p><p><img src="/2019/03/20/Fuzzing-Art-Science-and-Engineering/1.Fuzz Test.jpg" alt="Fuzz Test"></p><p><strong>Preprocess（C）–&gt;C</strong></p><blockquote><p> 用户为Preprocess提供一组fuzz configurations作为输入，并返回一组可能已修改的fuzz configurations。根据fuzz algorithm，Preprocess可以执行各种操作，例如将检测代码插入PUT，或测量种子文件的执行速度。见§3</p></blockquote><p><strong>Schedule(C,telapsed,tlimit) –&gt; conf </strong></p><blockquote><p>Schedule接收当前的fuzz configurations，当前时间t_elapsed和超时t_limit作为输入，并选择要用于当前模糊迭代的fuzz configuration。见§4。</p></blockquote><p><strong>InputGen（conf）–&gt;tcs </strong></p><blockquote><p>InputGen将fuzz configurations作为输入，并返回一组具体测试用例 tcs 作为输出。生成测试用例时，InputGen使用conf中的特定参数。一些模糊测试器使用conf中的种子来生成测试用例，而其他模糊器则使用模型或语法作为参数。见§5。</p></blockquote><p><strong>InputEval (conf, tcs, Obug) –&gt; B′, execinfos</strong></p><blockquote><p>InputEval采用fuzz配置conf，一组测试用例 tcs 和一个bug oracle Obug作为输入。它在tcs上执行PUT并使用bug oracle O_bug检查执行是否违反了安全策略。然后它输出发现的错误集B’和关于每个fuzz运行的信息 execinfos。我们假设O_bug嵌入在我们的模型模糊器中。见§6。</p></blockquote><p><strong>ConfUpdate(C，conf，execinfos) –&gt; C </strong></p><blockquote><p>ConfUpdate采用一组fuzz configurations C，当前配置 conf，以及每个模糊运行的信息 execinfos作为输入。它可能会更新一组fuzz configurations C.例如，许多灰盒模糊器会根据execinfos减少C中的模糊配置数量。见§7。</p></blockquote><p><strong>Continue (C) –&gt;  {True, False} </strong></p><blockquote><p>Continue将一组fuzz configurations C作为输入，并输出一个布尔值，指示是否应该进行下一个模糊迭代。此功能对于模型白盒模糊器很有用，当没有更多路径可以发现时，它可以终止。</p></blockquote><h2 id="2-4-Fuzzers-的分类"><a href="#2-4-Fuzzers-的分类" class="headerlink" title="2.4  Fuzzers 的分类"></a>2.4  Fuzzers 的分类</h2><p>在本文中，我们根据模糊器在每个模糊运行中观察到的语义粒度将模糊器分为三组：黑盒，灰盒和白盒fuzzer。请注意，这与传统的软件测试不同，传统的软件测试只有两个主要类别（黑盒和白盒测试）[147]。正如我们将在§2.4.3中讨论的那样，灰盒模糊测试是白盒模糊测试的一种变体，它只能从每次模糊运行中获取一些部分信息。 </p><p>图1按时间顺序列出了现有fuzzer的分类。从Miller等人的开创性工作开始。 [139]，我们手动选择了在大型会议上出现或获得超过100个GitHub stars的流行fuzzer，并将其关系显示在图上。黑盒fuzzer位于图的左半部分，灰盒和白盒模糊器位于右半部分。</p><p><img src="/2019/03/20/Fuzzing-Art-Science-and-Engineering/2.jpg" alt="2"></p><p>表1详细介绍了主要会议上出现的每个主要fuzzer所使用的技术。由于空间限制，我们省略了几个主要的fuzzer。每个模糊器都投影在我们上面提到的模型模糊器的五个功能上，其中一个杂项部分提供了有关fuzzer的额外细节。第一列（检测粒度）表示基于静态或动态分析从PUT获取多少信息。当fuzzer在两个阶段使用不同类型的插桩时，出现两个圆圈。例如，SymFuzz [48]运行白盒分析作为预处理，以便为随后的黑盒活动提取信息，而Driller [184]在白盒和灰盒模糊之间交替进行。</p><ul><li><p><strong>第二列</strong>显示来源是否公开。</p></li><li><p><strong>第三列</strong>表示模糊器是否需要源代码才能运行。</p></li><li><p><strong>第四列</strong>指出了模糊器是否支持内存模糊测试（参见§3.1.2）。</p></li><li><p><strong>第五列</strong>是关于fuzzer是否可以推断模型（参见§5.1.2）。</p></li><li><p><strong>第六列</strong>显示了在Preprocess中，fuzzer是执行静态分析还是动态分析。<strong>第七列</strong>指示fuzzers是否支持处理多个种子，并执行调度。</p></li><li><p><strong>变异列</strong>指定fuzzers是否执行输入变异以生成测试用例。我们使用“半黑半白”来表示fuzzer根据执行反馈引导输入变异。基于模型的专栏是关于fuzzer是否基于模型生成测试用例。</p></li><li><p><strong>基于约束的列</strong>显示fuzzers执行符号分析以生成测试用例。<strong>污点分析列</strong>意味着模糊测试器利用污点分析来指导其测试用例生成过程。</p></li><li><p><strong>InputEval部分</strong>中的两列显示fuzzers是使用堆栈哈希还是使用代码覆盖率执行崩溃分类。</p></li><li><p><strong>ConfUpdate部分</strong>的第一列指示在ConfUpdate期间模糊器是否进化种子池，例如，向池中添加有趣的种子（参见§7.1）。 ConfUpdate部分的第二列是关于fuzzers是否以在线方式学习模型。最后，ConfUpdate部分的第三列显示了从种子池中删除种子（参见§7.2）。</p></li></ul><p><img src="/2019/03/20/Fuzzing-Art-Science-and-Engineering/3.jpg" alt="表1"></p><h3 id="2-4-1黑盒fuzzer"><a href="#2-4-1黑盒fuzzer" class="headerlink" title="2.4.1黑盒fuzzer"></a>2.4.1黑盒fuzzer</h3><p>术语“黑盒”通常用于软件测试[29,147]，fuzzing表示没有看到PUT内部的技术 - 这些技术只能观察PUT的输入/输出行为，将其视为一个黑盒子。在软件测试中，黑盒测试也称为IO驱动或数据驱动测试[147]。大多数传统的模糊器[6,13,45,46,96]属于这一类。一些现代模糊器，例如<code>funfuzz</code> [143]和<code>Peach</code> [70]，也考虑了有关输入的结构信息，以生成更有意义的测试用例，同时保持不检查PUT的特性。类似的直觉用于自适应随机测试[51]。</p><h3 id="2-4-2白盒Fuzzer"><a href="#2-4-2白盒Fuzzer" class="headerlink" title="2.4.2白盒Fuzzer"></a>2.4.2白盒Fuzzer</h3><p>在频谱的另一个极端，白盒模糊[84]通过分析PUT的内部和执行PUT时收集的信息来生成测试用例。因此，白盒模糊器能够系统地探索PUT的状态空间。术语白盒模糊是由Godefroid [81]在2007年引入的，它指的是动态符号执行（DSE），它是符号执行的变体[35,101,118]。在DSE中，符号和具体执行同时进行，其中具体的程序状态用于简化符号约束，例如，具体化系统调用。因此，DSE通常被称为concolic testing（具体的+符号的）[83,176]。此外，白盒模糊测试也被用于描述采用污点分析的模糊器[78]。<br>白盒模糊测试的开销通常远高于黑盒模糊测试的开销。这部分是因为DSE实现[22,42,84]经常采用动态插桩和SMT求解[142]。虽然DSE是一个活跃的研究领域[34,82,84,105,160]，但许多DSE不是白盒模糊器，因为它们的目的不是找到安全漏洞。因此，本文没有提供有关DSE的全面调查，我们将读者引用到最近的调查论文[16,173]以获取更多信息。</p><h3 id="2-4-3灰盒Fuzzer"><a href="#2-4-3灰盒Fuzzer" class="headerlink" title="2.4.3灰盒Fuzzer"></a>2.4.3灰盒Fuzzer</h3><p>一些安全专家[62,72,189]提出了一种中间方法，并将其称为灰盒模糊测试。通常，灰盒模糊器可以获得PUT内部和/或其执行的一些信息。与白盒模糊器不同，灰盒模糊器不具备PUT的完整语义;相反，他们可以对PUT执行轻量级静态分析和/或收集有关其执行的动态信息，例如覆盖范围。 Greybox模糊器使用信息近似来测试更多输入。尽管安全专家之间通常存在共识，但黑盒，灰盒和白盒模糊测试之间的区别并不总是很明显。黑盒模糊器可能仍会收集一些信息，而白盒模糊器通常被迫做一些近似。本次调查中的选择，特别是表1中的选择，是有争议的，但是作者最好的判断。</p><p>灰盒模糊器的早期示例是EFS [62]，它使用从每个模糊运行中收集的代码覆盖率来使用进化算法生成测试用例。 <code>Randoop</code> [155]也使用了类似的方法，但它没有针对安全漏洞。现代模糊器如<code>AFL</code> [211]和<code>VUzzer</code> [164]是此类别中的示例。</p><h1 id="3-预处理-PREPROCESS"><a href="#3-预处理-PREPROCESS" class="headerlink" title="3 预处理(PREPROCESS)"></a>3 预处理(PREPROCESS)</h1><p>一些模糊器在第一次模糊迭代之前修改了初始的fuzz configurations。这种预处理通常用于插桩PUT，清除潜在的冗余配置（即(seed selection)种子选择[165]），并修剪种子</p><h2 id="3-1-插桩（Instrumentation-）"><a href="#3-1-插桩（Instrumentation-）" class="headerlink" title="3.1 插桩（Instrumentation ）"></a>3.1 插桩（Instrumentation ）</h2><p>与黑盒模糊器不同，灰盒和白盒模糊器可以在InputEval执行模糊运行（参见§6），或者在运行时模糊内存内容时插桩PUT以收集执行反馈。虽然还有其他方法可以获取PUT内部的信息（例如处理器跟踪或系统调用[86,188]），但插桩通常是收集最有价值信息的方法，因此几乎完全定义了颜色。模糊（从表1的第一列）。</p><p>程序插桩可以是静态的也可以是动态的 - 前者在PUT运行之前发生，而后者在PUT运行时发生。由于静态检测在运行时之前发生，因此它通常比动态检测产生更少的运行时开销。</p><p>静态插桩通常在编译时在源代码或中间代码上执行。如果PUT依赖于库，则必须单独插桩它们，通常通过使用相同的插桩重新编译它们。除了基于源代码的插桩，研究人员还开发了二进制级静态插桩（即二进制重写）工具[71,122,218]。</p><p>虽然它比静态插桩具有更高的开销，但动态插桩的优势在于它可以轻松地插桩动态链接库，因为插桩是在运行时执行的。有几种众所周知的动态插桩工具，如<code>DynInst</code>[161]，<code>DynamoRIO</code> [38]，<code>Pin</code>[131]，<code>Valgrind</code> [152]和<code>QEMU</code> [30]。通常，动态插桩在运行时发生，这意味着它对应于模型中的InputEval。但为了方便读者，我们在本节中总结了静态和动态插桩。</p><p>给定的模糊器可以支持多种类型的插桩。例如，AFL在源代码级别使用修改后的编译器支持静态插桩，或者在QEMU的帮助下支持二进制级别的动态插桩[30]。使用动态插桩时，AFL可以插桩（1）PUT本身的可执行代码（默认设置），或者（2）PUT中的可执行代码和任何外部库（使用AFL_INST_LIBS选项）。第二个选项 - 插桩所有遇到的代码 - 可以报告外部库中代码的覆盖信息，从而提供有关覆盖范围的更完整的图像。但是，这反过来会导致AFL模糊外部库函数中的其他路径。</p><h3 id="3-1-1执行反馈（Execution-Feedback-）"><a href="#3-1-1执行反馈（Execution-Feedback-）" class="headerlink" title="3.1.1执行反馈（Execution Feedback. ）"></a>3.1.1执行反馈（Execution Feedback. ）</h3><p>灰盒模糊器通常将执行反馈作为输入来演化测试用例。 AFL及其后代通过检测PUT中的每个分支指令来计算分支覆盖。但是，它们将分支覆盖信息存储在一个byte向量中，这可能导致路径冲突。 <code>CollAFL</code> [77]最近通过引入一个新的路径敏感哈希函数来解决这个问题。同时，<code>LibFuzzer</code> [7]和<code>Syzkaller</code> [198]使用节点覆盖作为执行反馈。<code>Honggfuzz</code>[188]允许用户选择要使用的执行反馈。</p><h3 id="3-1-2-内存模糊测试（In-Memory-Fuzzing-）"><a href="#3-1-2-内存模糊测试（In-Memory-Fuzzing-）" class="headerlink" title="3.1.2 内存模糊测试（In-Memory Fuzzing ）"></a>3.1.2 内存模糊测试（In-Memory Fuzzing ）</h3><p>在测试大型程序时，有时需要仅模糊PUT的一部分而不为每个模糊迭代重新生成进程，以便最小化执行开销。例如，复杂（例如，GUI）应用程序在接受输入之前通常需要几秒钟的处理。模糊这些程序的一种方法是在初始化GUI之后拍摄PUT的快照。为了模糊新的测试用例，可以在将新测试用例直接写入内存并执行之前恢复内存快照。同样的直觉适用于涉及客户端和服务器之间的大量交互的模糊网络应用程序。这种技术称为内存模糊[97]。例如，<code>GRR</code> [86,194]在加载任何输入字节之前创建快照。这样，它可以跳过不必要的启动代码。 AFL还使用fork服务器来避免一些流程启动成本。尽管它与内存模糊测试具有相同的动机，但是fork服务器涉及为每个模糊迭代分离一个新进程（参见§6）。</p><p>一些模糊器[7,211]对函数执行内存模糊测试，而不会在每次迭代后恢复PUT的状态。我们称这种技术为内存API模糊测试。例如，AFL有一个名为persistent mode [213]的选项，它在循环中重复执行内存API模糊测试而不重新启动进程。在这种情况下，AFL忽略了在同一执行中被多次调用的函数的潜在副作用。</p><p>虽然有效的内存API模糊测试会受到不合理的模糊测试结果的影响：内存模糊测试中发现的错误（或崩溃）可能无法重现，因为（1）为目标函数构造有效的调用上下文并不总是可行的，并且（ 2）可能存在多个函数调用未捕获的副作用。请注意，内存中API模糊的健全性主要取决于入口点函数，找到这样的函数是一项具有挑战性的任务。</p><h3 id="3-1-3线程调度（Thread-Scheduling-）"><a href="#3-1-3线程调度（Thread-Scheduling-）" class="headerlink" title="3.1.3线程调度（Thread Scheduling ）"></a>3.1.3线程调度（Thread Scheduling ）</h3><p>竞争条件错误可能难以触发，因为它们依赖于可能不经常发生的非确定性行为。但是，通过显式控制线程的调度方式，也可以使用插桩来触发不同的非确定性程序行为[43,410,121,157,169,174,175]。现有工作表明，即使是随机调度线程也可以有效地找到竞争条件错误[174]。</p><h2 id="3-2-种子选择（seed-selection-problem）"><a href="#3-2-种子选择（seed-selection-problem）" class="headerlink" title="3.2 种子选择（seed selection problem）"></a>3.2 种子选择（seed selection problem）</h2><p>回忆§2，模糊器接收一组控制fuzzing algorithm行为的fuzz configurations。不幸的是，fuzz configurations的一些参数，例如基于突变的模糊器的种子，具有大的值域。例如，假设分析师模糊测试接受MP3文件作为输入的MP3播放器。有无数的有效MP3文件，这提出了一个自然的问题：我们应该使用哪些种子进行模糊测试？这个问题被称为(<strong>seed selection problem</strong> )种子选择问题[165]。</p><p>有几种方法和工具可以解决种子选择问题[70,165]。常见的方法是找到最大化覆盖度量的最小种子集，例如节点覆盖，并且该过程称为计算最小集。例如，假设当前配置集C由两个seeds s1和s2组成，它们覆盖PUT的以下地址：{s1→{10,20}，s2→{20,30}}。如果我们有第三个种子s3→{10,20,30}的执行速度与s1和s2一样快，那么人们可能会认为fuzz s3而不是s1和s2是有意义的，因为它直观地测试了更多程序逻辑以一半的执行时间成本。这种直觉得到了Miller的报告[140]的支持，该报告显示，代码覆盖率增加1％会使发现的错误百分比增加0.92％。如§7.2所述，此步骤也可以是ConfUpdate的一部分。</p><p>Fuzzers在实践中使用各种不同的覆盖度量。例如，AFL的minset基于分支覆盖，每个分支上都有一个对数计数器。该决定背后的基本原理是，只有当分支计数在数量级上不同时才允许它们被认为是不同的。 Honggfuzz [188]根据执行指令数，执行分支数和唯一基本块计算覆盖率。此度量标准允许模糊器向minset添加更长的执行时间，这有助于发现拒绝服务漏洞或性能问题。</p><h2 id="3-3-种子修剪（Seed-Trimming-）"><a href="#3-3-种子修剪（Seed-Trimming-）" class="headerlink" title="3.3 种子修剪（Seed Trimming ）"></a>3.3 种子修剪（Seed Trimming ）</h2><p>较小的种子可能消耗较少的内存并且意味着更高的吞吐量。因此，一些模糊器试图在模糊种子之前减小种子的尺寸，这称为种子修剪。种子修剪可以在Preprocess中的主模糊循环之前或作为ConfUpdate的一部分进行。使用种子修剪的一个值得注意的模糊器是AFL [211]，只要修改后的种子达到相同的覆盖范围，它就使用其代码覆盖率插桩迭代地移除一部分种子。同时，雷伯特等人 [165]报道，他们的size minset算法，通过给予较小的种子更高优先级来选择种子，与随机种子选择相比，导致更少数量的独特错误。</p><h2 id="3-4准备驱动程序"><a href="#3-4准备驱动程序" class="headerlink" title="3.4准备驱动程序"></a>3.4准备驱动程序</h2><p>应用程序当难以直接fuzz PUT时，准备一个模糊驱动程序是有意义的。这个过程在很大程度上是手动的，尽管这只在模糊测试活动开始时才进行一次。例如，当我们的目标是库时，我们需要准备一个调用库中函数的驱动程序。类似地，内核模糊器可能会模糊用户态应用程序来测试内核[28,117,154]。 <code>MutaGen</code> [115]利用其他程序（驱动程序）中包含的PUT知识进行模糊测试。具体来说，它使用动态程序切片来改变驱动程序本身，以生成测试用例。 <code>IoTFuzzer</code> [50]通过让驱动程序成为相应的智能手机应用程序来定位物联网设备。</p><h1 id="4-调度-SEHEDULING"><a href="#4-调度-SEHEDULING" class="headerlink" title="4 调度(SEHEDULING)"></a>4 调度(SEHEDULING)</h1><p>在模糊测试中，调度意味着为下一个模糊运行选择模糊配置。正如我们在§2.1中所解释的，每个配置的内容取决于模糊器的类型。对于简单的模糊器，调度可以很简单 - 例如，<code>zzuf</code> [96]在其默认模式下只允许一个配置（PUT和其他参数的默认值），因此根本没有决定。但对于更高级的模糊器，如<code>BFF</code> [45]和<code>AFLFast</code> [33]，他们成功的一个主要因素在于他们的创新调度算法。在本节中，我们将仅讨论黑盒和灰盒模糊测试的调度算法;白盒模糊测试中的调度需要符号执行器独有的复杂设置，我们将读者引用到[34]。</p><h2 id="4-1-Fuzz配置调度（FCS）问题-The-Fuzz-Configuration-Scheduling-FCS-Problem"><a href="#4-1-Fuzz配置调度（FCS）问题-The-Fuzz-Configuration-Scheduling-FCS-Problem" class="headerlink" title="4.1  Fuzz配置调度（FCS）问题(The Fuzz Configuration Scheduling (FCS) Problem)"></a>4.1  Fuzz配置调度（FCS）问题(The Fuzz Configuration Scheduling (FCS) Problem)</h2><p>调度的目标是分析当前可用的配置信息，并选择一个更有可能产生最有利结果的信息，例如，找到最多的唯一错误，或生成的输入集所达到的最大化覆盖范围。从根本上说，每个调度算法都面临相同的探索与剥削冲突，时间可以花费在收集关于每个配置的更准确信息上，以便为将来的决策（探索）提供信息，或者模糊当前被认为可以产生更有利结果的配置。 （利用）。 Woo等人 [206]将此固有冲突称为模糊配置调度（FCS）问题。</p><p>在我们的模型模糊器（算法1）中，函数Schedule基于（i）当前的模糊配置集 C，（ii）当前时间 t_elapsed，以及（iii）总时间预算 t_limit 来选择下一个配置。然后，此配置将用于下一次模糊运行。请注意，Schedule仅与决策有关。完成此决策的信息由 Preprocess 和 ConfUpdate 通过更新C获取。</p><h2 id="4-2-黑盒FCS-算法"><a href="#4-2-黑盒FCS-算法" class="headerlink" title="4.2 黑盒FCS 算法"></a>4.2 黑盒FCS 算法</h2><p>在黑盒设置中，FCS算法可以使用的唯一信息是配置的模糊结果 - 与其一起发现的崩溃和错误的数量以及到目前为止花费的时间。 <code>Householder</code>和<code>Foote</code> [100]是第一个研究如何在CERT BFF黑盒突变模糊器中利用这些信息的人[45]。他们假定应该优先选择观察成功率较高的配置（#bugs / #runs）。事实上，在替换BFF中的统一采样调度算法后，他们观察到在运行 ffmpeg 500万次中独特崩溃次数增加了85％，证明了更先进的FCS算法的潜在优势。</p><p>不久之后，Woo等人在多个方面改进了上述想法 [206]。首先，他们从[100]中的伯努利试验序列到<code>Weighted CouponCollector’s Problem with Unknown Weights</code>（WCCP / UW），改进了黑盒突变模糊测试的数学模型。前者假设每个配置具有固定的最终成功概率并且随着时间的推移而学习它，后者在衰减时明确地保持该概率的上限。其次，WCCP / UW模型自然会引领Woo等人去研究<code>multi-armed bandit</code>（MAB）问题的算法，这是一种流行的形式以应对决策科学中的探索与剥削冲突[31]。为此，他们能够设计MAB算法以准确地利用尚未发生衰减的配置。第三，他们观察到，在其他条件相同的情况下，让fuzzing更快的配置允许模糊器收集更多的独特错误，或者更快地降低其未来成功概率的上限。这激发了他们将配置的成功概率标准化为花费在其上的时间，从而使得更快的配置更加可取。第四，他们将BFF中模糊运行的编排从每个配置选择的固定运行次数（BFF用语中的“epochs”）改为每次选择的固定时间量。通过此更改，BFF不再需要在可重新选择之前花费更多时间在慢速配置中。通过组合上述内容，评估[206]显示使用与现有BFF相同的时间量发现的独特错误数量增加1.5倍。</p><h2 id="4-3-灰盒FCS算法"><a href="#4-3-灰盒FCS算法" class="headerlink" title="4.3 灰盒FCS算法"></a>4.3 灰盒FCS算法</h2><p>在灰盒设置中，FCS算法可以选择使用关于每种配置的更丰富的信息集，例如，在模糊配置时获得的覆盖范围。 AFL [211]是此类别的先行者，它基于进化算法（EA）。直观地，EA维持一组配置，每个配置具有一些“适应性”值。 EA选择合适的配置并将其应用于遗传转化，例如突变和重组，以产生后代，后代可能成为新的配置。假设是这些产生的配置更可能适合。</p><p>要在EA的上下文中理解FCS，我们需要定义<strong>（i）使配置适合的内容是什么，（ii）如何选择配置，以及（iii）如何使用所选配置</strong>。作为高级近似法，在执行控制流边缘的配置中，AFL认为包含最快和最小输入的那个适合（AFL用语中的“favorite”）。 AFL维护一个配置队列，从中选择下一个匹配配置，就好像队列是循环的一样。一旦选择了配置，AFL就会使其基本上以恒定的运行次数进行模糊处理。从FCS的角度来看，请注意快速配置的首选项与黑盒设置的[206]相同。</p><p>最近，Böhme等人的AFLFast [33]在上述三个方面的每个方面都改进了AFL。首先，AFLFast为输入添加了两个最重要的标准，使其成为“favorite”：（i）在执行控制流边缘的配置中，AFLFast倾向于选择最少的输入。这具有在执行该边缘的配置之间循环的效果，从而增加了探索。 （ii）当（i）中存在平局时，AFLFast倾向于选择其中执行最少路径的那个。这具有增加稀有路径的执行效果，这可能揭示更多未观察到的行为。其次，AFLFast放弃了AFL中的循环选择，而是根据优先级选择下一个拟合配置。特别是，如果选择配置的频率较低，或者在平局时，如果它运行的路径较少，则适配配置的优先级高于另一配置。与第一次改变的想法相同，这具有增加适合配置和稀有路径执行的探索的效果。第三，AFLFast根据能量计划确定所选配置的次数变量。 AFLFast中的FAST能量计划以较小的“能量”值开始，以确保配置之间的初始探索，并以指数方式增加到极限，以快速确保充分利用。此外，它还通过生成相同路径的生成输入的数量来标准化能量，从而促进对频率较低的模糊配置的探索。这些变化的总体影响非常显着 - 在24小时的评估中，Böhme等人观察到AFLFast发现了AFL没有发现的3个错误，并且在两者都发现的6个错误上比AFL快7倍。 AFLGo [32]通过修改其优先级来扩展AFLFast，以便针对特定的程序位置。 QTEP [200]使用静态分析来推断二进制文件的哪个部分更“错误”并优先考虑覆盖它们的配置。</p><h1 id="5-输入生成-INPUT-GENERATION"><a href="#5-输入生成-INPUT-GENERATION" class="headerlink" title="5.输入生成(INPUT GENERATION)"></a>5.输入生成(INPUT GENERATION)</h1><p>由于测试用例的内容直接控制是否触发bug，因此输入生成技术自然是模糊测试中最有影响力的设计决策之一。传统上，模糊器分为基于生成或基于突变的模糊器[187]。基于生成的模糊器基于给定模型生成测试用例，该模型描述了PUT期望的输入。我们在本文中称这种模糊器为基于模型的模糊器。另一方面，基于突变的模糊器通过改变给定的种子输入来产生测试案例。基于突变的模糊器通常被认为是无模型的，因为种子仅仅是示例输入，并且即使在大量数量下它们也不能完全描述PUT的预期输入空间。在本节中，我们将基于底层测试用例生成（InputGen）机制对模糊器使用的各种输入生成技术进行解释和分类。</p><h2 id="5-1基于模型（基于生成）的模糊器"><a href="#5-1基于模型（基于生成）的模糊器" class="headerlink" title="5.1基于模型（基于生成）的模糊器"></a>5.1基于模型（基于生成）的模糊器</h2><p>基于模型的模糊器基于给定模型生成测试用例，该模型描述了PUT可以接受的输入或执行，例如精确表征输入格式的语法或不太精确的约束,例如标识文件类型的magic值。</p><h3 id="5-1-1预定义模型"><a href="#5-1-1预定义模型" class="headerlink" title="5.1.1预定义模型"></a>5.1.1预定义模型</h3><p>一些模糊器使用可由用户配置的模型。例如，Peach [70]，PROTOS [112]和Dharma [3]接受用户提供的规范。 Autodafé [197]，Sulley [15]，SPIKE [13]和SPIKEfile [186]公开了API，允许分析师创建自己的输入模型。 Tavor [219]还接受以Extended Backus-Naur形式（EBNF）编写的输入规范，并生成符合相应语法的测试用例。类似地，诸如PROTOS [112]，SNOOZE [26]，KiF [12]和T-Fuzz [107]之类的网络协议模糊器也接受来自用户的协议规范。内核API模糊器[108,146,151,198,203]以系统调用模板的形式定义输入模型。这些模板通常指定系统调用期望作为输入的参数的数量和类型。在内核模糊测试中使用模型的想法源于Koopman等人 [119]开创性的工作，他们将操作系统的稳健性与一系列有限的手动选择的系统调用测试用例进行了比较。</p><p>其他基于模型的模糊器针对特定的语言或语法，并且该语言的模型内置于模糊器本身。例如，<code>cross_fuzz</code> [212]和<code>DOMfuzz</code> [143]生成随机文档对象模型（DOM）对象。同样，<code>jsfunfuzz</code> [143]基于其自己的语法模型生成随机但语法正确的JavaScript代码。 <code>QuickFuzz</code> [88]利用现有的Haskell库来描述生成测试用例时的文件格式。一些网络协议模糊器如<code>Frankencerts</code> [37]，TLS-Attacker [180]<code>，</code>tlsfuzzer <code>[116]</code>和<code>llfuzzer</code>[182]设计有特定网络协议模型，如TLS和NFC。 Dewey等人[63,64]提出了一种生成测试用例的方法，这些测试用例不仅语法正确，而且通过利用约束逻辑编程也具有语义多样性。<code>LangFuzz</code> [98]通过解析作为输入给出的一组种子来产生代码片段。然后它随机组合片段，并将种子与片段一起变异以生成测试用例。由于它提供了语法，因此它始终生成语法正确的代码。 LangFuzz应用于JavaScript和PHP。 BlendFuzz [210]基于与LangFuzz类似的想法，但它以XML和正则表达式解析器为目标。</p><h3 id="5-1-2-推断模型"><a href="#5-1-2-推断模型" class="headerlink" title="5.1.2 推断模型"></a>5.1.2 推断模型</h3><p>推断模型而不是依赖于预定义的逻辑或用户提供的模型获得牵引力。虽然有大量关于自动输入格式和协议逆向工程主题的已发表研究[25,41,57,60,128]，但只有少数模糊测试者利用这些技术。模型推断可以分两个阶段完成：<code>Preprocess</code>或<code>ConfUpdate</code>。<br>Preprocess中的模型推理。一些模糊推测器将模型推断为模糊运动之前的第一步。 TestMiner [61]使用代码中可用的数据来挖掘和预测合适的输入。 Skyfire [199]使用数据驱动方法从给定语法和一组输入样本生成一组种子。与以前的作品不同，他们的重点是生成一组语义上有效的新种子。 IMF [93]通过分析系统API日志来学习内核API模型，并生成使用推断模型调用一系列API调用的C代码。 Neural [56]和Learn＆Fuzz [85]使用基于神经网络的机器学习技术从给定的一组测试文件中学习模型，并使用推断的模型生成测试用例。Liu等人[129]提出了一种特定于文本输入的类似方法。</p><p>ConfUpdate中的模型推断。在每个模糊迭代中都有模糊器更新模型。 PULSAR [79]从捕获到的程序生成的一组的网络数据包中自动的推断出网络协议模型。然后，学习的网络协议用于模糊程序。 PULSAR在内部构建状态机，并映射哪个消息令牌与状态相关。此信息稍后用于生成覆盖状态机中更多状态的测试用例。 Doupé等人 [67]提出了一种通过观察I / O行为来推断Web服务的状态机的方法。然后使用推断的模型来扫描Web漏洞。Ruiter等人 [168]工作类似，但目标是TLS，并将其实施基于<code>LearnLib</code> [162]。最后，<code>GLADE</code> [27]从一组I / O样本中合成了一个无上下文语法，并使用推断的语法来模糊PUT。</p><h2 id="5-2-无模型（基于突变）的模糊器"><a href="#5-2-无模型（基于突变）的模糊器" class="headerlink" title="5.2 无模型（基于突变）的模糊器"></a>5.2 无模型（基于突变）的模糊器</h2><p>经典随机测试[19,92]在生成满足特定路径条件的测试用例时效率不高。假设有一个简单的C语句：if（input == 42）。如果输入是32位整数，则随机猜测正确输入值的概率是2的32次方之一。当我们考虑结构良好的输入（如MP3文件）时，情况会变得更糟。随机测试极不可能在合理的时间内生成有效的MP3文件作为测试用例。因此，MP3播放器将主要在到达程序的更深层部分之前的解析阶段拒绝从随机测试中生成的测试用例。</p><p>这个问题促使使用基于种子的输入生成以及白盒输入生成（见§5.3）。大多数无模型模糊器使用种子，它是PUT的输入，以便通过改变种子来生成测试用例。<br>种子通常是PUT支持的类型的结构良好的输入：文件，网络包或一系列UI事件。通过仅改变有效文件的一小部分，通常可以生成大多数有效的新测试用例，但也包含异常值以触发PUT的崩溃。有多种方法可用于改变种子，我们将在下面描述常见的方法。</p><h3 id="5-2-1-比特翻转"><a href="#5-2-1-比特翻转" class="headerlink" title="5.2.1 比特翻转"></a>5.2.1 比特翻转</h3><p>比特翻转是许多无模型模糊器使用的常用技术[6,95,96,188,211]。一些模糊器简单地翻转固定数量的比特，而其他模糊器确定随机翻转的比特数。为了随机改变种子，一些模糊器使用一个称为突变比的用户可配置参数，该参数确定单次执行InputGen时要翻转的位位置数。假设一个模糊器想要从给定的N位种子中翻转K个随机位。在这种情况下，模糊器的突变比是K / N.<br><code>SymFuzz</code>等 [48]表明模糊性能对突变率非常敏感，并且没有一个比率适用于所有PUT。有几种方法可以找到良好的突变率。 BFF [45]和FOE [46]使用每个种子的指数缩放比例集，并将更多迭代分配给证明在统计学上有效的突变比[100]。 SymFuzz [48]利用白盒程序分析来推断出良好的突变率。然而，请注意，所提出的技术仅考虑推断单个最佳突变比率。使用多个突变比率进行模糊测试比使用单个最佳比率进行模糊测试更有可能，这仍然是一个开放的研究挑战。</p><h3 id="5-2-2-算术变异"><a href="#5-2-2-算术变异" class="headerlink" title="5.2.2 算术变异"></a>5.2.2 算术变异</h3><p>AFL [211]和honggfuzz [188]包含另一个变异操作，它将所选字节序列视为整数，并对该值执行简单算术。然后使用计算的值替换所选的字节序列。关键的直觉是通过少量的数值来限制突变的影响。例如，AFL从种子中选择一个4字节的值，并将该值视为整数 i。然后用 i ± r 替换种子中的值，其中r是随机生成的小整数。 r的范围取决于模糊器，通常是用户可配置的。在AFL中，默认范围是：0≤r&lt;35。</p><h3 id="5-2-3-基于块的变"><a href="#5-2-3-基于块的变" class="headerlink" title="5.2.3 基于块的变"></a>5.2.3 基于块的变</h3><p>有几种基于块的变异方法，其中块是种子的字节序列：（1）将随机生成的块插入种子的随机位置[7,211]; （2）从种子中删除随机选择的块[7,95,188,211]; （3）用随机值替换随机选择的块[7,95,188,211]; （4）随机置换一系列块的顺序[7,95]; （5）通过附加随机区块来调整种子的大小[188]; （6）从种子中取一个随机块来插入/替换另一个种子的随机块[7,211]。</p><h3 id="5-2-4-基于字典的变异"><a href="#5-2-4-基于字典的变异" class="headerlink" title="5.2.4 基于字典的变异"></a>5.2.4 基于字典的变异</h3><p>一些模糊器使用具有潜在显着语义权重的一组预定义值，例如0或-1，以及用于变异的格式字符串。例如，AFL [211]，honggfuzz [188]和LibFuzzer [7]在变换整数时使用诸如0，-1和1的值。 Radamsa [95]使用Unicode字符串，GPF [6]使用格式字符（如％x和％s）来改变字符串。</p><h2 id="5-3-白盒模糊器"><a href="#5-3-白盒模糊器" class="headerlink" title="5.3 白盒模糊器"></a>5.3 白盒模糊器</h2><p>白盒模糊器也可以分为基于模型或无模型的模糊器。例如，传统的动态符号执行[24,84,105,134,184]在基于变异的模糊器中不需要任何模型，但一些符号执行器[82,117,160]利用输入模型，如输入语法指导符号执行。</p><p>虽然许多白盒模糊器包括Godefroid等人[84]的开创性工作使用动态符号执行来生成测试用例，但并非所有的白盒模糊器都是动态符号执行器。一些模糊器[48,132,170,201]利用白盒程序分析来查找有关PUT接受的输入的信息，以便将其与黑盒或灰盒模糊测试一起使用。在本小节的其余部分中，我们将基于其基础测试用例算法简要总结现有的白盒模糊测试技术。请注意，我们故意省略动态符号执行器，如[42,47,54,83,176,192]，除非他们明确称自己为§2.2中提到的模糊器。</p><h3 id="5-3-1-动态符号执行"><a href="#5-3-1-动态符号执行" class="headerlink" title="5.3.1 动态符号执行"></a>5.3.1 动态符号执行</h3><p>在高级别，经典的符号执行[35,101,118]运行一个带有符号值作为程序的输入，它代表所有可能的值。在执行PUT时，它会构建符号表达式，而不是评估具体值。每当它到达条件分支指令时，它在概念上分叉两个符号解释器，一个用于真正的分支，另一个用于假分支。对于每个路径，符号解释器为执行期间遇到的每个分支指令构建路径公式（或路径谓词）。如果存在执行所需路径的具体输入，则路径公式是可满足的。可以通过查询SMT求解器[142]来生成具体输入，以获得路径公式的解。动态符号执行是传统符号执行的变体，其中符号执行和具体执行同时运行。这个想法是具体的执行状态可以帮助减少符号约束的复杂性。除了应用于模糊测试之外，对动态符号执行的学术文献的广泛回顾超出了本文的范围。然而，动态符号执行的更广泛处理可以在[16,173]中找到。</p><h3 id="5-3-2-引导式模糊测试"><a href="#5-3-2-引导式模糊测试" class="headerlink" title="5.3.2 引导式模糊测试"></a>5.3.2 引导式模糊测试</h3><p>一些模糊器利用静态或动态程序分析技术来增强模糊测试的有效性。这些技术通常涉及两个阶段的模糊测试：（i）用于获得关于PUT的有用信息的昂贵程序分析，以及（ii）在先前分析的指导下生成测试用例。这在表1的第六列（第9页）中表示。例如，TaintScope [201]使用细粒度污点分析来查找“热字节”，这是流入关键系统调用或API调用的输入字节。其他安全研究人员提出了类似的想法[69,103]。 Dowser [91]在编译期间执行静态分析，以找到可能包含基于启发式的错误的循环。具体来说，它查找包含指针解引用的循环。然后，它使用污点分析计算输入字节和候选循环之间的关系。最后，Dowser运行动态符号执行，同时只使关键字节成为符号，从而提高性能。VUzzer [164]和GRT [132]利用静态和动态分析技术从PUT中提取控制和数据流特征，并使用它们来指导输入生成。 Angora [50]通过使用污点分析将每个路径约束与相应的字节相关联来改进“热字节”的想法。然后，它通过梯度下降算法进行搜索，以指导其突变以解决这些约束。</p><h3 id="5-3-3-PUT-突变"><a href="#5-3-3-PUT-突变" class="headerlink" title="5.3.3 PUT 突变"></a>5.3.3 PUT 突变</h3><p>模糊测试的一个实际挑战是绕过校验和验证。例如，当PUT在解析输入之前计算输入的校验和时，来自模糊器的大多数生成的测试用例将被PUT拒绝。为了应对这一挑战，TaintScope [201]提出了一种校验和感知模糊测试技术，该技术通过污点分析识别校验和测试指令，并修补PUT以绕过校验和验证。一旦发现程序崩溃，它们就会为输入生成正确的校验和，以生成一个崩溃未修改的PUT的测试用例。 Caballero [40]提出了一种称为拼接动态符号执行的技术，它可以在校验和存在的情况下生成测试用例。</p><p>T-Fuzz [158]扩展了这个想法，通过灰盒模糊来有效地穿透所有类型的条件分支。它首先构建一组非关键检查（NCC），这些检查是可以在不修改程序逻辑的情况下进行转换的分支。当模糊测试活动停止发现新路径时，它会选择NCC，对其进行转换，然后在修改后的PUT上重新启动模糊测试活动。最后，当发现崩溃模糊转换程序时，T-Fuzz尝试使用符号执行在原始程序上重建它。</p><h1 id="6-输入评估"><a href="#6-输入评估" class="headerlink" title="6. 输入评估"></a>6. 输入评估</h1><p>生成输入后，模糊器执行输入，并决定如何处理该输入。由于模糊测试的主要动机是发现违反安全策略的行为，因此模糊测试程序必须能够检测到执行违反安全策略的行为。该策略的实现称为bug oracle，O_bug（参见§2.1）。 oracle标记的输入通常在被分类后写入磁盘。如算法1所示，为模糊器生成的每个输入调用oracle。因此，oracle能够有效地确定输入是否违反安全策略是至关重要的。</p><p>回想一下§3，一些模糊器还在执行每个输入时收集附加信息，以改善模糊测试过程。 Preprocess和InputEval在许多模糊器中彼此紧密耦合，因为检测到的PUT（来自Preprocess）将在执行时输出附加信息（来自InputEval）。</p><h2 id="6-1执行优化"><a href="#6-1执行优化" class="headerlink" title="6.1执行优化"></a>6.1执行优化</h2><p>我们的模型考虑按顺序执行单个模糊迭代。虽然这种方法的直接实现只是在每次模糊迭代开始时开始新过程时加载PUT，但是可以显着加速重复加载过程。为此，现代模糊器提供了跳过这些重复加载过程的功能。例如，AFL [211]提供了一个fork-server，它允许每个新的模糊迭代从已经初始化的进程中fork。类似地，内存中模糊测试是优化执行速度的另一种方法，如第3.1.2节中所述。无论确切的机制如何，加载和初始化PUT的开销都会在很多次迭代中摊销。Xu等人 [209]通过设计一个替换fork（）的新系统调用，进一步降低了迭代的成本。</p><h2 id="6-2-Bug-Oracles"><a href="#6-2-Bug-Oracles" class="headerlink" title="6.2  Bug Oracles"></a>6.2  Bug Oracles</h2><p>与模糊测试一起使用的规范安全策略认为每个程序执行都会被致命信号（例如分段错误）终止。此策略检测到许多内存漏洞，因为使用无效值覆盖数据或代码指针的内存漏洞通常会导致分段错误或在取消引用时中止。此外，该策略高效且易于实现，因为操作系统允许模糊器在没有任何仪器的情况下捕获这种异常情况。</p><p>但是，传统的检测崩溃的策略不会检测到触发的每个内存漏洞。例如，如果堆栈缓冲区溢出使用有效的内存地址覆盖堆栈上的指针，则程序可能会运行完成且结果无效而不是崩溃，并且模糊器不会检测到此情况。为了缓解这种情况，研究人员提出了各种有效的程序转换，可以检测不安全或不需要的程序行为并中止程序。这些通常被称为<code>sanitizers</code>。</p><p><strong>内存和类型安全</strong>。内存安全错误可以分为两类：空间和时间。非正式地，当指针被访问到其预期范围之外时，会发生空间存储器错误。例如，缓冲区溢出和下溢是空间内存错误的典型示例。在指针不在有效后访问时会发生时间内存错误。例如，use-after-free 漏洞，当一片内存的指针被释放之后又被使用，这是典型的时间内存错误。</p><p><code>Address Sanitizer（ASan）</code>[177]是一个快速存储器错误检测器，可在编译时检测程序。 ASan可以检测空间和时间内存错误，平均减速仅为73％，使其成为基本碰撞安全带的有吸引力的替代品。 ASan采用了一个影子存储器，允许每个存储器地址在被解除引用之前被快速检查其有效性，从而允许它检测许多（但不是全部）不安全的存储器访问，即使它们不会使原始程序崩溃。 MEDS [94]通过利用64位虚拟空间提供的近乎无限的内存空间并创建<code>redzones</code>来改进ASAN。</p><p><code>SoftBound / CETS</code>[148,149]是另一种在编译过程中监控程序的内存错误检测器。然而，SoftBound / CETS不是像ASan那样跟踪有效的内存地址，而是将边界和时间信息与每个指针相关联，理论上可以检测所有空间和时间内存错误。然而，正如预期的那样，这种完整性带来了更高的平均开销116％[149]。</p><p><code>CaVer</code>[123]，<code>TypeSan</code>[90]和<code>HexType</code>[106]在编译期间插桩程序，以便它们可以检测C ++类型转换中的错误转换。当对象转换为不兼容的类型时，例如当基类的对象强制转换为派生类型时，会发生错误的转换。事实证明，CaVer可以扩展到Web浏览器，这些浏览器历来包含这种类型的漏洞，并且开销在7.6到64.6％之间。</p><p>另一类存储器安全保护是控制流完整性[10,11]（CFI），它在运行时检测原始程序中不可能的控制流转换。 CFI可用于检测非法修改程序控制流的测试用例。最近一个专注于防范CFI违规子集的项目已经进入主流gcc和clang编译器[191]。</p><p><strong>未定义的行为</strong>。诸如C之类的语言包含许多由语言规范未定义的行为。编译器可以以各种方式自由处理这些构造。在许多情况下，程序员可以（有意或无意地）编写他们的代码，这样它只对某些编译器实现是正确的。虽然这看起来似乎不太危险，但许多因素都会影响编译器如何实现未定义的行为，包括优化设置，体系结构，编译器甚至编译器版本。当编译器的未定义行为的实现与程序员的期望不匹配时，通常会出现漏洞和错误[202]。</p><p><code>Memory Sanitizer（MSan）</code>是一种工具，可以在编译期间检测程序，以检测由于在C和C ++中使用未初始化的内存而导致的未定义行为[183]。与ASan类似，MSan使用一个影子内存来表示每个可寻址位是否已初始化。 Memory Sanitizer的开销约为150％。</p><p><code>Undefied Behavior Sanitizer（UBSan）</code>[65]在编译时修改程序以检测未定义的行为。与其他专注于未定义行为的特定来源的检测工具不同，UBSan可以检测各种未定义的行为，例如使用未对齐的指针，除以零，解除引用空指针和整数溢出。</p><p><code>Thread Sanitizer（TSan）</code>[178]是一种编译时修改，它通过精度和性能之间的权衡来检测数据竞争。当两个线程同时访问共享内存位置并且至少一个访问是写入时，发生数据争用。这样的错误可能导致数据损坏，并且由于非确定性而极难重现。</p><p><strong>输入验证</strong>。测试输入验证漏洞（如XSS（跨站点脚本）和SQL注入漏洞）是一个具有挑战性的问题，因为它需要了解为Web浏览器和数据库引擎提供支持的非常复杂的解析器的行为。<code>KameleonFuzz</code> [68]通过使用真实Web浏览器解析测试用例，提取文档对象模型树，并将其与人工提取的XSS工具模式进行比较来检测成功的XSS攻击。 <code>μ4SQLi</code>[17]使用类似的技巧来检测SQL注入。由于无法从Web应用程序响应中可靠地检测SQL注入，因此μ4SQLi使用数据库代理拦截目标Web应用程序与数据库之间的通信，以检测输入是否触发了有害行为。</p><p><strong>语义差异</strong>。通常通过比较类似（但不同）的程序来发现语义错误。它通常被称为差分测试[135]，并被几个模糊器[37,53,159]使用。在这种情况下，bug oracle是作为一组类似的程序给出的。Jung等人 [111]引入了术语黑盒差分模糊测试，它测量了给定两个或更多不同输入的PUT输出之间的差异。根据输出之间的差异，它们检测PUT的信息泄漏。</p><h2 id="6-3-分类"><a href="#6-3-分类" class="headerlink" title="6.3 分类"></a>6.3 分类</h2><p>分类是分析和报告导致违反策略的测试用例的过程。分类可以分为三个步骤：重复数据删除，优先级排序和测试用例最小化。</p><h3 id="6-3-1-重复数据删除"><a href="#6-3-1-重复数据删除" class="headerlink" title="6.3.1 重复数据删除"></a>6.3.1 重复数据删除</h3><p>重复数据删除是从输出集中修剪与其它测试样例触发相同的错误的测试样例的过程，理想情况下，重复数据删除会返回一组测试用例，其中每个测试用例都会触发一个独特的错误。</p><p>由于多种原因，重复数据删除是大多数模糊器的重要组成部分。作为一种实际的实现方式，它通过在删除硬盘上存储重复的结果来避免浪费磁盘空间和其他资源。作为可用性考虑因素，重复数据删除使用户可以轻松了解存在多少不同的错误，并能够分析每个错误的示例。这对各种模糊用户都很有用；例如，攻击者可能只想查看可能导致可靠利用的“home run”漏洞。</p><p>目前在实践中使用了两种主要的重复数据删除实现：<code>堆栈回溯哈希</code>和<code>基于覆盖的重复数据删除</code>。</p><p><strong>堆栈回溯哈希</strong>(Stack Backtrace Hashing )。堆栈回溯哈希[141]是用于重复数据删除崩溃的最古老和最广泛使用的方法之一，其中自动化工具在崩溃时记录堆栈回溯，并根据该回溯的内容分配堆栈散列。例如，如果程序在函数foo中执行一行代码时崩溃，并且调用堆栈为main→d→c→b→a→foo，那么n = 5的堆栈回溯散列实现会将所有执行组合在一起回溯以d→c→b→a→foo结束。</p><p>堆栈哈希实现差别很大，从哈希中包含的堆栈帧数开始。一些实现使用一个[18]，三个[141,206]，五个[45,76]，或者没有任何限制[115]。实现方式也包括每个堆栈帧中包含的信息量。某些实现只会哈希函数的名称或地址，但其他实现将哈希名称和偏移量或行。这两个选项都不能很好地工作，因此一些实现[76,137]产生两个哈希：主要和次要哈希。主要哈希很可能将不同的崩溃组合在一起，因为它只散列函数名称，而次要散列更精确，因为它使用函数名称和行号，并且还包括无限数量的堆栈帧。</p><p>虽然堆栈回溯哈希被广泛使用，但它并非没有缺点。堆栈回溯哈希的基本假设是类似的崩溃是由类似的错误引起的，反之亦然，但据我们所知，这个假设从未被直接测试过。有一些理由怀疑它的真实性：在导致崩溃的代码附近不会发生一些崩溃。例如，导致堆损坏的漏洞可能仅在代码的不相关部分尝试分配内存时崩溃，而不是在发生堆溢出时崩溃。</p><p><strong>基于覆盖的重复数据删除</strong>（Coverage-based Deduplication ）。 AFL [211]是一种流行的灰盒模糊器，它采用高效的源代码检测器来记录PUT每次执行的边缘覆盖范围，并测量每个边缘的粗略命中计数。作为灰盒模糊器，AFL主要使用此覆盖信息来选择新的种子文件。但是，它也会导致相当独特的重复数据删除方案。正如其文档中所描述的那样，如果（i）碰撞覆盖了以前看不见的边缘，或者（ii）碰撞未覆盖所有早期碰撞中存在的边缘，AFL认为碰撞是唯一的。</p><p><strong>语义感知的重复数据删除</strong>。Cui等人[59]提出了一个名为RETracer的系统，根据从反向数据流分析中恢复的语义对崩溃进行分类。具体来说，在崩溃之后，RETracer会检查哪个指针导致崩溃，并以递归方式识别哪个指令为其分配了错误值。它最终找到一个具有最大帧级别的函数，并“blames”该函数。blames功能可用于群集崩溃。作者表明，他们的技术成功地将数百万个Internet Explorer bugs合并为一个，这些漏洞通过堆栈散列分散到大量不同的组中。</p><h3 id="6-3-2-优先级和可利用性"><a href="#6-3-2-优先级和可利用性" class="headerlink" title="6.3.2 优先级和可利用性"></a>6.3.2 优先级和可利用性</h3><p>优先级，a.k.a.fuzzer taming问题[52]，是根据严重性和唯一性对违反测试用例进行排名或分组的过程。传统上使用模糊测试来发现内存漏洞，在这种情况下，优先级更好地称为确定崩溃的可利用性。可利用性非正式地描述了攻击者能够为测试用例暴露的漏洞编写实际漏洞的可能性。防御者和攻击者都对可利用的漏洞感兴趣。防御者通常会在不可利用的漏洞之前修复可利用的漏洞，并且出于显而易见的原因，攻击者对可利用的漏洞感兴趣。</p><p>第一个可利用性排名系统之一是Microsoft的 <code></code>!exploitable` [137]，它的名字来自它提供的 !exploitable 的WinDbg命令名称。 ！exploitable采用了几种启发式方法，并配有简化的污点分析[153,173]。它按以下严重性等级对每次崩溃进行分类：EXPLOITABLE&gt; PROBABLY_EXPLOITABLE&gt; UNKNOWN&gt; NOT_LIKELY_EXPLOITABLE，其中x&gt; y表示x比y严重。虽然这些分类没有正式定义，但是可利用的非正式意图是保守和错误报告的东西比它更具可利用性。例如，！exploitable断定，如果执行非法指令，则崩溃是可利用的，这是基于攻击者能够劫持控制流的假设。另一方面，除零崩溃被视为NOT_LIKELY_EXPLOITABLE。</p><p>自从！exploitable被引入以来，已经提出了其他类似的基于规则的启发式系统，包括GDB [76]和Apple的<code></code>CrashWrangler `[18]的可利用插件。然而，它们的正确性尚未得到系统的研究和评估。</p><h3 id="6-3-3测试用例最小化"><a href="#6-3-3测试用例最小化" class="headerlink" title="6.3.3测试用例最小化"></a>6.3.3测试用例最小化</h3><p>分类的另一个重要部分是测试用例最小化。测试用例最小化是识别触发违规所必需的违规测试用例部分的过程，并且可选地产生比原始测试用例更小且更简单但仍然导致违规的测试用例。</p><p>一些模糊器使用自己的实现和算法。 BFF [45]包括针对模糊测试[99]的最小化算法，其尝试最小化与原始种子文件不同的比特数。AFL [211]还包括一个测试用例最小化器，它试图通过机会性地将字节设置为零并缩短测试用例的长度来简化测试用例。<code>Lithium</code>[167]是一种通用测试用例最小化工具，它通过尝试以指数递减的大小删除相邻行或字节的“块”来最小化文件。Lithium是由JavaScript模糊器（如jsfunfuzz [143]）生成的复杂测试案例推动的。</p><p>还有各种测试用例减少器，它们不是专门用于模糊测试，但仍可用于模糊测试识别的测试用例。这些包括格式不可知技术，如<code>delta调试</code>[216]，以及特定格式的专用技术，如<code>C-Reduce</code> [166]用于C / C ++文件。尽管专业技术明显受限于它们可以减少的文件类型，但它们的优势在于它们可以比通用技术更有效，因为它们了解它们试图简化的语法。</p><h1 id="7-配置更新-CONFIGURATION-UPDATING"><a href="#7-配置更新-CONFIGURATION-UPDATING" class="headerlink" title="7.配置更新(CONFIGURATION UPDATING )"></a>7.配置更新(CONFIGURATION UPDATING )</h1><p>ConfUpdate函数在区分黑盒模糊器与灰盒和白盒模糊器的行为方面起着关键作用。如算法1中所讨论的，ConfUpdate函数可以基于在当前模糊测试运行期间收集的配置和执行信息来修改配置集（C）。在最简单的形式中，ConfUpdate返回未修改的C参数。除了评估bug oracle O_bug之外，黑盒模糊器不执行任何程序自我测试，因此它们通常不会修改C，因为它们没有收集任何允许它们修改它的信息。</p><p>但是，灰色和白盒模糊器的主要区别在于它们更复杂的ConfUpdate函数实现，它允许它们包含新的模糊配置，或者删除可能已被取代的旧模糊配置。 ConfUpdate允许在一次迭代期间传输收集的信息，以便在将来的循环迭代期间使用。例如，白盒模糊器中的路径选择启发式通常会为每个生成的新测试用例创建一个新的模糊配置。</p><h2 id="7-1进化种子库更新"><a href="#7-1进化种子库更新" class="headerlink" title="7.1进化种子库更新"></a>7.1进化种子库更新</h2><p>进化算法（EA）是一种基于启发式的方法，涉及生物进化机制，如突变，重组和选择。尽管EA看似非常简单，但它构成了许多灰盒模糊器的基础[7,198,211]。他们维持一个种子库，这是在模糊测试期间EA演变的人口。选择要变异的种子和突变本身的过程分别在§4.3和§5中详述。</p><p>可以说，EA最重要的一步是将新配置添加到配置集C中，这对应于模糊测试的ConfUpdate步骤。大多数模糊器通常使用节点或分支覆盖作为适应度函数：如果测试用例发现新节点或分支，则将其添加到种子池中。 AFL [211]进一步考虑了分支机构被采取的次数。Angora[158]通过考虑每个分支的调用上下文来改进AFL的适应性标准。 Steelix [126]检查哪个输入偏移影响PUT的比较指令的过程以及进化种子池的代码覆盖率。</p><p>VUzzer [164]仅在发现新的非错误处理基本块时才向C添加配置。他们的见解是将时间投入到程序分析中，以获得特定应用知识，从而提高EA效率。具体地，VUzzer为每个基本块定义权重，并且配置的适合度是每个运动的基本块上的频率的对数的加权和。 VUzzer具有内置的程序分析功能，可将基本块分类为普通和错误处理（EH）块。根据经验，他们的假设是，遍历EH块表示漏洞的可能性较低，因为可能由于未处理的错误而发生错误。对于正常块，其权重与包含该块的CFG上的随机游走根据VUzzer定义的转移概率访问它的概率成反比。对于EH块，其权重为负，并且是基本块的数量与此配置所执行的EH块的数量之间的缩放比率。实际上，这使得VUzzer更喜欢采用上述随机游走所认为罕见的正常块的配置。</p><h2 id="7-2-维护Minset"><a href="#7-2-维护Minset" class="headerlink" title="7.2 维护Minset"></a>7.2 维护Minset</h2><p>由于能够创建新的模糊测试配置，因此还存在创建过多配置的风险。用于降低此风险的常见策略是维护最小化或最小化测试用例集，以最大化覆盖度量。在预处理期间也使用Minsetting，并在§3.2中有更详细的描述。</p><p>一些模糊器使用维护专用于配置更新的minset的变体。作为一个例子，AFL [211]使用剔除程序将minset配置标记为有利，而不是完全删除不在minset中的配置（这是Cyberdyne [86]所做的）。通过调度函数，有利的模糊测试配置被选择用于模糊测试的可能性显着提高。 AFL的作者指出“这在队列循环速度和测试用例多样性之间提供了合理的平衡”[215]。</p><h1 id="8-结束语"><a href="#8-结束语" class="headerlink" title="8. 结束语"></a>8. 结束语</h1><p>正如我们在§1中所阐述的那样，本文的第一个目标是提炼出对现代fuzzing文献的全面而连贯的观点。为此，我们首先提出了一个通用模型模糊器以方便我们解释当前使用中的多种形式的模糊测试。然后，我们使用图1（第7页）和表1（第9页）说明了对模糊器的丰富分类。我们通过讨论设计决策以及展示整个社区的众多成就，探索了模型模糊器的每个阶段。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h1&gt;&lt;p&gt;在当今可用的众多软件漏洞发现技术中，模糊测试由于其概念简单，部署的低屏障以及发现现实世界软件
      
    
    </summary>
    
      <category term="论文" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/"/>
    
      <category term="fuzzing" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/fuzzing/"/>
    
      <category term="综述" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/fuzzing/%E7%BB%BC%E8%BF%B0/"/>
    
    
      <category term="综述" scheme="http://yama0xff.com/tags/%E7%BB%BC%E8%BF%B0/"/>
    
      <category term="Fuzzing" scheme="http://yama0xff.com/tags/Fuzzing/"/>
    
  </entry>
  
  <entry>
    <title>Lord of the X86 Rings: A Portable User Mode Privilege Separation Architecture on X86</title>
    <link href="http://yama0xff.com/2019/02/15/Lord-of-the-X86-Rings-A-Portable-User-Mode-Privilege-Separation-Architecture-on-X86/"/>
    <id>http://yama0xff.com/2019/02/15/Lord-of-the-X86-Rings-A-Portable-User-Mode-Privilege-Separation-Architecture-on-X86/</id>
    <published>2019-02-15T09:09:42.000Z</published>
    <updated>2019-02-15T09:40:18.300Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>前heartbleed漏洞导致的敏感信息常泄露一直是人们要解决的问题，即如何保护程序中的隐私数据不被任意的访问到。研究人员想到的方法根本出发点为，将隐私数据隔离，即使存在程序漏洞，也不能任意访问到这些敏感数据。而将隐私数据存放于什么位置，是人们一直以来需要解决的问题。此前的解决办法包括，线程隔离，进程隔离，使用可以信执行区域(如Intel SGX)等。这些方法或者性能影响比较大，或者受限到CPU型号。<strong><em>而在这篇论文里作者使用Intel x86处理器一直以来存在的r0-r3四个特权等级来将数据隔离访问，一方面解决了处理器兼容问题(几乎所有Intel AMD处理器均支持这四个特权级别)，一方面解决了性能问题。</em></strong></p><table><thead><tr><th>relevant information</th><th></th></tr></thead><tbody><tr><td><em>作者</em></td><td>Hojoon Lee, Chihyun Song, Brent Byunghoon Kang</td></tr><tr><td><em>单位</em></td><td>CISPA Helmholtz Center i.G. GSIS, School of Computing, KAIST</td></tr><tr><td><em>出处</em></td><td>ACM CCS’18</td></tr><tr><td><em>原文地址</em></td><td><a href="https://github.com/wtwofire/database/blob/master/papers/reverse/2018-Lord%20of%20the%20X86%20Rings%20A%20Portable%20User%20Mode%20Privilege%20Separation%20Architecture%20on%20X86.pdf" target="_blank" rel="noopener">https://github.com/wtwofire/database/blob/master/papers/reverse/2018-Lord%20of%20the%20X86%20Rings%20A%20Portable%20User%20Mode%20Privilege%20Separation%20Architecture%20on%20X86.pdf</a></td></tr><tr><td><em>源码地址</em></td><td></td></tr><tr><td><em>发表时间</em></td><td>2018年</td></tr></tbody></table><h1 id="x86-特权级别及切换"><a href="#x86-特权级别及切换" class="headerlink" title="x86 特权级别及切换"></a>x86 特权级别及切换</h1><p>这篇论文带读者复习了x86处理器的环(ring)特权等级，门描述，GDT，LDT，段选择子，段间跳转等内容。而这篇论文的内容主要基于现代操作系统几乎没有用到的r1,r2两个特权等级。用户程序运行在R3等级，而操作系统内核运行在R0级别。用户程序不能访问到内核数据空间，原因在于页表的访问权限的限制。以下将内核页面权限简称S页面，将用户页面权限称为U页面。作者将用户的敏感数据及访问这些数据的代码放置于S页面，从而达到普通用户程序无法访问到敏感数据。然后将段代码所运行的特级等级设置于r1，从而阻止代码访问到内核数据。达到双向隔离。即普通程序无法访问到敏感代码数据，敏感代码无法访问到内核数据。</p><h1 id="权限访问控制"><a href="#权限访问控制" class="headerlink" title="权限访问控制"></a>权限访问控制</h1><p><img src="/2019/02/15/Lord-of-the-X86-Rings-A-Portable-User-Mode-Privilege-Separation-Architecture-on-X86/1.png" alt=""></p><p>如上图所示，作者将敏感数据代码所在特权等级(r2)称为PrivUser-mode。用户模式由于页面属性的限制不能访问到内核及PrivUser，而作者将R2所在段的段基地地址与段限写在固定的位置，使得PrivUser的代码不能访问到内核。用户可以将特殊的数据如密钥等标记为敏感数据从而存放在PrivUser所在的S页面中。而需要访问到这些敏感数据需要先将处理器提升到R2级别。作者将访问数据的函数同样放到PrivUser所在的内存中，调用这些函数首先需要一个跨段跳转提升处理器级别。然后在R2特权中执行函数。</p><p><img src="/2019/02/15/Lord-of-the-X86-Rings-A-Portable-User-Mode-Privilege-Separation-Architecture-on-X86/2.png" alt=""></p><p>如上图即为作者的跨段跳转示意图，作者借助r1作为一个跨段跳转板，原因是他将R2段中的L标志(32位兼容模式)置位了，而跨段跳转指令不允许从一个非32位段跳到一个32位段，而允许从一个非32位段返回32位段，因此先进入R1将特权等级提升，再通过段返回指令如(lret)到PrivUser mode。这里我不能理解为何要将PrivUser段设置为32位兼容模式，从而导致多需要R1层作为跨段跳转中转。</p><h1 id="编译套件"><a href="#编译套件" class="headerlink" title="编译套件"></a>编译套件</h1><p>作者将这套系统命名为LOTRx86。其中包含一系列的能够帮助用户编译保护隐私数据的软件。整个编译系统的流程如下图所示</p><p><img src="/2019/02/15/Lord-of-the-X86-Rings-A-Portable-User-Mode-Privilege-Separation-Architecture-on-X86/3.png" alt=""></p><p>作者定义了一个宏，这个宏接受函数名称和参数类型等作为参数，并对外导出一个调用接口。开发者将访问敏感数据的函数导出，然后在主程序中使用系统所提供的宏来访问这个函数。由于PrivUser层的数据代码是32位兼容的，因此作者直接将这段内容直接链接进可以执行文件中。并且作者修改了libc中的malloc等内存分配函数使得PrivUser中的函数分配的内存始终在PrivUser内存中。其中包含一个内核模块，其功能为初始化LDT，初始化PrivUser内存，写入跨段跳转中转指令等。</p><h1 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h1><p>作者使用Privcall与一些常规的系统调用作对比，并且使用运行多次程序与在一次程序中多次调用来模拟程序使用接口的频繁程度。从图中可以看出Privcall相对于一些常规系统调用所带来的开销并不高。</p><p>接下来作者将LOTRx86方法与其他的两种方法作比较，即使页面保护与进程隔离两种方法。可以看出LOTRx86所带来的开销小于另外两个方法。</p><p><img src="/2019/02/15/Lord-of-the-X86-Rings-A-Portable-User-Mode-Privilege-Separation-Architecture-on-X86/4.png" alt=""></p><h1 id="评价"><a href="#评价" class="headerlink" title="评价"></a>评价</h1><p>相对于传统的使用进程隔离，页面保护的方法，使用段隔离的方法带的开销的确是比较小的。方法比较新颖。但是除了作者提到的几个缺点：</p><ol><li>参数仅支持32位</li><li>不支持ASLR</li><li>不能与用户程序共享数据空间</li></ol><p>我觉得作者的论文来缺乏了一点：没有将所用到的段描述详细的描述出来。</p><p>另外我觉得作者的关于对敏感数据的访问定义不够好，我觉得对于敏感数据的访问，不应该以代码段或者说函数来看，而应该以程序运行的时间段来看。即不能说某个函数是可以访问敏感数据的，而应该说在程序运行的某个时间段是可以访问敏感数据的。由于这个定义的不够好，所以我发现作者的设计中的一个缺陷。比如某个访问敏感数据 的函数需要使用libc中的fread函数，那么由于访问控制的原因，那么fread函数同样必须位于PrivUser层，而这样正常的函数需要使用fread的函数又必须将这函数位置PrivUser层中，这样的关联导致大片的函数无法分开。而我提出我的一个想法：</p><ol><li>构造一个LDT或者GDT，将段基地址写为0而将段限写为用户空间地址最大值。将这个段特权等级设置为1或者2，对应的SS,CS,DS都设置为使用这个LDT或者GDT。</li><li>将敏感数据放置于S页面中，当程序需要访问到敏感数据时，使用一个段跨越跳转跳到这个转中，跳转地址写为下一条指令。那么程序的执行流程正常进行，但是特权等级却切换到了高的特权等级上。</li><li>当不再需要访问敏感数据时则伪造一个栈结构，跨段返回到下一条指令，这样程正常继续以低特权运行。</li></ol><p>这样做的好处有：</p><ol><li>作法简单，只需要定义两个宏用于平衡栈和跨段跳转及返回</li><li>由于段空间与用户空间重叠，因此可以直接访问用户空间数据</li><li>符合访问敏感数据的定义，即访问敏感数据的代码与正常代码在内存中存在于一块，不需要另外编写一个宏将这段函数放在另外一个地方，只是访问时的特权等级变了。这样我所提到的函数牵连问就不存在。</li><li>粒度更加可控，作者提出的粒度基于函数，即将整个函数作为访问敏感数据的代码块，而这里可以选择一小块代码，外包一个跨段宏和退段宏即可。</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h1&gt;&lt;p&gt;前heartbleed漏洞导致的敏感信息常泄露一直是人们要解决的问题，即如何保护程序中的隐私
      
    
    </summary>
    
      <category term="论文" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/"/>
    
      <category term="软件分析" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90/"/>
    
    
      <category term="2018年" scheme="http://yama0xff.com/tags/2018%E5%B9%B4/"/>
    
      <category term="防护" scheme="http://yama0xff.com/tags/%E9%98%B2%E6%8A%A4/"/>
    
      <category term="ACM CCS&#39;18" scheme="http://yama0xff.com/tags/ACM-CCS-18/"/>
    
  </entry>
  
  <entry>
    <title>Digtool: A Virtualization-Based Framework for Detecting Kernel Vulnerabilities</title>
    <link href="http://yama0xff.com/2019/02/15/Digtool-A-Virtualization-Based-Framework-for-Detecting-Kernel-Vulnerabilities/"/>
    <id>http://yama0xff.com/2019/02/15/Digtool-A-Virtualization-Based-Framework-for-Detecting-Kernel-Vulnerabilities/</id>
    <published>2019-02-15T07:53:36.000Z</published>
    <updated>2019-02-15T08:44:19.666Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>发现操作系统（OS）内核中的漏洞并对其进行修补对于操作系统安全至关重要。但是，缺乏有效的内核漏洞检测工具，尤其是对于Microsoft Windows等封闭源操作系统。在本文中，我们介绍了Digtool，一个有效的，仅二进制代码的内核漏洞检测框架。 Digtool构建于我们设计的虚拟化监视器之上，成功捕获内核执行的各种动态行为，例如内核对象分配，内核内存访问，线程调度和函数调用。通过这些行为，Digtool已经确定了45个零日漏洞，例如最近版本的Microsoft Windows的内核代码和设备驱动程序中的out–bounds访问，free-after-free和check-time-of-use-of-use ，包括Windows 7和Windows 10。</p><table><thead><tr><th>relevant information</th><th></th></tr></thead><tbody><tr><td><em>作者</em></td><td>Jianfeng Pan, Guanglu Yan, Xiaocao Fan</td></tr><tr><td><em>单位</em></td><td>IceSword Lab, 360 Internet Security Center</td></tr><tr><td><em>出处</em></td><td>USENIX’17</td></tr><tr><td><em>原文地址</em></td><td><a href="https://github.com/wtwofire/database/blob/master/papers/fuzzing/2017-Digtool%EF%BC%9AA%20Virtualization-Based%20Framework%20for%20Detecting%20Kernel%20Vulnerabilities.pdf" target="_blank" rel="noopener">https://github.com/wtwofire/database/blob/master/papers/fuzzing/2017-Digtool%EF%BC%9AA%20Virtualization-Based%20Framework%20for%20Detecting%20Kernel%20Vulnerabilities.pdf</a></td></tr><tr><td><em>源码地址</em></td><td>无，相关材料：<a href="https://www.usenix.org/sites/default/files/conference/protected-files/usenixsecurity17_slides_guanglu_yan.pdf" target="_blank" rel="noopener">Slide</a>,<a href="https://www.youtube.com/watch?v=EOhIxpcyAiw" target="_blank" rel="noopener">Video</a></td></tr><tr><td><em>发表时间</em></td><td>2017年</td></tr></tbody></table><h1 id="一、背景"><a href="#一、背景" class="headerlink" title="一、背景"></a>一、背景</h1><p>目前，自动化检测系统内核漏洞的工具比较少，而且，很多的工具都是只能检测开源的系统内核（例如：Linux操作系统），对于不开源的操作系统（例如：Microsoft Windows）则无能为力。因此，很有必要开发一款专用的系统内核漏洞检测工具，在二进制层面检测系统内核潜在的漏洞。漏洞检测工具通常分为两个方面：路径探测和漏洞识别，路径探测通常使用fuzzer工具，查找尽可能多的分支路径；漏洞识别则用于检测这些路径上可能存在的漏洞。而在这篇文章中，作者结合了这两个方面的技术，具体检测了内核中的以下四种漏洞类型：</p><h2 id="1-UNPROBE"><a href="#1-UNPROBE" class="headerlink" title="1. UNPROBE"></a><strong>1. UNPROBE</strong></h2><p>在这篇文章中，作者把未经检查的、从用户层传下来的输入缓冲区指针所造成的漏洞叫做UNPROBE。很多内核模块都可能会忽略对用户层的指针进行检查，特别是一些被嵌套的指针，而这种情况是非常危险的，因为它可能会导致非法内存引用、任意的内存读或者写等严重后果。</p><h2 id="2-TOCTTOU-Time-Of-Check-To-Time-Of-Use"><a href="#2-TOCTTOU-Time-Of-Check-To-Time-Of-Use" class="headerlink" title="2. TOCTTOU (Time-Of-Check-To-Time-Of-Use)"></a><strong>2. TOCTTOU (Time-Of-Check-To-Time-Of-Use)</strong></h2><p>TOCTTOU漏洞来源于对同一个用户层的数据进行多次的访问。在有些系统调用处理例程中，当它要访问某一个用户层数据的时候，它首先会检查这个数据是否合法，然后再使用它，这就会产生两次对该数据的访问，而在这两次访问之间就会存在一个攻击窗口，一旦这个攻击窗口被攻击者利用，就有可能导致非法内存引用、任意的内存读或者写等严重后果。</p><h2 id="3-UAF-Use-After-Free"><a href="#3-UAF-Use-After-Free" class="headerlink" title="3. UAF (Use-After-Free)"></a><strong>3. UAF (Use-After-Free)</strong></h2><p>UAF漏洞是由于使用了被释放的内存导致的。很多情况下，这种漏洞可能会导致本地提权。在Linux上，像AddressSanitizer这样的工具已经可以用于检测这类漏洞；在Windows上，微软自己开发的DriverVerifier也可以用于检测这种类型的漏洞，但是限制条件比较多。</p><h2 id="4-OOB-Out-Of-Bound-access"><a href="#4-OOB-Out-Of-Bound-access" class="headerlink" title="4. OOB (Out-Of-Bound access)"></a><strong>4. OOB (Out-Of-Bound access)</strong></h2><p>OOB漏洞是由于访问了目标内存块之外的内存导致的。该漏洞导致的后果跟UAF漏洞导致的后果一样，都可能会导致本地提权，并且用于检测这两种漏洞的工具也基本一样。</p><h1 id="二、提出的方法以及解决的问题"><a href="#二、提出的方法以及解决的问题" class="headerlink" title="二、提出的方法以及解决的问题"></a>二、提出的方法以及解决的问题</h1><p>像Windows这样的闭源操作系统，要检测系统中存在的漏洞，就不能再使用基于源码的检测工具，必须使用基于二进制代码的检测工具。因此，为了检测Windows内核中出现的以上四种漏洞类型，作者提出了一个基于二进制代码的检测框架：DigTool。该框架建立在作者自己设计的一个虚拟化监视器（Hypervisor）之上，用来捕获内核执行过程中的各种动态行为，例如：内核对象的分配、内核中的内存访问、线程调度和函数调用等，并基于这些行为，发掘系统中存在的漏洞。</p><h1 id="三、技术方法"><a href="#三、技术方法" class="headerlink" title="三、技术方法"></a>三、技术方法</h1><p><img src="/2019/02/15/Digtool-A-Virtualization-Based-Framework-for-Detecting-Kernel-Vulnerabilities/1.jpg" alt=""></p><p>DigTool的总体架构如图1所示，它的各个模块分布在系统的不同的层次当中，它们分别包括：Hypervisor中、客户机的内核中以及客户机的用户空间。通过箭头可以知道它们之间的各个模块的相互作用关系：细箭头所连接的两个模块表明它们之间有直接的调用关系或者是直接的传输信息通道，粗箭头表明两个模块之间通过某种事件触发机制进行间接的相互作用。</p><h2 id="1-Hypervisor-组件："><a href="#1-Hypervisor-组件：" class="headerlink" title="(1). Hypervisor 组件："></a><strong>(1). Hypervisor 组件：</strong></h2><p>DigTool不依赖于Xen、KVM等当前存在的Hypervisor，而是自己开发一个Hypervisor，它包含三个重要的组成部分：VMM（Virtual Machine Monitor）infrastructure、Interface detection 和 memory detection。</p><ul><li>虚拟机监控模块（VMM infrastructure）： 首先，它负责检测机器上的硬件环境和操作系统的版本等，以确保DigTool能正确的运行；然后，它再初始化Hypervisor，并把一个原始的操作系统加载到一个VM虚拟机当中运行。</li><li>接口检测（Interface detection）： 它负责监控用户层的应用程序在调用系统调用的时候传递到内核中的参数。在内核中，它跟踪这些参数被使用和被检查所发生的位置，以发掘潜在的漏洞。为了提高性能，DigTool并不是监控所有的系统调用，它只监控自己感兴趣的系统调用（通过配置文件进行配置）。因此，它限制了被监控的系统调用的范围，以检查特定的系统调用所产生的漏洞。</li><li>内存检测（Memory detection）： 该模块通过使用SPT（Shadow Page Table）技术，监控客户机操作系统内核中的非法内存访问。为了检测特定的内核模块（例如Win32k等），该模块可以通过调用相应的服务接口（Hypervisor提供给客户机操作系统内核的接口）来限制被监控的内核模块和地址范围。</li></ul><h2 id="2-Kernel-Space-组件："><a href="#2-Kernel-Space-组件：" class="headerlink" title="(2). Kernel-Space 组件："></a><strong>(2). Kernel-Space 组件：</strong></h2><p>DigTool在客户机操作系统内核中的所有模块被统称为：Middleware，它属于一个中间桥梁（或者说是一个中间件），用于连接Hypervisor和客户机用户空间程序，具有承上启下的作用。</p><ul><li>例如图1中，在Loader加载Fuzzer之前，可以通过用户空间中的configuration文件配置被检测的系统调用的范围，然后通过Middleware把相应的信息传送到Hypervisor，这就使得Hypervisor可以在Fuzzer进程空间中检测相应系统调用中的漏洞了。</li><li>对于接口检测，Middleware通过一个工作线程（Work thread）把所有的相关信息（包括系统调用号、事件类型、事件发生的时间、指令地址以及访问的内存）都记录到日志文件中。以便于日志分析模块（Log analyzer）可以通过日志文件分析并查找出相应的漏洞。</li><li>对于内存检测，Middleware通过Hook特定的内存操作函数，辅助内存检测模块矫正被检测的内存范围（因为DigTool只检测部分相关的内存范围），并且通过调用Hypervisor提供的接口来限制被监控的内存区域，以提高性能。另外，如果在这个过程中发现一个潜在的漏洞，Middleware还会中断客户机，使之进入单步调试模式，等待外部调试工具（例如 WinDbg）连接，并获取有用的上下文环境，辅助漏洞分析。</li></ul><h2 id="3-User-Space-组件："><a href="#3-User-Space-组件：" class="headerlink" title="(3). User-Space 组件："></a><strong>(3). User-Space 组件：</strong></h2><p>为了提高系统的稳定性和健壮性，作者把DigTool的一部分作用功能模块放到用户空间中，这些模块包括：Loader模块、Fuzzer模块和Log Analyzer模块。</p><ul><li>Loader模块，它负责装载一个特定的进程，给DigTool提供一个检测漏洞的进程环境。该模块还需要配置configuration文件，限制被检测的系统调用的范围等（要检测哪些系统调用就把这些系统调用添加到配置文件中）。</li><li>Fuzzer模块，该模块由Loader模块装载，通过Fuzzer模块调用系统调用，并通过调整系统调用的参数，探索尽可能多的路径，使得漏洞检测模块可以发掘尽可能多的漏洞。</li><li>Log Analyzer模块，该模块负责分析日志文件，分析代码中可能存在的漏洞。</li></ul><h1 id="四、实验评估"><a href="#四、实验评估" class="headerlink" title="四、实验评估"></a>四、实验评估</h1><h2 id="1-有效性评估"><a href="#1-有效性评估" class="headerlink" title="(1). 有效性评估"></a><strong>(1). 有效性评估</strong></h2><p>作者通过测试不同的软件产品来评估DigTool的有效性，这些产品包括Windows操作系统和一些反病毒软件，并且这些产品都是当时最新的版本。实验环境包括Windows 7和Windows 10。为了安全起见，在这篇文章中，作者使用的例子是当时发现的0Day漏洞，并且是已经被相应的厂商修复的漏洞。</p><h4 id="Detecting-Vulnerability-via-Interface："><a href="#Detecting-Vulnerability-via-Interface：" class="headerlink" title="Detecting Vulnerability via Interface："></a><strong>Detecting Vulnerability via Interface：</strong></h4><p>如表1所示，对于Avast Free Antivirus v11.2.2262、Dr. Web 11.0、AhnLab v8.0、Norman Security Suite v11.0.0和Spyware Detector v2.0.0.3这五个反病毒软件，被检测出存在UNPROBE漏洞的数量总共为23个。</p><p><img src="/2019/02/15/Digtool-A-Virtualization-Based-Framework-for-Detecting-Kernel-Vulnerabilities/Table1.jpg" alt=""></p><p>如表2所示，对于同样的五个反病毒软件，被检测出存在TOCTTOU漏洞的数量总共为18个。</p><p><img src="/2019/02/15/Digtool-A-Virtualization-Based-Framework-for-Detecting-Kernel-Vulnerabilities/Table2.jpg" alt=""></p><h4 id="Detecting-Vulerabiliry-via-Memory-Footprints"><a href="#Detecting-Vulerabiliry-via-Memory-Footprints" class="headerlink" title="Detecting Vulerabiliry via Memory Footprints:"></a><strong>Detecting Vulerabiliry via Memory Footprints:</strong></h4><p>为了检测UAF和OOB漏洞，作者选择32位的Windows 10为实验环境。检测这两类漏洞不再使用日志的形式，而是使用中断客户机系统的形式，即：当发现可能存在的漏洞的时候，中断客户机系统，等待调试工具连接，等调试工具连接上来之后，可以获取当前产生漏洞的位置对应的上下文环境，用于分析漏洞。但是这种方式的不足之处在于：它需要手工去分析漏洞。</p><p>在win32kfull.sys文件中，DigTool最先发现了MS16-123/CVE-2016-7211 CVE漏洞。</p><p>而对于OOB漏洞，作者使用DigTool发现了三个win32kbase中的CVE，它们分别是：MS16-090/CVE-2016-3252、MS16-034/CVE-2016-0096 和 MS16-151/CVE-2016-7260。</p><h2 id="2-效率评估"><a href="#2-效率评估" class="headerlink" title="(2). 效率评估"></a><strong>(2). 效率评估</strong></h2><p>目前，由于Bochspwn（一个基于Bochs模拟器的内核漏洞检测工具）只能检测前文中提到的四种漏洞类型的一类：TOCTTOU，因此，作者只能将DigTool与Bochspwn进行TOCTTOU漏洞测试比较。基于相同的环境下（相同的硬件、相同的操作系统版本、相同的系统调用参数和相同的测试程序），作者选用了十个最经常使用、最经常被反病毒软件Hook的系统调用的系统调用来测试性能开销。此外，为了测试结果的完整性，作者还选用了一个常用的软件WinRAR来加入这个测试实验当中，这两个工具的性能比较结果如图2所示。</p><p>在上图的实验结果中，作者分两种情况进行比较:“Unrecorded”和“Recorded”,具体如下：</p><h4 id="Unrecorded"><a href="#Unrecorded" class="headerlink" title="Unrecorded"></a><strong>Unrecorded</strong></h4><p>在这种测试模式下，在DigTool的配置文件中不添加任何的系统调用（相当于没有内存页面被监控），也不做任何的日志操作，但是在接口检测（Interface Detection）模块中的其它子功能是处于工作状态当中的。由于在检测TOCTTOU漏洞的时候，大部分系统调用和线程都处于不被监控状态，因此，该模式可以反映整个系统的基本性能开销，很适合与Bochspwn进行比较。</p><p>该模式下的性能开销比Windows模式（既没有DigTool，也没有Bochs）下慢2.18到5.03倍，比Bochspwn（操作系统运行在Bochs中）快45.4到156.5倍。对于WinRAR的测试结果，DigTool比Windows模式慢2.25倍，比Bochspwn模式快428.8倍。</p><h4 id="Recorded"><a href="#Recorded" class="headerlink" title="Recorded"></a><strong>Recorded</strong></h4><p>在这种测试模式下，相应的系统调用将被写入到配置文件中，并且相应的行为也会被记录下来（监控配置文件中指定的系统调用和相关的线程，对于无关的系统调用和线程都不做任何操作）。</p><p>该模式下的性能开销比Windows模式（既没有DigTool，也没有Bochs）下慢70到90倍，但任然比Bochspwn（操作系统运行在Bochs中）稍快。对于WinRAR的测试结果，这次测试使用极端情况，即：监控NT kernel中的所有系统调用。测试结果表明：DigTool比Windows模式慢13.45倍，比Bochspwn模式快71.8倍。</p><h1 id="五、优缺点"><a href="#五、优缺点" class="headerlink" title="五、优缺点"></a>五、优缺点</h1><h2 id="优点："><a href="#优点：" class="headerlink" title="优点："></a>优点：</h2><ul><li>DigTool相对于Bochspwn来说，在性能方面有很大的优势。不管是在“Unrecorded”模式还是“Recorded”模式下，DigTool都比Bochspwn快。</li><li>相对于DriverVerifier（一款微软开发的、用于检测Windows内核漏洞的工具），DigTool具有更好的弹性。在检测到一个可能的漏洞的时候，DriverVerifier会造成系统蓝屏死机（BSOD）,而且当这个潜在的漏洞在没有被修复之前，DriverVerifier就不能继续往下运行，因此无法同时检测多个漏洞；而DigTool则不会出现这种情况，DigTool在检测到潜在的漏洞的时候，只会记录漏洞发生的地点等一些有用的信息，不会造成系统蓝屏死机，并且可以同时检测多个漏洞。</li><li>对于OOB漏洞和UAF漏洞，DigTool在检测到潜在的漏洞的时候，可以直接中断客户机，等待外部调试器（如WinDbg等）连接，查看产生漏洞时刻的上下文，方便分析人员获取有用的信息；而DriverVerifier在检测到潜在的漏洞的时候，只能Crash客户机，并且无法获取产生漏洞时的上下文环境，若要分析产生漏洞的原因，分析人员还需要做额外的逆向分析工作，以确定漏洞产生的具体位置以及具体原因。</li><li>DigTool可以检测UNPROBE和TOCTTOU漏洞类型，而DriverVerifier则不可以。</li><li>在检测UAF和OOB漏洞的时候，如果漏洞没有造成系统崩溃，则DriverVerifier无法检测到它的存在。</li><li>DigTool发现了45个0Day内核漏洞。</li></ul><h2 id="缺点："><a href="#缺点：" class="headerlink" title="缺点："></a>缺点：</h2><ul><li>虽然DigTool的性能相对于Bochspwn好很多，但是，由于DigTool需要从Hypervisor和客户机之间频繁的进行切换，性能开销依然比较大。</li><li>DigTool的可移植性依然不是那么好，它目前只能运行Windows平台上。虽然DigTool的Hypervisor层与平台无关，但是它的Middleware层是与特定的平台相关的，要想使得DigTool在别的平台上能够运行，则必须修改它的Middleware。</li><li>DigTool目前只能检测四种漏洞类型：UNPROBE、TOCTTOU、UAF和OOB。对于其它的漏洞类型（例如：空指针解引用、双重释放等）却无法检测到。</li><li>该工具不是开源的工具，目前网上没有该工具的源代码。</li><li>该工具只能应用于内核漏洞检测，无法用于应用层的漏洞检测。</li></ul><h1 id="六、个人观点"><a href="#六、个人观点" class="headerlink" title="六、个人观点"></a>六、个人观点</h1><p>目前，已经存在很多用于检测漏洞的工具，既有收费的工具，又有免费的工具，不同的工具一般都有不同的用途，并且很多工具都只是检测具体的某一类或者是某几类漏洞。它们的检测方法也各不相同，有些基于源码检测，有些则基于二进制代码检测。而基于源码检测的工具比较多，这些工具大部分都是用于检测应用层的应用程序，以及开源的系统内核（例如Linux内核等）。很少有检测Windows内核漏洞的工具，因为Windows内核是闭源的，无法获取到它的源代码。</p><p>对于检测Windows内核漏洞，目前有一款功能非常受限的、微软开发的检测工具DriverVerifier，前文也提到，该工具的限制条件比较多，检测的漏洞类型也很少，因此，作者自己开发了一款检测Windows内核漏洞的工具：DigTool，作为DriverVerifier的补充工具。</p><p>DigTool主要关注两个部分的内容，一个是系统调用入口，当应用程序调用系统调用的时候，可能会由于各种原因，导致非法的、或者是不适当的参数被传入到系统内核中，如果内核代码不能处理好外部传入的参数，攻击者就可能会利用这些入口点，来获得额外的权限，这可能会导致系统内核沦陷。另一种情况是，内核代码如果对内存操作不当，也可能会导致严重的后果（例如，系统可能会出现崩溃、拒绝服务等现象）。</p><p>DigTool是基于二进制代码的一个漏洞检测工具，它的总体架构分为三个组成部分（Hypervisor Component、Kernel-Space Component 和 User-Space Component），其中Hypervisor Component是与平台无关的，而另外两个部分是与平台相关的，如果我们能够把它的Kernel-Space Component（其实就是它的Middleware部分）移植到别的系统上（例如MacOS、Linux OS等），那么，我们也可以利用作者的这个工具检测别的系统上的漏洞。虽然DigTool的User-Space Component也是与平台相关的，但是这部分的移植相对于Middleware来说简单的多，因此，DigTool的可移植性主要体现在它的Middleware上。</p><p>作者的DigTool目前已经可以检测四种漏洞类型（UNPROBE、TOCTTOU、UAF和OOB），如果稍作改进，可能也会比较容易检测双重释放等类型的漏洞，因为作者的这个工具可以检测到任意的内存地址空间。作者在文章中说道，当检测OOB漏洞的时候，作者使用AVL树来保存已经分配的内存区域，如果一片内存区域已经被释放，则它将会从AVL树中被移除，如果再次释放该内存区域，则DigTool会首先在AVL树中查找该内存区域，若找到，则释放（一般不可能）；若没有找到，则表明已经被释放，或者是没有该内存区域，即：可以发现双重释放类型的漏洞。但是，有一个很大的问题限制了这个想法，那就是：作者的DigTool不开源，我们无法获取到他的源代码，因此，我们也就无法在他的这个工具上做二次开发。</p><p>​                                                                                                                                                               <strong><em>转载于GoSSIP</em></strong></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h1&gt;&lt;p&gt;发现操作系统（OS）内核中的漏洞并对其进行修补对于操作系统安全至关重要。但是，缺乏有效的内核
      
    
    </summary>
    
      <category term="论文" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/"/>
    
      <category term="fuzzing" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/fuzzing/"/>
    
    
      <category term="fuzzing" scheme="http://yama0xff.com/tags/fuzzing/"/>
    
      <category term="2017年" scheme="http://yama0xff.com/tags/2017%E5%B9%B4/"/>
    
      <category term="内核" scheme="http://yama0xff.com/tags/%E5%86%85%E6%A0%B8/"/>
    
      <category term="USENIX&#39;17" scheme="http://yama0xff.com/tags/USENIX-17/"/>
    
  </entry>
  
  <entry>
    <title>SoK: Security Evaluation of Home-Based IoT Deployments</title>
    <link href="http://yama0xff.com/2019/02/15/SoK-Security-Evaluation-of-Home-Based-IoT-Deployments/"/>
    <id>http://yama0xff.com/2019/02/15/SoK-Security-Evaluation-of-Home-Based-IoT-Deployments/</id>
    <published>2019-02-15T02:37:32.000Z</published>
    <updated>2019-02-15T03:10:26.749Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>智能家居在安全方面一直表现得不尽人意，究其原因，在于IoT系统相对于传统的嵌入式系统，还引入了智能终端和网络，这就导致了其本身暴露了更多的攻击面。本文通过总结大量论文来帮助研究人员和从业者更好的理解针对智能家居的攻击技术，缓解措施，以及利益相关者应该如何解决这些问题。最后作者利用这些方法评估了45款智能家居设备，并将实验数据公布在<a href="https://yourthings.info./" target="_blank" rel="noopener">https://yourthings.info%E3%80%82</a></p><table><thead><tr><th>relevant information</th><th></th></tr></thead><tbody><tr><td><em>作者</em></td><td>Omar Alrawi、Chaz Lever、Manos Antonakakis、Fabian Monrose†</td></tr><tr><td><em>单位</em></td><td>Georgia Institute of Technology</td></tr><tr><td><em>出处</em></td><td>S&amp;P’19</td></tr><tr><td><em>原文地址</em></td><td><a href="https://github.com/wtwofire/database/blob/master/papers/IOT/2019-SoK%EF%BC%9ASecurity%20Evaluation%20of%20Home-Based%20IoT%20Deployments.pdf" target="_blank" rel="noopener">https://github.com/wtwofire/database/blob/master/papers/IOT/2019-SoK%EF%BC%9ASecurity%20Evaluation%20of%20Home-Based%20IoT%20Deployments.pdf</a></td></tr><tr><td><em>源码地址</em></td><td></td></tr><tr><td><em>发表时间</em></td><td>2019年</td></tr></tbody></table><h1 id="方法论"><a href="#方法论" class="headerlink" title="方法论"></a>方法论</h1><h2 id="抽象模型"><a href="#抽象模型" class="headerlink" title="抽象模型"></a>抽象模型</h2><p><img src="/2019/02/15/SoK-Security-Evaluation-of-Home-Based-IoT-Deployments/1.jpg" alt=""></p><ul><li>V: A(apps)、C(cloud)、D(devices)</li><li>E: communication</li></ul><h2 id="安全特性"><a href="#安全特性" class="headerlink" title="安全特性"></a>安全特性</h2><h3 id="攻击面"><a href="#攻击面" class="headerlink" title="攻击面"></a>攻击面</h3><ul><li>Device<ul><li>Vulnerable services</li><li>Weak authentications</li><li>Default configurations（出厂设置）</li></ul></li><li>Mobile application (Android, iOS)<ul><li>Permissions: over-privileged</li><li>Programming: 密码学误用</li><li>Data protection: API keys, passwords, hard-coded keys</li></ul></li><li>Communication (local, Internet)<ul><li>Encryption</li><li>MITM</li></ul></li><li>Cloud<ul><li>Vulnerable services</li><li>Weak authentications</li><li>Encryption</li></ul></li></ul><h3 id="缓解措施"><a href="#缓解措施" class="headerlink" title="缓解措施"></a>缓解措施</h3><ul><li>patching</li><li>framework: 重构</li></ul><h3 id="利益相关"><a href="#利益相关" class="headerlink" title="利益相关"></a>利益相关</h3><ul><li>vendors</li><li>end-user</li></ul><p>其实还可以细分，芯片厂商，物联网平台，经销商，第三方的开发者等，来定义谁来负责解决谁的问题。</p><h2 id="分类的方法"><a href="#分类的方法" class="headerlink" title="分类的方法"></a>分类的方法</h2><ul><li>Merit: 创新性、有效性</li><li>Scope: 集中在讨论安全性（攻击性和防御性）</li><li>Impact: 影响力</li><li>Disruption: 揭示了一个新的领域</li></ul><h2 id="威胁模型"><a href="#威胁模型" class="headerlink" title="威胁模型"></a>威胁模型</h2><p>只考虑Internet protocol network attacker，不考虑low-energy based devices，作者认为攻击所需要的资源在大多数家庭都没有。同时如果能hacking hub devices，就默认exploit了所有的low-energy based devices。（这里就限制了讨论的范围）</p><h1 id="相关的研究"><a href="#相关的研究" class="headerlink" title="相关的研究"></a>相关的研究</h1><p><img src="/2019/02/15/SoK-Security-Evaluation-of-Home-Based-IoT-Deployments/2.jpg" alt=""></p><h2 id="Device"><a href="#Device" class="headerlink" title="Device"></a>Device</h2><ol><li>Attack Vectors 设备上暴露的引脚可以让攻击者轻而易举的获得权限，不安全的配置会加剧漏洞的产生， 而缺少或弱的身份认证是最容易出现的问题，这些都导致设备上的安全问题被频繁曝出。<ul><li>August Smart Lock，硬编码的密钥、debug接口</li><li>cloud-based cameras，强口令但是是mac地址的base64编码</li><li>Sonos device，在高端口开了后门服务，并且没有认证</li><li>厂商集成第三方库的安全使得其很难保证整体的安全性</li><li>Philips Hue device，通过侧信道攻击得到master key，配合协议的漏洞完成蠕虫</li></ul></li><li>Mitigations 要想解决以上问题，就要求vendor通过设备更新来打patch，要求security by design。<ul><li>Fear and logging in the internet of things</li><li>SmartAuth，识别IoT应用的权限，这个主要是针对SmartThings和Apple Home</li><li>FlowFence，把应用分成sensitive和non-sensitive两部分，这部分需要开发者来做。</li></ul></li><li>Stakeholders Vendors有责任patch和update有漏洞的设备，但也要授权给end-user一定的权限，比如可以关闭某些有问题的服务。<ul><li>SmartAuth提供一种可以导出认证规则的方式，但只能vendor来做。</li><li>Sonos device允许用户使用网络隔离的方式来缓解漏洞。</li></ul></li></ol><h2 id="Mobile-Application"><a href="#Mobile-Application" class="headerlink" title="Mobile Application"></a>Mobile Application</h2><ol><li>Attack Vectors over-privileges、programming error、hard-coded sensitive information<ul><li>August Smart Lock，作者用敏感信息dump密钥</li><li>IoTFuzzer，利用app来对设备做fuzzing，当然也可以利用app做攻击</li><li>用app来收集设备的有关信息，然后重新配置路由器的防火墙，使得设备处于公网</li><li>Hanguard，app宽松的安全假设导致设备的隐私泄露（App作为设备的入口，厂商往往默认App所处的网络是可信的）</li></ul></li><li>Mitigations<ul><li>基于角色的访问控制</li></ul></li><li>Stakeholders mobile的安全依赖user和vendor，user往往有权限控制的权利，同时user应该遵守从app store上下载app。vendor应该解决programming error并且安全存储数据。</li></ol><h2 id="Cloud-Endpoint"><a href="#Cloud-Endpoint" class="headerlink" title="Cloud Endpoint"></a>Cloud Endpoint</h2><ol><li>Attack Vectors<ul><li>August Smart Lock，cloud端实现的不安全的API导致越权</li><li>cloud没有对固件的更新包签名</li><li>web的xss漏洞，username枚举。。</li><li>AutoForge，伪造app的请求，实现爆破密码，token劫持等</li></ul></li><li>Mitigations<ul><li>身份认证</li><li>细粒度的访问控制</li></ul></li><li>Stakeholders 由于云平台一般只有厂商管理，所以cloud上的基础设施和API实现的安全应该由他们来负责。</li></ol><h2 id="Communication"><a href="#Communication" class="headerlink" title="Communication"></a>Communication</h2><p>classes of protocols <em> Internet protocol </em> low-energy protocol</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Zigbee</span><br><span class="line">Z-Wave</span><br><span class="line">luetooth-LE</span><br></pre></td></tr></table></figure><p>Application layer protocols，DNS、HTTP、UPnP、NTP</p><ol><li><p>Attack Vectors</p><ul><li><p>EDNS解析 导致信息泄露</p></li><li><p>用NTP的MITM攻击绕过HSTS</p></li><li><p>UPnP实现时缺少认证，内存破坏漏洞等问题</p></li><li><p>TLS/SSL， TLS 1.0的IV问题，TLS RC4的问题</p></li><li><p>BLE、Zigbee、Z-Wave，协议设计本身的问题</p></li><li><p>LE的重放攻击更容易</p></li></ul></li><li><p>Mitigations </p><ul><li>对于HTTP，UPnP，DNS和NTP协议，放弃使用不安全的协议，使用最新的协议。</li><li>为有实现缺陷的TLS/SSL，升级服务器端和客户端库到最新版本应解决漏洞。</li><li>对于基于LE的通信，第一代Zigbee和Z-Wave协议有严重的缺陷，并且缓解方案有限。供应商可以禁用这些协议。</li><li>最近也有研究者发现通过监控物联网设备的流量，可以侧信道出一些隐私数据。 Apthorpe 等设计了如何在家中构造流量网络来防止旁道攻击。</li></ul></li><li><p>Stakeholders </p><ul><li>互联网服务提供商（ISP）可以看到基于IP的协议的数据包，但它们不是负任何缓解。 对于ISP来说，他们必须提供其相应的义务（这个我理解是比如说Mira DDoS，ISP虽然不能阻止设备发出去的恶意流量，但是他可以ban掉设备访问C&amp;C域名）。</li><li>对于LE协议，供应商可以缓解禁用易受攻击的设备的配对。</li></ul></li></ol><h1 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h1><p>作者对45款比较流行的不同的设备进行了各方面的评估。这些设备主要包括</p><ul><li>appliances</li><li>cameras</li><li>home assistants</li><li>home automation</li><li>media</li><li>network devices</li></ul><p>实验配置的网络环境，包含一个linux machine用于监听所有的流量和一个路由器（包含Wi-Fi热点）。对流量抓包后分析，对device和cloud使用漏扫分析，对app使用自动化审计工具。这里存在几个难点，</p><ul><li>设备自动更新 – 手动关掉</li><li>云平台的分类 – 人工识别，排除CDN</li><li>无线流量分析 – Wireless to wireless，</li><li>iOS应用解密 – 砸壳</li><li>…</li><li></li></ul><p><img src="/2019/02/15/SoK-Security-Evaluation-of-Home-Based-IoT-Deployments/3.png" alt=""></p><p>MobSF(Mobile Security Framework）、Qark，Kryptowire这些针对app的漏洞扫描器。45个设备有42个有app，其中包含41个Android平台，42个iOS平台。24个Over-privileged。15个包含硬编码的API key。17个使用了硬编码的key和IV。 </p><p><img src="/2019/02/15/SoK-Security-Evaluation-of-Home-Based-IoT-Deployments/4.png" alt=""></p><p>Nessus Scanner扫描。45个设备4000个域名。这些域名包括 基于云的服务（950）， 第三方的服务。CDN（1287） 混合，使用了AWS，Azure的服务的厂商（630） ，未知（1288）。</p><p><img src="/2019/02/15/SoK-Security-Evaluation-of-Home-Based-IoT-Deployments/5.png" alt=""></p><p>Nessus Scanner扫描，分析设备的操作系统，服务，漏洞等。在45个设备中发现了84个服务，39个有issue。这些服务主要是SSH，UPnP，HTTP，DNS，Telnet，RTSP。这些issues包括</p><ul><li>错误配置的TLS/SSL, 比如自签名的证书、过期的证书、短的密钥。</li><li>UPnp未授权访问。</li></ul><p><img src="/2019/02/15/SoK-Security-Evaluation-of-Home-Based-IoT-Deployments/6.png" alt=""></p><p>Nessus Monitor，ntop-ng，Wireshark，sslsplit。用sslsplit做MITM。43个D-C，35个A-C，27个A-D（LAN）。IP 通信包括DNS（41）、HTTP（38）、UPnP（21）和私有的协议（5）。</p><p>MITM: D-C(4), A-C(2), A-D(20) Encryption: D-C(40), A-C(24), A-D(7) </p><p><img src="/2019/02/15/SoK-Security-Evaluation-of-Home-Based-IoT-Deployments/7.png" alt=""></p><p>缓解措施</p><ul><li>Device 通过安全信道更新并确保更新内容的完整性。设备在激活前可以检查配置是否正确并安全。设备应该保证只与验证过身份的设备交互。</li><li>Mobile 敏感信息，比如API key应该在安装的时候导出并秘密存起来。密码算法应该尽量使用成熟的第三方库实现。</li><li>Cloud 厂商应该尽量使用商业化的云平台。通过API管理endpoint的配置。不应该再支持不安全的协议。</li><li>Communication 验证endpoint的身份，防止中间人攻击。保护通信协议的完整性。</li></ul><p>​                                                                                                                                                               <strong><em>转载于GoSSIP</em></strong></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h1&gt;&lt;p&gt;智能家居在安全方面一直表现得不尽人意，究其原因，在于IoT系统相对于传统的嵌入式系统，还引入
      
    
    </summary>
    
      <category term="论文" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/"/>
    
      <category term="IOT" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/IOT/"/>
    
    
      <category term="综述" scheme="http://yama0xff.com/tags/%E7%BB%BC%E8%BF%B0/"/>
    
      <category term="IOT" scheme="http://yama0xff.com/tags/IOT/"/>
    
      <category term="S&amp;P&#39;19" scheme="http://yama0xff.com/tags/S-P-19/"/>
    
      <category term="2019年" scheme="http://yama0xff.com/tags/2019%E5%B9%B4/"/>
    
  </entry>
  
  <entry>
    <title>Enforcing Unique Code Target Property for Control-Flow Integrity</title>
    <link href="http://yama0xff.com/2019/02/14/Enforcing-Unique-Code-Target-Property-for-Control-Flow-Integrity/"/>
    <id>http://yama0xff.com/2019/02/14/Enforcing-Unique-Code-Target-Property-for-Control-Flow-Integrity/</id>
    <published>2019-02-14T13:01:44.000Z</published>
    <updated>2019-02-14T14:12:55.284Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>在这篇文章中，作者主要介绍了一种准确率更高的确保CFI的应用方式：Unique Code Target（UCT）。对于每次间接跳转（ICT），作者们设计了一个叫μUCT的系统来确保这一特性的实施。在编译时，μCFI就识别那些可能影响ICT的指令并让程序去记录一些必要的执行环境；在运行时，μCFI在另一个进程中监视程序的运行，并且在一些关键性的指令上使用内存安全地记录着地运行环境来做一些对点分析，判断这些指令的跳转是否符合预期。作者将μCFI这套系统布置到SPEC benchmark和2个服务器程序（nginx和vsftpd）上测试性能和overhead。同时它们还用它来测试了5个真实世界中的案例、1个<a href="https://csdl.computer.org/csdl/proceedings/sp/2015/6949/00/6949a745.pdf" target="_blank" rel="noopener">COOP</a>的poc进行攻击的案例。μCFI在这些测试上表现得都非常好，展现了100%的检测率和仅不到10%的overhead</p><table><thead><tr><th>relevant information</th><th></th></tr></thead><tbody><tr><td><em>作者</em></td><td>Hong Hu, Chenxiong Qian, Carter Yagemann, Simon Pak Ho Chung, Taesoo Kim and Wenke Lee, William R. Harris</td></tr><tr><td><em>单位</em></td><td>Georgia Institute of Technology, Galois Inc</td></tr><tr><td><em>出处</em></td><td>ACM CCS’18</td></tr><tr><td><em>原文地址</em></td><td><a href="https://github.com/wtwofire/database/blob/master/papers/reverse/2018-Enforcing%20Unique%20Code%20Target%20Property%20for%20Control-Flow%20Integrity.pdf" target="_blank" rel="noopener">https://github.com/wtwofire/database/blob/master/papers/reverse/2018-Enforcing%20Unique%20Code%20Target%20Property%20for%20Control-Flow%20Integrity.pdf</a></td></tr><tr><td><em>源码地址</em></td><td></td></tr><tr><td><em>发表时间</em></td><td>2018年</td></tr></tbody></table><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>CFI的健壮性在于它的跳转规则集合：过于严格的规则可能破坏了程序的正常运行，而松散的规则则让攻击者有了可乘之机。一些针对CFI的攻击也体现了普通的静态分析相比于理想CFI的不同：静态分析只是对于每个ICT给出了所有可能的跳转集合；而理想的CFI应是进一步结合当时的context来判断可能的跳转。近年的CFi开始结合了运行时的context来缩小集合范围，但是在一些情况下返回的集合大小仍然过大：如访问一个数组元素，在不知道index的情况下，返回的集合就是数组中的全部元素了。</p><p>在本论文中，作者的应用方式可以做到对于一个ICT<strong>只返回唯一确定的跳转可能</strong>。结合之前的CFI工作，本论文只讨论控制数据来劫持控制流的攻击手段。</p><p>那么如何实现UCT的呢？作者收集了一些<strong>必要的运行时信息</strong>来对控制的数据进行分析，这些信息被作者命名为<strong>constrained data</strong>。那么收集这些数据有三个问题需要解决： </p><ol><li>如何准确判断constrained data </li><li>如何高效地收集这些data </li><li>收集到这些数据后，如何高效准确地进行对点分析</li></ol><p>μCFI对代码进行静态分析，找到其中的constrained data。<strong>分析从函数指针开始，继而迭代地寻找那些在计算这些指针时引用的变量，同时还弄了门arbitrary data collection技术来高效记录运行时的constrained data。与此同时，作者们还对收集到的constrained data进行编码，然后应用Intel的硬件支持Processor Trace（<a href="https://software.intel.com/en-us/blogs/2013/09/18/processor-tracing" target="_blank" rel="noopener">PT</a>）技术来高效记录。μCFI在程序运行时作为一个平行的进程运行，从而来解析记录的constrained data。同时，为了高效的分析，作者还构建了部分执行路径来避免在于安全隐患无关的代码上浪费的时间。**</strong></p><p>也就是说，最终设计的系统包括<strong>一个编译器</strong>和<strong>一个执行监视器</strong>。监视器在每次ICT指令之后进行CFI检查，并且为了保证安全，监视器会与内核交互来在ICT指令之后立即block被监视的程序。其原型是用来针对jmp和call指令的，ret指令的CFI交给了之前的解决方案shadow stack来解决。</p><h1 id="Problem"><a href="#Problem" class="headerlink" title="Problem"></a>Problem</h1><p>样例代码：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">typedef</span> <span class="title">void</span> <span class="params">(*FP)</span><span class="params">(<span class="keyword">char</span> *)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">A</span><span class="params">(<span class="keyword">char</span> *)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">B</span><span class="params">(<span class="keyword">char</span> *)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">C</span><span class="params">(<span class="keyword">char</span> *)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">D</span><span class="params">(<span class="keyword">char</span> *)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">E</span><span class="params">(<span class="keyword">char</span> *)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">handleReq</span><span class="params">(<span class="keyword">int</span> uid, <span class="keyword">char</span> * input)</span> </span>&#123;</span><br><span class="line">  FP arr[<span class="number">3</span>] = &#123;&amp;A, &amp;B, &amp;C&#125;;</span><br><span class="line">  FP fpt = &amp;D;</span><br><span class="line">  FP fun = <span class="literal">NULL</span>;</span><br><span class="line">  <span class="keyword">char</span> buf[<span class="number">20</span>];</span><br><span class="line">  <span class="keyword">if</span> (uid &lt; <span class="number">0</span> || uid &gt; <span class="number">2</span>) <span class="keyword">return</span>;</span><br><span class="line">  <span class="keyword">if</span> (uid == <span class="number">0</span>) &#123;</span><br><span class="line">      fun = arr[<span class="number">0</span>];</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123; <span class="comment">// uid can be 1, 2</span></span><br><span class="line">      fun = arr[uid];</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">strcpy</span>(buf, input); <span class="comment">// stack buffer overflow</span></span><br><span class="line">  (*fun)(buf); <span class="comment">// fun is corrupted</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>理想情况下，CFI应该保证在<code>(*fun)(buf)</code>被执行时，uid为零时fun=A，为1时fun=B…而不应该被bof改写掉去执行别的内容。当CFI检查到不一致时，中止程序来避免任何可能的伤害。</p><p>当前各种CFI的运行结果如下：其中typeCFI/staticCFI均为静态分析法，πCFI和PITTYPAT均为动态分析法，可见只有µCFI能返回唯一确定的执行流预测。</p><p><img src="/2019/02/14/Enforcing-Unique-Code-Target-Property-for-Control-Flow-Integrity/All target sets.png" alt=""></p><p>这里给出了作者对于constrained data 的精确定义：<strong><em>它在IDT的跳转目标中有重要作用，但是其既不是一个直接代表函数地址的控制变量，也不是一个会被解引用出函数指针的一个指针。直到IDT真正发生时，它的值甚至才可能从实际的执行路径当中推断出来。而一旦它的值确定，之后的分析就可以在对任何执行路径上都对IDT给出唯一的推断结果。</em></strong>任何具有如上特性的变量都可以成为constrained data，如示例代码中的uid。</p><h1 id="System-Design"><a href="#System-Design" class="headerlink" title="System Design"></a>System Design</h1><p>在本系统的设计当中，作者将µCFI拆做两部分：静态编译器和动态监视器。在给出源代码的情况下，编译器首先进行静态分析找到constrained data。之后，其将每个基本块编上唯一ID并与constrained data一起记录。</p><p>µCFI的静态编译器产生三个结果：<strong>一个是生成的二进制文件，一个是用来对点分析的LLVM IR和LLVM IR基本块到对应唯一ID的一个对应表</strong>。 然后在程序的执行过程中，µCFI的监视器依靠内核驱动解析来自PT的记录，解码出对应的基本块ID和相应的constrained data。那么有了基本块的ID，监视器就可以确定每个在被执行的基本块并对每个间接跳转的执行进行点对点的分析了。 同时，由于有了constrained data，µCFI也可以为每个ICT生成唯一确定的跳转目标。那么再和PT记录的跳转比较一下，就可以发现是否被劫持了。</p><p><img src="/2019/02/14/Enforcing-Unique-Code-Target-Property-for-Control-Flow-Integrity/μCFI overview.png" alt=""></p><h2 id="constrained-data的判断"><a href="#constrained-data的判断" class="headerlink" title="constrained data的判断"></a>constrained data的判断</h2><p>算法分为两部分： <strong>1. 收集所有和间接跳转目标计算的有关的指令 2. 检查这些指令当中的非常量值，这些值也就成为了constrained data </strong></p><p>那么关于收集这些指令又分为直接相关和间接相关的指令：<strong>直接相关指指令读/写了函数指针；而间接相关指指令为直接相关的指令准备了相关数据。</strong></p><p>作者使用迭代的方式寻找这些指令：算法首先寻找代码中所有的敏感数据类型，这些数据类型包括函数指针和包含函数指针的复合变量类型（这里就有一个迭代）</p><p>接下来，算法寻找所有的敏感指令，这些指令要么产生了敏感类型的变量值，要么参与了已被确定的敏感指令计算。</p><p>那么最后一步，遍历找到的所有敏感指令，然后遍历这当中涉及到的所有操作数：如果某个操作数既不是敏感数据类型又不是常量，那么它就是一个constrained data</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">Input: G - program to be <span class="keyword">protected</span></span><br><span class="line">Output: constraining data <span class="built_in">set</span></span><br><span class="line">TS ← ∅                                           <span class="comment">// sensitive type set</span></span><br><span class="line">repeat</span><br><span class="line">  <span class="keyword">for</span> typ ∈ Types(G):</span><br><span class="line">      <span class="keyword">if</span> typ is function-pointer type: TS ← TS ∪ &#123;typ&#125;</span><br><span class="line">      elif typ is composite type:</span><br><span class="line">          <span class="keyword">for</span> sTyp ∈ allTypes(typ):</span><br><span class="line">              <span class="keyword">if</span> sTyp ∈ TS: TS ← TS ∪ &#123;typ&#125;</span><br><span class="line">until no <span class="keyword">new</span> sensitive type is found</span><br><span class="line">IS ← ∅                                           <span class="comment">// sensitive instruction set</span></span><br><span class="line">repeat</span><br><span class="line">  <span class="keyword">for</span> instr ∈ Instructions(G):</span><br><span class="line">      <span class="keyword">if</span> instr has type ∈ TS: IS ← IS ∪ &#123;instr&#125;</span><br><span class="line">      elif isLoadInst(instr) <span class="keyword">or</span> isStoreInst(instr):</span><br><span class="line">          <span class="keyword">if</span> value ∈ IS: IS ← IS ∪ &#123;pointer&#125;</span><br><span class="line">      elif isCallInst(instr):</span><br><span class="line">          <span class="keyword">if</span> form-arg ∈ IS: IS ← IS ∪ &#123;act-arg&#125;</span><br><span class="line">          <span class="keyword">if</span> act-arg ∈ IS: IS ← IS ∪ &#123;form-arg&#125;</span><br><span class="line">      ... ...</span><br><span class="line">until no <span class="keyword">new</span> sensitive instruction is found</span><br><span class="line">CS ← ∅                                           <span class="comment">// constraining data set</span></span><br><span class="line"><span class="keyword">for</span> instr ∈ IS:</span><br><span class="line">  <span class="keyword">for</span> oprnd ∈ Operands(instr):</span><br><span class="line">      <span class="keyword">if</span> oprnd &lt; IS <span class="keyword">and</span> ¬isConstant(oprnd):</span><br><span class="line">          CS ← CS ∪ &#123;oprnd&#125;</span><br></pre></td></tr></table></figure><p>那么经过如上的算法分析后，对之前的样例代码，有如下结果： – sensitive type: – void (char<em>)</em> – [3 x void (char<em>)</em>] – sensitive instruction: – FP arr[3] = {&amp;A, &amp;B, &amp;C}; – FP fpt = &D; – FP fun = NULL; – fun = arr[0]; – fun = arr[uid]; – (*fun)(buf); – constraining data: – uid</p><h2 id="对Arbitrary-Data的收集"><a href="#对Arbitrary-Data的收集" class="headerlink" title="对Arbitrary Data的收集"></a>对Arbitrary Data的收集</h2><p>作者们设计了一套新方法来高效传递执行当中的信息到监视器的方法，来解决朴素PT缺乏non-control信息的缺陷。</p><p>在这一步中，µCFI设置了两个函数：write_data(设置在被保护的程序中，用来生成编码的任意数据并dump到PT trace里)和read_data(设置在监视器中，用来恢复出数据用以分析)</p><p>那么write_data(av)到底是如何让PT记录任意数据的呢？对于任意数据av，首先将其拆成几个block，每个block占N bits，然后对于每个block中的值，将其加上一个BASE_ADDR，然后call这个值做一个函数调用，就可以让PT记录下这个值了。BASE_ADDR指向一个设计的特殊函数allRet，其中2N个指令全部是ret(0xC3 for Intel CPU)。作者也考虑了这个函数的安全问题，然后给出了证明其安全的两个方面（corrupt av只会导致记录的值变化，同时调用call后面的值也是一直保存在寄存器而不是内存中）</p><p>然后编译器就可以在需要audit的constrained data前插入write_data()这个函数来记录当前data的值，就可以对之后的间接跳转合法性进行检查了。</p><h2 id="高效的控制流构建"><a href="#高效的控制流构建" class="headerlink" title="高效的控制流构建"></a>高效的控制流构建</h2><p>µCFI之后就可以在LLVM的IR层上构建动态分析的控制流。然而这还面临两方面的额挑战： 1. 从高度压缩的PT trace当中重建完整的执行路径解析耗时 2. 实际生成的二进制文件指令由于编译器优化可能和LLVM IR层的执行流有很大区别。</p><p>作者们所设计的高效准确的IR层控制流重建基于以下他们观察到的三个现象： 1. 不管如何优化，编译总是保持函数本身的高阶功能，这其中就包括如一些内存访问、函数调用这类side-effecting的指令的执行顺序。那么只要IR层和执行代码有相同的这类指令的顺序，那么对其的分析从功能上而言是一样的。 2. 相同基本块中的执行执行顺序是一样的。因此作者们只需要知道IR基本块层面上的控制流就行了 3. 本论文中设计的对点分析不需要完整的控制流，而仅仅需要敏感指令的执行顺序即可。而这些指令占整个程序中的小部分，也因此对局部的敏感指令的控制流就足够了。</p><p>那么这部分的构建流程如下：µCFI编译器首先识别LLVM的IR基本块中含有敏感指令的块并标上BBID，然后在编译过程中在这些块的开头插入write_data(BBID)来让PT能够记录当前执行到了哪个基本块。那么监视器通过编译器编译时输出的ID2BB的map就可以判断出当前在执行哪个IR的基本块了。</p><p>然后，作者使用一个变量表PTS来记录每个sensitive data的变化，并且当IDT发生时，将当前存在变量fun中的跳转目标和当前存在PTS中的fun进行比较，如果b不一致就abort</p><p>那么对之前的样例代码进行添加后如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">handleReq</span><span class="params">(<span class="keyword">int</span> uid,<span class="keyword">char</span> *input)</span> </span>&#123;</span><br><span class="line">  write_data(ID1); <span class="comment">// BBID ID1</span></span><br><span class="line">  FP arr[<span class="number">3</span>] = &#123;&amp;A,&amp;B,&amp;C&#125;; <span class="comment">// s-instr</span></span><br><span class="line">  FP fpt = &amp;D; <span class="comment">// s-instr</span></span><br><span class="line">  FP fun = <span class="literal">NULL</span>; <span class="comment">// s-instr</span></span><br><span class="line">  <span class="keyword">char</span> buf[<span class="number">20</span>];</span><br><span class="line">  <span class="keyword">if</span> (uid &lt; <span class="number">0</span> || uid &gt; <span class="number">2</span>) <span class="keyword">return</span>;</span><br><span class="line">  <span class="keyword">if</span> (uid == <span class="number">0</span>) &#123; === TRACE ===&gt;&gt;</span><br><span class="line">      write_data(ID2); <span class="comment">// BBID ID2</span></span><br><span class="line">      fun = arr[<span class="number">0</span>]; <span class="comment">// s-instr</span></span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      write_data(ID3); <span class="comment">// BBID ID3</span></span><br><span class="line">      write_data(uid); <span class="comment">// c-data</span></span><br><span class="line">      fun = arr[uid]; <span class="comment">// s-instr</span></span><br><span class="line">  &#125;</span><br><span class="line">  write_data(ID4); <span class="comment">// BBID ID4</span></span><br><span class="line">  <span class="built_in">strcpy</span>(buf, input);</span><br><span class="line">  (*fun)(buf); <span class="comment">// s-instr</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>相应的，在监视器的内部有如下的处理逻辑：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// PTS: global points-to table, initialized with NULL</span></span><br><span class="line"><span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line"><span class="keyword">int</span> BBID = read_data();</span><br><span class="line"><span class="keyword">switch</span>(BBID) &#123;</span><br><span class="line">  <span class="keyword">case</span> ID1:</span><br><span class="line">      PTS[arr[<span class="number">0</span>]] = A; PTS[arr[<span class="number">1</span>]] = B;</span><br><span class="line">      PTS[arr[<span class="number">2</span>]] = C; PTS[fpt] = D;</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">case</span> ID2:</span><br><span class="line">      PTS[fun] = PTS[arr[<span class="number">0</span>]];</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">case</span> ID3:</span><br><span class="line">      <span class="keyword">int</span> uid = read_data();</span><br><span class="line">      PTS[fun] = PTS[arr[uid]];</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">case</span> ID4:</span><br><span class="line">      <span class="keyword">int</span> real_target = getPTPacket();</span><br><span class="line">      <span class="keyword">if</span> (real_target != PTS[fun])</span><br><span class="line">          <span class="built_in">abort</span>();</span><br><span class="line">          <span class="keyword">else</span> <span class="keyword">continue</span>;</span><br><span class="line">&#125;&#125;</span><br></pre></td></tr></table></figure><p>但是如果按上述代码这样进行的话需要承担每次ICT进行检查的过高执行overhead，因此µCFI的监视只是随着执行平行地进行CFI的判断，并且在执行敏感地系统调用的时候才会挂起被监视的进程。作者们选择的敏感系统调用包括: <strong>mmap, mremap, remap_file_pages, mprotect, execve, execveat, sendmsg, sendmmsg, sendto, and write。</strong></p><h1 id="Implementation"><a href="#Implementation" class="headerlink" title="Implementation"></a>Implementation</h1><p>编译器构建在LLVM 3.6之上。 LLVM进行constrained data的识别和编码，以及BBID编码。作者将监视器实现为一个root用户进程，这使其适用于保护非root进程。 它使用两个线程，一个用于PT跟踪解析，另一个用于点分析和CFI验证。作者使用来自<a href="https://github.com/TJAndHisStudents/Griffin-Trace" target="_blank" rel="noopener">Griffin</a>的PT驱动程序的修改版本进行跟踪管理，其中作者将跟踪写入每个线程的伪代码文件，并为作者的用户空间μCFI监视器设置适当的权限以读取它。</p><p>接下来，作者将介绍μCFI系统的几个实现细节，包括减少PT的trace量，与shadow stack整合以及针对lazy type的分析。</p><h2 id="减少trace"><a href="#减少trace" class="headerlink" title="减少trace"></a>减少trace</h2><p>PT允许对trace的函数进行定制，因此作者利用编译器将所有的间接调用转化为了对一个特定函数iCall的直接调用，通过传参进去再跳转来实现间接跳转功能；同理还对所有需要调查的ret指令替换为oneRet函数，其中填充ret指令。那么这样做就可以将PT的trace限定在这两个函数中，从而减少了对特定程序进行trace所需要cover的代码量</p><h2 id="整合Shadow-Stack"><a href="#整合Shadow-Stack" class="headerlink" title="整合Shadow Stack"></a>整合Shadow Stack</h2><p>Shadow Stack技术可以在栈上保存当前函数返回地址处的一个固定（或随机）偏移处保存一个返回地址的副本（也就是在栈上保存了两个返回地址值），然后在返回时比较二者是否仍然一致并且（或）将副本的值复制到该函数的返回地址保存处。</p><p>那么µCFI就将其整合进自己的系统中，在原有的基础上对LLVM X86的后端和ELF构建函数进行了修改。对后端的修改使得在编译时能在函数开头和末尾添加两条汇编指令，用来保存和恢复返回地址值； 而对构建函数的修改使得在binary loader调用该执行文件时先执行构建函数(ELF constructor functions)，进行shadow stack和两个栈之间的保护页的构建后再将控制权交给原来的程序</p><h2 id="Lazy-type的分析技术"><a href="#Lazy-type的分析技术" class="headerlink" title="Lazy-type的分析技术"></a>Lazy-type的分析技术</h2><p>为了构建变量表PTS，通常需要对复合类型进行扁平化，即将其中的复合类型迭代的代入直至其中不再包含复合类型。但是由于LLVM IR的高度优化特性，这一方法需要的对对象分配的准确定义信息可能不是很容易获得。那么作者在尽可能获得的基础上，设计了Lazy-type：在运行时对对象进行分配的时候，首先置其所含的变量类型为空，那么当这个对象被一个指针所引用时，作者就可以根据其偏移来确定成员的类型了</p><h1 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h1><p>环境设置 64-bit Ubuntu 16.04 system 8-core Intel i7-7740X CPU (4.30GHz frequency) 32 GB RAM 作者分两步编译每个程序。 首先使用<a href="https://github.com/travitch/%20whole-program-llvm." target="_blank" rel="noopener">wllvm</a> 生成base binary和LLVM IR表示。其次，作者使用μCFI编译器来检测IR并生成受保护的可执行文件。两种编译都采用默认的优化级别和选项，例如，针对SPEC的O2和针对nginx和vsftpd的O1。 作者使用提供的训练数据集来评估SPEC基准。 对于nginx和vsftpd，作者在评估环境中设置服务器，并从同一本地网络中的另一台机器请求不同大小的文件。 作者执行每个文件1000次，以避免意外偏差。 为了测量开销，作者将监视器与受保护的执行文件一起启动，并计算所有进程退出的时间，包括受保护的执行文件，监视器及其子进程。 </p><p><img src="/2019/02/14/Enforcing-Unique-Code-Target-Property-for-Control-Flow-Integrity/evaluation_result.png" alt=""></p><p><img src="/2019/02/14/Enforcing-Unique-Code-Target-Property-for-Control-Flow-Integrity/realworld_exploits_prevention.png" alt=""></p><p>表3和表4总结了作者的评估结果。 μCFI成功地为测试程序实现了UCT属性，因为它只允许一个有效目标用于所有间接控制流传输（Q1）。 μCFI平均为评估的SPEC基准测试引入7.88％的运行时开销，nginx的运行时开销为4.05％，vsftpd（Q2）的开销不到1％。 这意味着μCFI可以通过强大的安全保障有效地保护这些程序。 所有攻击，包括现实中的攻击，COOP概念证明攻击和synthesized攻击，都会在运行时被阻止（Q3）。 使用μCFI和shadow stack编译的程序运行良好。 组合保护为SPEC基准测试带来了额外的2.07％开销，对nginx和vsftpd（Q4）的额外开销可忽略不计。</p><h2 id="Enforcing-UCT-Property"><a href="#Enforcing-UCT-Property" class="headerlink" title="Enforcing UCT Property"></a>Enforcing UCT Property</h2><p>在table 3 中可以看到，µCFI对于SPEC中的所有对象中的ICT均只给出了唯一确定的跳转对象(Allowed Target)，而这应归功于constrained data的作用</p><h2 id="Preventing-Attack"><a href="#Preventing-Attack" class="headerlink" title="Preventing Attack"></a>Preventing Attack</h2><p>作者还应用μCFI来保护PittyPat [21]中引入的易受COOP攻击的程序[55]。 COOP是一种通过构造C++的对象来利用其虚函数表的图灵完备攻击方法，COOP对粗粒度CFI构成了巨大挑战。 μCFI通过保护所有constrained data来防止COOP攻击，从而允许它准确地跟踪内存中的函数指针。当程序被输入恶意输入时，μCFI成功区分合法和伪造对象以检测攻击。</p><h2 id="Overhead-Measurement"><a href="#Overhead-Measurement" class="headerlink" title="Overhead Measurement"></a>Overhead Measurement</h2><p>Performance Overhead Optimization Possibility  PT的PTWrite指令可以直接打印用户数据到PT的TIP包中，μCFI可以利用其来记录BBID和constrained data，进一步提升效率。 Memory Overhead Code Overhead</p><h2 id="Shadow-Stack-Integration"><a href="#Shadow-Stack-Integration" class="headerlink" title="Shadow Stack Integration"></a>Shadow Stack Integration</h2><p>作者测量μCFI与parallel shadow stack（PSS）保护的兼容性。 作者使用μCFI编译器和PSS编译每个程序，并测量执行的正确性和性能开销。 所有测试程序（包括SPEC基准测试，nginx和vsftpd）都可以很好地与良性输入一起使用，证明了μCFI的强大兼容性。 集成PSS的开销显示在表3中的+stack列中。平均而言，PSS引入2.07％的开销来评估SPEC基准测试，且在对nginx和vsftpd的开销中可忽略不计。 通过展示μCFI与影子堆栈的兼容性，作者澄清了具有各种安全保证的任何替代解决方案如基于随机化的SafeStack [36]和基于硬件的Intel CET技术[33]，可以与μCFI集成以提供未来继续实现更好UCT属性的两个方向。</p><h1 id="Discussion"><a href="#Discussion" class="headerlink" title="Discussion"></a>Discussion</h1><p>在关于未来的工作中，作者提到两点： 1. 验证signal或exception中的CFI，这些与OS有关，在Intel PT中以FUP包形式记载 2. 验证动态加载的代码中的CFI</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h1&gt;&lt;p&gt;在这篇文章中，作者主要介绍了一种准确率更高的确保CFI的应用方式：Unique Code T
      
    
    </summary>
    
      <category term="论文" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/"/>
    
      <category term="软件分析" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90/"/>
    
    
      <category term="2018年" scheme="http://yama0xff.com/tags/2018%E5%B9%B4/"/>
    
      <category term="防护" scheme="http://yama0xff.com/tags/%E9%98%B2%E6%8A%A4/"/>
    
      <category term="CFI" scheme="http://yama0xff.com/tags/CFI/"/>
    
      <category term="ACM CCS’18" scheme="http://yama0xff.com/tags/ACM-CCS%E2%80%9918/"/>
    
  </entry>
  
  <entry>
    <title>Using Logic Programming to Recover C++ Classes and Methods From Compiled Executables</title>
    <link href="http://yama0xff.com/2019/02/14/Using-Logic-Programming-to-Recover-C-Classes-and-Methods-From-Compiled-Executables/"/>
    <id>http://yama0xff.com/2019/02/14/Using-Logic-Programming-to-Recover-C-Classes-and-Methods-From-Compiled-Executables/</id>
    <published>2019-02-14T09:36:20.000Z</published>
    <updated>2019-02-14T09:48:10.204Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>  随着计算机硬件的发展，计算机软件也变得越来越庞大、越来越复杂。而为了开发这些复杂的计算机软件，软件工程师们逐渐把方向转向了面向对象 OO（Object Oriented）的编程语言，例如 C++ 等高级开发语言。这些高级的编程语言，对于开发庞大、复杂的应用程序，它可以提供一种高级抽象的框架（Natural Framework），使得面向对象的编程语言更加适用于构造复杂的数据结构 — Class。类可以把相关的数据成员和一组对数据成员进行操作的方法绑定在一起，这样的绑定方式极大的方便了 C++ 代码的维护与管理，使得开发者更容易、更高效地开发复杂的应用程序。虽然类可以给开发者带来极大的便利，但是，万事万物总有两面性，类也一样，它给开发者带来便利的同时，也给软件逆向分析工程师带来了不便，使得分析师在分析 C++ 开发的程序的难度有所提高，特别是在分析恶意程序的时候，分析 C++ 开发的恶意程序变成了一项更高难度的挑战。因此，如何从恶意程序中恢复出代码的高级抽象特性（例如类等），成为了一项值得深究的工作。</p><table><thead><tr><th>relevant information</th><th></th></tr></thead><tbody><tr><td><em>作者</em></td><td>Edward J. Schwartz, Cory Cohen, Jeff Havrilla, Jeff Gennari, Charles Hines, Michael Duggan</td></tr><tr><td><em>单位</em></td><td>Carnegie Mellon University</td></tr><tr><td><em>出处</em></td><td>ACM CCS’18</td></tr><tr><td><em>原文地址</em></td><td><a href="https://github.com/wtwofire/database/blob/master/papers/reverse/2018-Using%20Logic%20Programming%20to%20Recover%20C%2B%2B%20Classes%20and%20Methods%20From%20Compiled%20Executables.pdf" target="_blank" rel="noopener">https://github.com/wtwofire/database/blob/master/papers/reverse/2018-Using%20Logic%20Programming%20to%20Recover%20C%2B%2B%20Classes%20and%20Methods%20From%20Compiled%20Executables.pdf</a></td></tr><tr><td><em>源码地址</em></td><td><a href="https://github.com/cmu-sei/pharos" target="_blank" rel="noopener">https://github.com/cmu-sei/pharos</a></td></tr><tr><td><em>发表时间</em></td><td>2018年</td></tr></tbody></table><h1 id="提出的方法以及解决的问题"><a href="#提出的方法以及解决的问题" class="headerlink" title="提出的方法以及解决的问题"></a>提出的方法以及解决的问题</h1><p>    基于上述的背景，作者提出了一种新的二进制分析工具 — OOAnalyzer，用于分析 C++ 所开发出来的程序，特别是针对恶意软件的分析，该工具可以起到很好的辅助作用，极大的方便了软件分析工程师对软件的分析，使得分析师在分析 C++ 程序的时候，可以快速的掌握程序中的相关类之间的关系（比如继承关系等），并且快速了解各个类内部的各个组成部分（例如方法、数据成员、虚函数表（VFTable）、构造函数与析构函数等）。</p><h1 id="技术方法"><a href="#技术方法" class="headerlink" title="技术方法"></a>技术方法</h1><p>    分析 C++ 所开发的应用程序，主要是分析出程序中的数据与方法之间的关系，即从二进制文件中恢复出程序的高级抽象结构 — 类。如果有办法可以很方便的从二进制文件中恢复出程序中类的结构，让分析者能够知道各个类之间的关系，并且知道类中所包含的方法、数据成员、虚函数表（VFTable）、构造函数与析构函数等信息，这就可以使得分析者很容易的分析出该程序所具有的功能与用途，并且快速掌握程序的执行过程，完成程序分析任务。很可惜的是，目前没有一个高效的工具能够实现这样的功能，因此，OOAnalyzer 就诞生了，它的目的就是从二进制文件中恢复出程序中类的结构，尽可能的恢复出每一个类之间的关系，以及各个类所包含的各种信息等。该工具是基于逆向工程师在逆向分析程序的时候所采用的一般步骤和方法，并把这些方法和步骤用代码来实现，使之能够自动化的帮助分析师分析程序，并且还可以实现大规模分析、分析大型应用程序（例如FireFox、MySQL等）等。该工具中所包含的核心方法有：</p><ul><li>在二进制代码中识别简单的模式（Patterns）；</li><li>基于这些模式，使用逻辑推理并结合相关领域的专业知识，甚至是一些直觉（Intuition）等方法来分析目标程序；</li><li>分析过程包括使用一个轻量级的符号执行引擎和一个基于 Prolog 的推理系统，把分析师的分析行为转化为代码的形式，集成在 OOAnalyzer 当中。</li></ul><p><img src="/2019/02/14/Using-Logic-Programming-to-Recover-C-Classes-and-Methods-From-Compiled-Executables/1.png" alt=""></p><p>                                 图 1： OOAnalyzer 的执行流程</p><p> 如图 1 所示是 OOAnalyzer 的执行流程，OOAnalyzer 的最终目标就是从一个 C++ 开发的可执行文件中恢复出 C++ 代码的抽象信息（类的相关信息）。对于一个 C++ 开发的可执行文件，OOAnalyzer 首先对它执行 Fact Exporter 操作，生成初始的 Facts（比如函数调用、带对象指针的方法调用、创建和使用对象等行为） — Initial Facts。这里的 Fact Exporter 使用的是一个轻量级的符号分析引擎（<a href="https://github.com/cmu-sei/pharos" target="_blank" rel="noopener">Pharos binary analysis framework</a>）来实现语义分析和反汇编等操作。这里得到的 Facts 虽然不是完全正确可信的，但是它是后序操作的基础，它也需要被后序的操作来证实和验证自己。</p><p>    第一步得到了基础的 Facts 之后，OOAnalyzer 把它当做一个 Fact base，并开始执行基于 Prolog 的推理模块，该模块包含三个核心组成部分：Forward Reasoning、 Hypothetical Reasoning 和 Consistency Checking。其中，Forward Reasoning 内部包含了一系列的规则，这些规则都是基于 Fact base，并且由一些<strong>前提条件</strong>（Precondition）和<strong>结论</strong>（Conclusion）组成，通过查找程序，只要找到满足所有前提条件的结构存在，就可以把相应的数据结构归结为某一个特定的结论（比如构造函数等），生成一个对应的 fact（此处称之为 Entity fact，包括方法，虚函数表，类之间的关系，类的大小等），并加入到 Fact base 中，如此来不断的扩大 Fact base。</p><p>    在 Forward Reasoning 推理过程中可能对某些情况无法做出判断（这种情况称之为：Ambiguous properties），因此需要 Hypothetical Reasoning 来辅助推理分析，这个 Hypothetical Reasoning 也是 OOAnalyzer 的最关键一个部分，有了这个模块，才使得 OOAnalyzer 的分析能力有了非常大的提高（平均错误率从 81% 下降到 21.8%）。OOAnalyzer 通过一些 Hypothetical Reasoning Rules 来猜测（Educated guess）这些不确定的属性（Ambiguous properties），提出一些 Guesses 和 Assumptions， 以使得 OOAnalyzer 在分析的过程中可以不间断的执行下去。</p><p>    经过前面两步操作之后，OOAnalyzer 已经得到了一个比较完整的 Fact base， 但是在这个 Fact base 中，可能会产生互相冲突的情况（因为 Hypothetical Reasoning 可能会做出错误的假设和猜测），因此，还需要做一个一致性的检查（Consistency Checking），以解决这些不一致的情况。这里的 Consistency Checking 会按照一些特定的规则，当检测到 Inconsistency 的时候，就开始从最近的一个猜测（Last guess）开始回退分析（backtrack）来检测并解决 Fact base 中产生的冲突和不一致的情况，使得最终得到的 Fact base 中的每一个 fact 都不会互相冲突。</p><p>    当前面的所有步骤都顺利完成，并且没有残留的 Inconsistency 和 Proposed Guess 的时候，OOAnalyzer 就会把这个最终的模型展示给分析者。</p><h1 id="实验评估"><a href="#实验评估" class="headerlink" title="实验评估"></a>实验评估</h1><p>    作者的实验环境是：使用单核的 Intel Xeon <a href="mailto:E5-2695@2.4Ghz" target="_blank" rel="noopener">E5-2695@2.4Ghz</a> 的 CPU ，并且配置了 256GB 的内存。主要评估 OOAnalyzer 对 C++ 类的识别与类中的方法（包括构造函数、析构函数、虚函数等）的识别，以及 OOAnalyzer 的时间与空间开销。作者评估 OOAnalyzer 所使用的测试集是 27 个 32 位的 PE 可执行程序，包括 18 个 Cleanware 和 9 个 Malware， 在 18 个 Cleanware 中，还包括了两个大型的应用程序： FireFox 和 MySQL。同时，作者使用编辑距离（Edit Distance）来衡量一个方法是否属于某一个具体的类。此外，为了证明测试结果的正确性，作者通过解析每一个程序的 PDB 文件（由 Visual C++ 产生的一个符号文件）来验证。</p><h2 id="1-编辑距离（Edit-Distance）"><a href="#1-编辑距离（Edit-Distance）" class="headerlink" title="1. 编辑距离（Edit Distance）"></a>1. 编辑距离（Edit Distance）</h2><p>    作者在文中使用一组方法来代表一个类，并且使用编辑距离来衡量 OOAnalyzer 产生的类与真正的类之间的距离，编辑距离就是：OOAnalyzer 产生的类通过多少步操作之后才能和真正的类完全一样，这里的操作包括：</p><ul><li>把一个方法从一个类移动到另一个类中</li><li>向 OOAnalyzer 产生的类中添加一个方法（OOAnalyzer 未能正确识别的方法）</li><li>把 OOAnalyzer 产生的类中的一个方法移除（OOAnalyzer 错误的把它当做类的方法）</li><li>任意的分割一个类为两个类</li><li>合并两个单独的类为一个类</li></ul><p><img src="/2019/02/14/Using-Logic-Programming-to-Recover-C-Classes-and-Methods-From-Compiled-Executables/2.png" alt=""></p><p>​                              表 1：OOAnalyzer 产生的类的准确度</p><p>如表 1 所示（w/o 表示 Without），是 OOAnalyzer 产生的类的准确度，通过 Edit Distance 来衡量，Edit Distance 越小越好，表明 OOAnalyzer 产生的类越接近真实的类。由图中可知，RTTI（Runtime Type Identification，多态类才有该信息，包括类名称和基类信息等）对 OOAnalyzer 的影响很小，几乎可以忽略不计，而 guess（也就是前文所说的：Hypothetical Reasoning） 对 OOAnalyzer 的影响是极大的，去掉该功能之后（w/o guess），OOAnalyzer 的错误率从 21.8% 直接提升到 81%。</p><h2 id="2-方法属性"><a href="#2-方法属性" class="headerlink" title="2. 方法属性"></a>2. 方法属性</h2><p>    类成员包括构造函数、析构函数、虚函数表和虚方法等，而类成员恢复的比例是衡量 OOAnalyzer 的一项最关键的指标，标志着 OOAnalyzer 的性能好坏，如表 2 所示是 OOAnalyzer 在没有 RTTI 信息的情况下，对类成员恢复的召回率（Recall）和精确度（Precision），在表中，蓝色标志表示 Recall 或者 Precision 大于 0.75， 而红色表示 Recall 或者 Precision 小于 0.25。Recal 表示在 Ground True 中 OOAnalyzer 所能检测出来的方法数量，而 Precision 表示 OOAnalyzer 所检测出来的数量中，有多少个是正确的。 从表中可以看出，大部分检测结果都在 80% 以上，只有析构函数的恢复率比较低，表明析构函数比较难于检测和恢复，因为它经常会被编译器所优化。</p><p><img src="/2019/02/14/Using-Logic-Programming-to-Recover-C-Classes-and-Methods-From-Compiled-Executables/3.png" alt=""></p><h3 id="3-时间与空间开销"><a href="#3-时间与空间开销" class="headerlink" title="3. 时间与空间开销"></a><strong>3. 时间与空间开销</strong></h3><p>    OOAnalyzer 的时间开销在 30 秒到 22.7 个小时之间，平均开销为 2.3 小时， 但中位数（median）为 0.2 小时（因为大部分程序的时间开销都比较小，只有少部分程序的时间开销比较大，导致平均时间开销偏大）。OOAnalyzer 的空间开销在 41.3MB 到 3.5GB 之间，平均为 1.0GB， 中位数为 0.7GB。</p><h1 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h1><h2 id="优点："><a href="#优点：" class="headerlink" title="优点："></a><strong>优点：</strong></h2><ul><li>OOAnalyzer 不但可以恢复出具有多态形式的类的相关信息，还可以恢复出非多态类中的相关信息。</li><li>OOAnalyzer 不需要依赖于 RTTI 和 VFTable 会恢复类。</li><li>OOAnalyzer 对类的构造函数、成员方法和虚函数表的恢复效果非常好，平均准确度达到88% 以上。</li><li>OOAnalyzer 是 ObjDigger 的升级版本，它相比于 ObjDigger 的主要优势就在于 Hypothetical Reasoning 模块，该模块极大的减少了 OOAnalyzer 的错误率。</li></ul><h2 id="缺点："><a href="#缺点：" class="headerlink" title="缺点："></a><strong>缺点：</strong></h2><ul><li>由于编译器优化等原因（比如编译器内联某些函数等），可能对优化之后的程序的的分析效果不是很好，甚至是失效。</li><li>正常情况下，类中的方法调用都会采用 ecx 寄存器来传递 this 指针，但是，可能会存在很多无法判断的情况，例如，某些编译器可能不是使用 ecx 寄存器来传递对象指针，或者有时候编译器刚好就是用 ecx 寄存器来传递对象指针，但是调用的是一个普通的函数，而不是一个类中的方法等，这时候就会导致 OOAnalyzer 分析不准确。</li><li>OOAnalyzer 对析构函数的恢复效果依然不是很好。</li><li>OOAnalyzer 对于普通的程序分析效果还不错，但是对于一般的恶意软件，都会使用加壳等方法来保护自己，或者是减少自己的体积，在这种情况下，OOAnalyzer就无法使用了。</li><li>如果程序编译的时候开启了 Whole Program Optimization（WPO），则会导致 OOAnalyzer 的规则无法正常工作。</li><li>如果在不同的类中出现了相同的方法，则 OOAnalyzer 也可能会误以为它们是同一个类。</li><li>对于不可达的函数， OOAnalyzer 也无法执行分析。</li><li>由于静态的符号执行本身所具有的缺陷所导致 OOAnalyzer 分析不准确。</li></ul><h1 id="六、个人观点"><a href="#六、个人观点" class="headerlink" title="六、个人观点"></a>六、个人观点</h1><p>    作者在文中介绍的这款工具（OOAnalyzer），是一款功能强大的 C++ 高级语言抽象结构（Class）恢复工具，相比于其它的工具（例如 Lego、SmartDec等）具有很多的优势，例如 OOAnalyzer 不但可以恢复多态类中的信息，而且还可以恢复非多态类中的信息（Lego 则不行），OOAnalyzer 不需要依赖 RTTI 的相关信息（即使有 RTTI 的相关信息，对 OOAnalyzer 的作用也不大）。OOAnalyzer 不但可以恢复 C++ 程序中的各个类之间的关系（例如继承关系），而且还可以恢复各个类内部的相关信息（包括 构造函数、析构函数、虚函数表和虚拟函数等），其中，OOAnalyzer 对虚函数表的恢复效果最佳，准确度达到 99%，但是对于析构函数却略显不足。总之，这对于我们分析 C++ 程序提供了很大的帮助，能够给我们提供很多有用的信息，特别是对于我们逆向一些由 C++ 开发的恶意程序，能够让我们方便的了解到恶意程序内部的构造，可以提高我们的对恶意程序的分析效率。当然，这款工具也有很多可以改进的地方，例如，它对析构函数的识别效果不佳，对于编译器优化之后的程序的分析效果也没有这么理想。通过阅读这篇文章，我们还可以了解到它的过去版本 — ObjDigger，而 OOAnalyzer 就是在 ObjDigger 中添加了 Hypothetical Reasoning 之后形成的。此外，从文章中的相关链接（该项目的Github链接）还可以了解到，该工具只是 Pharos 项目中的一个组成部分，或者说是 Pharos 项目中的一个小插件，就像是 Clang StaticAnalyzer 是 LLVM 项目的一个小插件一样。最后，文章的难点在于 Prolog-Base 推理系统。个人觉得，作者在文章中写的规则说明的不是很到位，或者解释的不是很清楚。</p><p>​                                                                                              <strong><em>转载于GoSSIP</em></strong></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h1&gt;&lt;p&gt;  随着计算机硬件的发展，计算机软件也变得越来越庞大、越来越复杂。而为了开发这些复杂的计算机
      
    
    </summary>
    
      <category term="论文" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/"/>
    
      <category term="软件分析" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90/"/>
    
    
      <category term="2018年" scheme="http://yama0xff.com/tags/2018%E5%B9%B4/"/>
    
      <category term="ACM CCS&#39;18" scheme="http://yama0xff.com/tags/ACM-CCS-18/"/>
    
      <category term="静态符号执行、" scheme="http://yama0xff.com/tags/%E9%9D%99%E6%80%81%E7%AC%A6%E5%8F%B7%E6%89%A7%E8%A1%8C%E3%80%81/"/>
    
      <category term="逆向" scheme="http://yama0xff.com/tags/%E9%80%86%E5%90%91/"/>
    
      <category term="二进制分析工具" scheme="http://yama0xff.com/tags/%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7/"/>
    
  </entry>
  
  <entry>
    <title>Towards Paving the Way for Large-Scale Windows Malware Analysis: Generic Binary Unpacking With Orders-of-Magnitude Performance Boost</title>
    <link href="http://yama0xff.com/2019/02/14/Towards-Paving-the-Way-for-Large-Scale-Windows-Malware-Analysis-Generic-Binary-Unpacking-With-Orders-of-Magnitude-Performance-Boost/"/>
    <id>http://yama0xff.com/2019/02/14/Towards-Paving-the-Way-for-Large-Scale-Windows-Malware-Analysis-Generic-Binary-Unpacking-With-Orders-of-Magnitude-Performance-Boost/</id>
    <published>2019-02-14T07:51:11.000Z</published>
    <updated>2019-02-14T08:29:19.648Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>windows的软件脱壳本来已经在多年前已经被讨论得非常多了，目前安全学术会议上关于脱壳的论文非常少，然而这篇关于脱壳的论文还能在2018年被CCS所录取，足见他的方法之高效。此前关于脱壳的方法大多是跟踪脱壳时期的内存代码写入执行的变化，从而跟踪被加密代码的解密流程从而追溯到OEP。这也是对于分析脱壳的一个最为直观的方法，<strong><em>在这篇论文里作者提出来通过跟踪IAT(函数导入表)被恢复和引用的情况来追溯OEP，并且达到很理想的效果。作者将这款工具称为BinUnpack。</em></strong></p><table><thead><tr><th>relevant information</th><th></th></tr></thead><tbody><tr><td><em>作者</em></td><td>Binlin Cheng , Jiang Ming, Jianming Fu, Guojun Peng, Ting Chen, Xiaosong Zhang , Jean-Yves Marion</td></tr><tr><td><em>单位</em></td><td>Wuhan University , Hubei Normal University, University of Texas at Arlington, University of Electronic Science and Technology of China, LORIA</td></tr><tr><td><em>出处</em></td><td>ACM CCS’18</td></tr><tr><td><em>原文地址</em></td><td><a href="https://github.com/wtwofire/database/blob/master/papers/reverse/2018-Towards%20Paving%20the%20Way%20for%20Large-Scale%20Windows%20Malware%20Analysis%20Generic%20Binary%20Unpacking%20With%20Orders-of-Magnitude%20Performance%20Boost.pdf" target="_blank" rel="noopener">https://github.com/wtwofire/database/blob/master/papers/reverse/2018-Towards%20Paving%20the%20Way%20for%20Large-Scale%20Windows%20Malware%20Analysis%20Generic%20Binary%20Unpacking%20With%20Orders-of-Magnitude%20Performance%20Boost.pdf</a></td></tr><tr><td><em>源码地址</em></td><td></td></tr><tr><td><em>发表时间</em></td><td>2018年</td></tr></tbody></table><h1 id="IAT在脱壳中角色"><a href="#IAT在脱壳中角色" class="headerlink" title="IAT在脱壳中角色"></a>IAT在脱壳中角色</h1><p>IAT即为PE文件中的函数地址导入表，加壳软件会在对一个软件进行加壳时将IAT抹去，然后在运行解密时通过LoadLibrary和GetProcess两函数或者功能相同的函数再恢复，最后将控制权移交OEP。解密代码为了满足自身需要，通常也有一个自己的IAT，但是与原IAT位置并不在同一内存区域中，通常这个IAT的导入函数个数也要小得多，甚至只有一两个。作者的思路是，一旦某个函数调用是通过原IAT进行的，那么就表明这个时候，原代码已经完成了解密，这个时候往前回溯，即可找到OEP。</p><h1 id="Anti-Hook"><a href="#Anti-Hook" class="headerlink" title="Anti-Hook"></a>Anti-Hook</h1><p>为了跟踪函数的调用情况，hook是必不可少的，然而现在的加壳软件大多会检测函数hook并且存在许多反hook机制，这里记录一下加壳软件中用到的anti-hook方法。</p><p>首先Hook分为内核hook与用户层Hook,由于现在恶意软件想要加载内核模块越发困难，所以作者并没有考虑内核hook情况，这篇论文里，作者假设内核是安全的，未被加壳软件所修改。</p><p>用户层Hook分为以下几种：</p><ol><li>Stolen code. 即将所需要调用的函数代码从内存或者直接从文件系统中复制出来单独执行，这样.inlinehooke,iat,eat类型的Hook全部失效。</li><li>Child process,process hollowing.将脱壳行为分解到两个进程中进行，这样由于进程地址空间隔离，父进程hook全部失效。</li><li>Crash hooking module. 给api函数故意传入错误的参数，如果函数被Hook,则不能正确处理错误而程序崩溃 ，没有被Hook则能正确处理异常。以此可以检测是否被hook。</li><li>Integrity check. 使用哈希校验所调用模块的完整性。</li></ol><h1 id="Anti-anti-hook"><a href="#Anti-anti-hook" class="headerlink" title="Anti-anti-hook"></a>Anti-anti-hook</h1><p>作者设计了一个内核用户态混合的dll劫持系统来完成对函数的hook。作者通过逆向Loadlibrary发现，在内核中它最终需要将dll映射到进程的地址空间，而使用的内核函数是LdrMapDll。函数流程如下：</p><p><img src="/2019/02/14/Towards-Paving-the-Way-for-Large-Scale-Windows-Malware-Analysis-Generic-Binary-Unpacking-With-Orders-of-Magnitude-Performance-Boost/1.png" alt=""></p><p>作者修改内核使得NtMapViewOfSection加载定制的Hook版本dll，同时使得返回值变为STATUS_IMAGE_NOT_AT_BASE。这样第16行的NtMapViewOfSection也会被执行，这样定制的dll被加载进内存。另外有些加壳作者并不使用内存映射进行加载dll，而是使用读取文件如readfile读取dll，复制到内存，这样作者同样修改内存中这部分代码，使得加载的dll为定制的dll。</p><p>这样做能防住上述的提到的几种方法的anti-hook：</p><ol><li>Stolen code. 由于被加载时已经是被定制的dll，或者从文件系统读时都是被定制的dll，所以stolen code复制的代码依然是改变后的hook代码。</li><li>Child process,process hollowing. 同理，修改内核对于每个进程都生效。</li><li>Crash hooking module。这点作者认为正确处理了异常，存疑。</li><li>Integrity check。作者说借鉴使用了一种别人的方法，使得读取dll时读到的内容为原dll，执行时执行的是定制的dll，具体方法待研究。</li></ol><h1 id="Find-OEP"><a href="#Find-OEP" class="headerlink" title="Find OEP"></a>Find OEP</h1><p><img src="/2019/02/14/Towards-Paving-the-Way-for-Large-Scale-Windows-Malware-Analysis-Generic-Binary-Unpacking-With-Orders-of-Magnitude-Performance-Boost/2.png" alt=""></p><p>在结合了IAT与dll hijacking之后，寻找OEP的过程可以用上图来进行表示，首先进程加载时，加载的dll，包括系统dll，如Kernel32.dll,user32.dll等都被换成了作者定制的带hook版本。脱壳时一旦检测到某个函数调用来自原IAT，则进行回溯查找OEP及内存dump。由于可能存在加多个壳情况，即可能会更换IAT，但是这个IAT并不属于最开始被加壳的程序而是属于内层壳，这里作者的作法是，当切换IAT时则进行dump和回溯操作。</p><p><img src="/2019/02/14/Towards-Paving-the-Way-for-Large-Scale-Windows-Malware-Analysis-Generic-Binary-Unpacking-With-Orders-of-Magnitude-Performance-Boost/3.png" alt=""></p><h1 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h1><p>实验环境：laptop with an Intel Core i3-36100 processor (Quad Core,3.70GHz) and 8GB memory, running Windows 7.</p><p>作者使用VirusTotal检测结果来作为脱壳效果的检测结果。即对于一个不加壳的恶意软件，VirusTotal检测结果为n，被脱壳的检测结果越接近n则说明脱壳效果越好。</p><p>作者利用一款未被加壳的恶意软件hupigon.eyf，并用不同的壳对他进行加密，然后使用CoDisasm, PinDemonium, Arancino, BinUnpack四款脱壳工具进行脱壳。结果送VirusTotal进行检测，并记录脱壳所用到的时间。</p><p><img src="/2019/02/14/Towards-Paving-the-Way-for-Large-Scale-Windows-Malware-Analysis-Generic-Binary-Unpacking-With-Orders-of-Magnitude-Performance-Boost/4.png" alt=""></p><p>从图中可以看到，BinUpack的检测结果要远远高于其他三种脱壳工具。另外脱壳所用的到时间也缩短了一两个数量级。对于同一个软件加多个不同的壳，BinUpack的表现依然很出色，脱壳时间始终小于1s。而面对商业强壳Themida时，BinUnpack表现依然良好，VirusTotal检测结果能达到33，34这个级别，而其他三种壳都没有脱壳成功。</p><p>最后作者收集了271095个恶意软件进行测试，依然表现不俗。</p><h1 id="评价"><a href="#评价" class="headerlink" title="评价"></a>评价</h1><p>这篇论文对于脱壳来说实在是一篇不可多得好的好文。我觉得他的主要贡献在于出发点十分新颖，就在大家都认为脱壳方向已经被讨论得差不多的时候，能够另辟蹊径从IAT出发，合理的运用各种已知的成果。最终达到非常好的效果，这是非常难得的。另外关于这篇论文里面所提到的各种关于脱壳方面的知识，对于逆向人员来说也是一个非常不错的参考。对于文章里唯一有点不解的地方在于内核的hook，具体为如何去做这个Hook，要不要载原dll，参数怎么改，能写得更清楚就好了。另外有一点疑惑在于，如果一个壳故意的通过原IAT进行伪造的函数调用，那么，在检测到这种IAT调用时，可能原代码并未解密，那么这种情况我觉得论文里面没有很好的阐述，只是提到只要需要多次检测，但是检测只是发生在IAT切换的时候，伪造调用时发现IAT切换，但是代码并未解密，而后IAT不会切换，那么，何时进行检测呢？</p><p>​                                                                            <strong><em>转载于GoSSIP</em></strong></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h1&gt;&lt;p&gt;windows的软件脱壳本来已经在多年前已经被讨论得非常多了，目前安全学术会议上关于脱壳的论
      
    
    </summary>
    
      <category term="论文" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/"/>
    
      <category term="软件分析" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90/"/>
    
    
      <category term="2018年" scheme="http://yama0xff.com/tags/2018%E5%B9%B4/"/>
    
      <category term="ACM CCS&#39;18" scheme="http://yama0xff.com/tags/ACM-CCS-18/"/>
    
      <category term="脱壳" scheme="http://yama0xff.com/tags/%E8%84%B1%E5%A3%B3/"/>
    
  </entry>
  
  <entry>
    <title>HEAPHOPPER: Bringing Bounded Model Checking to Heap Implementation Security</title>
    <link href="http://yama0xff.com/2019/02/14/HEAPHOPPER-Bringing-Bounded-Model-Checking-to-Heap-Implementation-Security/"/>
    <id>http://yama0xff.com/2019/02/14/HEAPHOPPER-Bringing-Bounded-Model-Checking-to-Heap-Implementation-Security/</id>
    <published>2019-02-14T02:01:28.000Z</published>
    <updated>2019-02-14T02:31:15.088Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>堆元数据攻击已成为攻击者利用内存损坏漏洞的主要方式之一。虽然堆实现开发人员已经引入了缓解来防止和检测损坏，但攻击者仍然可以解决这些问题。在某种程度上，这是因为这些缓解是在没有原则基础的情况下创建和评估的，因此在许多情况下会导致堆元数据防御的复杂，低效和无效尝试。<strong><em>在本文中，我们提出了HEAPHOPPER，一种基于模型检查和符号执行的自动化方法，用于分析存在内存损坏时堆实现的可利用性。</em></strong>使用HEAPHOPPER，我们能够对不同的，广泛使用的堆实现进行系统分析，找到它们中令人惊讶的弱点。例如，我们的结果显示了ptmalloc中新引入的缓存机制（大多数Linux发行版使用的堆分配器实现）如何显著削弱其安全性。此外，HEAPHOPPER指导我们实施和评估对ptmalloc安全性的改进，用有效防御替代最近无效的缓解特定形式的堆元数据损坏的尝试。</p><table><thead><tr><th>relevant information</th><th></th></tr></thead><tbody><tr><td><em>作者</em></td><td>Moritz Eckert , Antonio Bianchi, Ruoyu Wang, Yan Shoshitaishvili , Christopher Kruegel , and Giovanni Vigna</td></tr><tr><td><em>单位</em></td><td>University of California, Santa Barbara, The University of Iowa, Arizona State University</td></tr><tr><td><em>出处</em></td><td>USENIX Security‘18</td></tr><tr><td><em>原文地址</em></td><td><a href="https://github.com/wtwofire/database/blob/master/papers/exploitation/2018-HEAPHOPPER%20Bringing%20Bounded%20Model%20Checking%20to%20Heap%20Implementation%20Security.pdf" target="_blank" rel="noopener">https://github.com/wtwofire/database/blob/master/papers/exploitation/2018-HEAPHOPPER%20Bringing%20Bounded%20Model%20Checking%20to%20Heap%20Implementation%20Security.pdf</a></td></tr><tr><td><em>源码地址</em></td><td><a href="https://github.com/angr/heaphopper" target="_blank" rel="noopener">https://github.com/angr/heaphopper</a></td></tr><tr><td><em>发表时间</em></td><td>2018年</td></tr></tbody></table><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>作者通过使用符号执行技术，自动化分析堆分配器，根据配置文件定义的情况可以自动生成不同exploitation primitive 的POC</p><p><img src="/2019/02/14/HEAPHOPPER-Bringing-Bounded-Model-Checking-to-Heap-Implementation-Security/1.png" alt=""></p><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>当程序逻辑存在漏洞时可以攻击堆分配器拿到程序控制权。为了缓解这些攻击，各大堆分配器都在内部进行了安全检查，然而并没有一个标准能评估加入一个补丁是否能缓解攻击。</p><p>以glibc的补丁为例</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment">/* Take a chunk off a bin list */</span></span><br><span class="line"> <span class="meta">#<span class="meta-keyword">define</span> unlink(AV, P, BK, FD) &#123;                                            \</span></span><br><span class="line">+    <span class="keyword">if</span> (__builtin_expect (chunksize(P) != prev_size (next_chunk(P)), <span class="number">0</span>))      \</span><br><span class="line">+      malloc_printerr (check_action, <span class="string">"corrupted size vs. prev_size"</span>, P, AV);  \</span><br><span class="line">     FD = P-&gt;fd;                                                                      \</span><br><span class="line">     BK = P-&gt;bk;                                                                      \</span><br><span class="line">     <span class="keyword">if</span> (__builtin_expect (FD-&gt;bk != P || BK-&gt;fd != P, <span class="number">0</span>))</span><br></pre></td></tr></table></figure><p>补丁作者加入了一个对size的检查，然而这可以被轻松的绕过，具体利用见</p><p><a href="https://github.com/shellphish/how2heap/blob/master/glibc_2.26/poison_null_byte.c" target="_blank" rel="noopener">poison_null_byte.c</a></p><p>因此作者通过符号执行技术对堆的交互进行了建模，从而可以自动化的评估堆分配器在特定情况下达到exploitation primitive的条件。</p><h1 id="生成堆交互模型"><a href="#生成堆交互模型" class="headerlink" title="生成堆交互模型"></a>生成堆交互模型</h1><h2 id="堆事务"><a href="#堆事务" class="headerlink" title="堆事务"></a>堆事务</h2><p>作者将会修改堆的状态的操作定义为事务，对堆的交互分为两种：直接交互和间接交互</p><p>直接交互指分配器功能，如malloc，free</p><p>间接交互指修改分配的内存区域，比如overflow</p><h3 id="malloc-M"><a href="#malloc-M" class="headerlink" title="malloc(M)"></a>malloc(M)</h3><p>HEAPHOPPER 通过传递一个符号化变量对malloc申请的大小进行建模。</p><p>一个不可约束的值可能会导致路径爆炸和约束复杂，因此将大小设置为了一个具体的范围，因此符号执行单元将会使用symbolic-but-constrained 变量作为传递给malloc的参数。</p><p>通常根据堆分配器不同的执行路径来确定大小，作者开发了一个工具根据libc的执行路径来确定大小选择（然而并没有看见这个工具，源码里面也有提及）。</p><h3 id="free-F"><a href="#free-F" class="headerlink" title="free(F)"></a>free(F)</h3><p>如果之前执行过多个malloc事务，HEAPHOPPER将会生成一个不同的序列将其中的每一个作为free事务的参数</p><h3 id="overflow-O"><a href="#overflow-O" class="headerlink" title="overflow(O)"></a>overflow(O)</h3><p>在模型中，一个overflow代表一个和堆的间接的交互。作者通过在malloc出的chunk的末尾插入符号内存来实现overflow。和free事务类似，HEAPHOPPER将会为先前分配的chunk创建一个不同的序列作为overflow的目标。和malloc同样的原因，需要限制溢出的长度。在这将会把overflow的大小作为symbolic-but-constrained 处理。HEAPHOPPER 还支持根据不同的场景将overflow的字节设定为特定的范围。</p><h3 id="use-after-free-UAF"><a href="#use-after-free-UAF" class="headerlink" title="use-after-free (UAF)"></a>use-after-free (UAF)</h3><p>我们通过将符号内存写入已经free的chunk作为UAF事务。和之前的事务相似，HEAPHOPPER需要为之前free过的chunk创建一个不同的序列，将有限的字节的数据写到内存中。</p><h3 id="double-free-DF"><a href="#double-free-DF" class="headerlink" title="double-free (DF)"></a>double-free (DF)</h3><p>double-free被建模为对之前释放过的内存执行free</p><h3 id="fake-free-FF"><a href="#fake-free-FF" class="headerlink" title="fake-free (FF)"></a>fake-free (FF)</h3><p>fake-free是释放一个假的，攻击者自定义的chunk。它被建模为free一个完全符号化的内存区域。这个符号化区域的大小必须有个限制。如果可能的话，符号执行单元将会自动确定符号区域的值能通过堆分配器的检查。</p><h3 id="堆交互模型"><a href="#堆交互模型" class="headerlink" title="堆交互模型"></a>堆交互模型</h3><p>HEAPHOPPER 将结合之前描述的堆事务生成一个交互列表，每个交互对应着堆模型的一条路径。HEAPHOPPER 通过创建所有可能的事务序列的排列来生成交互列表。</p><p>在这一步主要关注如何减少生成的事务序列而不丢失会导致产生exploitation primitives 的事务序列。因此，我们假设至少一次对堆进行了误操作（直接或间接），并且假设对堆的良性使用不会产生任何问题。此外，还排除了只有一个间接交互作为事务序列结束的情况，因为间接交互无法修改堆本身，修改堆本身至少需要一个直接交互。两个会对同一区域放置符号内存的的事务之间必须有影响这片内存的事务。</p><h1 id="模型检测"><a href="#模型检测" class="headerlink" title="模型检测"></a>模型检测</h1><h2 id="识别安全违规行为"><a href="#识别安全违规行为" class="headerlink" title="识别安全违规行为"></a>识别安全违规行为</h2><h3 id="Overlapping-Allocation-OA"><a href="#Overlapping-Allocation-OA" class="headerlink" title="Overlapping Allocation (OA)"></a>Overlapping Allocation (OA)</h3><p>HEAPHOPPER 使用 SMT求解程序去判断如下条件是否为真</p><p>∃B : ((A ≤ B)∧(A+sizeof(A) &gt; B))∨((A ≥ B)∧(B+sizeof(B) &gt; A))</p><p>A为申请的内存，B为已申请的内存</p><h3 id="Non-Heap-Allocation-NHA"><a href="#Non-Heap-Allocation-NHA" class="headerlink" title="Non-Heap Allocation (NHA)"></a>Non-Heap Allocation (NHA)</h3><p>提前记录堆分配器使用brk和mmap返回的地址，从而确定堆的范围</p><h3 id="Arbitrary-Write-AW-and-AWC"><a href="#Arbitrary-Write-AW-and-AWC" class="headerlink" title="Arbitrary Write (AW and AWC)"></a>Arbitrary Write (AW and AWC)</h3><p>在调用malloc，free时通过检测符号内存区域是否有写入来判断是否有AW或AWC。具体来说,我们查询约束求解器检查是否可以指定的写入特定的内存区域。</p><h1 id="局限性"><a href="#局限性" class="headerlink" title="局限性"></a>局限性</h1><h2 id="模型限制"><a href="#模型限制" class="headerlink" title="模型限制"></a>模型限制</h2><p>当前情况下需要手动指定攻击者可以执行的事务。HEAPHOPPER无法对可能发生但是HEAPHOPPER中没有实现的攻击场景进行推理。之前为了减少符号执行样本的数量加入了一些限制条件，这可能会导致HEAPHOPPER错过一些利用。其次一些攻击需要执行很多事务才能把堆设置为理想的状态</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h1&gt;&lt;p&gt;堆元数据攻击已成为攻击者利用内存损坏漏洞的主要方式之一。虽然堆实现开发人员已经引入了缓解来防
      
    
    </summary>
    
      <category term="论文" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/"/>
    
      <category term="自动化利用" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/%E8%87%AA%E5%8A%A8%E5%8C%96%E5%88%A9%E7%94%A8/"/>
    
    
      <category term="2018年" scheme="http://yama0xff.com/tags/2018%E5%B9%B4/"/>
    
      <category term="exploitation" scheme="http://yama0xff.com/tags/exploitation/"/>
    
      <category term="heap" scheme="http://yama0xff.com/tags/heap/"/>
    
      <category term="符号执行" scheme="http://yama0xff.com/tags/%E7%AC%A6%E5%8F%B7%E6%89%A7%E8%A1%8C/"/>
    
      <category term="USENIX&#39;18" scheme="http://yama0xff.com/tags/USENIX-18/"/>
    
  </entry>
  
  <entry>
    <title>Check It Again: Detecting Lacking-Recheck Bugs in OS Kernels</title>
    <link href="http://yama0xff.com/2019/02/05/Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels/"/>
    <id>http://yama0xff.com/2019/02/05/Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels/</id>
    <published>2019-02-05T11:05:47.000Z</published>
    <updated>2019-02-14T08:32:06.516Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>论文中，作者主要介绍分析操作系统内核中的LRC（lacking-recheck）类型bug。并介绍了自己设计的一个静态分析系统LRSan（在Linux上实现），用于检测操作系统内核中的LRC bug。<strong><em>本文的主要贡献： 1. 定义了LRC bugs，并第一次展示了关于LRC bug的深入研究。 2. 实现一个自动化的LRC bug检测系统（LRSan），基于LLVM，使用在Linux内核上，可以检测内核中的LRC bug。LRSan运用了很多新的程序静态分析技术。结果显示LRSan在Linux内核发现了2808个LRC case，检测耗时为4小时。并且作者会将它开源。 3. 识别Security check（SC）和相关Critical variable（CV）的方法。 4. 发现了Linux内核中的19个新的LRC bug。</em></strong></p><table><thead><tr><th>relevant information</th><th></th></tr></thead><tbody><tr><td><em>作者</em></td><td>Wenwen Wang, Kangjie Lu, and Pen-Chung Yew</td></tr><tr><td><em>单位</em></td><td>University of Minnesota</td></tr><tr><td><em>出处</em></td><td>ACM CCS’18</td></tr><tr><td><em>原文地址</em></td><td></td></tr><tr><td><em>源码地址</em></td><td></td></tr><tr><td><em>发表时间</em></td><td>2018年</td></tr></tbody></table><h1 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h1><p>如下图所示是LRC Bug形成的流程。</p><p><img src="/2019/02/05/Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels/E:/github\hexo\source\_posts\Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels\1.jpg" alt=""></p><p>如下图所示是一个LRC Bug的例子，其中的val就是<em>CV</em>。在第10行中val被进行了security check，但是在第16至19行中val被进行了修改，在第22行中val又被使用了，然而在使用前没有进行recheck。</p><p><img src="/2019/02/05/Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels/E:/github\hexo\source\_posts\Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels\2.jpg" alt=""></p><p>LRC bug的特点： – 拥有一个check-use chain。即执行路径中有对变量进行安全检查，并在之后对变量进行使用。 – 变量有被修改的可能. 变量在过了前面的security check后，在check-use chain中被修改。 – 缺少recheck。在变量过了安全检查后，如果在使用前又进行了安全检查，那即是在中间被修改了，也是安全的。因此缺少recheck也是LRC bug的成因之一。</p><p>作者在文章中还具体符号化定义了Security check、Use、Modification、Lacking recheck。</p><h2 id="1-1-Security-check"><a href="#1-1-Security-check" class="headerlink" title="1.1 Security check"></a>1.1 Security check</h2><p>Security check需要满足两个条件（作者通过观察总结的规律）才能被认定为是Security check： – 拥有一个条件语句，紧随其后的是两个分支：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">一个分支肯定会返回error code（condition 1）</span><br><span class="line">另一个分支有可能不返回error code（condition 2）</span><br></pre></td></tr></table></figure><h2 id="1-2-Modification1"><a href="#1-2-Modification1" class="headerlink" title="1.2 Modification1"></a>1.2 Modification1</h2><p>在执行路径上，通常变量的的security check和使用是比较复杂也可能比较远的，尤其是在处理涉及到用户空间和内核空间的多个变量时，因此LRC Bug在操作系统内核中是很常见的。</p><p>对security-checked变量的修改可能由如下一些情况导致： 1. Kernel race：操作系统内核通常为线程进程维护了很多共享的数据结构。通常来说很难保证Security checked variable不被修改。 2. User race：从用户空间抓取数据通常很容易被通过用户空间的多进程来进行修改。 3. Logic errors：一些逻辑问题可能导致线程本身不正确地将security-checked variable给修改了。 4. Semantic errors：例如类型转换和整数溢出的一些语义错误可能导致security-checked variable被修改。</p><h1 id="2-LRSan设计"><a href="#2-LRSan设计" class="headerlink" title="2. LRSan设计"></a>2. LRSan设计</h1><p>LRSan的整个结构和Workflow如下图所示，输入为内核源码编译后的LLVM IR。LRSan预处理时会构建一个全局的call-graph，用来进行inter-procedural analysis，并且标注了error codes。</p><p><img src="/2019/02/05/Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels/E:/github\hexo\source\_posts\Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels\3.jpg" alt=""></p><p>LRsan设计的4个关键部分： 1. Security check identification 2. Critical variable inference 3. check-use chain construction 4. modification inference。</p><h2 id="2-1-Automated-Security-Check-Identification"><a href="#2-1-Automated-Security-Check-Identification" class="headerlink" title="2.1 Automated Security Check Identification"></a>2.1 Automated Security Check Identification</h2><p>作者将security check认为是一个条件语句（例如if语句）。因此检测Secruity check就是查找这样的条件语句。</p><ol><li>搜集所有的error code，构建一个error-code CFG（ECFG），ECFG可以快速地判断出某一个执行路径是否会返回error code。ECFG的示例如下图所示。</li><li>通过前面提到的两个判断Security check的条件，来决定找到的条件语句是否是Security check。</li></ol><p><img src="/2019/02/05/Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels/E:/github\hexo\source\_posts\Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels\4.jpg" alt=""></p><h2 id="2-2-Recursive-Critical-Variable-Inference"><a href="#2-2-Recursive-Critical-Variable-Inference" class="headerlink" title="2.2 Recursive Critical Variable Inference"></a>2.2 Recursive Critical Variable Inference</h2><p>在前面的步骤中可以得到一个Security check set，通过这个set能直接得到Critcal variable set(CSet)，然后再通过CSet去找到更多的<em>CV</em>，查找的原则是越多越好（更少的假阴性，这里用的是反向的污点分析）。</p><p>例如下图，hdr是最先找到的<em>CV</em>，然后又将arg和buf都标记为<em>CV</em>。</p><p><img src="/2019/02/05/Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels/E:/github\hexo\source\_posts\Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels\8.jpg" alt=""></p><p>查找终止的条件是在寻找的过程中中碰到了<strong>hard-to-track values</strong>，例如全局变量，堆上的对象，用户空间的对象，这些可能是来自shared data，external source，如果把这些也标记上，会使得查找更加困难。</p><h2 id="2-3-Check-Use-Chain-Construction"><a href="#2-3-Check-Use-Chain-Construction" class="headerlink" title="2.3 Check-Use Chain Construction"></a>2.3 Check-Use Chain Construction</h2><p>这一步为<em>CSet</em>中的每个变量构建<strong>Check-use chain</strong>。<strong>Check-use chain</strong>可以用一个四元组来表示&lt;<em>SC, CV , Iu , PSet</em>&gt;。</p><p><em>Iu</em>：<em>CV</em>在<em>SC</em>后的第一次使用 <em>PSet</em>：<em>SC</em>后的一系列执行路径（到<em>Iu</em>结束）</p><p>构建<strong>Check-use chain</strong>的方法：污点追踪找到<em>Iu</em>，遍历<strong>CFG</strong>去收集一系列从<em>SC</em>开始，<em>Iu</em>结束的执行路径，这些执行路径的结果记为<em>PSet</em>。</p><p>这里还使用了LLVM里的Alias analysis来寻找一些隐式的use</p><h2 id="2-4-Modification-Analysis"><a href="#2-4-Modification-Analysis" class="headerlink" title="2.4 Modification Analysis"></a>2.4 Modification Analysis</h2><p>在找到了<strong>Check-use chain</strong> &lt;<em>SC, CV , I u , PSet</em>&gt;后，这一步的目的是识别潜在的对<em>CV</em>的修改（<strong>Check-use chain</strong>里找）。</p><p>主要检测的修改操作： 1. <em>CV</em>被修改成了一个新的值，通过一个普通的store指令 2. <em>CV</em>被例如memcpy或者copy_from_user等函数进行了修改。</p><p>如果找到了这样的修改，LRSan会再进一步检测这次修改之后是否有有critical variable进行recheck。最后将没有recheck的情况就认定为是LRC case。</p><h1 id="3-LRSan实现"><a href="#3-LRSan实现" class="headerlink" title="3. LRSan实现"></a>3. LRSan实现</h1><p>作者基于LLVM 6.0.0实现了LRSan。整个实现中包括两个独立的pass（大约3000行代码）。First pass是用来收集和准备静态分析锁需要的信息，例如构建global CFG，alias results。Second pass是用来进行静态分析检测LRC case的。</p><p>作者成功编译了16593个module，只有6个编译失败了。</p><p>过滤部分false positive： 1. <em>CV</em>被修改成的是一个常量 2. <em>CV</em>被修改成的是一个可以过Security check的变量 3. mutex-style check</p><h1 id="4-评估"><a href="#4-评估" class="headerlink" title="4. 评估"></a>4. 评估</h1><h2 id="4-1-Effectiveness"><a href="#4-1-Effectiveness" class="headerlink" title="4.1 Effectiveness"></a>4.1 Effectiveness</h2><p>如下图所示是LRSan检测后导出的检测结果。</p><p><img src="/2019/02/05/Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels/E:/github\hexo\source\_posts\Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels\5.jpg" alt=""></p><p>如下图所示，是LRSan在Linux kernel里找到的19个LRC bug。</p><p><img src="/2019/02/05/Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels/E:/github\hexo\source\_posts\Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels\6.jpg" alt=""></p><h2 id="4-2-Efficieny"><a href="#4-2-Efficieny" class="headerlink" title="4.2 Efficieny"></a>4.2 Efficieny</h2><p>LRSan测试时所用的LLVM IR是用Linux-4.17的源码编译的。作者实验时用的host为一个主存32G的Ubuntu16.04，Quad-Core 3.5 GHz Intel Xeon E5-1620 v4处理器，总共用了4个小时。其中超过80%的时间都是用在first pass（例如信息收集），因为first pass需要构建一个全局的CFG，并收集alias-analysis results。first pass实际上只需要运行一次，因此可以对它的结果进行重用，从而节省时间。</p><h1 id="5-Limitation"><a href="#5-Limitation" class="headerlink" title="5. Limitation"></a>5. Limitation</h1><h2 id="5-1-False-Positives"><a href="#5-1-False-Positives" class="headerlink" title="5.1 False Positives"></a>5.1 False Positives</h2><ol><li>Checked modification，符号执行来过滤</li><li>Satisfiable modification，符号执行来过滤</li><li>Uncontrollable modification，污点追踪来过滤</li><li>Transient check，作者手工排查</li><li>Unconfirmed race：source variable是一个shared variable（例如全局变量），即有可能被其他的线程进程修改，这是作者未来的工作</li><li>Other：静态分析的一些缺陷导致的false positives</li></ol><p><img src="/2019/02/05/Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels/E:/github\hexo\source\_posts\Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels\7.jpg" alt=""></p><h2 id="5-2-False-Negatives"><a href="#5-2-False-Negatives" class="headerlink" title="5.2 False Negatives"></a>5.2 False Negatives</h2><p>作者在查找security check时是基于失败后会返回error code，但是也有可能不返回error code。另外编译失败的一些kernel module也可能导致False negatives。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h1&gt;&lt;p&gt;论文中，作者主要介绍分析操作系统内核中的LRC（lacking-recheck）类型bug。
      
    
    </summary>
    
      <category term="论文" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/"/>
    
      <category term="fuzzing" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/fuzzing/"/>
    
    
      <category term="2018年" scheme="http://yama0xff.com/tags/2018%E5%B9%B4/"/>
    
      <category term="ACM CCS&#39;18" scheme="http://yama0xff.com/tags/ACM-CCS-18/"/>
    
      <category term="Lacking-Recheck Bugs" scheme="http://yama0xff.com/tags/Lacking-Recheck-Bugs/"/>
    
      <category term="Kernels" scheme="http://yama0xff.com/tags/Kernels/"/>
    
  </entry>
  
  <entry>
    <title>Automated Detection Exploitation and Elimination of Double-Fetch Bugs Using Modern CPU Features</title>
    <link href="http://yama0xff.com/2019/02/05/Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features/"/>
    <id>http://yama0xff.com/2019/02/05/Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features/</id>
    <published>2019-02-05T02:50:59.000Z</published>
    <updated>2019-02-14T08:30:14.383Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>Double-fetch bugs 是一种特殊的条件竞争，在高权限线程的time-of-check和time-of-use之间，低权限线程能够修改共享的内存，导致高权限线程访问的内存产生不一致。本文作者提出了一种检测，利用并消除double-fetch bugs的技术DECAF和Dropit。总体来说，<strong><em>贡献如下：1. 把cache attack与kernel fuzzing结合起来。2. 首个自动化的挖掘double-fetch bugs的方法。3. 利用的成功率高达97%。4.利用Hardware Transactional Memory的特性，消除double-fetch bugs。5.方法对fuzz TEE也有效。</em></strong></p><table><thead><tr><th>relevant information</th><th></th></tr></thead><tbody><tr><td><em>作者</em></td><td>Michael Schwarz, Daniel Gruss, Moritz Lipp, Clémentine Maurice, Thomas Schuster, Anders Fogh, Stefan Mangard</td></tr><tr><td><em>单位</em></td><td>Graz University of Technology, CNRS, G DATA Advanced Analytic</td></tr><tr><td><em>出处</em></td><td>AsiaCCS’18</td></tr><tr><td><em>原文地址</em></td><td></td></tr><tr><td><em>源码地址</em></td><td></td></tr><tr><td><em>发表时间</em></td><td>2018年</td></tr></tbody></table><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>现代操作系统的安全依赖操作系统kernel提供隔离性，在对kernel的攻击中，条件竞争是一个很难解决的问题。Double-fetch bugs 就是一种特殊的条件竞争。kernel两次访问同一块内存，首先检查数据的合法性，第二次就使用它，那在这两者之间，内存可能被修改。 Double Fetches有个明显的特征是要访问两次内存。如果数据在cache中，就从cache中读，如果不在就从主存中读到cache中，基于cache的攻击，比如著名的Flush+Reload攻击，可以利用CPU的这个特性来检测Double Fetches。</p><p>Intel TSX的hardware transactional memory特性能够保证当数据被读进transaction后，数据不能被任何transaction之外的操作修改。这种特性被用来实现安全加固，比如在这个场景中就可以天然的防御Double Fetch bugs。</p><p><img src="/2019/02/05/Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features/E:/github\hexo\source\_posts\Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features\1.jpg" alt=""></p><ul><li>通过Flush+Reload边信道检测double fetches</li><li>判断double fetches是否能够被利用</li><li>通过hardware transactional memory消除double fetch bugs</li></ul><h1 id="检测"><a href="#检测" class="headerlink" title="检测"></a>检测</h1><p>主要思想是监控cache访问syscall的参数（比如指针，结构体中的指针），筛选出这些指针后，另起一个Flush+Reload线程对这些指针进行监控。</p><p>效果如下所示，可以明显的看到两次cache的访问。</p><p><img src="/2019/02/05/Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features/E:/github\hexo\source\_posts\Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features\2.jpg" alt=""></p><h2 id="多次cache-hit的分类"><a href="#多次cache-hit的分类" class="headerlink" title="多次cache hit的分类"></a>多次cache hit的分类</h2><p>影响cache acess pattern的因素</p><ul><li>size of data type</li><li>parameter reuse</li></ul><h2 id="检测的概率"><a href="#检测的概率" class="headerlink" title="检测的概率"></a>检测的概率</h2><p>检测成功的概率取决于两次访问时间的间隔。因为本身Flush+Reload需要把数据从cache中清掉，这要消耗大概200多个CPU周期，这就要保证double fetch的两次访问间隔至少要是Flush+Reload两倍的的时间才行。 </p><p><img src="/2019/02/05/Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features/E:/github\hexo\source\_posts\Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features\3.jpg" alt=""></p><h2 id="TrinityDECAF"><a href="#TrinityDECAF" class="headerlink" title="TrinityDECAF"></a>TrinityDECAF</h2><p>作者基于trinity这个kernel syscall fuzz框架，实现了 TrinityDECAF，架构如图，基于trinity，为每个syscall的参数实现了一个监控的进程。</p><p><img src="/2019/02/05/Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features/E:/github\hexo\source\_posts\Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features\4.jpg" alt=""></p><h1 id="利用"><a href="#利用" class="headerlink" title="利用"></a>利用</h1><p>Flush-Reload or Flush+Flush</p><p>fuzz策略</p><ul><li>参数值改成0</li><li>翻转最低有效比特</li><li>增加值</li><li>参数值改为随机值</li></ul><h1 id="消除"><a href="#消除" class="headerlink" title="消除"></a>消除</h1><p>作者实现了Dropit的库，这个是基于硬件的特性，hardware transactional memory保证了两次内存访问之间不能再对该内存修改。实现起来也很简单，使用Intel TSX的XBEGIN和XEND指令讲存在bug的代码包起来即可。</p><p><img src="/2019/02/05/Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features/E:/github\hexo\source\_posts\Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features\5.jpg" alt=""></p><h1 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h1><h2 id="DECAF"><a href="#DECAF" class="headerlink" title="DECAF"></a>DECAF</h2><p>已知漏洞CVE-2016-6516 </p><p><img src="/2019/02/05/Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features/E:/github\hexo\source\_posts\Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features\6.jpg" alt=""></p><ul><li>可行性</li></ul><p><img src="/2019/02/05/Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features/E:/github\hexo\source\_posts\Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features\7.jpg" alt=""></p><ul><li>有效性</li></ul><p><img src="/2019/02/05/Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features/E:/github\hexo\source\_posts\Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features\8.jpg" alt=""></p><ul><li>利用的成功率</li></ul><p><img src="/2019/02/05/Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features/E:/github\hexo\source\_posts\Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features\9.jpg" alt=""></p><ul><li>在TEE上fuzz</li></ul><p><img src="/2019/02/05/Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features/E:/github\hexo\source\_posts\Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features\10.jpg" alt=""></p><ul><li>使用dropit和不使用的比较</li></ul><p><img src="/2019/02/05/Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features/E:/github\hexo\source\_posts\Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features\11.jpg" alt=""></p><p>参考于GoSSIP.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h1&gt;&lt;p&gt;Double-fetch bugs 是一种特殊的条件竞争，在高权限线程的time-of-ch
      
    
    </summary>
    
      <category term="论文" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/"/>
    
      <category term="fuzzing" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/fuzzing/"/>
    
    
      <category term="Double-Fetch Bugs" scheme="http://yama0xff.com/tags/Double-Fetch-Bugs/"/>
    
      <category term="AsiaCCS&#39;18" scheme="http://yama0xff.com/tags/AsiaCCS-18/"/>
    
      <category term="2018年" scheme="http://yama0xff.com/tags/2018%E5%B9%B4/"/>
    
  </entry>
  
  <entry>
    <title>VUzzer: Application-aware Evolutionary Fuzzing</title>
    <link href="http://yama0xff.com/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/"/>
    <id>http://yama0xff.com/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/</id>
    <published>2019-01-29T09:49:47.000Z</published>
    <updated>2019-01-29T13:06:48.164Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>Fuzzing是一种有效的软件测试技术，用于查找错误。考虑到实际应用程序的大小和复杂性，现代模糊器往往是可扩展的，但在探索执行更深层次的错误或者能够在应用程序中深入渗透但不具有可扩展性方面无效。在本文中，我们提出了一种应用程序感知的进化模糊测试策略，它不需要任何有关应用程序或输入格式的先验知识。<strong>为了最大化覆盖范围并探索更深入的路径，我们利用基于静态和动态分析的控制和数据流特征来推断应用程序的基本属性。</strong>与应用程序无关的方法相比，这可以更快地生成有趣的输入。我们在VUzzer中实现我们的模糊测试策略并在三个不同的数据集上进行评估：DARPA Grand Challenge二进制文件（CGC），一组实际应用程序（二进制输入解析器）和最近发布的LAVA数据集。在所有这些数据集中，通过快速查找几个现有和新的错误，VUzzer产生的结果明显优于最先进的模糊器。</p><table><thead><tr><th>relevant information</th><th></th></tr></thead><tbody><tr><td><em>作者</em></td><td>Sanjay Rawat, Vivek Jain, Ashish Kumar, Lucian Cojocar,Cristiano Giuffrida and Herbert Bos</td></tr><tr><td><em>单位</em></td><td>Computer Science Institute, Vrije Universiteit Amsterdam;Amsterdam Department of Informatics  International Institute of Information Technology, Hyderabad</td></tr><tr><td><em>出处</em></td><td>NDSS ’17</td></tr><tr><td><em>原文地址</em></td><td><a href="https://github.com/wtwofire/database/blob/master/papers/fuzzing/2017-VUzzer%20Application-aware%20Evolutionary%20Fuzzing.pdf" target="_blank" rel="noopener">https://github.com/wtwofire/database/blob/master/papers/fuzzing/2017-VUzzer%20Application-aware%20Evolutionary%20Fuzzing.pdf</a></td></tr><tr><td><em>源码地址</em></td><td><a href="https://github.com/vusec/vuzzer" target="_blank" rel="noopener">https://github.com/vusec/vuzzer</a></td></tr><tr><td><em>发表时间</em></td><td>2017年</td></tr></tbody></table><h1 id="论文简略概括："><a href="#论文简略概括：" class="headerlink" title="论文简略概括："></a>论文简略概括：</h1><p><img src="/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/17.png" alt=""></p><p><strong><em>其它相关源码地址：</em></strong></p><p>污点分析数据存储结构：<a href="https://github.com/lemire/EWAHBoolArray" target="_blank" rel="noopener">https://github.com/lemire/EWAHBoolArray</a></p><p>AFLPIN: <a href="https://github.com/mothran/aflpin" target="_blank" rel="noopener">https://github.com/mothran/aflpin</a></p><p>AFLFAST: <a href="https://github.com/mboehme/aflfast" target="_blank" rel="noopener">https://github.com/mboehme/aflfast</a></p><p>DECREE: <a href="https://github.com/CyberGrandChallenge/cgc-releasedocumentation/blob/master/walk-throughs/pin-for-decree.md" target="_blank" rel="noopener">https://github.com/CyberGrandChallenge/cgc-releasedocumentation/blob/master/walk-throughs/pin-for-decree.md</a></p><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>在本文中，我们介绍了VUzzer，一个应用程序感知的进化模糊器，它既可扩展又可快速发现执行中的漏洞。与优化输入生成过程以最大速率生成输入的方法相比，我们的工作探索了设计领域的一个新点，我们在前端做更多的工作，产生更少但更好的输入。关键的直觉是我们可以通过基于控制和数据流应用功能的“智能”突变反馈回路来提高通用模糊器的效率，而无需采用可扩展性较低的符号执行。我们展示了我们可以通过在模糊运行期间对应用程序进行轻量级静态和动态分析来提取这些功能。我们的控制流功能允许VUzzer优先考虑深度（并因此感兴趣）路径，并在改变输入时优先考虑频繁（因此无趣）路径的优先级。我们的数据流功能允许VUzzer准确地确定改变这些输入的位置和方式。</p><p>由于其应用感知突变策略，VUzzer比现有的模糊器更有效。我们评估了VUzzer在三个不同数据集上的表现：a）DARPA CGC二进制文件[15]，这是一组人工创建的交互式程序，旨在评估错误发现技术; b）一组具有不同复杂程度的Linux程序（djpeg，mpg321，pdf2svg，gif2png，tcpdump，tcptrace）和c）最近发布的来自LAVA团队的二进制文件[17]，许多Linux实用程序都有几个注入的错误。在我们对不同数据集的实验中，我们通过生成数量级较少的输入来表现优于AFL，同时发现更多崩溃。例如，在mpg3211中，我们通过执行23K输入发现300次独特崩溃，而883K输入则通过AFL找到19次独特崩溃。</p><p>贡献：我们做出以下贡献：</p><p>1）我们表明现代模糊器可以“更智能”而不需要采用符号执行（难以扩展）。我们的应用感知突变策略将AFL等最先进的模糊器的输入生成过程提高了几个数量级。</p><p>2）我们提出了几个应用程序特征来支持有意义的输入变异。</p><p>3）我们在三个不同的数据集上评估VUzzer，一个实现我们方法的功能齐全的模糊器，并表明它非常有效。</p><p>4）为了促进该领域的进一步研究和支持开放科学，我们开放我们VUzzer原型的源代码，可在<a href="https://www.vusec.net/projects/fuzzing获得。" target="_blank" rel="noopener">https://www.vusec.net/projects/fuzzing获得。</a></p><h1 id="总体描述"><a href="#总体描述" class="headerlink" title="总体描述"></a>总体描述</h1><p>为了解决上一节中提到的挑战，我们提出了VUzzer，一种应用程序感知的进化模糊器。图1概述了其主要组件。</p><p>由于VUzzer是一个进化模糊器，因此有一个反馈循环可以帮助从旧的输入中获得新的输入。生成新输入时，VUzzer会根据其在上一轮输入上的执行情况来考虑应用程序的特征。通过考虑这些特性，我们使反馈回路“智能”并帮助模糊器找到具有高频率的非零IG的输入。</p><p><img src="/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/1.png" alt=""></p><h2 id="1-特征"><a href="#1-特征" class="headerlink" title="1. 特征"></a>1. 特征</h2><p><strong>数据流特征</strong>：数据流特征提供有关应用程序中输入数据和计算之间关系的信息。 VUzzer使用诸如污点分析之类的众所周知的技术来提取它们，并使用它们根据输入中某些偏移处的数据类型来推断输入的结构。例如，它通过检测x86 ISA的cmp系列的每个指令来确定分支的字节（“分支约束”），以确定它使用哪些输入字节（偏移）以及它与哪些值进行比较。通过这种方式，VUzzer可以确定哪些偏移对于变异感兴趣以及在这些偏移处使用哪些值（在第I部分中提供问题的部分答案）。 VUzzer现在能够通过更频繁地定位此类偏移并通过在这些偏移处使用预期值来满足分支约束来更明智地进行变异。这样做可以解决魔术字节的问题，而无需使用符号执行。</p><p>同样，VUzzer监视lea指令以检查索引操作数是否被污染。如果是这样，它可以确定相应偏移处的值是int类型并相应地改变输入。除了这两个简单但功能强大的特征外，还有许多其他功能。</p><p><strong>控制流特征</strong>：控制流特征允许VUzzer推断某些执行路径的重要性。例如，图2显示了清单3中代码的简化CFG。执行错误块的输入通常是不感兴趣。因此，识别这样的错误处理块可以加速感兴趣输入的生成。我们将在以下部分中展示如何检测错误处理代码。目前，我们假设我们可以启发式地识别包含错误处理程序的基本块。</p><p>另一个例子涉及嵌套块的可达性。到达块F的任何输入更有可能比到达块H的输入更深入到代码中，因为后者不是嵌套的。我们使用控制流特征来对路径进行去优先级和优先级排序。由于枚举应用程序中的所有可能路径是不可行的，我们通过为各个基本块分配权重来实现此度量。具体而言，作为错误处理代码一部分的基本块获得负权重，而难以到达的代码区域中的基本块获得更高权重。</p><p><img src="/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/2.png" alt=""></p><p>图1显示了单次模糊测试包含几个步骤。 VUzzer期望有效输入的初始池SI，称为种子输入。第一步是执行过程内静态分析以获得一些控制流和数据流特征（第III-B节），然后是主要的进化模糊循环。在本节的其余部分，我们将介绍描述整个过程的所有步骤。</p><h2 id="2-静态分析器"><a href="#2-静态分析器" class="headerlink" title="2.  静态分析器"></a>2.  静态分析器</h2><p>在模糊测试过程开始时，我们使用轻量级过程内静态分析来（i）通过扫描应用程序的二进制代码来获得cmp指令的立即值，以及（ii）计算应用程序二进制文件基本块的权重。</p><p>应用程序代码中cmp指令中存在的许多立即值通常表示应用程序期望输入在某些偏移处具有许多这些值。例如，清单3中对程序的分析产生了每个基本块的权重列表LBB和包含{0xEF，0xFD，％，@，MAZE}的字节序列的列表Limm。为了确定基本块权重，我们将每个函数的CFG建模为马尔可夫模型，并计算到达函数中每个基本块b的概率pb。然后我们计算每个基本块b的权重wb为1 / pb。因此，到达基本块的概率越低，权重越高。使用该模型，每个基本块的概率和权重显示在图2中的每个节点旁边（参见第IV-A3节）。我们观察到，例如，到达基本块G的概率小于到达基本块F的概率，而基本块F的概率低于基本块H.VUzzer在模糊循环的后续步骤中使用这些列表。</p><h2 id="3-主fuzzing循环"><a href="#3-主fuzzing循环" class="headerlink" title="3.  主fuzzing循环"></a>3.  主fuzzing循环</h2><p>我们通过使用算法1中的步骤来描述主fuzzing循环。在主循环开始之前，我们用一组种子输入SI执行应用程序以推断出一组初始的控制流和数据流特征。对于SI中的所有输入，我们运行动态污点分析（DTA）以捕获有效输入的共同特征。具体来说，我们这样做是为了前面提到的魔术字节和错误处理代码检测。使用这些功能，我们生成一个初始输入总体，作为算法1中INITIALIZE步骤的一部分。请注意，我们的魔术字节检测确保这些新输入跨越第一次这样的应用程序检查。由于DTA具有很高的开销，我们在主循环开始后尽可能少地使用它。</p><p><strong>输入执行</strong>：我们使用上一步中的每个输入执行应用程序，并生成相应的已执行基本块的跟踪。如果任何输入执行以前未见过的的基本块，我们会污染输入并使用DTA通过监视应用程序的数据流功能来推断其结构属性。</p><p><strong>适应度计算</strong>：在算法1的EVALUATE步骤中，我们计算每个输入的适应度作为执行的基本块的频率的加权和。我们使用权重列表LBB在基本块上分配权重。属于错误处理代码的基本块会产生负权重 - 现在我们仍然假设我们可以识别这些基本块。该适应度计算背后的直觉是为执行具有较高权重的基本块的输入提供高分，从而对相应路径进行优先级排序，同时还执行具有高频率的某些基本块以捕获大循环。例如，让我们考虑两个路径p1和p2，分别由两个输入i1和i2执行，使得p1 = A-&gt; B - &gt; D - &gt;E - &gt;H - &gt;J和p2 = A - &gt;B - &gt;D - &gt;E - &gt;F - &gt;J.为简单起见，让我们假设错误处理基本块J得到权重-1并且每个基本块的执行频率为1.使用图2中的权重，p1和p2的频率的加权和为7 （1 + 1 + 2 + 2 + 2-1）和9（1 + 1 + 2 + 2 + 4-1）。因此，输入i2获得更高的适应度分数，并且将比i1更多地参与生成新输入。该步骤最终生成按其适应度分数降序排列的输入排序列表。</p><p><strong>遗传算子和新输入生成</strong>：这是我们模糊测试策略中最后也是最重要的功能，包括算法1中的SELECT，RECOMBINE和MUTATE步骤。这些子步骤一起负责生成有趣的输入。在主循环的每次迭代中，我们通过组合和突变SI的输入，所有受污染的输入以及Lf的前n％来生成新一代输入。我们将此集称为ROOT集。</p><p>具体来说，我们通过交叉和变异生成新的输入。首先，我们从ROOT中随机选择两个输入（父项）并应用交叉来生成两个新输入（子项）。具有固定概率，这两个输入进一步经历突变。 Mutation使用多个子操作，例如删除，替换和在给定输入中的某些偏移处插入字节。变异运算符利用数据流功能生成新值。例如，在插入或替换字节时，它使用来自Limm的字符来生成不同长度的字节序列。类似地，选择来自当前输入的父项的各种偏移用于突变。因此，如果存在任何魔术字节，它们将在结果输入中的适当偏移处被替换。</p><p>这个循环的输入生成一直持续到我们满足终止条件。目前，我们在发现崩溃或VUzzer达到预先配置的代数时终止。</p><h1 id="设计与实现"><a href="#设计与实现" class="headerlink" title="设计与实现"></a>设计与实现</h1><h2 id="1-实现细节"><a href="#1-实现细节" class="headerlink" title="1. 实现细节"></a>1. 实现细节</h2><p><strong>1）动态污点分析（DTA）</strong>：DTA是VUzzer的核心，因为它在发展新输入方面发挥着重要作用。这也是将VUzzer与现有模糊器区分开来的技术。 DTA用于监视应用程序内受污染的输入（例如，网络包，文件等）的流动。在程序执行期间，DTA可以确定哪些存储器位置和寄存器依赖于受污染的输入。根据粒度，DTA可以将受污染的值追溯到输入中的各个偏移量。 VUzzer使用DTA跟踪cmp和lea指令中使用的污染输入偏移。对于每个执行的cmp指令cmp op1，op2（op1和op2可以是寄存器，存储器或立即操作数），DTA确定op1和/或op2是否被一组偏移污染。我们的DTA实现能够在字节级别跟踪污点。对于给定的受污染操作数op，DTA为op的每个字节提供污点信息。</p><p><strong>2）魔术字节检测</strong>：基于我们对具有魔术字节的文件格式的理解，我们假设魔术字节是输入字符串中固定偏移处的固定字节序列。我们已经在几种具有魔术字节的文件格式上验证了这一假设，例如jpeg，gif，pdf，elf和ppm。由于VUzzer是给定应用程序的一些有效输入的可用性，我们在模糊测试开始时在这些输入上使用DTA的结果。由于应用程序期望输入包含魔术字节，因此DTA在cmp指令上的结果将包含对魔术字节的相应检查。</p><p>例如，清单3中的代码在输入文件的开头需要一个魔术字节0xFDEF。因此，DTA将捕获两条cmp指令 - cmp reg，0xFD，reg受到偏移0的污染，cmp reg，0xEF，reg受到偏移量1的污染。如果对这个程序我们有一个有效输入的集合，我们可以在所有相应的执行中观察这两条cmp指令。相反，如果对于一组有效输入，我们在所有输入的DTA结果中得到cmpi =（oi; vi），vi是偏移oi的魔术字节的一部分。</p><p>在魔术字节检测期间，对于给定的cmpi指令，如果相应的值取决于每个字节的多个偏移，我们不认为这种偏移是魔术字节候选。例如，对于给定的cmp指令，如果DTA检测到|Tji|&gt; 1，我们从魔术字节占位符的任何进一步考虑中排除这些偏移（ÎTji）。这种情况表明相应操作数的值可以从那些偏移ÎTji处的污染值导出。对多个字节的依赖打破了魔术字节是固定（常量）字节序列的假设。我们将所有这些偏移的集合表示为Oother。</p><p><strong>3）基本块权重计算</strong>：从基于覆盖的fuzzing角度来看，每条可行路径对于遍历都很重要。一个简单的模糊测试策略是花费同等的努力为所有可行路径生成输入。但是，由于存在控制结构，某些路径的可达性可能与其他路径的可达性不同。如果我们有嵌套的控制结构，这种情况就会频繁出现[41]。因此，与其他输入相比，任何运行这种难以触及的代码的输入都应该得到更多奖励。</p><p>我们通过为嵌套控制结构中包含的基本块指定更高权重来合并此奖励。由于枚举过程间级别的所有路径都难以缩放，我们的分析在过程间级别，即，我们计算包含在函数内的每个基本块的权重。稍后，我们收集并添加由给定输入执行的路径中所有基本块的权重。通过这种策略，我们通过将几个过程内路径分数拼接在一起来模拟过程间路径的分数。</p><p>如果我们认为特定基本块的输入到下一个基本块的转换取决于某个概率，我们可以从控制流图（CFG）中导出一个称为马尔可夫过程的概率模型用于输入行为。马尔可夫过程是一个随机过程，其中给定试验的结果仅取决于过程的当前状态[30]。我们将函数的CFG建模为马尔可夫过程，其中每个基本块具有基于其与其他基本块的连接的概率。</p><p>对于给定的基本块，我们为其所有输出边分配相等的概率。因此，如果out（b）表示基本块b的所有输出边缘的集合，则∀eb <em> Î out（b）; prob（eb </em>）= 1/|out（b）|。基本块b的转移概率（似然）计算如下：</p><p><img src="/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/11.png" alt=""></p><p>其中prod（b）是b的所有前辈的集合。我们使用定点迭代算法来计算与CFG中的每个基本块相关联的概率。 CFG的root基本块初始化概率为1。通过为每个后备项分配固定概率1来处理循环，从而忽略后备本身的影响（即，我们将循环展平以加速定点计算）。从等式1，每个基本块b的权重由下式给出：</p><p><img src="/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/12.png" alt=""></p><p><strong>4）错误处理代码检测</strong>：如前所述，在模糊测试期间，大多数突变输入将执行最终处于某种错误状态的路径。对这些执行路径进行优先级排序是提高创建有趣输入的机会的关键一步。我们的错误处理检测启发式依赖于有效输入的可用性，这是VUzzer的先决条件。由于我们的错误处理检测取决于应用程序的动态行为，因此它以增量方式检测错误处理基本块。</p><p><strong><em>初始分析</em></strong>：对于每个有效输入iÎSI，我们收集由i执行的基本块的集合BB（i）。设ValidBB表示所有有效输入的所有这些已执行基本块的并集。然后我们创建一组完全随机的输入，表示为TR。对于此集合中的每个输入，我们根据基本块收集其执行跟踪。如果在来自TR的输入的每次执行中存在并且它不存在于ValidBB中，则假定来自这样的一组执行的基本块是错误处理基本块（即，属于错误处理代码）。直觉是因为SI是一组有效输入，所以不会触发错误处理代码。因此，ValidBB将仅包含与有效路径对应的基本块。由于TR是一组完全随机的输入，它们很可能在执行期间被错误处理代码捕获。</p><p>我们是一种非常保守的错误处理基本块检测策略，因为如果某些输入被不同的错误处理代码捕获，我们可能会错过几个基本块。尽管如此，请注意，我们永远不会将与有效路径对应的基本块分类为错误处理基本块。更正式的表示如下</p><p><img src="/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/13.png" alt=""></p><p>EHB就是错误处理基本块集合。</p><p><strong><em>增量分析</em></strong>：我们观察到，由于我们的错误处理检测策略基于应用程序的动态行为，因此在初始分析期间不会触发所有错误处理代码。随着输入的发展，它们会探索更多路径，从而遇到新的错误处理代码。出于这个原因，我们在后来的模糊测试迭代期间启动增量分析。在我们的实验设置中，我们观察到，随着我们进行更多的模糊测试迭代，新的错误处理代码实例的数量减少了。这反映了软件具有有限数量的错误处理代码实例的直觉，这些代码实例在应用程序的不同部分中重用。因此，当我们执行更多迭代时，我们减少运行增量分析的频率。</p><p>我们的增量分析背后的直觉是观察到，随着模糊测试的进行，大多数新生成的输入最终会触发一些错误处理代码。在给定的迭代中，让I成为迭代中生成的输入集。让大多数量由|I|的n％量化。我们的（离线）实验表明，n = 90是一个合理的选择。设BB（I）是由I中的输入执行的所有基本块的集合。如果它与来自I的输入少与n％的相关联，且它不在V alidBB集中，则将来自BB（I）的基本块b分类为错误处理基本块。更正式地说，让P（I）表示I的幂集。然后</p><p><img src="/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/14.png" alt=""></p><p><strong><em>错误处理基本块的权重计算</em></strong>：在检测到错误处理基本块（EHB）之后，我们希望对包含此类块的路径进行优先级排序。我们通过惩罚相应的输入来实现这一点，以便这些输入参与下一代的机会较少。为此，每个EHB都给出负权重，这会影响相应输入的适合度（见第IV-A5节）。然而，这种策略本身并不充分，因为与输入执行的基本区块总数相比，EHB只是少数，因此这么小的数量将产生微不足道的影响。我们通过定义影响系数μ（可调参数）来解决这个问题，影响系数μ决定单个错误处理基本块可以使多少（非错误处理）基本块无效。直观地，该参数确定，一旦输入进入错误处理代码，任何相应基本块在计算适合度分数时的贡献必须减少因子μ。对于给定的输入i，我们使用以下公式进行重量计算。</p><p><img src="/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/15.png" alt=""></p><p>其中|BB（i）|是由输入i执行的所有基本块的编号，|EHB（i）|是由i执行的所有错误处理基本块的编号，并且0.1≤μ≤1.0。</p><p><strong>5）适应度计算</strong>：适应度计算是进化算法最重要的组成部分之一。这对于实现反馈回路至关重要，这为下一步的输入生成提供了动力。一旦产生新的输入，其参与产生新输入的机会取决于其适合度。</p><p>VUzzer以两种方式评估输入的适应性。如果输入的执行导致发现新的非EHB基本块，则输入有资格参与下一代。这类似于AFL（额外使用EHB组）。然而，如前所述，这种适应度测量认为所有新发现的路径相等，这是有问题的。输入的重要性（以及因此适应性）取决于其执行的路径的兴趣度，而该路径又取决于相应基本块的权重。因此，我们将输入i的适应度fi定义为捕获所有相应基本块权重的效果的函数。</p><p><img src="/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/16.png" alt=""></p><p>其中BB（i）是由输入i执行的基本块的集合，Freq（b）是当由i执行时基本块b的执行频率，Wb是基本块b的权重（通过使用等式2），li是输入i的长度，LMAX是输入长度的预配置限制。 LMAX用于解决输入膨胀现象。在遗传算法的说法中，两个适应度标准（即发现新基本块的能力和更高的fi）都对应于探索和开发的概念 - 发现新的基本块表示新的方向（即探索）和较高的fi表示基本块的较高执行频率（以及其他因素）（即，在相同方向上的利用）。</p><p><strong>6）输入生成</strong>：VUzzer的输入生成由交叉和变异两部分组成，它们不是互斥的，即交叉以固定的概率跟随在变异之后。</p><p>交叉：交叉是一种简单的操作，其中从前一代中选择两个父输入，并生成两个新的子输入。</p><p>变异：变异是一种更复杂的操作，它涉及若干子操作以将给定的父输入改变为相应的子输入。该过程在以下步骤中详述：</p><ul><li><p>步骤1：从集合Oother中随机选择受污染的偏移量并在这些偏移量处插入字符串。字符串由从集合Limm获得的字节组成。</p></li><li><p>步骤2：从集合Llea中随机选择偏移量并通过用有趣的整数值（例如0，MAX UINT，负数）替换它们来改变来自步骤1的字符串中的这种偏移量。</p></li><li><p>步骤3：对于父输入的所有受污染的cmp指令，如果op1 ≠ op2的值，则将步骤2中字符串中受污染偏移的值替换为op2的值，否则将以固定概率替换受污染的值字节由随机字节序列组成。</p></li><li><p>步骤4：将魔术字节放置在由我们的魔术字节检测器确定的相应偏移处。</p></li></ul><h2 id="2-实现细节"><a href="#2-实现细节" class="headerlink" title="2. 实现细节"></a>2. 实现细节</h2><p>VUzzer的核心功能是在<strong><em>Python 2.7</em></strong>中实现的。一些实现的分析，例如错误处理基本块检测的增量分析，是内存密集型的，因此我们还利用了更新版本（如<strong><em>BitVector3</em></strong>）提供的高效数据结构。 VUzzer内部由两个主要组件组成，包括静态和动态分析，如下面进一步详述。</p><p><strong>静态分析</strong>：VUzzer在IDA [27]中实现了两种静态分析（常量字符串提取和基本块权重计算）。分析是使用IDAPython [18]用Python编写的。</p><p><strong>动态分析</strong>：VUzzer在Pin动态分析框架的顶部实现了动态分析（基本块跟踪和DTA）[31]。对于基本块跟踪，我们实现了一个pintool来记录执行期间遇到的每个基本块及其频率。我们的pintool可以根据需要有选择地跟踪某些库执行的基本块。选择性库监控允许我们减少执行跟踪开销并专注于预期的应用程序代码。</p><p>我们的DTA实现基于Stamatogiannakis等[46]提出的<strong><em>DataTracker</em></strong>，后者又基于LibDFT [29]。由于LibDFT只能处理32位应用程序，因此当前的VUzzer原型只能用于模糊32位应用程序（也用于我们的评估）。请注意，这不是一个基本限制，事实上，我们正在VUzzer中实现64位支持。任何更新版本将在<a href="https://www.vusec.net/projects/fuzzing上提供。" target="_blank" rel="noopener">https://www.vusec.net/projects/fuzzing上提供。</a></p><p>为了使其适合我们的目的，我们还对DataTracker进行了一些更改：</p><ul><li><p>在DataTracker中，与每个内存位置关联的污点标记被建模为元组：&lt;ufd，file_offeset&gt;，即唯一文件描述符和与该描述符关联的文件的偏移量。这些元组中的每一个都是64位长（ufd为32位，file_offset为32位）。每个内存位置都有一组与之关联的元组，以确定偏移量和内存位置受污染的文件。我们将其更改为<strong>EWAHBoolArray type</strong>，它是一种压缩的bitset数据类型。由于我们只需要来自一个（输入）文件的数据流信息，因此我们修改了DataTracker以仅通过该文件传播污点。因此，在我们的修改版本中，与每个存储器位置相关联的污点标签被建模为仅包含偏移的EWAHBoolArray。因此，我们的实现速度至少快2倍，并且使用的内存比DataTracker少几倍。</p></li><li><p>我们为cmp系列指令添加了插桩回调，如CMP，CMPSW，CMPSB，CMPSL和lea指令，以捕获计算中涉及的操作数的字节级污点信息。</p></li><li><p>我们为每个实现的系统调用重写了钩子，并为一些额外的系统调用添加了钩子，例如pread64，dup2，dup3，mmap2等。为了评估我们在DARPA数据集[15]上的性能，我们还实现了基于DECREE的钩子系统调用，与普通的Linux系统调用不同。</p></li></ul><p><strong>crash分类</strong>：一旦模糊测试开始产生崩溃，它可能会继续产生更多的崩溃，并且应该有一些机制来区分由于不同的错误（或相同的错误但不同的实例）导致的崩溃。为了确定崩溃的唯一性，<strong>VUzzer使用由Molnar等人提出的堆栈散列的变体[37]</strong>。在我们的pintool中，我们实现了一个环形缓冲区，用于跟踪最后5个函数调用以及在崩溃之前执行的最后10个基本块。我们计算此缓冲区的哈希值，每次遇到新的崩溃时，我们将新生成的哈希值与旧的哈希值进行比较，以确定报告的崩溃是否是新的唯一崩溃。</p><h1 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h1><p>为了测量我们提出的模糊测量技术的有效性，本节介绍了对VUzzer的评估。为了将VUzzer显示给各种应用程序，我们选择在三个不同的数据集上测试VUzzer A. DARPA CGC二进制文件[15]，B. [43]中使用的二进制格式的杂项应用程序，C.最近的一组错误二进制文件由LAVA [17]生成。</p><p>我们在配备32位2核Intel CPU和4 GB RAM的Ubuntu 14.04 LTS系统上进行了实验。对于DARPA CGC数据集，（提供的）环境是具有称为DECREE的自定义OS的VM。我们要强调的是，我们的主要评估目标是展示VUzzer在识别错误（可能深埋在执行中）的效率，其输入比AFL等最先进的模糊器少得多。我们当前的VUzzer原型并不像AFL那样针对快速输入执行进行优化，因此我们不寻求这方面的比较。</p><h2 id="A-DARPA-CGC数据集"><a href="#A-DARPA-CGC数据集" class="headerlink" title="A.  DARPA CGC数据集"></a>A.  DARPA CGC数据集</h2><p>作为Cyber Grand Challenge的一部分，DARPA发布了一组二进制文件，这些二进制文件在一个名为DECREE的自定义操作系统中运行。共有131个二进制文件，其中注入了各种类型的错误。但是，由于以下原因，我们无法在所有这些上运行VUzzer：</p><ul><li><p>通过接受来自STDIN的输入，所有二进制文件本质上都是交互式的。一旦启动，其中许多人会提供一个菜单来选择一个动作，包括退出选项。此外，在许多情况下，有多个菜单（在程序的不同状态下）具有不同的退出选项。由于VUzzer需要生成完全随机输入的步骤（错误处理代码检测，第IV-A4节），执行此类输入会使应用程序循环，查找有效选项，包括退出选项。这会导致应用程序永远运行。这是一个接口问题，而不是我们的模糊测试方法的基本限制。</p></li><li><p>其中一些二进制文件是使用浮点指令编译的，这些指令LibDFT不能处理，因此VUzzer无法获得正确的数据流信息。</p></li><li><p>由于VUzzer基于Pin [32]，我们按照给定的程序在DECREE5中运行pintools。但是，我们无法使用Pin运行一些二进制文件。</p></li><li><p>某些二进制文件涉及与其他二进制文件的交互，而VUzzer无法处理这些二进制文件。 </p></li></ul><p>在考虑了上面提到的障碍之后，我们总共留下了63个二进制文件。为了与AFL进行比较，我们还运行了AFLPIN，一种基于pintool的AFL实现。 AFLPIN具有与AFL相同的模糊引擎，但是获取执行跟踪的机制不同。我们选择使用AFLPIN代替AFL是为了与SUT具有相同的接口机制，即通过文件描述符0（STDIN）将输入传递给pintool。</p><p>VUzzer在29个CGC二进制文件中发现了崩溃，而AFLPIN只发现了23个崩溃。由于每个CGC也附带修补版本，我们通过运行修补程序版本的二进制文件来验证VUzzer发现的每个错误，以避免进一步崩溃。最重要的结果是这两个模糊器中每次崩溃的执行输入数量。我们运行两个模糊器最多6个小时。图4描绘了两个模糊器发现崩溃（总共13个）的情况的执行次数，证明VUzzer与AFL相比可以显着修剪搜索空间。</p><p>在对特定二进制NRFIN_00015进行模糊测试时，我们观察到以离散方式计算适应度分数fi的重要性。此二进制文件中的漏洞是循环中缓冲区溢出的典型情况。我们观察到在第18次迭代之后，没有发现新的BB，但是fi保持增加，表明典型的循环执行行为。在第63次迭代（总执行次数13K），我们到达缓冲区的边界。 AFLPIN无法检测到这次崩溃。</p><p>我们注意到，我们目前对该数据集的结果是适度的，特别是在Driller [47]报告的结果中。我们进一步调查了结果，发现了一些可能会影响我们当前VUzzer原型在CGC上的性能的特性。</p><ul><li><p>在多个二进制文件中，只有通过执行给定菜单中的一组非常特定的操作才能达到错误状态。例如，在CROMU_00001应用程序中，必须执行以下操作：登录A - &gt;向用户B发送许多消息 - &gt;登录B - &gt;检查消息。目前，VUzzer无法重复序列。</p></li><li><p>有效输入的概念很模糊。回想一下，我们使用每个CGC二进制文件以XML文件形式提供的整个会话作为一个输入。因此，基本上没有无效输入的概念。因此，我们无法充分利用VUzzer的全部功能。</p></li><li><p>与上述相关的是有趣的抵消问题。由于CGC二进制文件是交互式的，因此输入本质上是一个探索应用程序状态的序列，它可能因输入而异。例如，其中一个二进制文件允许用户加载文件。处理文件时会触发该错误。相应的文件加载菜单可以出现在输入中的任何位置，因此文件中的偏移量与输入中加载的位置相关，因此很难自动推理偏移量。</p></li></ul><p>鉴于上述问题，我们认为VUzzer不适合交互式程序，主要是因为它与这些程序的接口机制不佳。</p><p><img src="/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/3.png" alt=""></p><h2 id="B-LAVA数据集"><a href="#B-LAVA数据集" class="headerlink" title="B.  LAVA数据集"></a>B.  LAVA数据集</h2><p>在最近的一篇论文中，Dolan-Gavitt等人。开发了一种注入难以触及的故障的技术，并创建了一些Linux实用程序的错误版本[17]，用于测试基于模糊测试和符号执行的错误查找解决方案。我们使用LAVA-M数据集[17]来评估VUzzer。该数据集由4个Linux实用程序-base64，who，uniq和md5sum组成，每个注入多个故障（每个实用程序使用相同的二进制文件）。 LAVA论文报告了在这些有缺陷的应用程序上评估基于覆盖的模糊器（FUZZER），符号执行和基于SAT的方法（SES）的结果。</p><p>为了提高可读性，我们重申表II中原始LAVA论文的结果。表II中的最后一列显示了VUzzer产生的结果。显示的数字是VUzzer识别的唯一错误。在md5sum的情况下，我们无法运行VUzzer，因为它在第一轮输入生成时崩溃，而不允许程序解析更多任何输入。 LAVA二进制文件中的每个注入故障都有一个ID，并且在每个二进制文件由于该故障而崩溃之前，ID将打印在标准输出上。这使我们能够精确识别VUzzer触发的故障。表III报告了VUzzer为每个LAVA二进制文件触发的故障的ID。</p><p><img src="/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/4.png" alt=""></p><p>我们的LAVA数据集结果中出现了一些有趣的点。大多数LAVA注入的断层都是基于人工注入的路径条件，如lava到达特定路径并触发bug。由于其数据流功能，VUzzer非常好地捕获了这一点。例如，在base64模糊测试期间，我们了解到前四个字节应该是’val或lav’以跟随特定路径。类似地，我们发现最后几个字节应包含以下任何值以采用不同的路径：las [，lat\x1b，Wsal等。应该注意，LAVA注入的大多数路径约束都是多字节约束。这种约束对于AFL在执行中更深入地造成了严重的问题（如[16]中所述）。另一个有趣的观点是VUzzer对who的表现。 LAVA文件中使用的模糊器甚至找不到一个bug，而VUzzer发现了几个独特的崩溃。</p><p><img src="/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/5.png" alt=""></p><p>总体而言，在两个人工数据集中，VUzzer报告了令人鼓舞的结果，尽管正如预期的那样，它确实与DARPA CGC数据集中的交互式程序相悖。我们现在继续在实际程序中评估VUzzerz，这些程序也被其他模糊器考虑过。</p><h2 id="C-各种应用程序（VA）数据集"><a href="#C-各种应用程序（VA）数据集" class="headerlink" title="C.  各种应用程序（VA）数据集"></a>C.  各种应用程序（VA）数据集</h2><p>我们使用真实世界程序的数据集（djpeg / eog，tcpdump，tcptrace，pdf2svg，mpg321，gif2png）来评估VUzzer的性能。Rebert等人还对这些程序进行了评估，以报告几个错误[43]，因此我们将这些程序纳入我们的评估中，用于比较目的。对于这些程序中的每一个，我们在Ubuntu 14.04中使用vanilla发行版。我们注意到，通过评估这些实用程序，我们还针对一些著名的库，如libpcap，libjpeg，libpoppler和libpng。每个程序最多24小时模糊。为了突出VUzzer的性能，我们还在这些应用程序上运行了AFL。表IV显示了在VA数据集上运行VUzzer和AFL的结果，VUzzer在发现的唯一崩溃次数和触发此类崩溃所需的输入数量方面明显优于AFL。</p><p><img src="/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/6.png" alt=""></p><p>图5详细描述了24小时内崩溃的分布情况。每个图的x轴显示每2小时采样的累计崩溃总和。如图所示，对于几乎所有应用程序，VUzzer在后续的模糊测试中不断发现崩溃，而AFL在几次初始迭代后很快就耗尽了精力。这是因为在后期阶段，AFL无法找到新的（更深的）路径，而VUzzer能够在探索新路径时学习分支约束，因此能够在模糊测试的后期阶段发现崩溃。图5中另一个有趣的注意事项是，与AFL相比，VUzzer不仅能够以更少的输入找到崩溃，而且还可以在更短的时间内完成（参见图5中垂直线的位置）。我们想再次说明我们还没有优化VUzzer来实现快速输入。我们认为存在多种提高VUzzer执行速度的技术，例如，在单个模糊迭代中使用类似AFL的fork服务器，或者在多个核心或机器上分配并发模糊工作者。</p><p><img src="/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/7.png" alt=""></p><h2 id="D-Crash-Triage分析"><a href="#D-Crash-Triage分析" class="headerlink" title="D.  Crash - Triage分析"></a>D.  Crash - Triage分析</h2><p>Fuzzers倾向于产生大量崩溃。修复与崩溃相关的每个错误都是一个耗时但有利可图的过程。提供给软件开发人员的唯一信息是应用程序的版本号和崩溃本身。当然，错误修补工作投入到更多（安全性）关键的错误中。</p><p>！Exploitable [19]是CERT提出的一种工具，它建立在GDB之上，并使用启发式方法来评估由bug引起的崩溃的可利用性。启发式算法基于崩溃位置，内存操作（读取或写入）以及应用程序触发的信号。虽然这种分析不合理，但它简单，快速，并提供了崩溃严重程度的提示。我们使用！Exploitable工具对VUzzer在此数据集上发现的崩溃进行排名。表五列出了我们的结果。</p><p>如表中所示，由于！Exploitable工具的简单性，大多数情况都被标记为未知。没有一个案例被标记为可能可利用。最后，VUzzer在tcptrace中发现的每次崩溃似乎都是可利用的。我们调查了tcptrace中的一个崩溃，并且有一种看似明显的方法来利用它：漏洞是对堆缓冲区的越界写入。写入的边界和数据受到污染（即，受攻击者控制）。</p><p><img src="/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/8.png" alt=""></p><p>了进一步分析VUzzer发现的错误的质量，我们测量了crash与所涉及的库之间的距离（如果有的话）。位于库中的错误可能会包含在使用该库的任何应用程序中，因此这些错误具有高优先级。我们还需要记住，这些是未知的错误，因此其中许多可能是0-day。当我们发现大量独特崩溃时，尽早报告最重要的崩溃是一个优先事项，因此我们依靠自动分析来估计错误的严重性。简而言之，如果库中发生崩溃，那么报告就是一个严重的错误。但是，有时在用户应用程序中会出现错误，但错误的真正原因在于应用程序使用的库。因此，当在应用程序代码中观察到崩溃时，我们还测量距上一次库调用的距离。</p><p>崩溃与库之间的距离由两个指标衡量。首先，我们计算崩溃和最后一次库调用之间执行的指令数。直觉是最终导致崩溃的计算（及其副作用）可能源于库调用。其次，我们计算崩溃和最后一次库调用之间的堆栈帧数。作为一个例子，使用驻留在主应用程序中的输出函数钩子的库（例如 tcpdump，tcptrace，mpg321）被这种启发式方法所覆盖。表VI列出了我们的分析结果。</p><p><img src="/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/9.png" alt=""></p><p>mpg321中的所有崩溃都发生在（libid3tag）库中。发行版维护者对libid3tag库进行了大量修补（补丁级别为10）。这表明该库已知包含许多错误。 gif2png总是在应用程序内部崩溃。高数据的指标均证实了这一点。 pdf2svg大部分时间都在libpoppler中崩溃。堆栈帧距离为3，因为信号从Linux的vdso通过标准库路由。 tcpdump和tcptrace使用相同的（libpcap）库，但由于tcpdump显示网络流的内容，因此它与库的距离更远。</p><p>基于上述分析，我们认为VUzzer报告的许多崩溃事件都发现了0-day漏洞，我们目前正在向开源社区进行负责任的披露。表七提供了迄今为止我们分析和报告的一些错误的信息。</p><p><img src="/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/10.png" alt=""></p><h1 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h1><p>在前面的部分中，我们已经强调了VUzzer和AFL之类的状态模糊器之间的一些主要区别。在本节中，我们调查了最近在模糊测试领域的其他研究工作。这使我们能够突出显示与现有工作相关的一些功能和差异。</p><h2 id="A-基于搜索的进化输入生成"><a href="#A-基于搜索的进化输入生成" class="headerlink" title="A.  基于搜索的进化输入生成"></a>A.  基于搜索的进化输入生成</h2><p>使用进化算法进行输入生成是软件工程中一个经过深入探索的研究领域[7]，[34]。已经尝试使用进化算法进行输入生成以发现应用程序中的漏洞[25]，[42]，[45]。不同之处在于，这些方法假定应用程序的先验知识集中在导致程序易受攻击部分的路径上。这个属性使这些方法更接近定向模糊测试，因此，我们的模糊测试策略大大偏离它们。与VUzzer不同，与AFL类似，这些方法使用的反馈循环不会尝试将应用程序行为与输入结构相关联以增强输入生成。</p><h2 id="B-Whitebox模糊测试方法"><a href="#B-Whitebox模糊测试方法" class="headerlink" title="B.   Whitebox模糊测试方法"></a>B.   Whitebox模糊测试方法</h2><p>Whitebox模糊测试是通过考虑应用程序的属性来提高传统随机模糊测试性能的最早尝试之一。有许多方法可以使模糊测试更有效，例如，通过应用符号执行和动态污点分析来解决分支约束[20] - [24]，[26]。虽然VUzzer在很多方面都与这些方法不同，但根本的区别仍然是符号执行的使用。与VUzzer类似，Ganesh等人提出的BuzzFuzz [20]利用动态污点分析，但用途完全不同。BuzzFuzz是一个定向模糊器，因此，它不会尝试学习每条路径的约束。它使用污点分析来检测影响代码中危险点的字节，如库调用参数，并在输入中改变这些字节以触发异常行为。大多数这些方法还需要源代码的可用性来执行分析。</p><h2 id="C-Blackbox-Graybox模糊测试方法"><a href="#C-Blackbox-Graybox模糊测试方法" class="headerlink" title="C.  Blackbox / Graybox模糊测试方法"></a>C.  Blackbox / Graybox模糊测试方法</h2><p>尽管简单且完全与应用程序无关，但Blackbox模糊器，如Peach [1]，Sulley [39]和Radamsa [40]已经发现了实际应用程序中的错误。但是，在整篇论文中，我们已经讨论了这种模糊器的局限性。</p><p>最近，基于符号和模仿执行的模糊测试方法在“智能”模糊测试领域占主导地位[12]，[38]，[47]，[51]。 Mayhem [12]是CMU的一个系统，用于自动查找二进制代码中可利用的错误，它使用多种程序分析技术（包括符号执行）来推理给定输入的应用程序行为。这与VUzzer的思想相似。但是，由于VUzzer的目标与Mayhem的目标不同，VUzzer不需要重量级的程序分析技术，而是通过应用基于轻量级程序分析的启发式方法来推断输入的重要属性。同样，Driller [47]使用混合的concolic执行技术[33]通过解决分支约束来进行更深入的路径探索来辅助模糊测试。在[28]中，Kargen’等提出一种不同的方法来生成模糊输入。对于正在测试的给定应用程序，他们的方法通过注入影响输出的故障来修改另一个输入生成器应用程序。使用此策略，错误程序生成变异输入。但是，目前尚不清楚这些突变输入是否确实会影响应用程序消耗这些输入的方式。 TaintScope [49] - 校验和感知模糊器 - 使用污点分析来推断校验和处理代码，这进一步有助于模糊旁路校验和检查。在模糊测试时，VUzzer也可以从这种（补充）技术中受益。在最近的一项工作[8]（与我们的工作同时进行）中，AFLFAST的作者提出了一种基于马尔可夫模型的技术来识别低频路径，以便将模糊测试的重点放在该方向上。部分由VUzzer使用的启发式算法是对由最大输入数量执行的路径进行优先级排序。 VUzzer的错误处理基本块检测技术与此类似，虽然权重很轻。 VUzzer应用其他数据和控制流功能来加速输入生成。</p><p>还有其他一些技术来增强模糊测试[11]，[43]，[51]。 VUzzer还可以通过多种方式从这些方法中受益。例如，种子选择[43]可以帮助VUzzer从一组良好的种子输入开始。</p><h1 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h1><p>本文认为，模糊测试的关键优势在于实现轻量级，可扩展的错误查找技术，并且应用重量级和不可扩展的技术（如基于符号执行的方法）不是提高基于覆盖fuzzing的性能的最终解决方案。在研究了几种现有的通用（黑/灰盒）模糊器（包括最先进的AFL模糊器）后，我们注意到它们往往与应用程序无关，这使得它们在发现根深蒂固的错误方面效率较低。应用程序不可知策略的关键限制是它们无法更快地生成有趣的输入。我们通过模糊化应用程序感知测试过程来解决这个问题。</p><p>我们利用应用程序的控制和数据流特征来推断输入的几个有趣属性。控制流特征允许我们对某些路径进行优先级排序和优先级排序，从而使输入生成成为受控过程。我们通过为基本块分配权重并为输入实现权重感知适应性策略来实现这一点。</p><p>通过使用动态污点分析，我们还监控应用程序的多个数据流特征，使我们能够推断输入的结构属性。例如，这为我们提供了有关输入中的哪些偏移在几个分支条件下使用，哪些值用作分支约束等的信息。我们在反馈循环中使用这些属性来生成新输入。</p><p>我们在一个名为VUzzer的开源原型中实现了我们的模糊测试技术，并在几个应用程序上对其进行了评估。我们还将其性能与AFL的性能进行了比较，结果表明，在几乎所有测试案例中，与AFL相比，VUzzer能够在少于一个数量级的输入下发现错误。这具体表明，通过分析应用行为来推断输入属性是一种可行且可扩展的策略，可以提高模糊性能，并为该领域的未来研究提供有希望的方向。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h1&gt;&lt;p&gt;Fuzzing是一种有效的软件测试技术，用于查找错误。考虑到实际应用程序的大小和复杂性，现代
      
    
    </summary>
    
      <category term="论文" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/"/>
    
      <category term="fuzzing" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/fuzzing/"/>
    
    
      <category term="fuzzing" scheme="http://yama0xff.com/tags/fuzzing/"/>
    
      <category term="2017年" scheme="http://yama0xff.com/tags/2017%E5%B9%B4/"/>
    
      <category term="污点分析" scheme="http://yama0xff.com/tags/%E6%B1%A1%E7%82%B9%E5%88%86%E6%9E%90/"/>
    
      <category term="LAVA" scheme="http://yama0xff.com/tags/LAVA/"/>
    
      <category term="pin" scheme="http://yama0xff.com/tags/pin/"/>
    
      <category term="静态分析" scheme="http://yama0xff.com/tags/%E9%9D%99%E6%80%81%E5%88%86%E6%9E%90/"/>
    
      <category term="动态分析" scheme="http://yama0xff.com/tags/%E5%8A%A8%E6%80%81%E5%88%86%E6%9E%90/"/>
    
      <category term="CFG" scheme="http://yama0xff.com/tags/CFG/"/>
    
      <category term="NDSS&#39;17" scheme="http://yama0xff.com/tags/NDSS-17/"/>
    
  </entry>
  
  <entry>
    <title>NAR-Miner Discovering Negative Association Rules from Code</title>
    <link href="http://yama0xff.com/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/"/>
    <id>http://yama0xff.com/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/</id>
    <published>2019-01-28T09:18:28.000Z</published>
    <updated>2019-01-28T09:55:24.772Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>从基于数据挖掘技术的源代码推断编程规则已被证明对检测软件错误是有效的。现有研究侧重于以A⇒B的形式发现积极规则，表明当操作A出现时，操作B也应该在这里。不幸的是，负面规则（A⇒¬B），表明程序元素之间的相互抑制或冲突关系，没有得到应有的重视。事实上，违反这些负面规则也会导致严重的错误。在本文中，我们提出了一种名为NAR-Miner的新方法，可以从大规模系统中自动提取负关联编程规则，并检测它们的违规行为来发现bug。然而，挖掘负面规则面临着比挖掘正面规则更严重的规则爆炸问题。大多数获得的负面规则都是无趣的，并且可能导致不可接受的错误警报。<strong>为了解决这个问题，我们设计了一个语义约束的挖掘算法，将规则挖掘集中在具有强语义关系的元素上。此外，我们引入信息熵来排列候选负面规则并突出有趣的规则</strong>。因此，我们有效地缓解了规则爆炸问题。我们实现NAR-Miner并将其应用于Linux内核（v4.12-rc6）。实验表明，不感兴趣的规则大大减少，检测到的17个违规行为已被确认为真正的错误并被内核社区修补。我们还将NAR-Miner应用于PostgreSQL，OpenSSL和FFmpeg，并发现了六个真正的错误。</p><table><thead><tr><th>relevant information</th><th></th></tr></thead><tbody><tr><td><em>作者</em></td><td>Pan Bian, Bin Liang,/Wenchang Shi,Jianjun Huang,Yan Cai</td></tr><tr><td><em>单位</em></td><td>School of Information, Renmin University of China; Key Laboratory of DEKE, Renmin University of China Beijing, China; State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences Beijing, China</td></tr><tr><td><em>出处</em></td><td></td></tr><tr><td><em>原文地址</em></td><td><a href="https://github.com/wtwofire/database/blob/master/papers/mine/2018-NAR-Miner%20Discovering%20Negative%20Association%20Rules%20from%20Code.pdf" target="_blank" rel="noopener">https://github.com/wtwofire/database/blob/master/papers/mine/2018-NAR-Miner%20Discovering%20Negative%20Association%20Rules%20from%20Code.pdf</a></td></tr><tr><td><em>源码地址</em></td><td></td></tr><tr><td><em>发表时间</em></td><td>2018年</td></tr></tbody></table><h1 id="1-引言"><a href="#1-引言" class="headerlink" title="1. 引言"></a>1. 引言</h1><p>静态错误/漏洞检测技术通常需要一些先验知识（即检测规则或漏洞签名）[9,13,17,19]。近年来，已经广泛证明了关于bug /漏洞检测的代码挖掘方法是非常有效的[1,4,6,7,14,20,25-27,29,30,36,38,44,47， 49,51-53,57,60]。这些方法自动从程序源代码中提取隐式编程规则，并进一步检测违反这些规则的错误或漏洞。通常，在代码挖掘期间，程序源代码首先被转换为项集[6,25,26,49]，图[7,34,57]或其他形式。接下来，将数据挖掘算法应用于变换后的格式以提取模式（例如，频繁项目集或子图）并推断编程规则。最后一步是检测违反推断规则的行为。例如，PR-Miner [25]和AntMiner [26]从Linux内核挖掘频繁项目集以提取关联规则（作为检测规则）并检测到许多未知错误。</p><p>这些现有研究的基本思想是利用统计数据来编制程序元素，并附带源代码的关系。这种关系表现为积极的编程模式。也就是说，在目标项目中，一些程序元素经常一起出现（达到给定的阈值）或者它们之间存在某种联系。例如，PR-Miner [25]和AntMiner [26]都以A⇒B的形式提取正关联规则，表明在函数内，当程序元素A出现时，元素B也应该出现。因此，如果函数实现违反规则（即，包含A而不包括B），则预期潜在的错误。已经提出了类似的技术来检测潜在的对象滥用错误[53]和控制结构之后缺少的程序元素[7]，已经推断出API的正确使用[60]。所有这些方法都针对一组具有相互支持关系的邻接程序元素，即积极关联。</p><p>然而，在实践中我们观察到一些隐式编程模式以A⇒¬B的形式表现为负关联。也就是说，当A出现时，B不应出现，反之亦然。从这个意义上说，否定规则反映了A和B之间的相互抑制或冲突关系。违反负面规则也可能导致严重的错误。通常不可能手动识别项目中的所有否定规则，尤其是像Linux内核这样的大规模规则。但据我们所知，现有方法没有可以自动从源代码中提取负面规则以进行错误检测。最先进的基于挖掘的解决方案只能提取积极的编程规则。与指示频繁模式的积极规则相比，否定规则通常更隐含，相应的错误更隐蔽。例如，图1中的错误已存在于Linux内核中超过10年（即，在Linux-2.6.4或更早版本中提供）。因此，开发一种自动提取隐式否定编程规则以检测相关错误和漏洞的有效方法既具有挑战性又迫切。</p><p>在本文中，我们提出NAR-Miner解决上述问题。最重要的想法是通过不频繁的模式挖掘来推断有趣的负关联规则，并进一步将相应的违规行为检测为潜在的程序错误。基本上，由于负面规则的性质[56]，直接挖掘不常见的模式以提取负面规则将产生大量规则。我们称之为规则爆炸问题。这些规则中的大多数对于错误检测都是无趣的，即它们不包含任何真实的应用程序逻辑，并且违反它们不会导致错误或程序质量问题。因此，基于这些不感兴趣的规则的检测结果将产生不可接受的误报。例如，直接将现有的负规则挖掘算法[43,46,61]应用于Linux内核将提取多达数十万条规则和数百万条违规行为。在有限的人力资源下进行人工审计变得不可能。为了解决规则爆炸问题，我们提出了一种语义约束的负关联编程规则挖掘算法，以避免尽可能地产生过多的不感兴趣的规则。此外，我们利用信息熵来识别易于导致不感兴趣的规则的一般函数。这一步有助于进一步遏制可能不感兴趣的规则。因此，NAR-Miner可以有效地缓解规则爆炸问题并获得理想的有趣规则来检测潜在的错误。</p><p>我们实现了NAR-Miner的原型，并首先在Linux内核（v4.12-rc6）上进行评估。实验表明，基于语义约束的负规则挖掘和基于信息熵的规则过滤在减少不感兴趣的规则数量方面表现良好。也就是说，它减少了46％的无趣规则（即，在200个排名靠前的负面规则中从198到107）。特别是，它在排名前50位的负面规则中实现了62％的真正正面率。NAR-Miner报告了违反排名最高的200条规则的356条违规行为。我们手动检查结果并发现23个可疑错误和数十个质量问题。我们向Linux内核维护者报告可疑错误。其中17个已被确认为真正的错误，相应的补丁已合并到最新版本（例如，v4.16）。我们进一步将NAR-Miner应用于PostgreSQL v10.3，OpenSSL v1.1.1和FFmpeg v3.4.2。从排名靠前的规则和违规行为中，我们手动识别出六个可疑错误，所有这些错误都由相应的维护人员进行了确认和修复</p><p>本文的主要贡献如下：</p><ul><li><p>据我们所知，我们的工作是第一个专注于从源代码中提取负面编程规则以检测错误的工作。它扩展了基于挖掘的错误检测技术的能力。</p></li><li><p>我们提出了一种通过在规则挖掘中引入程序语义并使用信息熵来识别一般函数来缓解规则爆炸问题的方法，该方法可以有效地提取用于错误检测的理想的有趣负编程规则。</p></li><li><p>我们针对真实世界的大型软件项目实现了NAR-Miner原型。我们将该工具应用于四个大型系统（即Linux内核，PostgreSQL，OpenSSL和FFmpeg）并引发相当多的错误，其中23个已被确认。</p></li></ul><h1 id="2-动机示例"><a href="#2-动机示例" class="headerlink" title="2.动机示例"></a>2.动机示例</h1><p>我们使用来自Linux内核（v4.12-rc6）的简化代码片段来激励我们的方法。在图1中，函数lapbeth_new_device在第5行调用alloc_netdev为网络设备分配一块内存。然后在第8行，在内联函数中调用netdev_priv以获取私有数据的起始地址并将其存储到变量lapbeth。如图1所示，lapbeth指向先前分配的内存中的位置。如果设备注册在第11行失败，则将释放设备的内存块。由变量ndev指向的已分配内存在第21行首先释放，然后在第23行释放私有数据。从代码片段突出显示从内存分配到空闲的执行序列中的关键操作，并相应地描述相应的内存状态。我们使用红色水平线来描述通过free_netdev和kfree的蓝色垂直线释放内存。通过图示，可以很容易地看出代码中存在双重错误。</p><p><img src="/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/1.png" alt=""></p><p>传统的静态检测方法难以在大规模系统（例如Linux内核）中发现此错误和其他类似错误，因为所需的错误模式或规则是特定于应用程序并且难以收集。现有的基于挖掘的方法也无法报告错误。例如，最先进的方法AntMiner [26]提取正关联规则并检查违规。在Linux内核中，我们发现在对alloc_netdev的90次调用中，共有77次出现{alloc_netdev，free_netdev}（85.6％）。并且在533个调用实例中只有一次调用free_netdev后跟kfree（0.2％）。 AntMiner将{alloc_netdev}⇒{free_netdev}视为一个正规则，最小置信度阈值为85％[26]。但是，图1中的代码同时调用alloc_netdev和free_netdev，因此是对规则的支持，而不是违反。因此，上述错误未被发现。此外，由于低信任度（0.2％«85％），AntMiner不会将{free_netdev}⇒{kfree}视为有效规则（即，以最小置信度阈值来消除）。因此，AntMiner无法将“kfree跟随free_netdev”报告为错误。</p><p>从上面的分析中，通过分析元素之间的伴随关系来检测图1中的错误是非常困难甚至是不可能的。实质上，与bug密切相关的两个程序元素（即free_netdev和kfree）是负相关的。通过统计分析可以发现这种知识。具体来说，我们发现在大多数情况下（大约99.8％）在Linux内核中，free_netdev后面没有kfree，我们了解到开发人员大多都知道在free_netdev之后调用kfree可能是不必要的或导致严重问题的情况。受此启发，相对少量的配对事件可被视为异常。</p><p>我们利用不频繁的项集挖掘算法来推断负关联规则并应用规则来检测它们的违规（例如，图1中的那个）。在挖掘和检测期间，我们还考虑了程序语义（例如，数据流信息）。在我们的示例中，kfree与free_netdev共享数据，并且它们的外观一起被视为不常见的模式。因此，我们推断出一个负面规则{free_netdev}⇒¬{kfree}。将规则应用于我们的示例可发现相应的错误（表2中的错误12＃）</p><h1 id="3-我们的方法"><a href="#3-我们的方法" class="headerlink" title="3.我们的方法"></a>3.我们的方法</h1><h2 id="3-1概述"><a href="#3-1概述" class="headerlink" title="3.1概述"></a>3.1概述</h2><p>我们提出了NAR-Miner，目标是检测程序包含一些操作（例如两个函数调用）的错误，这些操作被认为不会出现在一起，该方法不需要任何先验知识。NAR-Miner的高层理念是采用数据挖掘技术从源代码中推断出负关联规则并检测其违规行为。</p><p>图2显示了NAR-Miner的概述。它首先为挖掘阶段准备数据。与大多数基于挖掘的方法类似[6,25,26,49,60]，我们仅从每个单独的函数中提取编程规则，即在程序内，以避免过于复杂的分析。识别每个函数内的程序元素及其语义关系并将其转换为事务，然后将其存储在数据库（称为事务数据库）中。接下来，它从数据库中挖掘频繁且不频繁的项集，它们表示程序元素集。然后，它从挖掘的项集中推断出负关联规则，并利用函数的置信度和熵自动对规则进行排序。最后，它检测违反推断规则的情况，并将排名最高的规则报告为审计的潜在错误。</p><p><img src="/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/2.png" alt=""></p><h2 id="3-2挑战"><a href="#3-2挑战" class="headerlink" title="3.2挑战"></a>3.2挑战</h2><p>以前的研究[43,46,61]表明只有少数表现出负相关关系很有意思的模式。他们通过计算支持和信任来识别有趣规则的技术不能直接用于代码挖掘。构造有趣的负关联规则的程序元素应该在它们的语义中相互压制，而不是偶尔出现在一起。我们的实证研究表明，直接应用Wu等人提出的算法。 [56]从Linux内核中提取的事务数据库生成183,712个负关联规则（参见§4.2.2），而其中99％在采样分析中不感兴趣。报告的违规行为多达309,689起，这使得人工审核变得不可能。我们称之为规则爆炸问题，并将其视为提取负关联规则的主要挑战。我们将以下两个方面归结为规则爆炸的根本原因。</p><ol><li><p>现有的负关联规则挖掘方法[43,45,56,61]主要针对购物篮，医学诊断，蛋白质序列等。对于这类数据，来自挖掘单位的任何两个元素（例如，购物收据）除属于同一单位外，没有任何特定关系。换句话说，挖掘单元的元素是同类的。然而，在程序元素之间，通常存在各种语义关系，例如数据依赖性。忽略这样的关系可能会导致许多不感兴趣的规则由语义上独立的元素组成，这些元素实际上并没有相互抑制，而是偶尔出现在一起。</p></li><li><p>大型项目通常包含一定数量的通用API，几乎可用于所有编程环境，例如Linux中的printk和isalpha。它们可能巧合地与其他操作配对以形成关联规则。即使考虑到挖掘期间的强语义关系（例如，数据依赖性），这些API仍然可能导致许多负面无趣的规则。实际上，API越普遍，它与其他操作的相互抑制就越少。</p></li></ol><p>基于以上见解，我们如下缓解规则爆炸问题。 （1）考虑到如上所述的程序元素的本质，我们将规则挖掘集中在具有强语义关系（例如，数据依赖性）的程序元素上，以尽可能地减少不感兴趣的规则。 （2）我们使用信息熵来衡量API的普遍性，并用它来排列挖掘的候选负面规则。涉及高普遍性API的不感兴趣规则将被排除在最终审计之外。</p><h2 id="3-3数据准备"><a href="#3-3数据准备" class="headerlink" title="3.3数据准备"></a>3.3数据准备</h2><p>NAR-Miner将程序元素转换为事务并将它们存储到数据库中。在本文中，我们关注两种程序元素：函数调用和条件检查，因为许多错误是由函数或条件错误引起的[1,6,21,26,33,38,47,57]。如前所述，我们的目标是从事务中提取负关联规则，其元素具有强大的语义关系。如果它们之间存在数据关联，我们定义两个元素以具有强大的语义关系，包括数据依赖性和数据共享[7]。详细地说，给定两个语句s1和s2，如果s2使用s1中定义的值（即数据依赖），或者它们都出现在同一个执行路径上并使用相同的非常量值（即数据共享），我们说他们在语义上有很强的相关性。程序元素的语义关系通过数据流分析[3,15]来识别。</p><p>NAR-Miner的预处理器建立在GCC（v4.8.2）前端之上，该前端以SSA形式[12]提供控制流图和中间表示，用于数据流分析。图3（a）显示了一段代码，图3（b）显示了相应SSA形式的中间表示。 NAR-Miner可以判断is_valid，foo和bar是依赖于第2行的read2的数据。由于is_valid和foo在同一个执行路径中，因此它们具有数据共享关系。因为foo和bar之间没有路径，所以它们不被认为是语义相关的。</p><p>为了简化挖掘阶段，然后将中间表示转换为事务数据库。每个函数定义都映射到一个事务。事务由两部分组成：程序元素和这些元素之间的一组语义关系。在转储到数据库之前，每个程序元素都被规范化。函数调用用不带参数的函数名表示;如果条件语句中的变量保留某些函数的返回值，或者在其他情况下保留其数据类型，则使用“RET”重命名，如许多挖掘方法[6,7,25,26,57,58]中所做的那样。例如，图3中的条件表达式归一化为“RET == 0”。两个程序元素之间的语义关系表示为事务中的元组。例如，元组（foo，is_valid）表示函数foo和is_valid具有一些语义关系。图3（c）显示了代码片段的语义关系，其中节点表示程序元素，边缘表示关系（黑线表示数据依赖性、红线表示数据共享）。</p><p>我们将每个程序元素映射到一个唯一的整数，因此挖掘被应用于整数集以提高性能，因为大量的字符串等价比较是耗时的。</p><p><img src="/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/3.png" alt=""></p><h2 id="3-4提取频繁和不频繁的项集"><a href="#3-4提取频繁和不频繁的项集" class="headerlink" title="3.4提取频繁和不频繁的项集"></a>3.4提取频繁和不频繁的项集</h2><p>很少调用的程序元素总是很少与其他程序元素一起出现，并且会导致大量的负面模式。然而，这些模式在统计学中毫无意义[56]。因此，我们专注于挖掘负面模式，这些模式的元素经常单独出现但很少发生在一起。对于负关联规则A⇒¬B，其前因（即A）和后续（即B）是频繁的，但它们的组合（即（A∪B））是不频繁的。在本节中，我们将提出我们的算法来提取有趣的频繁和不频繁的项集，并将在下一节中解释如何生成否定规则。</p><p>提取频繁和不频繁项集的现有算法仅依赖于事务数据库中项集的出现[43,46,61]。他们都没有考虑元素之间的语义关系。直接将它们应用于§3.3中生成的数据库将导致大量无趣的规则。据我们所知，没有不常见的项集挖掘算法可以直接应用于我们的工作中。为了解决这个问题，我们设计了一个语义约束的挖掘算法，该算法侧重于提取与语义相关的强项集。强语义相关项集中的元素在语义上都彼此相关，例如，具有数据依赖性或数据共享关系。</p><p>我们基于众所周知的Apriori算法[2]设计我们的算法，该算法应用自下而上的方法通过将较小的频繁项目集合在一起来生成相对较大的候选项集。自下而上方法背后的原则是Apriori属性：频繁项集的任何子集也是频繁的。在我们的例子中，强语义相关项集的任何子集也与强语义相关，因为子集中的任何两个元素必须在语义上相关。因此，强大的语义相关项集也符合Apriori属性，可以自下而上的方式挖掘。</p><p>算法1中显示了我们挖掘频繁和不频繁的强语义相关项集的算法。除了事务数据库，它还要求用户指定两个参数：最小频率支持mfs和最大频率支持mis。如果项集的支持大于或等于mf s，则认为项集是频繁的，如果项集的支持小于或等于mis，则项集是不频繁的。算法的输出是所有频繁项目集（FI）和感兴趣的不频繁项目集（IIs）。</p><p><img src="/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/4.png" alt=""></p><p>在开始时，算法扫描事务数据库以找出所有频繁的1项集（第3行）。然后它试图从频繁的（k-1）-itemsets（第4~14行）中发现频繁且不频繁的k-项集。 k项目集包含k个项目。首先，它通过连接频繁（k-1）-项来生成感兴趣的候选k项集（参见第5行）。如果它们具有k-2个共同项，则可以连接两个（k-1）-itemsets。假设两个可连接（k-1）-itemsets是{i1，…，ik-2，ik-1}和{i1，…，ik-2，ik}，则连接结果是k-itemset {i1，…，ik-2，ik-1，ik}。其次，该算法利用Apriori属性来修剪具有不频繁子项集的k项集（第6行）。之后，调用函数count_support来计算每个k-itemset的支持（第8行）。如果项目集的支持不小于mfs，则将项目集插入Lk（第10行），即一组频繁的k项目集;否则，如果它的支持不大于mis，则将其插入不频繁的k项集Nk集（第12行）。应该注意，支持为0的项集自然会被忽略。 Lk和Nk分别与FI和IIs（第15行）合并。然后，频繁项目集Lk用于生成更大的项集Lk + 1和Nk + 1。当Lk对于某个k为空时，算法终止，并输出收集的频繁/不频繁项集（第17行）。</p><p>函数count_support扫描数据库以计算项集I的支持（第19~27行）。如果事务支持I（第23行），计数器将增加1。当且仅当它包含I中的所有项目以及所包含项目之间的所有可能关系时（表示为关系（I）），事务支持I。例如，图3中的事务支持itemset {foo，is_valid}，因为它不仅包括两个项foo和is_valid，还包括它们之间的语义关系，即元组（foo，is_valid）。但是，事务不支持itemset {foo，bar}，因为它不包含元组（foo，bar）。</p><p>为了挖掘像{kfree}⇒¬{kfree}这样的规则，我们还提取了像{g，g}这样的2项集，其中g经常被调用，但是在同一函数中它的两个调用实例在语义上很少相关。这有助于NAR-Miner找到表2中的错误14＃（参见§4.2.3）。</p><h2 id="3-5生成负关联规则"><a href="#3-5生成负关联规则" class="headerlink" title="3.5生成负关联规则"></a>3.5生成负关联规则</h2><p>负关联规则A⇒¬B意味着两个频繁项集A和B很少出现在同一事务中。也就是说，（A∪B）很少见。事实上，规则的前因和后果实际上是不常见的项目集的不相交分区。一种直接的负关联规则生成方法是从不频繁的项集I中找出所有对，如&lt;A，B&gt;，其中A∪B= I且A∩B=∅。它使用规则A⇒¬B的统一来确定其不频繁。这种说法的定义如下：</p><p><img src="/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/5.png" alt=""></p><p>其中，支持（A∪¬B）是支持A∪¬B，支持A但不支持A∪B的事务数量。因此，我们有支持（A∪¬B）=支持（A）-支持（A∪B）=支持（A）-支持（I），其中I =A∪B。因此，等式1可以改写为：</p><p><img src="/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/6.png" alt=""></p><p>从具有n个元素（n≥2）的不频繁项集I中，通过直接应用上述方法可以生成最多2个（n-1）个负关联规则。但是，对它们的违反是完全相同的，即支持项目集I的事务。因此，在面向错误检测的应用程序中仅跟踪它们中的一个就足够了。注意，从编程的角度来看，规则A⇒¬B意味着B中的元素不应出现在包含A的上下文中。如果反转规则B⇒¬A不感兴趣，则其违规总是误报，因为存在B并不意味着拒绝A.受此启发，在几乎所有情况下，如果我们期望支持不频繁项集I的事务成为真正的错误，那么从I派生的所有负关联规则应该是有趣的。因此，我们可以选择具有最低置信度的规则来表示这些规则。将置信度作为衡量标准，其他规则如果有趣则会很有趣。</p><p>实际编程中的逻辑通常非常复杂。一些挖掘的规则可能不适用于编程实践。根据它们检测到的违规通常是误报。一般方法是对挖掘的规则进行排名，使得有趣的规则排名最高，而无趣的规则排在最低位。现有工作主要根据他们的置信度对规则进行排名（高信任规则排名最高）。然而，这种信任仅反映了几个有限元素之间的（负/正）相关性。实际上，编程规则的有趣性也与其元素是否集中在某些上下文有关。也就是说，如果元素的调用上下文趋向于更加同类，则由它组成的规则更可能是有趣的。否则，如果元素在非常不同的上下文中使用，则它更通用，并且更可能与各种元素一起出现。在本文中，我们使用一般性来表明元素的上下文有多不同。一般而言，规则由具有高一般性的元素组成，更可能是无趣的元素。</p><p>我们引入信息熵来定量测量元素的一般性。对于程序元素g的调用实例，我们通过g依赖的元素和依赖于g的元素两个来描述它的上下文。我们在g的所有调用实例中提取这些元素并将它们放入包中。包的信息熵反映了调用实例的不同，可以用来衡量g的一般性。包的信息熵（表示为H（g））可以通过等式3计算:</p><p><img src="/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/8.png" alt=""></p><p>其中pi是包中第i个元素的频率; N是g的调用实例数。项集的熵是每个元素的熵的总和。</p><p>根据每个程序元素的一般性，负关联规则R的兴趣度可以测量为：</p><p><img src="/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/10.png" alt=""></p><p>其中H（gi）是元素gi的信息熵。</p><p>我们在算法2中形成了生成负关联规则的方法。该算法将§3.4中提取的频繁项集FI和不频繁项集II以及用户指定的阈值min_conf作为输入。它返回负关联规则NARs的集合。它首先为具有最低置信度的每个不频繁项集I生成代表性规则（第3~5行）。从等式2可以看出，A的支持越小，A⇒¬B的置信度就越低。因此，我们选择支持最小的I子集来生成代表性规则。然后，计算规则的置信度（第6行）并根据阈值min_conf（第7行）进行检查。信息熵用于衡量潜在有趣规则的兴趣（第10行）。最后，负关联规则按其兴趣的降序排序。</p><p><img src="/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/11.png" alt=""></p><h2 id="3-6检测违规行为"><a href="#3-6检测违规行为" class="headerlink" title="3.6检测违规行为"></a>3.6检测违规行为</h2><p>违反负关联规则R：A⇒¬B的是那些支持项集A∪B的事务。直接的方法是直接扫描数据库以找出包含项集A和B的所有事务。但是，这样的枚举方法这非常耗时，特别是对于拥有数十万事务的数据库而言。为了加快检测过程，我们采用了PR-Miner [25]中使用的技巧。在生成频繁且不频繁的项目集时，NAR-Miner还会收集支持它们的事务。我们使用支持者（I）来指示支持项集I的所有事务。然后，违反负关联规则R的集合恰好是支持者（A∪B）。</p><h1 id="4-评估"><a href="#4-评估" class="headerlink" title="4.评估"></a>4.评估</h1><h2 id="4-1实验设置"><a href="#4-1实验设置" class="headerlink" title="4.1实验设置"></a>4.1实验设置</h2><p>我们将NAR-Miner实现为原型系统，以检测大规模C程序中的错误。我们在众所周知的Linux内核（v4.12-rc6）上评估NAR-Miner。 Linux内核已被广泛用作基于挖掘的错误检测方法的评估目标（TOE）[6,14,20,20,22,24-26,30,42,46-48,57,60]。选择Linux内核作为我们的目标的主要原因是我们想要通过检测以前工作中找不到的一些真正的错误来检查我们方法的有效性。 Linux-v4.12-rc6是实验时的最新版本。它包含24,919个C和19,295个标题文件，包括376,680个函数和15,501,651行代码（LoC）。</p><p>为了验证NAR-Miner是否可以应用于其他系统中的错误检测，我们还从不同的域中选择了三种流行的大型C系统：PostgreSQL v10.3，OpenSSL v1.1.1和FFmpeg v3.4.2。 PostgreSQL是一个开源数据库，OpenSSL是一个用于安全通信的库，FFmpeg是一个用于编码/解码多媒体文件的框架。许多错误检测方法选择它们作为评估的目标[19,20,25,35,57]。</p><p>NAR-Miner需要指定三个参数：（1）频繁项集的最小支持阈值（即mfs），（2）不频繁项集的最大支持阈值（即mis），以及（3）有趣的负面规则最小置信度阈值（即min_conf）。通常，如果项目集是具有较高支持的频繁项目集或具有较低支持的不频繁项目集，则项目集将更有趣。此外，较高的最低限度可以进一步消除无趣的负面规则。实际上，不同的参数设置可能导致无法报告某些实际错误或产生过多的错误警报。用户可以保守地或积极地根据检测策略调整这些参数。为了确定合理的参数，我们进行了[6,25,26,49,60]中的实证研究。具体而言，通过抽样分析，当排名前10位的负面规则中有一半以上是有趣的规则时，参数设置被认为是可接受的。在这项研究中，我们将mf设置为15，将mis设置为5，将min_conf设置为85％。在我们的实验中，默认参数设置适用于四种不同的TOE（参见§4.2和§4.3）。</p><h2 id="4-2检测Linux内核中的错误"><a href="#4-2检测Linux内核中的错误" class="headerlink" title="4.2检测Linux内核中的错误"></a>4.2检测Linux内核中的错误</h2><h3 id="4-2-1预处理源代码"><a href="#4-2-1预处理源代码" class="headerlink" title="4.2.1预处理源代码"></a>4.2.1预处理源代码</h3><p>NAR-Miner花了大约77分钟来解析内核源代码并将其转换为事务数据库。在所有函数定义中，有333,248个函数包含一些程序元素（即函数调用或条件检查）。转换后，每个函数定义都映射到数据库中的事务。该数据库包括227,246个不同的元素，其中每个元素对应于函数调用或条件检查。其中，6,203个频繁出现在多个事务中。</p><h3 id="4-2-2挖掘负面规则的有效性"><a href="#4-2-2挖掘负面规则的有效性" class="headerlink" title="4.2.2挖掘负面规则的有效性"></a>4.2.2挖掘负面规则的有效性</h3><p>为了评估包含语义约束规则挖掘和基于信息熵的规则排序的方法的有效性，我们进行了三个实验：NAR-Miner–，NARMiner-，NAR-Miner。每个实验中采用的方法解释如下：</p><ol><li><p>NAR-Miner–：挖掘算法不考虑项目之间的语义关系，挖掘的规则根据其对应性进行排序;</p></li><li><p>NAR-Miner-：基于NAR-Miner–，项目之间的语义关系被用作约束来消除弱语义相关项集;</p></li><li><p>NAR-Miner：基于NAR-Miner-，我们引入信息熵来衡量负关联编程规则的趣味性。该实验评估了NAR-Miner的全部功能。</p></li></ol><p>我们在表1中显示了实验结果，包括频繁项目集（#FI），不频繁项目集（#IIs）的数量，推断的负关联规则的数量，检测到的违规数量以及挖掘，排名和检测的时间成本（时间）很快。</p><p>比较NAR-Miner–和NAR-Miner-或NAR-Miner的结果，我们观察到采用语义约束的挖掘减少了一个数量级的规则和违规总数（＃All列减少约88％） ）。规则爆炸问题在很大程度上得到了缓解。</p><p>由于时间有限，我们在每个实验中手动检查200个排名靠前的负关联规则。这些规则按照他们在NAR-Miner–和NAR-Miner-中的可信度排名，而他们在NAR-Miner中的兴趣则排名靠前。负关联规则如果真的很有意义则标记为“True”，违反它会导致错误或质量问题。例如，{free_netdev}⇒¬{kfree}是一个有趣的（“True”）规则，因为违反它将导致潜在的双重释放错误，例如§2中讨论的错误。在NAR-Miner中，前200条规则中只有2条被认为是有趣的规则。换句话说，其中99％导致违规检测的错误警报。这种有趣规则率低的主要原因是由这些规则组成的程序元素通常在语义上彼此独立。对于下面的例子，虽然在NAR-Miner中排名第一，并且具有99.96％的置信度，但规则{static_key_false}⇒¬{atomic_read}是无趣的，因为这两个函数将完全独立的变量作为包含他们的程序中的实际参数，他们并没有真正压制对方。</p><p><img src="/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/12.png" alt=""></p><p>引入语义约束的挖掘将NAR-Miner-中的误报率降低到90.5％，然而，这仍然太高而不能在实践中被接受。虽然推断规则具有语义相关的所有程序元素，但是一些元素非常通用，并且可以在违规不会导致错误的各种上下文中使用。例如，函数iowrite32是在它们一起出现时依赖于readl的数据，在Linux内核中只出现一次，并且推断出规则{iowrite32}⇒¬{readl}。该规则在NAR-Miner-中排名第8位，并且在99.64％的情况下排名第一，但仍然无趣，因为这两种功能都以各种方式使用，并且它们的组合不会导致任何错误。</p><p>NAR-Miner使用信息熵来测量函数的一般性。 iowrite32和readl分别为5.9和4.6。规则{iowrite32}⇒¬{readl}的有趣性是9.5％，小到足以排名低。以这种方式，大多数不感兴趣的规则被分配低兴趣度值并因此被排在底部，同时潜在有趣的规则被分配具有相对高的兴趣度值并且在顶部排名。在NAR-Miner中，前200个负面规则中有93个标记为“真”，几乎是NAR-Miner-中数字的5倍。特别是，在前50个中有31个“真正的”负规则。真阳性率为62％。也就是说，我们可以在不到两次手动审计中找到一个有趣的规则，这在实际的错误检测中是可以接受的，而不是针对Linux内核等真实的大型系统。</p><p>我们还检查了违反前200条推断规则的情况。从表1中的Violations和#Bugs列中，我们观察到更多报告的违规和由于应用基于语义约束的挖掘和基于信息熵的排序而导致的错误，这最终增强了NAR-Miner的能力，使其能够推断出更多有趣的规则（列#True和TP Rate）</p><p><img src="/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/13.png" alt=""></p><p>4.2.3检测违规行为</p><p>针对NAR-Miner提取的21,166个负关联规则，检测到37,453个违规。我们根据规则的排名手动检查报告的负关联规则及其违规。为了从检测中获得最大的收益，我们选择排名靠前的规则进行审核，因为违反这些规则更可能是真正的错误。我们在一个人一天内检查了200个排名靠前的负面关联规则和相应的356个违规行为（参见表1中的最后一行）。</p><p>我们发现了23个可疑错误和数十个程序质量问题，例如冗余条件检查和计算。由于Linux内核维护者经常忽略质量问题，我们只向Linux内核维护者提交23个可疑错误的补丁。到目前为止，这些补丁中有17个已经被内核维护者所认可和接受。</p><p>表2中列出了确认的bugs，其中包含错误（函数），违反的规则（违规规则）以及三个实验中的规则排名。最后一列显示了这些bug的补丁ID和我们在PatchWork站点上的补丁。在这些发现的bug中，六个（2＃，3＃，8＃，12＃，13＃和14＃）在内核2.6中出现，两个（3＃和12＃）甚至潜伏了10年以上。</p><p><img src="/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/14.png" alt=""></p><p>这些bug总共违反了12个负关联规则。如果按照排名进行排名，则只有其中一个在前200条规则范围内（NAR-Miner-列中为12＃）。但是使用信息熵对规则进行排名会使所有这些规则都进入前200名（NAR-Miner）。这一观察结果表明，将信息熵引入排名对于突出有趣的规则非常有用。我们还观察到这些规则中只有2个是在NAR-Miner–中提取的（“NA”表示没有命中），其他规则都缺失。例如，缺少规则{free_netdev}⇒¬{kfree}（12＃），因为有106个函数同时调用free_netdev和kfree。在不考虑语义关系的情况下，项集{free_netdev，kfree}的支持是106，这远远高于预定阈值mis = 5。</p><p>因此，它不会被视为不常见的项目集，因此无法推断出负关联规则。然而，凭借语义约束的挖掘和信息熵，NAR-Miner成功地推断出规则并发现相应的错误（图1）。因此，我们声称语义约束的挖掘不仅可以帮助减少误报，还可以减少误报。</p><h3 id="4-2-4与基于正规则挖掘的方法的比较"><a href="#4-2-4与基于正规则挖掘的方法的比较" class="headerlink" title="4.2.4与基于正规则挖掘的方法的比较"></a>4.2.4与基于正规则挖掘的方法的比较</h3><p>在实践中，违反负规则的某些错误也可能违反相应的积极规则。因此，应该通过基于负面和正面规则挖掘的方法来检测这样的错误。我们调查是否会发生这种情况。我们选择表2中的17个错误作为基线，进行另一个实验，从§4.2.2中挖掘出的266,449个频繁项目集中使用与NAR-Miner相同的mfs和min_conf设置来推断出正关联规则，然后检测违规规则，如[25]和[26]中所做的那样。手动检查显示检测到17个错误中的3个（表2中的2＃，3＃和15＃），而其他14个错误（约82.4％）丢失。然后，我们使用语义约束的挖掘来增强基于正规则挖掘的方法，即考虑程序元素之间的数据关系。发现了另外两个错误（5＃和14＃），但仍有12个错误（约70.6％）未被发现。因此，我们声称虽然语义约束的挖掘能够帮助基于正规则挖掘的方法检测更多错误，但基于负规则挖掘的方法可以专门发现许多基于正规则挖掘的方法无法实现的错误。</p><h2 id="4-3检测其他系统中的bug"><a href="#4-3检测其他系统中的bug" class="headerlink" title="4.3检测其他系统中的bug"></a>4.3检测其他系统中的bug</h2><p>NAR-Miner进一步应用于PostgreSQL v10.3，OpenSSL v1.1.1和FFmpeg v3.4.2。 NAR-Miner分别从PostgreSQL，OpenSSL和FFmpeg中提取了690,382和335个负面规则。我们在§4.2中手动检查排名靠前的负面规则（不超过50个）及其在每个系统中的违规行为。因此，我们确定了六次违规（每个目标两次），并将其报告给相应的社区。到目前为止，所有六个可疑错误都被相应的系统维护人员修复了。有关详细信息，请参阅邮件列表[41]中PostgreSQL的错误报告，ID为＃15104和＃15105，OpenSSL来自问题列表[40]，ID为＃5567和＃5568，以及来自邮件列表的FFmpeg [39] ID为＃7074和＃7075。实验证明NAR-Miner不限于特定的目标系统（例如，Linux内核），而是可以用于在各种大规模C系统中发现真正的错误。</p><h2 id="4-4案例研究"><a href="#4-4案例研究" class="headerlink" title="4.4案例研究"></a>4.4案例研究</h2><p>在本节中，我们将说明NAR-Miner的能力与基于肯定关联规则（PAR）挖掘的方法在PostgreSQL中的＃15105问题上进行比较。</p><p>在PostgreSQL中，函数OpenTransientFile分配一个文件描述符并将其存储到全局维护的已分配文件列表中。返回描述符必须与CloseTransientFile一起释放，它会在关闭之前从列表中删除描述符。直接使用close会使列表保留已发布的描述符，并可能导致释放后使用的错误。从统计上来说，在PostgreSQL v10.3中，OpenTransientFile在28个函数中被调用。在27个函数中，其返回值传递给CloseTransientFile，但在1函数中，其返回值直接传递给close，从而产生负关联规则{OpenTransientFile}⇒¬{close}和正关联规则{OpenTransientFile}⇒{ CloseTransientFile}具有相同的96.4％的置信度。</p><p>图4显示了函数dsm_impl_mmap，该函数错误地将在第4行用OpenTransientFile分配的文件名描述符fd传递给沿路径的第12行关闭。它违反了上述负面规则，因此被NAR-Miner报告。但是，从伴随分析的角度来看，因为在某些路径上，fd在第8和第16行正确传递给CloseTransientFile，这符合上述正规则的要求。因此，有缺陷的代码确实是支持而不是违反规则。我们通过用CloseTransientFile（fd）替换第12行来解决这个问题，如图4所示。修补程序已经被维护者接受了</p><p><img src="/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/15.png" alt=""></p><h1 id="5-讨论和限制"><a href="#5-讨论和限制" class="headerlink" title="5.讨论和限制"></a>5.讨论和限制</h1><p><strong>负面规则与正面规则</strong>。在本文中，我们主要基于负关联规则而不是正关联规则来检测错误。但是，这两种方法没有必要的矛盾。由于他们专注于不同类型的编程规则，因此它们可以相互补充。从错误检测的角度来看，我们的方法能够提取负面的编程规则并检测基于挖掘正关联规则的方法无法揭示的错误，反之亦然。理论上，两种方法的组合可以表现出更好的检测性能（更少的漏报率）。</p><p>此外，与挖掘积极规则相比，挖掘负面规则通常伴随着产生更多无趣的规则，导致大量的误报。在这种情况下，同一程序的积极规则可以帮助减少它们。例如，如果一段代码违反了否定规则但满足了正规则，则相应的负面规则的违反不太可能成为真正的错误。我们可以降低其排名以避免这种违规行为。类似地，基于正规则的错误检测也可能面临相同的挑战（即，报告误报）。因此，在这种情况下，一个直截了当的问题是，这两种方法是否有助于减少误报？我们将在未来进一步研究。</p><p><strong>规则爆炸</strong>。实质上，负关联规则挖掘中的规则爆炸问题无法完全解决。在本文中，我们采用了一种相对直接的方法。具体来说，我们利用元素之间的语义关系来消除挖掘过程中绝大多数不感兴趣的规则，然后使用信息熵来衡量规则的有趣性，以便进一步突出显示潜在的有趣规则。但是，可能存在多种解决方案。例如，我们可以进一步量化程序元素之间的语义关系的强度，以重新改善挖掘结果。除了数据依赖和数据共享关系之外，还可以利用其他关系，例如控制流关系。这些潜在的改进可以进一步缓解规则爆炸问题，从而降低手动审计效率。这也是我们未来的工作之一。</p><p><strong>挖掘算法</strong>。在本文中，我们采用项集挖掘算法来提取负编程规则。实际上，对于某些类型的编程规则，其他形式的表示和挖掘算法可能更合适。例如，使用序列来表示顺序敏感的编程逻辑[1,29,53,55]比使用项目集更合适。然而，基于序列的算法在发现对顺序不敏感的编程逻辑方面具有较差的鲁棒性。如果我们能够有效地确定编程模式是否对顺序敏感，则可以采用目标算法来挖掘相关规则。这将是我们未来的工作之一。</p><h1 id="6-相关工作"><a href="#6-相关工作" class="headerlink" title="6.相关工作"></a>6.相关工作</h1><p>程序分析已被广泛而成功地用于错误发布。例如，模型检查可以使用目标系统的模型和规范自动验证有限状态系统的正确性属性[10]。由于为目标系统编写模型的成本很高，因此开发实验级模型检查器并在系统代码中发现实际错误[32,59]。研究人员还利用程序分析来检测违反特定规则的行为。通常，向工具提供一组编程规则，其静态地或动态地检查目标系统是否违反给定规则。 Pasareanu和Rungta开发了SPF，通过将符号执行引入到模型检查中来生成Java程序的测试用例[37]。恩格勒等人。提出了使用系统特定编译器扩展[13]静态检查系统规则的技术，而FindBugs作为独立工具运行，以检查Java字节码中错误模式的出现[11]。 Livshits和Lams [28]将用户提供的漏洞规范转换为静态分析器，并使用它们来检测用Java编写的Web应用程序中的漏洞，例如SQL注入和跨站点脚本。此外，Molnar等人。利用动态测试生成来检查二进制程序中的整数错误，检查特定断言的违规情况[31]。尽管它们在解决错误方面取得了成功，但这些方法在很大程度上取决于系统的模型或错误的模式，例如高级API语义[50]，我们称之为先验知识。没有这种知识，他们就无法发现错误。相反，我们的工作会自动发现知识，然后根据收集的知识检测错误。</p><p>还提供了可以从目标系统自动提取知识的技术。 Engler等人提出的先驱工作。采用统计分析来推断给定规则模板的时间规则，检测错误而不指定具体规则[14]。 Kremenek等人使用因子图通过结合不同的信息来源推断程序的规范[22]。这两种方法仅限于推断具有预定模板的规则和必须由用户提供的特定知识。一些方法依赖于挖掘规则中的某些领域知识，并且专门用于推断关键API [1,16,36,49,53,55]或安全敏感函数[47,58]的规则。它们还要求用户提供领域知识以促进挖掘过程。但是，NAR-Miner在根据程序中包含的关联规则（隐式）提取规则时不需要用户提供先验知识。</p><p>最近，研究人员利用数据挖掘算法从真实的大型系统中提取更多一般规则[4,7,8,21,23-25,27,29,30,33,34,44,54,58]。这些基于挖掘的技术背后的首要思想是：在大多数情况下，程序是正确的，因此任何异常都可能是错误。通常，这些方法首先推断出来自目标系统的频繁出现的模式，并将这些模式视为开发人员在编码时应遵循的（隐式）规则。然后，他们发现任何违反这些规则的行为都是潜在的错误。推断的模式可以是正面的也可以是负面的。例如，PR-Miner [25]和AntMiner [26]提取了强制关联规则，强制配对表面的程序行为。Chang等通过从程序控制流中挖掘频繁关联的子图并检查偶发违规来检测缺失的代码结构[7]。 Yun等。根据不同API之间挖掘的语义正关联规则推断出API的正确用法[60]。与这些方法不同，NAR-Miner专注于从源代码中挖掘负关联规则，并检测违反这些规则的错误。也可以从动态执行跟踪中提取类似的规则。Beschastnikh等开发了Synoptic，从系统执行日志中生成时间系统不变量[5]。</p><p>Wang等人开发了Bugram，它使用n-gram语言模型来测量令牌序列的概率，并将低概率序列视为异常，即潜在的错误[52]。Bugram还可以检测由相互抑制的程序元素共同引起的某些错误。但是，由于序列窗口的大小有限，Bugram很难捕获涉及长距离程序元素的错误。</p><p>挖掘负关联规则已应用于购物篮，蛋白质序列和金融数据等数据[18]。对于这样的数据，两个元素之间的关系比对关系贡献不同强度的程序元素的关系简单得多。Wu等人提出了算法，以有效和高效地挖掘大型数据库中的负关联规则[56]。Zhou和Yau提出了一种组合算法来挖掘有趣的关联规则，减少了大量的否定规则[61]。NAR-Miner也可以采用这些算法作为基本挖掘算法，但需要处理程序语义以减少不感兴趣的规则。</p><h1 id="7-结论"><a href="#7-结论" class="headerlink" title="7.结论"></a>7.结论</h1><p>数据挖掘技术已广泛用于推断编程规则，然后根据规则检测软件错误。现有方法已经证明，正关联规则（表明相关的程序元素必须一起出现）对于通过检查违规来检测错误是有用的。然而，拒绝所涉及的程序元素的共同出现的负关联规则大多被忽略。我们提出NAR-Miner从源代码中挖掘负关联规则。我们引入程序语义来指导挖掘阶段。我们还利用函数熵对候选规则进行排名并突出显示有趣的规则。通过这种方式，NAR-Miner显着减少了不感兴趣的规则的数量，并在一定程度上缓解了规则爆炸问题。我们在四个流行的大型系统上评估原型，并发现了相当多的错误，其中一些已被维护者所困扰。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h1&gt;&lt;p&gt;从基于数据挖掘技术的源代码推断编程规则已被证明对检测软件错误是有效的。现有研究侧重于以A⇒B
      
    
    </summary>
    
      <category term="论文" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/"/>
    
      <category term="数据挖掘" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"/>
    
    
      <category term="2018年" scheme="http://yama0xff.com/tags/2018%E5%B9%B4/"/>
    
      <category term="数据挖掘" scheme="http://yama0xff.com/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"/>
    
      <category term="漏洞检测" scheme="http://yama0xff.com/tags/%E6%BC%8F%E6%B4%9E%E6%A3%80%E6%B5%8B/"/>
    
      <category term="源代码" scheme="http://yama0xff.com/tags/%E6%BA%90%E4%BB%A3%E7%A0%81/"/>
    
  </entry>
  
  <entry>
    <title>Superset Disassembly: Statically Rewriting X86 Binaries Without Heuristics Disassembly</title>
    <link href="http://yama0xff.com/2019/01/27/Superset-Disassembly-Statically-Rewriting-X86-Binaries-Without-Heuristics-Disassembly/"/>
    <id>http://yama0xff.com/2019/01/27/Superset-Disassembly-Statically-Rewriting-X86-Binaries-Without-Heuristics-Disassembly/</id>
    <published>2019-01-27T07:33:23.000Z</published>
    <updated>2019-02-14T08:29:43.126Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>静态代码重写是系统安全应用的一项核心技术，它的使用场景包括性能分析，优化和软件错误定位等。之前的许多静态二进制程序重写方法，例如CCFIR, PITTSFIELD, Google’s Native Client, BinCFI, UROBOROS等，在保证重写正确时，提出了有关二进制程序的许多假定，例如完全正确的反汇编，编译器要求，调试符号等等，给实际应用在Commercial off-the-shelf（COTS）二进制程序上制造了困难。作者提供了<code>multiverse</code>，一个新的二进制程序重写器，它不基于上述的任何假定并能够重写intel x86 COTS程序。在COTS二进制程序重写中，存在着两大挑战： （1）如何反汇编二进制代码并包含所有合法指令 （2）如何重新汇编重写后的指令并保留原程序的语义。<strong><code>multiverse</code>使用了两种技术分别解决这两大挑战：（1）superset disassembly：通过对所有offset起始的地址进行反汇编获得合法代码的superset。 （2）instruction rewriter：通过替换控制流转移指令，中转到一个映射表，能够将原程序中所有的指令重定位到任意其他位置。</strong></p><table><thead><tr><th>relevant information</th><th></th></tr></thead><tbody><tr><td><em>作者</em></td><td>Erick Bauman，Zhiqiang Lin，Kevin W. Hamlen 单位：University of Texas at Dallas.</td></tr><tr><td><em>单位</em></td><td>University of Texas at Dallas</td></tr><tr><td><em>出处</em></td><td>NDSS’18</td></tr><tr><td><em>原文地址</em></td><td><a href="https://github.com/wtwofire/database/blob/master/papers/reverse/2018-Superset%20Disassembly%EF%BC%9AStatically%20Rewriting%20x86%20Binaries%20Without%20Heuristics.pdf" target="_blank" rel="noopener">https://github.com/wtwofire/database/blob/master/papers/reverse/2018-Superset%20Disassembly%EF%BC%9AStatically%20Rewriting%20x86%20Binaries%20Without%20Heuristics.pdf</a></td></tr><tr><td><em>源码地址</em></td><td><a href="https://github.com/utds3lab/multiverse" target="_blank" rel="noopener">https://github.com/utds3lab/multiverse</a></td></tr><tr><td><em>发表时间</em></td><td>2018年</td></tr></tbody></table><h1 id="背景与概述"><a href="#背景与概述" class="headerlink" title="背景与概述"></a>背景与概述</h1><p>作者的目的是为了发展一种二进制转化方法，改善现有二进制程序转化方法的实用性和通用性。为了表达简洁，也因为x86的程序更少开源。同时之前的许多代码转化方法也以x86程序为目标，作者的方法集中与主流编译器编译的linux 32位x86程序，同时不适用dlopen等动态载入库和自修改代码。</p><h2 id="挑战"><a href="#挑战" class="headerlink" title="挑战"></a>挑战</h2><p>在编写一个通用的二进制程序重写器时存在着许多挑战：</p><p><strong>C1</strong>：识别和重定位静态内存地址 编译后的二进制程序代码包含许多固定地址，很多指向全局变量。代码重写在移动这些目标时，必须同时更新它们的引用。在反汇编代码中和地址段中识别这些地址常量是非常困难的，因为整数值和这些地址常量在语法上并没有明显的区别。</p><p><strong>C2</strong>：处理动态计算的内存地址<br>在程序中还存在许多动态计算的内存地址。由于地址计算方式比较复杂，生成间接控制流转换表(iCFT)非常困难。重映射iCFT对于二进制程序重写是一个核心挑战。</p><p><strong>C3</strong>：区分代码和数据<br>代码和数据在二进制文件中没有语法上的区别，在现代处理器中，为了优化性能，许多数据被放在代码段中。这给反汇编带来一些困难。</p><p><strong>C4</strong>：作为参数的函数指针<br>作为函数指针的参数如果在目标函数中没有正确识别并且更新到改写后的地址，那么重写后的程序在执行时很可能会调用已经被之前的函数地址，令执行失败。同时，识别函数地址也非常困难。</p><p><strong>C5</strong>：处理位置无关代码<br>主流编译器生成了许多位置无关代码。这些代码会根据自身地址和相对位置寻找其他的执行代码。如果改变了它们的相对位置，那么在执行时就有可能失败。</p><h2 id="核心想法"><a href="#核心想法" class="headerlink" title="核心想法"></a>核心想法</h2><p>基于之前的二进制重写方法，作者系统化了下面的这些想法来针对性地解决上面的挑战</p><p><strong>S1</strong>：保持原有数据空间的完好无损<br>保持程序中数据段原有的位置和内容，这个方法之前也被用在许多二进制重写器中，例如SECONDWRITE和BINCFI</p><p><strong>S2</strong>：创建一个从原有代码空间到新的重写代码空间的映射<br>作者在这个映射中忽略常用的地址计算中 基址+偏移 的方法，只考虑最后获得的最终地址，并将这个地址与重写后的代码地址进行对应。作者对于原有地址空间中的每个代码段地址都找到了一个映射，这样就简单的解决了动态计算的内存地址问题。</p><p><strong>S3</strong>：暴力反汇编所有可能的代码<br>为了解决反汇编可能存在缺失的问题，作者对于从代码段开始的每个偏移，都进行了反汇编直到遇上非法指令，或者已经反汇编过的地址。原程序中执行的所有代码必定是暴力反汇编获得的代码的子集。</p><p><strong>S4</strong>：重写所有用户级别的代码<br>通过重写所有用户级别的代码，可以在函数指针被调用处利用原程序与重写程序之间的地址映射，将指向原程序地址空间的函数指针映射到重写后的地址空间。</p><p><strong>S5</strong>：重写所有call指令以解决pic代码 在查看了x86指令集后，所有的pic代码计算方式在32位x86指令集中，都使用call指令来获得当前地址，作者改写了所有call指令，令其push一个未重写时的地址在栈上，被利用于计算地址时，即可以获得原有计算应得的地址，再由iCFT进行统一处理。</p><h2 id="系统Overview"><a href="#系统Overview" class="headerlink" title="系统Overview"></a>系统Overview</h2><p>基于上面的想法，作者实现了<code>multiverse</code>，正如下面的图片中显示，<code>multiverse</code>系统包含两个分开的步骤，映射和重写：</p><p><img src="/2019/01/27/Superset-Disassembly-Statically-Rewriting-X86-Binaries-Without-Heuristics-Disassembly/1.png" alt="图片1"></p><p>在映射阶段，superset disassembler是用下面所示的算法对代码段开始的每个offset进行反汇编，删除重复的代码并在尾部设置一个跳转指令。可以注意的是，在反汇编中，作者删除了从非法指令向前到最后一条控制转移指令的代码内容：</p><p><img src="/2019/01/27/Superset-Disassembly-Statically-Rewriting-X86-Binaries-Without-Heuristics-Disassembly/2.png" alt="图2"></p><p><code>multiverse</code>修改了反汇编获得的代码中占位符长度过短的jcc，jmp指令，因为它们原来的指令很可能长度不够填充新的跳转地址。在这之后，即可以确定所有重写后的指令长度和位置，此时所有的跳转指令依旧包含着占位符地址。</p><p>在重写阶段，<code>multiverse</code>根据重写后的地址位置和原程序地址创建一个本地代码的映射表。映射表的键值是原程序中的内存地址，值则对应着新的代码空间中的地址。 对于重写程序中的直接跳转，<code>multiverse</code>根据映射表将其修改为新的地址。 对于间接跳转，<code>multiverse</code>将其中转到一个搜索映射表的函数中。函数的输入，跳转目标处于原程序的代码空间中。这个函数通过对应映射表找到新代码空间中的对应地址，并执行跳转。 对于外部函数或地址的跳转。由于这些地址在本地映射表中对应。如下图所示，映射函数将在全局映射表中寻找它所处的代码文件并在其对应的映射表中寻找对应地址。</p><p><img src="/2019/01/27/Superset-Disassembly-Statically-Rewriting-X86-Binaries-Without-Heuristics-Disassembly/3.png" alt="图3"></p><p>为了处理位置无关代码和函数指针，<code>multiverse</code>对于所有的call和ret指令都进行了修改。 通过这样的方式，重写后的代码可以任意的安排指令和基本块位置。 最终<code>multiverse</code>利用重写后的代码生成一个新的elf文件。</p><h1 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h1><p>作者基于许多python库，包括python-capstone，pyelftools,pwntools实现了<code>multiverse</code>，包含超过3000行python代码和超过150行汇编代码。同时，基于重写所处的Linux环境，作者对于动态加载器和VDSO进行了特殊处理。</p><h1 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h1><p>作者使用了所有的SPECint 2006 benchmark程序，共12个，作为测试程序集。测试的机器使用一台ubuntu 14.04.1 lts，Intel i7-2600 cpu，4GB RAM。</p><h2 id="有效性"><a href="#有效性" class="headerlink" title="有效性"></a>有效性</h2><p>作者执行了<code>multiverse</code>重写后的所有程序，并和未重写的版本进行对应，所有重写后的程序都正确的执行完毕，输出和未重写的版本同样的结果。</p><p>下表描述了重写后的程序的详细信息：</p><p><img src="/2019/01/27/Superset-Disassembly-Statically-Rewriting-X86-Binaries-Without-Heuristics-Disassembly/4.png" alt="图4"></p><p>有趣的是，对于代码段，所有重写后的程序的代码段长度大约都是原程序的4-5倍，这很可能与x86指令的平均长度有关。同时，表中所有的.newtext段长度都没有包括大约4MB的全局映射表大小，对于代码段长度较小的case，例如429.mcf，这导致了较大的size overhead。</p><h2 id="开销"><a href="#开销" class="headerlink" title="开销"></a>开销</h2><p>作者在原来的benchmark程序和重写后的程序上运行了10遍，以对程序重写后的性能进行一个衡量，结果如下表所示：</p><p><img src="/2019/01/27/Superset-Disassembly-Statically-Rewriting-X86-Binaries-Without-Heuristics-Disassembly/5.png" alt="图5"></p><p>对于大部分的测试程序来说，时间overhead不超过100%，平均的性能overhead为60.42%。对于471.omnetpp 和 483.xalancbmk，性能损耗较高，这两个程序使用c++语言编写，对类函数和库函数的频繁调用在重写时带来了大量的性能损耗。</p><p>接着作者比较了不同优化措施对性能带来的影响，例如只不重写外部函数库，或者对回调函数进行特殊处理，对位置无关代码进行特殊处理。结果如下图所示：</p><p><img src="/2019/01/27/Superset-Disassembly-Statically-Rewriting-X86-Binaries-Without-Heuristics-Disassembly/6.png" alt="图6"></p><p>可以发现，通过对位置无关代码进行特殊处理（假设程序只使用get_pc_thunk函数），可以获得巨大的性能提升。</p><p>作者测试了使用<code>multiverse</code>进行插桩带来的性能开销，并和常用的工具pin进行了比较，两者都执行对于指令数统计的插桩。</p><p><img src="/2019/01/27/Superset-Disassembly-Statically-Rewriting-X86-Binaries-Without-Heuristics-Disassembly/7.png" alt="图7"></p><p>在大部分情况下，使用<code>multiverse</code>在程序重写中静态进行插桩带来的性能消耗比使用pin来的低，在以下情况下，由于pin对于插桩内部代码进行分析，使用pin的插桩性能损耗稍微好一些。</p><p>最后，作者测试了使用<code>multiverse</code>作为安全应用工具的性能，作者使用<code>multiverse</code>编写了一个shadow stack，并与用pin编写的工具相比较。使用<code>multiverse</code>编写的具有巨大的性能优势。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>作者通过使用了superset disassemble和 instruction rewriter两项技术，开发了<code>multiverse</code>系统，提供了一个不依赖启发式分析的二进制软件重写工具，并且通过对比，证明这个工具在安全应用的性能上，和当前主流的二进制插桩框架PIN相比更有优势。</p><hr><p><em>论文翻译内容转载至GoSSIP.</em></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h1&gt;&lt;p&gt;静态代码重写是系统安全应用的一项核心技术，它的使用场景包括性能分析，优化和软件错误定位等。之
      
    
    </summary>
    
      <category term="论文" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/"/>
    
      <category term="软件分析" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90/"/>
    
    
      <category term="2018年" scheme="http://yama0xff.com/tags/2018%E5%B9%B4/"/>
    
      <category term="二进制反汇编" scheme="http://yama0xff.com/tags/%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%8F%8D%E6%B1%87%E7%BC%96/"/>
    
      <category term="静态重写技术" scheme="http://yama0xff.com/tags/%E9%9D%99%E6%80%81%E9%87%8D%E5%86%99%E6%8A%80%E6%9C%AF/"/>
    
      <category term="NDSS&#39;18" scheme="http://yama0xff.com/tags/NDSS-18/"/>
    
  </entry>
  
  <entry>
    <title>Angora: Efficient Fuzzing by Principled Search</title>
    <link href="http://yama0xff.com/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/"/>
    <id>http://yama0xff.com/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/</id>
    <published>2019-01-25T08:31:20.000Z</published>
    <updated>2019-01-28T09:55:32.592Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>​    Fuzzing是一种用于查找软件错误的流行技术。然而，最先进的模糊器的性能还有很多不足之处。基于符号执行的模糊器产生高质量输入但运行缓慢，而基于随机变异的模糊器运行速度快但难以产生高质量输入。我们提出了一种新的基于突变的模糊器Angora，它的性能远远超过了最先进的模糊器。Angora的主要目标是通过解决路径约束来增加分支覆盖率而无需符号执行。<strong>为了有效地解决路径约束，我们引入了几个关键技术：可扩展的字节级污点跟踪，上下文敏感的分支计数，基于梯度下降的搜索和输入长度探索</strong>。在LAVA-M数据集上，Angora发现了几乎所有注入的错误，发现了比我们比较的任何其他模糊器更多的错误，并且发现错误是程序中第二好的模糊器的8倍。Angora还发现了LAVA作者注射但却无法触发的103个错误。我们还在八个流行的，成熟的开源程序上测试了Angora。Angora分别在file，jhead，nm，objdump和size中发现了6,52,29,40和48个新错误。我们测量了Angora的覆盖范围，并评估了其关键技术如何促成其令人印象深刻的性能。</p><table><thead><tr><th style="text-align:left">relevant information</th><th></th></tr></thead><tbody><tr><td style="text-align:left"><em>作者</em></td><td>Peng Chen, Hao Chen</td></tr><tr><td style="text-align:left"><em>单位</em></td><td>ShanghaiTech University, University of California, Davis</td></tr><tr><td style="text-align:left"><em>出处</em></td><td>IEEE S&amp;P’18</td></tr><tr><td style="text-align:left"><em>原文地址</em></td><td><a href="https://github.com/wtwofire/database/blob/master/papers/fuzzing/2018Angora%20Efficient%20Fuzzing%20by%20Principled%20Search.pdf" target="_blank" rel="noopener">https://github.com/wtwofire/database/blob/master/papers/fuzzing/2018Angora%20Efficient%20Fuzzing%20by%20Principled%20Search.pdf</a></td></tr><tr><td style="text-align:left"><em>源码地址</em></td><td><a href="https://github.com/AngoraFuzzer/Angora" target="_blank" rel="noopener">https://github.com/AngoraFuzzer/Angora</a></td></tr><tr><td style="text-align:left"><em>发表时间</em></td><td>2018年</td></tr></tbody></table><h1 id="1-简介"><a href="#1-简介" class="headerlink" title="1 简介"></a>1 简介</h1><p>​    Fuzzing是一种用于查找软件错误的流行技术。基于覆盖的模糊器面临着如何创建输入以探索程序状态的关键挑战。一些模糊器使用符号执行来解决路径约束[5,8]，但符号执行很慢，无法有效地解决许多类型的约束[6]。为了避免这些问题，AFL不使用符号执行或任何重量级程序分析[1]。它对程序进行插桩，以观察哪些输入探索新的程序分支，并将这些输入作为进一步变异的种子。 AFL在程序执行时产生很低的开销，但是它创建的大多数输入都是无效的（即，它们无法探索新的程序状态），因为它盲目地改变输入而不利用程序中的数据流。几个模糊器为AFL添加了启发式算法来解决简单的判断，例如“魔术字节”[25,19]，但它们无法解决其他路径约束。</p><p>​    我们设计并实现了一个名为Angora的模糊器，它通过解决路径约束而不使用符号执行来探索程序的状态。Angora跟踪未探测的分支并尝试解决这些分支上的路径约束。我们引入了以下技术来有效地解决路径约束。</p><ul><li><p>上下文敏感的分支覆盖。 AFL使用上下文敏感分支覆盖来近似程序状态。我们的经验表明，为分支覆盖添加上下文使Angora能够更普遍地探索程序状态（第3.2节）。</p></li><li><p>可扩展的字节级污点跟踪。大多数路径约束仅依赖于输入中的几个字节。通过跟踪哪些输入字节流入每个路径约束，Angora只改变这些字节而不是整个输入，因此大大减少了探索空间（第3.3节）。</p></li><li><p>基于梯度下降搜索。当改变输入以满足路径约束时，Angora避免了符号执行，这是昂贵的并且不能解决许多类型的约束。相反，Angora使用机器学习中流行的梯度下降算法来解决路径约束（第3.4节）。</p></li><li><p>类型和形状推断。输入中的许多字节共同用作程序中的单个值，例如，在程序中用作32位有符号整数的输入中的四个字节的组。为了允许梯度下降有效搜索，Angora定位上述组并推断其类型（第3.5节）。</p></li><li><p>输入长度探索。只有当输入的长度超过某个阈值时，程序才可以探索某些状态，但是符号执行和梯度下降都不能告诉模糊器何时增加输入的长度。 Angora检测输入长度何时可能影响路径约束，然后充分增加输入长度（第3.6节）。</p></li></ul><p>​        Angora大大超过了最先进的模糊器。表1比较了Angora与其他模糊器在LAVA-M数据集上发现的漏洞[9]。Angora在数据集中的每个程序中发现了更多错误。特别是，Angora发现了1541个漏洞，是第二个最好的模糊器Steelix发现的漏洞数量的8倍。此外，Angora发现了LAVA作者注射但却无法触发的103个错误。我们还在八个流行的，成熟的开源程序上测试了Angora。Angora分别在file，jhead，nm，objdump和size中发现了6,52,29,40和48个新错误（表5）。我们测量了Angora的覆盖范围，并评估了其关键技术如何促成其令人印象深刻的性能。</p><p><img src="/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/p1.png" alt="p1"></p><h1 id="2-背景：AFL"><a href="#2-背景：AFL" class="headerlink" title="2 背景：AFL"></a>2 背景：AFL</h1><p>​    模糊测试是一种自动测试技术，用于查找错误。 American Fuzzy Lop（AFL）[1]是一种基于突变的灰盒模糊器。 AFL采用轻量级编译时插桩和遗传算法来自动发现可能触发目标程序中新内部状态的测试用例。作为基于覆盖率的模糊器，AFL生成输入以遍历程序中的不同路径来触发错误。</p><h2 id="2-1-分支覆盖范围"><a href="#2-1-分支覆盖范围" class="headerlink" title="2.1 分支覆盖范围"></a>2.1 分支覆盖范围</h2><p>​    AFL通过一组分支来测量路径。在每次运行期间，AFL计算每个分支执行的次数。它将分支表示为元组（lprev; lcur），其中lprev和lcur分别是条件语句之前和之后的基本块的ID。AFL通过使用轻量级检测获取分支覆盖率信息。在编译时在每个分支点注入插桩。对于每次运行，AFL分配路径跟踪表以计算每个条件语句的每个分支执行的次数。表的索引是分支的散列，h（lprev; lcur），其中h是散列函数。</p><p>​    AFL还在不同的运行中保留全局分支覆盖表。每个条目都包含一个8位向量，用于记录分支在不同运行中执行的次数。该向量b中的每个位表示一个范围：b0,……,b7分别代表范围[1]，[2]，[3]，[4; 7]，[8; 15]，[16; 31]，[32; 127]，[128; ∞）。例如，如果设置了b3，则表示存在执行此分支执行4到7次的运行，包括。</p><p>​    AFL比较路径跟踪表和分支覆盖表，以启发式方式确定新输入是否触发程序的新内部状态。如果发生以下任一情况，输入将触发新的内部状态：</p><ul><li><p>程序执行新分支，即路径跟踪表具有此分支的条目，但分支覆盖表没有此分支的条目。</p></li><li><p>存在一个分支，其中当前运行中执行的此分支的次数n与先前的任何运行不同。 AFL通过检查表示n的范围的位是否被设置在分支覆盖表中的相应位向量中来近似地确定这一点。</p></li></ul><h2 id="2-2-变异策略"><a href="#2-2-变异策略" class="headerlink" title="2.2 变异策略"></a>2.2 变异策略</h2><p>​    AFL随机应用以下变异[3]。</p><ul><li><p>位或字节翻转。</p></li><li><p>尝试设置“有趣”的字节，单字或双字。</p></li><li><p>将小整数加到或减去字节，单字或双字。</p></li><li><p>完全随机的单字节集。</p></li><li><p>块删除，通过覆盖或插入来复制块，或块memset。</p></li><li><p>在随机位置拼接两个不同的输入文件。</p></li></ul><h1 id="3-设计"><a href="#3-设计" class="headerlink" title="3 设计"></a>3 设计</h1><h2 id="3-1-概述"><a href="#3-1-概述" class="headerlink" title="3.1 概述"></a>3.1 概述</h2><p>​    AFL和其他类似的fuzzer使用分支覆盖作为度量。但是，在计算分支覆盖范围时，它们没有考虑调用上下文。我们的经验表明，没有上下文，分支覆盖将无法充分探索程序状态。因此，我们建议使用上下文敏感分支覆盖作为覆盖度量（第3.2节）。</p><p>​    算法1显示了Angora的两个阶段：插桩和fuzzing循环。在fuzzing循环的每次迭代期间，Angora选择一个未探测的分支并搜索探索该分支的输入。我们介绍了以下关键技术，以有效地找到输入。</p><ul><li><p>对于大多数条件语句，其判断仅受输入中的几个字节的影响，因此改变整个输入将是徒劳的。因此，在探索分支时，Angora会确定哪些输入字节流入相应的判断，并专注于仅改变这些字节（第3.3节）。</p></li><li><p>确定要改变的输入字节后，Angora需要决定如何改变它们。使用基于随机或启发式的突变不能有效地找到令人满意的值。相反，我们将分支上的路径约束视为输入上黑盒函数的约束，并且我们调整梯度下降算法来解决约束（第3.4节）。</p></li><li><p>在梯度下降期间，我们在其参数上评估blackbox函数，其中一些参数由多个字节组成。例如，当输入中的四个连续字节总是作为整数流一起用于条件语句时，我们应该将这四个字节视为函数的单个参数而不是四个独立参数。为了实现这一目标，我们需要推断输入中的哪些字节统一用作单个值以及值的类型是什么（第3.5节）。</p></li><li><p>仅仅改变输入中的字节是不够的。只有在输入超过阈值后才会触发一些错误，但这会在决定输入长度时产生两难。如果输入太短，则可能不会触发某些错误。但如果输入太长，程序可能运行得太慢。大多数模糊器使用临时方法改变输入的长度。相比之下，Angora使用代码检测程序，该代码检测较长输入何时可以探索新分支并确定所需的最小长度（第3.6节）。</p></li></ul><p><img src="/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/图2.png" alt="图2"></p><p>​    图1显示了fuzzing条件语句的步骤图。图2中的程序演示了这些步骤。</p><ul><li><p>字节级污点跟踪：当使用字节级污点跟踪对第2行的条件语句进行模糊测试时，Angora确定字节1024-1031流入此表达式，因此它仅改变这些字节。</p></li><li><p>基于梯度下降的搜索算法：Angora需要分别找到在第2行上运行条件语句的两个分支的输入。Angora将条件语句中的表达式视为输入x上的函数f（x），并使用梯度下降来找到两个输入x和x’，使得f（x）&gt; 0且f（x’）≤0。</p></li><li><p>形状和类型推断：f（x）是向量x上的函数。在梯度下降期间，Angora分别计算f的每个分量的f的偏导数，因此它必须确定每个分量及其类型。在第2行，Angora确定x由两个组件组成，每个组件由输入中的四个字节组成，并具有32位有符号整数类型。</p></li><li><p>输入长度探索：除非输入至少有1032个字节，否则main不会调用foo。我们不是盲目地尝试更长的输入，而是检测从输入读取的常用函数，并确定更长的输入是否会探索新的状态。例如，如果初始输入短于1024字节，则第12行上的条件语句将执行true分支。</p></li></ul><p>​       由于fread的返回值与1024进行比较，因此Angora知道只有至少1024字节长的输入才能探索错误分支。类似地，第16行和第19行的检测指示Angora将输入扩展到至少1032个字节以执行函数foo。</p><p><img src="/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/图3.png" alt="图3"></p><p><img src="/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/图4.png" alt="图4"></p><h2 id="3-2-上下文敏感的分支计数"><a href="#3-2-上下文敏感的分支计数" class="headerlink" title="3.2 上下文敏感的分支计数"></a>3.2 上下文敏感的分支计数</h2><p>​    第2节描述了AFL的分支覆盖表。它的设计有几个优点。首先，它节省空间。分支数量与程序大小呈线性关系。其次，使用范围来计算分支执行在关于不同执行计数是否指示了程序新的内部状态提供了良好启发。当执行计数很小（例如，小于4）时，计数的任何变化都是显着的。然而，当执行计数很大（例如，大于32）时，变化必须足够大以被认为是重要的。</p><p>​    但这种设计有局限性。由于AFL的分支对上下文不敏感，因此它们无法区分不同上下文中同一分支的执行，这可能会忽略程序新的内部状态。图3说明了这个问题。考虑第3行分支的覆盖范围。在第一次运行期间，程序采用输入“10”。当它在第19行调用f（）时，它在第4行执行true分支。之后，当它在第21行调用f（）时，它在第10行执行false分支。由于AFL对分支的定义是上下文不敏感的，它认为两个分支都已执行。之后，当程序采用新输入“01”时，AFL认为此输入不会触发新的内部状态，因为第4行和第10行的分支都在上一次运行中执行。但实际上这个新输入触发了一个新的内部状态，因为当输入[2] == 1时它将导致第6行崩溃。</p><p>​    我们将上下文合并到分支的定义中。我们将分支定义为元组（lprev, lcur, context），其中l prev和lcur分别是条件语句之前和之后的基本块的ID，context是h（stack）其中h是散列函数，并且stack包含调用堆栈的状态。例如，让图3中的程序首先在输入10上运行。在它从第19行进入f（）之后，它将执行分支（l3; l4; [l19]）。然后，在从第21行进入f（）之后，它将执行分支（l3; l10; [l21]）。相反，当程序在输入“01”上执行时，它将执行分支（l3; l10; [l19]），然后执行（l3; l4; [l21]）。通过将调用上下文合并到分支的定义中，Angora可以检测到第二次运行会触发新的内部状态，这将在改变输入时[2]时导致第6行产生carsh。</p><p>​    向分支添加上下文会增加独特分支的数量，这在发生深度递归时可能会很明显。我们当前的实现通过选择用于计算调用堆栈的散列的特定函数h来缓解该问题，其中h计算堆栈上所有调用位置的ID的xor。当Angora插桩程序时，它会为每个调用点分配一个随机ID。因此，当函数f递归调用自身时，无论Angora将同一调用站点的ID推送到调用堆栈多少次，h（堆栈）最多输出两个唯一值，在函数f中这最多会使独特分支的数量增加一倍。我们对现实世界程序的评估表明，在结合上下文后，独特分支的数量增加了多达7.21倍（表7），以换取改进代码覆盖的好处（图7）。</p><h2 id="3-3-字节级别的污点跟踪"><a href="#3-3-字节级别的污点跟踪" class="headerlink" title="3.3 字节级别的污点跟踪"></a>3.3 字节级别的污点跟踪</h2><p>​    Angora的目标是创建执行未开发分支的输入。当它尝试执行未探测的分支时，它必须知道输入中的哪些字节偏移影响分支的谓词。因此，Angora需要字节级别的污点跟踪。然而，污点跟踪是昂贵的，尤其是在单独跟踪每个字节时，因此AFL避免了它。我们的主要观点是，在大多数程序运行中都不需要进行污点跟踪。一旦我们对输入运行了污点跟踪（图1中的步骤1），我们就可以记录哪些字节偏移流入每个条件语句。然后，当我们改变这些字节时，我们可以在没有污点跟踪的情况下运行程序。这通过其许多突变来分摊一个输入上的污点跟踪成本，这使得Angora具有与AFL类似的输入执行吞吐量（第5.6节）。</p><p>​    Angora将程序中的每个变量x与污点标签tx相关联，污点标签tx表示输入中可能流入x的字节偏移量。污点标签的数据结构对其内存占用量有很大影响。一个简单的实现是将每个污点标签表示为位向量，其中每个位i表示输入中的第i个字节。然而，由于该位向量的大小在输入的大小上线性增长，因此该数据结构对于大输入将是禁止的，但是在某些程序中找到错误需要大量输入。</p><p>​    为了减少污点标签的大小，我们可以将位向量存储在表中，并使用表中的索引作为污点标签。只要表中条目数的对数远小于最长位向量的长度（通常是这种情况），我们就可以大大减小污点标签的大小。</p><p>​    但是，这种数据结构带来了新的挑战。污点标签必须支持以下操作：</p><ul><li><p>INSERT（b）：插入位向量b并返回其标签。</p></li><li><p>FIND（t）：返回污点标签t的位向量。</p></li><li><p>UNION（tx; ty）：返回污点标签，表示污点标签tx和ty的位向量的并集。</p></li></ul><p>​       FIND代价很低，但UNION很高。 UNION采取以下步骤。首先，它找到两个标签的位向量并计算它们的联合u。这一步代价很低。接下来，它搜索表以确定u是否已存在。如果没有，它会增加u。但如何高效搜索？线性搜索会很昂贵。或者，我们可以构建一个位向量的哈希集，但是如果它们中有很多并且每个位向量都很长，那么计算哈希码和存储哈希集的空间就会花费很多时间。由于UNION是我们在算术表达式中跟踪污染数据时的常见操作，因此它必须是高效的。注意，我们不能使用UNION-FIND数据结构，因为矢量不是不相交的，即两个不同的位矢量可能在同一位置具有1。</p><p>​    我们提出了一种新的数据结构，用于存储位向量,允许有效INSERT，FIND和UNION。对于每个位向量，数据结构使用无符号整数为其分配唯一标签。当程序插入新的位向量时，数据结构会为其分配下一个可用的无符号整数。</p><p>​    数据结构包含两个组件。</p><ul><li><p>二叉树将位向量映射到其标签。每个位向量b由级别为|b|的唯一树节点vb表示，其中|b|是b的长度。 vb存储b的标签。要从根到达vb，检查b0,b1…顺序。如果bi为0，则转到左边的子节点;否则，去右边的子节点。每个节点都包含一个指向其父节点的后向指针，以允许我们从vb开始检索位向量。</p></li><li><p>查找表将标签映射到其位向量。标签是该表的索引，相应的条目指向表示该标签的位向量的树节点。</p></li></ul><p>​       在该数据结构中，树中的所有叶子表示位向量，并且没有内部节点表示位向量。但是，树中的许多节点可能是不必要的。例如，如果向量x00 <em>在树中但没有向量x0 [01] </em> 1 [01] <em>在树中，其中x是任何位序列，那么就不必在节点之后存储任何节点表示x，因为x只有一个是叶子的结点，而这个叶子代表x00 </em>。这里我们使用正则表达式的通用符号，其中x *表示x重复零次或多次，[xy]表示x或y。这个观察允许我们在将一个向量插入树中时修剪向量，如下所示：</p><ol><li><p>删除向量的所有尾随0。</p></li><li><p>跟踪向量中的位，从第一位到最后一位，遍历树。</p></li></ol><ul><li><p>如果位为0，请跟随左节点</p></li><li><p>否则，请跟随右节点。</p></li><li><p>如果节点不存在，请创建它。</p></li></ul><ol start="3"><li>将向量的标签存储在我们访问的最后一个节点中。</li></ol><p>​       算法2详细描述了这种插入操作。</p><p>​    算法3和算法4分别描述了FIND和UNION操作。请注意，当我们创建节点时，最初它不包含标签。稍后，如果此节点是我们插入位向量时访问的最后一个节点，我们将位向量的标签存储在此节点中。通过此优化，此树具有以下属性：</p><ul><li><p>每个叶节点都包含一个标签。</p></li><li><p>内部节点可能包含标签。我们可能会在没有标签的内部节点中存储标签，但我们永远不会在任何内部节点中替换标签。</p></li></ul><p>​        该数据结构极大地减少了用于存储位向量的存储器占用。设每个位向量的长度为n，并设有l个位向量。如果我们天真地将所有位向量存储在查找表中，则需要O（nl）空间。但是，在我们的数据结构中，树中的节点数是O（l）。每个节点可以存储最多一个索引到查找表。由于查找表具有l个条目并且每个条目是指针并且因此具有固定大小，因此查找表的大小是O（l），并且查找表的每个索引具有O（log 1）位。因此，总空间要求为O（l·log l）。</p><p><img src="/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/图5.jpg" alt="图5"></p><h2 id="3-4-基于梯度下降的搜索算法"><a href="#3-4-基于梯度下降的搜索算法" class="headerlink" title="3.4 基于梯度下降的搜索算法"></a>3.4 基于梯度下降的搜索算法</h2><p>​    字节级污点跟踪发现输入流中的哪些字节偏移成为条件语句。但是如何改变输入以运行未探索的分支语句？大多数模糊测试者随机地或使用粗略的启发式方法改变输入，但这些策略不太可能快速找到合适的输入值。相比之下，我们将此视为搜索问题，并利用机器学习中的搜索算法。我们在实现中使用了梯度下降，但其他搜索算法也可能有效。</p><p>​    在这种方法中，我们将用于执行分支断定看作黑盒函数f（x）的约束，其中x是输入中流入判断的值的向量，并且f（）捕获计算在从程序开始到此判断的路径。 f（x）有三种类型的约束：</p><ol><li><p>f（x）&lt;0。</p></li><li><p>f（x）&lt;= 0。</p></li><li><p>f（x）== 0。</p></li></ol><p>​       表2显示我们可以将所有形式的比较转换为上述三种类型的约束。如果条件语句的判断包含逻辑运算符&amp;&amp;或||，则Angora会将语句拆分为多个条件语句。例如，它将（a &amp;&amp; b）{s} else {t}拆分为if（a）{if（b）{s} else {t}} else {t}。</p><p>​    算法5显示了搜索算法。从初始x0开始，找到x使得f（x）满足约束。请注意，为了满足每种类型的约束，我们需要最小化f（x），并且我们使用梯度下降来实现此目的。</p><p>​    梯度下降找到函数f（x）的最小值。该方法是迭代的。每次迭代都从x开始，计算∇xf（x）（x处的f（x）的梯度），并将x更新为x-ε∇xf（x），其中ε是学习率。</p><p>​    在训练神经网络时，研究人员使用梯度下降来找到一组最小化训练误差的权重。然而，梯度下降的问题在于它有时可能会陷入局部最小值，而不是全局最小值。幸运的是，这在模糊测试中通常不是问题，因为我们只需要找到足够好的输入x而不是全局最优x。例如，如果约束是f（x）&lt;0，那么我们只需要找到一个x，其中f（x）&lt;0而不是f（x）是全局最小值。</p><p>然而，当将梯度下降应用于模糊时，我们面临着独特的挑战。梯度下降需要计算梯度∇xf（x）。在神经网络中，我们可以用分析形式编写∇xf（x）。然而，在模糊测试中，我们没有f（x）的分析形式。其次，在神经网络中，f（x）是连续函数，因为x包含网络的权重，但在模糊中f（x）通常是离散函数。这是因为典型程序中的大多数变量都是离散的，因此x中的大多数元素都是离散的。</p><p>​    我们使用数值近似解决了这些问题。 f（x）的梯度是唯一的矢量场，其每个点x处的任意单位矢量v的点积是f沿v的方向导数。我们用δf(x) /δ（xi）= f（x+δv i）-f（x））/δ逼近每个方向导数其中δ是小的正值（例如，1），vi是第i维的单位矢量。为了计算每个方向导数，我们需要运行程序两次，一次使用原始输入x，一次使用扰动输入x + δvi。在第二次运行中，程序可能无法到达计算f（x +δvi）的程序点，因为程序在较早的条件语句中采用了不同的分支。当发生这种情况时，我们将δ设置为小的负值（例如，-1）并尝试再次计算f（x +δvi）。如果成功，我们会根据它计算方向导数。否则，我们将导数设置为零，指示梯度下降不要在此方向上移动x。计算梯度的时间与矢量x的长度成比例，因为Angora分别计算每个方向导数。第3.5节将描述如何通过合并在程序中用作单个值的连续字节来减少x的长度。</p><p>​    理论上，梯度下降可以解决任何约束。实际上，梯度下降可以解决约束的速度取决于数学函数的复杂性。</p><ul><li><p>如果f（x）是单调的或凸的，那么即使f（x）具有复杂的分析形式，梯度下降也可以快速找到解。例如，考虑约束f（x）&lt;0，其中f（x）使用一些多项式系列近似log（x）。由于复杂的分析形式，符号执行很难解决这种约束。但是，梯度很容易解决，因为f（x）是单调的。</p></li><li><p>如果梯度下降的局部最小值满足约束，则查找解决方案也很快。</p></li><li><p>如果局部最小值不满足约束条件，则Angora必须随机走到另一个值x并从那里开始递减渐变，希望找到满足约束的另一个局部最小值。</p></li></ul><p>​       请注意，Angora不会生成f（x）的分析形式，而是运行程序来计算f（x）。</p><p><img src="/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/图6.png" alt="图6"></p><h2 id="3-5形状和类型推断"><a href="#3-5形状和类型推断" class="headerlink" title="3.5形状和类型推断"></a>3.5形状和类型推断</h2><p>​    天真地，我们可以让输入中的x中的每个元素成一个字节流入到判断处。但是，由于类型不匹配，这会导致梯度下降问题。例如，让程序将输入中的四个连续字节b3b2b1b0视为整数，并让xi表示该整数值。当计算f（x +δvi）时，我们应该将δ加到这个整数。但是如果我们天真地将每个字节b3，b2，b1，b0分配给x中的不同元素，那么我们将在每个字节上计算f（x +δvi），但这是不合适的。</p><p>​    程序将这些字节组合为单个值并仅使用表达式中的组合值，因此当我们向除最低有效字节之外的任何字节添加小的δ时，我们将显着更改此组合值，这将导致计算的偏导数是一个不正确的真实值的近似。</p><p>​    为了避免这个问题，我们必须确定（1）输入中的哪些字节总是一起用作程序中的单个值，以及（2）值的类型是什么。我们称第一个问题为形状推理，第二个问题类型推断，并在动态污点分析过程中解决它们。</p><p>​    对于形状推断，最初输入中的所有字节都是独立的。在污点分析期间，当指令将输入字节序列读入变量，其中序列的大小与基本类型的大小匹配（例如，1,2,4,8字节）时，Angora将这些字节标记为属于相同的值。当冲突发生时，Angora使用最小的尺寸。对于类型推断，Angora依赖于对值进行操作的指令的语义。例如，如果指令对有符号整数进行操作，则Angora将相应的操作数推断为有符号整数。当相同的值同时用作有符号和无符号类型时，Angora将其视为无符号类型。请注意，当Angora无法推断出值的精确大小和类型时，这并不能防止梯度下降找到解决方案 - 搜索只需要更长的时间。</p><p><img src="/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/图7.png" alt="图7"></p><h2 id="3-6-输入长度探索"><a href="#3-6-输入长度探索" class="headerlink" title="3.6 输入长度探索"></a>3.6 输入长度探索</h2><p>​    与大多数其他模糊器一样，Angora开始使用尽可能小的输入进行模糊测试。但是，仅当输入长于阈值时才执行某些分支。这给模糊器带来了两难境地。如果模糊器使用太短的输入，则无法探索这些分支。但如果它使用太长的输入，程序可能运行缓慢甚至内存不足。大多数工具使用临时方法尝试不同长度的输入。相比之下，Angora只有在这样做才能探索新的分支时才会增加输入长度。</p><p>​    在污点跟踪期间，Angora将类似read的函数调用中的目标内存与输入中的相应字节偏移相关联。它还使用特殊标签标记来自读取调用的返回值。如果在条件语句中使用返回值并且不满足约束，则Angora会增加输入长度，以便读取调用可以获取它请求的所有字节。例如，在图2中，如果第12行的条件语句为false，则Angora会扩展输入长度，以便fread可以读取它请求的所有1024个字节。我们的标准并非详尽无遗，因为程序可以消耗输入并以我们未预料到的方式检查其长度，但是一旦我们发现它们就很容易将这些标准添加到Angora。</p><h1 id="4-实现"><a href="#4-实现" class="headerlink" title="4  实现"></a>4  实现</h1><h2 id="4-1-插桩"><a href="#4-1-插桩" class="headerlink" title="4.1 插桩"></a>4.1 插桩</h2><p>​    对于每个要模糊的程序，Angora通过使用LLVM Pass [18]检测程序来生成相应的可执行文件。</p><ul><li><p>插桩收集条件语句的基本信息，并通过污点分析将条件语句链接到其对应的输入字节偏移。在每个输入上，Angora只运行此步骤一次（而不是在改变此输入时）。</p></li><li><p>记录执行跟踪以识别新输入。</p></li><li><p>在运行时支持上下文（第3.2节）。</p></li><li><p>在判定中收集表达式值（第3.4节）。</p></li></ul><p>​       为了支持3.3节中描述的可扩展字节级污点跟踪，我们通过扩展DataFlowSanitizer（DFSan）[21]为Angora实现了污点跟踪。我们为FIND和UNION操作实现了缓存设施，显着加快了污点跟踪。</p><p>​    Angora依赖于LLVM 4.0.0（包括DFSan）。它的LLVM pass包含820行C ++代码，不包括DFSan，运行时有1950行C ++代码，包括用于存储污点标签的数据结构以及用于污染输入和跟踪条件语句的钩子。</p><p>​    除了具有两个分支的if语句之外，LLVM IR还支持switch语句，这可能会引入多个分支。在我们的实现中，为方便起见，Angora将每个switch语句转换为if语句序列。</p><p>​    Angora识别libc函数，用于在条件语句中出现时比较字符串和数组。</p><p>​    例如，Angora将“strcmp（x，y）”转换为“x strcmp y”，其中strcmp是Angora理解的特殊比较运算符。</p><h2 id="4-2-Fuzzer"><a href="#4-2-Fuzzer" class="headerlink" title="4.2 Fuzzer"></a>4.2 Fuzzer</h2><p>​    我们以4488行Rust代码中实现了Angora。我们使用fork server [30]和CPU绑定等技术优化了Angora。</p><h1 id="5-评估"><a href="#5-评估" class="headerlink" title="5 评估"></a>5 评估</h1><p>​    我们分三个步骤评估了Angora。首先，我们将Angora的性能与其他最先进的模糊器进行了比较。然后，我们测量了Angora的测试覆盖率及其在现实世界程序中发现未知错误的能力。最后，我们评估了它的关键新颖特征。</p><p>​    我们在64位Ubuntu 16.04 LTS的Intel Xeon E5-2630 v3和256 GB内存的服务器上运行了所有实验。尽管Angora可以同时对多个内核上的程序进行模糊处理，但我们将其配置为在评估期间仅在一个内核上模糊该程序，以将其性能与其他模糊器进行比较。我们对每个实验进行了五次运行并报告了平均性能。</p><h2 id="5-1-Angora与其他模糊器进行比较"><a href="#5-1-Angora与其他模糊器进行比较" class="headerlink" title="5.1 Angora与其他模糊器进行比较"></a>5.1 Angora与其他模糊器进行比较</h2><p>​    比较模糊器的最终指标是它们发现错误的能力。一个好的测试集应该包含具有实际错误的真实程序。 LAVA是一种通过在程序源代码中注入大量实际错误来生成真实语料库的技术[9]。作者通过在每个程序中注入多个错误来创建语料库 LAVA-M。 LAVA-M由四个GNU coreutils程序组成：uniq，base64，md5sum和who。每个注入的bug都有一个唯一的ID，在触发bug时会打印出来。</p><p>​    我们将Angora与以下最先进的模糊器进行了比较：</p><ul><li><p>FUZZER（基于覆盖的模糊器）和SES（符号执行和SAT求解）。 LAVA的作者将它们都运行了5个小时[9]。</p></li><li><p>VUzzer：使用“魔术字节”策略的模糊器[25]。它的作者报告了LAVA-M程序中发现的错误数量，但没有报告运行时间。</p></li><li><p>Steelix：一个模糊器在LAVAM上表现优于VUzzer [19]。作者通过运行模糊器5小时报告了LAVA-M程序中发现的错误数量。[11]</p></li><li><p>AFL 2.51b：撰写本文时的最新版AFL。我们运行AFL五个小时，我们为AFL提供了一个CPU核心，用于对每个程序进行模糊测试。</p></li><li><p>Angora：我们使用与AFL相同的设置（每个程序一个CPU核心）。</p></li></ul><p>​       表1比较了所有模糊器发现的错误。AFL表现最差，在所有程序中总共发现了10个错误。 VUzzer的作者无法在md5sum上运行它，因为LAVA作者错误地修改了md5sum，导致它在所有输入上崩溃。我们向LAVA作者证实了这个问题并修复了它。 Steelix是第二个最好的模糊器，它发现了base64中几乎所有的错误，但是在uniq中28个中只有7个注入了错误，57个md5sum注入了错误中的28个，2136个中有194个注入了错误。Angora大大超过了Steelix，发现了uniq，base64和md5sum中的所有错误，并且2136中的1443个注入了错误。</p><p>​    LAVA为每个注入的bug分配一个唯一的ID，该ID在触发错误时打印。文件验证的错误列出了LAVA作者在创建LAVA时能够触发的所有注入错误。Angora不仅发现了uniq，base64，md5sum中列出的所有错误以及大多数列出的错误，还列出了103个未列出的错误（LAVA作者注入但无法触发的错误）。表3显示了这些未列出的错误的ID。表4显示了Angora发现的列出和未列出的错误的细分。</p><p><img src="/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/图8.png" alt="图8"></p><p>​    图4显示了Angora在who中随着时间的推移发现的错误累积数量。我们没有显示其他模糊器的结果，因为他们发现who没有错误。图4显示，最初Angora很快发现了错误，在不到五分钟内发现了1000个错误。然后发现速度减慢，但在总共2136个列出的错误中，它仅在45分钟内发现超过1500个错误。</p><p>​    我们接下来解释为什么Angora发现了比下一个最好的模糊器更多的错误。首先，LAVA使用“魔术字节”来保护包含错误的分支，但是一些魔术字节不是直接从输入复制而是从输入计算。由于VUzzer和Steelix的“魔术字节”策略只能将魔术字节直接复制到输入，因此该策略无法创建探索这些分支的输入。相比之下，Angora跟踪流入判定的输入字节偏移，然后通过梯度下降而不是假设“魔术字节”或输入与判定之间的任何其他特殊关系来改变这些偏移，因此Angora可以找到探索这些的输入分支机构。其次，VUzzer盲目地尝试“魔术字节”策略，一旦魔术字节中的一个与随机突变后的输入中的字节匹配，Steelix就会关注“魔术字节”策略。相比之下，Angora安排其所有计算能力来解决未探测分支上的路径约束，因此它可以覆盖更多分支，因此可以快速找到LAVA-M中的大部分注入错误。</p><p><img src="/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/图9.png" alt="图9"></p><h2 id="5-2-在未修改的真实程序中评估Angora"><a href="#5-2-在未修改的真实程序中评估Angora" class="headerlink" title="5.2 在未修改的真实程序中评估Angora"></a>5.2 在未修改的真实程序中评估Angora</h2><p>​    Angora在LAVA上的表现令人印象深刻，不仅发现了大部分列出的错误，还发现了许多未列出的错误。然而，它的怀疑论者可能会争辩说这些bug是人为注入的。为了解决这个问题，我们使用最新版本评估了八个流行的开源程序。由于这些成熟的，受欢迎的程序已经过广泛测试，我们预计它们几乎没有残留物崩溃的错误。因此，除了测量发现的新错误的数量外，我们还测量了Angora对这些程序的报道。我们使用了gcov，它记录了输入中程序中执行的所有行和分支[14]。我们将由Angora生成的每个输入馈送到用gcov编译的程序以获得累积代码覆盖率，并且afl-cov3允许我们自动执行此操作。我们还在这些程序上运行AFL进行比较。表5显示了使用一个CPU内核运行Angora和AFL五小时后的结果。我们通过AFL的afl-cmin -C命令重复删除了崩溃。</p><p>​    表5显示Angora在线路覆盖范围，分支覆盖范围以及每个程序发现崩溃时表现优于AFL。在文件，jhead，nm，objdump和大小中，AFL发现了0,19,12,4,6个独特的崩溃，而Angora分别发现了6,52,29,40和48个独特的崩溃。对比度在jhead最为突出，Angora的线路覆盖率提高了127.4％，分支覆盖率提高了144.0％。</p><p>​    图5比较了Angora和AFL随时间的累积线和分支覆盖率。它表明Angora在任何时候都覆盖了比AFL更多的线和分支。Angora优越覆盖的原因在于它可以探索复杂条件语句的两个分支。例如，图6显示了文件中的这样一个语句，其中Angora成功地探索了两个分支，但AFL无法探索真正的分支。在接下来的部分中，我们将评估Angora的每个关键特性如何有助于其卓越的性能。</p><p><img src="/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/图10.png" alt="图10"></p><p><img src="/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/图11.png" alt="图11"></p><p>5.3上下文相关的分支计数</p><p>​    <strong>5.3.1</strong> <strong>性能</strong>。 3.2节介绍了上下文相关分支计数。我们相信在不同的函数调用上下文中区分相同的分支会发现更多的错误。为了评估这个假设，我们分别使用上下文相关的分支计数和上下文不相关的分支计数来运行Angora。表6显示Angora发现6个错误具有上下文相关的分支计数，但在上下文不相关中它没有错误。图7显示从30分钟开始到模糊测试，Angora始终覆盖更多具有上下文相关分支计数的累积行。我们发现了几个真实世界的例子，其中上下文相关的分支计数允许Angora探索更多路径。例如，图8显示了程序文件中readelf.c文件中的代码片段。函数getu32在多个上下文中调用，它根据swap参数返回不同的结果。如果没有上下文相关的分支计数，Angora将无法在所有调用上下文中探索条件语句的两个分支。</p><p>​    <strong>5.3.2</strong> <strong>哈希碰撞</strong>。与AFL类似，Angora将分支计数存储在哈希表中。当Angora在计算分支覆盖率时合并调用上下文时，它会在哈希表中插入更多的唯一分支，因此我们必须增加哈希表的大小以保持较低的冲突率。</p><p>​    我们评估了5.2节中描述的真实世界程序中有多少独特的分支上下文相关性。 AFL的作者观察到，唯一分支（没有上下文）的数量通常在2k到10k之间，而具有216个bucket的哈希表应该足以满足常见情况[30]。表7显示合并上下文相关度将唯一分支的数量增加了至多8倍，这要求我们将散列表的大小增加8倍以具有相同的预期散列冲突率。默认情况下，Angora在其哈希表中分配220个bucket，这是AFL中哈希表的16倍，对大多数程序来说应该足够了。虽然在不再适合缓存时增加哈希表可能是有害的，但不像AFL那样遍历哈希表以查找新路径并优先处理覆盖许多基本块的输入，对于每个输入，Angora只遍历哈希表一次找到新的路径。因此，Angora受哈希表大小增长的影响较小，如第5.6节中的执行速度所示。</p><p><img src="/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/图12.png" alt="图12"></p><h2 id="5-4-基于梯度下降的搜索"><a href="#5-4-基于梯度下降的搜索" class="headerlink" title="5.4 基于梯度下降的搜索"></a>5.4 基于梯度下降的搜索</h2><pre><code>第3.4节描述了如何使用梯度下降来解决条件语句中的约束。我们将梯度下降与另外两种策略进行了比较：随机变异，VUzzer的魔术字节加随机变异。为了排除测量中的其他变量，我们确保三种策略接收相同的输入：我们收集了AFL在5.2节中生成的输入，并将它们作为模糊的唯一输入提供给Angora。我们分别使用上述三种策略运行Angora两小时。</code></pre><p>​    表8显示梯度下降解决了比所有程序中的其他两个策略更多的约束。如第5.1节的最后一段所述，“魔术字节”策略无法解决其值未直接从输入复制的约束。例如，图6中的变量descsz用于程序中的许多约束，但它不是直接从输入复制的，因此“魔术字节”策略没有帮助。</p><h2 id="5-5-输入长度探测"><a href="#5-5-输入长度探测" class="headerlink" title="5.5  输入长度探测"></a>5.5  输入长度探测</h2><p>​    第3.6节描述了当Angora观察到路径约束可能取决于长度时，按需增加输入的长度，而AFL和相关的模糊器随机增加输入长度。我们基于两个标准比较了这两种策略：</p><ul><li><p>策略增加输入长度的次数是多少？在这个战略创造的投入中，有多少是有用的？如果输入直接或在某些突变后探索新分支，则输入有用。</p></li><li><p>这些有用输入的平均长度是多少？</p></li></ul><p>​       我们分别用我们提出的策略和随机策略运行Angora五小时。表9显示Angora的策略将输入长度增加了大约两个数量级，比随机策略少了几个数量级，但它在所有情况下都发现了更有用的输入，除了两个：在readpng它发现总共46个中有用输入少3个，并且在jhead上，既没有策略发现任何有用的输入，因为jhead只解析图像的标题，因此不受图像数据长度的影响。表9还显示，虽然Angora的策略产生了更多有用的输入，但它在每个测试程序上平均产生较短的输入。较短的输入使许多程序运行得更快。该评估表明，Angora的战略比随机战略产生更高质量的投入。</p><p><img src="/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/图13.png" alt="图13"></p><p>5.6 执行速度</p><p>Angora的污染追踪代价很高。然而，Angora为每个输入运行一次污染跟踪，然后改变输入并多次运行程序而没有污点跟踪，因此一次性成本是摊销的。由于分支计数主导了没有污点跟踪的插桩代码的运行时间，因此Angora插桩程序的运行速度与其AFL插桩版本的运行速度大致相同。表10显示AFL以比Angora略高的速率执行输入。然而，由于Angora产生更高质量的输入，更有可能探索新的分支，Angora有更好的覆盖范围，并发现明显更多的错误，如前所示。</p><p><img src="file:///C:\Users\admin\AppData\Local\Temp\msohtmlclip1\01\clip_image002.jpg" alt="img"></p><h1 id="6-相关工作"><a href="#6-相关工作" class="headerlink" title="6 相关工作"></a>6 相关工作</h1><h2 id="6-1种子输入优先级"><a href="#6-1种子输入优先级" class="headerlink" title="6.1种子输入优先级"></a>6.1种子输入优先级</h2><p>​    基于突变的fuzzer的一个重要优化是明智地选择种子输入。雷伯特等人[26]制定并推理了种子选择调度问题。他们基于PeachFuzzer设计并评估了六种不同的种子选择算法[23]。算法使用不同的特征来最小化种子输入集，例如执行时间和文件大小。结果表明，种子选择算法采用的启发式方法比完全随机抽样方法表现更好。 AFLFast [4]观察到大多数模糊测试都使用了相同的几条“高频”路径。他们使用马尔可夫链来识别“低频”路径。 AFLFast优先考虑包含此类路径的输入。VUzzer [25]使用控制流功能来建模路径，以优先考虑路径难以到达的输入。此外，VUzzer检测到错误处理基本块，并优先考虑不包含这些基本块的有效输入。相比之下，Angora选择其路径包含具有未探索分支的条件语句的输入。这是一种更为通用的策略，在探索高频路径后，它会自动指示Angora专注于低频路径。</p><h2 id="6-2-基于污点的模糊测试"><a href="#6-2-基于污点的模糊测试" class="headerlink" title="6.2 基于污点的模糊测试"></a>6.2 基于污点的模糊测试</h2><p>​    污点跟踪有很多用途，例如分析恶意软件行为[24]，检测和防止信息泄漏[10,29]和调试软件[22,12]。它也可以用于模糊测试。基于污点的模糊器分析应用程序如何处理输入以确定应修改输入的哪个部分。其中一些模糊器[13,2,17]旨在将输入文件中安全敏感代码中使用的值定位，然后对输入文件的这些部分进行模糊处理以触发崩溃。例如，BuzzFuzz [13]使用污点定位来查找哪些输入字节由他们定义的“攻击点”处理。 Dowser [17]认为可能导致缓冲区溢出的代码是安全敏感代码。换句话说，这些模糊器旨在利用可到达路径中的错误。Woo等人。提到了在探索与利用之间的权衡[32]。Angora可以结合这些技术来开发探索的路径。 Taintscope [31]使用污点分析来推断校验和处理代码，并通过控制流程更改绕过这些检查，因为通过改变输入很难满足这些检查。</p><p>​    VUzzer [25]是一个应用程序感知模糊器，它使用污点分析来定位输入文件中“魔术字节”的位置，然后将这些魔术字节分配给输入中的固定位置。 VUzzer只有在连续出现在输入中时才能找到魔术字节。 Steelix [19]通过学习魔术字节位于输入中的程序状态以及如何有效地改变输入以匹配魔术字节来改进VUzzer。相比之下，Angora应用字节级污点跟踪来获取流入每个条件语句的输入中的字节偏移，然后改变这些字节以满足未探测分支的条件，因此Angora可以有效地找到更多类型的值。魔术字节，例如，非连续魔术字节或魔术字节，不是直接从输入复制而是从输入计算。此外，VUzzer使用压缩的位设置数据结构来表示污点标签，其中每个位对应于输入中的唯一字节偏移。因此，对于具有复杂输入字节偏移模式的值，污点标签的大小很大，因为它们无法有效压缩。相比之下，Angora将字节偏移存储在树中，并将索引作为污染标签用于树中，因此无论标签中有多少输入字节偏移，污点标签的大小都是常量。例如，当几个值的污点标签具有相同的字节偏移时，VUzzer会在每个污点标签中重复存储这些字节偏移，但Angora只在树中存储这些字节偏移一次，从而大大减少了内存消耗。</p><p>​    Angora有效表示污点标签的数据结构类似于简化有序二元决策图（roBDD）。 roBDD用于表示动态切片[33]和数据谱系[20]，但据我们所知，Angora是第一个使用这种想法有效地表示污点标签的。</p><h2 id="6-3-符号辅助模糊测试"><a href="#6-3-符号辅助模糊测试" class="headerlink" title="6.3 符号辅助模糊测试"></a>6.3 符号辅助模糊测试</h2><p>​    动态符号执行为目标应用程序提供了高度语义洞察力。由于这些技术知道如何触发所需的程序状态，因此它们可用于直接查找程序中的漏洞。符号执行实现的经典方法以最大化代码覆盖率以查找崩溃[5,8]。但路径爆炸和约束求解的挑战使符号执行难以扩展[6,27]。一些工具试图通过将其与模糊测试[15,16,7,28]相结合来缓解这一障碍。 DART [15]和SAGE [16]使用动态符号执行引擎来修改模糊测试中的输入。 SYMFUZZ [7]利用对执行跟踪的符号分析来检测输入中位置之间的依赖关系，然后使用此依赖关系来计算最佳突变率以指导模糊测试。 Driller [28]只有在AFL模糊不清时才使用动态符号执行。但是，它们都继承了符号执行的可伸缩性问题。相比之下，Angora不使用符号执行，并且可以有效地在大型程序上找到许多错误。</p><h1 id="7-结论"><a href="#7-结论" class="headerlink" title="7 结论"></a>7 结论</h1><p>​    我们设计并实现了Angora，这是一种强大的基于突变的模糊器，可以产生高质量的输入，这得益于以下关键技术：可扩展的字节级污点跟踪，上下文敏感的分支计数，基于梯度下降的搜索算法，形状和类型推断和输入长度探索。Angora在很大程度上超越了其他最先进的模糊器。它发现了比LAVA-M上的其他模糊器明显更多的错误，发现了当他们准备数据集时LAVA作者无法触发的103个错误，以及8个流行的，成熟的开源程序中总共175个新错误。我们的评估显示，Angora将模糊测试的标准提升到了一个新的水平。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h1&gt;&lt;p&gt;​    Fuzzing是一种用于查找软件错误的流行技术。然而，最先进的模糊器的性能还有很多
      
    
    </summary>
    
      <category term="论文" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/"/>
    
      <category term="fuzzing" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/fuzzing/"/>
    
    
      <category term="2018年" scheme="http://yama0xff.com/tags/2018%E5%B9%B4/"/>
    
      <category term="fuzzing" scheme="http://yama0xff.com/tags/fuzzing/"/>
    
      <category term="污点分析" scheme="http://yama0xff.com/tags/%E6%B1%A1%E7%82%B9%E5%88%86%E6%9E%90/"/>
    
      <category term="LAVA" scheme="http://yama0xff.com/tags/LAVA/"/>
    
      <category term="梯度下降算法" scheme="http://yama0xff.com/tags/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95/"/>
    
      <category term="S&amp;P&#39;18" scheme="http://yama0xff.com/tags/S-P-18/"/>
    
      <category term="LLVM" scheme="http://yama0xff.com/tags/LLVM/"/>
    
  </entry>
  
</feed>
