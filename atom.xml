<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>yama0xff&#39;s blog</title>
  
  <subtitle>CYBERSECURITY  BETWEEN 0 AND 1</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yama0xff.com/"/>
  <updated>2019-04-25T12:31:27.205Z</updated>
  <id>http://yama0xff.com/</id>
  
  <author>
    <name>yama0xff</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>A Deep Learning based Approach to Automated Android App Testing</title>
    <link href="http://yama0xff.com/2019/04/23/A-Deep-Learning-based-Approach-to-Automated-Android-App-Testing/"/>
    <id>http://yama0xff.com/2019/04/23/A-Deep-Learning-based-Approach-to-Automated-Android-App-Testing/</id>
    <published>2019-04-23T03:20:17.000Z</published>
    <updated>2019-04-25T12:31:27.205Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>自动输入生成器广泛用于移动应用程序的大规模动态分析和测试。这样的输入生成器必须不断地选择与其交互的UI元素以及如何与其交互，以便在有限的时间预算下实现高覆盖率。目前，大多数输入生成器采用伪随机或强力搜索策略，这可能需要很长时间才能找到可以将应用程序驱动到新的重要状态的正确输入组合。在本文中，我们提出了Humanoid，一种基于深度学习的自动Android应用程序测试方法。我们的见解是，如果我们可以从人类生成的交互跟踪中学习，则可以基于当前UI状态和最新状态转换中的视觉信息生成类似人类的测试输入。我们设计并实现了一个深度神经网络模型，以了解最终用户如何与应用程序进行交互（具体来说，与哪些UI元素进行交互以及如何进行交互），并表明我们可以基于以下任何新UI成功生成类似人类的输入学习的模型。然后，我们将该模型应用于Android应用程序的自动化测试，并证明它能够比最先进的测试输入生成器获得更高的覆盖率和更快的速度。</p><p>Index Terms—Software testing, automated test input generation, graphical user interface, deep learning, mobile application </p><table><thead><tr><th>relevant information</th><th></th></tr></thead><tbody><tr><td><em>作者</em></td><td>Yuanchun Liy, Ziyue Yangy, Yao Guoz, Xiangqun Chen</td></tr><tr><td><em>单位</em></td><td>Key Laboratory of High Confidence Software Technologies (Ministry of Education) Peking University</td></tr><tr><td><em>出处</em></td><td>arXiv</td></tr><tr><td><em>原文地址</em></td><td><a href="https://arxiv.org/abs/1901.02633" target="_blank" rel="noopener">https://arxiv.org/abs/1901.02633</a></td></tr><tr><td><em>源码地址</em></td><td></td></tr><tr><td><em>发表时间</em></td><td>2019年</td></tr></tbody></table><h1 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h1><p>移动应用程序（简称应用程序）近年来得到了广泛采用，在Google Play和Apple App Store中可以下载超过300万个应用程序，同时已经累积了数十亿次下载[1]，[2]。这些应用程序需要在发布之前进行充分测试，以便希望确保其应用程序正常运行的应用程序开发人员以及希望阻止恶意应用程序发布的应用程序市场。但是，由于快速的发布周期和有限的人力资源，开发人员和审计人员很难在短时间内手动构建测试用例。因此，移动应用程序的自动测试输入生成器已在学术界和工业界广泛研究。</p><p>移动应用程序的测试输入通常由与应用程序的图形用户界面（GUI）的交互来表示。具体地，交互可以包括点击，滚动或输入文本到GUI元素，例如按钮，图像或文本块。输入生成器的工作是为受测试的应用程序(AUT)生成一系列交互，可用于检测软件问题，例如错误，漏洞和安全问题。测试输入生成器的有效性通常通过其测试覆盖率来衡量。给定无限时间，可以尝试所有可能的交互序列和组合以实现完美的测试覆盖。但是，在实际情况下，测试时间有限且AUT可能包含数百个GUI状态和每个状态中的数十个可能的交互，测试输入生成器只能选择一小部分交互序列来探索。</p><p>自动化测试输入生成器成功的关键是为给定的UI（测试期间的当前UI）选择正确的交互，以便所选择的交互可以达到新的和重要的UI状态，这反过来将导致额外的UI状态。因为机器很难理解GUI布局和GUI元素内的内容，所以也难以确定点击哪个按钮或应该输入什么。因此，大多数现有的测试生成器[3]  -  [6]忽略了各种类型的UI元素之间的差异，并应用随机策略来选择一个与之交互。甚至其中一些可能维护应用程序的GUI模型，该模型仅用于记住已探索的状态和交互以避免重复探索。虽然随机策略也可以进一步优化，但它具有固有的局限性，使得难以选择最有效的路径来找到可以在短时间内将应用程序驱动到重要状态的交互。</p><p>与随机输入生成器相反，人类测试人员可以轻松识别值得与之交互的UI元素，即使对于他们以前从未见过的新应用程序也是如此。原因是人类测试人员本身就是应用程序用户，因此他们已经获得了有关各种移动应用程序的一些经验和知识。因此，人类测试人员知道在哪里点击以及输入什么，以便获得更高的覆盖率，并且花费更少的时间。我们要在本文中研究的关键问题是：我们可以教一个自动测试输入生成器，使其表现得像人类一样吗？</p><p><img src="/2019/04/23/A-Deep-Learning-based-Approach-to-Automated-Android-App-Testing/1.jpg" alt=""></p><p>本文提出了Humanoid，一种自动GUI测试生成器，能够了解人类如何与移动应用程序交互，然后使用学习模型指导测试生成作为人类测试人员。利用从人工交互轨迹中学到的知识，Humanoid可以根据GUI页面的重要性和意义来确定GUI页面上可能的交互的优先级，从而生成可以更快地导致重要状态的测试输入。</p><p>我们可以使用图1中所示的GUI页面作为激励示例。可以在该页面上执行20多个操作，但大多数操作无效或与AUT的核心功能无关，例如在当前页面上向左滑动（实际上不可滚动）或单击广告底部。虽然随机输入生成器可能必须尝试所有可能的选择（包括那些无效的选择），但Humanoid能够增加单击菜单按钮的概率，这更有可能将AUT驱动到其他重要的GUI状态。<br>Humanoid的核心是一个深度神经网络模型，它预测UI页面上的真实用户更有可能与哪些UI元素进行交互以及如何与其进行交互。模型的输入是当前UI状态以及最近的UI转换，表示为一堆图像，而输出是可能的下一个动作的预测分布，包括动作类型和屏幕上的相应位置坐标。通过将预测分布与UI页面上的所有可能动作进行比较，Humanoid能够为每个动作分配概率，并选择具有较高概率的动作作为下一个测试输入。</p><p>我们实现了Humanoid，并使用从大规模众包源的UI交互数据集Rico中提取的304,976个人类交互来训练交互模型[7]。只需更换输入选择逻辑，即可轻松将模型与其他测试工具集成。</p><p>为了评估Humanoid，我们首先检查了Humanoid是否可以通过使用它来为交互跟踪数据集中的每个UI状态的可能操作划分优先级来学习人类交互模式。结果表明，对于交互痕迹中的大多数UI状态，根据人形预测概率，人类执行的动作在所有动作中排名前10％，这明显优于预期为50％左右的随机策略。</p><p>为了评估交互模型在app测试中的有效性，我们将Humanoid与六个最先进的测试生成器进行了比较。用于测试的应用程序包括从AndroTest [8]数据集获得的68个开源应用程序，这是一个广泛使用的基准数据集，用于评估Android测试生成器。我们还测试了来自Google Play的200个热门应用，看看Humanoid在更复杂的应用中是否也有效。根据实验，Humanoid能够为开源应用程序实现43.1％的线路覆盖率，并为市场应用程序实现24.1％的活动覆盖率，在相同的时间内，这显着高于使用其他测试生成器实现的最佳结果（38.8％和19.7％）。</p><p>本文的主要贡献如下：</p><ul><li>1）据我们所知，这是第一部通过挖掘GUI交互跟踪来介绍通过深度学习生成类人测试输入的想法，以改进自动化移动应用程序测试。</li><li>2）我们提出并实现Humanoid，一种基于深度学习的方法，通过学习人类交互痕迹来生成类似人类的测试输入。</li><li>3）我们使用开源应用程序和流行的市场应用程序来评估Humanoid。结果表明，Humanoid能够比最先进的方法获得更高的测试覆盖率和更快的速度。</li></ul><h1 id="II-背景和相关工作"><a href="#II-背景和相关工作" class="headerlink" title="II.背景和相关工作"></a>II.背景和相关工作</h1><h2 id="A-Android-UI"><a href="#A-Android-UI" class="headerlink" title="A.Android UI"></a>A.Android UI</h2><p>对于移动应用，用户界面（UI）是人与机器之间发生交互的地方。应用程序开发人员设计UI以帮助用户了解其应用程序的功能，并且用户可以通过UI与应用程序进行交互。图形用户界面（GUI）是大多数移动应用程序最重要的UI类型，其中应用程序在屏幕上显示内容和可操作的小部件，用户使用点击，滑动和文本输入等操作与小部件交互。</p><p>移动应用程序中显示的GUI页面（或屏幕截图）通常使用树状结构布局。例如，在Android应用程序的屏幕截图中，所有UI元素都是使用View和ViewGroup对象构建的，并组织为tree。视图是一个叶节点，它在屏幕上绘制用户可以看到和交互的内容。 ViewGroup是一个父节点，它包含其他节点以定义接口的布局。UI状态可以被识别为当前UI树中的结构和内容的快照，并且UI树中的节点被称为UI元素。</p><p>可以将应用程序视为许多GUI状态及其之间转换的组合。每个GUI状态提供不同的功能或呈现不同的内容。应用程序用户通过与UI元素交互在UI状态之间导航。 </p><h2 id="B-自动GUI测试生成"><a href="#B-自动GUI测试生成" class="headerlink" title="B.自动GUI测试生成"></a>B.自动GUI测试生成</h2><p>自从移动应用程序普及以来，自动GUI测试生成已经成为一个活跃的研究领域。大多数研究工作都针对Android平台，部分原因是Android应用程序的普及，以及Android设备和操作系统版本的碎片化。</p><p>在Android中，测试工具以与人类相同的方式与应用程序交互：将模拟手势发送到应用程序的GUI。由于UI状态中可接受的手势是有限的，因此不同测试生成器之间的主要区别在于它们用于确定这些操作的优先级的策略。主要有三种策略：随机，基于模型和目标。</p><p>使用随机策略的典型示例是Monkey [3]，这是Android中自动应用程序测试的官方工具。 Monkey将随机类型的输入事件发送到屏幕上的随机位置，而不考虑其GUI结构。 DynoDroid [4]也使用随机策略，而DynoDroid发送的输入比Monkey更聪明：许多不可接受的事件根据应用程序中的GUI结构和注册事件监听器被过滤掉。 Sapienz [9]利用遗传算法优化随机测试序列。 Polariz [10]提取并重用人类测试者获得的图案，以帮助生成随机测试序列。</p><p>其他几个测试工具构建并使用应用程序的GUI模型来生成测试输入。这些模型通常表示为存储应用程序窗口状态之间转换的有限状态机。这种GUI模型可以动态构建[5]，[6]，[11]  -  [17]或静态[18]。基于GUI模型，测试工具可以生成快速将应用程序导航到未探测状态的事件。基于模型的策略可以以各种方式进行优化。例如，Stoat [14]可以基于现有的探索迭代地改进测试策略，DroidMate [15]可以通过从其他应用程序挖掘来推断UI元素的可接受动作。</p><p>目标策略旨在解决某些应用行为只能通过特定测试输入显示的问题。例如，恶意应用程序可能只在收到某个广播时发送短信[19]。这些测试工具[20]  -  [22]通常使用复杂的技术，如数据流分析和符号执行，来找到可以导致目标状态的交互。但是，它们的有效性很容易受到应用程序代码的复杂性以及将代码映射到UI元素的困难的影响。</p><p>现有测试生成器的一个主要缺点是它们忽略了UI元素的可视信息，这是人类用户或测试人员在探索应用程序时的重要参考。在Humanoid中，我们尝试通过了解应用程序的GUI如何影响用户与其交互的方式来指导测试生成。</p><h2 id="C-软件GUI分析"><a href="#C-软件GUI分析" class="headerlink" title="C.软件GUI分析"></a>C.软件GUI分析</h2><p>GUI是包括Android在内的大多数主要平台上不可或缺的软件部分。分析应用程序的GUI是许多研究人员和从业者非常感兴趣的。该领域主要有两个研究领域。一个是从软件工程的角度理解应用程序的行为。另一种是从人机交互的角度来分析用户界面设计。</p><p>如前所述，许多自动化测试工具构建并使用GUI模型来指导测试输入生成。与主要使用UI状态之间的转换来抽象应用程序行为的模型不同，还有一些方法侧重于分析每个UI状态中的信息。例如，Huang等人 [23]和鲁宾等人 [24]提出通过比较实际行为与UI来检测Android应用程序中的隐秘行为。 PERUIM [25]提取了应用程序对其UI的权限之间的映射，以帮助用户理解为何请求每个权限，而AUDACIOUS [26]提供了一种基于UI组件控制权限访问的方法。陈等人[27]引入了一种基于机器学习的方法，从UI图像中提取UI骨架，以便于GUI开发。</p><p>在人机交互研究中，软件GUI主要用于挖掘UI设计实践[28]，[29]和交互模式[30]。挖掘的知识可以进一步用于指导UI和UX（用户体验）设计。为了促进移动应用程序设计挖掘，Deka等人收集并发布了一个名为Rico [7]的数据集，其中包含大量UI屏幕和人工交互。</p><p>我们的工作在于软件工程与人机交互之间的交叉：我们提出了一种深度学习方法，用于从Rico数据集中挖掘人类交互模式，并使用学习模式来指导自动化测试。</p><h1 id="III-我们的方法"><a href="#III-我们的方法" class="headerlink" title="III.我们的方法"></a>III.我们的方法</h1><p>为了在移动应用程序上运用人类知识来增强移动应用程序测试，本文提出了Humanoid，一种新的自动化测试输入生成器，能够根据人类生成的应用程序交互跟踪中自动学习的知识生成类似人类的测试输入。与许多现有测试工具类似，Humanoid使用GUI模型来理解和探索被测试应用程序的行为。但是，与传统的基于模型的方法不同，传统的基于模型的方法随机选择在探索UI状态时要执行的操作，Humanoid会优先考虑更有可能与人类用户交互的UI元素。我们希望这种类似人类的探索能够比随机策略更快地将应用程序推向重要状态。</p><h2 id="A-方法概述"><a href="#A-方法概述" class="headerlink" title="A.方法概述"></a>A.方法概述</h2><p>图2显示了Humanoid的概述。 Humanoid的核心是一个机器学习模型，它学习人类如何与应用程序交互的模式。基于交互模型，整个系统可以分为两个阶段，包括用于生成具有人类生成的交互轨迹的模型的离线阶段和用于指导测试输入生成的在线阶段。</p><p><img src="/2019/04/23/A-Deep-Learning-based-Approach-to-Automated-Android-App-Testing/2.jpg" alt=""></p><p>在离线学习阶段，我们使用深度神经网络模型来学习GUI上下文和用户执行的交互之间的关系。 GUI上下文被表示为当前UI状态和最新UI转换中的视觉信息，而交互被表示为动作类型（触摸，滑动等）和动作的位置坐标。在从大规模人类交互轨迹中学习之后，Humanoid能够预测新UI状态的动作类型和动作位置的概率分布。然后可以使用预测的分布来计算每个UI元素与人交互的概率以及如何与其交互。</p><p>在在线测试阶段，Humanoid为被测应用程序（AUT）构建一个名为UI转换图（UTG）的GUI模型。 Humanoid使用GUI模型和交互模型来决定要发送的测试输入。 UTG负责指导Humanoid在已探索的UI状态之间导航，而交互模型则指导探索新的UI状态。</p><h2 id="B-交互跟踪预处理"><a href="#B-交互跟踪预处理" class="headerlink" title="B.交互跟踪预处理"></a>B.交互跟踪预处理</h2><p>首先，我们需要一个带有人工交互跟踪的大型数据集（Rico [7]）来训练用户交互模型，这是Humanoid中的关键组件。因为Rico中的人工交互痕迹不是为我们的目的而设计的，所以我们首先需要预处理交互痕迹。</p><p>原始人类交互轨迹通常是发送到屏幕的连续运动事件流[7]，其中每个运动事件由何时（时间戳）和光标（用户的手指）进入的位置（x，y坐标）组成，移动，离开屏幕。由于动画和动态加载的内容，状态更改也是连续的。</p><p>我们模型可接受的输入是一组用户交互流程。每个交互流程由一系列UI状态&lt;s~1~, s~2~, s~3~……,s~n~&gt;和在相应的UI状态中获取的一系列动作&lt;a~1~, a~2~,a~3~……,a~n~&gt;组成。要将原始交互跟踪转换为我们模型可接受的格式，我们需要分割光标移动并从中识别用户操作。</p><p>我们在Humanoid中考虑七种类型的用户操作，包括touch，long_touch，swipe_ up / down / left / right和input_text。每个操作都由操作类型和屏幕上的目标位置表示。为了从原始光标跟踪中提取用户操作，我们首先将光标移动聚合到交互会话中。</p><p>交互会话定义为光标进入屏幕和光标离开屏幕之间的时间段。我们将会话开始和会话结束的时间戳表示为time~start~和time~end~，将光标位置表示为loc~start~和loc~end~。然后我们根据启发式规则列表将交互会话映射到用户操作，如表I所示。</p><p>一旦我们提取了行动序列&lt;a~1~, a~2~,a~3~……,a~n~&gt;，我们能够将UI状态更改与基于操作时间戳的操作相匹配。我们使用在a~i~ 的时间戳之前捕获的UI状态作为s~i~来形成状态序列&lt;s~1~, s~2~, s~3~……,s~n~&gt;。状态序列和动作序列一起表示用户交互流，其将用作我们的人交互模型的训练数据。</p><p><img src="/2019/04/23/A-Deep-Learning-based-Approach-to-Automated-Android-App-Testing/3.jpg" alt=""></p><h2 id="C-模型训练"><a href="#C-模型训练" class="headerlink" title="C.模型训练"></a>C.模型训练</h2><p>本节详细介绍了我们如何使用机器学习模型从人类交互痕迹中学习人类交互模式。最终用户根据他们想要对应用程序执行的操作以及他们在GUI上看到的内容与应用程序进行交互。由于不同的应用程序通常共享通用的UI设计模式，因此直观的是人类与GUI交互的方式可以在不同的应用程序中进行推广。交互模型的目标是捕获这种可推广的交互模式。</p><p>我们引入了一个概念UI上下文来模拟人们在与应用程序交互时引用的内容。 UI上下文 context~i~ 包括当前UI状态s~i~和三个最新UI转换（s~i-1~, a~i-1~）, （s~i-2~, a~i-2~）, （s~i-3~, a~i-3~）。当前UI状态表示用户在执行操作时看到的内容，而最新的UI转换用于在当前交互会话期间对用户的潜在意图进行建模。</p><p><img src="/2019/04/23/A-Deep-Learning-based-Approach-to-Automated-Android-App-Testing/4.jpg" alt=""></p><p>图3显示了我们如何在模型中表示UI状态和操作。每个UI状态表示为双通道UI骨架图像，其中第一个通道（红色通道）呈现文本UI元素的边界框区域，第二个通道（绿色通道）呈现非文本UI的边界框区域元素。我们使用UI骨架而不是原始屏幕截图的原因是屏幕截图上的大多数字符不会影响人类与应用程序的交互方式。例如，同一应用程序的UI样式（字体大小，按钮样式，背景颜色等）可能会在不同的操作系统和应用程序版本中发生变化，而用户使用应用程序的方式则保持不变。有些应用甚至提供“夜间模式”等功能，允许用户在内部更改UI样式。这样的UI样式字符可能会给我们的模型带来噪声并影响模型的泛化能力，因此我们将它们从输入表示中排除。</p><p>每个动作由其动作类型和目标位置坐标表示。动作类型被编码为三维向量，其中每个维度映射到前面描述的七种动作类型之一。操作目标位置编码为热图。热图中的每个像素是像素在动作目标位置的概率。我们使用热图而不是原始坐标来表示动作位置，因为原始坐标是高度非线性的并且更难以学习[31]。</p><p>总之，UI上下文的表示，即我们的交互模型的输入特征，是一堆图像，包括用于当前UI状态的一个2通道图像和用于三个最新UI转换的三个3通道图像（每个转换包括一个用于UI状态的双通道图像和一个用于动作的单通道图像）。所有图像都缩放到180x320像素的大小。为了便于学习，我们还为当前UI状态添加了一个零填充通道。最后，UI上下文表示为4x180x320x3向量。</p><p>给定UI上下文向量，交互模型的输出是可能由人在当前状态下执行的“动作”。请注意，预测的“动作”不是当前UI状态中的实际可接受动作。相反，它是预期的类人行为的类型和位置的概率分布。具体而言，该模型的目标是学习两个条件概率分布：</p><p>1）p~type~（t | context~i~）其中t ∈ {touch, long_touch;swipe_up,…… }，意思是给定当前UI 上下文的情况，下一个动作a~i~的类型的概率分布t。</p><p>2）ploc（x, y | context~i~）其中0 &lt;x &lt;screen_width和0 &lt;y &lt;screen_height，表示在给定当前UI上下文的情况下，下一个动作a~i~的目标位置x,y的概率分布。</p><p><img src="/2019/04/23/A-Deep-Learning-based-Approach-to-Automated-Android-App-Testing/5.jpg" alt=""></p><p>图4显示了用于学习上面定义的两个条件概率分布的深度神经网络模型。它接受当前UI上下文 context~i~ 的表示作为输入，并输出a~i~的位置和类型分布。该模型由五个主要部分组成：卷积层，残余LSTM模块，去卷积层，完全连接层和 损失函数。</p><p><strong>卷积层</strong>。卷积网络结构已经成为一种流行的图像特征提取方法，因为它已被证明在大型真实世界数据集上的计算机视觉任务中非常强大[32]。在我们的模型中，我们使用具有RELU激活的5个卷积层来从UI骨架图像和动作热图提取特征。在每个卷积层之后，有一个stride-2 max-pooling层，它将输入的宽度和高度减少到一半。池化层还有助于模型识别具有相同形状但环境不同的UI元素。</p><p><strong>剩余的LSTM模块</strong>。 LSTM（长短期记忆）网络在序列建模问题中被广泛采用，例如机器翻译[33]，视频分类[34]等。在我们的模型中，从历史转换中提取特征也是序列建模问题。我们在最后3个卷积层的每一个之后插入残余LSTM模块，以便捕获不同分辨率级别上的UI转换序列特征。在残余LSTM模块中，输入的最后一维和正常LSTM的输出通过剩余路径直接相加。</p><p>这种残留结构使神经网络更容易优化[35]，并提示动作的位置应位于UI元素内。为了降低模型复杂度，我们还在每个残余LSTM模块之前添加了1x1卷积层，以减少特征维度。</p><p><strong>去卷积层</strong>。该组件用于从残余LSTM模块的低分辨率输出生成高分辨率概率分布。有几种方法可以实现这一点，例如双线性插值，反卷积等。我们使用反卷积层，因为它更容易与深度神经网络集成，并且比插值方法更通用。将不同分辨率级别的特征组合在一起，以提高生成热图的质量[36]。接下来使用softmax层来标准化生成的热图，使得热图中的所有像素总和为1，这是动作位置的概率分布。</p><p><strong>完全连接的层</strong>。使用softmax的单个完全连接层用于生成动作类型的概率分布。</p><p><strong>损失函数</strong>。该模型将行动位置和行动类型预测为概率分布。因此，它们对地面事实（由人类执行的动作）的交叉熵损失适合于模型优化。我们使用这两个损失的总和和层权重正则化器作为训练过程中的最终损失函数。</p><p>在训练期间，交互流中的每个动作ai（&lt;s~1~, s~2~, s~3~ ……, s~n~&gt;，&lt;a~1~, a~2~, a~3~…… a~n~&gt;）将转换为以下概率分布：</p><p><img src="/2019/04/23/A-Deep-Learning-based-Approach-to-Automated-Android-App-Testing/6.jpg" alt=""></p><p>和<br>$$<br>p_{loc}（x, y）= f（x - a_i.x, y - a_i.y）<br>$$<br>其中f是方差= 20的高斯分布的密度函数，我们使用高斯分布来逼近实际屏幕的概率分布当多个人多次交互相同的UI元素时，设备识别的坐标。</p><p>类似地，在应用模型时，我们使用当前UI状态的表示来提供它，以预测下一个动作的概率分布p~type~（t）和p~loc~（x, y）。由于预测的分布不能直接用于指导测试生成，我们需要进一步将它们转换为可以在当前状态下执行的操作的概率。为此，我们首先遍历UI树以查找当前状态中的所有可能操作，每个操作包含操作类型（表示为action.type）和操作目标元素（表示为action.element）。然后我们根据模型预测的分布计算每个动作的概率：<br>$$<br>p(action) = p_{type}(action.type) ∗ \sum_{x，y在action.element}p_{loc}(x, y)<br>$$<br>动作概率可能最终用于指导下一步的测试输入生成。</p><h2 id="D-引导测试生成"><a href="#D-引导测试生成" class="headerlink" title="D.引导测试生成"></a>D.引导测试生成</h2><p>在本节中，我们将描述如何应用人类交互模型来生成类似人类的测试输入。</p><p>Humanoid生成两种类型的测试输入，包括探索和导航。探索输入用于发现应用程序中看不见的行为，而导航输入将应用程序驱动到包含未探测操作的已知状态。当从探索输入中选择时，测试生成器不知道每个测试输入的结果，并且基于人类交互模型的指导做出决定（传统的测试生成器通常随机选择输入）。当生成导航输入时，测试生成器知道输入的目标状态，因为它已经保存了转换的存储器。</p><p>与许多现有的测试生成器类似，Humanoid使用GUI模型来保存转换的内存。我们使用的GUI模型表示为UI转换图（简称UTG），它是有向图，其节点是UI状态，边是导致UI状态转换的动作。 UTG是在运行时构造的：每次测试生成器观察到新的状态si时，它都会添加一个新的边&lt;s~i-1~; a~i-1~; s~i~&gt;到UTG，其中s~i-1~是最后观察到的UI状态，a~i-i~是在s~i-1~中执行的动作。图5显示了UTG的一个例子。使用UTG，测试生成器可以通过遵循状态路径导航到任何已知状态。</p><p><img src="/2019/04/23/A-Deep-Learning-based-Approach-to-Automated-Android-App-Testing/7.jpg" alt=""></p><p><img src="/2019/04/23/A-Deep-Learning-based-Approach-to-Automated-Android-App-Testing/8.jpg" alt=""></p><p>为了在探索和导航之间做出决定并生成输入动作，Humanoid采用了一种简单但有效的策略，如算法1所示。在每个步骤中，Humanoid检查当前状态中是否存在未探测的动作。如果存在未探测的动作，Humanoid会选择探索（第8行），如果完全探索当前状态，则选择导航（第10行到第12行）。导航过程很简单。在探索过程中，Humanoid获取交互模型预测动作的概率，并基于概率进行加权选择。由于人类将采取的行动将被赋予更高的概率，因此人类生物体作为测试输入被选择的机会更高。因此，Humanoid生成的输入比随机选择的输入更像人类。</p><p>与现有的测试工具相比，Humanoid的主要特征（以及不同基于模型的测试生成器之间的主要区别）是如何选择探索输入（第8行）。 Humanoid基于交互模型对勘探中更有价值的行为进行优先级排序，交互模型已经从人类交互痕迹进行了训练。此功能可以更快地发现正确的输入序列，从而将应用程序驱动到重要的UI状态，从而提高测试覆盖率。</p><h1 id="IV-评估"><a href="#IV-评估" class="headerlink" title="IV.评估"></a>IV.评估</h1><p>我们主要通过以下几个方面评估Humanoid：</p><ul><li>1）Humanoid能否学习人类交互模式？具体而言，交互模型能否以高精度预测UI状态下的用户操作？</li><li>2）Humanoid需要多长时间才能使用交互模型？具体而言，训练模型和预测行动概率需要多长时间？</li><li>3）当训练好的交互模型用于指导测试生成时，Humanoid可以实际上实现更高和更快的覆盖吗？</li></ul><p>我们进行了两次实验来回答这些问题。首先，我们使用人类交互痕迹的数据集来训练和测试交互模型。我们研究了该实验中的模型精度和时间效率。其次，我们将在数据集上训练的模型集成到测试生成器中，并使用测试生成器对两组不同的Android应用程序进行测试。我们测量了Humanoid的测试覆盖率和测试进度，并将结果与几种最先进的测试工具进行了比较。</p><h2 id="A-实验设置"><a href="#A-实验设置" class="headerlink" title="A.实验设置"></a>A.实验设置</h2><p>我们用于训练和测试Humanoid模型的数据集是从Rico [7]处理的，Rico [7]是人类交互的大量人群源数据集。我们通过识别动作序列和状态序列从原始数据中提取交互流。最后，我们获得了12,278个属于10,477个应用程序的交互流程。每个交互流平均包含24.8个状态。每个UI状态中可能的动作数量的累积分布函数（CDF）如图6所示。平均而言，每个UI状态有50.7个可能的动作候选者，而超过10％的UI状态包括100多个动作候选者。</p><p><img src="/2019/04/23/A-Deep-Learning-based-Approach-to-Automated-Android-App-Testing/9.jpg" alt=""></p><p>我们用来训练和测试交互模型的机器是一个带有两个Intel Xeon E5-2620 CPU，64GB RAM和一个NVidia GeForce GTX 1080 Ti GPU的工作站。该机器的操作系统是Ubuntu 16.04。该模型采用Tensorflow [37]实施。</p><p>在测试覆盖率评估实验中，我们使用了4台计算机，其硬件和软件与上述相同。我们在每台机器上运行了4个Android模拟器实例，以并行测试应用程序。我们用于测试的应用程序包括从AndroTest [8]获得的68个开源应用程序，这是一个用于评估Android测试输入生成器的常用数据集，以及从Google Play下载的200个流行商业应用程序。在测试开源应用程序时，我们使用Emma [38]来测量行覆盖率。对于没有源代码的商业应用程序，我们使用活动覆盖率（达到的活动的百分比）来衡量测试性能。</p><h2 id="B-交互模型的准确性"><a href="#B-交互模型的准确性" class="headerlink" title="B.交互模型的准确性"></a>B.交互模型的准确性</h2><p>在这个实验中，我们在现有的人类交互痕迹上训练和测试了我们的交互模型，以了解该模型是否能够了解人类如何与应用程序交互。</p><p>我们从数据集中随机选择了100个应用程序，并使用它们的交互跟踪进行测试。其余10,377个应用程序的交互痕迹用于训练。总的来说，我们有302,382个用于训练的UI状态和用于测试的2,594个UI状态。对于测试集中的每个UI状态，我们使用交互模型来预测所有可能操作的概率，并按预测概率的降序对操作进行排序。人类所采取的行动被视为基本事实。</p><p>表II示出了在每个UI状态中对人类执行的动作进行优先级排序时Humanoid人交互模型的准确性。具体而言，我们计算了地面实况（人类执行的动作）按照交互模型预测的动作顺序排在前N（N = 1,3,5,10）内的概率。为了比较，我们还计算了随机策略的topN准确度，即如果动作是随机顺序，则地面实况排名前N的概率。根据结果，我们的交互模型可以更准确地识别人类生成的行为并确定其优先级。</p><p>特别是，Humanoid能够为超过50％的UI状态分配人类生成动作的最高概率。我们还计算了每个UI状态中人为操作的百分位数。平均百分位数排名为20.6％，中位数为9.5％，这意味着Humanoid能够将类似人类的行为优先于大多数UI状态的前10％。</p><h2 id="C-交互模型的开销"><a href="#C-交互模型的开销" class="headerlink" title="C.交互模型的开销"></a>C.交互模型的开销</h2><p>我们然后评估了交互模型的开销。使用包含304,976个人为操作的数据集训练交互模型大约需要66个小时。这是可以接受的，因为模型在用于测试之前只需要训练一次。用于预测UI状态的动作概率所花费的平均时间是107.9毫秒。鉴于Android测试生成器通常需要2秒以上的时间来发送测试输入并等待加载新页面，我们的交互模型将给测试生成器带来的时间开销很小。</p><h2 id="D-引导测试的覆盖率"><a href="#D-引导测试的覆盖率" class="headerlink" title="D.引导测试的覆盖率"></a>D.引导测试的覆盖率</h2><p>在该实验中，我们使用在先前实验中训练的交互模型来指导测试生成。我们通过检查它是否能真正提高测试覆盖率来评估指导测试发生器。</p><p>我们测试了两套应用程序，包括68个开源应用程序和200个流行的市场应用程序。我们将Humanoid与六款最先进的Android测试生成器进行了比较，包括Monkey [3]，PUMA [12]，Stoat [14]，DroidMate [15]，Sapienz [9]和DroidBot [11]。所有工具都使用其默认配置。 PUMA，Stoat，DroidMate和DroidBot的输入速度接近600个事件/小时，因为他们都需要在执行操作之前读取UI状态并在发送输入后等待状态转换，而Monkey和Sapienz可以发送输入事件速度非常快（在我们的实验中大约6000次/小时）。</p><p>我们使用每个测试工具运行每个开源应用程序1小时，每个市场应用程序运行3个小时。为了适应最近的市场应用程序，大多数工具都是在Android 6.0上进行评估的，因为它得到了大多数工具的支持（一些工具经过了少量修改）。然而，由于Sapienz是近源的并且仅支持Android 4.4，因此它在Android 4.4上进行了评估。对于每个应用和工具，我们记录了每个操作执行后的最终覆盖率和渐进覆盖率。我们重复这个过程三次，并使用平均值作为最终结果。</p><p><img src="/2019/04/23/A-Deep-Learning-based-Approach-to-Automated-Android-App-Testing/11.jpg" alt=""></p><p><strong>1）开源应用程序的行覆盖率</strong>：开源应用程序上的测试工具实现的行覆盖率的总体比较如图7所示。平均而言，Humanoid实现了43.1％的行覆盖率，这是最高的跨所有测试输入生成器。</p><p>有趣的是，采用随机探索策略的Monkey实现了比除Humanoid之外的所有其他基于模型的测试工具更高的覆盖率。 Monkey比其他大多数测试工具表现更好的事实也得到了其他研究人员的证实[39]。因为Monkey能够在相同的时间内生成比其他工具更多的输入。但是，我们的工作证明了基于模型的方法的可扩展性的好处。如果正确使用GUI信息，基于模型的测试工具具有实现更好测试性能的巨大潜力。</p><p><img src="/2019/04/23/A-Deep-Learning-based-Approach-to-Automated-Android-App-Testing/10.jpg" alt=""></p><p>每个应用程序的详细行覆盖范围如表III所示。对于一些应用程序，如＃3，＃36和＃45，Monkey的覆盖范围要高得多。原因是Monkey可以生成许多其他工具不支持的输入（例如意图和广播）。对于大多数其他应用程序，Humanoid取得了最佳效果，特别是对于＃6，＃18，＃30等应用程序。</p><p>我们进一步研究了为什么Humanoid能够通过检查详细的测试痕迹来超越其他测试工具。我们仔细检查了五个应用程序，其中Humanoid实现了更高的覆盖率。我们发现了一些Humanoid表现优于其他人的情况，如表IV所示。总而言之，Humanoid的高覆盖率主要是由于两个原因：首先，当有大量UI元素可供选择时，Humanoid能够识别关键UI元素并确定其优先级。其次，Humanoid有更高的机会执行一系列有意义的操作，这可以将应用程序推向未开发的核心功能。</p><p><img src="/2019/04/23/A-Deep-Learning-based-Approach-to-Automated-Android-App-Testing/12.jpg" alt=""></p><p>图8显示了渐进式覆盖范围w.r.t。每个测试工具发送的输入事件数。请注意，我们没有将Sapienz包含在渐进式覆盖数据中，因为它发送的事件太快，我们无法将其放慢速度，因为它是近源的。在最初的几个步骤中，所有测试工具的行覆盖率迅速增加，因为应用程序刚刚启动，所有UI状态都是新的。 PUMA在前10个步骤中实现了最高覆盖率，因为它有一个在开始时重新启动应用程序的策略，这导致在许多应用程序中覆盖资源回收代码。Humanoid在大约20个事件后开始领先。那是因为那时已经涵盖了易于访问的代码，其他状态隐藏在其他测试工具难以产生的特定交互之后。</p><p>在第600个事件点，除了Monkey之外，大多数测试工具的线路覆盖率几乎已经收敛。这是因为Monkey的随机策略产生了大量无效和重复的输入事件，当我们计算事件数量时，这对于覆盖率改善没有帮助。但是，Monkey能够在相同的时间内生成更多的事件。其覆盖率将在第600步后继续增加，并在测试结束时达到约39％（相同的一小时测试持续时间）。</p><p><strong>2）市场应用程序的活动覆盖率</strong>：与开源应用程序相比，市场应用程序通常具有不同且更复杂的功能和UI结构。因此，我们进一步对市场应用程序进行了实验，以确定Humanoid是否仍然更有效。</p><p>由测试工具和渐进覆盖实现的最终活动覆盖分别如图9和图10所示。与开源应用类似，Humanoid与其他工具相比也实现了最高覆盖率（24.1％）。由于市场应用程序的复杂性，一些应用程序的覆盖范围在测试结束时没有收敛。但是，我们相信Humanoid即使在更长的测试时间内也能保持优势。 （由于与上述相同的原因，请注意这两个数字中Monkey的覆盖范围的差异。）</p><h1 id="V-限制和未来工作"><a href="#V-限制和未来工作" class="headerlink" title="V.限制和未来工作"></a>V.限制和未来工作</h1><p><strong>更多输入类型</strong>。有些类型的输入，例如系统广播，传感器事件等，本文未考虑这些类型。这是Humanoid的限制，因为这些输入很难从人类交互中收集，并且在我们的交互模型中也难以表示。但是，目前这不是一个大问题，因为大多数应用程序可以在没有这些操作的情况下进行良好测试Humanoid也不会在发送文本输入操作时预测文本，通过扩展模型以支持文本预测或集成其他文本输入生成技术，可以在将来修复文本输入操作[40]。</p><p><strong>覆盖范围进一步改善</strong>。虽然Humanoid已经能够从现有的测试工具中显着改善覆盖范围，但测试覆盖率仍然相对较低（比完美覆盖更差）。特别是，某些应用的覆盖率低于10％。这是因为许多应用程序需要特定的输入，例如电子邮件和密码，甚至无法自动生成。一种可能的解决方案是设计更好的半自动化测试方法，其中人类测试人员可以用最少的努力为自动工具提供必要的指导。</p><p><strong>利用文本信息</strong>。在学习人类交互模式时，我们使用UI框架来表示模型中的每个UI状态，而不使用每个UI元素中的文本。文本信息对于人类使用该应用程序非常重要。我们相信，如果可以在交互模型中正确地表示和学习文本信息，则可以进一步提高Humanoid的性能。</p><p><strong>学习非人类互动的痕迹</strong>。我们的方法在很大程度上依赖于人工交互轨迹，如果我们想要从更大的数据集中学习更多交互模式，这些轨迹可能难以扩展。由于模型实际从人类交互中学到的是每个UI中动作的重要性，因此只要可以分析动作的重要性，就可以直接训练机器生成的轨迹。</p><h1 id="VI-结束语"><a href="#VI-结束语" class="headerlink" title="VI.结束语"></a>VI.结束语</h1><p>本文介绍Humanoid，一种用于Android应用程序的新GUI测试输入生成器，能够通过深度学习生成类似人类的测试输入。 Humanoid采用深度神经网络模型来了解最终用户更可能与哪些UI元素进行交互以及如何与大量用户生成的交互跟踪进行交互。在学习模型的指导下，Humanoid能够准确预测与Android应用程序的真人交互。根据对大量开源应用程序和流行的商业应用程序的实验，Humanoid能够比六种最先进的测试工具实现更高的测试覆盖率和更快的速度</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h1&gt;&lt;p&gt;自动输入生成器广泛用于移动应用程序的大规模动态分析和测试。这样的输入生成器必须不断地选择与其
      
    
    </summary>
    
      <category term="论文" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/"/>
    
      <category term="fuzzing" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/fuzzing/"/>
    
      <category term="机器学习" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/fuzzing/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="fuzzing" scheme="http://yama0xff.com/tags/fuzzing/"/>
    
      <category term="机器学习" scheme="http://yama0xff.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="2019年" scheme="http://yama0xff.com/tags/2019%E5%B9%B4/"/>
    
      <category term="Android" scheme="http://yama0xff.com/tags/Android/"/>
    
  </entry>
  
  <entry>
    <title>Remote Protocol Vulnerability Discovery for Intelligent Transportation Systems (ITS)</title>
    <link href="http://yama0xff.com/2019/04/22/Remote-Protocol-Vulnerability-Discovery-for-Intelligent-Transportation-Systems-ITS/"/>
    <id>http://yama0xff.com/2019/04/22/Remote-Protocol-Vulnerability-Discovery-for-Intelligent-Transportation-Systems-ITS/</id>
    <published>2019-04-22T03:40:43.000Z</published>
    <updated>2019-04-23T03:08:59.233Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>ITS是当今典型的智能应用。为了实现更安全和更高效的运输系统的目标，发现ITS的脆弱性起着重要作用。本文基于ITS的通信视图分析了ITS的威胁源。提出了一个协议漏洞发现框架，用于基于模糊测试和自动分析保护ITS应用程序，支持机器学习，遗传算法和模式识别技术。最后，还给出了ITS中开放网络视频接口论坛（ONVIF）协议上的漏洞发现的典型案例，以证明所提议的协议漏洞发现框架的有效性和实用性。该案例的实验结果表明，协议漏洞发现框架支持以有效的方式发现ITS的漏洞。将不同协议模糊测试模式和分析模式组合到一个框架中的挑战，以及限制也被报告和讨论。最后，本文总结了ITS框架的未来研究方向和应用。（没啥新思路）</p><p>Keywords—ITS, protocol vulnerability discovery, threat model,fuzzing, automatic analysis </p><table><thead><tr><th>relevant information</th><th></th></tr></thead><tbody><tr><td><em>作者</em></td><td>Liang Ming, Gang Zhao, Minhuan HuangЪ, Ling PangЪ, Jin Li, Jingzhe Zhang, Dan Li, Shuaibing Lu</td></tr><tr><td><em>单位</em></td><td>National Key Laboratory of Science and Technology on Information System Security</td></tr><tr><td><em>出处</em></td><td>2018 IEEE Third International Conference on Data Science in Cyberspace</td></tr><tr><td><em>原文地址</em></td><td><a href="https://ieeexplore.ieee.org/iel7/8411555/8411822/08411968.pdf" target="_blank" rel="noopener">https://ieeexplore.ieee.org/iel7/8411555/8411822/08411968.pdf</a></td></tr><tr><td><em>源码地址</em></td><td></td></tr><tr><td><em>发表时间</em></td><td>2018年</td></tr></tbody></table><h1 id="I-引言"><a href="#I-引言" class="headerlink" title="I. 引言"></a>I. 引言</h1><p>智能交通系统（ITS）是一种重要的交通基础设施，在自动事件检测，智能视频监控，车辆到基础设施，动态交通灯序列等方面有着快速发展[1]。 ITS中涉及许多用户，控制器，演员和操作员。中心或领域中的每个实体直接或间接地改变了商品的流动方式。中心到现场（C2F）通信和中心到中心（C2C）通信使中心系统之间以及中心系统与该中心管理的多个控制或监视设备之间能够进行通信，从而有效地交换控制指令和状态以及交通流量信息[2]。</p><p>但保护ITS是他们为公共交通提供信息服务的基础。发现ITS的脆弱性是保护ITS并使流量畅通的有效方法[3]。 2015年，一则新闻震惊全国，黑客远程控制了一辆吉普车并在高速公路上杀死了它的发动机[4]。作为一种信息系统，ITS将比传统的计算机系统和网络遇到类似甚至更多的网络威胁。在ITS中，C2F通信和C2C通信是两种根本不同类型的交通控制通信，并且已经研究了许多方法来提高通信的安全性[5]。然而，ITS总体上继承了与计算机系统和无线网络相关的固有问题。</p><p>Fuzzing是一种黑盒测试方法，是一种黑盒软件测试技术，已广泛应用于发现通信协议的漏洞。有一些通用的模糊测试框架，如SPIKE [6]和ProtoFuzz [7]，它们不支持ITS应用程序。其他工具如ircfuzz [8]，dhcpfuzz [9]和InfigoFTPStressFuzzer [10]分别用于模糊特殊协议，但没有用于ITS协议漏洞发现的特殊模糊测试工具。</p><p>本文探讨了在实际网络中发现和分析ITS协议漏洞的有效性。各种应用协议可能会导致ITS的风险。本文将研究ITS的安全性，威胁和协议漏洞发现问题。本文的其余部分安排如下：第二部分总结了ITS的ITS通信视图和威胁源。在第III节中，提出了ITS的协议漏洞发现框架及其模糊设计，自动分析和概念验证案例。第四节讨论了这种提议的测试方法的挑战和局限性。最后一节第五节总结了整篇论文</p><h1 id="II-通信视图和威胁源"><a href="#II-通信视图和威胁源" class="headerlink" title="II.通信视图和威胁源"></a>II.通信视图和威胁源</h1><h2 id="A-ITS的通信视图"><a href="#A-ITS的通信视图" class="headerlink" title="A. ITS的通信视图"></a>A. ITS的通信视图</h2><p>协同和智能交通的架构参考（ARC-IT）是ITS的最新参考架构模型[11]。 ARC-IT提供了一个用于规划，定义和集成智能交通系统的通用框架，包括所有连接的车辆应用。它涵盖了国家ITS架构7.1版和互联汽车参考ITS架构（CVRIA）2.2版的所有范围和内容。此体系结构中有企业视图，功能视图以及物理视图和通信视图。特别地，图1中的通信视图描述了提供物理对象之间的互操作性所必需的协议，其提供了保护ITS的一般方式。</p><p><img src="/2019/04/22/Remote-Protocol-Vulnerability-Discovery-for-Intelligent-Transportation-Systems-ITS/1.jpg" alt=""></p><p>在通信视图中，ITS上面的IP协议栈中使用了大量协议。典型的信息层协议包括NTCIP（ITS协议的国家运输通信）系列，ONVIF（开放式网络视频接口论坛）等，应用层协议包括SNMP，STMP，HTTP，FTP，SOAP，C2C XML，DATEX [12] ]， 等等。每个协议都负责ITS中相应类型的应用程序。特别是NTCIP标准为运营运输管理系统的机构提供了更高的灵活性和选择。 NTCIP标准的使用消除了跨机构协调的障碍，并允许不同类型和不同制造商的设备混合在同一通信线路上。例如，NTCIP 1203是用于动态消息标志（DMS）的NTCIP对象定义，ONVIF规范定义了网络客户端和设备之间的通信过程，这使得使用已定义的通用和良好的接口来构建不同制造商的设备和接收器网络视频系统成为可能。</p><h2 id="B-ITS的威胁来源"><a href="#B-ITS的威胁来源" class="headerlink" title="B. ITS的威胁来源"></a>B. ITS的威胁来源</h2><p>除了未经授权的攻击外，还有一些攻击者可能伪装成合法用户。由于有很多用户，谁可以生成数据，在ITS发送消息和接收警报，因此内部攻击将越来越受欢迎。根据通信视图，以下列出了ITS中存在的安全威胁和攻击：</p><ul><li>应用层威胁包括消息重放攻击，消息篡改攻击，恶意消息攻击以及其他人员攻击，欺骗，嗅探和拒绝服务的攻击方式。消息重放攻击意味着攻击者重新发送合法用户最初发送的旧消息，以增加网络流量并导致拥塞。消息篡改攻击意味着攻击者作为中间人修改消息，然后将其发送出去以造成问题或误导用户。恶意消息攻击包括C2F，C2C和V2V通信中的恶意消息攻击，攻击者向网络中的其他节点发送虚假信息;从而误导用户并可能造成严重破坏。</li><li>传输层和网络层威胁包括伪造RSU攻击，拒绝服务，基础密钥泄漏以及其他通信干扰攻击。伪造RSU攻击是获取车辆节点的信息，然后扰乱车辆网络通信。传输和网络层中的拒绝服务是通过临时或无限期地中断连接到车辆网络的节点中的服务来使其预期用户无法使用网络资源。基础密钥泄漏是一种威胁，因为V2V通信中使用的主密钥可能被攻击者嗅探和滥用。</li><li>数据链路层和物理层威胁包括物理损坏，构建障碍和能源干扰。物理损坏是使汽车中的RSU或传感器物理损坏或混乱。建筑障碍是通过设置建筑物，墙壁等障碍物来中断车辆网络的无线信号通信。能量扰动是通过能量和功率控制来干扰车辆网络的无线通信。</li></ul><p>在上述威胁中，中间人攻击可能会危及ITS的机密性。嗅探可能会损害ITS的信息完整性。嗅探和欺骗可能会损害ITS的消息不可否认性。拒绝服务，物理攻击，信号中断和能源干扰可能会影响ITS的可用性。</p><p> 显然，与通信有关的威胁是关键问题，发现协议漏洞和安全协议是ITS安全的基础。除了这些技术威胁之外，ITS还面临着许多安全管理风险，例如操作故障，个人安全设置错误，车辆丢失引起的钥匙泄漏，租车误用等。总之，所有这些威胁和对抗方法都会给ITS带来风险，并大大提高ITS协议漏洞的可能性</p><h1 id="III-基于模糊的远程协议漏洞发现的自动框架"><a href="#III-基于模糊的远程协议漏洞发现的自动框架" class="headerlink" title="III.基于模糊的远程协议漏洞发现的自动框架"></a>III.基于模糊的远程协议漏洞发现的自动框架</h1><h2 id="A-漏洞发现框架"><a href="#A-漏洞发现框架" class="headerlink" title="A.漏洞发现框架"></a>A.漏洞发现框架</h2><p>协议漏洞发现是ITS安全的关键问题。在下文中，我们将介绍基于模糊测试的ITS协议的自动漏洞发现框架。 ITS中的信息层和应用层中有许多协议用于各种功能，服务和场景。 ITS中的所有设备都将与各自的协议进行通信。为了对各种应用层协议和信息层协议（如IETF HTTP，IETP FTP，SOAP，NTCIP系列和ONVIF）进行模糊测试，我们将构建ITS协议漏洞分析的通用框架。</p><p><img src="/2019/04/22/Remote-Protocol-Vulnerability-Discovery-for-Intelligent-Transportation-Systems-ITS/2.jpg" alt=""></p><p>在NTCIP系列中，应用程序级别采用SNMP，STMP，FTP，TFTP，C2C XML，DATEX等。在ONVIF标准中，应用程序级别采用SOAP / HTTP。所有这些应用程序级协议都可以在TCP / IP堆栈上运行。由于ITS中的几乎所有通信协议都在IP网络上工作，因此可以基于IP数据包通信以一般方式构建漏洞发现框架，如图2所示。</p><p>在图2中，ITS的协议漏洞发现框架包括三个组件：数据包捕获，模糊测试生成器和漏洞分析。 Packet Capture组件负责在线捕获软件包并将其输出到Fuzzing Generator组件以进行消息自定义，并将其输出到Vulnerability Analysis组件以发现漏洞。Fuzzing Generator组件负责自定义模糊测试消息，这些消息将发送到ITS中的目标并触发其漏洞。在Fuzzing Generator组件中，ITS，C2F和C2C通信都支持许多应用层协议，如SNMP，STMP，FTP，TFTP，C2C XML，DATEX和SOAP。并且可以使用各种模糊变量（例如静态模糊测试向量，源代码和随机数据）来组成请求模糊消息，这将在第III B节中详细描述。漏洞分析组件负责通过比较和分析来自Fuzzing Generator组件的请求消息和来自Packet Capture组件的响应消息来发现ITS中目标的漏洞。在漏洞分析组件中，机器学习算法，遗传算法和模式识别技术可用于自动发现漏洞以获得更高的效率，这将在第III节C中详细描述。通过使用学习和培训，漏洞分析组件可以构建一个强大的机器学习模型进行分类。通过将响应消息与关联的请求模糊消息进行比较，分类模型可以识别目标设备中的协议漏洞。一旦发现漏洞，模糊测试生成器组件将停止模糊测试，并且漏洞分析组件将存储所有请求模糊消息，模式和响应消息以供进一步验证。</p><p>该协议漏洞发现框架扩展了传统的计算机网络协议测试思想，为发现ITS的协议漏洞提供了一整套功能。通过漏洞分析组件，我们可以解码响应消息来检查关联请求消息的回复，并找出ITS的漏洞。此外，请求模糊消息有时可能会将目标设备堵塞在ITS中。为了确保目标仍然有效，Fuzzing Generator组件应定期运行探测工具，例如ping，以检查ITS中目标的工作状态。</p><h2 id="B-漏洞发现中的模糊设计"><a href="#B-漏洞发现中的模糊设计" class="headerlink" title="B.漏洞发现中的模糊设计"></a>B.漏洞发现中的模糊设计</h2><p>模糊测试是一种有效的信息定制方法，可以发现网络和信息系统中的协议漏洞。生成模糊消息的工作流程如图3所示。在工作流程图中，模糊消息定制是一个关键组件，它将模糊测试数据排列成与测试协议规范兼容的消息。为了自动生成请求模糊消息，可以通过下面详细描述的模糊模式对该过程进行形式化和编程。可以从静态模糊测试向量，随机数据和IP数据包捕获工具获得的源代码导入模糊测试数据。</p><p><img src="/2019/04/22/Remote-Protocol-Vulnerability-Discovery-for-Intelligent-Transportation-Systems-ITS/3.jpg" alt=""></p><p>基于TCP / IP，有一些典型的漏洞发现模糊模式，我们可以在形式化中描述它们，如下所示。</p><ul><li><p><strong>模式1：方法+目标地址+ [标题] + &lt;协议名称&gt; + [数据] + [功能]</strong></p></li><li><p><strong>模式2：方法+目标地址+ [标题] + &lt;随机数据&gt; +数据</strong></p></li><li><p><strong>模式3：[方法] +目标地址+  [标题] + [数据] + [功能]</strong></p></li></ul><p>在模式1，模式2和模式3中，METHOD是自定义请求消息中的操作。它包括GET，POST，PUT，SET，GET-REQUEST，GET-NEXT-REQUEST，SET-REQUEST，GET-RESPONSE，TRAP等，它们在SOAP，SNMP和STMP中使用。 METHOD部分通常可以填充静态模糊矢量。 TARGET ADDRESS指定目标设备，可以是URI，请求ID，IP地址，服务地址等。对于目标设备，TARGET ADDRESS是确定的。 HEADERS包括各种标头信息，例如Accept，Cache-Control，Content-Encoding，Content-Language，Content-Length，Content-Type，Error Status，Error Index等。 HEADERS通常可以从捕获的数据包中填充源代码。 PROTOCOL NAME是经过测试的协议及其版本的名称，例如HTTP / 1.0，HTTP / 1.1等。而PROTOCOL NAME是模式中的可选部分。 DATA指定协议规范下的消息内容，它可以是认证，功能和其他静态文本的全部或部分，通常可以通过在线捕获的数据包填充源代码。RANDOM DATA可以是任何随机字符，可用于模糊认证，功能等。 FUNCTIONS包括协议中的所有可用操作函数，例如GetUsers，CreatUser，GetDeviceInformation，SystemReboot等，它们可以在协议规范下填充静态模糊测试向量。随机数据和函数也可以是DATA的一部分。在所有模式中，方括号[]表示内部变量是静态模糊矢量，而天使括号&lt;&gt;表示内部变量是可选的。</p><p>显然，模式1，模式2和模式3只是请求消息的可用漏洞模糊模式的三个代表，它们适合ITS中的相应模糊测试应用。模式1侧重于通过修改消息数据来发现消息重放和消息修改中的协议漏洞。模式2侧重于通过修改部分消息数据来发现认证信息中协议的漏洞。模式3侧重于通过修改方法（如GET，SET等）来发现协议的漏洞。此外，对于各种协议，根据需要，还可以在模糊消息中使用一些新的模糊化请求消息模式。</p><p>事实上，漏洞模糊测试模式只是抽象了请求消息的关键字符。例如，在模式2中，METHOD，目标地址，若干HEADERS，变量RANDOM DATA和其他DATA组成关键字符向量，其表示具有类似模糊测试模式的一些请求消息。这些关键字符对于自动分析请求消息和响应消息非常有帮助，这将在下面进一步描述。</p><h2 id="C-漏洞发现中的自动分析"><a href="#C-漏洞发现中的自动分析" class="headerlink" title="C.漏洞发现中的自动分析"></a>C.漏洞发现中的自动分析</h2><p>模糊测试后，我们可以通过智能方法比较请求消息和响应消息，如机器学习模型，遗传算法，模式识别等。这是实现自动分析的关键步骤。一些典型的漏洞分析模式包括但不限于以下内容。</p><ul><li><strong>模式4：[请求字符] + [状态代码] -&gt;“通过/失败”</strong></li></ul><p>在模式4中，“请求字符”是请求模糊消息的关键字符。 STATUS CODES是响应消息的状态，例如HTTP状态码，并且可以在摘要中反映模糊消息的结果。 PASS / FAIL是漏洞发现的分类标签。例如，如果STATUS CODE为“200 OK”且REQUEST CHARACTER为“HTTP / 1.1”，则相应的SOAP请求消息可能会发现目标设备上的漏洞，并且漏洞发现的分类标签应为“PASS”。另一方面，如果STATUS CODE是“401 Unauthorized”且REQUEST CHARACTER是模式2，则相应的SOAP请求消息可能不会在目标设备上发现身份验证漏洞，并且漏洞发现的分类标签应为“FAIL”。 STATUS CODE可以通过源代码从在线捕获的数据包或协议规范获得。</p><ul><li><strong>模式5：[请求字符] + [敏感字符] -&gt;“通过/失败”</strong></li></ul><p>在模式5中，“请求字符”是模糊请求消息的关键字符。敏感字符是指响应消息中的敏感信息，例如用户名和执行结果，可以在捕获的数据包的源代码中找到。PASS / FAIL是漏洞发现的分类标签。例如，如果REQUEST CHARACTERS为“HTTP / 1.1”且SENSITIVE CHARACTERS为“&lt;tt：UserLevel&gt; Administrator &lt;/ tt：UserLevel&gt;”，则相应的请求消息可能会在目标设备上发现身份验证漏洞，并且分类标签为漏洞发现应该是“PASS”。另一方面，如果REQUEST CHARACTERS为“HTTP / 1.1”且敏感字符不匹配，则相应的请求消息可能无法在目标设备上发现身份验证漏洞，并且漏洞发现的分类标签应为 “FAIL ”。</p><ul><li><strong>模式6：[请求字符] + [错误字符] -&gt;“通过/失败”</strong></li></ul><p>在模式6中，请求字符是请求模糊消息的关键字符。错误字符是指响应消息中的错误警报或不合理的信息，例如输入文本，未记录的服务等。 PASS / FAIL是漏洞发现的分类标签。例如，如果REQUEST CHARACTERS是“Fuzzing work？”，这是一个有意识的输入字符串，并且响应消息还包含一个ERROR CHARACTERS“Fuzzing work？”，这与我们在请求消息中的输入相同，那么相应的请求消息可能会发现目标设备中的XSS漏洞，并且漏洞发现的分类标签应为“PASS”。相反，如果没有匹配的ERROR CHARACTERS，则相应的请求消息可能不会在目标设备上发现身份验证漏洞，并且漏洞发现的分类标签应为“FAIL”。错误字符可以通过源代码从线上捕获的数据包获得，也可以通过故意输入获得。</p><ul><li><strong>模式7：[请求字符] + [请求超时] -&gt; 通过/失败</strong></li></ul><p>在模式7中，REQUEST CHARACTERS是模糊请求消息的关键字符。 REQUEST TIMEOUT表示响应消息无法在所需时间内到达。 PASS / FAIL是漏洞发现的分类标签。例如，如果请求CHARACTERS是一个SNMP请求，和该请求后请求超时出现时，则对应的请求消息可能发现在目标装置中的拒绝服务（DoS）的脆弱性，以及脆弱性发现的分类标签应该是“PASS” 。相反，如果没有匹配的REQUEST TIMEOUTS，则DoS漏洞发现的分类标签应为“FAIL”。 REQUEST TIMEOUTS可以通过源代码从在线捕获的数据包或协议规范获得。</p><p>在模式4，模式5，模式6和模式7中，方括号[]表示内部变量是静态模糊矢量，它允许构建数据集以定义包含大量值的变量。例如，[REQUEST CHARACTERS]可以是请求消息的字符数据集。通过这些模式，可以创建足够的训练样本并将其用于机器学习模型。经过训练，我们可以使用该机器学习模型自动判断响应并在线请求消息。如果结果是PASS，这意味着请求消息发现漏洞，那么我们可以深入研究漏洞及其漏洞利用工具。实际上，除了这种自动分析方法之外，模式4，模式5，模式6和模式7也可以用于手动响应消息识别。通过这些精心设计的模式和字符，我们可以确定当前设备中是否存在漏洞。</p><p>如上所述，模式4，模式5，模式6和模式7中的请求字符可以是模式1，模式2和模式3的全部或任何部分。并且所有模式为处理请求消息和响应消息提供了良好的参考。 自动实现ITS的漏洞发现。在发现具有漏洞的可疑目标设备后，我们可以进一步分析并找到确切的漏洞地址，然后给出漏洞描述和改进建议。</p><h2 id="D-漏洞发现案例"><a href="#D-漏洞发现案例" class="headerlink" title="D.漏洞发现案例"></a>D.漏洞发现案例</h2><p>在这种情况下，我们将使用第III节中描述的漏洞发现框架对ITS中的ONVIF摄像机进行实际漏洞分析.ONVIF规范与SOA兼容，并且所有设备功能都被抽象为Web服务并使用简单对象访问协议（SOAP）通过HTTP进行通信。不幸的是，SOAP 1.1没有包含签名消息的条款，因此缺乏安全性。因此，我们使用设计良好的SOAP消息来模糊此漏洞所涉及的远程ONVIF设备。</p><p><img src="/2019/04/22/Remote-Protocol-Vulnerability-Discovery-for-Intelligent-Transportation-Systems-ITS/4.jpg" alt=""></p><p>基于上面的漏洞发现框架，我们在真实的网络实验环境中执行漏洞分析。实验场景是交叉路口上方的视频监控应用程序，如图4所示。我们可以访问ITS并访问此ONVIF摄像机，但我们没有摄像机的管理员权限。</p><p><img src="/2019/04/22/Remote-Protocol-Vulnerability-Discovery-for-Intelligent-Transportation-Systems-ITS/5.jpg" alt=""></p><p>为了在框架中实现Fuzzing Generator组件来制作模糊消息，我们使用Python语言开发了一个原型来修改具有与ONVIF规范兼容的各种功能的实际消息，然后将自定义消息发送到实际网络中的测试相机。真实的消息由Wireshark工具在线捕获。我们使用模式1作为自定义请求消息的参考，字符及其值如表I所示。因此，根据模式1，METHOD是POST，TARGET ADDRESS是摄像机IP地址，HEADERS是典型的HTTP标题和PROTOCOL NAME是HTTP / 1.1，DATA专注于从真实消息解码的认证信息，而FUNCTIONS是功能向量，包括Getusers，CreatUser，GetDeviceInformation，SystemReboot等。 Fuzzing Generator原型可以向ONVIF摄像机保留模糊消息，所有这些请求消息都存储在数据库中以供进一步分析。自定义请求消息之一如下。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;soap:Envelope</span><br><span class="line">xmlns:soap=&quot;http://www.w3.org/2003/05/soap-envelope&quot;</span><br><span class="line">xmlns:tds=&quot;http://www.onvif.org/ver10/device/wsdl&quot;</span><br><span class="line">xmlns:tt=&quot;http://www.onvif.org/ver10/schema&quot;&gt; &lt;s:Header</span><br><span class="line">xmlns:s=&quot;http://www.w3.org/2003/05/soap-envelop</span><br><span class="line">&lt;wsse:Security xmlns:wsse=&quot;http://docs.oasisopen.org/wss/2004/01/oasis-200401-wss-wssecurity-secext-1.0.xsd&quot; xmlns:wsu=&quot;http://docs.oasis-open.org/wss/2004/01/</span><br><span class="line">oasis-200401-wss-wssecurity-utility-1.0.xsd&quot;&gt;</span><br><span class="line">&lt;wsse:UsernameToken&gt;</span><br><span class="line">&lt;wsse:Username&gt;username&lt;/wsse:Username&gt;</span><br><span class="line">&lt;wsse:Password Type=&quot;http://docs.oasisopen.org/wss/2004/01/oasis-200401-wss-username-tokenprofile-</span><br><span class="line">1.0#PasswordDigest&quot;&gt;keys&lt;/wsse:Password&gt;&lt;wsse:Nonce&gt;k</span><br><span class="line">eys&lt;/wsse:Nonce&gt;</span><br><span class="line">&lt;wsu:Created&gt;time&lt;/wsu:Created&gt;</span><br><span class="line">&lt;/wsse:UsernameToken&gt;</span><br><span class="line">&lt;/wsse:Security&gt;</span><br><span class="line">&lt;/s:Header&gt;</span><br><span class="line">&lt;soap:Body&gt;</span><br><span class="line">&lt;tds: Getusers /&gt;</span><br><span class="line">&lt;/soap:Body&gt;</span><br><span class="line">&lt;/soap:Envelope&gt;</span><br></pre></td></tr></table></figure><p>在这种情况下，自动漏洞分析组件使用模式4实现。模式4中的参数及其值如表II所示。因此，根据模式4，REQUEST CHARACTERS是模式1，一旦响应消息的STATUS CODE为“200 OK”就会出现PASS。为了简化漏洞分析过程，我们使用模式识别来演示此步骤。我们在线捕获响应数据包并检查其状态代码，并将所有响应数据包存储在数据库中，以便与其请求消息进行相关性分析。与上述请求消息相关联的响应消息之一如下所示。</p><p><img src="/2019/04/22/Remote-Protocol-Vulnerability-Discovery-for-Intelligent-Transportation-Systems-ITS/6.jpg" alt=""></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">HTTP/1.1 200 OK</span><br><span class="line">Date: Wed, 28 Mar 2018 14:05:02 GMT</span><br><span class="line">Server: App-webs/</span><br><span class="line">Connection: close</span><br><span class="line">Content-Length: 2300</span><br><span class="line">Content-Type: application/soap+xml; charset=utf-8</span><br><span class="line">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span><br><span class="line">&lt;env:Envelope xmlns:env=&quot;http://www.w3.org/2003/05/soapenvelope&quot; …&gt;&lt;env:Body&gt;&lt;tds:GetUsersResponse&gt;&lt;tds:User</span><br><span class="line">&gt;&lt;tt:Username&gt;admin&lt;/tt:Username&gt;</span><br><span class="line">&lt;tt:UserLevel&gt;Administrator&lt;/tt:UserLevel&gt;</span><br><span class="line">&lt;/tds:User&gt;</span><br><span class="line">&lt;tds:User&gt;&lt;tt:Username&gt;user6&lt;/tt:Username&gt;</span><br><span class="line">&lt;tt:UserLevel&gt;User&lt;/tt:UserLevel&gt;</span><br><span class="line">&lt;/tds:User&gt;</span><br><span class="line">&lt;/tds:GetUsersResponse&gt;</span><br><span class="line">&lt;/env:Body&gt;</span><br><span class="line">&lt;/env:Envelope&gt;</span><br></pre></td></tr></table></figure><p>上面的响应消息回复状态代码“200 OK”，这意味着根据模式4，其请求消息触发了漏洞。实际上，经过测试的ONVIF摄像机会错误地响应管理员用户。在请求消息和响应消息中进行分析后，我们发现测试的摄像机存在ONVIF认证漏洞，漏洞位置是SOAP标头中的标识认证片段。由于它是ONVIF协议中的致命漏洞，因此我们还可以通过使用此框架对相机的云台变焦和录制服务进行模糊处理时发现类似的现象。从这个案例中，我们可以发现第III节A中提出的漏洞发现框架可以有效地远程发现ITS的协议漏洞。</p><h1 id="IV-测试方法的挑战和限制分析"><a href="#IV-测试方法的挑战和限制分析" class="headerlink" title="IV.测试方法的挑战和限制分析"></a>IV.测试方法的挑战和限制分析</h1><p>协议漏洞发现框架提供了一种通过请求模糊消息来查找ITS及其设备的协议漏洞的方法。但是仍然存在许多安全问题，例如社会工程威胁，结构脆弱性，能量干扰物理层中的电源中断等等。在这种情况下，ITS不仅应该通过通信视图中的协议测试进行分析，还要检查系统级和物理视图。<br>随着ITS应用的发展，应用协议将来会越来越多，因此将不同的消息定制协议组合到一个框架中将是一个挑战，需要在框架中用新的协议栈模块扩展第三节A中的框架。</p><h1 id="V-结论"><a href="#V-结论" class="headerlink" title="V.结论"></a>V.结论</h1><p>协议漏洞发现是保护ITS本身的关键问题。由于ITS在公共交通中公开广泛部署，越来越多的攻击和威胁会极大地影响ITS的可用性并损害其完整性和机密性，甚至使道路交通比以前更加糟糕。本文从ITS通信的角度提出了ITS威胁的分类，为ITS协议漏洞发现提供了良好的指导。接下来，提出了一种协议漏洞发现框架，用于通过使用模糊消息定制和自动分析来保护ITS，其支持机器学习算法，遗传算法和模式识别技术。最后，还给出了关于ITS中ONVIF协议漏洞的选定概念验证案例，以证明所提议的协议漏洞发现框架的有效性和实用性。可以在丰富可用的请求消息模式和漏洞分析模式以及扩展协议栈模块方面做进一步的工作，以提高协议漏洞发现框架对更多协议的能力。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h1&gt;&lt;p&gt;ITS是当今典型的智能应用。为了实现更安全和更高效的运输系统的目标，发现ITS的脆弱性起着重
      
    
    </summary>
    
      <category term="论文" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/"/>
    
      <category term="fuzzing" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/fuzzing/"/>
    
      <category term="机器学习" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/fuzzing/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="fuzzing" scheme="http://yama0xff.com/tags/fuzzing/"/>
    
      <category term="机器学习" scheme="http://yama0xff.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Automatic Text Input Generation for Mobile Testing</title>
    <link href="http://yama0xff.com/2019/04/19/Automatic-Text-Input-Generation-for-Mobile-Testing/"/>
    <id>http://yama0xff.com/2019/04/19/Automatic-Text-Input-Generation-for-Mobile-Testing/</id>
    <published>2019-04-19T03:41:06.000Z</published>
    <updated>2019-04-22T03:07:35.736Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>已经提出许多设计来改进自动化移动手机测试。尽管有这些改进，但提供适当的文本输入仍然是一个突出的障碍，这阻碍了大规模采用自动化测试方法。关键的挑战是如何在用例上下文中自动生成最相关的文本。例如，应在移动浏览器应用程序的地址栏中输入有效的网站地址，以继续测试应用程序;应在音乐推荐应用的搜索栏中输入歌手的姓名。如果没有正确的文本输入，测试将会卡住。我们提出了一种新颖的基于深度学习的方法来应对挑战，将问题简化为最小化问题。另一个挑战是如何使该方法通常适用于受过训练的应用程序和未经训练的应用程序。我们利用Word2Vec模型来应对挑战。我们已经将我们的方法构建为工具，并使用包括Firefox和Wikipedia在内的50种iOS移动应用程序对其进行评估。结果表明，我们的方法明显优于现有的自动文本输入生成方法。</p><table><thead><tr><th>relevant information</th><th></th></tr></thead><tbody><tr><td><em>作者</em></td><td>Peng Liu, Xiangyu Zhang, Marco Pistoia, Yunhui Zheng, Manoel Marques and Lingfei Zeng</td></tr><tr><td><em>单位</em></td><td>IBM T. J. Watson Research Center, Yorktown Heights, New York, USA</td></tr><tr><td><em>出处</em></td><td>2017 IEEE/ACM 39th International Conference on Software Engineering</td></tr><tr><td><em>原文地址</em></td><td><a href="https://dl.acm.org/citation.cfm?id=3097445" target="_blank" rel="noopener">https://dl.acm.org/citation.cfm?id=3097445</a></td></tr><tr><td><em>源码地址</em></td><td><a href="https://github.com/dkhamsing" target="_blank" rel="noopener">https://github.com/dkhamsing</a></td></tr><tr><td><em>发表时间</em></td><td>2017年</td></tr></tbody></table><h1 id="I-简介"><a href="#I-简介" class="headerlink" title="I. 简介"></a>I. 简介</h1><p>移动设备已成为我们生活中不可或缺的一部分。移动应用程序是提供各种便捷和高质量服务的工具，例如网页浏览，娱乐，交通信息辅助，银行和社交网络。为了满足日益增长的需求，移动市场正以每天1000多个新应用的速度快速增长[1] [6]。因此，开发团队一直处于激烈的竞争中，在发布截止日期前面临巨大的压力。遗憾的是，这通常会导致移动应用程序中的错误，例如运行时应用程序崩溃，UI设计中的缺陷以及未完全实现的功能。</p><p>移动测试的目标是在应用程序发布之前发现它们中的错误。有两种主流的移动测试方法：手动测试和自动monkey测试。在手动测试中，测试人员手动执行操作以尽可能多地运用用例。这种方法的缺点是需要大量的人力，因为测试人员需要在整个测试期间与应用程序密切交互。此外，通常专注于演示常见用例中的功能的人类测试人员可能经常会错过可能触发异常的极端情况。</p><p>自动化monkey测试[8]，[28]，[18]，[19]，[37]，[21]，[20]，[24]，[27]被提议用于减少人类的努力并最大化用例覆盖率。 “monkey”是描述这种测试如何运作的隐喻;像monkey一样，该工具执行随机动作序列，包括单击UI视图（或UI屏幕）上的按钮并执行随机击键。为了涵盖尽可能多的动作序列，研究人员提出了各种新颖的搜索算法，与monkey随机搜索策略形成对比。尽管有这些改进，但在monkey测试期间提供适当的文本输入仍然是一个突出的障碍，这阻碍了monkey测试方法的大规模采用。在许多用例中，大多数现有技术很难提供有意义的文本输入。例如，对于电影应用程序，monkey测试几乎无法提供有意义的输入，例如星际迷航。相反，它会产生不相关的输入，如4t6。因此，没有找到任何结果，从而使Monkey无法前往显示适当结果的屏幕。手动规范可以缓解这个问题，但需要大量的人力。</p><p>在本文中，我们提出了一个解决方案，让Monkey自动生成相关的文本输入。有了这样的输入，Monkey可以通过长动作序列进入工作流深处的UI屏幕（简称深UI屏幕），而不是一开始就卡住。一旦它到达深度UI屏幕，Monkey可以应用其他面向bug披露的测试技术，例如基于搜索的测试[26]，符号测试生成[22]，甚至是随机测试[34]来识别复杂工作流中的错误。</p><h2 id="A-生成相关输入"><a href="#A-生成相关输入" class="headerlink" title="A.生成相关输入"></a>A.生成相关输入</h2><p>输入生成的关键要求是生成与上下文相关的输入。<br>$$<br>Movie -&gt; search -&gt; star trek<br>$$</p><p>$$<br>Weather -&gt; search -&gt; New York<br>$$</p><p>在用例1中，在单击标记为“电影”的菜单项并且触发了标记为“搜索”的搜索栏后，应用程序将需要用户的电影标题。因此，输入星际迷航是相关的;在用例2中，单击标记为“天气”的菜单项并触发标记为“搜索”的搜索栏后，应用程序将使用该用户的城市名称。因此输入纽约是相关的。相反，在一个上下文中相关的输入可能在不同的上下文中不相关。例如，单击菜单项Weather时，输入Star Trek将不合适。我们还在第七节中将读者引用到更真实的例子中。</p><p><strong>挑战</strong>。上述要求对自动文本输入生成提出了很大的挑战。首先，相关性特定于自然语言语义，只有人类测试者才能理解。因此，传统的自动输入生成方法，例如基于符号执行的测试[22]，是不适用的。其次，包含确定相关文本输入的信息的动作（例如，点击菜单项电影或天气）可能不会立即在动作序列中的输入动作之前。因此，维护和查找文本输入与紧接在先行动的信息之间的映射是一种难以奏效的方法。</p><p><strong>我们的深度学习方法</strong>。我们提出了一种新颖的基于深度学习的方法来解决上述挑战。在高层次上，我们的解决方案包括两个阶段：在训练阶段，monkey学习测试人员的手动输入并统计地将他们与上下文相关联，例如行动历史和文本框标签;在预测阶段，monkey根据观察到的上下文自动预测文本输入。我们的方法的核心是递归神经网络（RNN）模型。这种类型的模型在许多自然语言处理（NLP）应用程序中取得了巨大成功，例如机器翻译和输入法自动完成。以输入法自动完成为例，RNN模型将单词之间的语义连接量化为非线性函数，其中参数用大的文本语料库进行训练。给定一个词，非线性函数计算其旁边的单词的概率分布，然后从分布中采样下一个单词。此外，RNN模型保持存储器状态以汇总来自先前单词的重要信息，并在推荐下一单词时将其用作另一输入源。据我们所知，我们是第一个将深度学习应用于自动测试移动设备的文本输入生成问题的人。</p><p>根据Mikolov等人的实证研究 [32]，RNN模型比传统的统计模型（如n-gram模型和隐马尔可夫模型）更精确。具体而言，与传统模型相比，RNN导致18％的误差减少，假设它们在相同的数据上训练，并且即使传统模型训练的数据比RNN模型多5倍，也导致12％的误差减少。</p><h2 id="B-与应用无关的输入生成"><a href="#B-与应用无关的输入生成" class="headerlink" title="B.与应用无关的输入生成"></a>B.与应用无关的输入生成</h2><p>输入生成的另一个重要要求是应用独立性。这意味着在一组应用程序上训练的RNN模型也应该适用于其他应用程序。</p><p><strong>挑战</strong>。在不同的应用程序中使用不同的单词来表示相同的概念对应用程序独立性提出了重大挑战。<br>$$<br>Film -&gt; search -&gt; ?<br>$$<br>假设在训练阶段没有看到标签Film。人类测试人员可以很容易地找出用例1中标签movie和film之间的语义相似性。因此，我们可以预测相关的文本输入 - 例如，星际迷航。然而，RNN模型完全忽略了标签film，因为它没有出现在训练阶段。因此，RNN模型无法预测标签Film的相关文本输入。</p><p><strong>我们基于Word2Vec的解决方案</strong>。我们通过从Google新闻语料库统计学习同义词的人类知识来应对挑战。同义词存储在等价类中。每个等价类的代表用于替换训练和预测期间属于该类的单词。</p><p>我们的方法建立在Word2Vec模型的基础上，这是NLP研究人员最近提出的统计模型。该模型将一个单词映射到一个向量，向量之间的距离测量单词的相似性。 Word2Vec模型通过求解优化问题来学习矢量编码。具体而言，它最小化相似单词之间的距离，并最大化不相关单词之间的距离。 Word2Vec是一种无监督学习算法，这意味着它不需要手动标记训练数据。Word2Vec在结果质量方面优于其他现有模型[33]。这主要是因为Word2Vec可以训练比先前工作多2到3个数量级的数据，而这只是之前工作所需时间的一小部分。</p><p>我们已经构建了一个工具，并使用50个iOS应用程序对其进行评估，包括Firefox和Wikipedia等热门应用程序。评估结果证实了我们的方法的有效性。</p><p>RNN预测平均将Monkey测试的覆盖率提高了21％，而RNN模型和Word2Vec模型的组合将覆盖率提高了28％。<br>此外，如果我们排除基准套件中可用UI屏幕很少的简单应用程序，我们发现RNN预测可将覆盖率提高46％，两种模型的组合可提高60％。同样重要的是，我们的预测非常有效，通常在1毫秒内完成。</p><p>总之，我们在本文中做出以下贡献：</p><ul><li>我们提出了一种基于深度学习的新方法，以自动生成移动UI测试的相关文本输入。</li><li>我们提出了Word2Vec NLP模型的新颖组合，以及使输入生成应用独立的学习。</li><li>我们已将我们的方法作为一个系统实施，并对包括Firefox和Wikipedia在内的50个iOS应用程序进行了实验。结果表明，我们的方法显着增加了Monkey测试的覆盖范围。</li></ul><h1 id="II-系统设计概述"><a href="#II-系统设计概述" class="headerlink" title="II.系统设计概述"></a>II.系统设计概述</h1><p>系统设计如图1所示。monkey测试引擎通过单击屏幕上的按钮来探索移动应用程序。当遇到文本框时，它会从文本输入服务器请求相关输入，如1、2所示。服务器通过进一步将其分派给人工测试人员或RNN运行实例来解析请求，该实例对应于两种模式：手动模式和AI模式。在手动模型中，在收到帮助请求3后，人工测试人员可以输入与上下文相关的文本输入4。如果她认为上下文不符合实际中的任何动作序列，则忽略它。然后，由测试者录入的输入和相应的上下文记录在与服务器相关联的数据库中。在AI模式中，我们首先使用记录在数据库5中的训练数据集训练RNN模型，之后RNN实例可以自动预测文本输入6。</p><p><img src="/2019/04/19/Automatic-Text-Input-Generation-for-Mobile-Testing/1.jpg" alt=""></p><p>在预测阶段6中，Monkey利用RNN模型来预测给定上下文中的文本输入值。基本上，考虑到Monkey测试引擎维护的上下文，模型预测文本输入值。但是，由于我们预测输入的应用程序与我们训练模型的应用程序不同，因此RNN模型可能无法识别Monkey测试期间遇到的某些上下文信息。为了解决这一挑战，我们使用Word2Vec模型改进了RNN模型，该模型有助于识别语义相似的上下文，尽管它们具有不同的句法形式（例如，“moive”和“film”）。通过RNN模型和Word2Vec模型的新颖组合，我们有效地解决了这个问题。</p><p>在下文中，我们首先介绍第III节中的背景，然后解释我们如何应用深度学习技术来自动预测第IV节中的文本输入。<br>在第五节中，我们将解释实现细节。在第六节中，我们讨论了这项工作的假设。第七节介绍评估结果。</p><h1 id="III-背景深度介绍"><a href="#III-背景深度介绍" class="headerlink" title="III. 背景深度介绍"></a>III. 背景深度介绍</h1><p>本节介绍了递归神经网络（RNN）和Word2Vec的背景。 RNN和Word2Vec都是神经网络的特殊形式。为了讨论这两个，我们首先要简要介绍一下神经网络。</p><p><img src="/2019/04/19/Automatic-Text-Input-Generation-for-Mobile-Testing/2.jpg" alt=""></p><p>神经网络（NN）有两种形式：图形形式和数学形式。在图形形式（图2a）中，NN具有输入层，输出层，一个或多个隐藏层。每个层（输入层除外）包括多个神经元，它们与前一层和下一层中的神经元相连。</p><p>每个神经元，如图2b所示，是一个基本的计算单元。它首先将沿着传入边传递的值线性组合为∑ ~i~ p~i~x~i~ + b，其中p~i~和b是要训练的参数。然后它应用激活函数f~a~，例如tanh函数[12]或sigmoid函数[11]。激活函数对于使神经元非线性非常重要。<br>没有激活函数，神经元仅仅是线性函数，神经网络也是线性函数，不能表征许多复杂模型。</p><p>在数学形式中，NN是由神经元代表的函数的组合。设f：R^n^→R^m^表示由神经网络表示的复合函数。设输入向量I∈R^n^表示输入层中n个神经元的输入。设输出向量O∈R^m^表示输出层中m个神经元的输出。神经网络的训练可以被视为一个优化问题：</p><p><img src="/2019/04/19/Automatic-Text-Input-Generation-for-Mobile-Testing/3.jpg" alt=""></p><p>更新参数以最小化预测输出和训练数据集上的实际输出之间的总损失，其中损失函数可以被定义为距离或其他形式。无论损失函数的复杂性如何，梯度下降算法[16]通常用于最小化其值。</p><p>A.递归神经网络</p><p>RNN是一种特殊形式的神经网络，具有反馈回路，如图3所示。为清楚起见，我们使用箭头来表示神经元之间的连接。</p><p><img src="/2019/04/19/Automatic-Text-Input-Generation-for-Mobile-Testing/4.jpg" alt=""></p><p>循环允许在网络执行步骤中导出的信息传递到下一个，类似于人类的长期记忆。图4显示了概念上展开的版本，其中神经网络在概念上被复制以通过多个步骤服务于一系列输入。</p><p><img src="/2019/04/19/Automatic-Text-Input-Generation-for-Mobile-Testing/5.jpg" alt=""></p><p>注意神经网络副本之间的连接。 RNN考虑输入法自动完成的应用，我们应用RNN生成句子“how are you doing”。这些单词一个接一个地输入到输入层。每个字在单热矢量表示中被编码以使得能够学习，例如，单词“how”被编码为[1,0,0,0]。简单地说，向量的每个条目对应于词汇表中的单词（[“how”，“are”，“you”，“doing”]），向量中值1的位置表示编码的单词。从概率的角度来看，向量表示具有100％概率的单词，而其他概率表示具有0％概率的单词。</p><p>利用初始参数设置，给定输入字与从最后一步传递的信息相结合，神经网络输出概率向量，其中第i个条目估计词汇表中的第i个单词接下来出现的概率。例如，基于输入“how”，假设它将下一个词预测为[0.4,0.2,0.1,0.3]，即，最可能的下一个词是“how”。但是，我们从训练数据集中观察到下一个单词应该是“are”。因此，训练算法需要更新参数，使得单词“are”的预测概率变得显着大于其他单词。同样，给定“are”这个词，神经网络需要预测“you”作为下一个词的概率高于其他词。 </p><h2 id="B-Word2Vec"><a href="#B-Word2Vec" class="headerlink" title="B.Word2Vec"></a>B.Word2Vec</h2><p>Word2Vec算法学习空间R^k^中每个单词的向量表示，其中相似的单词可能具有相似的向量。 Word2Vec通常应用于非常大的语料库。为了获得更好的可扩展性，Word2Vec采用传统的神经网络结构。</p><p>Word2Vec采用的矢量表示与上述RNN中使用的单热表示明显不同。 Word2Vec将每个单词映射到空间R^k^中的实值向量，其中k远小于词汇量s，而单热表示将每个单词映射到空间{0,1}^s^中的向量。首先，通过在低维空间中编码矢量，Word2Vec降低了计算的空间复杂度。更重要的是，Word2Vec的矢量表示处于连续空间中，并且两个矢量之间的距离（即，余弦相似距离）有效地测量了单词的相似性。相反，单热表示不能测量相似性。在我们的工作中，我们将Word2Vec视为黑盒子。</p><h1 id="IV-将深度学习应用于输入生成"><a href="#IV-将深度学习应用于输入生成" class="headerlink" title="IV.将深度学习应用于输入生成"></a>IV.将深度学习应用于输入生成</h1><p>在高级别，我们的方法在统计学上学习文本输入值与训练阶段的上下文之间的相关性（第IV-B节）。然后是预测阶段（第IV-C节），一旦Monkey需要在文本框中提供某些值，我们的方法就会根据Monkey目前观察到的上下文来预测值。第IV-D节进一步解释了我们如何推广输入生成以使其独立于应用程序。为便于讨论，我们首先介绍在训练阶段使用的训练数据集（第IV-A节）。</p><h2 id="A-训练数据集"><a href="#A-训练数据集" class="headerlink" title="A.训练数据集"></a>A.训练数据集</h2><p>在不失一般性的情况下，我们假设简化的用户行为模型。在模型中，我们只对两种类型的UI元素感兴趣：按钮和文本框∈domain T~ui~。各种可点击的UI元素（如菜单和tableview单元格）具有类似于按钮的行为，因此在我们的模型中具有相同的抽象。类似地，接受用户输入的一系列文本字段（例如安全文本字段和搜索字段）被抽象为文本框。请注意，我们的实现完全支持所有这些UI元素。我们只对两种类型的动作感兴趣，tap和typeText∈T~action~，它们是UI元素∈T~ui~的最具代表性的行为。</p><p>用户动作α∈A是一个元组，包括UI元素类型τ~ui~∈T~ui~，动作类型τ~action~∈T~action~、显示在UI元素中的标签 δ（例如，图5中的按钮中的“Moive”），以及在动作中涉及的可选值v，例如文本输入值。</p><p>训练数据集基本上记录了动作序列（α~0~，α~1~，….  ，α~n~），其中α~i~表示在第i步的用户动作。 α~n~之前的子序列指的是用户到达发生α~n~的UI屏幕所采取的动作。有关动作序列的更多细节将在第VI节中讨论。</p><p>我们观察到标签δ是用户在使用应用程序时所感知的最突出的信息，考虑提供什么作为输入值。基于这种观察，我们用动作序列中的每个动作α表示标签δ~α~，同时抽象掉所有其他信息。此外，我们还对在动作α~n~中输入的输入值v~αn~感兴趣。因此，上述动作序列简单地表示为（δα~0~，δα~1~，…. ，δa~n~，va~n~ ）.为了便于演示，我们还提到δα~0~，δα~1~，…. ，δa~n~作为输入值vα~n~的上下文。</p><p><img src="/2019/04/19/Automatic-Text-Input-Generation-for-Mobile-Testing/6.jpg" alt=""></p><p>考虑图5中的示例，假设测试人员执行操作以触发UI屏幕转换并输入输入值。在第一个屏幕中，测试人员点击（或点击）标有“Moive”的按钮，通向第二个屏幕，搜索栏标有“搜索”。在第三个屏幕中，测试仪在搜索栏中输入输入值“Star Trek”。<br>在用户操作模型之后，我们有两个操作：单击带有标签Movie的按钮，然后在搜索栏中输入带有标签Search的“Star Trek”。因此，记录的序列是“Moive”，“search”，“star Trek”。 </p><h2 id="B-训练阶段"><a href="#B-训练阶段" class="headerlink" title="B.训练阶段"></a>B.训练阶段</h2><p>不失一般性，我们假设每个标签δ或输入值v是单个单词，而不是短语。第VI节介绍了一种确保假设的简单预处理。</p><p>设Vocabulary V =L∪Val表示训练数据集中出现的所有标签和输入值的列表。在下文中，除非另有说明，否则我们不区分标签和输入值。相反，我们用一般术语词来引用它们。</p><p>为了实现学习，我们提出了每个单词的以下向量表示。给定单词ω，其矢量形式ω‘具有与词汇相同的大小。并且向量的每个条目被定义为，</p><p><img src="/2019/04/19/Automatic-Text-Input-Generation-for-Mobile-Testing/7.jpg" alt=""></p><p>因为只有一个条目可以取值1，所以向量表示也被称为单热表示。考虑图4.在步骤2，输入向量为[0,1,0,0]，如输入层所示。</p><p>在每个步骤，RNN模型接受单词的向量表示作为输入。输入以及隐藏层的先前状态（也被编码为矢量）用于预测输出，该概率矢量表征序列中接下来出现的每个单词的概率。训练的目标是更新RNN模型的参数，使得下一个词的预测概率分布接近从数据集观察到的真实概率分布。</p><p>我们将训练正式化为优化问题：</p><p><img src="/2019/04/19/Automatic-Text-Input-Generation-for-Mobile-Testing/8.jpg" alt=""></p><p>给定上下文δα~0~，δα~1~，….，δa~n~，我们找到具有最大条件概率的输入值vα~n~= x。在训练阶段，我们建立一个RNN模型来预测条件概率。自动计算模型的内部参数，以使预测的概率分布近似于从训练数据集中观察到的真实概率分布。然后，在假设上下文与文本框的输入值之间的概率关联没有显着改变的情况下，将训练的模型用于预测。我们在网站上解释了有关形式化的更多细节[4]。</p><h2 id="C-预测阶段"><a href="#C-预测阶段" class="headerlink" title="C.预测阶段"></a>C.预测阶段</h2><p>训练模型后，可以将其用于预测。通常，RNN模型接受一系列单词作为输入，并输出概率向量，该概率向量表征词汇表中的每个单词紧接在序列之后出现的概率（我们称之为下一个单词）。概率分布的采样将选择具有分布中描述的概率的单词。</p><p>在我们的问题设置中，当Monkey遇到文本框时，它会将动作历史记录和文本框的标签序列化为序列，然后将序列发送到训练模型以预测下一个单词的概率分布。最后，它对概率分布进行采样以获得下一个单词的值。</p><p>通常，词汇表中的任何单词都可以是下一个单词。词汇表中的单词可以对应于动作标签，文本框标签或文本输入值，但我们只对预测文本输入值感兴趣。如果采样结果不表示文本输入值（即，它不属于文本输入值的词汇表），我们将其丢弃并重新对分布进行采样。</p><p>对概率分布进行采样的想法如下。令o’ 表示RNN模型的输出向量，其表征概率分布。我们首先将0到1之间的范围分成| o ‘|间隔。区间i（0 ≤ i &lt;| o ‘|）从<img src="/2019/04/19/Automatic-Text-Input-Generation-for-Mobile-Testing/9.jpg" alt="">开始并以<img src="/2019/04/19/Automatic-Text-Input-Generation-for-Mobile-Testing/10.jpg" alt="">结束。均匀随机变量X~U（0,1）落入具有概率o’ [i]的区间，即区间的长度。换句话说，均匀随机变量X落入区间i的概率与我们选择单词＃ -  V [i]的概率相同。因此，如果随机变量落入区间i，我们返回单词V’ [i]。</p><p>请考虑以下示例。假设输出概率向量为[0.1,0.7,0.1,0.1]，如图4所示。图6显示了四个间隔。假设均匀随机变量的值为0.5，则它落入区间1（注意区间为0）。因此，我们返回单词V’ [1]，即单词“are”。</p><p><img src="/2019/04/19/Automatic-Text-Input-Generation-for-Mobile-Testing/11.jpg" alt=""></p><h2 id="D-独立于应用程序的输入生成"><a href="#D-独立于应用程序的输入生成" class="headerlink" title="D.独立于应用程序的输入生成"></a>D.独立于应用程序的输入生成</h2><p>我们的最终目标是预测我们尚未接受过训练的应用程序的输入。主要挑战是使输入生成应用独立。</p><p>我们的想法是，如果我们遇到一个在训练阶段没有看到的单词，我们可以将它连接到在训练阶段看到的一些类似的单词，利用Word2Vec。我们使用预先使用非常大的Google新闻语料库训练的Word2Vec模型。当遇到不在词汇表中的单词时，例如，在训练期间没有出现在任何应用程序中的文本框标签时，我们的系统会查询Word2Vec以查找词汇表中最相似的单词（更确切地说，词汇表动作标签和文本框标签）。如果可以从两个单词的矢量表示计算的相似度低于预设阈值0.7，则我们认为该单词在训练数据集中没有对应物并且在预测期间简单地忽略它。在最坏的情况下，如果这个词在确定文本输入值时很重要，那么我们的技术就会降低到传统的Monkey测试。这些情况的发生主要是因为应用程序属于一个与我们训练过的应用程序类型非常不同的新类别。</p><h1 id="V-实现"><a href="#V-实现" class="headerlink" title="V.实现"></a>V.实现</h1><p>我们在第II节中介绍了系统设计的概述。在本节中，我们将解释图1中所示的每个组件的实现细节。</p><p><strong>a）Monkey测试引擎</strong>：我们的monkey在探索动作序列时采用深度优先搜索策略，即在填充当前屏幕中所有文本框元素的值之后逐个点击可用按钮。可以以随机顺序或以某种顺序（例如，按钮标签的字母顺序）单击同一屏幕内的按钮。我们实现了两个选项并在我们的实验中采用了随机顺序。另外，为了避免重复探索同一个屏幕，我们构建了每个屏幕的签名，其中包括屏幕标题和屏幕中按钮的标签。具有相同签名的屏幕被视为同一屏幕，仅被探索一次。</p><p>请注意，除文本输入外，我们的系统还可以轻松扩展以预测下一步操作。然而，我们认为这会不利地限制Monkey实现良好覆盖的能力，因为它往往会跟随人类测试者的动作序列，这些动作序列是有限的。因此，我们系统的一个重要设计原则是使用随机探索动作和RNN预测文本输入。</p><p>我们使用Xcode IDE附带的测试自动化框架XCTest实现了iOS Monkey。该框架提供了一组API [9]，允许我们在屏幕中找到按钮或文本框元素。例如，我们可以使用以下API调用轻松找到当前屏幕中的所有按钮：</p><p>descendantsMatchingType（.Button）</p><p><strong>b）文本输入服务器</strong>：使用python web框架Bottle [2]实现的文本输入服务器是一个隐藏了如何生成输入的详细信息的抽象层。由于它是用Python实现的，而Monkey测试引擎是在Swift中实现的，因此两个组件之间存在编程语言障碍。为了打破障碍，他们通过以JSON格式发送HTTP消息来相互通信。输入服务器通过函数调用与RNN实例通信，因为它们都是用Python实现的。此外，我们为输入服务器维护了一个数据库，用于存储人类测试人员在某些上下文中输入的输入。我们采用了MongoDB [7]。输入服务器使用Python驱动程序PyMongo [10]与数据库交互。</p><p><strong>c）RNN实例</strong>：我们在Python深度学习框架Tensorflow [13]之上构建了RNN模型，它提供了高级API，同时隐藏了许多低级细节。通过Tensorflow的抽象，可以使用仅40行代码构建RNN模型，如我们的网站[3]所示。我们通过首先使用Word2Vec预处理数据集然后将它们输入RNN模型来训练模型。此外，经过训练的RNN模型可以保存到磁盘上并随时加载以供进一步使用。</p><h1 id="VI-讨论"><a href="#VI-讨论" class="headerlink" title="VI.讨论"></a>VI.讨论</h1><p>在本节中，我们将讨论我们在这项工作中所做的假设。<br>我们在训练/预测中做出的假设是标签或输入值是单个单词，而不是短语或句子。如果标签确实是一个短语，我们将其分解为单词并将每个单词视为单独的标签上下文。通过在单词级别推理，只要其中的单词属于我们的词汇表，我们的方法就可以处理任何短语。相反，对于作为短语的文本输入值，我们将短语视为原子单位，以便在整个训练和预测期间不对它们进行分区。</p><p>我们的方法的另一个重要假设是我们训练Monkey的应用程序和Monkey将测试的应用程序应该分享一些相似性，例如，它们属于App市场上的相同类别。否则，如果我们在娱乐应用程序上训练Monkey并将其应用于测试Tax应用程序，那么预测的文本输入将毫无意义。为了避免这种情况，我们收集尽可能多的不同类型的应用程序，并将它们用作训练主题。</p><p>在我们的方法中，我们假设上下文仅包含文本标签。在真实世界的应用程序中，开发人员可能会使用图标而不是文本标签。我们目前不支持非文字标签。我们注意到我们的方法可以扩展到支持非文本标签，例如，利用image2text工具[14]。</p><p>当我们记录动作序列时，我们维护一个列表并将每个动作附加到列表中。但是，如果我们遇到撤消上一个操作的操作，我们会放弃操作并从列表中删除上一个操作;如果我们遇到导致应用程序主屏幕的操作，我们只需清除列表即可。最后，我们的工作补充了自动行动序列生成的大量最新进展[28]，[24]，[27]。虽然我们期待很大的协同作用，但我们将把它留给我们未来的工作。</p><h1 id="七-评估"><a href="#七-评估" class="headerlink" title="七.评估"></a>七.评估</h1><p>在我们的实验中，我们对以下研究问题感兴趣：</p><ul><li>与其他用于移动测试的自动输入生成方法相比，我们的自动化方法的效果如何？</li><li>与仅使用RNN模型相比，Word2Vec是否允许更好的结果？</li><li>我们的工具产生的性能开销是多少？</li></ul><p>为了解决第一个问题，我们与自动随机输入生成方法进行比较，该方法从常用输入值池中随机选择[30]输入值。</p><p>我们通过计算屏幕覆盖率来测量有效性，即，在固定时间窗口内已经探索了多少不同的UI屏幕。通常采用monkey测试来探索尽可能多的用例。但是，识别独特的用例需要领域知识。相反，我们使用屏幕覆盖来客观地估计用例覆盖范围。</p><p>请注意，屏幕覆盖范围与功能测试中的经典覆盖标准（例如，语句覆盖率和路径覆盖率）不同。我们认为两者都很重要。特别是，我们的方法补充了功能测试，因为通过提供有意义的输入值，我们的技术允许Monkey访问有趣的UI屏幕。从这样的UI屏幕开始，可以应用现有的功能测试工作来暴露应用程序崩溃。此外，我们认为一些UI屏幕很有趣，即使它们与任何应用程序崩溃都不对应。我们将读者引用到我们的网站[5]以获取此类示例。</p><p>请注意，我们的方法与自动事件序列生成方法正交。在这项工作中，我们采用现有的深度优先搜索策略。我们的贡献主要在于根据上下文生成相关的文本输入，并容忍在不同的应用程序中使用不同的单词。</p><p>为了解决第二个研究问题，我们比较了仅启用RNN的版本以及启用了RNN和Word2Vec的版本。第VII-B节通过将三个版本比较在一起来解决上述两个问题。</p><p>最后，性能开销很重要，特别是考虑到在Monkey测试期间交互式预测。理想情况下，该方法应该以低性能开销实现有效性。性能的测量见第VII-A节。</p><p>  a）实验设置：我们在OS X EI Capitan的MacBook Pro上进行实验。 iOS应用程序在iPhone 6S Plus（iOS 9.2）的模拟器中运行。我们从Github收集了200个开源iOS应用程序，主要来自https：//github.com/dkhamsing/open-source-ios-apps。它们分为不同的类别，包括电影，新闻，图像，浏览器，旅行，广播，日历，天气和任务。它们包括流行的应用程序，如Firefox和维基百科。我们对150个应用程序进行了训练，并测试了其余50个应用程序的预测功能。</p><p>我们的训练数据集共包含14061个单词。当我们收集训练数据集时，我们尝试尽可能多地重用输入值。例如，当我们需要在不同的应用程序中输入电影名称时，我们会坚持使用相同的电影名称。</p><h2 id="A-性能开销"><a href="#A-性能开销" class="headerlink" title="A.性能开销"></a>A.性能开销</h2><p>学习/训练过程需要多次迭代。我们用于预测的模型训练了6个小时，但我们在更短的时间内测量了性能。我们测量每1000次迭代的计算时间并报告迭代的平均时间。我们还使用每1000次迭代后生成的模型，使用数据集中的随机序列预测下一个单词。这是为了抽样模型的准确性。我们还测量RNN模型用于训练和预测的时间。如图7所示，除初始步骤外，训练/预测时间保持不变。这是因为每次迭代处理固定数量的数据，并且神经网络结构不会动态变化。另一个重要的观察是每个预测平均需要0.7毫秒，与测试中的其他操作相比可以忽略不计（例如，输入文本）</p><p><img src="/2019/04/19/Automatic-Text-Input-Generation-for-Mobile-Testing/12.jpg" alt=""></p><p>我们还测量了Word2Vec模型的加载时间以及每个查询类似单词的时间。加载大约需要54秒，而每次查询大约需要0.7毫秒。由于空间限制，我们不显示数字。加载时间很长，因为模型很大，在Google新闻语料库中训练有30亿个运行单词。<br>我们的文本输入服务器通过在服务器初始化期间加载模型来解决此问题。加载后，该模型可用于所有传入的查询。</p><h2 id="B-我们方法的有效性"><a href="#B-我们方法的有效性" class="headerlink" title="B.我们方法的有效性"></a>B.我们方法的有效性</h2><p>为了衡量有效性，我们比较了三个版本：（1）随机，随机从常用输入值池中选取一个值。请注意，随机版本忽略了上下文信息。 （2）RNN，其应用RNN预测模型并因此知道上下文信息，（3）RNN + Word2Vec，其启用RNN预测和Word2Vec模型。</p><p>我们计算在5分钟内不同版本探索的屏幕数量。对于每个版本，我们重复实验三次并报告最大数量。图8中报告了50个应用程序的结果。RNN版本检测到的屏幕比随机版本多21.1％，而RNN + Word2Vec版本检测到的屏幕比随机版本多28.6％。由于有许多应用程序具有简单的功能，因此屏幕数量较少，因此这三个版本可以为这些应用程序探索相同数量的屏幕。通过排除这些情况，我们观察到RNN版本优于随机版本46％，而RNN + Word2Vec版本优于60％。请注意，RNN版本与RNN + Word2Vec版本之间的差异突出了使用Word2Vec的有效性。</p><p><img src="/2019/04/19/Automatic-Text-Input-Generation-for-Mobile-Testing/13.jpg" alt=""></p><p>我们手动检查详细结果并进行一些有趣的观察。首先，这三个版本为27个应用程序产生相同的结果。原因是这些应用程序要么不需要任何用户输入，要么使用任何类型的输入值。例如，在PropertyFinder中，即使Monkey在搜索栏中输入了无意义的输入值，该值也不会导致匹配，该应用程序仍会检索并显示待售房地产属性的列表。在另一个应用程序聊天中，该应用程序用于接收/发送消息，无论消息是什么，它都可以正常工作。</p><p>其次，我们观察到RNN版本可以探索随机版本无法探索的许多UI屏幕。直观地，当文本框需要特殊格式或特殊含义的输入值时，RNN版本知道上下文并根据从训练数据集中学习的经验产生适当的输入值。相比之下，无视上下文的随机版本通常会产生不符合特殊要求的输入值。例如，在sip-calculator应用程序中，有一个标签为“amount”的文本框，这意味着它需要一些数字输入（即，app将对输入数字执行一些算术运算）。使用我们的RNN模型的monkey知道上下文信息并且已经知道上下文与数字输入值强烈相关。结果，Monkey输入数字输入值并进入新屏幕。相反，随机版本不会产生任何数字输入，因此无法继续。</p><p>在极端情况下，AlzPrevent应用程序（即研究实验室的调查应用程序）要求用户在进行调查之前填写注册表。 AlzPrevent有10个用于注册过程的屏幕，包括用户名，身高，体重和其他一些信息。随机版本卡在第一页，而我们的RNN版本（以及RNN + Word2Vec版本）知道如何填写输入值，因为它已经过多个需要注册的应用程序的训练。因此，我们的RNN版本优于随机版本112％，RNN + Word2Vec版本优于212％。</p><p>第三，当上下文与受过训练的应用程序中的上下文略有不同时，我们发现RNN + Word2Vec版本的性能优于RNN版本。使用Word2Vec模型，该版本识别来自不同应用程序的上下文之间的语义相似性。基于相似性信息，版本基于与来自训练的应用的上下文相关联的知识来预测相关输入值。对RNN模型的改进表明了组合RNN模型和Word2Vec模型的重要性和有效性。</p><p>   我们还在第VII-C节中介绍了案例研究，以展示我们技术的优势。</p><h2 id="C-案例研究"><a href="#C-案例研究" class="headerlink" title="C.案例研究"></a>C.案例研究</h2><p><img src="/2019/04/19/Automatic-Text-Input-Generation-for-Mobile-Testing/14.jpg" alt=""></p><p><strong>a）Firefox</strong>：第一个案例来自官方的Firefox iOS应用程序。这个案例说明了生成相关输入值的重要性，并说明了我们的方法如何产生它们。如图9所示，在屏幕1上，缺少主页按钮（默认情况下），因此无法测试与按钮相关的功能。要显示主页按钮，必须点击设置按钮更改设置。但是，屏幕2上的输入值需要有效的网页URL。否则主页按钮不会显示。我们的Monkey可以根据其标签“输入网页”和操作历史设置→主页（屏幕2）预测文本框的有效URL，从而启用主页按钮，如屏幕3所示。</p><p>随机版本忽略了文本框中的“输入网页”标签，产生随机输入值“New York”。 Firefox应用程序不接受输入，因此不启用“主页”按钮。事实上，Firefox不会在其数据库中记录无效输入。在Monkey导航到另一个屏幕然后返回之后，Random版本输入的输入值将丢失。通过在训练数据集中手动搜索预测的网页URL，我们可以识别出一些有趣的连接。该网址由网络抓取工具应用使用，并与应用中的“网站”标签相关联。我们的方法首先基于Word2Vec识别“网站”和“网页”（屏幕2）之间的相似性，然后基于RNN模型预测最可能的输入值。此示例演示了我们的技术在探索新UI屏幕方面的有效性，即使这两个应用程序具有不同的用例或业务逻辑。</p><p><strong>b）第三方Github应用程序</strong>：图10显示了Github的第三方应用程序的案例。在这种情况下，我们的工具点击搜索菜单项（屏幕1），然后选择存储库类别（屏幕2）。它还成功预测了搜索栏的输入值Java，这导致了一些匹配的存储库返回的进一步进展（屏幕3）。我们的工具进一步单击每个存储库，从而发现异常。</p><p>如图11所示，异常发生在第116行。通过使用Swift语言[15]中的感叹号，开发人员假定变量repoDescription（即存储库的描述）不能为零（即，没有值）。但是，在实践中，某些存储库没有任何描述，这打破了开发人员的假设。因此，移动应用程序在尝试解包可选值为nil时崩溃。</p><p><img src="/2019/04/19/Automatic-Text-Input-Generation-for-Mobile-Testing/15.jpg" alt=""></p><p>相比之下，随机版本产生的输入值Benjamin Franklin在当前环境中是不合适的。因此，此版本无法找到上述错误。这个案例清楚地表明了我们工具的用处。</p><p><strong>c）Frameless</strong>：Frameless是一款采用极简主义UI设计的全屏网页浏览器。</p><p><img src="/2019/04/19/Automatic-Text-Input-Generation-for-Mobile-Testing/16.jpg" alt=""></p><p><img src="/2019/04/19/Automatic-Text-Input-Generation-for-Mobile-Testing/17.jpg" alt=""></p><p>我们的工具发现了类似于Github应用程序中发现的bug的错误，如图12所示。查找错误需要Monkey测试才能生成有效的输入。考虑图13，在第一个屏幕中，搜索栏显示网站URL或搜索。鉴于这样的背景，我们的工具基于从训练数据集学习的统计相关性在第二屏幕中产生有效的网站。移动应用程序然后转换到第三个屏幕。通过单击登录按钮，我们的工具暴露了图12中所示的异常。通过检查代码，我们发现单击登录按钮会导致内部执行一些错误修复代码，遗憾的是错误处理了URL的内容。在这种情况下，上下文由四个单词组成，所有单词都被发送到RNN模型以在搜索栏中产生有效输入。相比之下，Random版本没有生成有效的URL，因此无法找到上述错误。</p><h1 id="八-相关工作"><a href="#八-相关工作" class="headerlink" title="八.相关工作"></a>八.相关工作</h1><p>我们的工作与Android应用程序的自动测试生成密切相关。 Monkey [8]和Dynodroid [28]是基于随机探索的UI事件生成工具。 GUIRipper [18]（MobiGUITAR [19]），ORBIT [37]，A3E [21]，SwiftHand [23]和PUMA [25]为UI构建有限状态模型并生成事件以系统地探索模型中的状态。 Contest [20]基于一种复杂的执行方法生成事件，并通过检查事件序列之间的条件来修剪搜索空间。 Ermuth和Pradel [24]介绍了宏事件，它总结了单个步骤的低级UI事件的重复序列。通过将宏事件与随机测试相结合，它们利用记录的用户交互序列并自动生成新测试。与我们的方法相比，大多数自动化测试生成工作侧重于生成事件序列（或动作序列）。</p><p>除了事件和意图之外，生成测试输入值也很重要，因为只有满足输入值的谓词才能暴露某些行为。还应用了基于符号执行和进化算法的技术。 JPF-Android [36]扩展了Java PathFinder（JPF），是一个模型检查工具，用于探索所有路径并识别运行时故障。 EvoDroid [29]基于进化算法框架生成测试（包括事件和输入）。它使用随机方法生成输入。 Sapienz [30]是一款基于多目标搜索的Android应用测试工具。它结合了随机模糊测试，系统和基于搜索的探索，利用种子和多级插桩。虽然它可以提供字符串作为测试输入，但是这些字符串是通过逆向工程APK从应用程序中提取的，并随机播种到文本字段中。随机选择的输入在特定上下文中不太可能相关。 Afshan等 [17]应用基于n-gram语言模型的引导搜索来产生可读字符串输入而不是随机字符序列。但是，该方法不是为在用例上下文中生成字符串输入而设计的。</p><p>我们的工作还涉及基于机器学习的文本建模和生成技术。 Sutskever等人 [35]通过将大量训练的RNN应用于预测文本流中的下一个字符的任务，展示了它们的强大功能。 Melicher等 [31]提出了一种基于神经网络的方法来模拟人类选择的密码并测量其对猜测攻击的抵抗力。</p><h1 id="IX-结论"><a href="#IX-结论" class="headerlink" title="IX.结论"></a>IX.结论</h1><p>我们已经开发了一种基于深度学习的方法来自动生成移动测试的文本输入。它在上下文中生成最相关的输入值。此外，我们利用Word2Vec模型实现了独立性。对50多个iOS应用程序的评估证实了我们设计的有效性和效率。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h1&gt;&lt;p&gt;已经提出许多设计来改进自动化移动手机测试。尽管有这些改进，但提供适当的文本输入仍然是一个突出
      
    
    </summary>
    
      <category term="论文" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/"/>
    
      <category term="fuzzing" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/fuzzing/"/>
    
      <category term="机器学习" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/fuzzing/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="fuzzing" scheme="http://yama0xff.com/tags/fuzzing/"/>
    
      <category term="机器学习" scheme="http://yama0xff.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="2017年" scheme="http://yama0xff.com/tags/2017%E5%B9%B4/"/>
    
      <category term="Word2Vec" scheme="http://yama0xff.com/tags/Word2Vec/"/>
    
  </entry>
  
  <entry>
    <title>DeepFuzz: Automatic Generation of Syntax Valid C Programs for Fuzz Testing</title>
    <link href="http://yama0xff.com/2019/04/18/DeepFuzz-Automatic-Generation-of-Syntax-Valid-C-Programs-for-Fuzz-Testing/"/>
    <id>http://yama0xff.com/2019/04/18/DeepFuzz-Automatic-Generation-of-Syntax-Valid-C-Programs-for-Fuzz-Testing/</id>
    <published>2019-04-18T03:11:49.000Z</published>
    <updated>2019-04-19T03:17:49.511Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>编译器是构建软件最基本的编程工具之一。但是，生产编译器仍然存在问题。模糊测试通常用于新生成或突变输入，以便发现新的错误或安全漏洞。在本文中，我们提出了一种名为DEEPFUZZ的基于语法的模糊测试工具。基于生成的seq2seq模型，DEEPFUZZ自动且连续地生成格式良好的C程序。我们使用这组新的C程序来模糊现成的C编译器，例如GCC和Clang / LLVM。我们提供了一个详细的案例研究来分析生成的C程序的模糊测试的成功率和覆盖率改进。我们用三种采样方法和三种生成策略来分析DEEPFUZZ的性能。因此，DEEPFUZZ在行，函数和分支覆盖方面提高了测试效率。在我们的初步研究中，我们发现并报告了8个GCC漏洞，所有这些漏洞都由开发人员积极处理。</p><table><thead><tr><th>relevant information</th><th></th></tr></thead><tbody><tr><td><em>作者</em></td><td>Xiao Liu, Xiaoting Li, Rupesh Prajapati, Dinghao Wu</td></tr><tr><td><em>单位</em></td><td>College of Information Sciences and Technology<br>The Pennsylvania State University</td></tr><tr><td><em>出处</em></td><td><em>AAAI-19</em></td></tr><tr><td><em>原文地址</em></td><td><a href="https://faculty.ist.psu.edu/wu/papers/DeepFuzz.pdf" target="_blank" rel="noopener">https://faculty.ist.psu.edu/wu/papers/DeepFuzz.pdf</a></td></tr><tr><td><em>源码地址</em></td><td><a href="https://github.com/wtwofire/deepfuzz" target="_blank" rel="noopener">https://github.com/wtwofire/deepfuzz</a></td></tr><tr><td><em>发表时间</em></td><td>2019年</td></tr></tbody></table><h1 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h1><p>编译器是最重要的计算系统软件之一，它们通常是信任计算基础的一部分，但它们仍然存在问题。例如，GCC是1987年发布的一款长效软件，是许多类Unix操作系统的标准编译器。自创建以来，已经捕获了超过3,410个内部错误（Yang et al.2011）。同样，对于Java，Python和JavaScript，在那些广泛使用的编译器和解释器中发现了数千个错误。这些编译器错误可能导致意外的程序执行，并导致安全敏感应用程序的灾难性后果。当在应用程序或编译器中无法确定根本原因时，它还可能妨碍开发人员在调试程序时的工作效率。因此，提高编译器的正确性至关重要。但用不断增长的代码库验证编译器并不容易：今天的GCC代码库大约有1500万行代码（Sun et al.2016），接近整个Linux内核，大约有1900万行代码。</p><p>使编译器可靠是至关重要的。在过去十年中，编译器验证一直是计算研究中验证授权挑战的一个重要且活跃的领域（Hoare 2003）。主流研究侧重于形式验证（Leroy和Grall 2009），翻译验证（Necula 2000）和随机测试（Lidbury等人2015; Le，Afshari和Su 2014; Le，Sun和Su 2015）。前两个类别尝试提供经过认证的编译器。例如，CompCert（Leroy等人，2016）在这一领域取得了有希望的进展。但实际上，应用形式化技术来完全验证生成编译器（如GCC）是一项挑战，尤其是当证明不是与编译器一起构造时。因此，测试仍然是编译器验证的主要方法。</p><p>我们的工作重点是编译器测试。通过向不同的生产编译器提供不同功能的程序，启用不同级别的优化，可以在编译期间触发内部编译器错误（编译器的真正错误），并显示错误消息指示错误的位置和内容。但是，生成“好”程序以提高测试效率并通过自动化此过程构建连续测试框架具有挑战性。在现有方法中，每个测试（包括人工测试）都涵盖了一些功能，现在通常可以看到现代编译器越来越大的测试套件。这提高了测试覆盖率，但构建这些测试需要花费大量人力。然而，荣国模糊测试的实用方法可以减少人力。</p><p>Fuzzing（Bird和Munoz 1983）是一种发现漏洞或安全漏洞的方法。程序通过自动生成或修改的输入重复执行，以检测程序崩溃等异常行为。目前使用的输入模糊测试的主要技术是黑盒随机模糊测试（Zalewski 2015），基于白盒约束的模糊测试（Godefroid，Kiezun和Levin 2008），以及基于语法的模糊测试（Dewey，Roesch和Hardekopf 2014）。黑盒子和白盒模糊是完全自动的，并且历史证明在二进制格式文件解析器中找到安全漏洞是有效的。相反，基于语法的模糊测试需要输入语法，该输入语法指定被测应用程序的输入格式，该输入格式通常是手工编写的。这个过程费力，耗时且容易出错。然而，基于语法的模糊测试是当今已知的用于具有复杂结构化输入格式的模糊应用的最有效的模糊测试技术，例如编译器。在编译器测试的场景中，部署基于语法的模糊测试的一种方法是将C语法编码为测试用例生成的规则。但实际上，C11（国际标准化组织（ISO）2011），C编程语言的当前标准，有696页的详细规范，这为工程师构建这样一个基于语法的引擎带来了障碍。<br>在本文中，我们考虑使用生成递归神经网络自动生成语法有效输入的语法有效输入的问题。更具体地说，我们的目标是训练生成神经网络，以学习输入数据的“语法”，或者更确切地说，语言模式。我们建议在监督学习策略中训练序列到序列模型（Sutskever，Vinyals和Le 2014），利用生产编译器提供的原始测试套件。最初，序列到序列模型广泛用于机器翻译（Klein等人2017）和文本生成（Sutskever，Martens和Hinton 2011）。从理论上讲，通过训练原始段落的模型，我们隐含地将正确的单词拼写，句子的有效语法，写作行为的详细风格编码到生成模型中。同样的想法可以应用于程序综合，其中我们只需要训练模型以在种子数据集之上生成不同的语法上有效的程序。对于训练数据集，我们采用了原始的GCC测试套件，其中有超过10,000个短程序或小程序，涵盖了C11标准中规定的大多数功能。在训练阶段，我们调整参数以将C程序的语言模式编码到模型中，基于此，我们不断生成用于编译器模糊测试的新程序。<br>贡献。我们的工作是第一个使用生成递归神经网络进行基于语法的编译器模糊测试。</p><ul><li>首先，拟议的框架是全自动的。通过训练序列到序列模型，可以将其视为训练数据语言模式的隐式表示，在我们的上下文中使用C语法，我们的框架DEEPFUZZ将不断提供新的语法正确的C程序。</li><li>其次，我们构建了一个用于模糊现成的C编译器的实用工具。我们详细分析了关键因素将如何影响生成模型和模糊性能的准确性。</li><li>•第三，我们应用DEEPFUZZ技术测试GCC和Clang / LLVM。在我们的初步分析期间，测试覆盖范围（线路，功能和分支）增加，我们发现并报告了8个真实的错误。</li></ul><p>Fuzzing（Bird和Munoz 1983）是一种发现漏洞或安全漏洞的方法。程序通过自动生成或修改的输入重复执行，以检测程序崩溃等异常行为。目前使用的输入模糊测试的主要技术是黑盒随机模糊测试（Zalewski 2015），基于白盒约束的模糊测试（Godefroid，Kiezun和Levin 2008），以及基于语法的模糊测试（Dewey，Roesch和Hardekopf 2014）。黑盒子和白盒模糊是完全自动的，并且历史证明在二进制格式文件解析器中找到安全漏洞是有效的。相反，基于语法的模糊测试需要输入语法，该输入语法指定被测应用程序的输入格式，该输入格式通常是手工编写的。这个过程费力，耗时且容易出错。然而，基于语法的模糊测试是当今已知的用于具有复杂结构化输入格式的模糊应用的最有效的模糊测试技术，例如编译器。在编译器测试的场景中，部署基于语法的模糊测试的一种方法是将C语法编码为测试用例生成的规则。但实际上，C11（国际标准化组织（ISO）2011），C编程语言的当前标准，有696页的详细规范，这为工程师构建这样一个基于语法的引擎带来了障碍。</p><p>在本文中，我们考虑使用生成递归神经网络自动生成语法有效输入用于基于语法的fuzzing。更具体地说，我们的目标是训练生成神经网络，以学习输入数据的“语法”，或者更确切地说，语言模式。我们建议在监督学习策略中训练seq2seq模型（Sutskever，Vinyals和Le 2014），利用生产编译器提供的原始测试套件。最初，seq2seq模型广泛用于机器翻译（Klein等人2017）和文本生成（Sutskever，Martens和Hinton 2011）。从理论上讲，通过训练原始段落的模型，我们隐含地将正确的单词拼写，句子的有效语法，写作行为的详细风格编码到生成模型中。同样的想法可以应用于程序综合，其中我们只需要训练模型以在种子数据集之上生成不同的语法上有效的程序。对于训练数据集，我们采用了原始的GCC测试套件，其中有超过10,000个短程序或小程序，涵盖了C11标准中规定的大多数功能。在训练阶段，我们调整参数以将C程序的语言模式编码到模型中，基于此，我们不断生成用于编译器模糊测试的新程序。</p><p><strong>贡献</strong>。我们的工作是第一个使用生成递归神经网络进行基于语法的编译器模糊测试。</p><ul><li>首先，拟议的框架是全自动的。通过训练seq2seq模型，可以将其视为训练数据语言模式的隐式表示，在我们的上下文中使用C语法，我们的框架DEEPFUZZ将不断提供新的语法正确的C程序。</li><li>其次，我们构建了一个用于模糊现成的C编译器的实用工具。我们详细分析了关键因素将如何影响生成模型和模糊性能的准确性。</li><li>第三，我们应用DEEPFUZZ技术测试GCC和Clang / LLVM。在我们的初步分析期间，测试覆盖范围（行，函数和分支）增加，我们发现并报告了8个真实的错误。</li></ul><h1 id="2-概述"><a href="#2-概述" class="headerlink" title="2.概述"></a>2.概述</h1><h2 id="2-1-seq2seq模型"><a href="#2-1-seq2seq模型" class="headerlink" title="2.1 seq2seq模型"></a>2.1 seq2seq模型</h2><p>我们在seq2seq模型的基础上构建DEEPFUZZ，该模型实现了两个用于字符级序列预测的递归神经网络（RNN）。 RNN是由隐藏状态h和可选输出y组成的神经网络。它在可变长度序列上运行，x =（x~1~, x~2~……x~T~）。在每个步骤t，更新RNN的隐藏状态h~<t>~<br>$$<br>h_{<t>} = f(h_{t−1}, x_t)<br>$$<br>其中f是非线性激活函数。 RNN可以学习字符序列上的概率分布以预测下一个符号。因此，在每个时间步t，来自RNN的输出是条件分布p（x~t~ |x~t-1~……x~1~）。例如，在我们的例子中，在下一个字符的多项分布时，我们使用softmax激活函数作为输出<br>$$<br>p(x_{t,j} = 1| x_{t−1},……,x_1) = \frac{ exp(w_jh_{<t>})}<br>{\sum_{j=1}^Kexp(w_jh_{<t>})}<br>$$<br>对于所有可能的符号j = 1,……,K ，其中 w~j~ 是权重矩阵W的行。通过组合这些概率，我们计算序列x使用的概率<br>$$<br>p(x) =\prod_{t=1}^T<br>p(x_{t,j} = 1| x_{t−1},……,x_1)<br>$$<br>通过学习的分布，通过在每个时间步迭代地采样新字符来生成新序列是直截了当的。</t></t></t></t></p><p>seq2seq模型由两个RNN，编码器和解码器组成。编码器学习将可变长度序列编码为固定长度矢量表示，并且解码器将该固定长度矢量表示解码为可变长度序列。它最初是由Cho等人 （2014）提出的，用于统计机器翻译。编码器RNN读取输入序列x的每个字符，同时RNN的隐藏状态改变。在读取该序列的结束之后，RNN的隐藏状态是整个输入序列的概要c。同时，训练解码器RNN以通过预测给定隐藏状态h~<t>~的下一个字符y~t~来产生输出序列。然而，与纯RNN不同，y~t~和h~<t>~也都以y~t-1~和输入序列的摘要c为条件。在这种情况下，为了计算解码器的隐藏状态，我们有<br>$$<br>h_{<t>}= f(h_{<t-1>}, y_{t−1}, c)<br>$$<br>同样地，下一个字符的条件分布是<br>$$<br>p(y_t|y_{t−1}，……，y_1， c) = g(hti; yt−1; c);<br>$$<br>其中 f 和 g 是激活函数。总的来说，两个RNN编码器 - 解码器被联合训练以在给定输入序列的情况下生成目标序列。<br>所有RNN在循环层中都有反馈循环。</t-1></t></t></t></p><p>这种设计允许他们随着时间的推移将信息保存在“记忆”中。然而，训练标准RNN以学习长期时间依赖性可能是困难的，但这在程序中是常见的。这是因为损失函数的梯度随时间呈指数衰减（Chung et al.2014）。因此，在我们的设计中，我们采用RNN的变体，长短期记忆（LSTM），特别是在我们的编码器和解码器中。 LSTM单元包括“存储器单元”，其可以将信息长时间保存在存储器中，在这种情况下可以存储长历史信息。</p><p>在以前的研究中，seq2seq模型已经过训练，可以生成语法正确的PDF对象来模糊PDF解析器（Godefroid，Peleg和Singh 2017）。这项工作背后的核心思想是，源语言语法可以作为字符串对的训练副产品来学习。 Shi，Padhi和Knight（2016）通过实验研究了seq2seq模型可以学习关于源句的局部和全局句法信息。这项工作为RNN的正式语言合成奠定了基础。在我们的论文中，我们对编译器模糊测试应用了类似的想法。在训练期间，我们将序列分成固定大小为d的多个训练序列。通过剪切序列，我们得到第i个训练序列xi = s [i <em> d：（i + 1）</em> d]，其中s [k：l]是索引k和l之间s的子序列。每个训练序列的输出序列是下一个字符，即yt = s [（i + 1）* d + 1]。我们将此训练过程配置为学习一组训练序列的生成模型。</p><h2 id="2-2-工作流程"><a href="#2-2-工作流程" class="headerlink" title="2.2 工作流程"></a>2.2 工作流程</h2><p>一般而言，我们建议DEEPFUZZ用于两个主要目标。第一种是从一组语法正确的程序中生成遵循合法语法的新程序。主要挑战来自长序列处理和语言语法表示。第二个目标是提高编译器测试效率。我们的目标是提高覆盖率并捕获生产编译器中的更多内部错误。</p><p><img src="/2019/04/18/DeepFuzz-Automatic-Generation-of-Syntax-Valid-C-Programs-for-Fuzz-Testing/1.jpg" alt=""></p><p>图1显示了DEEPFUZZ的工作流程。整个工作流程分为两个阶段，即程序生成和编译器测试。我们的目标是生产编译器。如GCC，GNU Compiler Collection（2018）和LLVM / Clang（Clang：LLVM 2018的C语言系列前端）。在第一阶段，我们使用来自原始人工编译器测试套件的收集数据训练生成的Sequence-to-Sequence模型。在我们将序列输入训练模型之前，我们对它们进行预处理以避免噪声数据。我们稍后在预处理中详细说明预处理步骤。我们要拟合的模型是一个通用的Sequence-to-Sequence模型，它有2层，每层有512个隐藏单元。我们将模型配置与实验设置中最先进的序列生成研究进行比较。对于程序生成，我们尝试不同的生成策略。我们详细介绍了生成策略及其在生成策略中的基本原理。因为我们的目标是模糊生产编译器，所以我们的目标是生成涵盖C语言最多功能的程序。因此，我们还采用了采样变量中详述的一些采样方法，以使生成的程序多样化。</p><p>在第二阶段，我们将生成的C程序（在语法上正确或不正确）提供给不同优化级别的编译器，并记录编译消息。除了编译消息之外，我们还记录执行跟踪以提供覆盖信息。总之，对于此程序生成任务，我们有三个目标：生成语法有效程序，改进代码覆盖率以及检测新错误。我们针对评估中的三个目标，对三个相关指标，合格率，覆盖率和错误进行了研究。</p><h2 id="2-3-设计"><a href="#2-3-设计" class="headerlink" title="2.3 设计"></a>2.3 设计</h2><p>我们提出DEEPFUZZ持续性的为模糊测试生成编译器语法正确的C程序。如概述中所述，完整的工作流程包含两个阶段，即程序生成和编译器测试。在本节中，我们将介绍更多详细信息。</p><p>预处理在我们设置训练阶段之前，我们将序列分成多个固定大小的训练序列。每个训练序列的输出序列是输入序列旁边的下一个字符。我们将此训练过程配置为学习所有训练序列集的生成模型。但是，我们注意到连接序列中存在一些需要妥善处理的噪声。在预处理中，我们主要处理三个问题：注释，空格和宏。</p><ul><li><p><strong>注释</strong>。我们首先使用训练数据中正则表达式中的模式删除所有注释，包括行注释和块注释。</p></li><li><p><strong>空格</strong>。根据POSIX标准，空白字符包括公共空格，水平制表符，垂直制表符，回车符，换行符和换页符。为了统一程序样式，我们用一个空格替换了所有空白字符。</p></li><li><p><strong>宏</strong>。宏是C编程语言的常见特性。宏是一个代码片段，它已被赋予一个新名称。在我们的实现中，每当使用名称时，它总是被宏的内容替换。</p></li></ul><h2 id="2-4-采样变量"><a href="#2-4-采样变量" class="headerlink" title="2.4 采样变量"></a>2.4 采样变量</h2><p>我们使用学习的seq2seq模型来生成新的C程序。例如，利用前缀序列“int”，学习的分布很可能预测接下来是“main”。但是，我们的目标是使原始程序多样化，以生成更多生成的语句，如“int foo = 1;”或“int foo = bar（1）;”。因此，我们建议采用一些抽样方法来抽样学习的分布。我们在这里描述了我们用于生成新C程序的三种抽样方法：NoSample，Sample和SampleSpace。</p><p><strong>NoSample</strong>。在这种抽样方法中，我们直接依靠学习的分布来贪婪地预测给定前缀的最佳下一个字符。</p><p><strong>sample</strong>。为了克服NoSample方法的局限性，给定前缀序列，我们建议对下一个字符进行采样，而不是选择顶部预测的字符。</p><p><strong>SampleSpace</strong>。此采样方法是Sample和NoSample的组合。在这种方法中，当前缀序列以空格结束时，我们只对阈值中所有预测值的下一个字符进行采样。</p><h2 id="2-5-生成策略"><a href="#2-5-生成策略" class="headerlink" title="2.5 生成策略"></a>2.5 生成策略</h2><p>为了不断模糊生产编译器，我们使用学习模型生成C编程语言的新序列。我们将原始测试套件中的程序视为种子。基于原始程序中的序列作为前缀，我们将生成新代码。为了充分利用生成的序列，我们提出了三种生成策略：G1）我们将基于相同前缀序列的新生成的代码插入到原始格式良好的程序中; G2）我们生成新的代码片段，但是它们将使用从原始程序中的不同位置随机挑选的前缀序列生成，然后分别插回; G3）我们在原始程序的前缀序列之后删除相同数量的行，并将新生成的新行插入到已被删除的句子的位置。此外，可以在我们的框架内方便地建立更多的生成策略，但我们对这三种进行初步研究。</p><h1 id="3-评估"><a href="#3-评估" class="headerlink" title="3 评估"></a>3 评估</h1><h2 id="3-1实验设置"><a href="#3-1实验设置" class="headerlink" title="3.1实验设置"></a>3.1实验设置</h2><p>为了评估DEEPFUZZ，我们流程化了一个原型工作流程，该工作流程基于一组语法正确的C程序训练了一个seq2seq模型。最初，收集了包含10,000个格式良好的C程序的训练数据集，并从GCC测试套件中采样。我们训练了具有2层的序列到序列模型，每层有512个LSTM单元。我们将dropout rate 设定为0.2。我们已经发布了源代码。</p><p>在先前关于文本生成的研究中（Sutskever，Martens和Hinton 2011），研究人员训练了一个具有超过100 MB训练数据的单层RNN，并且在这个单层模型中有1,500个隐藏单元。对于最接近的相关工作，Learn＆Fuzz（Godefroid，Peleg和Singh 2017）采用生成的序列到序列模型为PDF解析器模糊测试生成新的PDF对象，研究人员训练了一个具有两层的模型，并在每个层中，有128个隐藏单位。他们在包含534个格式良好的PDF文件的数据集上训练了这个模型。在我们的研究中，我们训练了一个两层模型，其中DEEPFUZZ框架的每一层都有512个LSTM单元。训练数据集包含从生产编译器测试套件中采样的10,000个语法正确的C程序，比以前的任何研究都要大。</p><p>我们在监督设置中训练了序列到序列模型。为了分析训练表现，我们训练了由通过次数或迭代参数化的多个模型。迭代被定义为学习算法的迭代，以遍历整套训练数据。我们在具有2.90GHz Intel Xeon（R）E5-2690 CPU和128GB内存的服务器机器上训练了50次迭代的模型。我们在五个不同数量的时期保留了模型的快照：10,20,30,40和50。训练一个迭代花了大约30分钟，整个训练阶段花了25个小时。对于新程序生成，如设计中所述，我们使用不同的采样方法和各种生成策略来生成新的C程序。新生成的程序仍然基于原始训练数据;换句话说，我们使用原始的C程序作为种子，我们从中随机选择前缀序列。通过插入新行或用新行替换行到种子中，我们可以获得新程序。由于新生成的部分将引入新的标识符，新的分支，新的功能等，它将使新生成的程序的控制流更复杂，从而提高测试效率。<br>在我们的研究中，我们使用三个指标来衡量DEEPFUZZ的有效性：</p><ul><li><strong>通过率</strong>是衡量所有新生成的C程序中语法有效程序的比率的度量。序列到序列模型可能会将C语言模式编码到神经网络中。因此，通过率将是该网络在输入序列上的训练程度的良好指标。我们使用gcc的命令行来解析新生成的程序，如果没有报告错误，则表示该程序的语法正确性。</li><li><strong>覆盖率</strong>是测试的特定度量。直观地说，测试涵盖的代码越多，我们就越确定测试的完整性。我们在分析过程中收集了三种覆盖信息：行覆盖范围，函数覆盖范围和分支覆盖范围。我们使用gcc支持的命令行工具gcov来收集覆盖信息。</li><li>错误检测是测试的目标。对于编译器测试，通过向不同优化级别的编译器提供更多程序，预计会触发崩溃或其他代码错误等错误。作为一种自我保护机制，像GCC和Clang / LLVM这样的编译器定义了一种称为“内部编译器错误”的特殊错误。此错误表示编译过程中编译器本身的问题，错误消息将帮助我们找到编译器中的错误。</li></ul><h2 id="3-2-通过率"><a href="#3-2-通过率" class="headerlink" title="3.2 通过率"></a>3.2 通过率</h2><p>通过率是生成的语法有效程序与整个新生成程序集的比率。它是在所提出的序列到序列模型中C语言模式的编码程度的指标。在我们的评估中，具体而言，我们将分析通过率如何随着训练时期的数量，不同的采样方法和不同的生成策略而变化。</p><p><strong>迭代</strong>迭代被定义为学习算法的迭代，以遍历整套训练数据。我们对模型进行了总共50个迭代的训练，我们在不同的时期拍摄了模型的快照：10,20,30,40,50，并将模型应用于新的C程序生成。我们在生成策略G1下尝试了所有三种抽样方法的过程。</p><p>结果：图2显示了结果。</p><ul><li>通过率随着训练的迭代次数从10到30个增加而增加。 30个迭代周期后的合格率下降可能是过度拟合的结果。</li><li>所有采样方法的最佳通过率均在30个迭代周期的训练中实现。最高合格率为82.63％。</li></ul><p><strong>采样</strong>。训练模型后，我们采用了不同的采样方法。正如我们所提出的，采样方法决定了如何根据预测的分布选择新字符，它可以影响合格率。因此，我们根据种子程序在不同的采样方法下记录了新生成的10,000个程序的通过率：NoSample，Sample和SampleSpace。</p><p><img src="/2019/04/18/DeepFuzz-Automatic-Generation-of-Syntax-Valid-C-Programs-for-Fuzz-Testing/2.jpg" alt=""></p><p>结果：图2显示了结果。注意，该实验在生成策略G1下进行。</p><ul><li>对于所有采样方法，通过率在训练的30个迭代周期内增加，之后，有一个小的下降。</li><li>比较所有三种采样方法的通过率，NoSample为每个快照模型实现了比其他两种方法Sample和SampleSpace更好的通过率。最高合格率为82.63％。</li></ul><p><strong>生成策略</strong>。为了生成新程序，我们引入了三代策略：G1）在一个位置插入两行，G2）在不同位置插入两行，并且G3）替换两条新行。新生成的行基于种子程序中选择的前缀序列。为了分析通过率如何随着不同的生成策略而变化，我们记录了在30个迭代之后使用训练模型执行程序生成的结果。另外，我们在这个实验中使用了NoSample。</p><p>结果：表1显示了结果。</p><p><img src="/2019/04/18/DeepFuzz-Automatic-Generation-of-Syntax-Valid-C-Programs-for-Fuzz-Testing/3.jpg" alt=""></p><ul><li><p>三个生成策略的合格率分别为82.63％，79.86％和73.23％。比较这三种不同生成策略下的通过率，我们得出结论，在NoSample下，G1在通过率方面表现最佳。</p></li><li><p>G1和G2的结果在通过率方面相似，高于G3的通过率。原因可能是，删除行会引入不平衡的语句，例如未闭括号，括号或大括号。</p></li></ul><h2 id="3-3-覆盖率"><a href="#3-3-覆盖率" class="headerlink" title="3.3 覆盖率"></a>3.3 覆盖率</h2><p>除了通过率之外，如本节开头所述，由于我们正在进行测试，因此覆盖率信息是另一个重要指标。在这一部分中，我们分析了如何通过不同的采样方法和生成策略实现覆盖率改进（行，函数，分支）。</p><p><strong>采样</strong>。为了比较覆盖范围的改进，我们记录了覆盖率信息，包括原始种子测试套件（10,000）覆盖了多少行，函数和分支以及GCC-5和Clang-3新生成的测试套件（10,000） 。此外，为了分析抽样方法如何影响覆盖率的改善，我们记录了不同抽样方法下的覆盖率改善百分比。</p><p>结果：覆盖改进信息如表2所示，其中包含来自GEP-5的DEEPFUZZ的10,000个新生成的C程序的增强测试套件，并且比较指标，我们也在图3中显示。</p><p><img src="/2019/04/18/DeepFuzz-Automatic-Generation-of-Syntax-Valid-C-Programs-for-Fuzz-Testing/4.jpg" alt=""></p><p><img src="/2019/04/18/DeepFuzz-Automatic-Generation-of-Syntax-Valid-C-Programs-for-Fuzz-Testing/5.jpg" alt=""></p><ul><li>在三种不同的采样方法中，Sample在行，函数和分支覆盖改进方面实现了最佳性能。例如，在生成策略G2下，NoSample，Sample和SampleSpace的线覆盖率改善分别为5.41％，7.76％和7.14％。</li><li>不同采样方法的不同生成策略的覆盖率改善模式相似。G2总是最好的，G1在三者中总是最差的。换句话说，抽样方法的表现与生成策略略有关联。</li></ul><p><strong>生成策略</strong>。除了抽样方法，我们还对如何在不同的生成策略下改进这三种不同的覆盖范围感兴趣。</p><p>结果：图3显示了使用G1，G2和G3如何改善覆盖范围。</p><ul><li>比较三种不同发电策略下的覆盖范围改进，G2，即在不同位置插入两条新线路，在大多数情况下，在行，函数和分支覆盖范围改进方面实现了最佳性能。</li><li>与采样方法相比，采用生成策略是提高覆盖率的一个更有影响力的因素。例如，在SampleSpace下，三种生成策略的函数覆盖率改善百分比分别为0.17％，2.44％和1.72％。从G1变为G2后，覆盖率提高了42倍。</li><li>G2和G3在覆盖率改善方面表现相似，远高于G1。</li></ul><p><strong>总体</strong>。为了演示我们的工具如何在编译器模糊测试中执行，我们将DEEPFUZZ与用于编译器测试的精心设计的实用工具进行了比较。 Csmith（Yang et al.2011）是一个可以生成随机C程序的工具。为了进行公平的比较，我们记录了Csmith和DEEPFUZZ的覆盖范围改进，通过增加GCC和LLVM测试套件以及表3中的10,000个生成程序。</p><p>请注意，我们在进行此分析时使用Sample作为采样方法，使用G2作为我们的生成策略。我们还记录了图4中程序生成过程中的覆盖率改进。它演示了随着新测试数量的增加，行，函数和分支覆盖范围如何得到改善。</p><p><img src="/2019/04/18/DeepFuzz-Automatic-Generation-of-Syntax-Valid-C-Programs-for-Fuzz-Testing/6.jpg" alt=""></p><p>结果：</p><ul><li>对于所有案例，Csmith将覆盖率提高了不到1％，而DEEPFUZZ分别将行，函数和分支的覆盖率提高了7.14％，2.44％和3.21％。 DEEPFUZZ实现了比Csmith更好的覆盖率改善。</li><li>DEEPFUZZ的覆盖率改善模式的性能与GCC-5和Clang-3相似。</li></ul><p><img src="/2019/04/18/DeepFuzz-Automatic-Generation-of-Syntax-Valid-C-Programs-for-Fuzz-Testing/7.jpg" alt=""></p><h2 id="3-4新错误"><a href="#3-4新错误" class="headerlink" title="3.4新错误"></a>3.4新错误</h2><p>使用不同的生成策略和抽样方法，基于GCC测试套件中的种子程序，我们可以生成新程序。因为我们的目标是编译器模糊，所以检测到的错误数量是DEEPFUZZ功效的重要指标。在我们的初步研究中，我们发现了8个新确认的GCC错误，我们将详细说明我们检测到的两个错误。</p><p><strong>GCC错误84290</strong>：这是我们报告的错误。 DEEP FUZZ生成两个新行（第5行和第6行），它们触发内置函数原子载荷n的内部编译器错误。触发错误是因为此函数的第一个参数应该是指针，但它指向不完整的类型。此错误已修复，并且新测试（atomic-pr81231.c）已添加到GCC中的最新测试套件中。  这个检测到的错误显示了使用语法良好但语义无意义的测试进行编译器测试的重要性。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">double</span> <span class="title">f</span> <span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">double</span> r;</span><br><span class="line"><span class="keyword">asm</span> (<span class="string">"mov %S1,%S0; mov %R1,%R0"</span> : <span class="string">"=r"</span> (r) : <span class="string">"i"</span> (<span class="number">20</span>));</span><br><span class="line"><span class="keyword">asm</span> (<span class="string">"mov %S1,%S0; mov %R1,%R0"</span> : <span class="string">"+r"</span> (r) : <span class="string">"i"</span> (<span class="number">20.</span>));</span><br><span class="line"><span class="function">atomic load <span class="title">n</span> <span class="params">((<span class="keyword">enum</span> E ∗) <span class="number">0</span>, <span class="number">0</span>)</span></span>;</span><br><span class="line">;</span><br><span class="line"><span class="keyword">return</span> r;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>GCC Bug 85443</strong>：这是我们报告的错误。 DEEPFUZZ生成两条新行（第5行和第6行），引入了新的崩溃。生成的Atomic是用于定义原子类型的关键字，第6行的赋值触发了分段错误。这是GCC-5上新确认的错误，已在最新版本中修复。这个由DEEPFUZZ检测到的错误再次显示了使用语法上格式良好但语义无意义的测试进行编译器测试的重要性。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">char</span> acDummy[<span class="number">0xf0</span>] attribute (( BELOW100 ));</span><br><span class="line"><span class="function"><span class="keyword">unsigned</span> <span class="keyword">short</span> B100 <span class="title">attribute</span> <span class="params">(( BELOW100 ))</span></span>;</span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">short</span> ∗p = &amp;B100;</span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">short</span> wData = <span class="number">0x1234</span>;</span><br><span class="line">Atomic <span class="keyword">int</span> i = <span class="number">3</span>;</span><br><span class="line"><span class="keyword">int</span> a1 = <span class="keyword">sizeof</span> (i + <span class="number">1</span>);</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Do</span> <span class="params">(<span class="keyword">void</span>)</span> f</span></span><br><span class="line"><span class="function">B100 </span>= wData;</span><br><span class="line">g</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span> <span class="params">(<span class="keyword">void</span>)</span> f</span></span><br><span class="line">∗p = 0x9876;</span><br><span class="line">Do ();</span><br><span class="line"><span class="keyword">return</span> (∗p == <span class="number">0x1234</span>) ? <span class="number">0</span> : <span class="number">1</span>;</span><br><span class="line">g</span><br></pre></td></tr></table></figure><h1 id="4-限制"><a href="#4-限制" class="headerlink" title="4 限制"></a>4 限制</h1><p>观察生成的程序，我们注意到许多不正常的生成是由预期的表达式引起的。更具体地说，此错误消息表示错误，如不平衡的括号，括号或大括号。我们总结了导致这一问题的两个主要原因：缺乏训练和全局信息丢失。</p><p>由于第一个原因，训练数据很丰富，但在当前训练数据集中仍然缺乏足够的重复模式来训练良好的生成模型。在我们未来的工作中，我们可以通过枚举原始测试套件中具有新变量或函数名称的所有结构来创建更大的训练数据集。另一方面，因为生成基于前缀序列，所以它将丢失一些超出前缀序列范围的全局信息。为了解决这个问题，我们要么增加训练序列的长度以确保捕获足够的信息，要么我们可以使用一些启发式方法来帮助进行模型训练。前一种方法可能导致生成的程序中的多样性较少，后一种方法需要静态程序分析的帮助。</p><p>另外，我们提出的方法基于字符级序列到序列模型。我们为当前模型提供了一系列字符，这需要在处理令牌级语法时付出很多努力。它也会损害培训的可扩展性和通过率。在C中，少于32个关键字和100多个内置函数。如果我们通过Sequenceto-Sequence模型执行令牌级序列预测，则通过率和可伸缩性都将增加。</p><h1 id="5-相关工作"><a href="#5-相关工作" class="headerlink" title="5 相关工作"></a>5 相关工作</h1><p>多年来，人们广泛讨论了基于AI的软件安全和软件分析应用程序（Zamir，Stern和Kalech 2014; Elmishali，Stern和Kalech 2016; Nath和Domingos 2016）。基于神经网络的模型在各种应用中占主导地位，并且使用它们进行程序分析（Allamanis和Sutton 2013; Nguyen等人2013）和合成（Lin等人2017; Devlin等人2017年）的兴趣大幅增长。 ）。循环神经网络，尤其是基于序列到序列的模型，已经开发用于从大型代码语料库中学习源代码的语言模型，然后将这些模型用于多种应用，例如学习自然编码约定，代码建议，自动完成和修复语法错误（ Bhatia和Singh 2016; Hindle等人，2012）。事实证明，在提供大量数据时，提高系统效率以及节省人力是有效的。此外，基于RNN的模型适用于基于语法的模糊测试（Godefroid，Peleg和Singh 2017; Cummins等。2018）学习生成模型以生成PDF文件以模糊PDF解析器。</p><h1 id="6-结论和未来工作"><a href="#6-结论和未来工作" class="headerlink" title="6 结论和未来工作"></a>6 结论和未来工作</h1><p>编译器测试对于确保计算系统的正确性至关重要。在本文中，我们提出了一种基于语法的自动模糊测试工具，称为DEEPFUZZ，它学习生成的递归神经网络，不断生成语法正确的C程序，以模糊现成的生产编译器。 DEEPFUZZ生成了82.63％语法有效的C程序，并提高了行，函数和分支覆盖的测试效率。我们还发现了开发人员正在积极解决的新漏洞。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h1&gt;&lt;p&gt;编译器是构建软件最基本的编程工具之一。但是，生产编译器仍然存在问题。模糊测试通常用于新生成或
      
    
    </summary>
    
      <category term="论文" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/"/>
    
      <category term="fuzzing" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/fuzzing/"/>
    
      <category term="机器学习" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/fuzzing/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="fuzzing" scheme="http://yama0xff.com/tags/fuzzing/"/>
    
      <category term="机器学习" scheme="http://yama0xff.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Neural Fuzzing: A Neural Approach to Generate Test Data for File Format Fuzzing</title>
    <link href="http://yama0xff.com/2019/04/17/Neural-Fuzzing-A-Neural-Approach-to-Generate-Test-Data-for-File-Format-Fuzzing/"/>
    <id>http://yama0xff.com/2019/04/17/Neural-Fuzzing-A-Neural-Approach-to-Generate-Test-Data-for-File-Format-Fuzzing/</id>
    <published>2019-04-17T08:53:14.000Z</published>
    <updated>2019-04-18T01:51:22.849Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>本文旨在设计和实现文件格式模糊器。文件是大多数实际应用程序的重要输入。将输入文件生成为测试数据的实质难点在于重新调整文件的基础结构和格式。为了区分存储在文件中的纯数据和描述文件格式的元数据，本文提出了一种基于神经语言模型的深度学习方法。得到的学习模型可以作为混合测试数据生成器应用，以生成和模糊输入文件的文本和非文本部分。此外，该模型可以应用于生成测试数据以模糊元数据和存储在文件中的普通数据。我们使用两个已知的模糊测试工具AFL和Learn＆Fuzz进行的实验证明了我们提出的方法的代码覆盖率相对较高。实验还表明，简单的神经语言模型提供了比复杂的编码器 - 解码器模型更准确的学习模型。</p><table><thead><tr><th>relevant information</th><th></th></tr></thead><tbody><tr><td><em>作者</em></td><td>Morteza Zakeri Nasrabadi, Saeed Parsa, Akram Kalaee</td></tr><tr><td><em>单位</em></td><td>Iran University of Science and Technology, Tehran, Iran.</td></tr><tr><td><em>出处</em></td><td>arXiv</td></tr><tr><td><em>原文地址</em></td><td><a href="https://arxiv.org/abs/1812.09961" target="_blank" rel="noopener">https://arxiv.org/abs/1812.09961</a></td></tr><tr><td><em>源码地址</em></td><td><a href="https://github.com/m-zakeri/iust_deep_fuzz" target="_blank" rel="noopener">https://github.com/m-zakeri/iust_deep_fuzz</a></td></tr><tr><td><em>发表时间</em></td><td>2018</td></tr></tbody></table><h1 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h1><p>Fuzzing [1,2,3,4]是一种动态软件测试技术，用于检测程序中的故障和漏洞。为此目的，只要程序崩溃，或者观察到意外行为，就会生成测试数据集并将其注入到被测软件（SUT）中。在软件处理格式错误和不受信任的文件（包括Web浏览器，便携式文档格式（PDF）阅读器和多媒体播放器[5,6]）的情况下，文件格式模糊测试具有重要意义。</p><p>与文件格式模糊器有关的主要挑战是将测试数据生成为文件，覆盖SUT的执行路径。要为处理文件程序作为主要输入的模糊测试生成测试数据，模糊器需要知道文件格式。事实上，在没有文件格式的先验知识的情况下，大多数生成的测试数据可能在运行SUT后很快被拒绝，这可能导致代码覆盖率低[7]。手动提取文件格式是解决此问题的常用解决方案。然而，这种解决方案昂贵且耗时，并且总是需要可能不可用的文件格式规范。因此，文件格式的自动检测一直是测试数据生成方法的重点[8,9]。</p><p>与文件格式的自动检测有关的主要困境是区分用于定义格式的元数据（例如用于定义格式的标签和参数）与存储在文件中的纯数据。除了格式良好的测试数据外，还要对程序进行模糊处理，还需要格式错误的数据。畸形数据应保存在输入文件中的适当位置，以便揭示相应SUT的缺陷[9]。</p><p>通常，诸如MuPDF [10]之类的程序在解析和渲染的两个不同阶段处理给定的PDF文件[11] [12,7]。解析器检查格式，同时将检查的格式复制到主存储器中的某些数据结构中。在呈现阶段，处理加载的数据。例如，向用户显示文件的内容。因此，观察到文件格式模糊器应该在解析和呈现阶段模糊SUT。因此，模糊器应该能够区分数据和保存在文件中的元数据以确定其格式。</p><p>实现相对较高的代码覆盖率存在巨大挑战。例如，AFL [13]是一种众所周知的基于变异的文件格式模糊器，它采用进化方法，旨在生成具有最大代码覆盖率的测试数据。 AFL改变随机选择的文件群以实现文件，覆盖尚未观察到的新路径。<br>然而，据观察，对于大量执行路径，AFL在合理的时间内不能满足可接受的代码覆盖率，并且它不适合具有复杂输入结构的模糊程序[14]。一种有前景的方法是使用学习技术来模糊测试数据生成。为此，Learn＆Fuzz [8]作为基于生成的文件格式模糊器，采用seq2seq[15,16]方法，以将输入文件的结构学习为生成模型。然后使用生成模型生成文件作为输入测试数据。</p><p>最初，seq2seq旨在映射不同域的两个序列[15]。但是，学习文件的结构不是映射问题，可以使用更简单的模型来完成。在Learn＆Fuzz [8]中，只学习文本数据，而复杂的文件格式包含文本和非文本数据。此外，在Learn＆Fuzz中，生成数据始终以固定前缀obj开头，导致测试数据种类繁多，最后，所提出的模糊算法（称为SampleFuzz [8]）可能不会在所有执行中终止。</p><p>在本文中，为了缓解上述挑战，我们提出了一种新的测试数据生成方法，应用于文件格式的模糊器。我们的方法通过使用基于深度递归神经网络（RNN）的神经语言模型（NLM）而不是seq2seq模型来学习复杂输入文件的结构。引入了两个新的模糊算法来模糊输入文件的文本和二进制部分，每个部分都针对文件执行过程的一个阶段。我们还设计并实现了IUST DeepFuzz，这是一种新的模块化文件格式模糊器，可进行模糊测试。 IUST DeepFuzz可以学习任何复杂的文件格式并全自动生成新的测试数据。总之，我们的主要贡献如下：</p><ul><li>我们引入了混合测试数据生成方法，利用基于突变和基于生成的方案。 </li><li>我们设计并实现了一种新的文件格式模糊器IUST DeepFuzz。</li><li>我们提供了一个新的数据集，IUST PDF Corpus，用于训练和测试描述PDF文件格式的模型。</li><li>我们应用NLM来学习具有长依赖性的复杂文件格式的结构。</li></ul><p>通过学习PDF文件格式[11]来评估所提出的方法，然后使用结果格式生成PDF文件作为测试数据来模糊开源PDF查看器MuPDF [10]。我们的评估结果表明，相比较先进的文件格式模糊器，代码覆盖率相对较高[8,13]。此外，在本文中，我们表明NLM优于学习和模糊序列，以及关于学习文件格式准确性的序列模型。</p><p>本文的其余部分安排如下。在第2节中，我们简要介绍语言模型（LM）和RNN作为我们提出的方法中使用的基本概念。在第3节中，我们描述了我们提出的用于学习文件结构，生成和模糊新测试数据的方法。第4节涉及各种实验和评估，通过将我们的方法与现有方法进行比较而提供。相关的工作在第5节中讨论。最后，在第6节中，我们总结了我们提出的方法，并讨论了一些关于模糊测试的未来工作。</p><h1 id="2-语言模型和递归神经网络"><a href="#2-语言模型和递归神经网络" class="headerlink" title="2.语言模型和递归神经网络"></a>2.语言模型和递归神经网络</h1><p>我们已经应用语言模型来学习文件的结构作为符号序列。语言模型是NLP中的基本概念，它允许预测序列中的下一个符号[17]。更确切地说，LM是在一系列单词/符号上的概率分布，其识别给定序列的概率。通过使用LM，我们可以在一些现有的序列中选择更可能的序列。序列的LM为x = &lt;x^（1）^…… x^（n）^&gt;定义如下[18]：</p><p><img src="/2019/04/17/Neural-Fuzzing-A-Neural-Approach-to-Generate-Test-Data-for-File-Format-Fuzzing/1.jpg" alt=""></p><p>在等式1中，每个单独的项p（x^（t）^| x ^&lt;t^）指示给定先前符号x ^&lt;t^的当前符号x^（t）^的条件概率，也称为上下文。在实践中，以等式1的形式计算该概率几乎是不可能的，因为我们需要查看所有可能的序列。为了克服计算挑战，传统的n-gram LM仅考虑基于某种马尔可夫假设的n-1个单词的固定上下文窗口。虽然很有希望，但在许多情况下，这些模型不适用于长序列（超过4或5个符号）或看不见的序列[18]。</p><p>为了解决n-gram问题，可以使用一系列深度神经网络，即用于构建LM的递归神经网络，这被称为神经语言模型[19]。 NLM可以扩展到更长的上下文而不会遇到零概率问题。 RNN用于处理顺序数据。它以一系列时间步长处理输入序列，并更新其内存以产生隐藏状态h（i）。图1显示了一个带有一个隐藏层的简单RNN。在每个时间步t中，处理输入序列的一个矢量。 RNN的前馈方程定义为方程2至5 [20]：</p><p><img src="/2019/04/17/Neural-Fuzzing-A-Neural-Approach-to-Generate-Test-Data-for-File-Format-Fuzzing/2.jpg" alt=""></p><p><img src="/2019/04/17/Neural-Fuzzing-A-Neural-Approach-to-Generate-Test-Data-for-File-Format-Fuzzing/4.jpg" alt=""></p><p><img src="/2019/04/17/Neural-Fuzzing-A-Neural-Approach-to-Generate-Test-Data-for-File-Format-Fuzzing/3.jpg" alt=""></p><p>其中b和c是偏置矢量，矩阵U，V和W分别是在网络训练期间学习的输入 - 隐藏，隐藏 - 输出和隐藏 - 隐藏连接的权重。通过定义损失（目标）函数并使用优化方法来最小化它来实现学习。 σ是一种激活函数，如sigmoid。 softmax函数应用于输出层，以将网络输出转换为有效的概率分布。</p><p>LM作为生成模型，在一系列符号上提供概率分布。通过从这样的分布中采样，可以生成新的序列。在我们提出的方法中，每个文件都被视为一个字节序列，从文件的语言派生而来。然后，我们将为每种文件格式构建相应的语言模型。</p><h1 id="3-神经模糊测试"><a href="#3-神经模糊测试" class="headerlink" title="3.神经模糊测试"></a>3.神经模糊测试</h1><p>我们提出的测试数据生成方法包括三个主要步骤。首先，收集一些样本数据，即输入文件，并对它们进行预处理。其次，在提供的训练集上训练语言模型。第三，通过学习模型生成和模糊测试数据。生成测试数据后，我们就可以对任何给定目标进行模糊测试。图2显示了我们提出的方法的流程图，将在以下部分中进行更详细的讨论。</p><p><img src="/2019/04/17/Neural-Fuzzing-A-Neural-Approach-to-Generate-Test-Data-for-File-Format-Fuzzing/5.jpg" alt=""></p><h2 id="3-1-概述"><a href="#3-1-概述" class="headerlink" title="3.1.概述"></a>3.1.概述</h2><p>如图2所示，在开始时（步骤1），我们以我们想要学习的格式收集大量样本文件，例如HTML或PDF文件。然后，每个样本文件中的二进制（非ASCII）部分被替换为唯一令牌，称为二进制令牌（BT）。例如，我们用令牌流替换PDF文件中的所有流。通过使用这种简单的策略，我们可以仅使用一组ASCII序列训练LM。这样的模型可能在生成阶段预测BT，因此我们可以用突变的二进制部分替换BT，其先前由基于突变的方法生成。当然，我们需要保留原始二进制元素以用于未来的突变和替换。这样，与忽略二进制部分[8]的当前方法不同，我们可以同时生成测试数据的二进制和文本部分。</p><p>在预处理阶段，我们还在每个文件的末尾添加一个结束标记（ET），指示已处理文件的完整性。然后，我们将所有文件连接在一起并构建大量文件。该序列用于训练LM，但在训练之前，我们将其分为三个独立的集合，如训练集，测试集和验证集。需要这样的划分来测量对看不见的数据的模型准确性和困惑度。它也有助于我们生成新数据（参见第3.3节）。某些文件格式明确具有ET。例如，HTML文件以令牌&lt;/ html&gt;结束。在这种情况下，不需要添加额外的令牌。现在，我们可以定义我们的模型并在提供的数据集上训练它们（步骤2）。</p><p>最后，我们的两个新引入的模糊算法用于生成和模糊新的测试数据，称为DataNeuralFuzz和MetadataNeuralFuzz（步骤3）。前者用于模糊测试数据中的数据，后者用于模糊文件的格式。</p><p>为了研究模型复杂性在学习文件结构中的作用以及使用结果结构生成测试数据，我们构建了四个具有不同超参数的模型和基于RNN的体系结构，如表1所示。乍一看，它似乎模型越复杂，描述所需文件格式的语言模型就越准确。但是，我们的实验表明，情况并非总是如此。我们使用不同复杂性模型得到的语言模型应用实验表明，相比之下，更简单的模型导致语言模型可以达到相对较高的代码覆盖率。</p><p>表1中列出的每个模型使用长短期记忆（LSTM）单元[21]作为可以学习长序列输入的RNN单元。前三个模型是单向多对一LSTM [22]，其架构类似于图1.这些模型是不同的w.r.t.每个图层中隐藏图层和单位的大小会影响每个模型的训练参数数量。最后一个模型（模型4）是双向LSTM。双向LSTM以后向和前向顺序访问输入序列。双向LSTM由两个单向LSTM组成。其中一个处理输入序列从左到右，另一个从右到左处理。结果，每个前向传递具有两个输出。需要合并功能来组合这些输出并生成单个输出。我们选择使用sum函数，它按元素添加两个输出向量。</p><p><img src="/2019/04/17/Neural-Fuzzing-A-Neural-Approach-to-Generate-Test-Data-for-File-Format-Fuzzing/6.jpg" alt=""></p><h2 id="3-2-训练模型"><a href="#3-2-训练模型" class="headerlink" title="3.2.训练模型"></a>3.2.训练模型</h2><p>表1中显示的所有模型的训练过程是相同的。神经网络以监督模式进行训练;也就是说，网络的每个输入都需要输出标签。为了训练每个模型，我们需要指定相应的深度神经网络的输入和输出。我们将训练集序列S分成具有固定长度d的多个较小子序列，使得第i个子序列xi将是：</p><p><img src="/2019/04/17/Neural-Fuzzing-A-Neural-Approach-to-Generate-Test-Data-for-File-Format-Fuzzing/7.jpg" alt=""></p><p>其中S [l：u]是索引l和u之间S的子序列，j是跳跃步骤，表示从原始序列S中选择下一个子序列的前向跳转; xi是模型的输入序列。每个输入序列xi的相应输出或换句话说标签定义为：</p><p><img src="/2019/04/17/Neural-Fuzzing-A-Neural-Approach-to-Generate-Test-Data-for-File-Format-Fuzzing/8.jpg" alt=""></p><p>实际上，输出是输入序列的下一个符号。在生成所有输入序列及其相应的输出符号之后，可以训练模型。在训练期间，模型学习条件概率p(x^(i+d+1)^ | &lt; x^(i)^，……， x^(i+d)^ &gt;) 这将最终使它能够预测给定子序列xi的下一个符号x^（i+d+1）^的出现。</p><p><img src="/2019/04/17/Neural-Fuzzing-A-Neural-Approach-to-Generate-Test-Data-for-File-Format-Fuzzing/9.jpg" alt=""></p><p>图3显示了上述示例HTML文件的训练方法的示例。前三个训练序列及其对网络的呈现如图所示。参数d和j分别设置为3和1。在实践中，d可以设置为大数，即40或甚至100，这使得可以学习长依赖性。</p><h2 id="3-3-生成新的测试数据"><a href="#3-3-生成新的测试数据" class="headerlink" title="3.3.生成新的测试数据"></a>3.3.生成新的测试数据</h2><p>训练过程完成后，我们可以使用学习的模型生成新数据。为此，我们首先从测试集序列中随机选择长度为d的前缀P，并将其提供给模型。该模型将下一个符号的预测作为所有符号的有效分布。然后，选择符号形式的该分布，并将其扩展到P的末尾。接下来，去除P的第一个符号，而P的长度为d。现在，我们使用更新的前缀查询模型并生成下一个符号。此过程将继续，直到生成结束令牌ET。</p><p>从输出分布中选择一个符号有很多策略。<br>一个简单的策略是贪婪地选择具有最高概率的符号。这样的策略导致格式良好的文件。但是，生成的测试数据总是限于前缀的数量，即测试集的大小。另一种常见策略是将预测分布作为多项分布进行采样。采样可以产生各种测试数据，但并不能保证它们都是格式良好的。因此，我们需要一种机制来控制采样期间生成的测试数据的多样性。</p><p>在[8]中，作者引入了SampleSpace，它结合了贪婪选择和采样，但该方法有点复杂，并不是生成新测试数据的明确方法。他们的纯采样策略产生了更好的结果。我们在采样策略中引入了超参数，多样性。分集D是区间（0， 1）中的实数。在生成阶段，模型预测值除以分集，D。应用softmax函数后，进行抽样。结果，较低多样性导致采样策略关闭贪婪策略并产生较少的各种但格式良好的测试数据。另一方面，更高的多样性使得采样策略远离贪婪策略并创建更多种不同但形成错误的测试数据。</p><h2 id="3-4-模糊测试数据"><a href="#3-4-模糊测试数据" class="headerlink" title="3.4.模糊测试数据"></a>3.4.模糊测试数据</h2><p>当我们使用表1中的模型和上一节中概述的采样策略生成测试数据时，生成的数据将存在固有的变化，因此这些数据可用作测试数据。然而，学习文件结构和模糊它是光谱的两端。学习希望捕获格式良好的文件的结构，并生成可以通过文件解析器的文件，而模糊测试打算破坏文件结构，希望使程序执行失败。在本节中，我们介绍了神经模糊算法，目的是在前两个目标和文件格式模糊测试的最终生成测试数据之间建立权衡。我们的算法扩展和改进了SampleFuzz算法[8]。正如我们所提到的，文件由数据和元数据的两部分组成，每个部分都在一个单独的阶段中处理。我们引入了两个名为DataNeuralFuzz的算法，用于模糊数据，针对渲染阶段，MetadataNeuralFuzz用于模糊元数据，针对解析阶段。</p><p>DataNeuralFuzz显示在算法1中，MetadataNeuralFuzz显示在算法2中。两种算法都将学习模型M，序列前缀P，分集D，模糊率FR，结束标记ET，二进制标记BT作为输入，并作为输出返回测试数据T D.每个算法都有一个主循环，一直持续到没有生成ET。在while循环内，M用D采样。然后在算法中不同的某些条件下修改（模糊）预测符号。退出while循环后，算法检查T D是否包含BT。如果它包括BT，则BT被实际二进制部分替换，该实际二进制部分在基于突变的方法中被模糊化，例如随机地。请记住，在将二进制部件与原始数据集分离时，我们已经存储了它们。最后，算法返回T D.</p><p><img src="/2019/04/17/Neural-Fuzzing-A-Neural-Approach-to-Generate-Test-Data-for-File-Format-Fuzzing/10.jpg" alt=""></p><p><img src="/2019/04/17/Neural-Fuzzing-A-Neural-Approach-to-Generate-Test-Data-for-File-Format-Fuzzing/11.jpg" alt=""></p><p>这两种算法的主要特征之一是与SampleFuzz不同，它们总是终止。在每个算法进入其while循环之前，将具有最小值a和最大值b的随机整数设置为T D的最大长度MaxLen变量。如果ET不是由模型产生并且T D的长度大于MaxLen，则在while循环中生成T D期间，然后通过算法将ET添加到T D的末尾，并且while循环将断开。 a和b的值应由测试者确定。一个好的做法是将它们设置在数据集文件的平均长度附近。</p><h3 id="3-4-1-DataNeuralFuzz"><a href="#3-4-1-DataNeuralFuzz" class="headerlink" title="3.4.1. DataNeuralFuzz"></a>3.4.1. DataNeuralFuzz</h3><p>DataNeuralFuzz算法旨在模糊存储在文件中的数据。存储在不同文件中的数据最明显的特性是其多样性。因此，观察到学习模型预测存储数据的概率低于描述文件格式的元数据。这意味着包含纯数据的位置中的模型预测向量比包含元数据的位置更平滑。使用存储在预测矢量中的概率的这种特性，可以确定数据的类型，如纯数据或元数据。为了确定数据类型，如纯数据或元数据，我们将通过实验获得的阈值α设置为边界线。如果符号c的概率，即p（c）小于α，则c被认为是纯数据。 DataNeuralFuzz用c’替换纯数据项c，其中c‘具有最低似然性，条件是：</p><ol><li>符号c的概率p（c）小于给定阈值α。</li><li>符号c既不属于BT也不属于ET。</li><li>测试仪给出的模糊率FR高于随机数p_fuzz，它是由i.i.d.3随机生成器生成的。</li></ol><p>模糊率FR表示在测试数据生成期间要模糊的数据百分比。例如，如果FR设置为0.1，则算法只会对10％的数据进行模糊测试。此外，我们不愿意模糊关键令牌，即BT和ET，因为这些令牌被插入到文件中以分别处理文件的二进制部分和结尾。这就是为什么确保纯数据项c不属于BT和ET的原因。</p><p> 纯数据的另一个方面是它看起来像长度大于1的标记。我们的DataNeuralFuzz算法旨在通过更改令牌的一个或多个符号来模糊纯数据令牌。建议[23,6]使用最高可能值更改数据令牌，具体取决于令牌的类型。  在实验上，模糊测试的最佳实践是用其边界值替换数据标记。例如，使用999…… 9而不是整数数据是个好主意。通常，众所周知，用作输入数据的边界值可能导致SUT执行的呈现阶段中的崩溃。</p><p> 学习的模型可用于生成任何文件，作为模糊SUT的输入。为此，将一个文件（作为固定长度的输入字符串）提供给模型，模型生成下一个符号。下一次输入字符串向前移动一个符号，这次输入字符串将包括新生成的符号。将得到的字符串再次馈送到学习模型以生成第二符号。只要创建了足够的符号并构建了新的输入文件，就会重复此过程。为了提高生成的输入文件的有效性，每次学习模型生成新符号时，只要保持上述三个条件，我们就在使用符号之前对符号进行模糊处理。每次模型决定通过将此符号添加到下一个前缀来模糊数据令牌的第一个符号时，我们让模型保持模糊预测状态。下一次学习模型想要预测符号时，其预测将受到模糊符号的影响，这可能导致另一个格式错误的符号。我们称这种机制为“将模糊传播到前缀”。</p><h3 id="3-4-2-MetadataNeuralFuzz"><a href="#3-4-2-MetadataNeuralFuzz" class="headerlink" title="3.4.2. MetadataNeuralFuzz"></a>3.4.2. MetadataNeuralFuzz</h3><p>如上所述，我们的fuzzing算法由两个不同的部分DataNeuralFuzz和MetadataNeuralFuzz组成，分别用于生成和模糊生成文件的纯数据和格式/元数据。实际上，生成的文件进一步格式错误，以实现使SUT执行崩溃的更高概率。 MetadataNeuralFuzz尝试使SUT的文件格式解析器崩溃。为了避免被SUT解析阶段中使用的异常处理机制所困，MetadataNeuralFuzz尝试：</p><ol><li>应用学习的模型，描述文件的适当结构，以生成新文件，以测试SUT。</li><li>使用测试人员给出的特定百分比来模糊描述文件格式的一些符号。</li></ol><p>MetadataNeuralFuzz算法旨在模糊文件格式，同时尽可能保留整个文件结构。通过这种方式，MetadataNeuralFuzz可以检查解析器对无效或格式错误的文件格式的健壮性。学习模型本身对元数据和纯数据没有任何假设。它只是在生成文件时预测下一个符号出现的概率。 MetadataNeuralFuzz在生成元数据时对其进行模糊处理。为了区分元数据和纯数据，MetadataNeuralFuzz使用在训练步骤中获得的符号频率。通常，元数据比语料库中的纯数据重复得多。据观察，学习模型比纯数据更高概率地预测元数据，非常接近于1。如果预测符号c的概率大于给定阈值β，则算法猜测符号c可能属于文件格式并用最低发生概率的符号替换它。为了控制模糊符号的百分比，使用模糊率FR。 MetadataNeuralFuzz模糊元数据，假设随机生成的数字p模糊小于由测试者给出的预定模糊测试速率FR。</p><p>MetadataNeuralFuzz将ET和BT视为模糊测试，因为这些标记是格式的一部分。当由学习模型生成的符号被模糊时，它仅存储在目标文件中，并且不影响学习模型对下一个符号的预测。以这种方式，确保模糊符号不传播到下一个前缀（MetadataNeuralFuzz算法的第10行）。两个算法MetadataNeuralFuzz和DataNeuralFuzz之间的差异在MetadataNeuralFuzz算法中突出显示，算法2中显示了该算法。</p><h2 id="3-5实现"><a href="#3-5实现" class="headerlink" title="3.5实现"></a>3.5实现</h2><p>为了实现深度NLM，我们使用了一个高级深度学习库Keras [24]。 Keras包含一组高级API，用于构建用Python编写的深度学习模型，并需要一个低级运行时后端来执行深度学习代码。我们决定使用TensorFlow [25]，一个用于机器学习任务的Google框架，作为Keras的后端。我们使用交叉熵作为目标函数，<code>Adam</code> [26]将学习率1×10^-4^和1×10^-3^作为训练过程中的优化算法。我们还应用了<code>Dropout</code>[27]技术来防止我们的模型过度拟合。</p><p>本文的目的是提供一种自动生成测试数据的方法。但是，单独测试数据生成还不足以进行模糊测试。<br>为了评估提出的方法，我们需要一个文件格式模糊器。模糊器将测试数据注入SUT并检查意外结果，例如使SUT的存储器崩溃。我们设计并实现了IUST DeepFuzz作为模块化文件格式模糊器。 IUST DeepFuzz使用<code></code>Microsoft Application Verifier<code>[28]，一个免费的运行时监控工具，作为监控模块来捕获任何内存损坏。它还使用微软的另一个工具</code>VSPerfMon` [29]来测量代码覆盖率。</p><p>IUST DeepFuzz的主要模块是一个测试数据生成器，它实现了我们的神经模糊算法。这些模块使用适当的Python和批处理脚本连接。以上配置中的IUST DeepFuzz可以在Windows操作系统上运行。要在其他操作系统上使用它，我们需要更换监视工具，即Application Verifier [28]。测试数据生成器是用Python编写的，可以在任何平台上运行。代码覆盖率测量模块仅用于评估目的，我们的模糊测试不需要它。 IUST DeepFuzz是一款带有混合测试数据生成器的黑盒子模糊器[1]。每个生成的测试数据在注入SUT之前存储在磁盘上，因此如果Application Verifier报告崩溃，则可以检索导致该崩溃的测试数据以进行故障本地化过程。图4显示了IUST DeepFuzz的体系结构和数据流。</p><p><img src="/2019/04/17/Neural-Fuzzing-A-Neural-Approach-to-Generate-Test-Data-for-File-Format-Fuzzing/12.jpg" alt=""></p><h1 id="4-实验和评估"><a href="#4-实验和评估" class="headerlink" title="4.实验和评估"></a>4.实验和评估</h1><p>在本节中，我们将介绍使用IUST DeepFuzz进行实验的结果。我们使用IUST DeepFuzz来模糊MuPDF [10]，这是一个免费的开源PDF，XPS和电子书阅读器，它将复杂的PDF文件[11]作为输入进行处理。 PDF是一种复杂的文件格式。 Adobe PDF规范[11]中描述了PDF文件的完整规范。同样，简要介绍[8]中指定的PDF文件的基本部分。 PDF文件的主要部分是表示文件的所有功能和方面的数据对象。按照[8]中提出的方法，我们在PDF对象集上训练我们的模型，然后生成新的PDF文件到模糊MuPDF查看器[10]。</p><p>我们还实现了Learn＆Fuzz方法[8]并在MuPDF查看器[10]上进行了评估，因为Edge PDF解析器和Learn＆Fuzz的其他材料包括数据集和模型超参数，并未公开提供。通过这种方式，我们能够在我们提出的方法和提到的方法之间进行有意义的比较，作为该领域最相关的工作。</p><h2 id="4-1-评估指标"><a href="#4-1-评估指标" class="headerlink" title="4.1.评估指标"></a>4.1.评估指标</h2><p>模糊测试的主要目的是在SUT中查找与代码覆盖率有关的故障和漏洞。学习文件结构的主要目标是生成与模型精度相关的格式良好的文件。根据这些事实，我们在实验中考虑以下指标来衡量我们提出的方法的有效性。</p><ol><li><strong>模型准确度和误差</strong>：这些指标基于Keras [24]在训练每个模型时报告的目标函数。精度和误差是根据验证集数据计算的，验证集数据是从预处理阶段的数据集中导出的。</li><li><strong>模型困惑度</strong>：困惑度是评估LM的最常见指标，它被定义为[30]：</li></ol><p><img src="/2019/04/17/Neural-Fuzzing-A-Neural-Approach-to-Generate-Test-Data-for-File-Format-Fuzzing/13.jpg" alt=""></p><p>在等式8中，x是具有长度n的序列以评估困惑度。困惑表明预测序列和测试集序列之间的差异。因此，较低的困惑意味着更好的LM。对于每个模型，我们在训练期间计算验证集的困惑度。我们使用困惑来评估所提出的模型在捕获输入文件的结构方面的优异性以及比较不同的建议NLM。</p><ol start="3"><li><strong>代码覆盖</strong>：对于每个测试数据执行，基本块覆盖由VSPerfMon工具[29]测量。基本块覆盖是语句覆盖的扩展，其中每个非分支语句序列被视为一个语句单元。基本块覆盖的主要优点是它可以低开销应用于目标代码。测试集的总覆盖范围是各个覆盖范围的并集。 VSPerfMon还报告行覆盖率，这与高级代码的语句覆盖率相同。</li><li><strong>故障和漏洞</strong>：对于每个测试数据执行，Application Verifier [28]创建一个日志文件。然后，我们使用简单的脚本搜索这些日志文件，以查找任何错误或安全警告。</li></ol><p>前两个指标确定了学习文件格式的有效性，接下来的两个指标衡量了模糊测试的质量和实用性。 </p><h2 id="4-2-实验设置"><a href="#4-2-实验设置" class="headerlink" title="4.2.实验设置"></a>4.2.实验设置</h2><p>表1中的训练模型是在具有单个Nvidia GTX 1080 GPU，Intel Core i7 CPU和20 GB RAM的物理ubuntu 16.04机器上进行的。模糊测试在具有Intel Core i7 CPU和8 GB RAM的虚拟Windows 10计算机上完成。我们在进行实验时使用了最终版本的MuPDF查看器[10]，即版本MuPDF 2017-04-114。</p><p><img src="/2019/04/17/Neural-Fuzzing-A-Neural-Approach-to-Generate-Test-Data-for-File-Format-Fuzzing/14.jpg" alt=""></p><p>在我们生成测试数据之前，我们应该训练我们的模型。表2显示了我们模型的关键超参数以及每个模型的时期数和训练时间。模型的复杂性，即训练参数的数量，随着模型的ID而增加。对于更复杂的模型，获得更多训练样本是合理的。因此，在模型3和4中，我们减少跳跃步骤，这导致增加训练样本。在模型3中，我们使用Dropout [27]和p = 0.3进行正则化。</p><h2 id="4-3-数据集和主机文件"><a href="#4-3-数据集和主机文件" class="headerlink" title="4.3.数据集和主机文件"></a>4.3.数据集和主机文件</h2><p>深度神经网络的成功训练需要大量且足够的数据集。因此，我们从各种来源收集了大量PDF文件，包括Mozilla PDF.js开放测试语料库[31]，AFL [13]中使用的一些PDF作为初始种子，以及从不同语言的公共网络收集的PDF。 最后，我们发布了IUST PDF Corpus超过6000个PDF文件。此类语料库之前未公开发布，也可用于其他类型的PDF操作和测试。</p><p>为了学习PDF对象的统计结构，我们从IUST PDF Corpus提取了500000的个对象。这些对象中约有27％具有二进制流。我们用二进制令牌流替换二进制流，提取并将它们存储到单独的数据集中，并在我们的训练过程中包含修改后的对象。与[8]的一个关键区别是我们在提取对象之前没有应用种子最小化，因为我们想要学习文件的结构，更多的数据可能会改善学习。整个提取的PDF数据对象集可在IUST PDF Corpus中找到。</p><p>由于我们只学习和生成PDF对象，因此我们需要一种机制来创建完整的PDF文件。按照[8]中提出的方法，我们决定将新生成的对象附加到现有的格式良好的PDF文件中，称为host。PDF文件可以按照PDF参考指南[11]中的说明逐步更新。新对象附加到现有PDF的末尾，其偏移量将添加到交叉引用表中。此方法允许用户更新PDF文件而无需重写整个文件。实际上，新对象重写现有对象的内容，该对象由ID标识并且绝对是旧标识。有关增量更新的更多详细信息，请参见[11]。</p><p>下一步是选择主机文件。在[8]提出的工作中，这几乎是随机的，只从他们的语料库中选择最小的三个PDF文件。<br>针对这项工作，为了研究主机复杂性对代码覆盖率的影响，我们首先通过运行MuPDF计算语料库中所有PDF文件的代码覆盖率，然后选择具有最大，最小和平均代码的三个文件覆盖范围分别为host1_max，host2_min和host3_avg。</p><h2 id="4-4-代码覆盖的基线"><a href="#4-4-代码覆盖的基线" class="headerlink" title="4.4.代码覆盖的基线"></a>4.4.代码覆盖的基线</h2><p>为了将新生成的PDF文件的代码覆盖率与现有的PDF文件进行比较，我们首先测量了每个主机的MuPDF [10]代码覆盖率，然后构建了1 000个PDF文件，其中包含从测试集中随机选择的对象。这些对象以两种不同的模式附加到主机文件：</p><ol><li>单个对象更新（SOU）：查找主机文件中的最后一个对象ID，并用新对象重写它。在此模式下，每个文件中只会更改一个对象。</li><li>多个对象更新（MOU）：重写每个PDF文件中对象的固定部分。首先，在此模式中，计算主机中的总对象数，然后新对象将覆盖随机选择的对象ID列表。</li></ol><p><img src="/2019/04/17/Neural-Fuzzing-A-Neural-Approach-to-Generate-Test-Data-for-File-Format-Fuzzing/15.jpg" alt=""></p><p>表3显示了每个主机中的对象数以及MOU模式下重写对象的部分。图5显示了通过在三个主机上运行MuPDF查看器获得的代码覆盖率，除了两个测试套件的覆盖范围，一个用于SOU，称为基线源，一个用于MOU，称为基线mou。 host123表示从主机1,2和3获得的代码覆盖的并集。观察到以下结果。 </p><ul><li>每个基线的代码覆盖率高于单个主机的覆盖范围。这意味着更改主机会增加代码覆盖率。</li><li>基线覆盖范围与主机覆盖范围有直接关系。例如，host1_max在host1_max，host2_min和host3_avg中具有最高的代码覆盖率。这表明选择合适的主机文件是一项基本工作，并对基线覆盖率产生重大影响。</li><li>在所有情况下，基线mou的代码覆盖率均大于基线。  这意味着进一步修改文件内容会增加代码覆盖率。</li><li>最大代码覆盖率属于host123，表示每个主机已执行不同的基本块。</li><li>最后，覆盖代码的顺序在20,000个基本块的范围内，显示MuPDF查看器[10]是一个大型应用程序，PDF文件具有复杂的格式。 </li></ul><h2 id="4-5-模型评估"><a href="#4-5-模型评估" class="headerlink" title="4.5.模型评估"></a>4.5.模型评估</h2><p><img src="/2019/04/17/Neural-Fuzzing-A-Neural-Approach-to-Generate-Test-Data-for-File-Format-Fuzzing/16.jpg" alt=""></p><p>表4显示了在50个时期训练后我们的模型的困惑，准确性和误差。名为laf的最后一列显示了Learn＆Fuzz模型的这个值[8]。 Keras报告了这些指标。困惑由公式8计算。准确度和误差来自交叉熵损失函数。图6还显示了训练过程中模型2和模型laf的验证错误图。模型2已在此图中说明，因为它与架构和超参数设置中的laf最相似。观察到以下结果。</p><ul><li>所有NLM的误差小于laf误差，并且它们的准确度大于它。这意味着NLM在文件的学习语法中优于编码器 - 解码器模型。</li><li>最大精度属于模型4，我们唯一的双向LSTM。该网络以从左到右和从右到左的方向处理输入序列。因此它可以达到较高的准确度，从而导致较低的困惑。</li><li>在图6中，模型2的错误图始终位于模型laf下当然，迭代有不同的时期，因此点对点比较可能并不令人兴奋。但是，我们也看到这种关系在训练过程开始时的相等间隔内是正确的。</li><li>在我们的数据集中，所有模型的最大困惑是在没有NLM的情况下是困惑的。 50个训练时期之后的困惑度小于1.5，这表明NLM可以学习如此优秀的文件语言。最小困惑属于具有最大可训练参数数量的模型3。</li></ul><p><img src="/2019/04/17/Neural-Fuzzing-A-Neural-Approach-to-Generate-Test-Data-for-File-Format-Fuzzing/17.jpg" alt=""></p><h2 id="4-6-采样多样性和代码覆盖率"><a href="#4-6-采样多样性和代码覆盖率" class="headerlink" title="4.6.采样多样性和代码覆盖率"></a>4.6.采样多样性和代码覆盖率</h2><p>为了研究生成测试数据时多样性对代码覆盖率的影响，我们使用不同多样性0.5,1.0和1.5的采样策略在每个主机上生成1,000个PDF文件。该实验提供了关于代码覆盖中的最佳模型，主机，分集和更新模式（即，SOU和MOU）的信息。因此，我们可以选择用于模糊测试的最佳配置。 我们在训练时间的每个时期结束时保存一个检查点，然后选择所有检查点之间具有最小验证误差的模型。我们选择最佳学习模型进行抽样。</p><p>在SOU模式下使用我们的模型生成1,000个PDF文件大约需要60分钟，在MOU模式下大约需要190分钟。在MuPDF查看器上运行每个测试套件并获得覆盖平均花费65分钟。总的来说，我们在此实验中生成并测试了72,000个PDF文件。所有代码覆盖率如图7所示。观察到以下结果。</p><ul><li>在大多数情况下，生成数据的代码覆盖率小于基线代码覆盖率，因为生成的对象在我们的测试集中并不是真正的PDF对象。但是，在这种情况下，我们会看到代码覆盖率的增加，例如在图表host2_min_mou中。这意味着对于小型主机，添加更多内容会导致更好的代码覆盖率。</li><li>增加多样性会导致双向LSTM（模型4）中的代码覆盖率增加，但其他模型则不然。通常，在大多数模型和大多数主机上生成具有分集一的数据似乎更有效，而不是SUT的代码覆盖。</li><li>几乎在所有图表中，模型2在代码覆盖率方面优于其他模型。这意味着更简单的NLM比更复杂的NLM更好。</li><li>通过查看host123图表，作为结果的汇总，我们可以得出结论，具有多样性的模型2是模糊测试的最佳模型。<br>因此，我们选择此模型用于4.7节中的神经模糊算法。</li></ul><p><img src="/2019/04/17/Neural-Fuzzing-A-Neural-Approach-to-Generate-Test-Data-for-File-Format-Fuzzing/18.jpg" alt=""></p><h2 id="4-8-神经模糊测试"><a href="#4-8-神经模糊测试" class="headerlink" title="4.8.神经模糊测试"></a>4.8.神经模糊测试</h2><p>在第四次和最后一次实验中，我们将MuPDF [10]放在真正的模糊测试上。我们使用DataNeuralFuzz和MetadataNeuralFuzz算法生成10,000个PDF文件，然后使用IUST DeepFuzz进行模糊测试。除了模糊我们的神经模糊算法外，我们还通过FileFuzz [5]进行模糊测试，这是一种基于变异的简单文件格式模糊器，以及Learn＆Fuzz（即SampleFuzz算法）[8]。在所有实验中，我们使用host1_max作为主机文件或FileFuzz的初始种子。在这个实验中，我们用40,000个PDF文件模糊了MuPDF查看器。</p><p>表5显示了为DataNeuralFuzz和MetadataNeuralFuzz算法设置的输入和常量值，以便在可用值中生成测试数据。表6显示了各种模糊测试方法的代码覆盖率结果，包括Learn＆Fuzz [8]和FileFuzz [5]。最后，表7显示了我们提出的方法和其他四种已知文件格式模糊器的代码覆盖率之间的差异：Learn＆Fuzz，AFL [13]，Augmented-AFL [14]和FileFuzz。微软研究最近推出了增强型AFL作为AFL的改进。观察到以下结果。</p><p><img src="/2019/04/17/Neural-Fuzzing-A-Neural-Approach-to-Generate-Test-Data-for-File-Format-Fuzzing/19.jpg" alt=""></p><p><img src="/2019/04/17/Neural-Fuzzing-A-Neural-Approach-to-Generate-Test-Data-for-File-Format-Fuzzing/20.jpg" alt=""></p><p><img src="/2019/04/17/Neural-Fuzzing-A-Neural-Approach-to-Generate-Test-Data-for-File-Format-Fuzzing/21.jpg" alt=""></p><p><img src="/2019/04/17/Neural-Fuzzing-A-Neural-Approach-to-Generate-Test-Data-for-File-Format-Fuzzing/22.jpg" alt=""></p><ul><li>MetadataNeuralFuzz代码覆盖率低于DataNeuralFuzz。正如我们已经说过的那样，操作文件格式的一小部分可能会使其完全无效，因此解析器会尽快拒绝该文件并导致代码覆盖率降低。但是，更改文件中的数据会影响文件执行的呈现阶段。结果证明两种算法都符合我们的预期。一个fuzzes格式，另一个fuzzes数据。</li><li>与SampleFuzz [8]相比，DataNeuralFuzz和MetadataNeuralFuzz都覆盖了MuPDF查看器代码的更多基本块（当然还有更多行）。这表明带有RNN的NLM在模糊测试中优于编码器 - 解码器模型。另一种解释是混合测试数据生成优于基于生成的方法。</li><li>我们的混合测试数据生成方法也优于基于突变的模糊器，如AFL和AugmentAFL，如表7所示.AFL和增强AFL的代码覆盖率取自[14]作为基准。</li><li>基于模糊测试的测试数据生成部分，智能算法与随机变 异的优势是显而易见的。随机算法无法访问复杂输入结构中的高代码覆盖率。 DataNeuralFuzz算法的覆盖范围是FileFuzz [5]中使用的算法的三倍多。</li><li>尽管我们在模糊测试过程中改进了MuPDF查看器[10]的代码覆盖率，如表6所示，覆盖代码的百分比仍然低于25％。这意味着大多数观众代码都没有被执行，这不是好消息。另一方面，我们应该知道MuPDF查看器可以解析和播放不同的文件格式，如XPS。这意味着当输入采用这样的格式时，将使用部分未执行的代码。因此，我们不希望仅通过生成和注入PDF文件来运行它们。</li></ul><h2 id="4-9-故障和漏洞"><a href="#4-9-故障和漏洞" class="headerlink" title="4.9.故障和漏洞"></a>4.9.故障和漏洞</h2><p>可用于评估模糊器的最佳度量标准是在模糊测试期间发现的故障和漏洞的数量。在每次测试执行后，我们没有看到Application Verifier [28]生成的报告中出现任何错误。鉴于我们测试了MuPDF软件的最终版本[10]，假设其大多数错误在试用版本中得到修复，因此很难找到新的错误。另一方面，MuPDF是正在积极开发的软件，它拥有出色的开发人员和用户社区，使其成为强大的软件。但是，DataNeuralFuzz算法检测到不安全功能的多种用法，并将其报告为安全警告。</p><p>似乎Application Verifier [28]在Windows 10 x64上运行时无法检测到32位应用程序的内存错误。我们尝试使用已知错误对一个简单的32位应用程序进行模糊测试，但ApplicationVerifier不会报告任何内容。 64位应用程序但没有这样的问题，它们的错误由ApplicationVerifier检测到。因此，我们测试了32位和64位版本的MuPDF查看器[10]。 IUST DeepFuzz打开带有测试数据的SUT并在固定时间后关闭它，尝试在测试套件中注入下一个测试数据。在我们的配置中，每个测试套件包含10,000个测试数据，需要大约28个小时进行处理。模糊测试是一种压力测试，通常在几天或几周内完成，以发现故障和漏洞。我们计划在更大规模的测试服上测试MuPDF，其中包含100,000个PDF文件以及更多可能会破坏MuPDF的文件。</p><h1 id="5-相关工作"><a href="#5-相关工作" class="headerlink" title="5.相关工作"></a>5.相关工作</h1><p>在本节中，我们将讨论一些相关的模糊测试工作，并解释他们在测试数据生成方面存在的问题。根据测试数据生成方法，模糊器分为基于突变和基于生成[32,33,34]。将各种技术应用于两种方法以改进它们。大多数这些技术都专注于人工智能算法。</p><p><strong>I.基于突变的模糊测试</strong>。在基于突变的情况下，使用一个或多个有效输入数据作为初始种子。然后该种子发生变异以产生另一个测试数据。很容易构建基于突变的模糊器并用它生成错误形成的测试数据。在这种情况下，不需要事先理解输入数据结构。基于突变的方法的缺点是该方法取决于初始种子的变化。如果没有不同的样本输入，基于突变的模糊器就无法实现高代码覆盖率[35]，这表明初始种子在基于突变的方法中的重要性。 AFL [13]和FileFuzz [5]是基于突变的模糊器的例子。</p><p><strong>II.基于生成的模糊测试</strong>。基于生成的方法完全随机地生成测试数据，或者从诸如语法，模板或模型的形式描述生成测试数据。最新的使用输入格式规范来构建生成模型。此方法通常应用于某些文档可用的格式。通常，与基于突变的模糊器相比，它实现了更高的代码覆盖率[35]。但是，正如我们所说，应该花费大量的时间和金钱来完全理解文件格式的规范，并为它构建正确的语法，模板或模型。 SAGE [36]和Peach [37]是基于生成的模糊器的例子。还存在利用两种方法的特征的混合方法。 IUST DeepFuzz在本文中提出了一种混合模糊器，它通过生成模型生成结构化文本数据，通过突变生成非结构化二进制数据。</p><p><strong>III.进化模糊</strong>。通过应用遗传等进化算法[38]，首次尝试将模拟带入模糊测试。进化模糊器从运行时信息（通常是代码覆盖率信息）接收反馈，并将导致新执行路径的测试数据添加到队列中。之后，当模糊器想要生成测试数据时，它只会改变队列中存在的测试数据，希望能够运行代码的新部分。 AFL [13]是最先进的进化文件格式，模糊器的工作方式与上面完全相同。通过使用先前运行的反馈，AFL可以选择更好的测试数据，但是，它会随机改变它们。结果，将生成大量重复的测试数据，这些数据不一定影响包括代码覆盖的测试标准。另一方面，在复杂的输入结构中，更改某些关键部分会导致输入测试数据在解析的初始阶段被解析器拒绝。因此，我们需要一种机制来告知fuzzer输入文件的变异（偏移）。</p><p><strong>IV.基于变异和进化方法的深度学习</strong>。Augmented-AFL [14]作为AFL [13]的改进补丁，尝试使用深度学习技术找到适合变异的位置。在Augmented-AFL创建新的测试数据后，它会查询模型以查看生成的测试数据是否足够好？这种方法提高了测试速度，但是大量数据在生成时被模型（否决）拒绝。此外，Augmented-AFL在MuPDF解析器的代码覆盖率方面没有显着改进[10]。对于具有复杂输入结构的应用程序而言，基于突变的方法似乎无法丰富高代码覆盖率。</p><p><strong>V.基于生成方法的深度学习</strong>。 Godefroid等人最初提出了应用基于神经网络的统计学习从样本输入自动生成输入语法。 [8]。他们还提出了一种生成模糊输入的算法。这项工作的主要思想是学习一组PDF文件的生成模型[11]。为此目的，他们使用一种序列来对结构进行排序[15,16]，其最初用于将来自不同域的两个序列映射到一起，例如机器翻译的任务。他们称他们的方法为Learn＆Fuzz。在整篇论文中，我们讨论了Learn＆Fuzz方法的一些弱点，并为它们提供了一些解决方案。基于这项工作，Cummins 等人介绍了使用RNN [21]的LSTM架构对程序代码进行建模的DeepSmith [39]。他们将该工具应用于OpenCL编程语言的模糊编译器。他们的模型不是混合模型，只能用于生成文本测试数据。</p><h1 id="6-结论"><a href="#6-结论" class="headerlink" title="6.结论"></a>6.结论</h1><p>本文旨在为复杂的输入结构（如PDF文件）引入新的智能测试数据生成技术。由递归神经网络构建的深度神经语言模型可以最好地应用于将复杂输入文件的结构学习为符号序列。可以简单地学习输入文件的文本部分。但是，学习二进制部分的格式是一项艰巨的任务。为了解决这个难题，我们建议暂时删除二进制部分，并用特定的标记替换这些部分。在训练阶段完成之后并且当应用学习模型来生成测试数据时，将令牌替换为已删除部分的变异形式。为了提高模糊效率，我们在应用学习模型时将数据和元数据模糊，以生成新的输入文件作为测试数据。我们相信，无论代码覆盖范围如何，在完成模糊测试时都需要这两种算法。神经模糊算法旨在测试程序的不同部分。 MetadaaNeuralFuzz测试文件格式的解析器和DataNeuralFuzz测试文件格式的渲染器。</p><p>测试数据生成器是模糊器中最重要的模块。提供可以在被测软件中实现高代码覆盖率的自动测试数据生成器，尤其是具有复杂输入结构的目标，对于发现故障至关重要。已经成功地应用基于生成和基于突变的方法来生成用于模糊测试的测试数据。但是，前者不是完全自动的，后者的代码覆盖率很差。</p><p>为了解决这些问题，我们提出了一种基于NLM和深度学习技术的方法。我们的混合测试数据生成方法自动学习输入文件的结构，然后通过模糊输入格式的文本和二进制部分来生成新的多样化测试数据。由于该方法智能地确定了模糊的位置以及应该用于模糊的值，因此可以有望地应用于测试复杂目标。</p><p>我们以复杂的文件格式（即PDF）进行了实验，结果证实了与以前的方法相比，代码覆盖率和我们提出的方法的准确性得到了显着改善。除了一般结论之外，我们的分析揭示了一些有价值的经验事实，最值得注意的是：</p><ul><li>混合测试数据生成用于模糊复杂输入结构的文本和二进制部分，增加SUT的代码覆盖率。</li><li>人们普遍认为，作为LM的双向LSTM可以在同一数据集上获得更高的精度和更少的误差。然而，观察到更简单的NLM，例如没有丢失的单向LSTM，例如本文中的模型2，在代码覆盖中可以胜过更复杂的方法。[14]报道了类似的结果。</li><li>基于具有高代码覆盖率的PDF文件的增量更新过程会导致更多代码覆盖。</li><li>尽管提供比随机和现有智能模糊器更高的代码覆盖率，但我们提出的模糊器可以改进，以便为复杂的输入结构（如PDF文件结构）提供更高的覆盖率。</li></ul><p>关于这个主题，未来有很多工作要做。一种是使用其他强大的深度学习模型，如生成对抗网络（GAN）[40]来生成测试数据。另一个方向是应用这些模型在其他类型的模糊器（如网络协议模糊器）中生成测试数据。为了生成更有效的测试数据，我们打算向IUST DeepFuzz添加一个反馈循环，旨在接收运行时信息并微调学习模型。 SUT中有部分代码处理用户交互。然而，诸如AFL [13]和IUST DeepFuzz之类的模糊器不利用用户交互部件进行模糊测试，并且不支持执行这些部分代码。目前，我们计划支持用户与SUT交互的自动化</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h1&gt;&lt;p&gt;本文旨在设计和实现文件格式模糊器。文件是大多数实际应用程序的重要输入。将输入文件生成为测试数
      
    
    </summary>
    
      <category term="论文" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/"/>
    
      <category term="fuzzing" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/fuzzing/"/>
    
      <category term="机器学习" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/fuzzing/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="fuzzing" scheme="http://yama0xff.com/tags/fuzzing/"/>
    
      <category term="机器学习" scheme="http://yama0xff.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Faster Fuzzing: Reinitialization with Deep Neural Models</title>
    <link href="http://yama0xff.com/2019/04/17/Faster-Fuzzing-Reinitialization-with-Deep-Neural-Models/"/>
    <id>http://yama0xff.com/2019/04/17/Faster-Fuzzing-Reinitialization-with-Deep-Neural-Models/</id>
    <published>2019-04-17T03:48:08.000Z</published>
    <updated>2019-04-17T08:27:29.712Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>我们通过使用生成对抗网络（GAN）模型来改进美国模糊Lop（AFL）模糊测试框架的性能，以使用新的种子文件重新初始化他的系统。我们根据生成新颖和看不见的代码路径的时间速率来评估性能。我们将此方法与在训练种子文件中观察到的随机抽取字节的种子文件生成进行比较。代码路径长度和变化不够多，无法完全取代AFL输入生成。但是，使用这些额外的代码路径扩充原始AFL表明比原AFL有所改进。具体而言，实验表明，GAN比LSTM更快，更有效，并且优于随机增强策略，通过发现的唯一代码路径的数量来衡量。 GAN帮助AFL在相同的CPU时间内发现比随机策略多14.23％的代码路径，找到6.16％的唯一代码路径，并找到平均13.84％的路径。使用GAN有望成为AFL的重新初始化策略，以帮助模糊测试人员在软件中运行深入的路径。</p><table><thead><tr><th>relevant information</th><th></th></tr></thead><tbody><tr><td><em>作者</em></td><td>Nicole Nichols, Mark Raugas, Robert Jasper, Nathan Hilliard</td></tr><tr><td><em>单位</em></td><td><a href="mailto:nicole.nichols@pnnl.gov" target="_blank" rel="noopener">nicole.nichols@pnnl.gov</a><br><a href="mailto:mark.raugas@pnnl.gov" target="_blank" rel="noopener">mark.raugas@pnnl.gov</a></td></tr></tbody></table><p><a href="mailto:robert.jasper@pnnl.gov" target="_blank" rel="noopener">robert.jasper@pnnl.gov</a><br><a href="mailto:nathan.hilliard@pnnl.gov" target="_blank" rel="noopener">nathan.hilliard@pnnl.gov</a> |<br>| <em>出处</em>               | arxiv                                                        |<br>| <em>原文地址</em>           | <a href="https://arxiv.org/abs/1711.02807" target="_blank" rel="noopener">https://arxiv.org/abs/1711.02807</a>                           |<br>| <em>源码地址</em>           |                                                              |<br>| <em>发表时间</em>           | 2017                                                         |</p><h1 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h1><p>通过测试识别软件缺陷是一个具有挑战性的问题。多年来，已经开发了许多方法来测试软件，包括随机变异测试（黑盒模糊测试）Doupéu.a （2012），Woo.u.a（2013），抽象解释（来通过源源代码或机器代码）Cousot和Cousot（1977），Cadar.u.a （2008），Ma.u.a （2011年），和基于性能的测试Arts.u.a （2006年）,Claessen und Hughes（2011年）。</p><p>符号执行等方法提高了程序的分析保真度Schwartz.u.a （2010年）。 Z3，Boolector等可满足性模数理论（SMT）求解器的开发使得对软件的推理进行了强有力的程序化分析，De MouraundBjørner（2008） Brummayer und Biere（2009）。分离逻辑允许将分析应用于复杂的数据结构Reynolds（2002）; Dongol.u.a（2015年）。</p><p>American Fuzzy Lop（AFL）是一种先进的模糊测试框架，用于发现许多新颖的软件漏洞（<a href="https://github.com/mrash/afl-cve）。" target="_blank" rel="noopener">https://github.com/mrash/afl-cve）。</a> AFL使用字节串的随机变换来识别唯一的代码路径并发现目标程序中的缺陷。然后，成功生成唯一代码路径的输入被记录为“种子文件”。我们建议使用这些原生种子文件作为深度生成模型的训练数据，以创建增强的种子文件。我们提出的重新初始化方法是一个可扩展的过程，可以缩短发现软件缺陷的时间。</p><p>其他研究人员使用机器学习来增强模糊测试框架，包括：Godefroid .u.a （2017），wang.u.a （2017年）。为了识别更深层次的错误和代码路径，Steelix Li.u.a（2017）使用基于程序状态的二进制模糊方法和Driller Stephens .u.a（2016）演示了使用模糊测试和选择性执行的混合方法。 AFLFASTBöhme.u.a（2016）使用马尔可夫链模型扩展AFL。深度神经网络（DNNs）Bengio.u.a（2015），在自然语言处理（NLP）Jones（2014）领域取得了巨大成功；Wu.u,a （2016）计算机视觉Krizhevsky.u.a（2012年），以及像Go Mnih.u.a（2013）这样的有界游戏，或像ATARI Silver.u.a （2016）等视频游戏。。这些DNN可以帮助现有的程序分析工具更好地运行吗？在我们的工作中，我们调查了这个问题，我们使用Generative Adversarial Networks（GAN）Goodfellow.u.a（2014）和长期短期记忆（LSTM）Sak.u.a （2014）增加其唯一代码路径发现率从而来增强AFL Zalewski，一个先进的模糊测试框架。</p><p>我们的工作量化了生成模型等增强策略可以提供的好处，即使受到少量培训数据的限制。通过在探索输入空间时周期性地干扰AFL的状态，我们能够改善其性能，如通过唯一代码路径所测量的。具体来说，我们测试了我们围绕以太坊木业（2014）项目的软件生态系统的方法。作为一个金融系统，以太坊代码库的正确性对于保证事务或计算无故障运行非常重要。我们选择Ethkey作为最初的模糊测试目标。Ethkey是一个小型C ++程序，作为cpp-ethereum项目的一部分提供，用于对以太坊钱包进行加载，解析和执行维护，更重要的是，它采用简单的输入文件，使用AFL进行测试变得容易。</p><h1 id="2-实验设计"><a href="#2-实验设计" class="headerlink" title="2 实验设计"></a>2 实验设计</h1><p>首先，我们描述AFL的基本功能，突出显示与建议的增强框架相关的关键功能。接下来，我们将介绍用于创建LSTM和GAN生成的种子文件的方法。作为基线，我们还考虑从用于构建LSTM和GAN模型的训练数据中随机生成种子文件。 AFL扩展了GCC编译器，它与遗传算法结合使用，用于创建种子文件。每个种子文件记录产生唯一代码路径的输入，发现时间，并用作生成未来种子文件的变异（或模糊测试）的基础。我们的扩充策略利用了这样一个事实：如果外部工具在AFL工作目录中放置其他种子文件，AFL将在后续模糊测试运行中将这些文件用作输入。</p><p>为了生成我们方法的训练数据，我们在目标程序P上运行AFL一段固定的时间。对于通过P获取的每个唯一执行轨迹τ，AFL生成初始种子文件集S = {S<sub>0</sub>，…，S<sub>K</sub>}。我们使用S作为LSTM和GAN模型的训练样例，这些模型都使用Keras Chollet（2017）进行训练。</p><p>我们的LSTM通过将AFL生成的种子文件语料库S连接到单个文件中进行训练，并生成最大长度为40个字符的新种子文件。 LSTM模型具有128宽的初始层，内部隐藏层和最终的softmax激活层。为了训练LSTM模型，我们使用RMS传播作为我们的优化器和分类交叉熵损失函数。该模型接收从训练语料库中采样的种子序列，并预测序列中的下一个字符。我们另外调整单独的温度参数以使从网络中的输出种子文件多样化。生成的种子文件记为S<sub>L</sub>。</p><p>在我们的GAN架构中，构建了两个模型，一个生成器G，它与鉴别器D进行对比。G被优化以生成真实的输出，鉴别器D的任务是预测数据是真还是假。这种训练策略是无人监督的，特别富有表现力。生成模型G是完全连接的2层DNN，具有ReLU非线性作为内部激活和tanh输出激活。它通过随机梯度下降训练二元交叉熵损失函数。辨别模型D是3层DNN，但是第一层具有25％的丢失，接着是两个完全连接的层。它使用Adam优化器进行随机梯度下降，并将GAN过程产生的种子文件记为SG。</p><p><img src="/2019/04/17/Faster-Fuzzing-Reinitialization-with-Deep-Neural-Models/1.jpg" alt=""></p><p>另外，给定原始AFL种子文件S，我们从该训练集中随机抽取字节并产生与SG相同长度的新的随机种子文件SR。这作为基线来确定基于GAN和LSTM的种子生成的增加的时间和复杂性是否真正提供了优于随机扰动AFL状态的简单策略的优势。</p><p><strong>小实验</strong>：仅种子文件（SR，SG和SL）不是最终目标。但是，我们感兴趣的是描述它们的可变性和其他属性，因为它们将在AFL重新启动时提供一组初始条件。在单个CPU内核的模糊运行中，我们生成936个用于训练初始GAN和LSTM模型的唯一代码路径。通过从/ dev / urandom绘制随机字节来执行随机种子生成。对于每种方法，我们生成200个样本，在单个CPU上重新初始化AFL，仅使用一种方法的种子文件，再运行72小时以测量对代码路径发现的影响。 LSTM和GAN模型都非常出色地进行AFL重新初始化的随机抽样。我们总结了在表1中发现新代码路径的平均时间。</p><p>每个种子文件在作为ethkey的输入提供时会生成程序跟踪。具有不同长度的代码路径将在至少一个基本块或分支指令中不同。唯一的代码路径长度可以快速计算，但只能在使用AFL的模糊运行中提供测试框架所执行的唯一代码路径数量的下限。具有相同长度的两个代码路径可以由唯一跟踪产生，因此需要详细评估以确定来自种子文件执行的代码路径的真实唯一性。</p><p><strong>大型实验</strong>：为了演示此扩充策略的可扩展性，我们在200个CPU内核上执行了延长的AFL运行72小时。 AFL运行中的每个核心在前10到12个小时的模糊测试后停止查找种子文件，并在49个工作日中累积了39,185个种子文件。由于AFL的内部簿记机制，已知在给定节点内生成的所有种子文件都是唯一的。但是，内容在节点之间不同的种子文件原则上可以使用相同的代码路径。通过测量每个程序跟踪（代码路径）的长度，我们可以计算仅通过计算具有唯一长度的路径而发现的唯一路径数的下限。在从节点之间移除相同的种子文件并且导致导致相同代码路径长度的种子文件之后，我们估计初始文件的802与独立工作者节点重复。删除这些重复项会导致总共38,384个唯一文件。<br>然后，我们在唯一种子文件的总语料库上训练GAN和LSTM网络，并分别从每种方法生成大约20,000个样本，以用作合成种子文件以重新初始化AFL。 GAN花了大约30分钟来训练和生成合成种子文件，而LSTM需要14个小时才能完成。</p><p><img src="/2019/04/17/Faster-Fuzzing-Reinitialization-with-Deep-Neural-Models/2.jpg" alt=""></p><p>在表2中，我们总结了与来自原始AFL的种子文件和来自该较大实验的合成生成方法相关联的程序轨迹（即，代码路径）的长度的均值和方差。与AFL相比，合成种子文件作为被测程序的输入提供时，不会导致探索深层路径。因此，我们不能简单地用生成模型取代AFL。相反，我们寻求将生成模型与AFL结合起来以提高其性能。我们从这些数据中看到，实际上，LSTM和GAN生成的种子文件在生成的代码路径的均值和方差方面不能代表分布S.这强化了使用SG和SL作为增强策略而不是直接替代AFL种子的需要。</p><p>接下来，我们使用来自初始种子文件的随机字节采样（即，不对种子文件进行学习）对GAN，LSTM和随机重新初始化策略进行24小时模糊测试。表3总结了我们的结果。所有这三种策略都允许生成其他种子文件。基于GAN的方法产生的种子文件比随机方法快14.23％，比使用LSTM快60.72％。我们确实失去了30分钟的GAN训练时间，否则可以使用随机抽样方法进行模糊测试;按这段时间折扣会使代码路径速率降低11.85％。但是，我们对唯一的代码路径最感兴趣。 GAN发现了最多的种子文件，其相关的代码路径在初始模糊测试中没有找到长度，优于随机控制方法6.16％。<br>GAN发现的平均代码路径长度比随机控制长13.84％，因此GAN能够在程序中执行更深的路径。 LSTM模型的表现落后于GAN和随机抽样，并且花费了相当长的时间（14小时）进行训练。</p><h1 id="3-结论"><a href="#3-结论" class="headerlink" title="3 结论"></a>3 结论</h1><p>在这项工作中，我们探索了使用深度神经模型增强随机变异测试的效用。原始AFL通过使用编译器插件将来自遗传算法的文件变异策略与程序设备相结合。当我们使用从GAN模型构建的新种子文件重新开始中间模糊运行时，我们观察到AFL性能的最大改进。尽管合成种子文件统计平均具有相似的路径长度，但是当重新启动模糊测试系统时，GAN从随机或LSTM策略中执行重新初始化。 LSTM模型在训练时间和代码路径发现时间方面都存在缺陷。这两种方法都没有使用手动分析或有关被测程序的文件格式的信息。 GAN和随机策略都改善了AFL的性能，即使程序的内部状态永远不会直接暴露。</p><p>未来的工作包括对其他目标的实验，包括DARPA网络大挑战问题，开源OS网络服务，字节码解释器以及其他容易生成输入数据的系统应用程序和程序。我们还计划探索暴露被测试程序的内部状态，以便为强化学习定义奖励功能。我们设想这种内部状态可以通过以下方式公开：1）插桩AFL通过其GCC编译器插件添加到程序中，2）使用英特尔的PIN工具输出每个代码路径的长度或关于给定迹线的摘要信息3）记录程序跟踪使用诸如Mozilla的rr工具之类的重放框架来收集其他描述性统计信息。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h1&gt;&lt;p&gt;我们通过使用生成对抗网络（GAN）模型来改进美国模糊Lop（AFL）模糊测试框架的性能，以使
      
    
    </summary>
    
      <category term="论文" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/"/>
    
      <category term="fuzzing" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/fuzzing/"/>
    
      <category term="机器学习" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/fuzzing/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="fuzzing" scheme="http://yama0xff.com/tags/fuzzing/"/>
    
      <category term="机器学习" scheme="http://yama0xff.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="2017年" scheme="http://yama0xff.com/tags/2017%E5%B9%B4/"/>
    
  </entry>
  
  <entry>
    <title>Not all bytes are equal: Neural byte sieve for fuzzing</title>
    <link href="http://yama0xff.com/2019/04/15/Not-all-bytes-are-equal-Neural-byte-sieve-for-fuzzing/"/>
    <id>http://yama0xff.com/2019/04/15/Not-all-bytes-are-equal-Neural-byte-sieve-for-fuzzing/</id>
    <published>2019-04-15T12:34:54.000Z</published>
    <updated>2019-04-16T03:44:46.349Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>Fuzzing是一种流行的动态程序分析技术，用于发现复杂软件中的漏洞。模糊测试涉及使用精心设计的恶意输入来呈现目标程序，该输入旨在导致崩溃，缓冲，内存错误和异常。以有效的方式制作恶意输入是一个难以解决的开放问题，通常产生此类输入的最佳方法是通过对预先存在的有效输入（种子文件）应用统一的随机突变。我们提出了一种学习技术，该技术使用神经网络从过去的模糊探索中学习输入文件中的模式，以指导未来的模糊探索。特别地，神经模型学习一种功能，以预测输入文件中的好（和坏）位置，以基于过去的突变和相应的代码覆盖信息执行模糊突变。我们实现了几个神经模型，包括LSTM和可以编码可变长度输入文件的序列到序列模型。我们将模型整合到最先进的AFL（American Fuzzy Lop）模糊器中，并在代码覆盖范围，独特的代码路径以及各种输入格式（包括ELF，PNG，PDF和XML）的崩溃方面显示出显着的改进。</p><table><thead><tr><th>relevant information</th><th></th></tr></thead><tbody><tr><td><em>作者</em></td><td>Mohit Rajpal; William Blum; Rishabh Singh</td></tr><tr><td><em>单位</em></td><td>Microsoft Research</td></tr><tr><td><em>出处</em></td><td>CoRR杂志</td></tr><tr><td><em>原文地址</em></td><td><a href="https://arxiv.org/abs/1711.04596" target="_blank" rel="noopener">https://arxiv.org/abs/1711.04596</a></td></tr><tr><td><em>源码地址</em></td><td><a href="https://github.com/arvindrao7589/augmented-afl-fuzz" target="_blank" rel="noopener">https://github.com/arvindrao7589/augmented-afl-fuzz</a></td></tr><tr><td><em>发表时间</em></td><td>2017年</td></tr></tbody></table><h1 id="I-简介"><a href="#I-简介" class="headerlink" title="I  简介"></a>I  简介</h1><p>模糊测试[18]，[12]是最广泛使用的自动化软件测试技术之一，已成功地在复杂程序中自动发现大量安全漏洞。模糊测试的关键思想是不断生成新的恶意输入，对目标程序进行压力测试，以发现崩溃，缓冲流或异常等意外行为。通常，模糊器以一组初始种子输入文件启动，通过随机突变，约束求解或使用一组手动定义的启发法连续转换以生成恶意输入。由于输入格式可能非常复杂，因此生成恶意输入通常需要数百万个突变，因此模糊测试过程可以被视为一个巨大的搜索问题，可以识别出一组良好的突变，从而导致更高的代码覆盖率和更多的崩溃。在本文中，我们提出了一种学习技术，该技术使用神经网络从先前的模糊探索中学习输入文件中的模式，以指导未来的模糊探索。特别是，神经模型学习输入文件中不同位置的分布以应用突变，这反过来又用于指导模糊过程以探索新的唯一代码路径和崩溃。</p><p>目前的模糊测试技术大致可分为三大类：i）Blackbox模糊测试[18]，[14]，[1]，ii）Whitebox模糊测试[12]，以及iii）Greybox模糊测试[26]。Blackbox模糊器将目标程序视为黑盒子，程序内部没有内部检查。相比之下，白盒模糊器需要知道正在测试的程序的结构（可能但不一定是通过程序源代码的分析）来生成输入突变以特定地针对某些代码片段。Greybox模糊器形成了一个中间地带，他们执行有限的源代码检查，例如使用轻量级代码检测计算代码覆盖率。尽管所有模糊测试技术都有不同的优点和缺点，但基于随机突变的灰盒模糊技术已经导致AFL（American Fuzzy Lop）[26]等模糊测试，它已经成功地在复杂程序中发现了大量的实际错误。 greybox模糊器的成功很大程度上源于其简单性，允许有效的低级实现。在本文中，我们探讨是否有可能使用机器学习来学习基于先前执行输入历史和代码覆盖率信息来指导输入突变的策略。更具体地说，我们的目标是学习一种能够预测输入文件中最佳位置以执行突变的功能。我们首先在有限时间内运行传统的模糊测试技术，以获取有关哪些突变导致新代码覆盖的数据，然后使用此数据来学习一种功能，以指导进一步的输入修改以产生新的有前景的输入。虽然我们的技术适用于任何模糊测试系统，但我们在当前最先进的AFL模糊器[26]上实例化它，这是一种基于遗传算法的灰盒模糊器。AFL对一组种子输入文件执行随机变换，并维护有希望的新输入文件的输入队列，这导致执行新的代码路径。由于难以使用随机突变精确地改变输入文件，通常会丢弃数百万新生成的输入，并且只考虑其中的少数（在输入队列中）以用于将来的突变。我们的技术旨在学习如何指导这一输入生成过程，以最大限度地减少生成无意义输入所花费的时间，从而增加模糊器覆盖新代码路径的机会。</p><p>我们实现了几种神经网络架构，以学习在给定一组输入修改的情况下预测预期代码覆盖图的功能。由于输入文件可以有不同的长度，我们使用LSTM（长短期记忆）[15]和序列到序列的结构，注意[3]可以编码可变长度序列。在模糊测试时，我们使用学习函数来预测完整输入文件的热图，其对应于导致新代码覆盖的每个文件位置的突变的可能性。然后，我们使用覆盖图来确定突变位置的优先级。为了训练这些功能，我们首先在种子文件子集上运行AFL一段有限的时间，并获得突变覆盖的训练数据信息。</p><p>我们在几种输入格式（如ELF，PNG，PDF和XML）上评估我们的技术。我们观察到神经增强AFL导致ELF和PNG解析器的代码覆盖率明显高于AFL，而对于PDF和XML解析器，覆盖范围具有可比性。我们观察到神经增强AFL始终导致为ELF，PNG和XML解析器探索显着更多数量的唯一代码路径。最重要的是，对于ELF和XML解析器，神经引导AFL的观察到的崩溃次数显着增加。我们观察到PDF解析器的覆盖率改善较小，因为学习模型需要额外的时间来预测大型PDF输入文件上的覆盖图，但我们相信通过一些额外的性能工程可以提高性能。本文的主要贡献如下：</p><ul><li><p>我们使用不同的神经网络架构模拟了在输入文件中模拟有前途位置的模糊问题。</p></li><li><p>我们提出了一种技术，可以有效地训练位置预测功能，然后使用学习的功能进行模糊测试。</p></li><li><p>我们在最先进的AFL模糊器中实现我们学习的神经模型，并表明它会导致更多的代码覆盖，独特的代码路径以及不同输入格式的崩溃。</p></li></ul><h1 id="II-AFL背景"><a href="#II-AFL背景" class="headerlink" title="II AFL背景"></a>II AFL背景</h1><p>AFL是最先进的greybox进化模糊器。AFL有一个简单的策略来制作恶意输入：尝试许多小的局部突变到种子文件，以及一些堆叠突变，同时突变种子中的许多位置。 AFL的优势在于其遗传算法。 AFL仪器在编译期间获取源代码，以便在执行期间访问代码覆盖率。在执行目标程序期间，AFL观察到变异种子诱导的代码覆盖。如果一个变异的种子诱导了一些前所未见的代码要执行，或者如果它改变了之前看到的代码片段的执行频率，那么它就被认为是有趣的。这被称为输入增益。 AFL保存突变的输入，这些输入诱导输入增益并将它们视为进一步的种子文件以进行变异。种子池的这种不断演变有助于达到许多模糊的代码路径，这需要许多迭代的小突变才能到达。这个池也经常被淘汰，以挑选最好的种子进行变异。AFL的策略在成熟的开源项目中发现了许多错误，例如Mozilla Firefox，ffmpeg，OpenSSL，clang等。简单的黑盒随机模糊器和AFL模糊器的核心算法的比较如图1所示。</p><p><img src="/2019/04/15/Not-all-bytes-are-equal-Neural-byte-sieve-for-fuzzing/1.jpg" alt=""></p><p>模糊测试是计算密集型的。即使很小的输入增益也需要数千到数百万的随机突变才能发现。然而，并非所有突变都是平等的。文件格式及其解析器是异构的。我们认为文件头或其他关键部分的突变更有可能产生输入增益。这可能是一种情况，因为许多条件分支依赖于小的关键部分。相反，包含原始数据的部分不太可能产生输入增益，因为它们通常由紧密循环中的小块代码读取。然而，在没有大量领域专业知识的情况下手动识别复杂输入格式的这些位置是困难的。</p><p>自然的下一步是编纂定量技术，以自动识别最佳位置以进行变异。我们研究基于神经网络的机器学习技术，使用代码覆盖反馈自动识别输入文件中的有用位置。</p><h1 id="III-框架概述"><a href="#III-框架概述" class="headerlink" title="III 框架概述"></a>III 框架概述</h1><p>我们的框架由一个模糊器和一个模型组成，它突出了输入文件中的有用位置。在运行期间，模糊器查询每个种子文件的模型，并将突变集中在突出显示的位置上。突出显示种子文件的样本如图2所示。给定以字节序列格式的输入文件，该模型注释热图函数，突出显示改变输入文件中每个位置的相对效率。由于种子文件的长度可变，该模型被定义为一系列函数。</p><p><img src="/2019/04/15/Not-all-bytes-are-equal-Neural-byte-sieve-for-fuzzing/2.jpg" alt=""></p><p><img src="/2019/04/15/Not-all-bytes-are-equal-Neural-byte-sieve-for-fuzzing/3.jpg" alt=""></p><p>为简单起见，我们将这一系列函数表示为简单的f，它可以将任意数量k的输入位置作为输入。该函数将输入文件中的每个位置与产生输入增益的突变概率相关联。在增强执行期间，模糊器首先在执行突变之前查询该模型，并使用所得到的热图来指导突变朝向有用位置。针对少数有用位置的潜在输入在增强执行期间被否决;这可以通过避免对不太可能提供输入增益的输入执行来节省时间。形式上，变异输入被否决，除非它满足等式2中所示的所需截止值。</p><p><img src="/2019/04/15/Not-all-bytes-are-equal-Neural-byte-sieve-for-fuzzing/4.jpg" alt=""></p><p>这里</p><p><img src="/2019/04/15/Not-all-bytes-are-equal-Neural-byte-sieve-for-fuzzing/5.jpg" alt=""></p><p>面上，x ⊙ x’ 是相对于种子的变异输入的差异。等式2中的关键思想是仅考虑修改许多有用字节位置的差异，如 f(x) 所示。α参数控制必须突变的“有用”字节数。热图功能f的这种表达很容易并且有效地与任何模糊系统集成，因为它在任何种子文件的开始执行一次热图计算。</p><p>为了训练模型来学习函数f，需要输入文件和相应的代码覆盖。特别是，以下元素用于训练模型：</p><ul><li><p>x：种子文件被模糊; </p></li><li><p>b：通过在x上执行目标程序产生的代码覆盖位图; </p></li><li>x’：变异的种子文件; </li><li>b’：通过在上执行目标程序产生的代码覆盖位图。</li></ul><p>请注意，这些数据元素是大多数greybox模糊器的第一类公民，不需要额外的工具来生成。Blackbox模糊器也可以轻松扩充，以生成目标程序的代码覆盖率信息。</p><p>虽然很明显代码覆盖率缺乏变化表明突变应用于无用位置，但没有直接的方法通过（输入，代码覆盖）元组确定有用的位置。在b,b’的一些评分上创建监督的训练数据集对的一般框架，表示为s(b,b’)，是：</p><p><img src="/2019/04/15/Not-all-bytes-are-equal-Neural-byte-sieve-for-fuzzing/6.jpg" alt=""></p><p>对于某些实值截止值γ。给定训练数据集，目标是学习一个模型，该模型可以将输入文件x映射到差异热图x ⊙ x’，这反过来可以用于识别可能有用的位置，以集中模糊变形的注意力。</p><p>上述方法的优点在于它导致剔除无用突变，其得分低于有用突变。从数据集学习的模型将在监督设置中获得许多得分良好的(x, x ⊙ x’)对。单个种子通常与许多突变配对。为了最大限度地减少这种“一对多”关系的总损失，学习了给出x：E[(x ⊙ x’)| x ]的diff  x ⊙ x’的期望值。这捕获了在某些位置移动字节的相对有用性。</p><p>原则上，s(b,b’)的有效化身具有挑战性。s(b,b’)的所需行为突出显示导致输入增益的突变，从而导致目标程序中“从未见过”的执行行为。这种对模糊测试历史的顺序依赖需要一个以先前的覆盖历史为条件的函数s<em>，遗憾的是，这对于学习模型的方法来说是困难的。因此，我们选择 s </em>的直观近似：</p><p><img src="/2019/04/15/Not-all-bytes-are-equal-Neural-byte-sieve-for-fuzzing/7.jpg" alt=""></p><p>其中b<sub>i</sub>表示位图b的第i位，|b| 表示位图的长度。表I中给出了按位严格小于函数的真值表。</p><p><img src="/2019/04/15/Not-all-bytes-are-equal-Neural-byte-sieve-for-fuzzing/8.jpg" alt=""></p><p>按位’严格小于’评分函数突出显示未在b中执行但在 b’ 中执行的代码段。此功能奖励代码覆盖率增加。在实践中，我们发现这种评分功能可以在很多目标计划中取得良好的效果。</p><h1 id="IV-学习增强模糊"><a href="#IV-学习增强模糊" class="headerlink" title="IV 学习增强模糊"></a>IV 学习增强模糊</h1><p>我们用于学习增强模糊测试的设计包括对AFL的修改以及用于预测模糊的最佳位置的神经网络模型。</p><h2 id="A-增强型AFL"><a href="#A-增强型AFL" class="headerlink" title="A.增强型AFL"></a>A.增强型AFL</h2><p>我们为这项工作增加了AFL模糊器以利用神经模型。Augmented-AFL在模糊测试之前使用每个种子查询神经网络模型。神经模型将种子分类为字节粒度的有用和无用部分，该部分在模糊测试期间使用。在执行之前，没有针对没有有用部分的突变被否决。这种增强方法如图3所示。</p><p><img src="/2019/04/15/Not-all-bytes-are-equal-Neural-byte-sieve-for-fuzzing/9.jpg" alt=""></p><p>AFL模糊测试策略应用以下小的局部突变。请注意，以下所有突变均在连续切片上进行。</p><ul><li><p>位flips：通过一次移位[1/2/4]位来改变输入。</p></li><li><p>Byte flips：通过应用exclusve或[1/2/4]字节（0xFF）来改变输入。</p></li><li><p>算术突变：通过以[1/2/4]字节粒度添加/减去感兴趣的量来改变输入。</p></li><li><p>有趣的替换：通过以[1/2/4]字节粒度拼接“有趣”值来改变输入。</p></li><li><p>字典替换：通过用用户提供的“有趣”值替换字节来改变输入。这些长度可能超过4个字节。</p></li></ul><p>上述所有突变都是小的局部变化，对于给定的种子，其变化非常大。在确定性阶段结束后，AFL开始堆叠许多这些小的局部突变，这些突变是非局部的并且相对于输入具有显着的汉明距离。AFL可以应用于均匀选择的2到128个堆叠变化之间。除了前面提到的位置突变，还可以应用以下突变：</p><ul><li><p>随机字节分配：将随机值分配给随机字节。</p></li><li><p>删除字节：删除输入文件的一部分。</p></li><li><p>克隆字节：将字节附加到输入文件的一部分。</p></li><li><p>覆盖字节：覆盖输入文件的一部分。</p></li></ul><p>由于AFL模糊测试的位置和上下文不敏感性，大多数突变不会产生任何输入增益。增强模糊测试的目标是提高突变的命中率。使用模型提供的注释种子，避免了不太可能提供输入增益的突变。我们使用了一种高度宽容的否决方法来拒绝不针对任何有用位置的突变。增强变异算法如图4所示。</p><p><img src="/2019/04/15/Not-all-bytes-are-equal-Neural-byte-sieve-for-fuzzing/10.jpg" alt=""></p><h2 id="B-神经网络架构"><a href="#B-神经网络架构" class="headerlink" title="B.神经网络架构"></a>B.神经网络架构</h2><p>我们现在描述用于学习覆盖热图预测功能的不同神经网络架构。回想一下，要学习的函数族具有以下格式：</p><p><img src="/2019/04/15/Not-all-bytes-are-equal-Neural-byte-sieve-for-fuzzing/11.jpg" alt=""></p><p>该系列函数的可能编码方案是将输入“按原样”提供给底层神经网络。这将涉及将数据编码为[0, 255]范围内的实值浮点数序列。然而，这是次优的，因为二进制数据不一定代表量值，但也可以代表状态。假设每个字节表示数字量，它可以表示位掩码或其他非数字值是不正确的。因此，我们以“比特序列”格式编码字节级信息：</p><p><img src="/2019/04/15/Not-all-bytes-are-equal-Neural-byte-sieve-for-fuzzing/12.jpg" alt=""></p><p>此函数以比特粒度确定有用性。我们通过平均每个字节的组成位值来重构给定的f’。</p><p>由于输入的长度和顺序性质不同，回归神经网络（RNN）是显而易见的选择。每个输入文件是顺序数据，最有可能由目标程序顺序解析。 RNN能够统计[21]。这对于在固定偏移处包含标题信息的文件格式进行注释很有用。RNN已经成功地用于统计机器翻译[6]，[3]，这个任务很相似，因为二进制文件格式可以被认为是一种语言。已知RNN具有较长序列的问题。由于这个原因，我们选择长期短期记忆（LSTM）作为我们的基础复发单位[15]。LSTM将循环单元的存储能力扩展到更长的序列。这是通过一个独立的记忆流程来完成的。LSTM还可以“忘记”已经失去其实用性的记忆，这使得更长的序列具有更强的表现力。回想一下，循环单元计算状态更新和输出h<sub>t</sub>,o<sub>t</sub>，如下所示。</p><p><img src="/2019/04/15/Not-all-bytes-are-equal-Neural-byte-sieve-for-fuzzing/13.jpg" alt=""></p><p>LSTM将上述整体框架分解为以下子组件。</p><p><img src="/2019/04/15/Not-all-bytes-are-equal-Neural-byte-sieve-for-fuzzing/14.jpg" alt=""></p><p>这里</p><ul><li><p>σ = Sigmoid激活函数</p></li><li><p>W<sub>*</sub> = 学习的权重向量</p></li><li><p>b<sub>*</sub> = 学习的偏向量</p></li></ul><p>忘记门f<sub>t</sub>和输入门i<sub>t</sub>控制是否忘记旧存储器，以及当前输入是否值得记忆。这种相互作用允许LSTM的存储器信息通过更长的序列持续存在。</p><p>我们使用LSTM作为我们的基本重复单元来探索几种架构，以确定输入注释和神经结构。神经机器翻译的最新进展突出了一些重要的架构，如Seq2Seq [6]和Seq2Seq与注意[3]。在学习二进制格式的结构时，这些以翻译为中心的架构是否也能很好地工作？总的来说，我们评估了以下架构：</p><ul><li><p>LSTM：简单的单向LSTM [15]。</p></li><li><p>双向LSTM：双向LSTM，可以向前和向后看输入。</p></li><li><p>Seq2Seq：序列到序列架构[6]。</p></li><li><p>Seq2Seq + Attn：序列到序列架构，注意[3]。</p></li></ul><p>双向LSTM以向后和向前的顺序查看输入。双向LSTM由两个单向LSTM组成，每个LSTM在前向和后向各一个。给定长度为n的序列，为计算时间步长t的值，前向LSTM的h<sub>(t-1)</sub>和后向LSTM的h<sub>(n-t-1)</sub>结合使用。合并函数用于合并单向LSTM的输出。合并函数可以是组合两个相似大小的向量（例如求和，乘法或连接）的许多函数之一。我们选择将sum函数用于单层双向LSTM，并将LSTM的连接函数用于两层或更多层。</p><p>我们还尝试了每个时间步长提供的层数和LSTM输入的块大小。目的是确定复杂的字节预测是多么复杂，以及更复杂的模型是否优于更简单的模型。</p><p>我们的模型每次迭代消耗k位，并且每次迭代也输出k位。我们尝试将输入序列分块为64位或128位块。我们提出的架构和可训练参数的总数详见表II。</p><p><img src="/2019/04/15/Not-all-bytes-are-equal-Neural-byte-sieve-for-fuzzing/15.jpg" alt=""></p><p>单层双向LSTM使用求和合并功能，而双层双向LSTM使用串联功能。双层双向LSTM的第二层是单向LSTM。Seq2Seq和Seq2Seq + Attn由一个编码和一个解码层组成。编码层是双向LSTM，它使用concatenate函数合并。解码层是单向LSTM。我们没有探索单向Seq2Seq或Seq2Seq + Attn。</p><h1 id="V-评估"><a href="#V-评估" class="headerlink" title="V 评估"></a>V 评估</h1><p>我们评估增强型AFL对四个目标计划的有效性，目的是评估实践中遇到的各种程序中的增强策略。选择的目标程序是readpng [22]，readelf [10]，mupdf [16]和libxml [24]。我们调查了这些程序的几个指标，主要包括代码覆盖率和输入增益。代码覆盖率和输入增益是AFL使用的第一类指标。输入增益通过输入总数来测量，这些输入会在模糊器的运行时间内产生输入增益。还测量了使用增强AFL和AFL发现的碰撞次数。</p><p><img src="/2019/04/15/Not-all-bytes-are-equal-Neural-byte-sieve-for-fuzzing/16.jpg" alt=""></p><p>我们从大样本群体中为每个程序收集了180个随机选择的种子文件。种子文件被均匀地分成训练和测试集。为了收集用于训练模型的数据，AFL运行了24小时。以均匀的1％采样率收集输入，代码覆盖对。该收集策略在图5中突出显示。在训练之前，数据以严格小于函数的方式进行过滤，截止值为0以形成训练集。也就是说，给定一组(x,x’,b,b’)，训练数据集X Y如下构造。</p><p><img src="/2019/04/15/Not-all-bytes-are-equal-Neural-byte-sieve-for-fuzzing/17.jpg" alt=""></p><p>模型实现是使用Keras [7]设计的，这是一个高级深度学习库。我们选择使用Tensorflow [2]作为Keras的低级后端。</p><p>训练数据的长度是异质的，并且可以包括长达200千字节的非常大的输入文件。为了缓解这些问题，超过10kB的输入数据被分段为一组10kB段。在分段之后，根据长度对数据进行分箱并填充到最近的块大小的边界。每个训练步骤包括选择与箱尺寸成比例的箱，以及在所选箱中构建元件的小批量。这些模型经过12小时的训练，以确保收敛，并在具有12千兆字节RAM的Nvidia K40M GPU上进行培训。我们使用平均绝对误差（MAE）的损失函数，并使用具有5 x 10^-5^学习率的Adam优化器[17]来训练模型。</p><p>尽管Augmented-AFL可以利用以前学过的模式来提高突变的命中率，但它并没有像基准AFL算法那样进行探索。为了抵消这种趋势，对于每个种子，增强型AFL可以以50％的概率选择使用未增强的模糊测试策略。这允许在勘探和开采之间进行良好的混合。有许多技术可以更好地实现我们希望在未来追求的探索和开发之间的平衡。为了评估学习模型，我们在种子文件的测试集上重新启动AFL和Augmented-AFL。该评估阶段进行24小时。为了最小化方差，一次运行许多AFL实例。对于AFL，16个AFL实例在16核机器上运行。对于AugmentedAFL，在16核计算机上运行8个AFL实例，其中8个核保留用于模型查询。对于大多数验证，我们使用Azure标准F16s机器，配备2.40GHz的Intel Xeon E5-2673 v3 CPU和32GB RAM。由于内存不足问题，Azure Standard D14大小的VM仅用于少数情况。Azure标准D14 VM与标准F16相同，只有112GB的RAM。验证期间未启用动态CPU频率缩放。执行24小时后，数据在许多实例上取平均值。</p><h2 id="A-代码覆盖范围"><a href="#A-代码覆盖范围" class="headerlink" title="A.代码覆盖范围"></a>A.代码覆盖范围</h2><p>报告表III中所有程序的所有体系结构的代码覆盖率。我们可以观察到readelf和readpng程序的代码覆盖率指标的显着改进。几乎所有模型都优于这些程序的基准（基线AFL）。通常，最简单的单向模型优于其他更复杂的模型。但是，使用mupdf和libxml没有观察到代码覆盖率指标的显着改进。对于mupdf，大多数增强模型的性能都比基准测试差。唯一的例外是mupdf的Seq2Seq + Attn模型，它的性能优于基准。对于libxml，所有模型的代码覆盖率都相似。报告的代码覆盖率都集中在2.10％左右，并且在误差范围内。</p><p><img src="/2019/04/15/Not-all-bytes-are-equal-Neural-byte-sieve-for-fuzzing/18.jpg" alt=""></p><h2 id="B-输入增益"><a href="#B-输入增益" class="headerlink" title="B.输入增益"></a>B.输入增益</h2><p>衡量效率的第二个指标是输入增益。输入增益是在目标程序中发现的从未见过的行为的路径数。此行为的特征在于执行新的代码块，或者增加先前执行的代码块的执行频率。图6显示了每个程序的两个性能最高的模型的输入增益与时间曲线。</p><p><img src="/2019/04/15/Not-all-bytes-are-equal-Neural-byte-sieve-for-fuzzing/19.jpg" alt=""></p><p>对于除PDF之外的所有程序，都会观察到输入增益的显着改善。这对于readpdf和readelf是预期的，因为这些程序的代码覆盖率通常会增加。但是，libxml在验证期间没有显示代码覆盖率增加。这可能意味着相同的代码部分在执行频率的变化下得到更彻底的运用。</p><p>mupdf解析器在代码覆盖率或输入增益方面没有显着改进。我们相信这显示了所提出的设计中的模型查询与执行权衡。由于典型的PDF文件大小非常大（超过100kB），因此模型查询时间会对Augmented-AFL的性能产生负面影响。在对每个种子文件进行模糊测试之前，必须对该种子文件查询模型，对于这样的大种子文件可以是几秒钟。在模糊器的运行时间内，此查询时间会对总模糊测试性能产生负面影响，因为模型查询通常会阻止执行。我们相信，模型查询的吞吐量和性能改进将提高增强型AFL技术对PDF等冗长格式的有效性。</p><h2 id="C-崩溃"><a href="#C-崩溃" class="headerlink" title="C.崩溃"></a>C.崩溃</h2><p>测量模糊效应的最重要指标是发现的恶意输入数量，我们通过记录执行期间发现的唯一崩溃数量来衡量。我们只观察了readelf和libxml的崩溃，因此我们省略了readpng和mupdf的图。随着时间的推移发现的独特崩溃图显示在图7中的readelf和libxml中。</p><p>增强AFL优于两个程序的AFL基准。对于readelf，在24小时标记处观察到几次独特的崩溃（超过20次），而基准测试没有观察到崩溃。同样，与AFL发现大约80个独特崩溃相比，增强AFL导致在24小时标记内发现大约110个libxml的唯一崩溃。这些结果显示出相对于基线的显着改善。</p><p><img src="/2019/04/15/Not-all-bytes-are-equal-Neural-byte-sieve-for-fuzzing/20.jpg" alt=""></p><p>这些结果显示了AFL的改进，AFL是一种遗传算法greybox fuzzer。使用机器学习来预测感兴趣的有趣位置，我们能够改善各种目标程序和文件格式的模糊测试性能。因此，我们认为机器学习引导模糊是一种很有前途的技术，可以改进greybox和blacbkox模糊器，并且可以应用类似的技术来学习将来的其他几个模糊测试参数。</p><h1 id="VI-相关工作"><a href="#VI-相关工作" class="headerlink" title="VI 相关工作"></a>VI 相关工作</h1><p>我们现在简要讨论一下使用机器学习技术（特别是基于神经网络的模型）来指导程序模糊测试和程序分析的一些相关工作。</p><p><strong>a）基于语法的模糊测试的机器学习</strong>：最近开发了用于训练神经网络（LSTM）的Learn＆Fuzz [13]方法，以学习基于语法的模糊测试的输入格式的生成模型。对于复杂的输入格式（如PDF），随机改变输入会很快导致无效输入，因此通常使用基于语法的模糊测试技术来定义这些格式的输入语法。但是，手动编写语法是繁琐且容易出错的，尤其是对于复杂的输入格式。Learn＆Fuzz介绍了一种使用LSTM来学习使用字符级模型的PDF对象的语法（分布）的技术，然后可以对其进行采样以生成新的输入。我们的技术不是学习语法，而是使用神经网络来学习预测种子文件中有希望的位置以执行突变的功能。我们相信我们的技术可以补充Learn＆Fuzz，以进一步改善基于神经语法的模糊测试。</p><p><strong>b）Fuzzing的强盗配方</strong>：通过强盗优化技术激发了我们的工作。将模糊测试和强盗优化与模糊配置调度相结合已有一些工作[25]。特别是，Woo等人 [25]将模糊化的配置选项建模为强盗问题。然而，我们的工作通过将模糊测试模拟为强盗问题来进一步采用这种方法。我们认为模糊测试是一个离散的优化问题，可以通过识别具有最高收益的字节位置子集来简化，并且最佳字节位置的识别是通过多臂匪徒方法最好地解决的问题。这种“bytesas-bandits”方法值得进一步研究，特别是，我们希望进一步阐明识别最佳字节的理论上最佳方法。</p><p><strong>c）进化模糊测试</strong>：进化模糊测试使用执行反馈来指导未来的变异决策。沿着这个方向的一些早期工作包括DeMott等人的进化模糊系统（EFS） [8]。EFS使用遗传算法技术来演化种子池，其中定义函数被定义为诱导代码覆盖。EFS使用几种复杂的交叉方法来随时间推移种子池。与AFL相比，EFS仅使用基因交叉方法来“模糊”种子文件集。进化模糊测试的最新进展包括基于Taint的Directed Whitebox Fuzzing [11]和VUzzer [20]。基于污染的定向白盒模糊测试使用动态污点跟踪来识别可能导致危险代码段执行的种子部分。突变针对这些部分以发现错误。VUzzer采用类似的方法使用动态污点跟踪，但不会尝试识别和关注危险的代码段。VUzzer致力于提高代码覆盖率并彻底运用代码。</p><p>上述技术中的共同主题是依赖于过去执行行为的反馈循环。虽然我们的方法也包含反馈循环，但我们赞成使用神经方法来指导未来的模糊测试操作。这是新颖的，因为易于开发和集成。我们的神经引导可以使用现成的Deep Learning库快速开发方法，并且可以轻松地将其集成到现有的Greybox或Blackbox模糊器中。我们的方法具有相对较低的开销，因为简单模型具有低查询时间并且可以有效地计算覆盖图。</p><p><strong>d）用于程序分析的神经网络</strong>：最近有几项工作用于训练神经网络以执行程序分析，例如程序修复[4]，程序优化[5]和程序综合[19]，[9]，[23] ]。这些工作学习程序的神经表示来执行各种预测任务，而在我们的工作中，我们训练神经模型代替输入文件。此外，我们的工作提出了训练神经网络的第一个应用，以学习输入文件中有前途的模糊位置。</p><h1 id="VII-未来的工作和结论"><a href="#VII-未来的工作和结论" class="headerlink" title="VII  未来的工作和结论"></a>VII  未来的工作和结论</h1><p>我们已经演示了一种新的基于神经的增强灰色框模糊测试。这种增强确定了在种子文件中模糊的有用位置。我们认为大多数二进制文件格式包含很小的部分，这些部分会严重影响程序的执行行为。在这些小部分上聚焦模糊是有用的，因为它们可能在目标程序中产生新颖的执行行为。</p><p>我们的增强目标是针对像AFL这样的灰盒模糊器。Greybox模糊器是完美的测试平台，因为它们为每次执行提供代码覆盖率反馈。该反馈用于训练神经网络模型以识别最有希望的模糊测试位置。我们的方法简单易用，可与大多数灰盒模糊器集成。</p><p>我们发现像LSTM这样的复现模型很适合这项任务。此任务可以被视为类似于统计机器翻译。近年来，循环模型在统计机器翻译任务上取得了巨大成功。我们使用各种目标二进制文件格式（如PDF，XML，PNG和ELF）评估模型。该模型在除PDF之外的所有目标程序上都明显优于最先进的AFL模糊器。通常，最简单的模型优于更复杂的模型。我们相信PDF上的模型性能显示了在大输入文件上查询模型的成本优势。但是，我们相信可以通过一些额外的性能工程改进PDF等大文件格式的结果。</p><p>虽然我们的结果很有希望，但还有很多途径需要进一步开展工作。我们在一个受监督的环境中训练我们当前的模型。这项工作的一个自然延伸是使用强化学习在线学习，以便随着模糊测试过程的进行，模型不断改进。我们相信通过“反馈循环模糊测试”可以大大增强模糊测试，其中过去的执行行为指导未来的突变。我们设想了一种新型的模糊器，它利用机器学习模型来指导其变异决策。Fuzzing提供了高质量结构化数据的宝库。信噪比很高。沿着这条道路的另一个可能的扩展是使用生成模型。我们的模型是限制性的，其中AFL提出的突变被否决。一种更有趣的方法是生成应用于种子文件的突变，我们计划在不久的将来考虑这些突变。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h1&gt;&lt;p&gt;Fuzzing是一种流行的动态程序分析技术，用于发现复杂软件中的漏洞。模糊测试涉及使用精心设
      
    
    </summary>
    
      <category term="论文" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/"/>
    
      <category term="fuzzing" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/fuzzing/"/>
    
      <category term="机器学习" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/fuzzing/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="fuzzing" scheme="http://yama0xff.com/tags/fuzzing/"/>
    
      <category term="机器学习" scheme="http://yama0xff.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="2017年" scheme="http://yama0xff.com/tags/2017%E5%B9%B4/"/>
    
  </entry>
  
  <entry>
    <title>Recurrent Neural Networks for Fuzz Testing Web Browsers</title>
    <link href="http://yama0xff.com/2019/04/15/Recurrent-Neural-Networks-for-Fuzz-Testing-Web-Browsers/"/>
    <id>http://yama0xff.com/2019/04/15/Recurrent-Neural-Networks-for-Fuzz-Testing-Web-Browsers/</id>
    <published>2019-04-15T01:40:54.000Z</published>
    <updated>2019-04-15T12:14:37.083Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>基于生成的模糊测试是一种软件测试方法，能够发现软件中不同类型的错误和漏洞。然而，已知设计和微调经典模糊器以实现可接受的覆盖是非常耗时的，即使对于小规模软件系统也是如此。为了解决这个问题，我们研究了一种基于机器学习的模糊测试方法，其中我们概述了一系列基于递归神经网络（RNN）的测试用例生成器，并使用最少的人工微调来训练那些现成的数据集。与先前的工作相比，所提出的生成器不依赖于启发式采样策略，而是依赖于预测分布的原理采样。我们提供详细的分析，以在具有挑战性的Web浏览器测试场景中演示所提出的生成器的特征和功效。实证结果表明，基于RNN的发生器能够提供比基于突变的方法更好的覆盖，并且能够发现经典模糊器未发现的路径。我们的研究结果补充了其他领域的研究结果，表明使用RNN进行基于代数的模糊测试是通过使用合适的模型选择/分析程序来获得更好软件质量的可行途径</p><p>Keywords: Software security, fuzz testing, browser security </p><table><thead><tr><th>relevant information</th><th></th></tr></thead><tbody><tr><td><em>作者</em></td><td>Martin Sablotny, Bjørn Sand Jensen, Chris W. Johnson</td></tr><tr><td><em>单位</em></td><td>University of Glasgow, School of Computing Science, Glasgow, Scotland</td></tr><tr><td><em>出处</em></td><td>ICISC</td></tr><tr><td><em>原文地址</em></td><td><a href="https://arxiv.org/abs/1812.04852" target="_blank" rel="noopener">https://arxiv.org/abs/1812.04852</a></td></tr><tr><td><em>源码地址</em></td><td><a href="https://github.com/susperius/icisc_rnnfuzz" target="_blank" rel="noopener">https://github.com/susperius/icisc_rnnfuzz</a></td></tr><tr><td><em>发表时间</em></td><td>2018</td></tr></tbody></table><h1 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h1><p>最近，模糊测试在理论和实际软件测试中越来越受欢迎。这主要归因于在复杂软件系统中触发非预期行为的明显能力，例如，美国模糊Lop（AFL）[28]发现的错误摘要，并通过在微软和谷歌等软件公司中使用模糊测试进一步证明（例如通过他们的开源工具ClusterFuzz [12]），它在许多不同的领域显示了成功和适用性。然而，将一组输入示例上的变异与进化方法相结合的标准方法有其局限性，即增加关键词的必要性和对句法规则的遵从性（例如，在本工作中考虑的HTML）。这些问题可以通过基于生成的模糊器解决，这些模糊器能够遵守这些规则，使用正确的关键字并生成新的输入。传统上，开发基于生成的模糊器所需的时间取决于输入规范的复杂性。例如，为网络协议开发生成器的时间较少，与使用各种字段和状态实现文件传输协议（FTP）[16]相比，它具有三个不同可能值的单个字段。此外，有必要在引入的错误和总体正确性之间找到适当的平衡，以触发导致意外行为的代码路径。</p><p>开发基于生成的模糊器的主要瓶颈是需要严格理解和实现输入文件格式。因此，必须仔细研究潜在的复杂输入规范，将其转换为测试用例生成器，然后需要对其进行微调，以便在测试用例中找到正确性和引入错误之间的正确平衡。这种隐式优化过程通过生成在给定规范的某些区域中偏离的测试用例来寻求最大化代码覆盖，因此能够执行不同的低级执行路径。因此，很明显，可以自动推导或减少输入规范的方法将能够通过更快地部署基于生成的模糊测试技术来加速软件测试。这可能会导致软件安全性和稳定性的提高。</p><p>学习输入规范（例如语法规则）显然不是微不足道的，特别是由于可以应用输入规范的长时间依赖性。这些依赖性对特定位置的可能输出具有直接影响，因此必须通过学习算法捕获以产生规范附加输出。然而，生成机器学习模型的最新进展（[26]，[3]，[6]，[2]）已经证明了机器学习模型如何用于从实例中学习复杂的规则和分布，并从获得的知识中生成新的例子。</p><p>Godefroid等人的模糊测试已经对这些进行了改进[11]。他们演示了如何使用深度神经网络生成PDF对象，这些对象被用作渲染引擎的输入。这些输入文件能够在渲染引擎中触发新指令。然而，他们关注的是学习正确的输入结构和模糊测试之间的紧张关系，换句话说，他们在遵守学习规范和偏离规范之间寻求平衡。他们没有提供对学习过程本身的分析，也没有对基于简单变异的基线进行比较。此外，他们没有提供有关基线与其拟议抽样策略之间重叠的任何信息。为了在模糊测试中使用深度学习模型，重要的是要看它是否值得探索和训练。因此，有必要将其与易于实现的方法进行比较，如简单的变异算法。对不同方法之间现有重叠的分析还可以更深入地了解模型和采样选择，因为在测试期间触发尽可能多的新执行路径以找到触发意外行为的路径非常重要。</p><p>在这项工作中，我们研究了如何训练具有不同类型细胞的递归神经网络（RNN）并将其用作HTML模糊器。模型在基于生成的HTML-fuzzer创建的数据集上进行训练，这使我们能够快速，系统地调整数据集大小和复杂性。<br>我们使用这些模型从生成的概率分布中生成新的HTML标记，这些标记用于形成测试用例。这些是用Firefox [19]执行的，用于收集他们的代码覆盖率数据，并与来自数据集的HTML标记和简单变异数据集生成的基线进行比较。因此，本文的贡献包括： </p><ul><li><p>用于训练和评估具有不同类型细胞的递归神经网络的系统且稳健的方法，用于HTML模糊测试。</p></li><li><p>用于模型选择的过程和度量，并比较机器学习模糊器与标准和基于普通突变的方法（包括基于相似性的分析）</p></li><li><p>对Web浏览器进行广泛的实证评估，证明学习的模糊测试器能够胜过标准测试方法。</p></li><li><p>通过Github 开源了实现代码和数据。</p></li></ul><h1 id="2-背景"><a href="#2-背景" class="headerlink" title="2.背景"></a>2.背景</h1><h2 id="2-1模糊测试"><a href="#2-1模糊测试" class="headerlink" title="2.1模糊测试"></a>2.1模糊测试</h2><p>模糊测试是一种动态软件测试方法，因此动态意味着被测软件实际上是与静态分析相对应的。模糊测试的目标是引发在早期测试阶段未检测到的意外行为，因此测试中的软件使用由所谓的模糊器创建的输入执行。这些输入不完全符合基础输入规范，以便找到导致触发意外行为的状态的路径。我们对非预期行为采用广义定义，这使其适用于各种软件和设备[27]。例如，在模糊测试桌面软件期间，意外行为可能是正在运行的进程的终止，甚至可能是对进程进行控制的可能性。在Web应用程序测试期间，非预期行为可能被定义为信息泄漏或规避访问限制，这两种情况都可能由于SQL注入漏洞而发生，其中任意输入用作有效的SQL语句。</p><p>正如这些例子所强调的那样，如果可以为攻击者提供优势，那么意外行为就会变得更加严重。这里的优势可能意味着从访问受限信息到接管设备的控制。为了找到这些漏洞，使用了模糊测试。模糊测试期间的一般工作流程如图1所示。测试本身分为两部分，第一部分是测试用例生成，第二部分是行为分析。通常，在模糊测试期间创建测试用例可以分为两类：基于突变和基于生成[27]，[8]和[20]。基于突变的模糊测试使用有效的输入集和变异模糊，以便从输入集中导出新的测试用例。如果输入示例可用（例如JPG文件），则可以快速实现这种类型的模糊测试。主要缺点是基于普通变异的模糊测试创建的测试用例无法快速发现调用树深处的代码路径，因为许多创建的测试用例在早期程序执行阶段被过滤掉。这一类别的一个非常突出和成功的例子是前面提到的fuzzer AFL及其进化突变方法。其次，基于生成的模糊测试使用一种从头开始创建测试样例的方法，例如通过基于语法的创建。在研究输入结构和开发生成器时，这种方法需要付出很多努力，但一般来说它能够发现更深层次的代码路径。但是，必须找到遵守规则和打破规则之间的平衡，以便在目标中引发意外行为。</p><p><img src="/2019/04/15/Recurrent-Neural-Networks-for-Fuzz-Testing-Web-Browsers/1.jpg" alt=""></p><h2 id="2-2-回归神经网络"><a href="#2-2-回归神经网络" class="headerlink" title="2.2 回归神经网络"></a>2.2 回归神经网络</h2><p>许多软件产品的输入数据在互联网上很容易获得（例如HTML，JPG，PNG），深度学习算法已经在不同的使用案例中显示出它们的性能，特别是在大型可用数据集上训练的情况下，例如文本生成[26]，程序创建[3]和机器翻译[6]，[2]。这导致我们在模糊测试期间使用生成模型来创建测试用例。此外，HTML和其他输入格式的结构，其中实际字符或字节依赖于序列中的先前位置导致使用RNN。</p><p>RNN用于建模顺序数据，例如用于文本生成[26]，语言建模和音乐预测[21]。他们使用隐藏状态作为短期记忆，在时间步之间传递信息。传统RNN通过输入x<sub>t</sub>和隐藏状态向量h<sub>t</sub>和输出 y^<sub>t</sub>在时间步骤 t 定义如下:<br>$$<br>h_t = f_h(x_t; h_{t−1}) ; y_t = f_o(h_t);<br>$$<br>f<sub>h</sub>和f<sub>o</sub>分别是隐藏层转换函数和输出函数。因此，输入x<sub>t</sub>可以是N维向量，表示输入结构，例如位置t处的单个像素的RGB值。</p><p>正如Hochreiter [13]和后来的Bengio等人所述[4]，RNN受到消失或爆炸梯度问题的影响。这意味着在训练期间权重更新变得无穷小，这会消耗大量时间但不会导致更好的网络优化。 Hochreiter和Schmidhuber引入了长短期记忆（LSTM）细胞的概念[14]使用这些细胞的RNN不会遭受消失（爆炸）梯度问题。 LSTM单元使用隐藏状态，候选值和三个门，即忘记门，输入门和输出门。门控制了多少信息被遗忘，从输入中使用并分别控制流进入新的隐藏状态。它们是默认的前馈神经网络，每个都有自己的可训练参数。</p><p>另一种流行的RNN细胞，门控递归单位（GRU）由Cho等人引入 [6]。该单元仅使用两个门，一个重置门和一个更新门。这里，重置门控制忘记过去隐藏状态的哪些信息，并且更新门控制信息流进入新的隐藏状态。这种更简单的模型可以说比基于标准LSTM的模型更容易训练。</p><p>当学习用于测试用例生成的输入格式结构时，学习顺序结构的能力（其中存在对先前输入的依赖性）显然是重要的特征。这在例如HTML中尤其明显，其中在开始标记和对应的结束标记之间存在长期依赖性。</p><h1 id="3堆叠RNN用于HTML-Fuzzing"><a href="#3堆叠RNN用于HTML-Fuzzing" class="headerlink" title="3堆叠RNN用于HTML-Fuzzing"></a>3堆叠RNN用于HTML-Fuzzing</h1><p>本工作中使用的模型的基本概念如图2所示。该模型由三个模块组成。首先，输入模块，让X = {x1, x2,… xn}是输入值的序列，其中xt ∈N0 | 1 ≤ t ≤ N，其中xt是表示输入序列中位置t处的字符的自然数。例如，字符’f’在输入序列中的位置t，其分配的数字是17，xt = 17。</p><p>然后输入模块采用这样的xt并将其转换为 I = max（X）+ 1的单热编码矢量 x’t ∈ R^I^，使用0来添加到条目中。<br>设x‘t =（ x’1， x‘ 2，… x‘I）|然后<br>$$<br>x’_j = 0 \forall 1≤ j≤ I：j \neq x_t ∨ x_j = 1 \Leftrightarrow j = x_t<br>$$<br>对于前一个示例字符’f’，所有 x’j = 0，除了x’17，等于1.从整数值转换是必要的，因为我们将输入解释为分类数据（每个字符是它自己的类别），这些类别是在训练过程中作为特征处理。</p><p> 其次，循环模块由LSTM或GRU节点组成，如2.2节所述，s,l ∈N。这里s是节点的内部大小，l是所使用的层的数量，例如，如图2所示对于基于LSTM的模型，l = 2。与Chung等人证明的基本RNN方法相比，LSTM细胞已经证明了高性能增益 [7]。 Cho等人[6]介绍的门控递归单元（GRU）表现类似于LSTM细胞[7]，但Jozefowicz等人 [17]表明LSTM细胞在XML建模过程中表现更好。我们决定评估两个单元的性能，以分析XML建模结果是否可以转换为HTML建模。</p><p><img src="/2019/04/15/Recurrent-Neural-Networks-for-Fuzz-Testing-Web-Browsers/2.jpg" alt=""></p><p>最后，输出层由具有I节点的默认前馈网络组成。它将最后一个回归层ht^l^  ∈ R^s^的输出作为输入值，并且在计算其输出之后应用softmax函数。得到的y’t提供用于预测输入序列的下一个值的概率分布。训练期间的目标是最小化交叉熵损失函数<br>$$<br>L(Θ) = − \frac{1}{N}<br>\sum_{i=1}^N<br>y_ilog(y’_i) + (1 − y_i) log(1 − y’_i);<br>$$<br>其中Θ表示模型的参数（即W和b的集合）。为了找到使上述损失L最小化的Θ，应用ADAM [18]优化算法。它是一种基于梯度的优化算法，与其他算法相比，它只需要一阶梯度并且具有减少的内存占用。此外，Dropout（30％丢失概率）[25]用作正则化。</p><h1 id="4-实验"><a href="#4-实验" class="headerlink" title="4 实验"></a>4 实验</h1><p>以下部分介绍了用于验证我们的RNN应用程序的方法，以生成模糊测试复杂系统中网络安全性的测试用例。</p><p>基本思想是在大量HTML标签上训练具有不同深度的上述神经网络。在训练之后，这些模型用于直接使用给定序列的字符的概率分布来生成HTML标签。然后将生成的输出用作Web浏览器的输入。对该浏览器进行检测，以便在基本块的基础上执行期间收集代码覆盖率数据。然后使用所收集的代码覆盖率数据来与通过执行数据集的HTML标签收集的代码覆盖率数据以及对该HTML标签执行的普通变异策略比较模型的性能。</p><h2 id="4-1环境设置和实现"><a href="#4-1环境设置和实现" class="headerlink" title="4.1环境设置和实现"></a>4.1环境设置和实现</h2><p>模型训练在配备单个NVIDIA GeForce 1080 Ti和NVIDIA GeForce TITAN Xp的Ubuntu 16.04系统上进行，通过利用其并行计算功能缩短了必要的训练时间。这些模型是使用Google的TensorFlow框架[1]及其Python绑定实现的。该框架已经为我们的模型提供了必要的单元类型，优化算法和损失函数，缩短了开发时间。</p><p>代码覆盖率数据是在运行Ubuntu 16.04和Firefox 57.0.1的虚拟机（VM）上收集的，它允许在所谓的无头模式下运行。在此模式下，Firefox不显示图形用户界面，但仍会呈现网页。我们还修改了标准配置，以便禁用内部服务，以避免尽可能多的错误代码覆盖数据。<br>此外，安全模式已禁用，因为在自动代码覆盖率收集期间，Firefox未正确关闭，因此可能会在几个测试用例后尝试以安全模式启动。无头模式的使用还节省了代码覆盖率收集期间的时间，这是由DynamoRIO的drcov工具收集的（参见第4.4小节）。 VM本身使用16 GB的RAM和固态硬盘。 VM用于通过克隆和部署到多个主机系统来促进并行数据收集。</p><h2 id="4-2数据集生成"><a href="#4-2数据集生成" class="headerlink" title="4.2数据集生成"></a>4.2数据集生成</h2><p>为了提供可重复和可控的实验，训练（和地面实况）数据集由PyFuzz2 [24]中包含的现有HTML-fuzzer生成。它提供了一个可控制的发生器，从而确保与从互联网收集数据集相比，训练数据集内变化的不确定性更小。因此，可以在每个标记的基础上控制生成的HTML的复杂性，而必须解析收集的集合，然后对不需要的HTML标记进行过滤以控制结果数据集。</p><p>修改了预先存在的模糊器，以避免嵌套HTML标记，删除所有级联样式表并每行输出一个HTML标记。由于没有嵌套HTML标签的限制，有些像td或th被排除在外，因为它们需要在此示例表中使用外部标记。引入这些限制是为了通过降低整体数据集的复杂性来减少对基本问题的关注。这进一步降低了必要的模型复杂性并有效地缩短了训练这些模型所需的时间。</p><p>清单1.1显示了用于训练模型的数据集的摘录，其中突出了上述修改。创建的文件由409,000个HTML标记组成，总大小为36MB。</p><p><img src="/2019/04/15/Recurrent-Neural-Networks-for-Fuzz-Testing-Web-Browsers/3.jpg" alt=""></p><h2 id="4-3训练"><a href="#4-3训练" class="headerlink" title="4.3训练"></a>4.3训练</h2><p>所有模型都经过训练可以预测每个字符的输入其中一个偏移。例如，将清单1.1中第1行的“&lt;h2 i”作为长度为5的输入序列，然后该特定输入序列的标签将为“h2 id”。在训练期间使用的实际序列长度是150个字符，并且每个模型被训练50个时期，这已经足以使模型收敛。为了训练模型，我们使用了前面提到的ADAM [18]优化算法。起始学习率设定为0.001，每10个时期减半。训练模型的分批大小为512。对于所有受过训练的模型，LSTM和GRU单元的内部大小设置为256，层数从1到6变化。层的权重由Glorot uniform initializer初始化[10]。因此，权重是从区间中的均匀分布</p><p><img src="/2019/04/15/Recurrent-Neural-Networks-for-Fuzz-Testing-Web-Browsers/4.jpg" alt=""></p><p>中绘制的，其中nj是层j的内部大小。</p><p>数据集的前30MB用于训练，另外1MB用于验证。所有模型都经过5次不同的训练/验证分裂训练，重复3次，不同的初始化（以减轻极差的局部最小值），这导致每个细胞类型共有90个训练模型。随机选择分割而没有重叠部分。</p><h2 id="4-4-数据收集"><a href="#4-4-数据收集" class="headerlink" title="4.4 数据收集"></a>4.4 数据收集</h2><p>代码覆盖率数据是通过执行由DynamoRIO的drcov [9]插桩Firefox收集的。该工具收集有关被测程序的已执行基本块的数据。收集的代码覆盖率数据被解析为Firefox的libxul.so库中唯一执行的基本块，其中包括负责HTML呈现的整个Web引擎。即使重新启动过程，也可以识别这些基本块，因为记录的数据使用基本块与存储器中库的基址的偏移量，并且对于固定版本，此偏移量始终相同。因此，基本块被定义为具有单个入口（分支目标）和单个出口（分支指令）的机器指令的线性序列。</p><p>所有测试用例都包含一个基本的HTML模板，HTML标签插入到body标签中。初步实验表明，多次执行相同的测试用例会返回不同的代码覆盖率数据。这是由于捆绑在libxul.so库中的其他函数，它们不是Web引擎本身的一部分。例如，这些功能可以仅在多次重启之后或以固定的时间间隔执行。为了识别相应的基本块，执行空白HTML模板1024次，并将结果代码覆盖存储起来供以后使用。</p><p>通过使用HTML模糊器创建6×16384 HTML标签来建立比较基线然后使用16384个HTML标签的每个集合来创建两个数据集，一个包含64个文件，每个文件具有256个HTML标签，第二个包含128个文件包含128个HTML标签。这导致了12个数据集。</p><p>通过使用HTML模糊器创建6×16384 HTML标签来建立比较基线然后使用16384个HTML标签的每个集合来创建两个数据集，一个包含64个文件，每个文件具有256个HTML标签，第二个包含128个文件包含128个HTML标签。这导致了12个数据集。<br>为了建立第二个比较基线，通过改变数据集测试用例并从中收集代码覆盖率来创建其他测试集。应用了一个简单的变异函数，其中一个位置被随机选择的字符（只有已经存在于数据集中的字符）替换。结果是另外20个测试用例集，10组由128个案例组成，每个案例有128个HTML标签，10个组由64个案例组成，每个案例有256个HTML标签，总共有1920个案例。<br>替换概率在0：1％和51.2％之间变化。这样做是为了确保存在差异，因此有动机使用经过训练的模型来创建测试用例，而不是实现基于简单变异的方法。<br>对于每个训练的模型，生成总共16384个HTML标签，然后用于创建两组不同的测试用例。第一组每个案例使用128个HTML标签，每个模型训练产生128个案例，而第二个案例每个案例使用256个HTML标签，每个模型产生64个案例。这样做是为了分析HTML标记对代码覆盖率的影响，并观察与模型性能的关系。 HTML标签是通过使用“&lt;”字符作为起始输入生成的，从得到的概率分布中抽取下一个字符，然后将其用作新输入。重复此操作直到采样“\n”（换行符），因为它标记了HTML标记的结束。</p><p>最后，计算来自测试用例的基本块集合和空白案例之间的集合差异，以过滤掉上述不相关的基本块。</p><h2 id="4-5-结果"><a href="#4-5-结果" class="headerlink" title="4.5 结果"></a>4.5 结果</h2><p>训练阶段已显示两种细胞类型之间的行为差异。基于LSTM的模型显示平均验证损失和标准偏差降低至三层，如图3a所示，之后有所增加。特别是，与其他模型相比，6层模型显示出较大的标准偏差和平均验证损失的大幅增加。这表明这些模型具有太多参数，以便对我们的问题和训练集进行训练。从一般的机器学习角度来看，这种行为是可以预期的，并且因为与使用生成神经网络的其他类似应用相比，训练过程是相同的，例如生成文本。</p><p>相比之下，基于GRU的模型的训练显示从1层模型到2层情况的小幅增加，但之后随着标准偏差的总体小差异而减小。这表明基于GRU的模型或者更适合于再现输入结构，或者没有达到基于6层LSTM的模型的整体复杂性，这也通过比较这些模型的可训练参数来支持。基于GRU的模型有2, 276,971比3, 026, 795。</p><p><img src="/2019/04/15/Recurrent-Neural-Networks-for-Fuzz-Testing-Web-Browsers/5.jpg" alt=""></p><p><img src="/2019/04/15/Recurrent-Neural-Networks-for-Fuzz-Testing-Web-Browsers/6.jpg" alt=""></p><p>总的来说，验证丢失的一个小的数字差异可能导致生成的HTML标签的质量有很大差异。例如，清单1.2显示了由1层LSTM模型生成的摘录。它几乎不可识别为HTML，并且模型没有生成现有的HTML开放和结束标记，并且在这个特定示例中，两个生成的HTML属性拼写错误。与此相反，清单1.3显示了由3层LSTM模型生成的两个HTML标记。两者都只使用现有的HTML标记，但第二个不使用正确的结束标记和拼写错误的一个属性名称。图4提供了关于两种细胞类型模型之间质量差异的进一步证据。它显示了每个标记的HTML错误率如何跟随验证损失的趋势，并突出显示小差异对HTML质量的影响很大。 6层LSTM HTML错误率的高扩散反映了训练期间观察到的大标准偏差。</p><p><img src="/2019/04/15/Recurrent-Neural-Networks-for-Fuzz-Testing-Web-Browsers/7.jpg" alt=""></p><p><img src="/2019/04/15/Recurrent-Neural-Networks-for-Fuzz-Testing-Web-Browsers/8.jpg" alt=""></p><ul><li><strong>具有128个HTML标签的测试用例</strong></li></ul><p>在 代码覆盖性能方面，整体趋势也遵循验证损失和标准偏差，其中较小的验证损失和标准偏差表示更好的性能。图5a显示了每层两种细胞类型的总发现基本块。它强调两种类型的4层模型和GRU 5和6层模型都能够发现数据集范围内的基本块，甚至超越它。</p><p>此外，图6a显示了基本块数量与性能最佳数据集的差异。它表明所有模型都能够发现不是由数据集触发的基本块，而5层GRU模型平均表现最佳。与不同的突变组相比，最大重叠率达到90％，突变几率为1.6％，这并不奇怪，因为相同的突变组与性能最佳的数据集重叠87.6％，如同图7.表现最佳的5层GRU模型与不同突变机会的结合重叠78％，突出了模型发现基本块的能力，这是简单突变方法无法触发的。总体上表现最佳的模型也是与数据集重叠最多的模型。</p><p><img src="/2019/04/15/Recurrent-Neural-Networks-for-Fuzz-Testing-Web-Browsers/9.jpg" alt=""></p><ul><li><strong>具有256个HTML标记的测试用例</strong></li></ul><p>具有256个HTML标记的测试用例的代码覆盖率结果各自显示类似的探索，但总体性能略低，如图5b和图6b所示。预期整体性能较低，因为两个运行基本上使用相同的HTML标签，并且只有插入的HTML标签的数量不同。</p><p><img src="/2019/04/15/Recurrent-Neural-Networks-for-Fuzz-Testing-Web-Browsers/10.jpg" alt=""></p><p>就绝对基本块而言，4层模型是最好的基于LSTM的模型，但是在此设置中它没有到达数据集覆盖区域。然而，基于4层，5层和6层GRU的模型能够到达数据集覆盖区域，其中6层模型具有最多数量的唯一触发的基本块。<br>考虑到与突变测试用例的重叠，总体结果与128个HTML标签的情况相同。表现最佳的四层模型与74.6％的突变集平均重叠。这表明256个HTML标签案例也能够在Web渲染引擎中触发新的代码路径。</p><h1 id="5讨论"><a href="#5讨论" class="headerlink" title="5讨论"></a>5讨论</h1><p>结果表明，使用基于RNN的模型成功训练模型和生成测试HTML案例确实是可能的。但是，监控此过程以获得稳健的结果至关重要，例如，6层LSTM模型无法以可靠的方式进行训练。这很可能是由于缺乏训练数据或优化中涉及的大量参数。</p><p>一旦对模型进行了训练，结果表明平均验证损失可以用作良好的初始选择标准，用于选择用于生成测试用例的良好模型，尽管隐式耦合代码覆盖度量。这是特别有趣的，因为在模型选择阶段没有可用的代码覆盖数据，并且在模糊测试期间覆盖尽可能多的代码路径对于发现软件错误很重要。结果还表明，HTML错误率可用于确定良好的生成模型，从而增加选择过程。这尤其有用，因为仅平均验证损失和标准偏差可能表明两个模型之间的差异较小，例如参见清单1.2和1.3。这些模型之间的最高平均验证损失差异≤0.02，但HTML错误率的差异为0.3。这意味着性能最差的单层LSTM模型每个标签的误差是最佳性能的3层LSTM模型的两倍。</p><p>总体而言，表现最佳的模型比其他模型生成更有效的HTML标签，从而导致使用现有的HTML标签。那些生成的和通常有效的HTML标签并不总是用正确的相应HTML标签关闭。这导致性能最佳的模型偶然构建嵌套的有效HTML标记，因为这些模型使用有效的开始HTML标记，但不生成相应的结束HTML标记。但是，这可能仍会在文件的后续阶段生成。假定的呈现行为和嵌套HTML标记的创建会触发基线集未触发的代码路径，因为在基线集中，每个打开的标记都会被关闭，每行中都有相应的结束标记。</p><p>LSTM模型与基线集之间的重叠基本块（参见图7a）的相似性低于128个HTML标签情况下与突变集和彼此之间的模型的重叠。这可能表明模型无法完全复制给定的输入结构，因此另一个模型选择更适合学习此结构，或者所提供的训练集太小而无法使用所选的模型体系结构捕获输入结构。对于GRU模型，表现最佳的模型还显示与数据集的重叠高于具有变异集的重叠（参见图7b）。这进一步加强了这样的假设，即模型必须达到一定的质量才能表现良好。</p><p>总的来说，我们能够证明特别是基于GRU的RNN能够创建HTML标签，然后可以在浏览器的模糊测试中使用。至关重要的是，生成的HTML测试用例还能够触发大量独特的基本块，而数据集的基线和简单突变方法无法实现这些基本块。</p><p><img src="/2019/04/15/Recurrent-Neural-Networks-for-Fuzz-Testing-Web-Browsers/11.jpg" alt=""></p><h1 id="6-相关工作"><a href="#6-相关工作" class="headerlink" title="6 相关工作"></a>6 相关工作</h1><p>最接近的相关工作由Godefroid等人完成 [11]。他们使用两层堆叠RNN来研究可实现的代码覆盖率，以对PDF对象进行采样，并重点关注训练持续时间对此的影响。将他们实现的代码覆盖率结果与基线进行比较，该基线是从训练集中随机选择的。与此相反，我们使用模型在训练阶段未见的数据来建立我们的比较基线。此外，他们分析了创建测试用例的不同方法并对其进行了比较。他们还强调了学习和模糊测试之间观察到的紧张关系，并提出了一种名为SampleFuzz的算法。如果模型的最高预测概率高于某个阈值并且随机抛硬币成功，则该算法使用最低预测概率。虽然我们的工作研究了不同的输入格式，即HTML，与PDF对象相比，它是一种结构更依赖的输入格式。我们还研究了模型深度对结果代码覆盖率的影响。我们无法观察到前面描述的学习和模糊测试之间的紧张关系。这可能与我们训练集的相对较大的大小有关，或者表明他们的模型开始过度拟合训练样本，因此需要额外的随机性来产生新的测试用例。无论如何，我们没有确定是否需要引入额外的随机值（例如，通过使用SampleFuzz）。</p><p>其他相关工作在执行期间利用控制和数据流来生成新的测试用例。 Rawat等人[23]利用所谓的进化算法来推导新的测试用例。而Hochele等人[15]从收集的执行信息中导出输入语法。这两种方法都需要直接访问被测程序以对其进行检测并收集必要的数据。相反，我们的方法能够直接从输入示例中学习输入结构，这缩短了设计和学习过程。</p><p>Bohme等人提出了一种利用代码覆盖和基于突变的模糊测试的不同方法 [5]。他们在突变过程中用马尔可夫链增强了AFL。他们的AFLFast调用方法使用Markov链来确定状态转换为新的测试输入。他们已经证明，他们缩短了在一组经过测试的软件中发现错误所需的时间。但是，它们没有提供任何有关高度依赖结构的输入格式的信息，如HTML，这被描述为一般AFL方法的不足之处。</p><p>Pradel等人评估了另一种结合深度学习以便在软件中发现错误的方法 [22]。他们使用训练有素的模型来分类潜在的错误源代码。因此，他们将他们的模型训练为特定错误类别的单独分类器。与之相反，我们训练模型生成输入，然后可以用来触发和观察软件中的错误。此外，他们的方法需要直接访问源代码，而我们需要访问足够的输入示例来训练RNN模型。</p><h1 id="7-结论和未来工作"><a href="#7-结论和未来工作" class="headerlink" title="7 结论和未来工作"></a>7 结论和未来工作</h1><p>我们的工作提供了证据，证明可以使用堆叠的RNN生成HTML标签，以便为浏览器的渲染引擎进行模糊测试生成新的测试用例。结果还清楚地表明，即使训练参数较少，基于GRU的模型也能够胜过LSTM模型。此外，所提出的评估程序和基于相似性的分析表明，数据集与模型生成的测试用例之间的基本块的重叠平均非常低。此外，与简单突变组的重叠平均约为70％，这表明训练的网络能够发现以前未通过具有不同突变机会的幼稚突变方法发现的新代码路径。这提供了一个明确的证据，即只要应用合适的模型选择和分析程序，RNN就可以被训练并用作有效的HTML模糊器。</p><p>我们目前正在寻求以至少三种方式扩展目前的工作：首先，研究更复杂/更合适的神经网络模型对于提高生成的HTML的整体质量是必要的，因为其他流行的Web技术（如JavaScript）不能用于破坏的HTML标签都有效。其次，重要的是验证当前关于真实HTML示例的工作的概括，与此处考虑的模糊器生成的训练数据形成对比。最后，我们正在探索在训练过程中利用收集的代码覆盖率数据的方法，并在发现意外行为或新代码路径时奖励学习算法。我们推测这可以通过强化学习来实现，以系统地权衡模型拟合与探索。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h1&gt;&lt;p&gt;基于生成的模糊测试是一种软件测试方法，能够发现软件中不同类型的错误和漏洞。然而，已知设计和微
      
    
    </summary>
    
      <category term="论文" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/"/>
    
      <category term="fuzzing" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/fuzzing/"/>
    
      <category term="机器学习" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/fuzzing/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="fuzzing" scheme="http://yama0xff.com/tags/fuzzing/"/>
    
      <category term="堆叠RNN" scheme="http://yama0xff.com/tags/%E5%A0%86%E5%8F%A0RNN/"/>
    
      <category term="2019" scheme="http://yama0xff.com/tags/2019/"/>
    
  </entry>
  
  <entry>
    <title>NEUZZ: Efficient Fuzzing with Neural Program Smoothing</title>
    <link href="http://yama0xff.com/2019/04/11/NEUZZ-Efficient-Fuzzing-with-Neural-Program-Smoothing/"/>
    <id>http://yama0xff.com/2019/04/11/NEUZZ-Efficient-Fuzzing-with-Neural-Program-Smoothing/</id>
    <published>2019-04-11T13:05:03.000Z</published>
    <updated>2019-04-15T01:39:12.194Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>Fuzzing已经成为发现软件漏洞的事实上的标准技术。然而，即使是最先进的模糊器也不能很有效地找到难以触发的软件错误。最流行的模糊器使用进化指导来生成可以触发不同错误的输入。这种进化算法虽然快速且易于实现，但常常陷入无效的随机突变序列中。梯度引导优化是进化指导的有前途的替代方案。梯度引导技术已经被证明通过有效利用基础函数的梯度或高阶导数来解决机器学习等领域中的高维结构优化问题，从而显着优于进化算法。然而，梯度引导方法不能直接应用于模糊测试，因为真实世界的程序行为包含许多不连续性，平台和脊，其中基于梯度的方法经常被卡住。我们观察到这个问题可以通过创建一个近似于目标程序的离散分支行为的平滑代理函数来解决。在本文中，我们提出了一种新的程序平滑技术，使用替代神经网络模型，可以逐步学习复杂的，真实世界的程序的分支行为的平滑近似。我们进一步证明，这种神经网络模型可以与梯度引导输入生成方案一起使用，以显着提高模糊测试过程的效率。我们的广泛评估表明，NEUZZ在发现新漏洞和实现更高边缘覆盖率方面，在10个流行的真实世界节目中明显优于10个最先进的灰盒模糊器。 NEUZZ发现31个先前未知的错误（包括两个CVE），其他模糊测试器在10个真实世界的程序中找不到，并且比24小时运行的所有测试的灰盒模糊器实现了3倍的边缘覆盖。此外，NEUZZ在LAVA-M和DARPA CGC bug数据集上也优于现有的模糊器。</p><table><thead><tr><th>relevant information</th><th></th></tr></thead><tbody><tr><td><em>作者</em></td><td>Dongdong She, Kexin Pei, Dave Epstein, Junfeng Yang, Baishakhi Ray, and Suman Jana</td></tr><tr><td><em>单位</em></td><td>Columbia University</td></tr><tr><td><em>出处</em></td><td>IEEE S&amp;P</td></tr><tr><td><em>原文地址</em></td><td><a href="https://arxiv.org/abs/1807.05620" target="_blank" rel="noopener">https://arxiv.org/abs/1807.05620</a></td></tr><tr><td><em>源码地址</em></td><td><a href="https://github.com/Dongdongshe/neuzz" target="_blank" rel="noopener">https://github.com/Dongdongshe/neuzz</a></td></tr><tr><td><em>发表时间</em></td><td>2019</td></tr></tbody></table><h1 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h1><p>模糊测试已成为发现软件漏洞的事实上的标准技术[88]，[25]。模糊测试过程涉及生成随机测试输入并使用这些输入执行目标程序以触发潜在的安全漏洞[59]。由于其简单性和低性能开销，在许多真实世界的程序中，模糊测试在寻找不同类型的安全漏洞方面非常成功[3]，[1]，[30]，[70]，[11]，[78] 。尽管它们有巨大的希望，但流行的模糊测试器，特别是对于大型程序，往往会在尝试冗余测试输入时遇到困难，并且很难找到隐藏在程序逻辑深处的安全漏洞[82]，[36]，[68]。</p><p>从概念上讲，模糊测试是一个优化问题，其目标是找到程序输入，以最大化在给定量的测试时间内发现的漏洞数量[60]。然而，由于安全漏洞往往是稀疏且不规律地分布在程序中，因此大多数模糊测试器旨在通过最大化某种形式的代码覆盖（例如，边缘覆盖）来测试尽可能多的程序代码，以增加其发现安全漏洞的机会。最流行的模糊器使用进化算法来解决潜在的优化问题 - 生成最大化代码覆盖的新输入[88]，[11]，[78]，[45]。进化优化从一组种子输入开始，将随机突变应用于种子以生成新的测试输入，执行这些输入的目标程序，并且仅保留有希望的新输入（例如，那些实现新代码覆盖的输入）作为进一步突变的语料库。然而，随着输入语料库变大，进化过程在到达新代码位置时变得越来越低效。</p><p>进化优化算法的主要限制之一是它们不能利用底层优化问题的结构（即梯度或其他高阶导数）。梯度引导优化（例如，梯度下降）是一种很有前途的替代方法，已被证明在解决包括空气动力学计算和机器学习在内的各种领域中的高维结构优化问题时显着优于进化算法[89]，[46]，[ 38。</p><p>然而，梯度引导优化算法不能直接应用于模糊现实世界的程序，因为它们通常包含大量不连续行为（不能精确计算梯度的情况），因为不同程序分支的行为差别很大[67]，[ 21]，[43]，[20]，[22]。我们观察到可以通过创建近似于目标程序关于程序输入的分支行为的平滑（即，可微分）代理函数来克服该问题。不幸的是，现有的程序平滑技术[21]，[20]会产生令人望而却步的性能开销，因为它们严重依赖于符号分析，但是由于路径爆炸，不完整的环境建模和符号内存建模的大量开销等几个基本限制而无法扩展到大型程序50]，[77]，[14]，[16]，[15]，[35]，[49]。</p><p>在本文中，我们介绍了一种新颖，高效，可扩展的程序平滑技术，该技术使用前馈神经网络（NN），可以逐步学习复杂的，真实世界的程序分支行为的平滑近似，即预测控制流边缘。目标程序由特定的输入执行。我们进一步提出梯度引导搜索策略，其计算并利用平滑近似的梯度（即，NN模型）来识别目标突变位置，其可以最大化目标程序中检测到的错误的数量。我们演示了如何通过在错误预测的程序行为上逐步重新训练模型来改进NN模型。我们发现前馈神经网络是我们任务的自然拟合，因为（i）它们证明了近似复杂非线性函数的能力，如通用逼近定理[33]所暗示的，以及（ii）它们对有效和精确计算梯度/高阶导数[38]。</p><p>我们设计并实施了我们的技术，作为NEUZZ的一部分，NEUZZ是一种新的学习型模糊器。我们将NEUZZ与10个最先进的模糊器进行比较，包括6种不同的文件格式（例如，ELF，PDF，XML，ZIP，TTF和JPEG），平均为47.546行代码，LAVA-M bug数据集[28]和CGC数据集[26]。我们的结果表明，NEUZZ在检测到的错误和实现的边缘覆盖方面始终优于所有其他模糊器。 NEUZZ在其他模糊测试仪未能找到的测试程序中发现了31个以前未知的错误（包括CVE-2018-19931和CVE-2018-19932）。我们对DARPA CGC数据集的测试也证实，NEUZZ在发现不同的错误时可以胜过最先进的模糊器，如Driller [82]。</p><p>我们在本文中的主要贡献如下：</p><ul><li>我们是第一个确定程序平滑的重要性，采用有效的梯度引导技术进行模糊测试。</li><li>我们引入了第一个使用替代神经网络的高效且可扩展的程序平滑技术，以有效地模拟目标程序的分支行为。我们进一步提出了一种增量学习技术，以在更多训练数据可用时迭代地改进替代模型。</li><li>我们证明了替代神经网络模型的梯度可用于有效地生成程序输入，从而最大化目标程序中发现的错误数量。</li><li>我们作为NEUZZ的一部分设计，实施和评估我们的技术，并证明它在各种实际程序以及策划的bug数据集上明显优于10个最先进的模糊器。</li></ul><p>本文的其余部分安排如下。第二部分总结了有关优化和梯度引导技术的必要背景信息。第三部分概述了我们的技术以及一个激励性的例子。第IV节和第V节详细描述了我们的方法和实施。我们在第VI节中介绍了我们的实验结果，并描述了NEUZZ在第VII节中发现的一些样本错误。第八节总结了相关工作，第九节总结了论文</p><h1 id="II-优化基础"><a href="#II-优化基础" class="headerlink" title="II.优化基础"></a>II.优化基础</h1><p>在本节中，我们首先描述优化的基础知识以及梯度引导优化相对于平滑函数的进化指导的益处。最后，我们演示了如何将模糊测试作为优化问题。</p><p>优化问题通常由三个不同的组件组成：参数x的向量，要最小化或最大化的目标函数F（x），以及一组约束函数Ci（x），每个约束函数包括必须满足的不等式或相等性。优化过程的目标是找到参数向量x的具体值，其最大化/最小化F（x），同时满足所有约束函数Ci（x），如下所示。</p><p><img src="/2019/04/11/NEUZZ-Efficient-Fuzzing-with-Neural-Program-Smoothing/1.jpg" alt=""></p><p>这里R，N和Q分别表示实数集，不等式约束指数和等式约束指数</p><p><strong>函数平滑和优化。</strong>优化算法通常在循环中操作，从对参数向量x的初始猜测开始，并逐渐迭代以找到更好的解。任何优化算法的关键组件是它用于从一个x值移动到下一个值的策略。大多数策略利用目标函数F，约束函数Ci以及梯度/高阶导数（如果可用）的值。</p><p>不同优化算法收敛到最优解的能力和效率在很大程度上取决于目标和约束函数F和Ci的性质。通常，可以比具有许多不连续性（例如，脊或平台）的函数更有效地优化更平滑的函数（即，具有明确定义和可计算的导数的函数）。直观地，目标/约束函数越平滑，优化算法就越容易准确地计算梯度或高阶导数，并使用它们系统地搜索整个参数空间。</p><p>对于本文的其余部分，我们特别关注不具有任何约束函数的无约束优化问题，即C =φ，因为它们非常模仿模糊化，即我们的目标域。对于无约束平滑优化问题，梯度引导方法在解决高维结构优化问题时可以明显优于进化策略[89]，[46]，[38]。这是因为梯度引导技术有效地利用梯度/高阶导数有效地收敛到最优解，如图1所示。</p><p><img src="/2019/04/11/NEUZZ-Efficient-Fuzzing-with-Neural-Program-Smoothing/2.jpg" alt=""></p><p><strong>凸度和梯度引导优化。</strong>对于称为凸函数的常见函数类，梯度引导技术非常高效，并且总能收敛到全局最优解[86]。直观地，如果连接函数图上任意两点的直线完全位于图上方或上方，则函数是凸的。<br>更正式地，如果在其域中的所有点x和y满足以下属性，则函数f被称为凸函数：f（tx +（1-t）y）≤ tf（x）+（1-t）f （y）,存在 t 属于[0; 1]。</p><p>然而，在非凸函数中，梯度引导方法可能会陷入局部最优解，其中目标函数（假设目标是最大化）比所有附近的可行点更大但是在整个其他地方存在其他更大的值可行参数值的范围。然而，即使对于这种情况，简单的启发式方法，例如从新的随机选择的起始点重新启动梯度引导方法，已经证明在实践中非常有效[38]，[86]。</p><p><strong>模糊作为无约束的优化。</strong>模糊测试可以表示为无约束优化问题，其目标是最大化测试程序中针对固定数量的测试输入发现的错误/漏洞的数量。因此，目标函数可以被认为是F<sub>p</sub>（x），如果输入x在使用输入x执行目标程序p时触发错误/漏洞，则返回1。然而，这种函数太不正常（即，主要包含平坦的平台和一些非常尖锐的过渡）以便有效地优化。</p><p>因此，大多数灰盒模糊器试图最大化测试代码的数量（例如，最大化边缘覆盖）作为替代代理度量[88]，[11]，[73]，[55]，[22]。这样的目标函数可以表示为F’<sub>p</sub>（x），其中F’返回程序P的输入x所覆盖的新控制流边缘的数量。注意，F比原始函数F相对更容易优化。所有可能的程序输入执行新的控制流边缘往往明显高于触发错误/安全漏洞的输入。</p><p>大多数现有的灰盒模糊器使用进化技术[88]，[11]，[73]，[55]，[22]以及其他特定领域的启发式算法作为其主要的优化策略。在梯度引导优化中选择此类算法的关键原因是大多数真实世界的程序由于沿着不同程序路径的显着不同的行为而包含许多不连续性[19]。这种不连续性可能导致梯度引导优化陷入非最优解。在本文中，我们提出了一种新技术，使用神经网络平滑目标程序，使其适用于梯度引导优化，并演示模糊器如何利用这些策略来显着提高其效率。</p><h1 id="III-我们的方法概述"><a href="#III-我们的方法概述" class="headerlink" title="III.我们的方法概述"></a>III.我们的方法概述</h1><p>图2展示了我们方法的高级概述。我们将在下面详细介绍关键组件</p><p><img src="/2019/04/11/NEUZZ-Efficient-Fuzzing-with-Neural-Program-Smoothing/3.jpg" alt=""></p><p><strong>神经程序平滑。</strong>平滑地逼近程序的不连续分支行为对于精确计算梯度引导优化所必需的梯度或高阶导数至关重要。没有这种平滑，梯度引导的优化过程可能会卡在不同的不连续性/平台上。平滑过程的目标是创建一个平滑的函数，该函数可以模拟程序的分支行为而不会引入大的错误（即，它与原始程序行为的偏差最小）。为此，我们使用前馈神经网络（NN）。<br>正如通用逼近定理[33]所暗示的那样，NN非常适合近似任意复杂（可能是非线性和非凸）的程序行为。此外，NN在设计上也支持对我们的目的至关重要的有效梯度计算。我们通过使用现有的测试输入或现有的进化模糊器生成的测试输入语料库来训练NN，如图2所示。</p><p><strong>梯度引导优化。</strong>一旦经过训练，平滑NN模型可用于有效地计算梯度和高阶导数，然后可利用这些导数更快地收敛到最优解。梯度下降，牛顿方法或类牛顿方法（如L-BFGS算法）的梯度制导算法的不同变体使用梯度或高阶导数来实现更快的收敛[10]，[13]，[65]。平滑NN使得模糊输入生成过程可以使用所有这些技术。在本文中，我们设计，实现和评估了一种简单的梯度引导输入生成方案，该方案适用于基于覆盖的模糊测试，详见第IV-C节。</p><p><strong>增量学习。</strong>任何类型的现有测试输入（只要它们暴露目标程序中的不同行为）都可以用于训练NN模型并引导模糊输入生成过程。在本文中，我们通过运行像AFL这样的进化模糊器来收集一组测试输入和相应的边缘覆盖信息来训练NN。</p><p>然而，由于用于训练NN模型的初始训练数据可能仅涵盖程序空间的一小部分，我们在模糊测试期间观察到新的程序行为时通过增量训练进一步细化模型。增量训练的关键挑战是，如果NN只接受新数据的训练，它可能会完全忘记从旧数据中学到的规则[57]。我们通过设计一种新的基于覆盖的过滤方案来避免这个问题，该方案创建了新旧数据的精简摘要，允许NN在其上进行有效的培训。</p><p><strong>一个激励的例子。</strong>我们在图3中展示了一个简单的激励示例，以展示我们的方法背后的关键洞察力。图3中显示的简单C代码片段演示了许多真实世界程序中常见的类似switch的代码模式。特别地，示例代码计算输入的非线性指数函数（即，pow（3，a + b））。它根据计算函数的输出范围返回不同的值。让我们假设如果函数输出范围在（1,2）中，则执行有缺陷的代码块（标记为红色）。</p><p>考虑像AFL这样的进化模糊器已经设法探索第2行和第9行中的分支但是未能在第5行探索分支的情况。这里的关键挑战是找到将在第5行触发分支的a和b的值。进化模糊器通常会遇到这样的代码，因为通过随机变异找到解决方案的可能性非常低。例如，图3a显示了代码段所代表的原始函数。函数表面从a + b = 0到a + b- e = 0（e -&gt; +0）。为了在模糊测试期间最大化边缘覆盖，进化模糊器只能对输入采用随机突变，因为这种技术不考虑函数表面的形状。相比之下，我们的NN平滑和梯度引导突变旨在利用梯度测量的函数表面形状。</p><p>我们从其他两个分支 训练NN模型的程序行为。 NN模型平滑地近似于程序行为，如图3b和3c所示。然后，我们使用NN模型执行更有效的梯度引导优化，以找到a和b的期望值，并逐步细化模型，直到找到执行目标错误的所需分支。</p><p><img src="/2019/04/11/NEUZZ-Efficient-Fuzzing-with-Neural-Program-Smoothing/4.jpg" alt=""></p><h1 id="IV-方法"><a href="#IV-方法" class="headerlink" title="IV.方法"></a>IV.方法</h1><p>我们在下面详细描述我们方案的不同组成部分。</p><h2 id="A-程序平滑"><a href="#A-程序平滑" class="headerlink" title="A.程序平滑"></a>A.程序平滑</h2><p>程序平滑是使梯度引导优化技术适用于模糊具有离散行为的真实世界程序的重要步骤。没有平滑，梯度引导优化技术对于优化非平滑函数不是非常有效，因为它们往往会陷入不同的不连续性[67]。平滑过程使这种不规则性最小化，因此使梯度引导优化在不连续功能上显着更有效。</p><p>通常，不连续函数 f 的平滑可以被认为是 f 和平滑掩模函数g之间的卷积运算，以产生如下所示的新的平滑输出函数。流行的平滑掩模的一些示例包括不同的高斯和Sigmoid函数。<br>$$<br>f’(x) = \int_{-\infty}^{+\infty}f(a)g(x − a)da<br>$$<br>然而，对于许多实际问题，不连续函数f可能不具有闭合形式的表示，因此不可能分析地计算上述积分。在这种情况下，使用离散版本<br>$$<br>f’（x）= \sum_a f（a）g（x-a）<br>$$<br>并且数值地计算卷积。例如，在图像平滑中，通常使用固定大小的2-D卷积核来执行这种计算。但是，在我们的设置中，f是计算机程序，因此无法通过分析计算相应的卷积。</p><p>程序平滑技术可分为两大类：黑盒和白盒平滑。黑盒方法从f的输入空间中选取离散样本，并使用这些样本以数字方式计算卷积。相比之下，白盒方法会查看程序语句/指令，并尝试使用符号分析和抽象解释来总结它们的效果[21]，[20]。黑盒方法可能会引入大的近似误差，而白盒方法会产生令人望而却步的性能开销，这使得它们对于真实世界的程序来说是不可行的。</p><p>为了避免这些问题，我们使用NN以灰盒方式学习程序行为的平滑近似（例如，通过收集边缘覆盖数据），如下所述。</p><h2 id="B-神经程序平滑"><a href="#B-神经程序平滑" class="headerlink" title="B.神经程序平滑"></a>B.神经程序平滑</h2><p>在本文中，我们对程序平滑提出了一种新的方法，通过使用代理NN模型来基于观察到的程序行为来学习和迭代地改进目标程序的平滑近似。替代神经网络可以平滑地推广到观察到的程序行为，同时还准确地建模潜在的非线性和非凸行为。一旦经过训练，神经网络可用于有效地计算梯度和更高级别的导数，以指导模糊输入生成过程，如图3所示。</p><p><strong>为何选择NN？</strong>正如通用逼近定理[33]所暗示的那样，NN非常适合近似复杂（可能是非线性和非凸）的程序行为。使用NN来学习平滑程序近似的优点如下：（i）NN可以精确地模拟复杂的非线性程序行为并且可以被有效地训练。基于模型的优化的先前工作使用简单的线性和二次模型[24]，[23]，[71]，[52]。然而，这些模型不适合用于建模具有高度非线性和非凸性行为的真实软件; （ii）NN支持有效计算其梯度和高阶导数。因此，梯度引导算法可以在模糊测试期间计算和使用这些信息，而无需任何额外开销; （iii）NN可以概括并学习根据类似输入的行为来预测程序对看不见的输入的行为。因此，NN可以基于其对少量输入样本的行为来潜在地学习整个程序的平滑近似。<br><strong>NN训练。</strong>虽然NN可用于模拟程序行为的不同方面，但在本文中，我们专门用它们来建模目标程序的分支行为（即，预测由给定程序输入执行的控制流边缘）。使用神经网络对分支行为进行建模的挑战之一是需要接受可变大小的输入。与现实世界的程序不同，前馈NN通常接受固定大小的输入。因此，我们设置最大输入大小阈值，并在训练期间使用空字节填充任何较小尺寸的输入。请注意，支持更大的输入不是主要问题，因为现代NN可以轻松扩展到数百万个参数。因此，对于较大的程序，我们可以根据需要简单地增加阈值大小。然而，我们凭经验发现相对适度的阈值产生最佳结果，而较大的输入不会显着提高建模精度。</p><p>形式上，让f：{0x00，0×01,…, 0xff}^m^ -&gt; {0, 1}^n^ 表示将程序输入作为具有大小为m的字节序列的NN，并输出大小为n的边缘位图。设θ表示 f 的可训练权重参数。给定一组训练样本（X, Y），其中X是一组输入字节，Y代表相应的边缘覆盖位图，参数函数f（x,θ）= y的训练任务是获得参数θ ^<br>$$<br> \overlineθ =arg min_θ\sum_{x\in X,y\in Y} L（y, f（x,θ））<br>$$<br>其中L（y, f（x,θ））定义NN的输出与训练集中的真实标签y ∈ Y之间的损失函数。训练任务是找到NN f的权重参数θ以最小化损失，其使用距离度量来定义。特别是，我们使用二进制交叉熵来计算预测位图和真实覆盖位图之间的距离。特别是，让 y <sub>i</sub> 和f<sub>i</sub>（x,θ）分别表示真实数据和 f 预测的输出位图中的第i位。然后，这两者之间的二元交叉熵定义为：<br>$$<br>−\frac{1}{n}\sum_{i=1}^n<br>[y_i · log(f_i(x, θ) + (1 − y_i) · log(1 − f_i(x, θ)]<br>$$<br>在本文中，我们使用前馈完全连接的NN来模拟目标程序的分支行为。前馈架构允许高效计算梯度和快速训练[53]。</p><p>我们的平滑技术对于训练数据的来源是不可知的，因此可以对从现有输入语料库收集的任何边缘覆盖数据训练NN。对于我们的原型实现，我们使用现有的进化模糊器（如AFL）生成的输入语料库来训练我们的初始模型。</p><p><strong>训练数据预处理。</strong>由训练数据执行的边缘覆盖通常倾向于偏差，因为它仅包含程序中所有边缘的一小部分的标签。例如，一些边缘可能总是由训练数据中的所有输入一起运用。一组标签之间的这种类型的相关性在机器学习中被称为多重共线性，这通常会阻止模型收敛到一个小的损失值[34]。为了避免这种情况，我们通过将总是一起出现在训练数据中的边缘合并到一个边缘来遵循降维的常见机器学习实践。此外，我们仅考虑在训练数据中至少激活一次的边缘。这些步骤将标签数量平均从大约65536大幅减少到4000左右。请注意，我们在每次增量学习迭代时重新运行数据预处理步骤，因此一些合并标签可能会因为在模糊测试期间发现新边缘数据时相关性降低而分裂。</p><h2 id="C-梯度引导优化"><a href="#C-梯度引导优化" class="headerlink" title="C.梯度引导优化"></a>C.梯度引导优化</h2><p>不同的梯度引导优化技术，如梯度下降，牛顿法或准牛顿法，如L-BFGS，可以使用梯度或更高阶导数来实现更快的收敛[10]，[13]，[65] 。平滑NN使得模糊输入生成过程可以通过支持梯度和高阶导数的有效计算来潜在地使用这些技术中的任何一种。在本文中，我们专门设计了一个简单的梯度引导搜索方案，该方案对于较小的预测误差具有鲁棒性，以证明我们的方法的有效性。我们将更复杂的技术探索作为未来的工作。</p><p>在描述基于NN梯度的变异策略之前，我们首先提供梯度的形式定义，指示每个输入字节应该改变多少以影响NN f 中最终层神经元的输出（指示改变的边缘覆盖范围在程序中）[80]。这里，每个输出神经元对应于特定边缘，并计算0和1之间的值，总结给定输入字节对特定边缘的影响。 NN f w.r.t.输出神经元的梯度。输入已广泛用于对抗性输入生成[39]，[66]和可视化/理解DNN [87]，[80]，[56]。直观地，在我们的设置中，基于梯度的指导的目标是找到将改变对应于从0到1的不同边缘的最终层神经元的输出的输入。</p><p>给定如IV-B部分中定义的参数NN y = f（θ,x），令 y<sub>i</sub> 表示 f 的最后一层中的第i个神经元的输出，其也可以写为f<sub>i</sub>（θ,x）。 f<sub>i</sub>（θ,x）相对于输入x的梯度G可以定义为G = ▽<sub>x</sub>f<sub>i</sub>（θ, x）= δy<sub>i</sub> / δx。注意，可以容易地计算 f 的梯度w.r.t到θ，因为NN训练过程需要迭代地计算该值以更新θ。因此，通过简单地将θ的梯度的计算替换为x的梯度，也可以容易地计算G.注意，梯度G的维数与输入x的维度相同，在我们的例子中，它是一个字节序列。</p><p><img src="/2019/04/11/NEUZZ-Efficient-Fuzzing-with-Neural-Program-Smoothing/5.jpg" alt=""></p><p>梯度引导优化。算法1显示了梯度引导输入生成过程的概要。关键思想是识别具有最高梯度值的输入字节并对其进行改变，因为它们表明对NN具有更高的重要性，因此具有更高的机会导致程序行为发生重大变化的机会（例如，翻转分支）。</p><p>从种子开始，我们迭代地生成新的测试输入。如算法1所示，在每次迭代时，我们首先利用梯度的绝对值来识别输入字节，该输入字节将导致对应于未捕获边缘的输出神经元的最大变化。接下来，我们检查每个字节的梯度符号以确定突变的方向（例如，递增或递减它们的值）以最大化/最小化目标函数。从概念上讲，我们对梯度符号的使用类似于[39]中介绍的对抗性输入生成方法。我们还将每个字节的变异限制在其合法范围内（0-255）。第6行和第10行表示使用剪辑功能来实现这种边界。</p><p>我们用一个小的变异目标（算法1中的k）开始输入生成过程，并指数增加要变异的目标字节数，以有效地覆盖大的输入空间。</p><h2 id="D-通过增量学习进行细化"><a href="#D-通过增量学习进行细化" class="headerlink" title="D.通过增量学习进行细化"></a>D.通过增量学习进行细化</h2><p>梯度引导输入生成过程的效率在很大程度上取决于代理NN对目标程序的分支行为进行建模的准确程度。为了获得更高的准确度，当在模糊测试过程中观察到不同的程序行为时（即，当目标程序的行为与预测的行为不匹配时），我们逐步细化NN模型。我们使用增量学习技术通过在触发新边缘时学习新数据来更新NN模型。</p><p>NN改进背后的主要挑战是阻止NN模型在训练新数据时突然忘记先前从旧数据中学到的信息。这种遗忘是深度学习文献中众所周知的现象，并被认为是稳定性 - 可塑性困境的结果[58]，[8]。为了避免这种遗忘问题，NN必须足够改变权重以学习新任务，但不能过多地使其忘记以前学过的表示。</p><p>细化NN的最简单方法是将新训练数据（即程序分支行为）与旧数据一起添加，并再次从头开始训练模型。但是，随着数据点数量的增加，这种再训练变得更难以扩展。先前的研究试图主要使用两种广泛的方法来解决这个问题[44]，[51]，[31]，[75]，[29]，[40]，[76]。第一个尝试为新旧模型保留单独的表示，以最大限度地减少使用分布式模型，正则化或从多个模型中创建集合的遗忘。第二种方法维护旧数据的摘要，并在新数据上重新训练模型以及汇总的旧数据，因此比完全再训练更有效。我们将感兴趣的读者引用到Kemker等人的调查中。 [48]了解更多详情。</p><p>在本文中，我们使用基于边缘覆盖的过滤来仅保留触发新分支的旧数据以进行重新训练。随着新的训练数据变得可用，我们确定实现新边缘覆盖的数据，将它们与过滤的旧训练数据放在一起，并重新训练NN。这种方法有效地防止训练数据样本的数量在重新训练迭代次数上急剧增加。我们发现我们的过滤方案可以轻松支持多达50次重新训练，同时仍将训练时间保持在几分钟之内。</p><h1 id="V-实现"><a href="#V-实现" class="headerlink" title="V.实现"></a>V.实现</h1><p>在本节中，我们将讨论我们的实现以及如何微调NEUZZ以实现最佳性能。我们已经通过GitHub在<a href="http://github.com/dongdongshe/neuzz发布了我们的实现。我们所有的测量都是在运行Arch" target="_blank" rel="noopener">http://github.com/dongdongshe/neuzz发布了我们的实现。我们所有的测量都是在运行Arch</a> Linux 4.9.48并使用Nvidia GTX 1080 Ti GPU的系统上进行的。</p><p><strong>NN架构。</strong>我们的NN模型在Keras2.1.3 [5]中实现，Tensorflow-1.4.1 [6]作为后端。 NN模型由三个完全连接的层组成。隐藏层使用ReLU作为其激活功能。我们使用sigmoid作为输出层的激活函数来预测控制流边缘是否被覆盖。 NN模型被训练50个时期（即，整个数据集的50次完整通过）以实现高测试准确度（平均约95％）。由于我们使用简单的前馈网络，所有10个程序的训练时间不到2分钟。即使在运行频率为3.6GHz的Intel i7-7700上进行纯CPU计算，训练时间也不到20分钟。</p><p><strong>训练数据收集。</strong>对于每个测试的程序，我们在单个核心机器上运行AFL-2.5.2 [88]一小时，以收集NN模型的训练数据。为10个项目收集的平均训练输入数量约为2K。得到的语料库进一步分为训练和测试数据，比例为5：1，其中测试数据用于确保模型不会过度拟合。我们使用10KB作为阈值文件大小，用于从AFL输入语料库中选择我们的训练数据（平均90％的AFL生成的文件低于阈值）。</p><p><img src="/2019/04/11/NEUZZ-Efficient-Fuzzing-with-Neural-Program-Smoothing/6.jpg" alt=""></p><p><strong>突变和再培训。</strong>如图2所示，NEUZZ迭代运行以生成1M突变并逐步重新训练NN模型。我们首先使用算法1中描述的变异算法来生成1M突变。我们将参数 i 设置为10，为种子输入生成5,120个突变输入。接下来，我们在目标程序中随机选择代表100个未探测边缘的100个输出神经元，并从两个种子生成10,240个突变输入。最后，我们使用AFL的fork服务器技术[54]执行具有1M突变输入的目标程序，并使用覆盖新边缘的任何输入进行增量重新训练。</p><p><strong>模型参数选择。</strong> NEUZZ的成功取决于训练模型和产生突变的不同参数的选择。在这里，我们通过经验探索确保最佳边缘覆盖四个程序的最佳参数：readelf，libjpeg，libxml和mupdf。结果总结在表I中。</p><p>首先，我们评估每个初始种子需要突变的关键字节数（算法1的第1行中的参数ki）。我们选择k = 2，如第IV-C节所述，并显示通过三次迭代（i = 7,10,11算法1第1行中的）实现的覆盖率，每次迭代有1M个突变。对于所有四个程序，较小的突变（每个突变更改的字节更少）可能导致更高的代码覆盖率，如表1a所示。 i = 11的最大值实现了所有四个程序的最小代码覆盖率。这个结果可能是由于算法1中的第4和第8行 - 在单个种子上浪费了太多突变（超出1M突变预算），而没有尝试其他种子。但是，最佳突变字节数在四个程序中有所不同。对于readelf和libxml，i的最佳值为10，而libjpeg和mupdf的最佳值为7。由于在i = 7和i = 10之间实现的代码覆盖率的差异不大，我们选择i = 10用于剩余的实验。</p><p>接下来，我们通过改变每个隐藏层中的层数和神经元数来评估NN模型中超参数的选择。特别地，我们将NN架构分别与每层的1和3个隐藏层以及4096和8192个神经元进行比较。对于每个目标计划，我们使用相同的训练数据来训练四种不同的NN模型并生成1M突变以测试所实现的边缘覆盖。对于所有四个程序，我们发现具有1个隐藏层的模型比具有3个隐藏层的模型执行得更好。我们认为这是因为1隐藏层模型足够复杂以模拟目标程序的分支行为，而较大的模型（即具有3个隐藏层）相对较难训练并且还倾向于过度拟合。</p><h1 id="VI-评估"><a href="#VI-评估" class="headerlink" title="VI.评估"></a>VI.评估</h1><p>在本节中，我们评估NEUZZ的错误发现性能，并获得与其他最先进的模糊器相关的边缘覆盖率。具体来说，我们回答以下四个研究问题：</p><ul><li>RQ1. NEUZZ可以找到比现有模糊器更多的错误吗？</li><li>RQ2. NEUZZ能否实现比现有模糊器更高的边缘覆盖？</li><li>RQ3. NEUZZ能否比现有的基于RNN的模糊器表现更好？</li><li>RQ4.不同的模型选择如何影响NEUZZ的性能？</li></ul><p>我们首先描述我们的研究对象和实验设置。</p><h2 id="A-研究对象"><a href="#A-研究对象" class="headerlink" title="A.研究对象"></a>A.研究对象</h2><p>我们在三种不同类型的数据集上评估NEUZZ：（i）10个真实世界的程序，如表IIb所示，（ii）LAVA-M [28]，以及（iii）DARPA CGC数据集[26] 。为了演示NEUZZ的性能，我们将NEUZZ检测到的边缘覆盖范围和缺陷数量与10个最先进的模糊器进行比较，如表IIa所示。</p><p><img src="/2019/04/11/NEUZZ-Efficient-Fuzzing-with-Neural-Program-Smoothing/7.jpg" alt=""></p><h2 id="B-实验设置"><a href="#B-实验设置" class="headerlink" title="B.实验设置"></a>B.实验设置</h2><p>我们的实验设置包括以下两个步骤：首先，我们运行AFL一小时以生成初始种子语料库。然后，我们使用相同的初始种子语料库运行每个模糊器一个固定的时间预算，并比较它们实现的边缘覆盖率和发现的错误数量。具体而言，10个真实世界程序，LAVA-M数据集和CGC数据集的时间预算分别为24小时，5小时和6小时。对于进化模糊器，种子语料库用于初始化模糊过程。对于基于学习的模糊器（即，基于NEUZZ和RNN的模糊器），使用相同的种子语料库来生成训练数据集。对于KleeFL，一种由Klee和AFL组成的混合工具，我们运行Klee一小时以生成额外的种子，然后将它们添加到原始种子语料库中，用于随后的24小时模糊测试过程。请注意，我们仅报告每个模糊器的变异输入所涵盖的附加代码，而不包括初始种子语料库中的覆盖信息。</p><p>在RQ3中，我们评估和比较NEUZZ与基于RNN的模糊器的性能。基于RNN的模糊器比NEUZZ的训练时间长20倍。然而，为了关注这两种突变算法的功效，我们评估固定数量突变的边缘覆盖率，以排除这些不同的训练时间的影响。我们还进行了独立评估，比较了这两种模型的训练时间成本。在RQ4中，我们还评估了固定数量突变的边缘覆盖率，以排除不同模型中不同训练时间成本的影响。</p><h2 id="C-结果"><a href="#C-结果" class="headerlink" title="C.结果"></a>C.结果</h2><h3 id="RQ1-NEUZZ可以找到比现有模糊器更多的错误吗？"><a href="#RQ1-NEUZZ可以找到比现有模糊器更多的错误吗？" class="headerlink" title="RQ1. NEUZZ可以找到比现有模糊器更多的错误吗？"></a>RQ1. NEUZZ可以找到比现有模糊器更多的错误吗？</h3><p>为了回答这个RQ，我们评估了NEUZZ w.r.t.三种设置中的其他模糊器：（i）检测现实世界中的错误。 （ii）检测LAVA-M数据集中注入的错误[28]。 （iii）检测CGC错误。我们详细描述结果。</p><p><strong>（i）检测现实世界的错误。</strong>我们比较了NEUZZ和其他模糊器在24小时运行时发现的错误和崩溃的总数，给出相同的种子语料库。 NEUZZ和其他模糊器发现了五种不同类型的错误：内存不足，内存泄漏，断言崩溃，整数溢出和堆溢出。为了检测不一定会导致崩溃的内存错误，我们使用AddressSanitizer [4]编译程序二进制文件。我们通过比较AddressSanitizer报告的堆栈跟踪来测量发现的唯一内存错误。对于不会导致AddressSanitizer生成错误报告的崩溃，我们会检查执行跟踪。通过手动分析触发无限循环的输入找到整数溢出错误。我们使用未定义的行为清理程序进一步验证整数溢出错误[7]。结果总结在表III中。</p><p><img src="/2019/04/11/NEUZZ-Efficient-Fuzzing-with-Neural-Program-Smoothing/8.jpg" alt=""></p><p>NEUZZ在6个程序中查找所有5种类型的错误。 AFL，AFLFast和AFL-laf-intel发现了3种类型的错误 - 它们没有找到任何整数溢出错误。其他模糊器只发现2种类型的错误（即内存泄漏和断言崩溃）。 AFL可以在程序size上出现堆溢出错误，而NEUZZ可以在程序nm上找到相同的错误和另一个堆溢出错误。总的来说，NEUZZ发现的错误比第二个最好的模糊器多2倍。此外，strip中的整数溢出错误和nm中的堆溢出错误（仅由NEUZZ发现）已经分配了CVE-2018-19932和CVE-2018-19931，后来由开发人员修复。</p><p><strong>（ii）检测LAVA-M数据集中注入的错误。</strong>创建LAVA数据集是为了通过提供一组注入大量错误的真实程序来评估模糊器的有效性[28]。 LAVA-M是LAVA数据集的子集，由4个GNU coreutil程序base64，md5sum，uniq和who分别注入44,57,28和2136个错误组成。所有的错误都受到四字节magic比较的保护。只有满足条件时才会触发错误。我们将NEUZZ在发现这些缺陷方面的性能与其他最先进的模糊器进行比较，如表IV所示。按照传统做法[22]，[28]，我们使用5小时的时间预算来完成模糊器的运行时间。</p><p><img src="/2019/04/11/NEUZZ-Efficient-Fuzzing-with-Neural-Program-Smoothing/9.jpg" alt=""></p><p>触发LAVA数据集中的magiv条件对于覆盖引导的模糊器来说是一项艰巨的任务，因为模糊器必须在256^4^种可能情况下生成4个连续字节的精确组合。为了解决这个问题，我们使用了一个定制的LLVM传递来检测magic字节检查，如Steelix [55]。但与Steelix不同，我们利用NN的渐变来指导输入生成过程，以找到满足magic检查的输入。我们运行AFL一小时来生成训练数据并用它来训练NN，其梯度识别触发magic字节条件的第一个字节比较的可能关键字节。接下来，我们对与第一个关键字节相邻的每个字节执行局部穷举搜索，以便通过256次尝试解决剩余的三个字节比较中的每一个。因此，我们需要一个NN梯度计算来查找影响魔法检查的字节位置，并且需要4×256 = 1024个试验来触发每个bug。对于程序md5sum，根据LAVA-M作者的最新建议[27]，我们进一步将种子减少到单行，这显着提高了模糊性能。</p><p>如表IV所示，NEUZZ查找程序base64，md5sum和uniq中的所有错误，以及程序的错误数量最多。请注意，LAVA-M作者在所有4个程序中都留下了一些未列出的错误，因此NEUZZ发现的错误总数实际上高于列出的错误数，如结果所示。</p><p>与其他模糊器相比，NEUZZ具有两个关键优势。首先，NEUZZ将搜索空间分成多个可管理的步骤：NEUZZ在AFL生成的数据上训练底层NN，使用计算的梯度到达第一个关键字节，并在找到的关键区域周围执行本地搜索。其次，与VUzzer相反，VUzzer利用目标二进制中硬编码的magic来构建程序输入，NEUZZ的基于梯度的搜索策略不依赖于任何硬编码的magic。因此，它可以找到程序md5sum中的所有错误，它在magic检查之前对输入字节执行一些计算，导致VUzzer失败。Angora（LAVA-M数据集当前最先进的模糊器）相比，NEUZZ在md5sum中发现了3个更多的错误。与Angora不同，NEUZZ使用NN渐变来更有效地触发复杂的magic条件</p><p><strong>（iii）检测CGC错误。</strong> DARPA CGC数据集[2]由DARPA网络大挑战中使用的易受攻击的程序组成。这些程序实现为执行各种任务的网络服务，旨在镜像具有已知漏洞的实际应用程序。程序中的每个错误都受到输入上的一些健全性检查的保护。 数据集附带一组输入作为漏洞的证据。</p><p>我们在50个随机选择的CGC二进制文件中评估NEUZZ，Driller和AFL。由于为每个模糊器运行每个测试二进制文件需要6个小时才能在CPU / GPU上运行，并且我们有限的GPU资源不允许我们并行执行多个实例，我们随机选择50个程序以将总实验时间保持在合理的范围内。与LAVA-M类似，这里我们也运行AFL一小时来生成训练数据并用它来训练NN。我们为所有三个模糊器提供相同的随机种子，让它们运行六个小时。 NEUZZ使用与LAVA-M数据集相同的自定义LLVM传递来检测CGC二进制文件中的magic检查。</p><p>结果（表五）显示，NEUZZ在50个二进制文件中发现31个错误的二进制文件，而AFL和Driller分别找到21个和25个。 NEUZZ发现的有缺陷的二进制文件包括Driller和AFL发现的所有文件。 NEUZZ进一步发现6个新的二进制文件中的错误，AFL和Driller都无法检测到这些错误。</p><p><img src="/2019/04/11/NEUZZ-Efficient-Fuzzing-with-Neural-Program-Smoothing/10.jpg" alt=""></p><p>我们分析了一个示例程序CROMU_00027（如清单1所示）。这是一个ASCII内容服务器，它从客户端获取查询并提供相应的ASCII代码。在用户尝试将命令设置为VISUALIZE后，将触发空指针解除引用错误。 AFL未能在6小时的时间预算内检测到这个错误，因为它在猜测magic字符串方面效率低下。虽然Driller试图通过concolic执行来满足这种复杂的魔术字符串检查，但在这种情况下，它无法找到满足检查的输入。相比之下，NEUZZ可以轻松使用NN渐变来定位程序输入中影响magic比较的关键字节，并找到满足magic检查的输入。</p><p><strong>结果1：NEUZZ在6个不同的程序中找到了31个以前未知的错误，其他模糊器找不到。NEUZZ在寻找LAVA-M和CGC漏洞方面也优于最先进的模糊器</strong></p><h3 id="RQ2-NEUZZ能否实现比现有模糊器更高的边缘覆盖？"><a href="#RQ2-NEUZZ能否实现比现有模糊器更高的边缘覆盖？" class="headerlink" title="RQ2. NEUZZ能否实现比现有模糊器更高的边缘覆盖？"></a>RQ2. NEUZZ能否实现比现有模糊器更高的边缘覆盖？</h3><p>为了研究这个问题，我们比较了24小时固定运行时预算的模糊器。此评估不仅显示模糊器发现的新边缘总数，还显示新边缘覆盖的速度与时间的关系。</p><p><img src="/2019/04/11/NEUZZ-Efficient-Fuzzing-with-Neural-Program-Smoothing/11.jpg" alt=""></p><p><img src="/2019/04/11/NEUZZ-Efficient-Fuzzing-with-Neural-Program-Smoothing/12.jpg" alt=""></p><p>我们从AFL的边缘覆盖率报告中收集边缘覆盖率信息。结果总结在表VI中。对于所有10个真实世界的节目，NEUZZ在边缘覆盖方面明显优于其他模糊器。如图4所示，NEUZZ在第一个小时内可以比其他模糊器获得更多的新边缘覆盖。在程序strip，harfbuz和readelf，NEUZZ在一小时内可以达到1000以上新的边缘覆盖。对于程序readelf和objdump，NEUZZ运行1小时的新边缘覆盖数量甚至超过所有其他模糊器24小时运行的新边缘覆盖数量。这表明NEUZZ具有优越的边缘覆盖能力。对于所有10个节目中的9个，NEUZZ分别实现了比基线AFL 6×，1.5×，9×，1.8×，3.7×，1.9×，10×，1.3×和3×边缘覆盖，以及4.2×，1.3× ，7×，1.2×，2.5×，1.5×，1.5×，1.3×和3×边缘覆盖率均高于所有6个模糊器中的第二高数量。对于代码小于2k的最小程序zlib，NEUZZ与其他模糊器实现了类似的边缘覆盖。我们相信它会在24小时模糊测试后发现这样一个小程序的大部分可能边缘时达到饱和点。显着的优异性能显示了NEUZZ使用渐变覆盖新边缘有效定位和突变关键字节的有效性。 NEUZZ在大型系统中也可以很好地扩展。实际上，对于超过10K行的程序（例如，readelf，harfbuzz，mupdf和libxml），NEUZZ实现了最高的边缘覆盖，其中采用污点辅助的fuzzer（即VUzzer）和符号执行辅助fuzzer（即KleeFL）执行较差或并不能扩展。</p><p>梯度引导变异策略允许NEUZZ探索不同的边缘，而其他基于进化的模糊器经常卡住并重复检查相同的分支条件。此外，NN平滑技术的最小执行开销有助于NEUZZ在较大程序中很好地扩展，而其他高级进化模糊器由于使用了重量级程序分析技术（如污点跟踪或符号执行）而导致高执行开销。</p><p>在进化模糊器中，AFLFast使用优化的种子选择策略，更多地关注稀有边缘，因此在8个程序中实现比AFL更高的覆盖率，特别是在libjpeg，size和harfbuzz中。另一方面，VUzzer在小程序（例如，zlib，nm，objdump，size和strip）的第一个小时内实现了比AFL，AFLFast和AFL-laf-intel更高的覆盖率，但它的导致很快停止并且最终是超过其他模糊器。同时，VUzzer的性能会因readelf，harfbuzz，libxml和mupdf等大型程序而降低。我们怀疑VUzzer的污点跟踪器引入的不精确会导致它在大型程序上表现不佳。 KleeFL使用符号执行引擎Klee生成的其他种子来指导AFL的探索。与VUzzer类似，对于小程序（nm，objdump和strip），KleeFL在开始时具有良好的性能，但其在Klee的额外种子的优势在几小时后逐渐消失。<br>此外，KleeFL基于Klee，无法扩展到具有复杂库代码的大型程序，这是众所周知的符号执行限制。因此，KleeFL在程序libxml，mupdf和harfbuzz上没有结果。与VUzzer和KleeFL不同，NEUZZ不依赖任何繁重的程序分析技术; NEUZZ使用从NN计算的梯度来生成有希望的突变，即使对于较大的程序也是如此。有效的NN梯度计算过程允许NEUZZ在识别影响不同看不见的程序分支的关键字节时比VUzzer和KleeFL更好地扩展，从而实现更多的边缘覆盖。</p><p>AFL-laf-intel使用LLVM传递将复杂的magic比较转换为嵌套的字节比较，然后在转换的二进制文件上运行AFL。它在程序strip上实现了第二高的新边缘覆盖率。但是，比较转换会为常见的比较操作添加额外的指令，从而导致潜在的边缘爆炸问题。边缘爆炸大大增加了边缘冲突的速度，并且损害了进化模糊的表现。此外，这些附加指令会导致额外的执行开销。<br>结果，像频繁比较操作的libjpeg这样的程序遭受显着的减速（例如，libjpeg），并且AFL-laf-intel努力触发新的边缘。</p><p><strong>结果2：与其他灰盒式模糊器相比，NEUZZ可以实现更高的边缘覆盖率（比AFL高4倍，比24小时运行的第二好的高出2.5倍）</strong></p><h3 id="RQ3-NEUZZ能否比现有的基于RNN的模糊器表现更好？"><a href="#RQ3-NEUZZ能否比现有的基于RNN的模糊器表现更好？" class="headerlink" title="RQ3.NEUZZ能否比现有的基于RNN的模糊器表现更好？"></a>RQ3.NEUZZ能否比现有的基于RNN的模糊器表现更好？</h3><p>现有的基于递归神经网络（RNN）的模糊器从过去的模糊测试经验中学习突变模式，以指导未来的突变[72]。这些模型首先从AFL生成的大量突变输入中学习突变模式（由关键字节组成）。接下来，他们使用突变模式为AFL构建一个过滤器，它只允许关键字节上的突变通过，否决所有其他非关键字节突变。我们选择了之前研究的4个项目来评估NEUZZ与基于RNN的模糊器相比100万个突变的性能。我们使用相同的训练数据训练两个NN模型，然后让两个基于NN的模糊器运行产生100万个突变，并比较两种方法实现的新代码覆盖率。我们报告了实现的边缘覆盖率和训练时间，如表VII所示。</p><p><img src="/2019/04/11/NEUZZ-Efficient-Fuzzing-with-Neural-Program-Smoothing/13.jpg" alt=""></p><p>对于所有四个程序，NEUZZ在1M突变方面明显优于基于RNN的模糊器。 NEUZZ比四个程序中基于RNN的模糊器达分别达到8.4×， 4.2×，6.7×和3.7×更多的边缘覆盖。此外，基于RNN的模糊器平均比NEUZZ多20倍的训练开销，因为RNN模型比前馈网络模型复杂得多。</p><p>基于RNN的模糊器与AFL的另外比较表明，使用1小时语料库，前者在libxml和mupdf上的平均边缘覆盖率比AFL高2倍。我们还观察到基于RNN的模糊器否决了AFL产生的大约50％的突变。因此，来自基于RNN的模糊器的1M突变的新边缘覆盖可以实现普通AFL中2M突变的边缘覆盖。这就解释了为什么基于RNN的模糊器在一些程序中发现AFL的新边缘增加了2倍左右。如果AFL在2M突变后卡住，基于RNN的模糊器也会在1M过滤突变后卡住。 <strong>NEUZZ相对于基于RNN的模糊器的关键优势在于，NEUZZ使用基于神经网络的梯度引导搜索获得关键位置，而RNN模糊器尝试以端到端方式对任务进行建模。</strong><br>我们的模型可以区分RNN模型可能遗漏的关键字节的不同影响因素，如我们的实验结果所示。对于突变生成，我们对由相应的贡献因子确定的关键字节进行穷举搜索，而基于RNN的模糊器仍然依赖于AFL的均匀随机突变。</p><p><strong>结果3：NEUZZ，一个基于简单前馈网络的模糊器，通过在不同项目中实现3.7倍到8.4倍的边缘覆盖率，明显优于基于RNN的模糊器</strong></p><h3 id="RQ4-不同的型号选择如何影响NEUZZ的性能？"><a href="#RQ4-不同的型号选择如何影响NEUZZ的性能？" class="headerlink" title="RQ4.不同的型号选择如何影响NEUZZ的性能？"></a>RQ4.不同的型号选择如何影响NEUZZ的性能？</h3><p>NEUZZ的模糊测试性能在很大程度上取决于训练有素的NN的准确性。如第五部分所述，我们凭经验发现具有1个隐藏层的NN模型足以表达真实世界程序的复杂分支行为。在本节中，我们通过探索1个隐藏层架构的不同模型设置来进行消融研究，即，线性模型，没有细化的NN模型，以及具有渐进细化的NN模型。我们评估这些模型对NEUZZ性能的影响。</p><p>为了比较模糊测试性能，我们在4个程序中为每个版本的NEUZZ生成1M突变。我们通过去除隐藏层中使用的非线性激活函数来实现线性模型，从而使整个前馈网络完全线性化。 NN模型由AFL训练相同的种子语料库。接下来，我们从被动学习模型中生成1M突变，并测量这些1M突变所实现的边缘覆盖。最后，我们筛选出突变的输入，这些输入在100万个突变中运行看不见的边缘，并将这些选择的输入添加到原始种子语料库中，以递增地重新训练另一个NN模型并使用它来产生进一步的突变。结果总结在表VIII中。我们可以看到，两个NN模型（有或没有增量学习）都优于所有4个测试程序的线性模型。这表明非线性NN模型可以比简单的线性模型更好地逼近程序行为。我们还观察到增量学习有助于NN实现更高的准确度，从而提高边缘覆盖率。</p><p><img src="/2019/04/11/NEUZZ-Efficient-Fuzzing-with-Neural-Program-Smoothing/14.jpg" alt=""></p><p><strong>结果4：NN模型优于线性模型，增量学习使NN随着时间的推移更加准确。</strong></p><h1 id="VII-BUGS的案例研究"><a href="#VII-BUGS的案例研究" class="headerlink" title="VII. BUGS的案例研究"></a>VII. BUGS的案例研究</h1><p>在本节中，我们提供和分析NEUZZ发现的三种不同类型的错误的样本：整数溢出，内存不足和崩溃诱发错误。<br>我们注意到，由于对极值变量的错误处理导致了大量的程序错误。由于NEUZZ可以枚举从0x00到0xff的所有关键字节（参见算法1第3行），我们设法找到由错误处理的极值引起的大量错误。例如，通过将影响内存分配大小的输入字节设置为极大值，NEUZZ能够在libjpeg，objdump，nm和strip中找到许多内存不足的错误。</p><p><strong>strip的整数溢出。</strong> NEUZZ发现了一个整数溢出错误，可以在strip上产生无限循环。清单2显示了strip程序中的一个函数，它解析输入ELF文件的程序头表中的每个部分，并将所有部分分配给输出ELF文件中的新程序头表。整数溢出发生在清单2的第11行的if条件中，因为NEUZZ将segment_size设置为一个非常大的值。因此，程序陷入无限循环。我们发现在最新版本的Binutils 2.30和旧版本2.26和2.29中都存在此错误。</p><p><strong>libjpeg的内存不足。</strong>在JPEG压缩过程中，每个颜色空间的数据通过相应的采样因子进行下采样，以减小文件大小。<br>根据JPEG标准，采样因子必须是1到4之间的整数。在解压缩过程中使用此值来确定需要分配多少内存，如清单4所示.NEUZZ设置一个较大的值，导致过多要为图像数据分配的内存，导致内存不足错误。利用libjpeg显示图像，可能会利用此类错误在服务器上启动拒绝服务攻击。</p><p><img src="/2019/04/11/NEUZZ-Efficient-Fuzzing-with-Neural-Program-Smoothing/15.jpg" alt=""></p><p><strong>readelf的崩溃。</strong> ELF文件由文件头，程序头，节头和节数据组成。根据ELF规范，ELF头包含位于第60个字节的字段e_shnum，用于64位二进制，它指定ELF文件中的节数。 NEUZZ将输入文件的节数设置为0.如清单3所示，如果节的数量等于0，则实现返回一个NULL指针，该指针被后续代码取消引用，触发崩溃</p><h1 id="VIII-相关工作"><a href="#VIII-相关工作" class="headerlink" title="VIII .相关工作"></a>VIII .相关工作</h1><p><strong>程序平滑。</strong> Parnas等 [67]观察到不连续性是开发安全可靠软件背后的基本挑战之一。 Chaudhury等人 [21]，[18]，[19]提出了程序平滑的想法，以促进程序分析，并使用抽象解释和符号执行提出了严格的平滑算法。不幸的是，这种算法会产生过高的性能开销，特别是对于大型程序。相比之下，我们的平滑技术利用NN的学习能力来实现更好的可扩展性。</p><p><strong>基于学习的模糊测试。</strong>最近，人们越来越关注使用机器学习技术来改进模糊器[37]，[72]，[84]，[9]，[81]，[12]，[64]。然而，现有的基于学习的模糊器将模糊测试模型化为端到端ML问题，即，他们学习ML模型以直接预测可以实现更高代码覆盖的输入模式。相比之下，我们首先使用NN平滑地逼近程序分支行为，然后利用梯度引导输入生成技术来实现更高的覆盖范围。因此，我们的方法比ML模型更容忍学习错误而不是端到端方法。在本文中，我们凭经验证明我们的策略在发现错误和实现更高边缘覆盖方面优于端到端建模[72]。</p><p><strong>基于污点的模糊测试。</strong>几个进化模糊器试图使用污点信息来识别有希望的变异位置[85]，[42]，[63]，[73]，[55]，[22]。例如，TaintScope [85]旨在识别影响系统/库调用的输入字节，并专注于改变这些字节。同样，Dowser [42]和BORG [63]专门使用污点信息来分别检测缓冲区边界违规和缓冲区过度读取漏洞。相比之下，Vuzzer [73]通过静态分析捕获magic常数，并将现有值变为这些常数。 Steelix [55]使用二进制文件来收集有关比较指令的其他污点信息。最后，Angora [22]使用动态污点跟踪来识别有希望的突变位置并执行坐标下降以指导这些位置上的突变。</p><p>然而，所有这些基于污点追踪的方法基本上受限于动态污点分析导致非常高的开销而静态污点分析遭受高误报率的事实。我们的实验结果表明，NEUZZ通过使用神经网络识别有希望的突变位置，轻松胜过现有的基于污点的现有模糊器。</p><p>一些模糊测试器和测试输入发生器[43]，[83]，[22]试图直接在目标程序上使用不同形式的梯度引导优化算法。然而，如果没有程序平滑，这种技术往往会挣扎并陷入不连续性。</p><p><strong>符号/执行的执行。</strong>符号和执行执行[50]，[14]，[77]，[61]，[36]使用可满足模数理论（SMT）求解器来解决路径约束并找到有趣的测试输入。一些项目也尝试将模糊测试与这些方法相结合[17]，[32]，[82]。不幸的是，由于符号分析的几个基本限制，包括路径爆炸，不完整的环境建模，符号记忆建模的大量开销等，这些方法在实践中难以扩展[16]。</p><p>与我们的工作同时，NEUEX [79]通过使用NN学习程序的中间变量之间的依赖关系以及使用梯度引导神经约束求解在结合传统的SMT求解器，使符号执行更有效。相比之下，在本文中，我们专注于使用NN来提高模糊效率，因为它是迄今为止在大型真实世界程序中发现安全关键错误的最流行的技术。</p><p><strong>神经程序。</strong>神经程序本质上是一个神经网络，它学习目标程序逻辑的潜在表示。最近的一些工作已经从程序的输入输出样本中合成了这样的神经程序，以准确地预测程序的新输入输出[41]，[74]，[62]。相比之下，我们使用NN来学习程序分支行为的平滑近似。</p><h1 id="IX-结论"><a href="#IX-结论" class="headerlink" title="IX 结论"></a>IX 结论</h1><p>我们提出了NEUZZ，一种有效的学习型模糊器，它使用代理神经网络来平滑地逼近目标程序的分支行为。我们进一步演示了梯度引导技术如何用于生成新的测试输入，可以发现目标程序中的不同错误。我们的广泛评估表明，NEUZZ在检测到的错误数量和边缘覆盖率方面明显优于其他10个最先进的模糊器。我们的研究结果表明，利用不同的梯度引导输入生成技术和神经平滑技术可以显着提高模糊过程的有效性。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h1&gt;&lt;p&gt;Fuzzing已经成为发现软件漏洞的事实上的标准技术。然而，即使是最先进的模糊器也不能很有效
      
    
    </summary>
    
      <category term="论文" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/"/>
    
      <category term="fuzzing" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/fuzzing/"/>
    
      <category term="机器学习" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/fuzzing/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="fuzzing" scheme="http://yama0xff.com/tags/fuzzing/"/>
    
      <category term="S&amp;P&#39;19" scheme="http://yama0xff.com/tags/S-P-19/"/>
    
      <category term="神经网络" scheme="http://yama0xff.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>ExploitMeter: Combining Fuzzing with Machine Learning for Automated Evaluation of Software Exploitability</title>
    <link href="http://yama0xff.com/2019/04/08/ExploitMeter-Combining-Fuzzing-with-Machine-Learning-for-Automated-Evaluation-of-Software-Exploitability/"/>
    <id>http://yama0xff.com/2019/04/08/ExploitMeter-Combining-Fuzzing-with-Machine-Learning-for-Automated-Evaluation-of-Software-Exploitability/</id>
    <published>2019-04-08T12:38:23.000Z</published>
    <updated>2019-04-09T12:46:54.173Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>可利用的软件漏洞对其信息安全和隐私构成严重威胁。尽管已经投入大量精力来提高软件安全性，但量化软件可利用性的研究仍处于起步阶段。在这项工作中，我们提出了ExploitMeter，这是一个基于模糊的软件可利用性量化框架，可以促进软件保障和网络保险的决策。 ExploitMeter设计为动态，高效和严谨，它以贝叶斯方式集成了基于机器学习的预测和动态模糊测试。使用100个Linux应用程序，我们进行了大量实验，以评估ExploitMeter在动态环境中的性能。</p><table><thead><tr><th>relevant information</th><th></th></tr></thead><tbody><tr><td><em>作者</em></td><td>Guanhua Yan Junchen Lu Zhan Shu Yunus Kucuk</td></tr><tr><td><em>单位</em></td><td>Department of Computer Science<br>Binghamton University, State University of New York</td></tr><tr><td><em>出处</em></td><td>2017 IEEE Symposium on Privacy-Aware Computing</td></tr><tr><td><em>原文地址</em></td><td></td></tr><tr><td><em>源码地址</em></td><td>http：//<a href="http://www.cs.binghamton.edu/~ghyan/code/ExploitMeter/" target="_blank" rel="noopener">www.cs.binghamton.edu/~ghyan/code/ExploitMeter/</a></td></tr><tr><td><em>发表时间</em></td><td>2017年</td></tr></tbody></table><h1 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1. 介绍"></a>1. 介绍</h1><p>软件安全在确保网络空间可信度方面发挥着关键作用。由于零日软件攻击的地下市场蓬勃发展，大部分网络犯罪都是通过利用易受攻击的软件系统来实现的。不幸的是，在可预见的未来，软件漏洞不太可能被消除，因为现代软件系统变得如此复杂，以至于只有有限认知能力的软件程序员几乎不可能测试他们所有的角落情况，更不用说那些不安全的语言了。 C仍在广泛使用。</p><p>在这项工作中，我们探讨了以下基本问题：鉴于软件系统中可能存在许多软件漏洞，我们能否量化其可利用性？软件可利用性的量化可以在两个重要的情况下找到它的应用：软件保障和网络保险。在国家信息保障术语表[30]中，软件保证被定义为“软件没有漏洞的信任程度，无论是故意设计到软件中还是在其生命周期的任何时间意外插入，以及软件在预期中运行“可量化的软件可利用性提供了对可利用软件漏洞不存在的这种信心的定量测量，从而促进了安全关键软件程序部署中的决策。另一方面，新兴的网络保险市场需要采用严格的方法，保险公司可以使用这些方法定量评估使用潜在易受攻击的软件系统与被保险人相关的风险。</p><p>正如[33]所述，由于运营网络安全的对抗性和动态性，很难实现可量化的安全措施。事实上，随着新开发技术的发展和部署的新的漏洞缓解功能，软件开发的格局不断变化。针对2006年至2012年期间针对Microsoft Windows平台的软件漏洞的调查显示，堆栈损坏漏洞利用率的百分比已经下降，但UAF漏洞的漏洞率却在上升[26]。</p><p>虽然已经做了许多致力于提高软件安全性的努力，但仍然缺乏一个统一的框架来量化软件可利用性在动态操作环境中，正如软件保障和网络保险所需要的那样。在行业中，CVSS（通用漏洞评分系统）[1]被广泛用于估计已知软件漏洞的严重性，包括基于其攻击向量，攻击复杂性，所需权限和用户交互计算的可利用性度量。除了CVSS之外，还提出了一些其他方法来评估软件安全性，例如攻击面度量[22]，漏洞密度度量[7]，[9]，具有危险系统调用的入口点的可达性[39]，以及基于机器学习的预测[12]，[19]。但是，这些方法都不允许我们量化动态执行环境中的软件可利用性。</p><p>在此背景下，我们在这项工作中提出了一个名为ExploitMeter的新框架，旨在定量和动态地评估软件可利用性，以促进软件保障和网络保险的决策。在ExploitMeter框架的核心是模仿人工评估人员的认知过程贝叶斯推理引擎：评价者首先基于静态特征采用机器学习今天初步的预测，然后与来自不同模糊器的多个动态模糊测试的新观察结果来更新自己对软件可利用性的判定。此外，评估者使用这些不同的模糊器的经验被用于更新他们的感知性能 - 也以贝叶斯方式 - 并且这些性能测量形成评估者量化软件可利用性的基础。因此，ExploitMeter的推理引擎可以被描述为动态非线性系统，其输入来自基于机器学习的预测和动态模糊测试。</p><p>在构建ExploitMeter框架的最后，我们在这项工作中的贡献总结如下：</p><ul><li><p>我们从软件程序的静态分析中提取各种特征，我们从中训练分类模型以预测软件程序可能具有的漏洞类型（例如，堆栈溢出和use-after-free）。评估者使用这些分类器的分类性能来得出她对预测结果的初始置信水平。</p></li><li><p>对于每个受测试的软件，我们使用各种模糊器来生成崩溃，从中我们发现导致崩溃的软件漏洞类型。对于发现的每种类型的软件漏洞，我们使用贝叶斯方法来计算评估者对软件漏洞的后验信念。</p></li><li><p>基于概率论，我们将软件程序包含的不同类型软件漏洞的可利用性分数结合起来，以生成最终的可利用性分数。</p></li></ul><p>我们在以下网址提供ExploitMeter的源代码：http：//<a href="http://www.cs.binghamton.edu/~ghyan/code/ExploitMeter/。为了证明其实用性，我们进行了大量实验，其中使用了两个不同的软件模糊器来模拟虚拟机中的100个标准Linux实用程序。我们在不同配置下使用ExploitMeter动态量化这些程序的可利用性，从而深入了解ExploitMeter如何促进软件保障和网络保险实践中的决策制定。" target="_blank" rel="noopener">www.cs.binghamton.edu/~ghyan/code/ExploitMeter/。为了证明其实用性，我们进行了大量实验，其中使用了两个不同的软件模糊器来模拟虚拟机中的100个标准Linux实用程序。我们在不同配置下使用ExploitMeter动态量化这些程序的可利用性，从而深入了解ExploitMeter如何促进软件保障和网络保险实践中的决策制定。</a></p><p>在本文的其余部分安排如下。第二节总结了相关工作。第三节提供了ExploitMeter的实际背景。 ExploitMeter采用的主要方法在第IV节中讨论。在第五节中，我们介绍了实验结果，并在第六节中得出结论性意见</p><h1 id="II-相关工作"><a href="#II-相关工作" class="headerlink" title="II 相关工作"></a>II 相关工作</h1><p>许多努力致力于提高软件漏洞发现的效率。这些技术主要分为两类，静态分析（例如，[16]，[21]，[20]，[35]）和动态模糊测试（例如，[32]，[34]，[17]）。 ExploitMeter的当前实现依赖于动态模糊测试来发现软件漏洞，因为模糊测试工具可以轻松实现自动化，程序的崩溃状态允许我们推断导致崩溃的漏洞类型。但是，在ExploitMeter框架中，很容易合并其他软件漏洞发现工具，这仍然是我们未来的工作。</p><p>软件安全研究人员也一直在开发模型来预测软件漏洞。该领域的工作通常利用国家漏洞数据库中的大量软件漏洞数据，并通过改进历史漏洞数据来训练预测模型（例如[18]，[9]，[28]，[8]，[ 8]，[27]，[40]）。与我们的工作更相关的是那些应用机器学习来推断软件漏洞的可利用性的工作。例如，Bozorgi等人 [12]训练线性支持向量机，使用从两个公共漏洞数据源中的描述中提取的基于文本的特征，对易受攻击的软件程序是否可利用进行分类。 [12]中提出的预测模型不能用于预测日常漏洞的可利用性。在[19]中Grieco等人从静态分析和动态执行软件程序中提取C标准库调用序列，以分类它们是否容易受到内存损坏。虽然这项工作直接适用于可执行程序，但它并不像ExploitMeter那样提供可量化的软件可利用性度量。所有这些先前工作的共同点是，他们从历史数据中训练模型以预测未来威胁的特征。 ExploitMeter与这些作品不同，因为预测模型仅用于推导先验信念，但这些信念应该用新的测试结果动态更新。这有效地解决了在软件开发技术和威胁缓解功能之间存在军备竞争的动态环境中可预测性的下降。</p><p>ExploitMeter还涉及一些关于自动生成软件漏洞的最新工作，例如AEG [10]和Mayhem [14]尽管ExploitMeter的设计受到了这些工作的启发，但是没有必要针对易受攻击的程序找到可操作的漏洞来评估其可利用性。 ExploitMeter采用的方法类似于我们之前的工作[38]，它采用贝叶斯方法来量化软件可利用性。但是，这项工作主要是理论性的，没有具体说明如何推导出先前的信念以及应该使用哪些工具来测试软件漏洞。相比之下，ExploitMeter提供了量化软件可利用性的实用框架</p><h1 id="III-背景"><a href="#III-背景" class="headerlink" title="III 背景"></a>III 背景</h1><p>可量化的软件可利用性有助于软件保障和网络保险的决策。为了解释这一动机，我们为这两个应用程序中的每一个提供了一个示例场景：</p><ul><li>软件保障：考虑一个安全关键环境，其中运行的每个软件应该不受利用，即使软件可能包含已知或未知的漏洞。当要部署新软件时，系统管理员需要确保在其执行环境中可以利用它的可能性应低于某个阈值。可量化的软件可利用性允许系统管理员在决定是否运行软件程序时建立置信度。</li><li>网络保险：IT（信息技术）经理希望确保企业免受恶意网络威胁。为了计算溢价，网络保险公司需要评估被保险企业网络中安装的软件的安全性。软件可利用性的定量测量允许保险公司量化与在被保险人网络内使用软件相关的风险。一旦投保，可以通过可信计算模块的远程证明来确保软件的完整性。这有助于保险公司仅为已经评估过的软件制定保险单。</li></ul><p>两个示例的共同点是必须量化在特定执行环境中运行的软件程序的可利用性。我们的目标是建立一个名为ExploitMeter的实用框架，系统管理员可以使用它来决定是否应该部署特定软件（软件保证），或者由保险公司用来评估软件程序的开发风险然后相应地计算保费（网络保险）。</p><p>利用软件的先决条件是它包含一些可以从其攻击面利用的软件漏洞。经典类型的软件漏洞包括堆栈缓冲区溢出，释放后使用引用，堆损坏，整数溢出，除零，解除引用空指针以及类型混淆。有许多工具可用于自动发现软件漏洞。由于软件的源代码可能无法在操作环境中使用，因此我们排除了依赖静态代码分析来查找软件漏洞的工具。并非所有软件漏洞都可以在相同程度上被利用。例如，虽然除零可能会有效地崩溃程序并因此启用拒绝服务攻击，但它不容易被利用用于更有趣的目的，例如权限提升。</p><h1 id="IV-方法"><a href="#IV-方法" class="headerlink" title="IV 方法"></a>IV 方法</h1><p>如图1所示，ExploitMeter是一个评估动态环境中软件可利用性的框架。在ExploitMeter中，计划按顺序测试软件S = {s0，s1，…，si，…}的列表。对于每个软件s∈S，假设其可利用性由假想的人类评估者测量，作为她对软件可被利用的可能性的主观信念。但是，软件可以通过各种低级软件漏洞利用，例如缓冲区溢出和整数溢出。此外，攻击者可以利用每种类型的这些安全漏洞的可能性可能会有所不同。因此，我们的模型使评估者能够推断每个软件漏洞类型的软件可利用性。设V = {v0，v1，…，v | V | -1}表示考虑的软件漏洞类型集。因此，软件通过漏洞类型v∈V的可利用性是评估者对通过漏洞类型v利用软件的可能性的主观信念。因此，我们的关键利益是评估零假设H0（s，v）的概率。这表明软件不易受类型v的攻击。我们让H1（s，v）表示相反的假设，即假设软件易受类型v攻击。</p><p><img src="/2019/04/08/ExploitMeter-Combining-Fuzzing-with-Machine-Learning-for-Automated-Evaluation-of-Software-Exploitability/1.jpg" alt=""></p><p>因此，由于类型v导致的软件的可利用性可以被表征为评估者的主观概率P（H0（s，v））。在贝叶斯推理[11]中，假设评估者保留P（H0（s，v））的先验概率，并且在看到证据E后，她的后验信念根据贝叶斯规则更新：<br>$$<br>P{H0(s, v)|E} =  \frac {P{E|H0(s, v)}* P{H0(s, v)}}{P{E}}<br>$$<br>为了应用贝叶斯推理[11]，我们需要解决如何推导先验概率P {H0（s，v）}以及如何获得证据E以支持软件可利用性的后验更新。</p><h2 id="A-从机器学习模型中获得初始概率"><a href="#A-从机器学习模型中获得初始概率" class="headerlink" title="A.从机器学习模型中获得初始概率"></a>A.从机器学习模型中获得初始概率</h2><p>ExploitMeter允许评估人员使用预测分类模型快速评估软件可利用性。对于每种类型的软漏洞，对基于软件程序的静态分析提取的特征训练分类模型。我们使用f（s）来表示从软件程序中提取的一组特征。给定特征向量f∈F，其中F是特征空间，给出的漏洞类型v的分类模型cv，由<code>cv：F→{positive，negative}</code>从历史数据中训练以预测具有特征向量 f 的软件程序 是否包含v类型的漏洞。</p><p>受过训练的分类模型可能会对软件程序包含的漏洞类型做出错误的预测。错误预测的来源可以是从软件程序中提取的弱特征，不准确的预测模型（例如，具有不良泛化能力的训练数据过度拟合的模型），或者本质上缺乏可预测性的非静止数据。因此，当使用机器学习模型来预测软件可利用性时，有必要考虑它们的预测性能。 ExploitMeter使用四重（TP，FP，TN，F N）监控每个分类器的性能，其中包括过去预测中的真阳性，假阳性，真阴性和假阴性的数量。令p（cv）表示与分类器cv相关联的性能四元组，并且其第i个元素由p（cv）[i]给出。</p><p>为了应用贝叶斯推理，需要假设P {H0（s，v）}的先验概率。基于所评估的软件程序没有发现类型v的漏洞的分数来建立P {H0（s，v）}的先验概率的合理模型。因此，计数器n用于保持评估的软件程序的数量，并且对于每种漏洞类型，nv用于保持已发现包含类型v的漏洞的软件程序的数量。但是，我们可能不想要直接使用nv / n作为先验概率，因为如果nv = 0，则对P {H0（s，v）}的先验概率为0，这决定了方程（1）中后验概率的计算。 忽视了E的存在。为了解决这个问题，ExploitMeter用一些正数初始化nv和n。例如，n = 2且nv = 1最初假设P {H0（s，v）}的初始先验信念是0.5，并且计数器在评估的每个软件程序时更新。</p><p>当评估新的软件程序时，分类器cv的预测结果证明了E的存在。根据等式（1），如果cv预测s为正，我们有：<br>$$<br>P{H0(s, v)| classifier cv predicts s to be positive }<br>=<br>\frac {<br>\frac {nv}{n}·\frac{p(cv)[2]}<br>{p(cv)[2]+p(cv)[3]}}<br>{<br>\frac {nv}{n}·\frac{p(cv)[2]}<br>{p(cv)[2]+p(cv)[3]} + \frac{n−nv}{n} · \frac{p(cv)[1]}{p(cv)[1]+p(cv)[4]}<br>}<br>$$<br>如果cv预测s为负数，我们有：<br>$$<br>P{H0(s, v)| classifier cv predicts s to be positive }<br>=<br>\frac {<br>\frac {nv}{n}·\frac{p(cv)[3]}<br>{p(cv)[2]+p(cv)[3]}}<br>{<br>\frac {nv}{n}·\frac{p(cv)[3]}<br>{p(cv)[2]+p(cv)[3]} + \frac{n−nv}{n} · \frac{p(cv)[4]}{p(cv)[1]+p(cv)[4]}<br>}<br>$$</p><h2 id="B-基于模糊测试的软件可利用性后验更新"><a href="#B-基于模糊测试的软件可利用性后验更新" class="headerlink" title="B.基于模糊测试的软件可利用性后验更新"></a>B.基于模糊测试的软件可利用性后验更新</h2><p>从软件程序提取的特征数据可能具有低稳定性，因此对于预测其可利用性的能力有限。例如，用于开发这些软件的编程语言的分布可能会随着时间的推移而发生变化，即使对于相同的编程语言，它也可能随着用新的功能替换过时功能而发展。此外，由于网络安全的对抗性质，可以在具有悠久历史的软件中找到新的安全漏洞。例如，自1989年9月以来，2014年发现的ShellShock漏洞突然使所有版本的Bash变得脆弱[36]。对于关键的网络安全操作，我们因此不应仅依赖从历史数据训练的模型来预测软件可利用性。</p><p>ExploitMeter允许评估者通过向她提供的新证据更新她对软件可利用性的信念。为了获得新的证据，使用一组模糊器Z = {z0，z1，…，z | Z | -1}来查找被测软件中的漏洞。每个模糊器的工作原理是将格式错误的数据注入程序以创建崩溃。进一步分析这些崩溃以推断潜在的安全漏洞。模糊测试的输出要么软件成功终止，要么导致崩溃。对于每次崩溃，我们都可以推断导致崩溃的软件漏洞类型。在第IV-C节中，我们将详细说明如何在ExploitMeter框架中完成此操作。</p><p>在使用Z中的模糊器对软件进行模糊测试后，模糊测试结果将作为评估者更新其后验概率的证据。如果模糊器发现软件的漏洞类型为v，则将Esv定义为1，否则为0。然后我们有两个用fuzzer模糊软件的Esv案例：</p><p>案例A：Esv = 1.在这种情况下，模糊器在软件中成功找到v类型的漏洞。有了这样一个确凿的证据，评估者对软件免疫v的后验概率应该是0，而不管她从回归模型得出的初始概率。这可以通过贝叶斯规则得到证实：<br>$$<br>P(H0(s, v) | Esv = 1)<br>=<br>\frac{P(Esv = 1 | H0(s, v)) · P(H0(s, v))}<br>{P(Esv = 1)} = 0<br>$$<br>必须保持最终的相等性，就好像软件不易受类型v攻击一样，任何模糊器都不可能找到导致它因类型v而崩溃的软件输入。</p><p>案例B：Esv = 0.在这种情况下，模糊器在软件s中找不到类型v的漏洞。但是，软件仍然可能容易受到v攻击，因为模糊器可能由于其模糊测试策略而无法检测到漏洞。使用贝叶斯规则，我们有以下内容：<br>$$<br>P(H0(s, v) | Esv = 0)<br>=<br>\frac{P(Esv = 0 | H0(s, v)) · P(H0(s, v))}<br>{P(Esv = 0)}<br>$$<br>一些模糊测试者比其他模糊测试人员更能检测到特定类型的漏洞。例如，[25]中开发的SmartFuzz方法专注于检测整数错误。让模糊器z对漏洞类型v的检测率为q（v，z）。我们因此：<br>$$<br>P(Es,v = 0 | H1(s, v)) = 1 − q(v, z)<br>$$<br>如果假设H0（s，v）为真（即软件不易受类型v影响），则情况B必须保持。因此，我们有：<br>$$<br>P(Es,v = 0 | H0(s, v)) = 1<br>$$<br>结合方程（6）和（7），我们有：<br>$$<br>P(Es,v = 0) = \sum_{i=0}^1 P(H_i(s,v))·P(Esv=0|H_i(s,v))<br>= P(H0(s,v))+(1−P(H0(s,v)))·(1−q(v,z)<br>$$<br>最后，我们有以下内容：<br>$$<br>P(H0(s, v) | Es,v = 0) =<br>\frac{P(H0(s,v))}<br>{P(H0(s,v))+(1−P(H0(s,v)))·(1−q(v,z)) }<br>$$<br>软件程序的可利用性取决于它包含的漏洞类型以及每种漏洞类型转化为软件漏洞的可能性。为了对这种依赖关系进行建模，我们假设评估者对于每个漏洞类型v∈V，都相信其被利用的可能性，用r（v）表示。假设V中的漏洞类型是独占且独立的，在看到模糊器的模糊测试结果后，软件的整体可利用性由下式给出：<br>$$<br>U(s) = 1−<br>\prod_{v∈V}[(1−r(v))·(1−P(H0(s,v)|Es,v))+P(H0(s,v)|Esv)]<br>= 1 − \prod_{v∈V}[1 − r(v) + r(v) · P(H0(s, v) | Esv)]<br>$$<br>其中P（H0（s，v）| Esv）是在看到证据Esv后，评估者对假设H0（s，v）的后验概率。方程式（9）RHS（右手侧）的第二个术语， 给出了软件不能通过V中任何类型的漏洞被利用的概率。</p><p>ExploitMeter在模糊器模糊后重新计算软件程序的可利用性分数。基于该可利用性得分，如果可利用性得分高于某个置信度阈值，则可以做出决定。否则，评估者需要更多证据来确定软件程序是否确实可以利用。</p><h2 id="C-崩溃造成的漏洞干扰"><a href="#C-崩溃造成的漏洞干扰" class="headerlink" title="C.崩溃造成的漏洞干扰"></a>C.崩溃造成的漏洞干扰</h2><p>当程序崩溃或以其他方式异常终止时，现代OS通常允许将崩溃进程的存储器映像和程序寄存器转储到本地文件系统上。这些核心转储文件可以进一步加载到调试器中，例如GNU调试器或Microsoft WinDbg，以在崩溃发生时恢复进程的内部状态。这些核心转储文件可用于推断导致崩溃的漏洞类型。例如，可以检查崩溃进程的堆栈跟踪缓冲区溢出的可能性，这是一种典型的软件漏洞。<br>Microsoft安全工程中心开发了一个名为！exploitable [4]的WinDbg扩展，根据其原因对崩溃进行分类，例如使用先前释放的堆缓冲区和堆栈缓冲区溢出。可以将每个原因视为漏洞类型，并且不同漏洞类型的可利用性不同。在！exploitable 的情况下，所有类型的软件漏洞都分为四类，具体取决于它们被开发的可能性，可利用，可能可利用 ，可泵不可利用和未知性。 Apple开发了一个名为CrashWrangler的类似工具来检查Mac OS平台上的软件崩溃[3]，并开发了CERT分类工具来评估Linux平台上的软件可利用性[5]。</p><p>ExploitMeter依靠这些工具来推断导致程序崩溃的软件漏洞类型。表1中给出了可由CERT分类工具推断出的漏洞类型列表。尽管这些工具是ExploitMeter框架的一个组成部分，但我们知道它们在评估软件崩溃时的安全性方面并不完美。 [31]这些工具背后的一个基本假设是攻击者可以完全控制导致崩溃的错误指令的输入操作数。如果无法从程序的攻击面更改这些输入操作，则这些工具往往会高估发现软件漏洞的风险。此外，这些工具还应用基于规则的启发式和轻量级污点分析，这些技术中固有的局限性可能导致错误的漏洞分类。</p><p><img src="/2019/04/08/ExploitMeter-Combining-Fuzzing-with-Machine-Learning-for-Automated-Evaluation-of-Software-Exploitability/2.jpg" alt="table 1"></p><h2 id="D-训练分类模型"><a href="#D-训练分类模型" class="headerlink" title="D.训练分类模型"></a>D.训练分类模型</h2><p>ExploitMeter目前旨在评估ELF（可执行和可链接格式）可执行文件的可利用性。它从ELF可执行文件中提取特征以训练分类模型，该模型预测它们是否包含特定类型的漏洞。可以从ELF可执行文件的静态分析中提取各种类型的功能。<br>ExploitMeter目前使用以下类型的功能：</p><ul><li>Hexdump功能。我们使用hexdump实用程序从二进制程序中获取字节序列，然后计算软件程序中出现的每个n-gram字节序列的频率。有256个1-gram特征（即0x00到0xFF）和65536个2-gram特征（即0x0000到0xFFFF）。</li><li>Objdump功能。我们使用objdump来反汇编二进制可执行程序，并且对于每个指令，我们将其表示为操作码及其操作数类型的组合。例如，指令mov edi，0x600dc0被抽象为mov-register-immediate，而指令mov rax，QWORD PTR [rip + 0x981375]被抽象为mov-register-memory。使用操作数类型扩展操作码的直觉是ExploitMeter目前专注于评估与内存相关的软件漏洞，因此希望明确识别指令是否访问内存有助于提高分类性能。然后，我们计算出软件程序代码部分中出现的每个n-gram序列的频率。由于软件开发针对合法软件，我们希望大多数合法程序不会使用恶意软件中的大量混淆来混淆反汇编过程。</li><li>库功能。我们使用ldd实用程序来获取可执行程序所需的共享库列表。值得注意的是，严格来说，ldd实用程序不是静态分析工具，因为它使用动态加载程序来决定运行时需要哪些共享库，但它比静态分析工具（如objdump）提供了更准确的共享库覆盖。对于某些ELF可执行文件，例如mediainfo和pdftk，由于ld.so检测到不一致问题，在它们上运行ldd会崩溃。对于他们，我们使用objdump -p来查找所需的共享库。</li><li>搬迁功能。我们使用readelf实用程序（使用-rW选项）来发现重定位部分的内容，然后使用c ++ filt实用程序对重定位的符号进行解码。每个已解密的符号都被视为值为1的要素，如果在重定位部分中找不到，则为0。</li></ul><p>在动态环境中，分类模型定期重新训练。我们按时间划分为几个时期，T = {T0，T1，…}。获得这些时期的选择可以是灵活的。例如，我们可以将时间划分为相等的长度（例如，三个月），或者让在不同时期测试的软件的数量大致相同，或者将模糊测试活动视为时期。让时期Ti中使用的分类模型cv被区分为c（vi），其中i = 0,1，……对于第一个时期T0，由于没有历史数据来训练每个漏洞类型的分类模型，我们可以使用领域知识来指定先前的概率。</p><p>在每个时期的开始，使用所有历史数据对每个漏洞类型重新训练分类模型。通过略微滥用符号S，我们定义Si，其中i = 0,1，…作为已在时期Ti中测试的软件集。当在i ≥ 1的时期Ti的开始建立漏洞类型v的分类模型时，我们如下导出训练数据集。对于每个软件s∈{Sk} 0≤k≤i-1，我们让Ys（v）∈{positive，negative}表示软件s是否被任何模糊器检测到包含v类型的漏洞;我们将元组（f（s），Ys（v））添加到训练数据集中，其中我们记得f（s）是软件s的特征向量。用于时期Ti的分类模型c（vi）通过从f（s）预测所有s∈{Sk}0≤k≤i-1的Ys（v）来训练。 ExploitMeter中分类模型的选择是灵活的，我们将在实验中根据经验评估各种分类模型的性能</p><h2 id="E-贝叶斯参数估计"><a href="#E-贝叶斯参数估计" class="headerlink" title="E.贝叶斯参数估计"></a>E.贝叶斯参数估计</h2><p>回想一下，参数q（v，z）表示模糊器z对漏洞类型v的检测率。为了估计q（v，z），我们维护一个性能计数表，用C表示，大小为| V | x | Z |。表C的每个条目C [v，z]是保持模糊器z成功检测到具有漏洞类型v的软件的次数的计数器。除了表C之外，长度为| V |的向量D也保留，其中每个i在[0，| V | -  1]，D [v]给出已用漏洞类型v识别的软件数量。</p><p>表C和向量D更新如下。限定：<br>$$<br>V_s^{‘} = {v ∈ V : Esv = 1}.<br>$$</p><p>因此，设置Vs’包含至少一个fuzzer在软件中找到的所有漏洞类型。对于每个v∈Vs’,我们将D [v]增加1，因为在软件中已发现v类型的新漏洞。此外，对于每个v∈Vs‘,我们得到模糊器列表L（s，v）在软件中成功识别出这种类型的漏洞。即，L（s，v）= {z∈Z：Ts [v，z] = 0}。然后，对于每个z∈L（s，v），我们将C [v，z]增加1。</p><p>如果假设一个频率论者的观点，我们应该将表C和矢量D中的所有条目初始化为零，并且让q（v，z）简单地为C [v，z] / D [v]。但是，如果在漏洞类型v中找到的软件测试很少，则q（v，z）的估计值可能不稳定。这类似于这样一种情况，即一个先前相信硬币应该公平的人，即使在连续看到三个头之后也不会认为它应该始终产生头部。</p><p>因此，我们在估算时考虑了评估者对q（v，z）的先验概率。我们假设当在具有概率q（v，z）的软件中查找漏洞类型v时，每个模糊器z遵循二项式过程。由于二项式过程的共轭先验是Beta分布，我们假设参数q（v，z）的先验取一个<br>$$<br>Beta（c_0^{（v，z）}+ 1，d_0^{（v）} - c_0^{（v，z）}+ 1）<br>$$<br>分布，其中d0（v）≥c0( v，z）。使用MAP（Maximum A Posteriori）方法估计q（v，z），我们得到：<br>$$<br>q(v, z) = \frac{c_0^{(v,z)} + C[v, z]}<br>{d_0^{(v)}+ D[v]}<br>$$<br>其中表C和向量D被初始化为全0。简化等式（13），我们可以通过让C [v，z]为所有v∈V和z∈Z的c0（v，z）来初始化表C，并且对于所有v∈V，D [v]是d0（v） 。如果是这样等式（13）简单地变成：</p><p>$$<br>q(v, z) = \frac{C[v, z]}<br>{D[v]}<br>$$<br>注意：注意q（v，z）估计如公式(14)所示有偏见，因为D [v]不包括软件包含漏洞类型v的情况，但没有一个模糊检测器正确检测到它。因此等式（14）具有过高估计q（v，z）的真值的趋势。由于可能无法在复杂的软件程序中找到所有漏洞，因此可以通过在ExploitMeter中使用更大的互补模糊器来缓解此类系统错误。</p><p>类似地，我们以贝叶斯方式估计等式（11）中的参数r（v）。还假设r（v）遵循具有共轭先验Beta（a0（v）+ 1，b0（v）+1）的二项分布。我们使用两个向量A和B，每个向量的大小为| V |，分别存储每种类型的软件漏洞可被利用和不可利用的次数。对于每个漏洞类型v，A [v]和B [v]分别被初始化为a0（v）和b0（v）。最终分析每次崩溃以验证它是否确实可以被利用。对于每次独特的崩溃，如果发现可利用，A [h（d）]增加1;否则，B [h（d）]增加1。 MAP方法导致以下公式：<br>$$<br>r(v) = \frac{A[v]}<br>{A[v] + B[v]}<br>$$<br>因此，r（v）的先验估计由a0（v）/（a0（v）+ b0（v））给出，并且在分析由于模糊引起的崩溃之后r（v）的后验估计被连续更新手动。</p><h1 id="五，实验结果"><a href="#五，实验结果" class="headerlink" title="五，实验结果"></a>五，实验结果</h1><p>目前，ExploitMeter已经实现了大约1300行Python代码（不包括模糊器代码）。出于评估目的，我们使用100个Linux应用程序，这些应用程序列在表IV中。所有实验都在以相同方式配置的KVM / QEMU虚拟机中执行：64位Ubuntu 14.04.1,8个逻辑主机CPU，8G RAM和16GB VirtIO磁盘。四个物理工作站专门用于实验，每个工作站有8个内核和32G RAM。在我们的实验中，每个应用程序在模糊测试中提供10个随机选择的种子文件，并且每个应用用这些种子模糊30小时。因此，完成所有模糊测试需要6000个CPU小时。由于有限的计算资源，我们仅使用10个种子来模糊每个应用程序，尽管可以理解，希望用更多种子模糊每个应用程序以实现更好的代码覆盖。对于每种漏洞类型v，ExploitMeter在评估每10个软件程序后重新训练其分类模型。</p><h2 id="A-fuzzing-结果"><a href="#A-fuzzing-结果" class="headerlink" title="A. fuzzing 结果"></a>A. fuzzing 结果</h2><p>自从作为威斯康星大学麦迪逊分校[24]的课程项目引入的模糊概念开始以来，已经开发了许多开源模糊器。然而，许多这些模糊器不成熟，不稳定或支持不足[23]。在研究了许多开源模糊器的可用性之后，我们决定在ExploitMeter的当前实现中使用以下模糊器（尽管其他模糊器可以很容易地结合到ExploitMeter中）：</p><ul><li>BFF（基本模糊测试框架）[13]。 BFF是由CERT开发的用于查找Linux和Mac OS平台的软件安全漏洞的模糊测试框架。其核心是zzuf，一个流行的模糊测试软件，通过随机改变程序的输入来发现错误[6]。</li><li>OFuzz [2]。来自卡内基梅隆大学的研究产品OFuzz是一个突变的模糊测试框架，旨在促进对模糊测试结果的严格统计分析。它采用OCaml语言实现，其模块化设计使得开发新的模糊测试功能变得容易，例如优化模糊测试的种子选择[29]，在模糊测试活动中更改调度算法[37]，以及优化突变比率一个模糊的[15]。</li></ul><p>表IV列出了BFF和OFuzz的模糊测试结果。这些结果的一些统计数据总结如下：</p><ul><li>BFF：在100个应用程序中，26个在模糊测试期间崩溃。对于这26个应用程序中的每一个，平均而言，它崩溃了21.6次，具有19.7个独特的堆栈哈希，归因于5.9种类型的软件漏洞。</li><li>OFuzz：在100个应用程序中，29个在模糊测试期间崩溃。对于这29个应用程序中的每一个，平均而言，它崩溃了108270.4次，具有17.3个独特的堆栈哈希，归因于4.9种类型的软件漏洞。</li></ul><p>在被模糊器撞毁的35个应用程序中，其中20个被两个模糊器崩溃，这表明使用多个模糊器可以提高查找软件漏洞的效率。比较两个模糊器的模糊测试结果，虽然OFuzz比BFF崩溃的应用程序略多，但它平均崩溃的频率比BFF高5012.5倍。对于这些崩溃，我们使用CERT分类工具提供的堆栈哈希值，这些哈希值是在每次崩溃后对堆栈中前五个堆栈帧进行散列而得到的，以估算唯一崩溃的数量。显然，OFuzz往往比BFF更频繁地报告相同的崩溃，因为OFuzz报告的每个崩溃应用程序的平均堆栈哈希数小于BFF。使用CERT分类工具对每个崩溃的漏洞类型进行分类，我们发现对于每个崩溃的应用程序，BFF发现的软件漏洞类型比OFuzz更多。这与我们之前的观察结果一致，即BFF为每个崩溃的应用程序产生比OFuzz更多的独特崩溃。<br>在图2中，我们针对每个漏洞类型显示了基于两个模糊器的模糊测试结果而导致崩溃的不同应用程序的数量。结果发现，漏洞类型16（SourceAV）导致所有22种漏洞类型中的大多数应用程序崩溃。此外，大多数漏洞类型导致至少一个应用程序崩溃，但类型1（ReturnAv），类型2（UseAfterFree），类型5（StackCodeExecution）和类型14（BlockMoveAv）除外。</p><p><img src="/2019/04/08/ExploitMeter-Combining-Fuzzing-with-Machine-Learning-for-Automated-Evaluation-of-Software-Exploitability/3.jpg" alt=""></p><h2 id="B-软件漏洞的可预测性"><a href="#B-软件漏洞的可预测性" class="headerlink" title="B.软件漏洞的可预测性"></a>B.软件漏洞的可预测性</h2><p>接下来，我们评估软件程序可能具有四个函数名称的不同类型软件漏洞的可预测性。图4（1）显示了在从每个类型的软件漏洞的核心转储中恢复的堆栈上可以找到哪些共享库。结果发现，422个共享库中只有28个或6.6％出现在从核心转储中恢复的堆栈中至少一次。可以经常使用这些共享库。例如，由于漏洞类型4（BrachAv）和7（PossibleStackCorruption）以及库libX11.so.6和libpcre.so.3，32个应用程序使用的库libstdc ++.so.6被发现涉及核心转储。由于漏洞类型7，每个应用程序使用31个应用程序，都涉及核心转储。某些库与许多类型的软件漏洞相关联。例如，由于12种不同类型的软件漏洞，仅由应用程序abiword使用的库libabiword-3.0.so已出现在核心转储堆栈上。图4（2）分别显示了每个漏洞类型在核心转储堆栈上具有相关共享库名称的唯一崩溃的比例。显然，对于除18（BenignSignal）之外的任何漏洞类型，超过一半的独特崩溃涉及共享库。此外，图4（3）显示了可以在核心转储堆栈上找到其共享库名称的易受攻击应用程序的比例。我们发现，对于五种漏洞类型，所有易受攻击的应用程序在执行时都会在核心转储堆栈上留下共享库名称的痕迹。这些观察结果表明，ELF可执行文件使用的共享库列表提供了有价值的信息，用于预测它可能包含的软件漏洞类型。</p><p><img src="/2019/04/08/ExploitMeter-Combining-Fuzzing-with-Machine-Learning-for-Automated-Evaluation-of-Software-Exploitability/4.jpg" alt=""></p><p>与库功能相比，重定位功能在函数级别提供了更细粒度的信息，因为它们包括在修补代码时需要解析的功能名称。对于在核心转储堆栈上找到的函数名称，我们检查ELF可执行文件的重定位部分，以查看它们是否出现在重定位功能中。由于相同的函数名称可能出现在两个不同的共享库中，因此我们也需要匹配库名称。但是，重定位部分不提供确切的库名称。例如，应用程序mpv和mplayer在其重定位部分中都有函数pa_context_new @ PULSE_0，其中相应的库是libpulse.so.0。因此，我们从重定位部分中的每个函数名称中搜索库密钥，然后查找是否可以在核心转储堆栈上找到的库名中找到不区分大小写的密钥。按照前面的示例，不区分大小写的键是pulse，我们可以从库名libpulse.so.0中找到它。此外，还添加了两个异常情况：如果密钥是GLIBC或CXXABI，我们将分别在库名称中搜索libc.so和libstdc ++。图4（2）给出了唯一崩溃的部分，其中堆栈上的函数名称可以在ELF可执行文件的重定位部分中找到，类似地，图4（3）显示了某些函数名称上的易受攻击的应用程序的分数核心转储堆栈可以在其重定位部分中找到。据观察，这些分数是显着的，表明从重定位部分提取的特征确实可用于预测软件漏洞。虽然这些数字似乎低于库功能中的数字，但是知道应用程序调用易受攻击的函数显然提供了有关其漏洞的更多信息，而不是知道它链接了易受攻击的共享库。</p><p><img src="/2019/04/08/ExploitMeter-Combining-Fuzzing-with-Machine-Learning-for-Automated-Evaluation-of-Software-Exploitability/5.jpg" alt=""></p><h2 id="C-为什么选择贝叶斯？"><a href="#C-为什么选择贝叶斯？" class="headerlink" title="C.为什么选择贝叶斯？"></a>C.为什么选择贝叶斯？</h2><p>我们接下来解释在ExploitMeter中使用贝叶斯推理的好处。为了便于解释，我们仅考虑漏洞类型16的预测结果。由于只考虑了一种漏洞类型，我们假设评估者有一个置信度阈值来确定软件程序在评估的不同阶段是否存在16类漏洞： </p><ul><li><p>prior:先验概率计算为nv / n，其中我们记得nv是先前看到的包含漏洞类型v和n已经评估的样本数的样本的数量。</p></li><li><p>Prior+ ML：后验概率来自等式（2）和（3）使用分类模型预测软件程序是否包含漏洞类型16.在分类模型中，我们使用所有重定位，库和objdump 2-gram特征。</p></li><li>Prior + ML + BFF：在看到模糊器BFF的模糊测试结果后得出后验概率，模糊器BFF总是在模糊器Ofuzz之前使用。</li></ul><p>决策规则很简单：如果概率得分高于给定的置信度阈值，则被评估的软件被认为不易受攻击（对于类型16）。图6显示了在不同评估阶段应用决策规则的精确度和召回分数。为了比较，我们还显示了单独使用BFF和Ofuzz的精确度和召回分数。由于模糊测试结果没有误报，我们可以看到单个模糊器在图6（1）中的精度得分始终为1。</p><p><img src="/2019/04/08/ExploitMeter-Combining-Fuzzing-with-Machine-Learning-for-Automated-Evaluation-of-Software-Exploitability/6.jpg" alt=""></p><p>从图6中，我们发现现有方法的性能对置信度阈值敏感。当阈值较低时，该方法始终将新应用程序分类为负数，这会导致调用0和未定义的精度。当阈值超过阳性样本的分数时，该方法倾向于将新应用分类为正，这导致精度降低和具有置信度阈值的召回增加。先前的+ ML方法在看到机器学习的预测结果后，基于后验概率做出决定。该方法的精确度随置信度阈值降低，并且该方法的召回随置信度阈值增加，因为较高置信度阈值导致更多应用被归类为具有相同分类模型的正数。先前的+ ML + BFF方法在看到BFF的模糊测试结果后更新后验概率后作出决定。使用该方法的精度和召回曲线的趋势类似于先前的+ ML方法的趋势。<br>贝叶斯方法有助于在不同的操作环境下进行决策。例如，在军事网络等安全严密的环境中，在应用程序实际部署之前建立对应用程序安全性的高度信任至关重要。在这种情况下，操作员可以使用具有高置信度阈值的先前+ ML方法来查找具有高召回率的易受攻击的应用程序;然而，高置信度阈值也导致高误报率（即，低精度），并且操作员需要对机器学习模型检测到为正的那些应用执行更多模糊测试以确保它们不易受攻击。另一方面，具有低误报率容限的普通用户可以使用具有低置信度阈值的先前+ ML方法;但是，用户必须承担使用未被检测到的易受攻击程序的风险。</p><p><img src="/2019/04/08/ExploitMeter-Combining-Fuzzing-with-Machine-Learning-for-Automated-Evaluation-of-Software-Exploitability/7.jpg" alt=""></p><h2 id="D-可利用性评分的评估"><a href="#D-可利用性评分的评估" class="headerlink" title="D.可利用性评分的评估"></a>D.可利用性评分的评估</h2><p>ExploitMeter提供了一个包含各种输入参数的丰富框架。在本节中，我们将评估ExploitMeter如何使用表II中汇总的参数设置评估可利用性分数。对于每个漏洞类型v和每个模糊器z，漏洞类型v的模糊器z的初始检测率被设置为10/12（即，大约83.3％）。此外，对于CERT分类工具分类为EXPLOITABLE，PROBABLY_EXPLOITABLE，PROBABLY_NOT_EXPLOITABLE或UNKNOWN的漏洞类型，其初始可利用性分别设置为80％，60％，10％或1％。在我们的实验中，这些可利用性分数未更新，因为验证发现的每个漏洞的可利用性是耗时的。</p><p>图7（1）显示了ExploitMeter在100个Linux应用程序上按顺序运行后每个应用程序的最终可利用性得分。图中的四条曲线表示每个应用程序在四个不同阶段的可利用性得分：计算先前的信念，从分类模型预测，使用BFF模糊测试，以及使用Ofuzz进行模糊测试。最终的可利用性分数（在使用fuzzer Ofuzz之后）有20个峰值，可利用性分数高于0.6。为了研究分数与表IV中显示的模糊测试结果之间的相关性，我们总结了表III中具有高可利用性分数的20个应用程序的列表，以及CERT分类工具中属于每个可利用性类别的漏洞类型的数量。在100个应用程序中，其中19个至少有一个漏洞类型属于EXPLOITABLE类别，只有它们的可利用性分数高于0.8。应用程序qpdfview有两种漏洞类型属于PROBABLY_EXPLOITABLE类别，也导致相对较高的可利用性得分为0.647。因此，最终的可利用性分数与其模糊测试结果高度相关。</p><p> <img src="/2019/04/08/ExploitMeter-Combining-Fuzzing-with-Machine-Learning-for-Automated-Evaluation-of-Software-Exploitability/8.jpg" alt=""></p><p>图7（1）还揭示了从机器学习模型预测的可利用性分数与从模糊测试结果估计的最终值不一致。由于分类性能较差，预计会出现这种情况，如图3所示，这些漏洞属于EXPLOITABLE或PROBABLY_EXPLOITABLE类别。</p><p>图7（2）显示了每个应用程序的平均可利用性得分以及具有随机测试顺序的20个样本运行中的标准偏差。结果发现，对于具有高可利用性分数的20个应用程序，当测试顺序发生变化时，它们的可利用性分数差别很小。这是合理的，因为无论测试顺序如何，一旦发现一种易于利用的漏洞，它就会将评估者对该漏洞类型的后验信念降低为0，从而显着提高其可利用性评分。</p><p><img src="/2019/04/08/ExploitMeter-Combining-Fuzzing-with-Machine-Learning-for-Automated-Evaluation-of-Software-Exploitability/9.jpg" alt=""></p><p>相比之下，评估者基于机器学习模型的预测结果的初始信念更容易改变那些没有发现任何高度可利用漏洞的应用程序的可利用性分数。</p><h1 id="VI-结论"><a href="#VI-结论" class="headerlink" title="VI 结论"></a>VI 结论</h1><p>在这项工作中，我们开发了一个名为ExploitMeter的框架，它将模糊测试与机器学习相结合，以评估软件的可利用性。 ExploitMeter依赖于分类建模来估计基于从静态分析中提取的特征的软件可利用性的初始信念。 ExploitMeter进一步使用动态模糊测试来更新可利用性的信念。 ExploitMeter采用的贝叶斯方法以有机的方式集成了基于机器学习的预测和模糊测试结果。我们将ExploitMeter应用于100个Linux应用程序列表，以深入了解其性能。</p><p>在我们未来的工作中，我们计划提高ExploitMeter中使用的机器学习模型的预测准确性。我们将特别研究以下研究问题：更多的阳性样本是否有助于提高所用机器学习模型的预测准确度？是否有可能找到具有更好预测能力的其他类型的功能？或者，深度学习等新机器学习模型能否提升预测性能？</p><p><img src="/2019/04/08/ExploitMeter-Combining-Fuzzing-with-Machine-Learning-for-Automated-Evaluation-of-Software-Exploitability/10.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h1&gt;&lt;p&gt;可利用的软件漏洞对其信息安全和隐私构成严重威胁。尽管已经投入大量精力来提高软件安全性，但量化
      
    
    </summary>
    
      <category term="论文" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/"/>
    
      <category term="fuzzing" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/fuzzing/"/>
    
      <category term="可利用性判定" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/fuzzing/%E5%8F%AF%E5%88%A9%E7%94%A8%E6%80%A7%E5%88%A4%E5%AE%9A/"/>
    
    
      <category term="机器学习" scheme="http://yama0xff.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="2017年" scheme="http://yama0xff.com/tags/2017%E5%B9%B4/"/>
    
      <category term="可利用性判定" scheme="http://yama0xff.com/tags/%E5%8F%AF%E5%88%A9%E7%94%A8%E6%80%A7%E5%88%A4%E5%AE%9A/"/>
    
  </entry>
  
  <entry>
    <title>Experimenting machine learning techniques to predict vulnerabilities</title>
    <link href="http://yama0xff.com/2019/04/08/Experimenting-machine-learning-techniques-to-predict-vulnerabilities/"/>
    <id>http://yama0xff.com/2019/04/08/Experimenting-machine-learning-techniques-to-predict-vulnerabilities/</id>
    <published>2019-04-08T01:43:42.000Z</published>
    <updated>2019-04-08T11:39:18.080Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>软件度量标准可用作软件漏洞存在的指示器。这些指标已用于机器学习，以预测容易包含漏洞的源代码。虽然无法找到缺陷的确切位置，但模型可以显示在检查和测试期间哪些组件需要更多关注。每种新技术都使用他自己的评估数据集，该数据集多次具有有限的大小和代表性。在此体验报告中，我们使用大型且具有代表性的数据集来评估几种最先进的漏洞预测技术。该数据集是使用来自五个广泛使用的开源项目的2186个漏洞的信息构建的。结果表明，数据集可用于区分哪种是最佳技术。还表明，一些技术可以预测几乎所有数据集中存在的漏洞，尽管精度非常低。最后，准确性，精确度和召回率并不是表征这种工具有效性的最有效方法。<br>关键词 - 机器学习，软件度量，软件安全，漏洞</p><table><thead><tr><th>relevant information</th><th></th></tr></thead><tbody><tr><td><em>作者</em></td><td>Henrique Alves, Baldoino Fonseca,Nuno Antunes</td></tr><tr><td><em>单位</em></td><td>Instituto de Computac¸ao Universidade Federal de Alagoas;CISUC, Department of Informatics Engineering University of Coimbra</td></tr><tr><td><em>出处</em></td><td>7th Latin-American Symposium on Dependable Computing</td></tr><tr><td><em>原文地址</em></td><td><a href="https://ieeexplore.ieee.org/document/7781850" target="_blank" rel="noopener">https://ieeexplore.ieee.org/document/7781850</a></td></tr><tr><td><em>数据集地址</em></td><td><a href="https://eden.dei.uc.pt/~nmsa/metrics-dataset/index.html" target="_blank" rel="noopener">https://eden.dei.uc.pt/~nmsa/metrics-dataset/index.html</a></td></tr><tr><td><em>发表时间</em></td><td>2016年</td></tr></tbody></table><h1 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h1><p>软件漏洞代表了当今软件开发人员最头疼的问题之一。正在开发的大多数软件都以某种方式暴露给外部用户，这些用户迟早会试图利用恶意的方式利用它。即使在软件安全方面投入了大量精力，攻击仍然经常发生，每年的财务损失达到2260亿美元[1]。更糟糕的是，软件的大小和复杂性的增加加剧了这个问题。</p><p>开发安全代码是一项艰巨而昂贵的任务，需要花费大量时间。软件工程师有许多技术可以找到这些缺陷和漏洞，但众所周知，最有效的技术通常需要大量的时间和专业资源。代码检查和测试等技术是发现漏洞的有效且被广泛接受的方法，但这些方法有其局限性。代码审查和检查[2]被认为是减少错误数量的非常有效的方法，但众所周知，它们的成本限制了它们在大型工件中的适用性。即使测试虽然更容易和更便宜，但可能会导致测试代码多于其自己的系统代码，以覆盖整个系统代码。随着系统规模的增长变得越来越昂贵，以满足提供高度信任的严格覆盖要求[2]。为了解决这个问题，开发人员试图将精力集中在系统中最棘手的部分。</p><p>虽然识别系统中最有问题的部分是一个有趣且有效的解决方案，但执行此分析的标准可能是多样化和混乱的。诸如[3]，[4]，[5]，[6]等研究已经研究了这种可能性，并使用了几种与机器学习技术相结合的软件度量来完成这项活动。很明显，没有代码生而平等且具有不同的特征。这些工作表明，这些功能可以区分代码中漏洞的存在（最近的一项研究证实[7]）。</p><p>在这项工作中，我们感兴趣的是代表代码静态属性的软件度量。代码执行和代码流失度量标准不在范围之内。现有工作使用不同的配置和方法呈现不同的结果，并考虑不同的度量集。例如。虽然在[8]中使用了9个软件度量来构建预测模型，但在[9]中使用了17个软件度量。此外，还有各种各样的机器学习技术，通过这些技术，文章可以更频繁地使用某些技术，并且每种技术都支持基于其中任何一种的特定结果。我们意识到最常见的是朴素贝叶斯，决策树，随机森林和逻辑回归。</p><p>在这种情况下，很难比较这些工作并选择最适合每种利用方案的工作。此外，每项工作中提供的评估结果并不是评估其有效性的非常有用的方法，主要有两个原因[7] :( i）每项工作都使用特定的数据集来进行评估; （ii）使用的数据集具有有限的代表性[7]。</p><p>该实践经验报告提供了一项比较研究，以评估现有方法预测C / C ++软件项目漏洞的有效性。该研究基于一个大型数据集[7]，其中包含有关函数和文件的软件度量的信息，以及从安全角度来看五个项目中是否存在安全漏洞，因为它们被广泛使用并暴露于攻击。使用此数据集，可以评估第三方工作中呈现的预测模型的有效性。我们复制了六项研究中提出的方法，这些研究涉及基于软件指标预测软件漏洞。</p><p>此篇文章的结构如下。第二节介绍了进行的研究。第三节介绍并讨论了取得的成果。第四部分回顾了相关工作，第五部分讨论了对本研究有效性的潜在威胁，第六部分总结了论文。</p><h1 id="II-研究"><a href="#II-研究" class="headerlink" title="II.研究"></a>II.研究</h1><p>本研究提出了在C / C ++软件环境下脆弱性预测方法有效性的实验评估。主要目标是从文献中提出的方法中了解哪些方法能够产生更好的模型来预测脆弱性。在实践中，该研究试图回答以下问题：</p><ul><li><p>生成的模型于预测易受攻击的文件并避免误报有多好用？</p></li><li><p>在这种环境中哪些技术表现更好？</p></li><li><p>表征方法有效性的最佳指标是什么？</p></li></ul><p>为了回答这个问题，我们设计了一种基于五个关键组件的方法，如图1所示。以下小节将讨论这些组件中的每一个。</p><p><img src="/2019/04/08/Experimenting-machine-learning-techniques-to-predict-vulnerabilities/1.jpg" alt=""></p><h2 id="A-数据集"><a href="#A-数据集" class="headerlink" title="A. 数据集"></a>A. 数据集</h2><p>评估中使用的数据集在[7]中给出，可以从[10]下载。它包含有关函数和文件的软件度量标准以及是否存在安全漏洞的信息。表I列出了数据集中的数据摘要。我们可以观察到，数据集是基于2186安全补丁和相应源存储库的4372个快照构建的：1对应于紧接在补丁之前的提交，1对应于紧随其后的提交。</p><p><img src="/2019/04/08/Experimenting-machine-learning-techniques-to-predict-vulnerabilities/2.jpg" alt="table 1"></p><p>此数据集包含有关函数，文件的软件度量以及是否存在安全漏洞的信息。这些信息是针对五个开源项目收集的：Mozilla Firefox，Linux内核，Xen Hypervisor，Httpd和Glibc。这些项目具有良好的安全性，是区分漏洞的良好选择，因为它们是不同领域的项目。 Mozilla是一个Web浏览器，Linux内核是操作系统内核，Xen是虚拟器环境，Httpd是通信协议，Glibc是用C编写的系统调用库。<br>最后，如图II-A所示，与中性代码相比，易受攻击代码的百分比非常低。</p><p><img src="/2019/04/08/Experimenting-machine-learning-techniques-to-predict-vulnerabilities/3.jpg" alt="fig 2"></p><h2 id="B-测试主题平衡和验证"><a href="#B-测试主题平衡和验证" class="headerlink" title="B.测试主题平衡和验证"></a>B.测试主题平衡和验证</h2><p>在这种工作中预计会出现差异，因为预计在这种数据集中，易受攻击的实例的数量远远小于非易受攻击的实例的数量。因此，针对此类任务的所有方法都需要执行数据平衡。<br>评估的方法涉及称为随机欠采样（RU）的平衡技术，移除随机选择的多数类数据。选定的比例是直到多数类中的数据实例数与少数类的数相同。<br>同样重要的是要强调的是，不同的方法对结果交叉验证使用不同的策略。在某些情况下，它使用了10倍交叉验证（[9]），而在其他情况下，这种重复使用重复10次，命名为10x10倍验证[6]，[11]。最后，一些案例使用下一个版本验证（Release-fold），其中模型使用以前的版本进行训练，并使用下一个版本进行测试[5]，[12]。这些配置总结在表II的配置列中。</p><p><img src="/2019/04/08/Experimenting-machine-learning-techniques-to-predict-vulnerabilities/4.jpg" alt=""></p><h2 id="C-评估方法"><a href="#C-评估方法" class="headerlink" title="C.评估方法"></a>C.评估方法</h2><p>在我们的研究中评估的方法来自已发布的工作，这些作品使用软件度量来构建预测模型，以找到具有更高可能性的漏洞的文件。</p><p>在[12]中提出了使用九种代码复杂度指标的案例研究。该方法提交来自Mozilla模块训练预测模型的逻辑回归数据。他们的结果表明，复杂度指标能够识别最容易出现漏洞的区域，但是，这种方法仍需要改进，因为结果显示低误报率和高假阴性率。</p><p>类似地，在[9]中使用了17个软件度量来训练预测模型，其中7个特定于面向对象语言。作者使用四台机器避免了最大限度，因为它们代表了不再关注模型的易受攻击的代码。</p><h2 id="E-方法有效性的指标"><a href="#E-方法有效性的指标" class="headerlink" title="E.方法有效性的指标"></a>E.方法有效性的指标</h2><p>在我们的分析过程中，我们使用下面提供的一组指标来表征这些方法的有效性。这些指标是根据实验期间获得的基本测量值计算的：真阳性（TP）;误报（FP）;真阴性（TN）;和漏报（FN）。</p><p>准确度（1）表示正确分类的案例与总案例之间的比例。误报率（fpr）（2）表示错误预测的文件与实际中性文件易受攻击的比率。高fpr显示模型将许多实例作为误报返回给开发人员。<br>$$<br>accuracy = \cfrac{T P + T N}{T P + F N + T N + F P}<br>$$</p><p>$$<br>fpr = \cfrac{F P}{T N + F P}<br>$$</p><p>我们还使用了长期用于表征系统有效性的指标，特别是在信息检索领域。精度（3）表示正确预测的易受攻击文件与检测到的所有文件的比率。Recall（4）描述了模型正确预测为易受攻击的真实易受攻击文件的百分比。也称为真阳性率，它与模型如何覆盖易受攻击的实例有关。最后，FMeasure（5），也称为F1Score，代表精度和召回的调和平均值。<br>$$<br>precision = \cfrac{T P}{T P + F P}<br>$$</p><p>$$<br>recall = \cfrac{T P}{T P + F N} = tpr<br>$$</p><p>$$<br>FMeasure = 2 <em> \cfrac{precision </em> recall}{precision + recall} = F_1Score<br>$$</p><p>虽然这些指标解决了不同的问题，但所有这些指标都存在一些可能影响其有用性和代表性的偏见[14]：1）阳性样例的患病率; 2）模型的偏差; 3）倾斜; 4）成本比率。这些偏见促使我们在分析中包含不同的指标。</p><p>受到博彩公司赔率[15]的启发，提出了无偏见的指标来表征考虑分类比例的预测因子的有效性，类似于投注赔率。Bookmaker Informedness（6）描述了预测因子的有效性，考虑了结果比例的测量。它量化了预测变量预测结果的一致程度，即预测变量对指定条件的信息与机会的相关性。另一方面，Markedness（7）量化了结果将预测变量作为标记的一致性，即指定预测变量的条件与机会的标记程度。<br>$$<br>Informedness =  \cfrac{T P}{T P + F N} - \cfrac{F P}{T N + F P}<br>$$</p><p>$$<br>Markedness = \cfrac{T P}{T P + F P} - \cfrac{F N}{T N + F N}<br>$$</p><p><img src="/2019/04/08/Experimenting-machine-learning-techniques-to-predict-vulnerabilities/6.jpg" alt="table 3"></p><h1 id="III-结果和讨论"><a href="#III-结果和讨论" class="headerlink" title="III.结果和讨论"></a>III.结果和讨论</h1><p>在平衡数据集中应用论文的方法，我们得到了表III中的结果。我们可以观察到，取得的成果差异很大。精度值范围为0.32％至30.50％，召回值范围为0.36％至100.00％。</p><p>通过使用决策树算法的方法获得了精确度方面的最佳结果。 Logistic回归在recall方面呈现出最佳结果，但在精确度方面表现非常糟糕，这降低了报告实例的可信度。重要的是要注意该方法可以配置和调整，即配置要使用的阈值，但由于缺乏信息，我们使用了Weka的默认配置。</p><p>精确度度量的结果对于描述这些技术的有效性似乎并不十分有用。我们可以观察到，许多技术的准确度高于50％，除了7个案例从7.59％到45.33％不等，3个案例等于0.52％。然而，其中许多案例的精确度不到1％。精确度量提供的结果也没那么有用，因为它们专注于误报并完全忽略漏报。如果模型过于专注于避免误报，那么它最终会报告少量的真阳性。<br>标记是一个更完整的指标，因为它也认为是假阴性。</p><p>我们可以清楚地看到，大多数方法的精度值非常低。这是因为学习模型报告的误报太多，因为他们使用平衡数据集进行训练，但随后使用不平衡数据集进行测试。这种不平衡的数据集具有更多中性实例，其中一些最终报告为易受攻击。</p><p>三种方法实现了100％的召回，另外六种方法实现了超过80％的召回。虽然这看起来非常令人印象深刻，但当我们考虑到机会以及假阳性和真阴性的分布时，我们理解结果并不像第一眼看上去那么好。事实上，没有一种方法达到Informedness值高于45％。这表明，在某些情况下，召回可能是误导性的指标。</p><p>由于精确度和召回率的这种限制，我们决定使用度量informedness 和markedness 对技术进行更详细的分析，这些分析不会受到偏差的影响。图3显示了这两个指标的所有方法的结果摘要。</p><p>第一个观察结果是树的方法在informedness 方面明显优于其他方法：23,24,27。正如我们所看到的，方法6,7,8显然远离这些树方法，尽管它们呈现出更高的recall比那些方法。事实上，只比较informedness 值，我们可以看到，在（4,6,7,8,26）中考虑了一系列机会非常差的方法。如上所述，虽然这些方法似乎具有非常高的召回率，但实际上这种高召回率是由于所产生的模型报告的事件比其余方法更为积极，导致误报过多。</p><p><img src="/2019/04/08/Experimenting-machine-learning-techniques-to-predict-vulnerabilities/5.jpg" alt=""></p><h1 id="IV-相关工作"><a href="#IV-相关工作" class="headerlink" title="IV 相关工作"></a>IV 相关工作</h1><p>I软件度量已被多次使用，以训练有效预测故障的预测模型[16]，[17]，[18]。虽然圈复杂度受到了很多关注，但其他指标也与理解代码有关。例如，有一段时间讨论了哪个是“最具预测性”的指标：Cyclomatic Complexity或LoC数量[18]。我们认为，在安全漏洞的情况下，这些指标与具有报告漏洞的代码之间存在某种关系。下面我们回顾一下这些工作并讨论它们的优点和缺点。</p><p>一些工作集中评估和比较不同的技术。对于实际情况，将使用文本挖掘技术获得的结果与基于软件度量的方法进行比较，如[13]中所述。这些实验基于三个开源php项目的223个漏洞：Drupal，Moodle和PHPMyAdmin。在所有三种应用中，文本挖掘模型具有比软件度量更高的召回率。但是，使用的数据集具有明显的代表性问题</p><p>鉴于CCC指标在识别漏洞方面显示的有趣结果，[9]提出了一个框架，通过使用CCC指标和现有的机器学习技术自动预测漏洞。通过对Mozilla Firefox进行实证研究并使用四个预测器C4.5决策树，随机森林，Logistic回归和Naive Bayes来验证所提出的方法。结果表明，这些预测器能够预测与Mozilla Firefox中的文件相关的大部分漏洞。<br>[19]中的工作提供了几种机器学习方法的比较分析，其中哪些方法在检测代码气味方面更有效。基于手动验证的数据集，在总共16种算法中包括若干技术和配置。在检测代码气味时，一些技术的准确度高于96％，使用决策树和随机森林算法可以获得最佳结果。</p><h1 id="V-对有效性的威胁"><a href="#V-对有效性的威胁" class="headerlink" title="V.对有效性的威胁"></a>V.对有效性的威胁</h1><p>实验的有效性受到以下威胁：T1）并非所有方法的配置都可用，不能保证实验在理想条件下再现。 T2）数据集包含报告的漏洞，因此可能存在从未识别的易受攻击的代码。 T3）最后的威胁是，这些方法中的某些方法是针对不同语言提出的，而不是数据集代码：C / C ++。</p><h1 id="VI-结论"><a href="#VI-结论" class="headerlink" title="VI. 结论"></a>VI. 结论</h1><p>本实践经验报告对基于软件指标的18种最先进的漏洞预测方法进行了评估。此评估基于一个大型且具有代表性的数据集，该数据集构建了五个广泛使用的开源项目中2875个漏洞的信息。</p><p>有可能观察到这样的传统指标，如准确性在这种情况下可能不是很有用，而且即使使用平衡数据集，精度和召回也可能略有误导。另一方面，诸如informedness 和markedness 等指标更有效。</p><p>结果表明，一些方法明显优于其他方法，随机森林实施在所考虑的所有指标中都取得了非常高的结果。<br>未来的工作包括根据所考虑的语言扩大该分析的范围，以及脆弱性预测算法的基准程序提案</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h1&gt;&lt;p&gt;软件度量标准可用作软件漏洞存在的指示器。这些指标已用于机器学习，以预测容易包含漏洞的源代码。
      
    
    </summary>
    
      <category term="论文" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/"/>
    
      <category term="fuzzing" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/fuzzing/"/>
    
      <category term="评估" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/fuzzing/%E8%AF%84%E4%BC%B0/"/>
    
    
      <category term="综述" scheme="http://yama0xff.com/tags/%E7%BB%BC%E8%BF%B0/"/>
    
      <category term="2016年" scheme="http://yama0xff.com/tags/2016%E5%B9%B4/"/>
    
      <category term="评估" scheme="http://yama0xff.com/tags/%E8%AF%84%E4%BC%B0/"/>
    
  </entry>
  
  <entry>
    <title>如何做科研</title>
    <link href="http://yama0xff.com/2019/04/04/%E5%A6%82%E4%BD%95%E5%81%9A%E7%A7%91%E7%A0%94/"/>
    <id>http://yama0xff.com/2019/04/04/如何做科研/</id>
    <published>2019-04-04T06:32:22.000Z</published>
    <updated>2019-04-04T08:14:12.803Z</updated>
    
    <content type="html"><![CDATA[<p>内容主要分为四个部分：1.科学研究的内涵与外延。2.科学研究的方法与手段。3.博士生如何开展科学工作。4.其它。该内容为上课中从王俊峰教授PPT中记录而来。主要介绍了博士生在读博期间如何做科研的相关问题。</p><h1 id="1-科学研究的内涵与外延"><a href="#1-科学研究的内涵与外延" class="headerlink" title="1. 科学研究的内涵与外延"></a>1. 科学研究的内涵与外延</h1><h2 id="1-1-对科学研究的认识"><a href="#1-1-对科学研究的认识" class="headerlink" title="1.1 对科学研究的认识"></a>1.1 对科学研究的认识</h2><h4 id="相当普遍的看法"><a href="#相当普遍的看法" class="headerlink" title="相当普遍的看法"></a>相当普遍的看法</h4><ul><li>开发一个软/硬件系统或平台</li><li>解决一个有难度的理论问题</li><li>发表了高水平的学术论文</li><li>发表了很多篇SCI/EI/ISTP检索的论文</li><li>申请了软件登记、发明专利、提交了标准或草案</li><li>升职或获得学位</li></ul><h4 id="上述看法都是片面的"><a href="#上述看法都是片面的" class="headerlink" title="上述看法都是片面的"></a>上述看法都是片面的</h4><ul><li>不是发论文、争名利、混学位</li></ul><h4 id="启发性的观点"><a href="#启发性的观点" class="headerlink" title="启发性的观点"></a>启发性的观点</h4><ul><li>是<strong>发现问题，解决问题</strong>的过程</li><li>是<strong>要做创新的工作</strong></li><li>科学研究是<strong>多样性的</strong>，没有固定的模式</li></ul><h4 id="更客观的观点"><a href="#更客观的观点" class="headerlink" title="更客观的观点"></a>更客观的观点</h4><ul><li>科学研究是对未知的客观事件认知的过程，加深人类对客观世界的理解，扩展人类对客观事件的利用、改造和适应的能力。</li></ul><h2 id="1-2-科学研究的目的和意义"><a href="#1-2-科学研究的目的和意义" class="headerlink" title="1.2 科学研究的目的和意义"></a>1.2 科学研究的目的和意义</h2><h4 id="解决实际存在的问题（第一阶段）"><a href="#解决实际存在的问题（第一阶段）" class="headerlink" title="解决实际存在的问题（第一阶段）"></a>解决实际存在的问题（第一阶段）</h4><ul><li>发现需求和问题是进行科学研究的前提条件</li><li>利用、改造和适应客观世界</li></ul><h4 id="探索未知的领域（第二阶段）"><a href="#探索未知的领域（第二阶段）" class="headerlink" title="探索未知的领域（第二阶段）"></a>探索未知的领域（第二阶段）</h4><ul><li>从未知到已知</li></ul><h2 id="1-3-科学研究成果"><a href="#1-3-科学研究成果" class="headerlink" title="1.3 科学研究成果"></a>1.3 科学研究成果</h2><h4 id="主要研究成果"><a href="#主要研究成果" class="headerlink" title="主要研究成果"></a>主要研究成果</h4><ul><li>最有价值的是思想</li><li>思想的交流</li></ul><h4 id="研究成果的载体"><a href="#研究成果的载体" class="headerlink" title="研究成果的载体"></a>研究成果的载体</h4><ul><li>学术论文、研究报告、专著、专利、奖励</li><li>只能从一个侧面反映所获得研究成果和思想体会</li></ul><h4 id="现状"><a href="#现状" class="headerlink" title="现状"></a>现状</h4><ul><li>学术论文是研究成果的主要窄体</li><li>学术论文是获得博士学位的前提条件</li></ul><hr><h1 id="2-科学研究的方法与手段"><a href="#2-科学研究的方法与手段" class="headerlink" title="2. 科学研究的方法与手段"></a>2. 科学研究的方法与手段</h1><h2 id="2-1-科学研究的一般过程-–-提出问题"><a href="#2-1-科学研究的一般过程-–-提出问题" class="headerlink" title="2.1 科学研究的一般过程 – 提出问题"></a>2.1 科学研究的一般过程 – 提出问题</h2><h4 id="发现问题"><a href="#发现问题" class="headerlink" title="发现问题"></a>发现问题</h4><ul><li>科研工作中发现问题是最重要的步骤</li><li>问题或需求驱动研究</li><li>一流高手提问题、二流高手解问题、三流高手做习题</li></ul><h4 id="如何发现问题"><a href="#如何发现问题" class="headerlink" title="如何发现问题"></a>如何发现问题</h4><ul><li>在打的研究方向上需要经验</li><li>那些已清除定义的问题，往往研究空间很小，且难度也大</li><li>从实际工作中发现问题，从综述中凝练问题，从前人工作不总中挖掘问题</li></ul><h4 id="问题的抽象"><a href="#问题的抽象" class="headerlink" title="问题的抽象"></a>问题的抽象</h4><ul><li>不能<strong>只见树木，不见森林</strong>，<strong>跳出问题看问题</strong></li></ul><h2 id="2-2-科学研究的一般过程-–-分析问题"><a href="#2-2-科学研究的一般过程-–-分析问题" class="headerlink" title="2.2 科学研究的一般过程 – 分析问题"></a>2.2 科学研究的一般过程 – 分析问题</h2><h4 id="在解决问题之前，需要对问题有准确的定义"><a href="#在解决问题之前，需要对问题有准确的定义" class="headerlink" title="在解决问题之前，需要对问题有准确的定义"></a>在解决问题之前，需要对问题有准确的定义</h4><ul><li>理清问题的来龙去脉</li><li>给出问题的清晰定义，深入理解问题</li><li>问题的分析要“言之有理”，“言之有物”</li></ul><h4 id="“分而治之”的分析方法"><a href="#“分而治之”的分析方法" class="headerlink" title="“分而治之”的分析方法"></a>“分而治之”的分析方法</h4><ul><li>将无从下手的大问题分解成具体的小问题</li><li>“细分”与“专业化”是科学研究的重要发展</li><li>在“细分”的过程中发现研究的机会</li></ul><h4 id="注意联系的思想"><a href="#注意联系的思想" class="headerlink" title="注意联系的思想"></a>注意联系的思想</h4><ul><li>注意学科交叉、方法借鉴</li></ul><h4 id="注意问题背后的假设与场景"><a href="#注意问题背后的假设与场景" class="headerlink" title="注意问题背后的假设与场景"></a>注意问题背后的假设与场景</h4><ul><li>假设与场景往往是问题存在的基石和前提条件</li><li>假设与场景的变化往往是影响问题的内涵，产生新的问题</li></ul><h4 id="问题的分析是个迭代的过程"><a href="#问题的分析是个迭代的过程" class="headerlink" title="问题的分析是个迭代的过程"></a>问题的分析是个迭代的过程</h4><h2 id="2-3-科学研究的一般过程-–-解决问题"><a href="#2-3-科学研究的一般过程-–-解决问题" class="headerlink" title="2.3 科学研究的一般过程 – 解决问题"></a>2.3 科学研究的一般过程 – 解决问题</h2><h4 id="分清主次，抓住重点"><a href="#分清主次，抓住重点" class="headerlink" title="分清主次，抓住重点"></a>分清主次，抓住重点</h4><ul><li>人的精力是有限的，不可能解决所有问题，彻底解决一个问题的可能性也不大</li><li>列出所有涉及的问题，按重要程度进行排序</li><li>列出正在解决问题所设计的关键技术，逐个攻关</li><li>博士生研究工作应是系统的，研究的问题应是相关的</li></ul><h4 id="先解决简单问题，积累经验后再解决复杂问题"><a href="#先解决简单问题，积累经验后再解决复杂问题" class="headerlink" title="先解决简单问题，积累经验后再解决复杂问题"></a>先解决简单问题，积累经验后再解决复杂问题</h4><ul><li>解决同样的问题，往往有很多思路，不应满足于一种思路</li><li>解决同样的问题，不同的思路或方法往往存在折中，找一种完美的方法对博士生来说可能是危险的</li><li>针对一种解决问题的思路，往往鱼与熊掌不可兼得</li></ul><h1 id="3-博士生如何开展科学工作"><a href="#3-博士生如何开展科学工作" class="headerlink" title="3. 博士生如何开展科学工作"></a>3. 博士生如何开展科学工作</h1><h2 id="3-1-博士生培养一般过程"><a href="#3-1-博士生培养一般过程" class="headerlink" title="3.1 博士生培养一般过程"></a>3.1 博士生培养一般过程</h2><table><thead><tr><th>阶段</th><th>事情</th><th>时间流程（月，总共3年）</th></tr></thead><tbody><tr><td>1</td><td>课程</td><td>10个月</td></tr><tr><td>2</td><td>选课</td><td></td></tr><tr><td>3</td><td>文献调研</td><td></td></tr><tr><td>4</td><td>科研设计</td><td></td></tr><tr><td>5</td><td>开题报告</td><td>15个月</td></tr><tr><td>6</td><td>科研工作</td><td></td></tr><tr><td>7</td><td>中期检查</td><td></td></tr><tr><td>8</td><td>整理资料</td><td></td></tr><tr><td>9</td><td>撰写论文</td><td>31个月</td></tr><tr><td>10</td><td>论文答辩</td><td>33个月</td></tr><tr><td>11</td><td>学位委员会审议</td><td></td></tr><tr><td>12</td><td>授予学位</td><td>34个月</td></tr></tbody></table><h2 id="3-2-博士生的心态"><a href="#3-2-博士生的心态" class="headerlink" title="3.2 博士生的心态"></a>3.2 博士生的心态</h2><h4 id="典型心态"><a href="#典型心态" class="headerlink" title="典型心态"></a>典型心态</h4><ul><li>茫然型：两眼一抹黑</li><li>躁动型：有感兴趣的研究方向，但无从下手</li><li>试探型：在做具体工作，不知能否做出成果</li><li>春风得意型：取得部分研究成果</li><li>失落型</li></ul><h4 id="古今之成大事业、大学问者，必经过三种之境界"><a href="#古今之成大事业、大学问者，必经过三种之境界" class="headerlink" title="古今之成大事业、大学问者，必经过三种之境界"></a>古今之成大事业、大学问者，必经过三种之境界</h4><ul><li>昨夜西风凋碧树，独上高楼，望尽天涯路。（晏殊）</li><li>衣带渐宽终不悔，为伊消得人憔悴。（柳永）</li><li>众里寻他千百度，蓦然回首，那人却在，灯火阑珊处。（辛弃疾）</li></ul><h2 id="3-3-如何选题-–-课题的来源"><a href="#3-3-如何选题-–-课题的来源" class="headerlink" title="3.3 如何选题 – 课题的来源"></a>3.3 如何选题 – 课题的来源</h2><h4 id="导师的项目"><a href="#导师的项目" class="headerlink" title="导师的项目"></a>导师的项目</h4><ul><li>科研项目：重点研发计划，NSFC，国防预研基金</li><li>开发项目：重大工程装备项目</li><li>横向委托：企业委托的一般开发项目</li></ul><h4 id="个人兴趣"><a href="#个人兴趣" class="headerlink" title="个人兴趣"></a>个人兴趣</h4><ul><li>通过个人工作积累，提炼出研究方向</li><li>延续硕士期间工作</li><li>突发灵感的研究方向，奇思妙想</li></ul><h4 id="跟风"><a href="#跟风" class="headerlink" title="跟风"></a>跟风</h4><ul><li>人做亦做</li><li>无病呻吟</li></ul><h4 id="3-4-如何定题"><a href="#3-4-如何定题" class="headerlink" title="3.4 如何定题"></a>3.4 如何定题</h4><ul><li>导师的科研项目：一般选题比较先进，有较大可能在较短时间内有做出成果，认可度高</li><li>导师的重大开发项目：应结合国家或行业重大应用提炼问题，有较大可能在短期内得到应用推广，认可程度高</li><li>通过个人积累或延续前期工作，也有望在较短时间内做出程度，认可程度较高</li><li>横向委托项目：一般不宜作为博士生的选题方向，采用成熟的技术，不侧重与理论或技术上创新，风险较大</li><li>跟风选题：认可程度高，具体方向需要提炼，风险大</li><li>突发灵感的选题：看运气</li></ul><h2 id="3-5-如何查资料-–-SCI、EI、ISTP"><a href="#3-5-如何查资料-–-SCI、EI、ISTP" class="headerlink" title="3.5 如何查资料 – SCI、EI、ISTP"></a>3.5 如何查资料 – SCI、EI、ISTP</h2><ul><li>科学引文索引：SCI, Science Citation Index</li><li>工程索引：EI, Engineering Index</li><li>科技会议论文集索引：ISTP, Index to Scientific &amp; Technical PRoceedings</li></ul><h4 id="国内电子信息类"><a href="#国内电子信息类" class="headerlink" title="国内电子信息类"></a>国内电子信息类</h4><ul><li>中国科学E辑</li><li>中国科学E辑，英文版</li><li>JCST</li><li>电子学报英文版</li><li>计算机学报英文版</li><li>软件学报</li><li>计算机研究与发展</li><li>通信学报</li><li>系统工程与电子学英文版</li><li>航空学报英文版</li><li>几个高校学报</li></ul><h4 id="重要的外文全文数据库"><a href="#重要的外文全文数据库" class="headerlink" title="重要的外文全文数据库"></a>重要的外文全文数据库</h4><ul><li>ACM(美国计算机学会)Digital Library</li><li>IEL (IEEE/IEE E;ectronic Library)</li><li>Elsevier SDOS</li><li>Springer- Link</li><li>Kluwer Online Journals</li><li>Wiley InrerScience</li><li>WorldSciNet</li><li>ISI Web of Science//档次稍微低点</li><li>EI Village//档次稍微低点</li><li>PQDD·B（博硕士论文网络数据库）//档次稍微低点</li></ul><h4 id="好的习惯"><a href="#好的习惯" class="headerlink" title="好的习惯"></a>好的习惯</h4><ul><li>建立本领域主流期刊、重要会议、主要科研团队和知名专家数据库</li><li>订阅期刊目录（Table of Contents）邮件列表</li><li>定期浏览主流刊物主页，了解感兴趣研究论文摘要</li><li>关注本领域主要国际会议的Conference Program</li><li>定期了解主流科研团队和专家的科研进展，科研重点，Survey或Keynote Speech、</li></ul><h2 id="3-6-如何阅读文献-–-自上而下的方法"><a href="#3-6-如何阅读文献-–-自上而下的方法" class="headerlink" title="3.6 如何阅读文献 – 自上而下的方法"></a>3.6 如何阅读文献 – 自上而下的方法</h2><h4 id="阅读文献的两种目的"><a href="#阅读文献的两种目的" class="headerlink" title="阅读文献的两种目的"></a>阅读文献的两种目的</h4><ul><li>已有具体研究问题，通过阅读文献找到解决方法</li><li>无具体研究问题，通过阅读文献来找问题</li></ul><h4 id="从Survey-Review-the-State-of-the-Art-Tutorial入手"><a href="#从Survey-Review-the-State-of-the-Art-Tutorial入手" class="headerlink" title="从Survey , Review, the State of the Art, Tutorial入手"></a>从Survey , Review, the State of the Art, Tutorial入手</h4><ul><li>Google、Google Scholar</li><li>IEEE COMM Survey &amp;Tutorial</li><li>期刊或会议中Related Work</li></ul><h4 id="泛读为主"><a href="#泛读为主" class="headerlink" title="泛读为主"></a>泛读为主</h4><ul><li>侧重于摘要、前言与结论</li></ul><h4 id="广度优先"><a href="#广度优先" class="headerlink" title="广度优先"></a>广度优先</h4><ul><li>针对一个具体问题，看20-30篇密切相关的文献</li><li>论文太多，无法聚焦</li><li>针对3-5篇文献，精度，深度优先</li></ul><h4 id="带着问题看文献"><a href="#带着问题看文献" class="headerlink" title="带着问题看文献"></a>带着问题看文献</h4><ul><li>能解决自己所遇到的问题？</li><li>哪些问题不能解决？</li><li>…</li></ul><h4 id="挑剔的眼光看文献"><a href="#挑剔的眼光看文献" class="headerlink" title="挑剔的眼光看文献"></a>挑剔的眼光看文献</h4><ul><li>在新的应用背景下的自适应新如何？</li><li>方法或技术效率如何？</li></ul><h2 id="3-7-开展具体研究工作"><a href="#3-7-开展具体研究工作" class="headerlink" title="3.7 开展具体研究工作"></a>3.7 开展具体研究工作</h2><ul><li>因学科领域不同而不同</li><li>因人而异</li><li>研究过程本身无统一标准</li><li>研究过程无优劣之分</li></ul><h1 id="4-其它"><a href="#4-其它" class="headerlink" title="4. 其它"></a>4. 其它</h1><h2 id="4-1-朴素的博士生科研工作观"><a href="#4-1-朴素的博士生科研工作观" class="headerlink" title="4.1 朴素的博士生科研工作观"></a>4.1 朴素的博士生科研工作观</h2><ul><li>要踏踏实实，勤勤恳恳，甚至默默无闻；不要指望做明星</li><li>要循序渐进，一步登天可能性不大</li><li>要学会从事本领域科研工作的基本技能，先做实干家，在做指挥家</li><li>不要经常师徒去颠覆经典理论，时间有限，又开创新理论可能时先与导师沟通</li><li>不要在自己的研究成果中严厉地批评他人的成果，更不能人生攻击，就事论事，宜委婉</li><li>不要挑剔所从事的科研项目优劣，导师也在探索过程中，博士生是科研的主力军</li><li>不以物喜，不以己悲（范仲淹）</li></ul><h2 id="4-2-数学基础很重要？"><a href="#4-2-数学基础很重要？" class="headerlink" title="4.2 数学基础很重要？"></a>4.2 数学基础很重要？</h2><ul><li>数学基础和能力比较重要</li><li>数学基础不是影响博士生研究工作质量的主要因素，更不是罪关键因素</li><li>时间有限，不要无的放矢的学数学</li><li>带着问题补充相关的数学基础</li><li>对论文中所采用的新颖数学方法要有敏感、博闻</li><li>经常泛读相关的数学书</li></ul><h2 id="4-3-英语很重要？"><a href="#4-3-英语很重要？" class="headerlink" title="4.3 英语很重要？"></a>4.3 英语很重要？</h2><ul><li>英语基础和写作能力比较重要</li><li>时间有限，不要无的放矢的学英语</li><li>通过阅读专业文献学英语</li><li>英语写作要学会模范，但不是抄袭</li><li>不要以应对英语写作的方式写英文报告或论文</li><li>不要卖弄英语文发，少使用长句，不使用生僻词</li></ul><h2 id="4-4-基本技能要掌握"><a href="#4-4-基本技能要掌握" class="headerlink" title="4.4 基本技能要掌握"></a>4.4 基本技能要掌握</h2><ul><li>至少要精通word,有条件学习LaTex</li><li>至少要使用好一种绘图工具</li><li>至少要使用好一种仿真工具（计算机网络领域，其它未知）</li></ul><h2 id="4-5-结束语"><a href="#4-5-结束语" class="headerlink" title="4.5 结束语"></a>4.5 结束语</h2><ul><li>博士生阶段做什么具体课题是次要的，重要的是一种训练过程和思考问题的方法</li><li>博士生阶段是最艰苦的阶段之一，是最值得怀恋的经历之一</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;内容主要分为四个部分：1.科学研究的内涵与外延。2.科学研究的方法与手段。3.博士生如何开展科学工作。4.其它。该内容为上课中从王俊峰教授PPT中记录而来。主要介绍了博士生在读博期间如何做科研的相关问题。&lt;/p&gt;
&lt;h1 id=&quot;1-科学研究的内涵与外延&quot;&gt;&lt;a href=
      
    
    </summary>
    
      <category term="科研" scheme="http://yama0xff.com/categories/%E7%A7%91%E7%A0%94/"/>
    
    
      <category term="科研" scheme="http://yama0xff.com/tags/%E7%A7%91%E7%A0%94/"/>
    
  </entry>
  
  <entry>
    <title>A Review of Machine Learning in Software Vulnerability Research</title>
    <link href="http://yama0xff.com/2019/04/03/A-Review-of-Machine-Learning-in-Software-Vulnerability-Research/"/>
    <id>http://yama0xff.com/2019/04/03/A-Review-of-Machine-Learning-in-Software-Vulnerability-Research/</id>
    <published>2019-04-03T08:16:36.000Z</published>
    <updated>2019-04-04T12:55:23.551Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>搜索和识别计算机软件中的漏洞具有悠久而丰富的历史，可用于预防或恶意目的。在本文中，我们研究了机器学习（ML）技术在软件漏洞研究（SVR）中的应用，讨论了以前和当前的工作，以说明学术界和工业界如何利用ML。我们发现，主要关注的不仅仅是发现新方法，而是通过简化和自动化流程来帮助SVR从业者。考虑到已经证明的各种应用，我们相信ML将在未来继续为SVR提供帮助，因为探索了新的使用领域，并且可以使用改进的算法来增强现有功能。</p><table><thead><tr><th>relevant information</th><th></th></tr></thead><tbody><tr><td><em>作者</em></td><td>Tamas Abraham  and Olivier de Vel</td></tr><tr><td><em>单位</em></td><td>Cyber and Electronic Warfare Division  Principal Scientist<br>Defence Science and Technology Group</td></tr><tr><td><em>出处</em></td><td>Cyber and Electronic Warfare Division</td></tr><tr><td><em>原文地址</em></td><td><a href="https://www.dst.defence.gov.au/sites/default/files/publications/documents/DST-Group-GD-0979.pdf" target="_blank" rel="noopener">https://www.dst.defence.gov.au/sites/default/files/publications/documents/DST-Group-GD-0979.pdf</a></td></tr><tr><td><em>源码地址</em></td><td></td></tr><tr><td><em>发表时间</em></td><td>2017年</td></tr></tbody></table><h1 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h1><p>创建计算机软件是一个非常重要的复杂过程，通常会产生包含一些缺陷和脆弱点的代码。大型代码库的验证可能很困难，或者有时由于成本而被忽略，导致操作系统由于它们表现出来的意外和不良行为而可能崩溃或被操纵。虽然软件安全性错误的严重程度是可变的，但有些可能会非常严重，以至于被利用导致生产力损失，知识产权损失甚至物理损坏来对用户造成严重伤害。 Dowd等人[30]将术语软件错误中能被用于恶意目的的子类称为漏洞， 虽然在特定环境中实际利用漏洞可能并非总是可能，或者也不适合攻击者的目标。解决易受攻击软件引起的问题的方法已经在软件漏洞研究（SVR）中创建了研究。<br>对影响计算机系统的漏洞的研究不仅限于软件。但是，我们在本文中的重点是基于软件的漏洞，我们不考虑硬件或系统架构。软件本身可以作为源代码或二进制文件进行分析，提供多种途径来发现漏洞。软件漏洞的研究过程可以定期分为发现，分析和利用的过程，并将缓解作为预防活动[73]。每个阶段探讨了处理漏洞的不同方面，通常需要代码审计员等从业者的长期和费力的投入。自动化在许多SVR活动中起着重要作用，然而目前通过人工解释发现了大多数漏洞。越来越多的机器学习（ML）技术被整合到SVR过程中，以进一步减少对手动交互的需求。成功应用后，ML算法可以引导用户找到最可能的解决方案，并可能发现以前未知的漏洞。本文的目的是对利用机器学习的SVR内部的目录进行编目，以突出当前事业的状态，并确定可能在未来做出进一步贡献的可能领域。</p><h1 id="2-背景"><a href="#2-背景" class="headerlink" title="2. 背景"></a>2. 背景</h1><p>本文的重点是机器学习在软件漏洞研究中的应用。为了进行讨论，我们分别介绍了两个领域和一些一般细节。在审查各个出版物时，后续章节将根据需要提供进一步的详情。接下来是对这两个研究领域的简单概述，在这个阶段，没有强调它们之间的任何联系。</p><h2 id="2-1-软件漏洞研究"><a href="#2-1-软件漏洞研究" class="headerlink" title="2.1 软件漏洞研究"></a>2.1 软件漏洞研究</h2><p>对软件漏洞进行分类不是一项简单的任务。特定漏洞所属的类别通常在分析软件错误期间显示。有时，在漏洞发现过程中可以预期某种类型，因为某些技术隐含地针对有限范围的漏洞类型。<strong>扫描程序</strong>等工具会查找错误的结构，例如过时的库函数以及代码中的其他与安全相关的错误。<strong>模糊测试</strong>是为软件可执行文件提供异常输入以引起意外行为（如崩溃或内存泄漏）的过程，然后可以在相应的源代码中进行调查。全面的<strong>手动代码审查</strong>也可用于发现错误，但它们可能是其他漏洞发现方法的昂贵替代方案。<strong>格式校验</strong>提供了正确性的数学证明，如果不成功，则可以指出问题。然而，由于复杂性和成本，它通常限于小代码段或算法。<strong>符号执行</strong>是一种分析通过程序分支遍历变量值（输入）的技术，是另一种发现方法，尽管它可能遭受诸如路径爆炸之类的扩展问题。</p><p>源代码中的一些错误可能很容易组合，尽管某些漏洞仅与其他因素（例如它们部署在其上的平台）结合使用，因此可能难以进行初始分类。计算机体系结构，操作系统，计算机语言的多样性以及语言特定错误的存在使分析更加复杂化。我们使用Dowd等人的书中给出的分类法 [30]作为定义软件漏洞类型的指南。语言特定问题包括：</p><ul><li><p>内存损坏，例如缓冲区（堆栈，off-by-one，堆，全局和静态数据）</p></li><li><p>算术边界条件（如数字上溢和下溢）</p></li><li><p>类型转换错误（有符号/无符号，符号扩展，截断，比较）</p></li><li><p>操作符误用（sizeof（），移位，模数，除法）</p></li><li><p>指针算术错误</p></li><li>其他错误（评估顺序逻辑，结构填充，优先级，宏/预处理器，拼写错误）</li></ul><p>其他漏洞更复杂。问题类别包括实际应用程序中存在的问题类别，例如与操作系统或应用程序平台相关的问题类别，即使基础问题可能由更简单的错误（如内存损坏或指针错误）引起：</p><ul><li><p>字符串和元字符漏洞</p></li><li><p>特定于操作系统的漏洞（特权问题，文件权限问题，竞争条件，进程，IPC，线程，环境和信令问题）</p></li><li><p>平台漏洞（SQL注入，跨站点脚本（XSS） ），跨站点请求伪造（CSRF），文件包含和访问，shell调用，配置，访问控制和授权？aws）</p></li></ul><p>对漏洞进行分类的另一种方法是从攻击角度出发。例如，Open Web Application Security Project [3]提供了一个攻击类型列表，并定期编译一系列顶级当代漏洞[1]，并非所有漏洞都与源代码或二进制文件有关。在那些注入攻击（代码，SQL，HTML脚本，远程文件和shell）和控制流劫持，如溢出（buffer，整数，字符串格式）和堆喷射类似于我们上面列出的那些。像Bletsch这样的其他作者提供类似的分类，讨论如何通过代码重用（面向返回的编程（ROP），返回到libc（RILC），面向跳转的编程（JOP））来利用漏洞[80]。 。</p><p>随着软件中的漏洞被发现，它们通常与更广泛的社区共享。The Common Vulnerabilities and Exposures  （CVE）是一个公知的信息安全漏洞和风险的库 [4]，目前由MITRE组织维护。漏洞通常附加一个分数来描述其严重性，通用漏洞评分系统（CVSS）[40]是最常用的评分标准之一。提供对CVE，分数和其他相关信息的访问的服务包括诸如开源漏洞数据库（OSVDB）和美国国家漏洞数据库（NVD）之类的数据库。和允许对新发现的漏洞进行实时更新的API（如VulnDB和vFeed）。根据不同类别中发现的漏洞数量，每年都会根据流行漏洞编制统计数据，尽管每种类型的攻击频率和严重程度之间可能没有相关性。例如，Price和Kouns [46]列出了跨站点脚本，SQL注入，跨站点请求伪造，文件包含，拒绝服务和过度攻击，这是2014年根据OSVDB最常见的滥用行为。</p><p>减轻软件漏洞影响的方法也产生了各种策略和解决方案。尽管可能无法实现完全错误预防，但软件生产商仍希望尽量减少其产品包含漏洞的可能性。这些包括在开发周期中的全面测试和修复错误，在软件发布后提供数据，以及在安全编程语言中编写代码。在Vanegue [82]中列出了在软件发布之前可以使用的漏洞发现技术列表，例如软件测试，模糊测试和程序验证（定理证明，抽象解释，模型检查）。使用抽象语法树（AST），控制流图（CFG），程序依赖图（PDG）和代码属性图（CPG）等图形建模代码执行可以帮助识别开发过程中的问题。 OS和硬件制造商也提供了软件发布后使用的其他缓解技术。数据执行保护（DEP）/不执行（NX），地址空间布局随机化（ASLR），指令集随机化（ISR），运行时检查（金丝雀，LibSafe），程序引导，控制流完整性（CFI），数据流完整性（DFI）和控制流锁定是当前使用的一些技术，参见[80]。用于执行各种发现任务的软件工具随时可用，包括商业和开源[87]。</p><p>程序分析是分析软件行为问题的核心。从理论上讲，软件错误的识别是不可判定的，即在一般情况下不可能编写程序来表示和计算另一个程序的所有可能的执行[67]。在实践中，某些程序行为可能会被忽略，因为它们与当前分析无关。然而，这可能导致在近似下 - 排除可能有效的行为，并且过度近似–包含可能但无效的行为–增加复杂性和资源需求。图1将一些程序分析技术组织到一个图表中，突出显示了各个方法的样式和自动化级别。静态分析在不执行程序的情况下进行，可以提供良好的代码覆盖率和所有可能执行的原因，但无法分析可执行环境，例如操作系统和硬件。另一方面，动态分析是在程序执行期间进行的，或者通过检测程序来分析行为。但是，它只能推断观察到的执行路径而不是所有可能的程序路径。</p><p><img src="/2019/04/03/A-Review-of-Machine-Learning-in-Software-Vulnerability-Research/1.jpg" alt=""></p><h2 id="2-2-机器学习"><a href="#2-2-机器学习" class="headerlink" title="2.2 机器学习"></a>2.2 机器学习</h2><p>在本节中，我们简要概述了机器学习概念，并重点介绍了我们在本文后面讨论的出版物中遇到的一些相关技术。<br>存在许多不同的分类法用于分类ML技术。为方便起见，我们使用Barber [13]的书作为本节的参考源，除非给出了具体的参考。</p><p>机器学习领域关注数据的自动化探索，产生可用于预测的描述性模型。通常，认识到两种主要的学习方式：<strong>监督学习</strong>从标记数据源构建其模型并关注预测的准确性，而<strong>无监督学习</strong>则集中于从未标记数据提供紧凑描述。除了这两种主要风格外，还可以观察到几种变化。<strong>异常检测</strong>会查找与建模模型不同的数据中的异常值。随着新数据的出现，<strong>在线学习</strong>能够不断更新模型。<strong>主动学习</strong>可以通过要求来自当前模型无法有效描述的环境区域的更多数据来构建更好的模型。<strong>强化学习</strong>能够以反复试验的方式与环境互动，以创建根据某种形式的奖励进行优化的模型。最后，<strong>半监督学习</strong>利用标记和未标记的数据，使用一种类型的数据来改进可以仅从其他类型的数据创建的模型。</p><p>多年来，在上述学习方式中已经提出并开发了大量算法。监督学习主要使用多种类型的分类器中的一种来预测数据点所属的组（类）。这是一种离散学习形式，因为输出仅限于一组值。当结果需要在一个值范围内时（即它是一个连续变量），回归就是使用的技术。最简单的分类算法之一是K-最近邻（kNN）算法，它通过查看其K个最近邻居的标签并选择最常见的邻居来确定数据点的类标签，例如基于实例学习使用数据集中的示例而不是使用从中构建的模型来决定类的决策。 NaïveBayes分类器是一种概率算法，它假设描述数据的变量之间具有条件独立性，以简化生成模型的构建。点的类标签是通过使用贝叶斯规则给出不同标签的数据的概率及其条件概率来估计的。其他分类技术对数据进行线性模型，并根据与已知示例计算的决策边界相对应的数据点的位置确定类成员资格。逻辑回归是一种分类算法，它使用最大似然函数来近似属于类的数据点的概率。线性支持向量机（SVM）产生超平面以分离类，使得平面每侧上的最近点之间的距离最大化。</p><p>决策树分类器将顺序决策过程建模为特殊图形，每个节点用作特征测试，以便给定特征的不同值沿着不同的分支布置。树的叶子决定了类型成员资格。从任何特定的示例数据集中，可以构建许多不同的树，并且通常使用来自单个数据集的多个树的组合来构建更好的模型。随机森林是决策树的集合，旨在提供对作为单个树创建的模型的改进预测。图表在表示用作分类器的各种形式的神经网络（NN）[14]中也很突出。神经网络按节点层组织，包含输入层和输出层，其间有隐藏层。每个节点对应于一个函数，该函数使用分配给节点连接边的权重将其输入值映射到单个输出值。 NN分类的流行变体包括多层感知器（MLP）前馈神经网络，卷积神经网络和长期短期记忆复现神经网络。神经网络也是深度学习的核心，深度学习是一种机器学习范式，它也关注数据表示的学习。</p><p>无监督学习通常与聚类分析相关联，即基于相似性的定义将数据组织成组。这些可以包括基于数据分布的统计方法，例如使用期望最大化（EM）来构建高斯混合模型（GMM）。利用数据连接的算法是层次聚类的示例，或者是自下而上构建的，即从每个数据点开始作为集群然后是合并操作，或者自上而下，从单个集群开始并根据某种策略进行拆分。基于质心的聚类通过确定选定数量的聚类中心并将每个数据点分配给最近的聚类中心来识别聚类。另一方面，基于密度的聚类根据某个距离测量的阈值找到彼此接近的点集群，并且如果它们不满足这些要求，则可以将数据保留为未分配的噪声。Associations [5]是受市场数据分析启发的规则。它们代表了if…then构造描述数据中以某种最小所需频率出现的强模式。找到频繁项目集或特征值比其他项目更频繁地出现，可以揭示数据的趋势。顺序模式挖掘是一种具有相同目标的学习活动，但随着时间的推移分析数据，利用数据点的时间顺序来构建模型。遗传算法也是规则发现算法，它通过将交叉和变异算子应用于初始数据集并评估后续世代的精度直到满足某些终止条件来模拟自然选择。</p><p>学习通常先于预处理过程，然后是模型评估等任务。一些预处理包括特征提取，以及数据中噪声和错误的处理。特征选择和降维旨在识别与学习任务相关的特征并降低复杂性以便改进由学习算法生成的模型。有监督和无监督的学习者都可以从这个过程中受益。一些重要的例子包括主成分分析（PCA），线性判别分析（LDA），非负矩阵因子分解（NMF）和奇异值分解（SVD）。采样以减少数据大小和平衡输入数据可以提高算法的效率和性能。使用套袋和增强等集成方法可以提高单个学习算法的预测性能。出于评估目的，可以使用性能评估方法来评估算法的有效性。在二进制分类中，可以使用若干概念来描述预测条件与数据点的实际条件之间的关系。真阳性（TP）或命中，是正确预测的阳性实例。假阳性（FP）是错误预测为阳性的阴性实例。对于真阴性和假阴性，存在类似的定义。真阳性率（TPR）或算法的召回是所有阳性实例的真阳性率。精度是TP与TP和FP之和的比率，表示在预测正实例时所犯错误的数量。算法的准确性是所有数据点上正确识别的实例（TP加TN）的比率。存在许多模型评估方法，例如ROC分析[31]。结合起来，它们不仅可以提供算法评估，还可以确定其他学习策略，例如不同的特征选择方法或参数优化。</p><p>机器学习已应用于众多研究领域。可以与检查计算机程序相关的一个是自然语言处理（NLP），这是一个关注语言建模，解析和语音识别等任务的领域。可用于文档分类的一些值得注意的技术包括Latent Dirichlet Allocation（LDA）和Latent Semantic Indexing（LSI），它们都将文本建模为主题集合。</p><h1 id="3-机器学习在软件漏洞中的研究"><a href="#3-机器学习在软件漏洞中的研究" class="headerlink" title="3.机器学习在软件漏洞中的研究"></a>3.机器学习在软件漏洞中的研究</h1><p>机器学习可以为软件漏洞研究等复杂的研究领域带来许多好处。它可用于模拟代码的语法和语义，并推断代码模式以分析大型代码库，协助代码审计和代码理解，同时实现可容忍的误报率。随着SVR流程复杂性的增加，对SVR从业者可用的自动化水平的需求也在增加。结果，提出了用于发现和预防目的的分析软件的新方法。其中一些是特别的。其他人使用来自其他科学领域的现成技术，包括统计学，机器学习和数据挖掘。在接下来的部分中，我们将讨论利用主要机器学习的现有工作，根据基于内容相似性的松散分组来组织它们。</p><p>我们首先指出一小部分最近的论文，这些论文考虑在更广泛的层面上解决软件漏洞问题。例如，Avgerinos等 [11]承认在广泛使用的大型软件项目中存在软件错误，例如Firefox浏览器和Linux内核，一些已知，但其他可能仍未被发现。由于在关键软件中发现了如此多的错误，作者提出了以下问题：“我们应该尝试优先修复哪些错误？”，“我们可以确定哪些是可利用的？” Jimenez等 [41]可能表明未来可能的方式。他们分析过去已知的漏洞（在本例中为Android）并建立一个分类，列出导致软件漏洞的问题，漏洞所在代码中位置的特征，这些位置的复杂性以及漏洞的复杂性。创建公共数据集，如VDiscovery [34]收集测试用例的结果，并可用于促进进一步的研究是另一项有希望的举措，众包试的寻找bug的想法这个模型由zhao等人描述[93]。</p><h2 id="3-1-源代码分析"><a href="#3-1-源代码分析" class="headerlink" title="3.1 源代码分析"></a>3.1 源代码分析</h2><p>如前所述，减少SVR人类从业者的手动任务量是许多提议方法的主要目标。自动化的例子包括Parfait [26]，一个用于发现C / C ++代码中的错误的框架。 Parfa的每个bug类型都设计有多层，用于速度和可扩展性的程序分析。该解决方案背后的理念是采用更简单的分析来预测某些类型的错误，然后转向计算量更大的错误，以实现最佳的覆盖率和精度。另一个平台Mélange[74]也分享了同样的理念，同时也分析了C和C ++代码。 Mélange执行数据和控制流分析，并生成错误报告，以解释发现的错误，以帮助解决必要的问题。在执行阶段进行分析，包含局部和全局，后者按需使用以验证局部分析的结果。另一个例子是SZZ算法[88]，它被开发用于自动识别诱导修复的代码提交，并且可以被研究人员用来验证软件度量或模型以预测故障组件，这是防止bug的重要活动。</p><p>然而，这些方法是向自动化迈进并不一定依赖于机器学习技术的示例。以下类别详细说明了它们的用途。</p><h3 id="3-1-1-编码实践"><a href="#3-1-1-编码实践" class="headerlink" title="3.1.1 编码实践"></a>3.1.1 编码实践</h3><p>用于代码分析的机器学习的早期用途之一是PR-Miner [50]，数据挖掘技术的应用，为源代码构建一组编程规则。它从大型代码库（如Linux，PostgreSQL和Apache HTTP Server）生成频繁的项目集，以自动生成隐式编程规则，然后可以使用其他算法检查违规。对结果进行排序并按照假设的严重程度提供给分析师，以确定它们是否构成实际错误。这个过程很快，作者认为它能够识别比使用用户定义模板的类似工具更复杂的违规行为（例如，包含两个以上的规则组件）。 AutoISES [77]是一种类似的工具，它通过从源代码推断安全规范来检测漏洞，而不是要求手动提供这些漏洞。规范的推断仍然受到与安全编码实践相关的概念的指导，但现在根据代码中观察到的证据提取规则，并且违规被提供用于手动验证。 Linux内核和Xen用作测试用例，对于84个提取规则，发现了8个新漏洞。</p><p>协助开发人员正确使用应用程序编程接口（API）方法一直是一些论文的焦点，通常受到缺乏足够可用文档的启发。<br>UP-Miner工具[83]采用了几种数据挖掘方法，例如聚类和频繁闭合序列挖掘，以创建频繁的API使用模式。它还包含新的度量标准，以优化所得模式的简洁性和覆盖范围，然后将其作为概率图提供给用户以供检查和理解。与Microsoft开发人员合作对大型Microsoft代码库进行的测试证实了该方法的实用性。Nguyen等人详细介绍了另一个有趣的贡献 [59]。他们研究API前置条件，这些条件需要在调用之前通过API方法的参数来满足。他们开发了一个系统，该系统找到调用API的客户端方法，计算每个调用站点的控制依赖关系，然后挖掘用于访问这些调用站点的条件，最终推断出每个API的前提条件。使用SourceForge和Apache项目对Java Development Kit进行的大规模评估确定了书面规范中缺少的一些先决条件。此外，结果可用于识别不满足源代码中的前提条件的编码错误。本文还对早期API挖掘文献中的参考文献进行了很好的收集。</p><p>VCCFinder [62]是一个工具，它将有关代码中的漏洞的知识与有关对存储库的commits的元数据相结合，以识别可能存在漏洞的软件代码commits。为两种源类型的每个提交生成的一系列功能与已知的漏洞贡献提交案例的功能相匹配？ （VCC），从CVE的提交数据中识别，以确定新提交是否可能是漏洞的来源。为此目的构建了两级SVM。对66个GitHub项目的测试表明，与现有工具相比，误报率（FPR）大大降低，同时保持了类似的真阳性率。虽然成功识别VCC可以大大减少检查安全性的代码量，但是从业者仍然需要重要的专业知识和审核它们的手册。</p><h3 id="3-1-2克隆检测"><a href="#3-1-2克隆检测" class="headerlink" title="3.1.2克隆检测"></a>3.1.2克隆检测</h3><p>重复代码不仅会使软件项目由于代码膨胀而更难以维护，而且还会因为复制粘贴编程而分散在大型代码库中问题的问题难以解决。因此，检测克隆在文献中引起了很多关注，包括从脆弱性的角度来看。 Roy等人最近的一项调查 [70]提供了克隆检测技术的概念和定性比较和评估。与克隆检测相关的许多研究都集中在确定代码片段相似性以定位复制的代码。Udagawa [81]提出了一种代码结构基础的方法，使用解析器提取从Java源代码片段词汇数据，并应用相似性度量通过令牌的完全匹配序列的数目的比率定义到部分序列匹配状态的数量。 Lazar和Banias [47]在基于结构的方法的另一个例子中使用抽象语法树在多个文件集中使用子树相似性度量。这些通常优于基于文本或令牌的方法，因为它们对代码和变量名称更改是健壮的，尽管由于可伸缩性问题它们通常不适合大型程序。</p><p>克隆检测算法也被用于与机器学习相结合的bug修复目的，例如Steild和Göde[76]。他们的想法是从克隆中提取特征，并在训练分类模型后，确定类似的克隆是否具有不完整的bug修复。克隆检测本质上是基于令牌的，即语句被标记化而不是表示为树，并且这反映在从代码片段中提取的特征类型中：全局上下文特征与本地词汇特征相互补充，允许克隆中的轻微不一致。作者研究了多种分类技术，发现决策树是最有希望的，并且对用户来说是一种易于理解的表示。测试结果表明，即使假阳性与真阳性的比例很高（大约四个五分之一是假的），与人工分析相比，他们的方法代表了显着的改善。</p><p>进一步采用克隆检测的概念，C3系统[45]研究了源代码库中的代码变化。这个想法是通过自动定位类似的代码更改来简化bug修复的应用，而无需与用户交互和/或现有的代码更改模式，将其传递给其他应用程序工具。提出了两种相似性度量，一种基于传统的基于二维的表示，另一种基于抽象语法树，其用于提取的代码变化以生成相似性矩阵。然后使用聚类来检测类似变化的组（而不是与克隆的情况相同的组）。大型代码存储库的结果表明，它们可以以高效的方式交付，其成功率类似于专家手动提取所获得的成功率。</p><h3 id="3-1-3错误检测"><a href="#3-1-3错误检测" class="headerlink" title="3.1.3错误检测"></a>3.1.3错误检测</h3><p>代码错误无论是否可利用，都难以识别，特别是在大型软件项目中。在源代码的情况下，一些更常用的发现错误的技术包括使用模板来指导搜索已知漏洞;检查源代码文件的内容并与已知的易受攻击者进行比较;并分析代码结构以诊断潜在的错误。通常，使用方法的组合来强化结果，这些活动的主题要么是识别与正常不同的代码，要么是识别与类似的已知坏的代码。</p><p>当用于定位特定的漏洞模式时，使用先验知识可能非常有效。被忽视的条件是Chang等人的主题 [25]。他们的方法要求用户指定用于从代码中学习条件规则的约束，该代码用于发现指示被忽略条件的违规。提取的规则表示为图形和最大频繁子图挖掘算法，后跟图形匹配算法分类规则违规。可以咨询用户以评估所提取的规则的有用性并在匹配发生之前调整它们。使用这种方法测试了各种开源软件项目，并揭示了以前未知的违规行为。 Alattin [79]是另一个使用一种名为ImMiner的修改频繁模式挖掘算法来识别被忽视条件的提议。它引入了替代模式的概念，作为在程序中执行相同API调用的两个规则的分离。当两个单独的模式频繁时，替代模式称为平衡;当只有一个时，替代模式被称为不平衡，并且可以用于程序理解和缺陷检测。已经开发了频繁项集挖掘算法的变体来搜索平衡和不平衡的替代模式，并且应用于检测API调用周围的被忽略的条件。与类似的解决方案相比，该方法测试良好，可作为Eclipse插件使用。</p><p>描述正常行为而非违规的模式也用于错误检测。Gruska等 [35]解析大量的软件项目，以提取表示函数调用之间的数据流的频繁时态属性。然后使用异常检测算法来使用关联规则提升措施来检测对学习模式的违反，以对它们进行排序和过滤以供用户评估。在实际测试中，排名靠前的25％的违规行为被发现是问题，无论是实际缺陷还是代码设计中的弱点。</p><p>将源代码作为文档集处理并构建描述它们的模型是另一种开发对软件项目的理解的方法。 Lukins等人[52]使用Latent Dirichlet Allocation生成关于字符串文字，注释和标识符的主题模型，然后在几个案例研究中使用手动制作的错误描述查询来评估它们。他们发现他们的技术与竞争方法相比具有优势，并且在大型源代码库中使用时可以很好地扩展。 Hovsepyan等 [39]还会查看单个源代码文件，并通过删除注释，字符串和数值将其转换为特征向量，并将剩余的代码元素（关键字，变量和函数名称）标记为监督学习的特征词。在运行支持向量机算法之前，将标签分配给每个文件以训练用于预测从测试文件中提取的易受攻击的特征向量的模型。该技术能够以较低的错误发现率识别大多数测试的漏洞，并且旨在补充基于软件度量的现有漏洞发现解决方案。Pang等人[60]通过将n-gram包含在生成的特征向量中来扩展这项工作。考虑多达五个令牌的序列而不是单个单词，并且为了避免产生的特征爆炸，使用统计特征选择算法来提供排名。然后，前20％的特征与SVM算法一起使用。对四个Android Java项目的测试取得了比早期尝试稍微更好的分类结果。 Scandariato等[72]在将源代码文件标记化为特征向量时，使用单个单词（包括注释和字符串值），但引入离散化以对各种特征计数进行分类，以便改进其机器学习算法生成的模型。除了SVM之外，他们还使用决策树，k-最近邻居，朴素贝叶斯和随机森林进行测试，后两种算法在他们的实验中表现最佳。本文还回顾了以前的可比较的工作，包括那些依赖软件指标来确定文件是否包含软件漏洞的工具。这些在文本挖掘解决方案的指标的优化是Tang等人的主题 [78]。他们认为虽然许多基于机器学习的解决方案可能会显示出改进的结果，但它们并不足以证明应用这些模型而不是基于软件指标的模型所需的额外成本是合理的。</p><p>许多研究人员研究利用程序结构特性的解决方案。机器学习已经在Kremenek等人中使用。 [44]研究源代码程序分析和概率图模型的组合，以直接从程序中自动推断程序规范。通过创建注释因子图来进行推理，该图可用于在检查任何推断的规范之前通过其概率对可能的错误进行排序。对开源代码库的测试表明，在内存分配/释放规范的情况下，真正的阳性率很高。彭等人[61]探索深度学习对程序分析的可能性。他们认为基于自然语言令牌的粒度可以产生稀疏数据，而是将抽象语法树节点编码表示为矢量，将AST中的节点编码为单个神经层。然后将它们用作卷积神经网络的输入，用于深度监督学习以对程序进行分类。使用k均值聚类进行矢量表示的定量评估，以表明类似的节点可以成功地组合在一起，而对分类任务的定性评估显示，与基线分类器（如逻辑）相比，深度学习的结果比回归和支持向量机稍微优越一些。</p><p>利用特定于漏洞发现的程序结构一直是Yamaguchi及其合作者的焦点。抽象语法树节点的潜在语义分析[90]是在审计源代码库期间向安全分析师提供帮助的早期尝试。在提取API和语法节点之后，它们被嵌入到向量空间中，并且使用LSA来识别结构模式以生成主题。然后可以将这些与已知漏洞识别的特征进行比较。对几个开源项目的测试有助于发现新的零日漏洞。缺少检查是另一个Yamaguchi等人的目标。详细介绍了Chucky [92]，这是一种异常检测器，可以静态地污染源代码，并识别源代码中与安全关键对象相关的异常或缺失条件。在提取抽象语法树之后，使用k近邻算法来执行相关函数的邻域发现。轻量级污染，然后将函数嵌入向量空间，然后通过几何比较检查与代码库其余部分中类似函数嵌入的已知检查，识别异常，可以比较缺失的检查。 Chucky经过测试，以极高的检测率诊断已知漏洞，并且还能够通过生成各种开源项目的异常排序列表，帮助分析师识别以前未知的漏洞。Joern项目[89]引入了代码属性图（CPG）的概念，它是抽象语法树，控制流图（CFG）和程序依赖图（PDG）的组合，三个现有的代码表示，每个代码都是能够捕获一些但不是所有对漏洞研究很重要的软件特征。这个想法是，CPG将这些特征结合起来，形成一个可以用来更普遍地模拟现有漏洞的表示。然后检查代码库将成为构建代码并将代码表示为CPG的练习，并针对生成的图形发出图形遍历查询以找到漏洞模式的匹配项。该平台已针对Linux内核代码库进行了测试，并能够识别18个先前未知的漏洞。设计的局限性在一项提案中得到了部分解决，该提议旨在自动推断污点式漏洞的搜索模式[91]。后置控制器树（PDT）用于增强代码属性图，以捕获在另一个之前执行语句的情况，从而能够检测代码中的函数调用，从而导致对其参数进行修改。然后可以使用这些来生成图遍历模式以搜索污点风格的漏洞。该方法已作为Joern的插件实现，并显示可大幅减少代码检查。</p><h3 id="3-1-4-Bug修复和补丁"><a href="#3-1-4-Bug修复和补丁" class="headerlink" title="3.1.4 Bug修复和补丁"></a>3.1.4 Bug修复和补丁</h3><p>Bug修复，无论是反应性的还是预防性的，仍然是软件开发中的必要活动。 Vulture [57]是一种工具，可以自动从过去的漏洞位置学习，以预测新组件在完全实施之前的未来漏洞。这是通过从源代码组件中提取import语句并应用频繁模式挖掘来确定它们是否与现有漏洞相关来实现的。然后可以使用基于项目导入矩阵构建的分类模型和从上一步骤获得的漏洞向量，评估新组件以确定它是否会基于其导入而易受攻击。使用SVM分类器进行预测的系统在Mozilla项目上进行了评估。 Kim等人 [43]提出了一种称为“改变”的技术。在代码行而不是完整的模块，文件或功能上运行的分类。这是通过检查软件配置管理系统中的代码历史来实现的。针对bug修复和根据更改元数据，软件复杂性指标，日志消息和代码的常规提交来提取特征。选择SVM分类器来构建模型，以预测新代码更改是否有缺陷或干净，并在新的更改提交时立即获得结果。本文还分析了不同特征群的预测能力。</p><p>但是，了解软件项目中易受攻击的组件并不能解决这些漏洞被利用的可能性的问题。 Bozorgi等人[15]提出了自动对漏洞进行排序的潜在解决方案。利用CVE和OSVDB等公共漏洞数据库对最有可能被利用的漏洞进行分类和预测。从现有漏洞披露报告中的文本字段，时间戳，交叉引用和其他条目中提取了大量特征。然后在随机平衡样本上训练线性SVM，使用具有漏洞的漏洞的正标签和不具有漏洞的漏洞的负标签。然后，该方法用于研究离线和在线漏洞利用预测，识别与预测最相关的特征，并估计利用漏洞所需的时间。后一主题也在Wijayasekara等人 [86]的研究中进行了研究，其中讨论了使用文本挖掘技术挖掘bug数据库中的错误报告，以帮助发现隐藏的影响漏洞。隐藏影响漏洞是在相关错误通常通过补丁发布向公众披露之后的某个时间识别的漏洞，攻击者可以使用该漏洞发现潜在的高影响漏洞。通过处理（标记，词干等）错误报告中的文本来获得特征向量，并且通过计算贝叶斯检测率或者如果检测到错误是隐藏的影响漏洞的概率来获得分类。并将该bug标为漏洞。 Linux内核和MySQL错误数据库用作数据源。对隐藏影响漏洞与漏洞的比率的分析表明它相对较高，并且在研究的最后两年中还观察到其增加。</p><p>一旦确定了错误并确定了优先级，就必须对它们进行修复。 Prophet [51]是一个自动补丁生成系统的示例，它从开源软件存储库中获取补丁并构建正确代码的模型。该概率模型是在从先前代码修订中提取的成功补丁的特征的初始训练阶段中学习的，并且用于生成新缺陷的候选补丁并对其进行优先级排序。然后验证候选补丁并将其提供给开发者进行手动检查和插入。对来自8个开源项目的69个真实世界缺陷的基准测试表明，Prophet比现有的补丁生成系统更有优势。 GenProg [84]在抽象语法树和加权程序路径上使用遗传编程方法来纠正代码中的缺陷。一旦识别出错误，例如，程序未通过测试用例，就会搜索原始程序的变体，直到找到有效版本。该技术使用观察来通过采用来自程序中的另一位置的现有代码来修复缺陷。通过使用类似的模板改变缺陷代码，可以通过程序成功修补先前失败的测试用例来识别修复。DeepSoft框架[29]是一种雄心勃勃的方法，用于模拟软件及其开发，以预测和降低风险，并自动为已识别的错误生成代码补丁。它采用深度学习，LSTM来模拟源代码及其演变。他表示结合自然语言处理使得能够自动生成用于解决问题的代码补丁。 Le等人 [48]调查应用自动修复软件错误识别案例的有效性。他们有兴趣在合理的时间内进行维修，并认为根据某些定义的时间预算，有时手动而非自动干预可能会更具成本效益。为此，他们构建了一个随机森林分类器，它使用多次GenProg运行来生成数据，并添加了一个有效性指标作为分类标签。随后的模型用作预测未来修复实例的有效性的预言。结果表明，对于更合适的修复类型，正确地识别出四分之三的修复。</p><h3 id="3-1-5-缓解和预防"><a href="#3-1-5-缓解和预防" class="headerlink" title="3.1.5 缓解和预防"></a>3.1.5 缓解和预防</h3><p>在文献中也经常探索减少软件开发过程中引入的错误数量的方法。减少代码错误概率的一种可能方法是引导自动生成正确的代码片段。许多作者讨论了代码完成，包括Hindle等 [36]，他们使用自然语言处理中的n-gram概念来统计模拟代码令牌序列，基于代码类似于语言，重复和可预测的假设。他们发现源代码的熵远低于自然语言的熵。他们从他们的模型开发一个新的Eclipse插件作为概念验证，显示出优于内置代码完成引擎的功能。 Allamanis和Sutton [7]通过编译和分析更大的数据集，进一步扩展到giga-token 模型并引入新的数据驱动指标来衡量代码复杂性。他们证明这些模型在代码建议方面更胜一筹。 SLANG [66]补充了具有递归神经网络的n-gram模型，使用API方法调用以解决在代码中生成完整的holes（间隙，缺少行）的问题。代码完成被视为预测句子概率的自然语言处理问题。由此产生的工具能够合成具有多个语句和参数的复杂解决方案，这些语句和参数可以正确地进行检查，并在90％的案例中包含前3个结果中的所需结果。 DeepSyn [65]是JavaScript程序的代码完成系统。它利用领域特定语言而不是抽象语法树，它删除了代码规范并促进了对部分解析树的学习。然后可以生成该语言中与训练数据最佳匹配的程序，该程序在代码完成任务中表现得比现有解决方案更好。</p><p>Bruch等人讨论了用于智能代码完成的数据挖掘技术 [17]。设计了三个独立的解决方案来改进内置的Eclipse代码建议系统。首先，通过频率计数简单地命令所有可用的建议，而不是默认的Eclipse排序。第二个使用关联规则来查找代码对象之间的相关性，并建议与观察对象密切相关的那些。第三种解决方案是k近邻算法的变体，称为最佳匹配邻居算法。它为代码库中的每个变量提取二进制特征向量，编码有关使用它们的API调用的指示符，并根据汉明距离的修改使用计算当前代码库和示例代码库之间的距离。然后根据所选最近邻居的频率推荐代码完成。在测试中，每个提案都优于默认的Eclipse建议系统，最佳匹配邻居算法产生了领先的结果。</p><p>GraLan [58]是一种基于图形的统计语言建模方法，它计算使用图出现概率并将其用于代码完成。在从源代码示例构建语言模型之后，可以从当前编辑的代码的邻域中提取使用子图，并且可以使用GraLan来计算给定那些使用子图的children图的概率。这些被收集并作为建议的候选API元素排名。这种方法进一步扩展到ASTLan，这是一种基于AST的语言模型，用于在当前编辑位置建议语法模板而不是API元素。 GraLan和ASTLan都比以前的API代码和语法模板建议更有优势，本文还提供了代码完成研究的广泛概述。</p><p>机器学习技术也被用于帮助证明程序的存储器安全性和功能正确性。一个例子是Cricket [16]，这是一种验证工具扩展，它利用逻辑回归和双层神经网络来自动化具有适当不变量的程序注释。最初，只学习形状属性并用于验证堆程序的正确性。如果失败，则在具有数据不变量的第二阶段中加强有效的形状不变量，以再次采用ML算法来改善所获得的存储器安全性证据。</p><p>3.1.6 归属</p><p>代码漏洞分析后的潜在后续活动是代码归属于其作者。这些信息可以识别软件项目之间的关系，可以证明代码的质量和成熟度，并协助开发和应用适当的漏洞预防解决方案。 Caliskan-Islam等 [24]使用机器学习解决了C ++源代码的作者属性问题。他们的方法考虑了三种类型的特征，总共最多20,000个特征：代码样式特征是布局特征，例如不改变程序含义的空格;词法特征来自程序令牌，或具有识别含义的字符串，例如循环次数，if / then语句和注释;语法特征源自AST，如AST节点类型的术语频率逆文档频率（TFIDF）。使用信息增益标准，原始特征集大幅减少，随机森林集合分类器用于作者身份归属，具有高度准确的结果。作者认为语法特征对代码混淆尝试具有弹性，并且发现高级程序员具有比新手更具识别性/唯一性的编码风格。</p><h2 id="3-2-二进制代码分析"><a href="#3-2-二进制代码分析" class="headerlink" title="3.2. 二进制代码分析"></a>3.2. 二进制代码分析</h2><p>二进制文件是源代码的转换，因此，它来自高级编程语言中固有的一些语义损失。因此，漏洞研究中的一些活动，特别是那些旨在防止漏洞被引入软件的活动，要么不可用，要么不适用，要么采用不同的方法或技术。当可以分析源代码和相应的二进制文件时，研究人员有机会使用丰富的数据集。但是，二进制文件通常都是可用的，可以进行调查。与源代码类似，它们可以转换为不同的表示，这可能使一些早期看到的技术适合与此媒体一起使用。但是，不同的计算机体系结构和对相同源代码的不同编译器优化可能会在二进制分析中引入额外的复杂性层。</p><p>自动化仍然是二进制代码的SVR活动的主要目标。一些示例包括GUEB [32]，一种静态工具，用于检测反汇编代码上的释放后使用（UaF）漏洞。它利用抽象存储器表示，在其上执行值集分析，使用控制流图的正向遍历来促进UaF检测。 Sword [23]是一个自动模糊测试系统，它优先考虑二进制区域以进行模糊测试。它结合了多种漏洞检测方法来提高效率，即搜索和识别目标程序所需执行路径的符号执行，以及污点分析以检查执行路径并生成路径相关信息以引导模糊器执行漏洞分析。 Code Phage [75]是一个自动将正确的代码从施体者应用程序转移到接收者应用程序中以消除后者错误的系统。一旦为程序识别出引起错误的输入，就会在数据库中搜索施体者应用程序，其中相同的输入不会触发错误。各种活动，包括候选检查发现，补丁切除，插入和验证都遵循此步骤，如果它们不能产生安全的解决方案，则会重复这些活动。本文还概述了早期的程序修复工作。 Brumley等人[20]讨论了与修复相反的问题，即基于对为其发布的检查补丁的自动利用程序。 我们的想法是找到补丁中引入的任何新的校验检查，并找到他们防范的输入。攻击者可以利用这些信息，假设这些输入可能是未修补程序的潜在攻击，这些程序通常不会及时收到更新。</p><p>代码相似性也可用于漏洞识别。 Tree Edit Distance-Equational Matching [64]是一种用于自动识别包含已知错误的二进制代码区域的方法。在预处理阶段，提取表达树形式的语义信息，其总结在基本块中执行的计算的结果。对于已知错误，这用作签名以定位类似的代码区域，使用基于树编辑距离的以块为中心的度量来测量二进制代码的相似性。该度量标准允许代码中的小型语法差异，并已用于识别软件中的未知漏洞，例如流行的SSH客户端PuTTY的分支。 Pewny等人 [63]提出了使用代码相似性度量在多个CPU架构中基于签名的错误发现方法的概括。</p><h3 id="3-2-1-数据结构"><a href="#3-2-1-数据结构" class="headerlink" title="3.2.1 数据结构"></a>3.2.1 数据结构</h3><p>二进制程序分析的一项基本任务是了解程序特征，以便进一步调查隐藏在代码中的潜在问题。 Laika [28]使用贝叶斯无监督学习来识别程序图像中的数据结构及其实例化。它定位指向潜在数据对象的指针，并使用机器把word转换为块类型的向量作为特征来估计它们的大小。然后使用概率相似性度量将相似序列聚类在一起以确定数据结构的类别。生成的数据结构在病毒检测场景中进行了测试，并证明是高效的。 White和Lüttgen[85]使用遗传编程从程序执行轨迹中识别动态数据结构，方法是将它们与预定义的模板进行匹配以进行标记。模板捕获操纵复杂数据结构（如链表和二叉树）所需的操作，测试表明这种方法能够以较低的误报率推断出这种数据结构。</p><h3 id="3-2-2程序结构"><a href="#3-2-2程序结构" class="headerlink" title="3.2.2程序结构"></a>3.2.2程序结构</h3><p>二进制文件中的结构也扩展到可执行代码。 Rosenblum等 [68]解决了“函数开始识别”问题，或者在剥离的二进制代码中识别函数入口点（FEP）。他们使用基于Conditional Random Fields （CRF）统计建模方法的监督分类算法。每个字节偏移被假定为候选FEP，考虑两个模型：一个基于单个FEP的分类，另一个基于结构方面，例如可以调用其他函数的函数。第一个模型使用短指令模式作为特征集，逻辑回归模型被表述为用于分类的条件随机字段。第二个模型使用CRF使用成对函数/结构调用和重叠特征来模拟函数调用交互。该方法优于使用现有工具（例如Dyninst [37]和商业反汇编IDA Pro）所获得的结果。 ByteWeight [12]改进了这种方法，通过采用基于prefix树的技术来学习用于函数开始识别目的的签名，然后通过将二进制片段与签名匹配来识别函数。这是通过在源代码的参考语料库及其相应的二进制文件上训练分类模型来完成的，其中函数地址是已知的。该模型采用加权的prefix树的形式，其对函数开始字节序列进行编码：如果prefix树中的相应序列终端节点具有大于给定阈值的权重值，则检测实际函数开始。一旦找到函数开始，可以使用其他技术从二进制文件中提取完整函数。</p><p>描述二进制文件的一般结构以实现详细分析是许多出版物中探索的目标。例如，BAP [19]是一个多用途分析平台，用于对二进制文件执行程序验证和分析任务。与许多类似的解决方案一样，它将二进制指令转换为中间语言，以便能够以语法导向的形式编写后续分析。以这种方式提供的任务可以包括创建控制流和程序依赖图，消除死代码，执行值集分析以及根据给定的后置条件生成验证条件。</p><p>3.2.3。动态分析</p><p>VDiscover [34]是一种应用机器学习方法的系统，该方法使用从二进制文件中提取的可伸缩，轻量级静态和动态特性来预测漏洞测试用例是否可能包含软件漏洞。通过检测从程序调用图的随机遍历获得的库函数调用的潜在子序列，从反汇编代码中提取静态特征。动态特征从执行跟踪中捕获，包含用其参数扩充的具体函数调用。为了减少大量的特征值，对参数值进行子类型化，并通过将函数调用的每个执行跟踪视为文档进行预处理，并使用潜在语义分析来降低维数。在系统中测试的机器学习分类算法包括逻辑回归，多层感知器和随机森林。随机森林在一项旨在识别内存损坏程序的大型实验中取得了最好的结果。</p><h3 id="3-2-4-符号执行"><a href="#3-2-4-符号执行" class="headerlink" title="3.2.4 符号执行"></a>3.2.4 符号执行</h3><p>符号执行探索程序的执行空间并生成具有高覆盖率的测试用例。该方法的局限性在于可能的程序路径的数量通常过大。已经提出了各种方案来指导根据一些选定的策略来探索程序路径以克服该问题。李等人 [49]通过检查长度为n的子路径的频率分布来关注较少行进的路径，以便改进测试覆盖率和错误检测。我们的想法是通过维护之前探索子路径的次数来对已经覆盖的子路径进行统计分析。然后，对于给定的执行状态，选择具有最低计数的子路径以继续执行。该策略已在符号执行引擎KLEE [21]中实现，并在GNU Coreutils程序上进行了测试。 Cadar和Sen [22]提供了类似提案的概述，并讨论了与符号执行相关的挑战。特别是，他们专注于更高级别的自动化，例如修剪冗余路径，生成导致错误的输入，甚至创建相应的漏洞。 Avancini和Ceccato [10]使用遗传算法和符号执行来生成测试用例，以识别Web应用程序中的跨站点脚本（XSS）漏洞。他们将这两种技术结合起来，首先执行遗传算法，并在切换到符号执行之前将一组测试用例演化几代。收集，解决和重新插入符号约束作为新的输入值并且执行返回到遗传算法。重复该过程直到满足一些预先定义的终止条件。<br>测试表明，与随机测试用例生成和单独使用的两种方法相比，使用这种组合技术可以实现更高的覆盖率。</p><p>BitScope [18]是用于恶意二进制文件自动路径分析的示例平台。它的体系结构包含监视恶意二进制文件内外信息流的组件，优先考虑可用的探索路径，并执行结合二进制符号（复杂）执行以构建公式以表示执行的满意度路径。然后，提取器模块生成已发现代码的控制图，二进制文件沿不同执行路径传输所需的输入以及二进制文件的输入和输出之间的依赖关系信息。然后，从业者可以使用该数据来进一步分析该程序。</p><p>基于相似度函数的自动漏洞发现（SFAVD）[53]是一个将源代码中的机器学习与符号执行测试相结合以检测漏洞的过程。首先，使用多步骤过程生成类似于已知易受攻击的一组函数，该多步骤过程包括为每个函数创建抽象语法树表示，将它们枚举成特征向量并对易受攻击的函数执行相似性评估。然后，为具有最大相似性的函数生成函数调用图，并且将KLEE与约束求解器一起使用以确定它们是否易受攻击。测试表明，与仅使用KLEE分析程序相比，可以实现执行时间的显着缩短。</p><h3 id="3-2-5-恶意软件"><a href="#3-2-5-恶意软件" class="headerlink" title="3.2.5 恶意软件"></a>3.2.5 恶意软件</h3><p>虽然恶意软件分析不是软件漏洞研究的各种活动的严格组成部分，但它是机器学习受到广泛关注并且显示有用的相关领域之一。恶意软件分析还可以帮助开发漏洞缓解策略，并且通常采用与其他SVR任务直接相关的技术，从而暴露在这些区域中使用相同或类似ML方法的机会。对恶意软件的分析通常始于相关特征的识别。艾哈迈德等人 [6]从Windows API调用参数和序列中提供的空间和时间信息中提取统计特征。它们包括地址指针的均值，方差和熵以及从API序列的离散时间马尔可夫链建模获得的大小参数和特征。使用这些特征比较各种机器学习算法，包括基于实例的学习器，决策树分类器，朴素贝叶斯，归纳规则学习器和支持向量机，并且它们表明当使用时可以实现改进的结果。用于分类的空间和时间特征的组合。 OPEM [71]还使用一系列算法检查恶意软件，例如决策树，贝叶斯分类器，支持向量机和k近邻，但使用了一组不同的特性。静态功能基于恶意软件中的固定长度的操作代码序列的频率。动态要素从执行跟踪中提取为二进制向量，表示可执行文件中存在特定的系统调用，操作和引发的异常。使用信息增益将特征减少应用于静态特征，以便产生可管理的特征集。结果表明，与仅使用单一类型的特征相比，组合的静态和动态特征产生更好的结果。安德森等人[9]描述了仅使用一种类型的特征的示例，在这种情况下，使用来自动态收集的指令轨迹的特征。指令序列被转换为马尔可夫链表示，形成有向指令跟踪图（ITG），由加权邻接矩阵表示。两级支持向量机用于分类并产生高度准确的结果。不幸的是，用于确定ITG之间相似性的图形内核对于大图来说计算起来可能很昂贵。 Gascon等 [33]也使用SVM，但它通过采用受线性时间图内核启发的显式映射，基于函数调用图的结构嵌入来推导其特征，从而产生静态特征集。在测试中，使用此技术实现的恶意软件检测率相当高，误报率低。</p><p>Saxe [42]提出了一系列相似性措施，以抵抗恶意软件中的混淆，以更好地识别它们所属的类。这是一项重要任务，因为确定恶意软件样本的正确组可以协助归因和后续活动。这个想法是对整个恶意软件的完全混淆是困难的，因此即使在个体相似性度量无效的情况下，使用多种分析技术也应该产生可靠的结果。提出的四种措施基于PE（可移植可执行）元数据相似性，动态相似性，指令 - 克相似性和文件相似性。与其他可用技术（如群集）相比，此方法是识别恶意软件组的更简单且更具可扩展性的解决方案。</p><h3 id="3-2-6-二进制文件的归属"><a href="#3-2-6-二进制文件的归属" class="headerlink" title="3.2.6 二进制文件的归属"></a>3.2.6 二进制文件的归属</h3><p>也可以对二进制文件进行作者分析。 Rosenblum等 [69]收集具有已知作者身份的程序集，并使用控制流图和指令序列，根据特征和标签之间的相互信息，从每个程序中提取和确定相关的文体特征。这些功能使用支持向量机分类器进行测试，并用于学习一个度量，该度量最小化同一作者在程序之间的特征空间中的距离。然后，该度量与k-means聚类一起用于对未知作者的程序进行分组。该技术实现了合理的性能（正确作者排名在前五位的时间的94％），这使得论文的作者得出结论，程序员风格可以通过编译过程得以保留。随后提出了对该技术的若干改进。 Alrabaee等 [8]认为需要更加分层的方法。首先，预处理层过滤掉库代码以消除与样式无关的功能。然后，代码分析层提取对应于源代码词汇表的二进制代码块，以构建用于分类的作者分类。最后，一个寄存器流分析层使用寄存器流程图来描述寄存器的操作方式，用于定义作者风格的签名和识别程序作者。与[69]中取得的结果相比，归因准确度有所提高。但是，这些方法都没有专门设计用于处理具有多个作者的程序。 Meng [54]为团队编写的属性代码引入了新的块级功能。在分析从属性源代码[55]生成的机器指令之后，基本块被确定为属于单个作者的合适候选者。因此，在这个级别提出了几个新功能，以补充以前的现有功能。基本块的线性SVM分类器与早期报告的结果相当，表明作者身份识别在基本块级和多个作者中都是实用的。</p><h1 id="4-总结"><a href="#4-总结" class="headerlink" title="4.总结"></a>4.总结</h1><p>在本文中，我们报告了软件漏洞研究社区最近涉及使用机器学习的一些活动。虽然没有提供详尽的清单，但我们的目的是提供一份代表性的出版物集，说明使用ML支持SVR。我们发现，除了寻找解决大型代码库的解决方案的新方法之外，SVR中最大的主题是帮助代码审计员等从业者，尽可能简化或自动化他们的流程。机器学习是越来越多地用于改进传统方法的工具之一。它已成功应用于解决单个SVR任务或通过多个步骤来提供复杂过程的指导。在这个角色中，ML应该继续受益于未来。 SVR中仍然存在有限使用ML的区域（例如，模糊测试[38]），甚至那些当前利用机器学习的区域也可以改进，因为提出了新的，更有效和更有效的技术。识别这些趋势并认识到它们对特定SVR问题的适应性并非易事，并且需要SVR从业者，程序分析和机器学习专家之间的密切联系。特别是，我们认为使用语义输入信息的机器学习而不是其在句法特征上的应用可以为许多SVR活动产生更有意义的结果。最后，我们想要认识到最近几个旨在为软件漏洞研究目的提高认识和鼓励协作的方法。 2016年网络大挑战[2]是研究人员之间的竞赛，旨在评估软件，测试漏洞并在网络计算机上自动生成和应用安全补丁。MUSE项目[56]是一项正在进行的计划，旨在通过开发自动构建和修复软件程序的方法，寻求来自多个学科的专家使用大数据分析来提高软件可靠性。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h1&gt;&lt;p&gt;搜索和识别计算机软件中的漏洞具有悠久而丰富的历史，可用于预防或恶意目的。在本文中，我们研究了
      
    
    </summary>
    
      <category term="论文" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/"/>
    
      <category term="fuzzing" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/fuzzing/"/>
    
      <category term="综述" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/fuzzing/%E7%BB%BC%E8%BF%B0/"/>
    
    
      <category term="综述" scheme="http://yama0xff.com/tags/%E7%BB%BC%E8%BF%B0/"/>
    
      <category term="2017年" scheme="http://yama0xff.com/tags/2017%E5%B9%B4/"/>
    
  </entry>
  
  <entry>
    <title>Sofware Vulnerability Analysis and Discovery Using Machine-Learning and Data-Mining Techniques: A Survey</title>
    <link href="http://yama0xff.com/2019/04/02/Sofware-Vulnerability-Analysis-and-Discovery-Using-Machine-Learning-and-Data-Mining-Techniques-A-Survey/"/>
    <id>http://yama0xff.com/2019/04/02/Sofware-Vulnerability-Analysis-and-Discovery-Using-Machine-Learning-and-Data-Mining-Techniques-A-Survey/</id>
    <published>2019-04-02T13:50:44.000Z</published>
    <updated>2019-04-03T04:06:36.364Z</updated>
    
    <content type="html"><![CDATA[<p><strong>由于其中主要内容都是关于数据挖掘技术在源代码漏洞和分析中的使用总结，涉及到使用机器学习方法的较少，所以未翻译阅读完，后续再继续翻译。</strong></p><h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>软件安全漏洞是计算机安全领域的关键问题之一。由于其潜在的高严重性影响，在过去几十年中已经提出了许多不同的方法来减轻软件漏洞的损害。机器学习和数据挖掘技术也是解决该问题的众多方法之一。在本文中，我们对利用机器学习和数据挖掘技术的软件漏洞分析和发现的许多不同工作进行了广泛的回顾。我们回顾了这个领域中不同类别的工作，讨论了优点和缺点，并指出了挑战和一些未知的领域。</p><table><thead><tr><th>relevant information</th><th></th></tr></thead><tbody><tr><td><em>作者</em></td><td>SEYED MOHAMMAD GHAFFARIAN；HAMID REZA SHAHRIARI</td></tr><tr><td><em>单位</em></td><td>Amirkabir University of Technology</td></tr><tr><td><em>出处</em></td><td>ACM Comput. Surv</td></tr><tr><td><em>原文地址</em></td><td><a href="https://dl.acm.org/citation.cfm?id=3092566" target="_blank" rel="noopener">https://dl.acm.org/citation.cfm?id=3092566</a></td></tr><tr><td><em>源码地址</em></td><td></td></tr><tr><td><em>发表时间</em></td><td>2017年</td></tr></tbody></table><h1 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h1><p>如今，计算机软件无处不在，现代人类生活在很大程度上依赖于各种各样的软件。在不同的平台上运行不同形式的计算机软件，从手持移动设备上的简单应用程序到复杂的分布式企业软件系统。这些软件采用多种不同的方法生成，基于各种各样的技术，每种技术都有自己的优点和局限。这个庞大的关键行业以及计算机安全领域的一个重要问题是软件安全漏洞问题。在这个问题上引用行业专家的话：</p><blockquote><p>“In the context of software security, vulnerabilities are specifc ﬂaws or oversights<br>in a piece of software that allow attackers to do something malicious: expose or alter<br>sensitive information, disrupt or destroy a system, or take control of a computer system<br>or program.” Dowd et al. (2007) </p></blockquote><p>软件漏洞所带来的威胁的严重程度不同取决于开发复杂性和攻击面等因素（Nayak等人，2014）。在过去的二十年中，存在大量的例子和事件，其中软件漏洞给公司和个人带来了重大损害。为了强调这个问题的重要性，我们近年来提到了一些例子。一个突出的例子是流行浏览器插件中的漏洞情况，这些漏洞威胁到数百万互联网用户的安全和隐私（例如，Adobe Flash Player（US-CERT 2015; Adobe Security Bulletin 2015）和Oracle Java（US-CERT 2013） ）。此外，流行和基础开源软件中的漏洞也威胁到全球数千家公司及其客户的安全（例如Heartbleed（Codenomicon 2014）ShellShock（赛门铁克安全响应2014）和Apache Commons（Breen 2015） ）。</p><p>上述示例只是每年报告的大量漏洞中的一小部分。由于这个问题的重要性，学术界和软件行业的研究人员已经研究了许多不同的缓解方法。 Shahriar和Zulkernine（2012）提出了一项针对缓解计划安全漏洞的不同方法的广泛调查，包括测试，静态分析和混合分析，以及1994年至2010年期间发布的安全编程，程序转换和修补方法。</p><p>除了在Shahriar和Zulkernine（2012）中审查的众所周知且经过深入研究的方法之外，还存在一种不同的方法，这些方法利用来自数据科学和人工智能（AI）的技术来解决软件漏洞分析和发现。 Shahriar和Zulkernine（2012）忽略了这类有趣的方法，但在接下来的几年中（从2011年开始），研究界越来越关注这一方法。</p><p>在本文中，我们针对利用数据挖掘和机器学习技术的软件漏洞分析和发现的这类方法提出了分类评论。首先，我们确定了软件漏洞分析和发现的问题，并简要介绍了在这个领域的传统方法。我们还简要介绍了机器学习和数据挖掘技术以及它们使用背后的动机。之后，我们将分别回顾利用机器学习和数据挖掘技术解决软件漏洞分析和发现问题的许多不同工作。我们为这类作品提出了不同的类别，并讨论了它们的优点和局限性。最后，我们在结束本文时讨论了在这个领域的挑战，并指出了一些未知的领域，以激发这一新兴研究领域的未来工作。</p><h1 id="2-背景：软件漏洞分析和发现"><a href="#2-背景：软件漏洞分析和发现" class="headerlink" title="2.背景：软件漏洞分析和发现"></a>2.背景：软件漏洞分析和发现</h1><h2 id="2-1-定义"><a href="#2-1-定义" class="headerlink" title="2.1 定义"></a>2.1 定义</h2><p>我们首先说明软件安全漏洞的定义。在他关于软件漏洞分析问题的博士论文中，Ivan Krsul将软件漏洞定义为：</p><blockquote><p>“an instance of an error in the specifcation, development, or confguration of software<br>such that its execution can violate the security policy.” (Krsul 1998) </p></blockquote><p>差不多十年之后，Ozment承认Krsul的定义，但建议稍作修改：</p><blockquote><p>“A software vulnerability is an instance of a mistake in the specifcation, development,<br>or confguration of software such that its execution can violate the explicit or implicit<br>security policy.” Ozment (2007) </p></blockquote><p>Ozment将单词error更改为mistake，并引用IEEE标准术语软件工程术语（IEEE Standards 1990）来证明这一点。如前所述，行业专家提供了类似的定义：</p><blockquote><p>“In the context of software security, vulnerabilities are specifc ﬂaws or oversights<br>in a piece of software that allow attackers to do something malicious: expose or alter<br>sensitive information, disrupt or destroy a system, or take control of a computer system<br>or program.” Dowd et al. (2007) </p></blockquote><p>从上述定义可以看出，不同的关键术语用于定义软件漏洞。为了澄清这些术语并选择最合适的术语，我们参考IEEE标准软件工程术语表（IEEE标准1990）。我们查找四个关键术语的定义：“error”，“fault”，“failure”和”mistake”根据IEEE标准（1990），<strong>error</strong>的定义是：“计算的，观察的或测量的值或条件与真实的，规定的或理论上正确的值或条件之间的差异”（IEEE标准1990）。<strong>fault</strong>是：“计算机程序中的步骤，过程或数据定义不正确”（IEEE标准1990）。<strong>faults</strong>也称为flaws或bugs。<strong>failure</strong>是：“系统或组件无法在规定的性能要求下执行其所需的功能”（IEEE标准1990）。最后，<strong>mistake</strong>是：“产生错误结果的人为行为”（IEEE标准1990）。这些术语的关系的总结和澄清是“区分人类行为（mistake），其表现（硬件或软件faults），故障结果（failure）以及结果的数量不正确（error）“（IEEE标准1990）。</p><p>从这些定义可以清楚地看出，用于定义软件漏洞的合适关键术语是“fault”（也是flaw或bug）。更确切地说：</p><blockquote><p>A software vulnerability is an instance of a flaw, caused by a mistake in the design, development, or configuration of software such that it can be exploited to violate some explicit or implicit security policy.</p></blockquote><p>软件漏洞的原因是人为错误，其表现形式是flaw（fault或bug）。执行faulty 状态的软件不一定违反安全策略;直到某些特制数据（漏洞利用代码）或某些具有某些条件的随机数据到达有缺陷的语句，此时，其执行可能违反某些安全策略（利用导致安全性失败）。</p><p>其他人已经承认将软件漏洞定义为faults，并将mistake定义为其原因。 Ozment指出“由于开发错误导致的漏洞是一个fault”（Ozment 2007），但他区分了开发错误导致的漏洞，以及设计或配置错误导致的漏洞;但没有提供这种差异的解释。 Dowd等人。还说：</p><blockquote><p>“In general, software vulnerabilities can be thought of as a subset of the larger phenomenon of software bugs. Security vulnerabilities are bugs that pack an extra hidden surprise: A malicious user can leverage them to launch attacks against the software and supporting systems.” Dowd et al. (2007)</p></blockquote><h2 id="2-2-健全性，完整性和不可判定性"><a href="#2-2-健全性，完整性和不可判定性" class="headerlink" title="2.2 健全性，完整性和不可判定性"></a>2.2 健全性，完整性和不可判定性</h2><p>程序漏洞分析是确定给定程序是否包含已知安全漏洞（根据安全策略）的问题。基于图灵停止问题和赖斯定理的不可判定性，可以证明许多程序分析问题在一般情况下也是不可判定的（Landi 1992; Reps 2000）。对于从业者来说，不可判断性意味着不存在对问题的完整解决方案。</p><p>在数学逻辑中，如果系统不能批准无效参数，则证明系统是合理的。如果所有有效参数都可以被系统批准，则证明系统是完整的。通过推论，一个完整的证据系统是一个可以批准所有有效论证并反驳所有无效论证的系统（Xie et al.2005）。</p><p>在软件安全的背景下，如果漏洞分析系统从未批准易受攻击的程序（没有漏掉漏洞），那么它就是健全的。如果可以批准所有安全程序（没有虚假漏洞），则漏洞分析系统是完整的。根据推论，健全且完整的漏洞分析系统可以批准所有安全程序并拒绝所有易受攻击的程序（没有错过漏洞且没有漏洞）（Xie et al.2005）。如前所述，已知这种完善和完整的系统是不存在的（Jhala和Majumdar，2009）。</p><p>除了漏洞分析之外，更实用的系统是程序漏洞发现（或漏洞报告）系统。与批准或不批准给定程序的安全性（即二进制输出）的漏洞分析系统相比，程序漏洞发现系统报告给定的每个漏洞的更详细信息（例如类型，位置等）程序。这是软件行业更有用和理想的系统，它可以帮助开发人员和工程师更轻松地检测和修复漏洞。同样，众所周知，一个完善的软件漏洞发现系统（一个不报告漏洞，报告所有实际漏洞的系统）是不存在的。</p><h2 id="2-3传统方法"><a href="#2-3传统方法" class="headerlink" title="2.3传统方法"></a>2.3传统方法</h2><p>尽管软件漏洞分析和发现问题具有不可判定的性质，但由于该问题的重要性，学术界和软件行业的从业者已经研究和提出了大量的方法。提出的方法都不可避免地是近似解;他们都缺乏健全性或完整性，或两者兼而有之。因此，与以前的工作相比，所有研究工作都试图提出一种改进的方法，涉及软件漏洞分析和发现过程的特定方面;例如，漏洞覆盖率，发现精度，运行时效率等。</p><p>Shahriar和Zulkernine（2012）提出了对缓解程序安全漏洞的不同方法的广泛审查，包括在1994年至2010年期间的程序漏洞分析和发现方法。所有程序分析方法可分为三大类：</p><ul><li><strong>静态分析</strong>：根据源代码分析给定程序，无需执行。这些方法利用广义抽象来分析程序的属性，因此静态分析方法最健全的（即没有错过的漏洞，但可能会报告错误的漏洞）。泛化越准确，报告的漏洞就越少。在实践中，必须在分析精度和计算效率之间进行交易。</li><li><strong>动态分析</strong>：通过使用特定的输入数据执行并监视其运行时行为来分析给定程序。在这种方法中，一组输入测试用例用于分析程序的属性，并且由于通常存在无限可能的输入和运行时状态，因此动态分析系统无法分析整个程序的行为。因此，动态分析系统是最完整性的（即，批准所有安全程序而不报告虚假漏洞），但它们不可能是健全的，因为它可能会遗漏一些隐藏在看不见的程序状态中的漏洞。动态分析方法存在实际缺点，即对给定程序的工作运行时的环境要求，以及在分析大型复杂软件时处理所有输入测试用例所需的长时间和高成本。然而，动态分析方法在软件行业中得到了极大的应用。<ul><li><strong>混合分析</strong>：使用静态分析和动态分析技术的混合分析给定程序。基于先前关于静态和动态分析方法的讨论可能存在误解，混合分析方法可能是完整的和健全的（因此，违反了问题的不可判定性）。不幸的是，事实并非如此，虽然混合分析方法可以从静态和动态分析的优势中获益，但它们也受到两种方法的局限性的影响。混合分析方法可以是利用动态分析来识别错误漏洞的静态分析系统，也可以是利用静态分析技术来指导测试用例选择和分析过程的动态分析方法。</li></ul></li></ul><p>但应注意，并非所有静态分析系统都是健全的，并非所有动态分析系统都是完整的。在众多不同的漏洞发现方法中，有些在软件行业中更为成熟;亦即</p><ul><li>Software Penetration Testing: a manual software security testing approach, carried out  by a team of security experts (also referred to as white-hat hackers) (Arkin et al. 2005; Bishop<br>2007).                                                       </li><li>Fuzz-Testing: also known as random-testing, where well-formed input data are randomly  mutated and fed to the program under test at large, while monitoring for failures (Godefroid   2007; Godefroid et al. 2012).                                </li><li>Static Data-Flow Analysis: also known as “Tainted Data-ﬂow Analysis,” it is a static program analysis approach where untrusted data from input sources is marked as tainted and  its ﬂow to sensitive program statements known as sinks is tracked as a potential indicator  of vulnerability (Evans and Larochelle 2002; Larus et al. 2004; Ayewah et al. 2008; Bessey  et al. 2010).                                                </li></ul><h1 id="3-使用机器学习和数据挖掘技术"><a href="#3-使用机器学习和数据挖掘技术" class="headerlink" title="3.使用机器学习和数据挖掘技术"></a>3.使用机器学习和数据挖掘技术</h1><p>除了上述方法之外，还有一类不同的工作利用数据科学和人工智能（AI）的技术来解决软件漏洞分析和发现的问题。在Shahriar和Zulkernine（2012）的评论中忽略了这一类有趣的方法，而在接下来的几年（从2011年起），研究界越来越关注这一方法。<br>人工智能技术中的机器学习技术在许多不同的应用领域都被证明是有效的（Russell和Norvig 2009）。对于计算机安全和隐私领域也是如此，许多不同的应用程序已经使用这些技术解决（例如，垃圾邮件过滤（Guzella和Caminhas 2009; Caruana和Li 2012）和入侵检测系统（Garcia-Teodoro等。 2009; Zhou et al.2010），仅举几例）。</p><p>正如Arthur Samuel在他的开创性工作中所定义的那样，机器学习是开发计算技术和算法的研究，使计算机系统能够在没有明确编程的情况下获得新的能力（Samuel，1959）。数据挖掘是从大量数据中提取知识的计算过程，包括以下几个步骤：数据提取和收集，数据清理和集成，数据选择和转换，知识挖掘以及最终可视化和通信（Han et al.2011） 。机器学习算法和技术经常用于数据挖掘的过程中，用于预处理，模式识别和生成预测模型。</p><p>机器学习技术可大致分为三种主要方法：（1）监督学习：学习系统基于一组标记的训练样例推断出所需的功能/模型，其中每个例子由输入数据（通常是矢量）和所需的相应输出值（标签）。 （2）无监督学习：在没有标记训练数据的情况下，学习系统的目标是识别给定数据集中的模式和结构。 （3）强化学习：学习系统通过与动态环境的交互来接受奖励和惩罚，通过训练来达到某个目标。</p><h2 id="3-1希望和恐惧"><a href="#3-1希望和恐惧" class="headerlink" title="3.1希望和恐惧"></a>3.1希望和恐惧</h2><p>尽管机器学习技术在安全应用中的应用可以追溯到几十年，但近年来机器学习和数据挖掘技术的进步和能力以及它们解决许多困难应用问题的成功案例促使研究人员更加彻底调查这些技术的有效利用，以解决计算机安全和隐私领域的难题。例如，Carl Landwehr分享了他对此事的看法如下：</p><blockquote><p>“在他们的早期，计算机安全和人工智能似乎没有太多可说的对…安全研究人员的目的是解决他们认为防漏的计算基础设施或设计基础设施的漏洞……但是多年来，这两个地方的距离越来越近，特别是在攻击旨在模拟合法行为的地方……我们可能会想象系统会对他们处理的数据有一定程度的自我意识。反射系统（可以参考和修改自己的行为的系统）的概念起源于AI社区……想象一下，一个管道系统包含一个可以检测初期泄漏的智能管道系统。包含智能管道模拟的网络基础设施将引起极大兴趣。“Landwehr（2008）</p></blockquote><p>其他研究人员强调了人工智能技术在计算机安全和隐私领域获得解决复杂问题的重要作用。例如，Tyugu（2011）指出：“很明显，只有在使用人工智能方法时才能成功解决许多网络防御问题。”Heinl（2014）提出了类似的观点。</p><p>另一方面，安全社区也担心使用人工智能技术。例如，尽管在基于异常的入侵检测系统的研究中发表了大量研究，但是之前的一些研究表明这些系统很少部署在入侵检测行业（Sommer和Paxson 2010）。其他研究也对网络入侵检测的异常检测范例提出了挑战（Gates和Taylor 2006）。这些研究的结果强调了这样一个事实，即在计算机安全和隐私领域有效使用AI技术并非易事，需要对这些技术的特性有充分的了解（Sommer和Paxson 2010）。为了获得最佳结果，应该定制机器学习和数据挖掘技术以适应安全问题的特征。在这件事上，莫瑞尔说：</p><blockquote><p>“尽管过去已经完成了一些工作，但AI并没有在当今的网络安全中发挥核心作用，网络安全并不像人工智能那样强烈追求人工智能的发展领域，而其他人…… AI技术是围绕应用程序开发的。网络安全从未成为人工智能集中的一个领域……人工智能已经取得了很多成就，并且有许多与网络安全相关的知识，许多适合网络安全的新技术可以从人工智能中的现有技术中获得启发。“Morel（ 2011）</p></blockquote><p>为此，应该研究针对计算机安全问题量身定制的机器学习技术。</p><h2 id="3-2-以前工作的分类"><a href="#3-2-以前工作的分类" class="headerlink" title="3.2 以前工作的分类"></a>3.2 以前工作的分类</h2><p>在软件漏洞分析和发现的过程中，许多研究在前几年发表研究机器学习和数据挖掘技术的使用，我们在本文中对此进行了广泛的综述。我们将审查的工作分为四大类，总结如下，并将其区分如下：</p><ul><li><p>（1）基于软件度量的漏洞预测模型：大量研究利用（主要是监督的）机器学习方法构建基于众所周知的软件度量作为特征集的预测模型，然后使用该模型根据测量的软件工程指标评估软件工件的漏洞状态。</p></li><li><p>（2）异常检测方法：这类工作利用无监督学习方法从软件源代码中自动提取正常模型或挖掘规则，并将漏洞检测为多数正常和规则的异常行为。</p></li><li><p>（3）漏洞代码模式识别：这类工作利用（主要是监督的）机器学习方法从许多漏洞代码示例中提取漏洞代码段的模式，然后使用模式匹配技术来检测和定位软件中的漏洞源代码。</p></li><li><p>（4）杂项方法：一些值得注意的近期着作，利用AI和数据科学的技术进行软件漏洞分析和发现，这些技术不属于任何上述类别，也不构成一个连贯的类别。</p></li></ul><p>提议分类背后的基本原理是双重的：首先，我们区分分析程序语法和语义的工作，而不区分程序语法和语义。大多数不分析程序语法和语义的工作使用软件工程指标进行漏洞预测。另一方面，在基于分析程序语法和语义的大量研究中，我们观察到两种主要方法：漏洞代码模式识别和异常检测方法。图1直观地总结了分类方案。</p><p>虽然其他标准也可用于分类目的（例如：监督与非监督学习范式，不同的学习和挖掘技术，特征表示方案等），但它们不能创建先前作品的语义连贯类别。我们认为，拟议的分类结果会产生更有意义的研究家族，从而可以更好地比较各种方法，因此我们认为这是对有史以来研究的有组织调查的合适选择。</p><p><img src="/2019/04/02/Sofware-Vulnerability-Analysis-and-Discovery-Using-Machine-Learning-and-Data-Mining-Techniques-A-Survey/1.jpg" alt=""></p><h1 id="4基于软件度量的漏洞预测"><a href="#4基于软件度量的漏洞预测" class="headerlink" title="4基于软件度量的漏洞预测"></a>4基于软件度量的漏洞预测</h1><p>我们在本文中讨论的第一类方法是“漏洞预测模型”，它利用数据挖掘，机器学习和统计分析技术来预测易受攻击的软件工件（源代码文件，面向对象的类，二进制组件，等）基于通用软件工程指标。这些方法的主要思想来自于软件工程领域的软件质量和可靠性保证，其中软件测试和验证的有限资源需要一个指导模型来实现更有效的软件测试计划。为此，已经研究并在工业中使用“故障预测模型”（或“缺陷预测模型”）（Khoshgoftaar等人1997）。故障预测模型是基于从软件项目收集的历史数据训练的计算模型，并提供更可能包含故障的软件工件列表以优先考虑软件测试。历史数据基于不同的软件工程指标，例如源代码大小，复杂性，代码流失和开发人员活动指标（Kaner和Bond 2004）。根据IEEE标准软件工程术语表，术语“度量”被定义为“系统，组件或过程拥有给定属性的程度的定量度量”（1990）。在调查文章中回顾的软件工程领域的故障预测模型的主题上进行了广泛的研究和发表（Catal和Diri 2009; Malhotra 2015）。</p><p>基于与故障预测模型类似的动机，在软件工程领域中提出了漏洞预测模型。检测和缓解安全漏洞需要经过安全思维培训的专家进行人工分析（Heelan 2011）;然而，软件质量和可靠性保证团队的资源有限，需要引导他们进行更有效，更有效的安全审计和测试。基于漏洞是一种特定类型的故障这一事实，已经在业界和学术界提出并研究了漏洞预测模型。与故障预测模型类似，脆弱性预测模型也基于各种软件度量建立，并且不包含程序分析方法（即，分析某些属性的程序源代码）。在下文中，我们将回顾一下这个领域的一些最新作品。</p><h2 id="4-1最近工作总结"><a href="#4-1最近工作总结" class="headerlink" title="4.1最近工作总结"></a>4.1最近工作总结</h2><p>Zimmermann 等人（2010）研究了基于先前用于缺陷预测的研究中使用的经典度量来预测专有商业产品（Microsoft Windows Vista）的二进制模块中存在漏洞的可能性。作为第一个分析，他们使用Spearman的秩相关性计算度量与每个二进制的漏洞数量之间的相关性。结果表明，经典度量与漏洞数量具有统计上的显着相关性;但是，效果很小。另一项分析是评估这些指标的预测能力。作者使用二元Logistic回归分析了经典指标（流失，复杂性，覆盖，依赖和组织）的五组。模型评估采用十倍交叉验证和计算精度以及召回值。作者报告说，大多数指标预测的漏洞具有平均精度（低误报率）;然而，召回率非常低（错误的假阴性或错过的漏洞）并且覆盖率指标未能产生任何有意义的结果。结果包括精度低于67％，召回率低于21％。</p><p>Meneely和Williams（2010）研究了开发者活动指标和软件漏洞之间的关系。正在研究的开发人员活动指标包括：更改源文件的不同开发人员数量，向文件提交的提交数量，以及在贡献网络中包含文件的测序路径数量。作者对三个开源软件项目进行了研究。每个研究中收集的数据集包括一个标签，表明源代码文件是否已修补，以及版本控制日志中的开发人员活动指标。使用统计相关性分析，作者报告发现每个指标与漏洞数量存在显着的显着相关性;但相关性各不相同，并不是很强。作者使用贝叶斯网络作为预测模型，通过十倍交叉验证生成训练和验证集。据作者说，分析表明开发人员活动可以用来预测脆弱的人群;然而，精确度和召回率值令人失望（精确度在12％-29％之间，召回率在32％-56％之间）。</p><p>Doyle和Walden（2011）分析了2006年至2008年间14个最广泛使用的开源Web应用程序中的软件度量和漏洞之间的关系，例如WordPress和Mediawiki。作者使用静态分析工具（例如，Fortify源代码分析器，PHP CodeSni等等）来测量这些应用程序的源代码库中的各种度量，包括静态分析漏洞密度（SAVD），源代码大小，圈复杂度，嵌套复杂性，以及作者提出的另一个名为安全资源指标（SRI）的指标。为了预测，Spearman的等级相关性是在SAVD和其他指标之间计算的。结果表明，没有一个度量标准适用于区分高漏洞Web应用程序和低漏洞Web应用程序;然而，每个函数的平均圈复杂度是几个应用程序的有效预测器，特别是当与SRI分数结合使用时，将应用程序分类为高安全性和低安全性焦点应用程序。由于静态分析工具可能会产生很高的误报，作者手动审查了两个选定的Web应用程序的一个工具（Fortify SCA）的报告，其误报率为18％;得出结论认为假阳性率是可以接受的，对有效性没有威胁。</p><p>Shin和Williams（2013）研究了基于复杂性和代码流失度量的传统故障预测模型是否可用于漏洞预测。为此，作者使用18个复杂度指标，5个代码流失度量标准和故障历史度量标准对Mozilla Firefox进行了实证研究。测试了几种分类技术来预测故障和脆弱的人群;作者声称所有技术的结果都相似。虽然故障源代码的数量是脆弱源数量的7倍，但故障预测模型和漏洞预测模型在漏洞预测方面表现相似;召回率约为83％，精确度约为11％。基于这些结果，作者得出结论，基于传统度量的故障预测模型也可用于脆弱性预测;然而，未来的研究需要提高精确度（减少误报），同时保持高召回率</p><p>在同一作者的另一个工作中，Shin和Williams（2011）研究了使用执行复杂度指标作为软件漏洞的指标。这组作者说，这项研究背后的动机是基于安全专家的直觉，安全专家经常假设“软件复杂性是软件安全的敌人。”为此，作者对两个开源项目进行了实证案例研究，比较执行复杂性和静态复杂性指标对漏洞检测的有效性。总共，本研究收集了23个复杂度指标。作者对指标进行了判别和预测分析。对于判别分析，作者使用Welch的t检验来比较弱势文件与中性文件的度量值的均值。结果显示，其中一个项目的23个指标中有20个表现出统计上显着的判别力;但是，这仅适用于其他项目的大约一半指标，包括没有执行复杂性指标。为了评估指标的预测能力，作者使用Logistic回归进行了二元分类，并进行了十倍的交叉验证。为了解释许多指标中的冗余信息，作者基于信息增益排名执行了特征空间缩减。另一个问题是大多数（中立的人）和少数群体（弱势群体）之间的严重失衡，作者通过随机抽样多数阶层来解决这个问题。最终结果是，对于所有三组指标（代码，依赖关系，所有组合），召回率是公平的（67％-81％），但精确度令人失望（8％-12％）。总之，结果表明这些指标没有静态显着的判别力，预测能力不可靠。</p><p>Shin等人（2011）对复杂性，代码流失和开发人员活动（CCD）指标是否可用于漏洞预测进行了更广泛的研究。为此，作者对两个开源项目进行了实证案例研究。本研究共分析了28个CCD软件指标，包括14个复杂度指标，3个代码流失指标和11个开发人员活动指标。为了评估指标的判别能力，作者使用了Welch的t检验，其中两个项目的28个指标中至少有24个支持检验假设。为了评估指标的预测能力，作者测试了几种分类技术，但它们只呈现了一种分类结果，因为所有技术都提供了类似的性能。为了验证模型的预测能力，作者进行了下一次发布验证，其中有几个版本可供使用，交叉验证只有一个版本可用。评估了单变量和多变量预测假设。基于从故障预测文献中找到的平均值，作者选择阈值至少为70％用于回忆，并且最多25％用于假阳性率以支持预测假设。 28个单变量模型中只有2个，以及使用基于发展历史的指标的4个多变量模型中的3个预测了两个项目的高召回率和低误报率的脆弱性。作者得出结论，与本研究中收集的代码复杂度指标相比，开发历史指标是更强的漏洞指标。</p><p>Moshtari等人（2013）提到了先前关于脆弱性预测模型的研究的三个主要局限性，因此他们提出了一种新方法，通过解决先前研究的局限性，基于复杂性度量来预测软件中的脆弱位置。作者提出了一种半自动分析框架来检测软件漏洞，并将其输出用作漏洞信息，而不是报告的漏洞，作者声称这些漏洞提供了有关软件漏洞的更完整信息。与之前仅研究项目内漏洞预测的研究不同，本研究基于从开源项目收集的数据调查了项目内和项目间的漏洞预测。各种分类技术用于实验。在fle级别粒度下测量了一组11个单元复杂度度量和4个耦合度量。在Mozilla Firefox上进行的项目内预测的报告结果对于各种分类技术而言令人印象深刻（召回率高于90％，误报率低于10％）。作者声称，更完整的漏洞信息有助于这种改进，并通过将提出的方法与Shin等人之前的工作的复制进行比较来证明其声称的合理性。 （2011年）。在随机选择的五个项目版本上进行跨项目实验，其中一个项目被视为测试数据，模型在另外四个项目上进行了培训。根据报告的F2测量，跨项目预测的最佳模型实现了约70％的检测率，约26％的误报。</p><p>Moshtari等人。 （2013）提到了先前关于脆弱性预测模型的研究的三个主要局限性，因此他们提出了一种新方法，通过解决先前研究的局限性，基于复杂性度量来预测软件中的脆弱位置。作者提出了一种半自动分析框架来检测软件漏洞，并将其输出用作漏洞信息，而不是报告的漏洞，作者声称这些漏洞提供了有关软件漏洞的更完整信息。与之前仅研究项目内漏洞预测的研究不同，本研究基于从开源项目收集的数据调查了项目内和项目间的漏洞预测。各种分类技术用于实验。在fle级别粒度下测量了一组11个单元复杂度度量和4个耦合度量。在Mozilla Firefox上进行的项目内预测的报告结果对于各种分类技术而言令人印象深刻（召回率高于90％，误报率低于10％）。作者声称，更完整的漏洞信息有助于这种改进，并通过将提出的方法与Shin等人之前的工作的复制进行比较来证明其声称的合理性。 （2011年）。在随机选择的五个项目版本上进行跨项目实验，其中一个项目被视为测试数据，模型在另外四个项目上进行了培训。根据报告的F2测量，跨项目预测的最佳模型实现了约70％的检测率，约26％的误报。 </p><p>Meneely等人（2013）通过将Apache HTTPD Web服务器中的65个以上漏洞追溯到最初贡献易受攻击代码的版本控制提交，探讨了漏洞贡献提交（VCC）的属性。作者手动发现了124个VCC，跨越17年，他们使用统计分析技术根据代码流失和开发人员活动指标进行分析。根据这项探索性研究的结果，他们提出了几个方面：（1）代码流失度量标准与VCC在经验上相关，其方式是更大的提交可能会引入漏洞; （2）承诺更多的开发人员更有可能成为VCC; （3）由新开发商提交给来源，更有可能是VCC。</p><p>Bosu等人（2014）进行了类似的实证研究，他们分析了来自10个开源项目的260,000多个代码审查请求，使用三阶段半自动化流程识别了400多个易受攻击的代码更改。他们的目标是确定漏洞代码更改的特征，并确定可能引入漏洞的开发人员的特征。一些关键的因素包括：（1）经验不足的贡献者的变化显然更有可能引入漏洞; （2）漏洞可能性随着变化的大小而增加（更多行改变）; （3）与修改后的文件相比，新文件不太可能包含漏洞。</p><p>Perl等人（2015）研究了使用代码存储库中包含的元数据以及代码度量来识别漏洞贡献提交的效果。作者声称软件逐渐增长，大多数开源项目都使用版本控制系统，因此，提交是检查漏洞的自然单位。有了这个动机，作者编译了一个包含来自66个C / C ++ GitHub项目的170,860个提交的数据集，其中包括映射到相关CVE ID的640个漏洞贡献提交（VCC）。作者选择了一组代码流失和开发人员活动指标，以及来自不同范围（项目，作者，提交和文件夹）的GitHub元数据，并为收集的数据集提取这些功能。基于该数据集，作者评估了他们提出的名为VCCFinder的系统，该系统使用支持向量机（SVM）分类器来识别来自中立提交的VCC。为了评估，该系统在2010年底之前接受了数据培训，并根据2011年至2014年报告的CVE进行了测试。作者将他们提出的系统的结果与FlawFinder静态分析工具的结果进行了比较。在相同的召回水平（召回率= 24％），FlawFinder的精度仅达到1％，而VCCFinder达到60％的精度，产生的误报率要低得多。上述数据集由作者公开发表，作为对研究界的贡献。</p><p>Walden等人（2014）进行了一项研究，以比较基于软件度量与文本挖掘技术预测漏洞软件组件的性能。为此，作者首先构建了一个手工策划的漏洞数据集，这些数据集来自三个大型流行的开源PHP Web应用程序（Drupal，Moodle，PhpMyAdmin），包含223个漏洞。该数据集作为贡献提供给研究界。对于基于软件度量的漏洞预测，为该研究选择了一组12个代码复杂度度量。对于文本挖掘，每个PHP源文件都是第一个标记化的，不必要的标记被删除或转换（注释，标点符号，字符串和数字文字等），并计算最终标记的频率。众所周知的“词袋”技术用于从每个PHP源文本的文本标记构造数字特征向量。基于先前的漏洞预测研究经验，作者选择随机森林模型作为主要分类算法。对于模型评估，作者使用分层三重交叉验证。作者还通过对多数类（非易受攻击代码）执行随机欠采样来解决不平衡类数据的问题。根据作者的各种实验，基于文本挖掘的预测技术平均表现更好（即，更高的召回率和精确度），并且差异在统计上是显着的。作者还测试了跨项目漏洞预测，但两种方法的跨项目预测性能普遍较差。由于作者没有考虑应用程序之间数据的不均等分布，因此预计跨项目预测表现不佳。</p><p>Morrison等人（2015）指出，虽然微软团队采用了缺陷预测模型，但漏洞预测模型（VPM）并非如此。为了解释这种差异，作者尝试复制Zimmermann等人提出的VPM。 （2010）有两个较新版本的Microsoft Windows操作系统。作者将二进制水平预测精度提高了约75％，并且召回率约为20％;然而，二进制文件通常对于实际检查来说非常大，并且工程师首选源级别预测。因此，作者为源流水平粒度建立了相同的模型，其精度低于50％，召回率低于20％。基于这些结果，作者得出结论：“必须通过安全特定指标来”重新调整VPM以实现可操作的性能。“</p><p>Younis等人。 （2016）尝试识别包含更可能被利用的漏洞的代码的属性。为此，作者收集了来自Linux内核和Apache HTTPD Web服务器项目的183个漏洞，其中包括82个可利用的漏洞。作者从四个不同的类别中选择八个软件度量来表征这些漏洞，并使用Welch的t检验来检验每个度量的判别力。指标的判别力的结果是混合的;一些指标在统计上具有显着的判别力，而其他指标则没有。作者还研究了是否存在可用作可利用漏洞预测因子的指标组合，其中测试了三种不同的特征选择方法和四种不同的分类算法。表现最佳的模型是具有包装子集选择方法的随机森林分类，其实现了84％的F-度量。</p><h2 id="4-2讨论"><a href="#4-2讨论" class="headerlink" title="4.2讨论"></a>4.2讨论</h2><p>在前一小节中，我们回顾了基于软件度量的脆弱性预测模型的最新研究。表1列出了本节所述所有文章的摘要，其中我们指定了每项工作的主要差异因素。</p><p><img src="/2019/04/02/Sofware-Vulnerability-Analysis-and-Discovery-Using-Machine-Learning-and-Data-Mining-Techniques-A-Survey/2.jpg" alt=""></p><p>人们可能会质疑基于软件工程指标来预测软件漏洞存在的基本决策，作为混淆症状和原因的一个例子（Zeller etal. 2011 ）。一些研究（例如，Walden等人（2014）强调了这种批评，这些研究表明，与基于某些软件度量的脆弱性预测模型相比，软件源代码的基本文本挖掘可以在预测性能方面产生更好的结果;尽管如此，这种实证研究不能推广到所有软件项目和所有软件指标。另一方面，Tang等人最近的一项研究（2015）批评了Walden等人的结论（2014），因为他们没有考虑影响代码检查的单个组件的大小;因此，他们比较了这两种预测模型在易受影响的漏洞预测背景下的预测能力，并得出结论，这两种指标的表现相似。</p><p>使用软件度量进行漏洞预测的一个理由是，这些度量标准通常很容易获得，或者很容易在软件工程项目中获得。此外，软件故障/缺陷预测模型已经在一些软件项目中使用，而构建漏洞预测模型不需要额外的专业知识。另一方面，这些系统的目的是仅作为更好地规划和分配软件工程团队资源的指导模型。因此，基于软件度量的漏洞预测模型是工业界和学术界的一系列研究。</p><p>基于上面回顾的上述工作，很明显，基于软件指标的漏洞预测模型尚未成熟。从以往研究的回顾中可以得出一些结论，包括挑战和可能的未来工作： </p><ul><li><p>脆弱性预测模型的统计挑战是由数据集中的漏洞很少而且稀疏的事实引入的。在数据挖掘和机器学习的过程中，这个问题被称为不平衡类数据，它可以极大地阻碍机器学习算法的性能，并且有解决该问题的实践（Domingos 2012）。本节中回顾的一些先前的工作已经解决了不平衡类数据问题，并且对大多数类进行了随机欠采样。这是一个重要的问题，任何利用机器学习和数据挖掘技术的研究都不应忽视这一问题。</p><ul><li>与之前的大多数研究相比，Moshtari等人（2013）使用半自动化框架进行漏洞检测，他们使用这种框架代替通过公共咨询和漏洞数据库（例如NVD）提供的信息。与之前的作品相比，他们获得了显着更高的召回率和精确度值（即使在跨项目设置中）。这可能是一种很有前景的方法，未来的研究也可以用来收集更完整的漏洞信息并获得更好的结果。</li><li>漏洞预测模型领域中的跨项目研究很少，因此是未来工作的一个领域。特别是与缺陷预测模型相比，跨项目漏洞预测的研究非常不足。跨项目预测引入了额外的挑战，这些挑战源于训练和测试集中的数据分布可能显着变化并且阻碍传统机器学习和统计分析技术的性能。这一挑战在机器学习研究中被称为“归纳转移”（或“转移学习”）技术（Pan and Yang 2010），它们的使用已经在软件缺陷预测研究中得到了研究（Ma et al.2012 ; Nam et al.2013）。这些研究可以成为未来跨项目脆弱性预测模型研究的基础。</li><li>基于软件指标的漏洞预测研究中的大多数研究报告结果不佳。一个可能的结论是传统的软件度量标准不适合软件漏洞。 Morrison等人明确讨论了这一结论（2015年）。从此以后，确定安全特定指标，例如Doyle和Walden（2011）提出的安全资源指标（SRI）是未来研究的另一个领域。</li><li>这个领域的未知领域正在使用深度学习方法进行漏洞预测。深度学习是机器学习研究中新出现的一个主题，它在几个应用领域取得了巨大成就，并且越来越受到研究人员和从业者的关注（LeCun等人，2015）。Yang等人（2015）提出了一项关于应用深度学习方法进行即时软件缺陷预测的研究。这是脆弱性预测模型的未来研究的另一个有希望的领域。</li></ul></li></ul><h1 id="5异常检测方法"><a href="#5异常检测方法" class="headerlink" title="5异常检测方法"></a>5异常检测方法</h1><p>在本节中，我们将回顾一类使用机器学习和数据挖掘技术进行软件漏洞分析和发现的异常检测方法。异常检测是指数据中的模式不符合正常和预期行为的问题;通常被称为anomalies或outliers（Chandola等，2009）。在许多不同的研究领域和应用领域中已经广泛研究了这个问题;包括软件缺陷和漏洞发现领域。</p><p>在软件质量保证的背景下，异常检测方法旨在通过使源代码中的位置不符合应用程序编程接口（API）的通常或预期代码模式来识别软件缺陷。这种API使用模式的简单示例是malloc和free的函数调用对，或者lock和unlock。除了这些简单的众所周知的模式之外，每个API都有自己的规则和模式份额，这些规则和模式也很复杂，而且记录不完善。不符合API的预期规则和使用模式可能导致软件缺陷，也可能导致软件漏洞。</p><p>异常检测方法应用于软件质量保证的另一个领域是检测被忽视的条件或缺少检查。缺少检查是许多软件缺陷和漏洞的根源。这些检查可大致分为两类：（1）正确使用API所需的检查; （2）检查实现程序逻辑。这两种类型都可能导致软件缺陷或软件漏洞。第一种类型的示例是检查用作API函数调用的参数的输入数据的正确类型或值。缺少这样的检查可能导致软件崩溃，未定义或不期望的行为（例如，除以零）。失败也可能产生安全后果（例如，流量溢出，SQL注入等）。在访问资源对象时，缺少第二种类型的示例来检查主题的权限或权限。同样，这些逻辑缺陷可能具有安全性后果，从而导致安全逻辑漏洞（例如，机密性和完整性访问控制）。</p><p>已经提出异常检测方法用于检测不正确的API使用模式和丢失检查。这些方法的一个重要方面是自动提取正常行为，换句话说，自动提取规范，规则和模式，然后将其用作检测异常行为的基础。自动提取正常行为对于这些方法的适用性和成功性至关重要，而如果人类用户提供正常行为或规范，则会极大地妨碍该方法的效率，因为：（1）编写规范是艰巨而乏味的任务; （2）人为错误可导致不准确的指定，导致不正确的结果。</p><p>在下文中，我们按时间顺序回顾和总结以前的工作，从过去十年的早期工作开始，到近年来在软件缺陷和漏洞检测的异常检测方法中的最新工作。请注意，一些经过审核的工作侧重于安全漏洞，而其他漏洞则没有;但我们仍在审查这些工作，因为所提出的方法并非专门针对非安全性缺陷。</p><h2 id="5-1-最近工作总结"><a href="#5-1-最近工作总结" class="headerlink" title="5.1 最近工作总结"></a>5.1 最近工作总结</h2><p>已经提出异常检测方法用于检测不正确的API使用模式和丢失检查。这些方法的一个重要方面是自动提取正常行为，换句话说，自动提取规范，规则和模式，然后将其用作检测异常行为的基础。自动提取正常行为对于这些方法的适用性和成功性至关重要，而如果人类用户提供正常行为或规范，则会极大地妨碍该方法的效率，因为：（1）编写规范是艰巨而乏味的任务; （2）人为错误可导致不准确的指定，导致不正确的结果。</p><p>在下文中，我们按时间顺序回顾和总结以前的工作，从过去十年的早期工作开始，到近年来在软件缺陷和漏洞检测的异常检测方法中的最新工作。请注意，一些经过审核的工作侧重于安全漏洞，而其他漏洞则没有;但我们仍在审查这些工作，因为所提出的方法并非专门针对非安全性缺陷。</p><p>Engler 等人（2001）指出，解决程序错误的一个主要障碍是知道系统必须遵守的正确性规则，这些规则通常是无证的或以临时方式指定的。为了解决这个问题，他们演示了一种自动提取程序源代码隐含的程序员beliefs的技术。为此，他们讨论了错误作为异常行为的概念，并提出了一种方法，通过为源代码定制“规则模板”来提取程序员的beliefs（例如，规则模板“<a>必须与之配对的函数调用 <b>“）。提取了两种类型的规则：（1）Must-beliefs 和（2）May-beliefs。Must-beliefs 是某些众所周知的编程规则（例如，“指针解引用意味着程序员必须相信指针是非空的”）。 May-belief是一些代码特征表明beliefs的情况，但可能是巧合。为了区分有效的May-beliefs 和巧合，使用称为Z-排名的统计分析技术来发现这些beliefs的违规（或错误），以对错误进行排序和分类。为了评估，作者检查了复杂软件系统上的各种规则模板，例如Linux和OpenBSD项目。结果显示不同情景下的假阳性率不同，从4％到57％不等。作者还使用众所周知的安全漏洞规则测试安全检查程序，导致Linux和OpenBSD中出现35个安全漏洞。</b></a></p><p>Livshits和Zimmermann（2005）提出了一个名为DynaMine的工具，它根据高度相关的方法调用分析修订历史中的源代码校验，以自动提取特定于应用程序的编码模式。 DynaMine分析增量变化，这有助于实现更精确的结果。所提出的方法首先预处理已插入的方法调用的软件修订历史，并将该信息存储在要挖掘的数据库中。挖掘方法基于经典先验算法的修改版本，其使用一组项目作为其输入并且在项目之间产生频繁的项目集和强关联规则。这些修改改进了算法的运行时间，并允许该方法进行扩展以分析大型软件系统。此外，作者将几种排名策略应用于算法挖掘的模式。提取的模式被呈现给用户以进行评估。在用户选择模式之后，使用动态分析工具进一步验证所选模式并检测违规。该方法在两个大型Java项目上进行了评估。据作者称，拟议的挖掘方法发现了56种以前未知的，高度应用程序特定的模式。根据实验结果，56个（57％）模式中有32个在运行时被击中，其中32个（66％）模式中的21个被认为是非常有效的模式。此外，发现超过260种模式违规，但作者没有评估假阳性率。</p><p>Li和Zhou（2005）断言程序通常遵循许多隐式和未记录的编程规则，这些规则违反了这些规则，不知情的程序员很容易引入缺陷。作者提出了一种名为PR-Miner的方法，用于从大型源代码中提取隐式编程规则，而无需事先了解软件，也不需要程序员的大量工作。 PRMiner旨在以一般形式（没有fxed模板）提取编程规则，包含不同类型的多个元素，如函数，变量和数据类型。总之，PR-Miner首先解析和预处理程序源代码，删除不必要的元素，如关键字，常量数据值等，并根据数据将结构中的函数和数据中的局部变量重命名为相似的名称类型。在预处理之后，所有程序元素被散列为数字，并且函数定义被映射到函数内的所有元素的一组数字散列值，作为行插入到项集数据库中。使用频繁项集挖掘算法（即FPclose）挖掘该数据库，以找出一起出现的频繁程序元素。这些频繁的程序元素集称为编程模式。有效的规则生成算法用于从频繁的编程模式中提取编程规则。编程规则用于检测违规，这是基于在大多数情况下通常遵循编程规则并且很少发生违规的想法。对三个大型开源项目进行评估。结果表明，PR-Miner在这些软件项目中发现了数以千计的规则，作者无法对所有这些规则进行验证，只讨论了一些样本。 PR-Miner还报告了许多违规行为，作者设法仅手动评估前60位报告，揭示假阳性率很高（73％-90％之间）。</p><p>Wasylkowski等（2007）重申这样一个事实，即与对象交互通常需要遵循模型或协议，这些模型或协议并不总是记录在案，并且违规可能导致缺陷。为了自动提取典型的对象使用模型，作者提出了在程序源代码中挖掘方法调用的序列，然后将其用作偏差作为缺陷候选者。首先，从Java字节码中提取对象使用模型，Java字节码是具有匿名状态的fnite状态自动机，以及作为状态转换的可行方法调用。使用每个单一方法的过程内静态分析来提取该模型。然后，使用对封闭模式的频繁项集挖掘，从使用模型中挖掘方法调用的时间属性（例如，“方法next（）可以在hasNext（）之前”）。这些频繁的模式表示正常的对象使用，并用于训练分类器以识别对这些模式的违反，这些模式被视为可能的缺陷位置。此外，作者还引入了一个缺陷指标，该指标根据几个因素对异常进行排序。提出的方法是作为一个名为JADET（用于Java异常检测器）的工具实现的。评估是在fve流行的开源Java程序上进行的。根据报告的结果，在所有5个项目中JADET检测到的前77个异常中，有40个（52％）误报，5个缺陷，5个代码smells和27个提示。</p><p>Acharya等（2007）指出以前的方法无法在API使用模式中捕获一些有用的排序信息，特别是当跨不同的进程涉及多个API时。作者提出了一种从API客户端代码中提取“频繁部分规则”的自动方法。该方法包括四个主要步骤，并基于一些名为MAPO的作者的先前工作（Xie和Pei 2006）。在第一步中，采用下推模型检查（PDMC）过程来提取与API相关的进程间控制流敏感的静态迹线。在第二步中，在给定的跟踪上使用算法来分离不同的使用场景，因此可以单独挖掘每个场景。在第三步中，名为FRECPO的方法用于从每个静态执行跟踪中提取的一组场景中挖掘“频繁闭合的部分规则”（FCPO）。 FCPO可能不是通用模式，只能针对分析的客户端代码进行指定。为了解决这个问题，引入了一个名为Mine-Verify的算法，该算法使用两个随机拆分的不相交的客户端集来验证模式。为了评估，该框架应用于X11 UNIX窗口系统的72个客户端程序。对于每个实验，随机选择36个客户作为挖掘客户端，其余36个客户端用作验证客户端。作者没有对他们的实验结果进行评估，而是仅对一个例子进行评估;为此，通过该方法成功检测到6种已知模式中的5种，并且仅报告了一种错误模式。</p><p>Chang等 （2008）通过对Firefox项目的版本1.0和1.5中的bug fxes进行初步研究，强调忽略条件作为一种难以解决的缺陷类别的重要性，该项目显示167个选定的错误中有109个（65％）涉及一个或多个被忽视的条件。为此，作者提出了一种方法，将数据挖掘技术与静态程序分析相结合，以提取代码库中的隐式条件规则，并将被忽视的条件作为规则违规进行检测。因此，程序由“系统依赖图（SDG）”表示，作为修改的“过程依赖图（PDG）”的集合，称为“增强PDG”（EPDG）。 EPDG增加了所谓的“共享数据依赖边缘”（SDDE），它链接在控制流路径中使用相同变量定义的程序元素。潜在规则由EPDG minors代表，可以将其视为EPDG的子图，其中一些路径已经收缩到边缘。 “启发式最大频繁子图挖掘（HMFSM）”算法用于在EPDG子图的“近传递闭包（NTC）”的数据库中找到重复的图minors。在提取和确认有效规则之后，使用启发式图匹配算法搜索NTC图数据库的规则违反（忽略条件）。为了评估，作者通过在四个开源项目中应用该方法进行了实验。在所有四个项目中，该方法检测到超过1200个候选规则，平均不到25％的检测规则无效（没有语义意义）。启发式图匹配算法在fnding规则实例中完全成功，具有100％的精度，但违规检测的结果并不令人印象深刻，其中所有四个项目中79％的报告违规都是误报。作者声称“大约一半的误报是由语义上等同的陈述给出了不同的标签”，并提出了改善未来工作情况的一些建议。</p><p>Thummalapenta和Xie（2009）提出了一种新方法来降低自动挖掘编程规则的误报率。为此，他们引入了“替代模式”的概念，其中API调用的各种频繁模式被一起考虑。例如，替代模式可以是P1或P2形式，其中P1和P2都是频繁的，P2是P1的语义替代。误报的另一个原因是不平衡的替代模式，其中P1和P2是语义上有效的替代方案，但P1是高频率的，而P2在整个代码库中并不常见。这些不平衡的替代方案表示为“P1或P2”，使用传统的挖掘技术更具挑战性。提出了一种称为“Alattin”的方法，其包括称为“ImMiner”的新挖掘算法，其使用迭代挖掘策略来挖掘平衡和不平衡模式以及用于检测被忽略条件的技术。首先，Alattin在源代码中提取重用的API，并将它们提供给代码搜索引擎以收集其他相关的代码示例。在收集的数据库上执行频繁的项集挖掘以提取频繁的模式。然后，对于每个频繁模式，输入数据库被分成两个负数据库和正数据库，其中否定数据库包括不符合模式的所有模式候选者，而肯定数据库包括所有符合候选者。频繁的项目集挖掘再次应用于否定数据库以构建不平衡的替代模式。然后使用这些挖掘的模式来检测方法调用站点处的违规。为了检测被忽略的条件，Alattin提取围绕API调用站点的所有条件检查。由于每个挖掘模式都包含多个备选方案，因此只有在呼叫站点不满足任何备选方案时，Alattin才会报告违规行为。出于评估的目的，对6个Java库执行了经验实验，其中总共144个模式被挖掘，运行时间约为1小时。作者手动评估了144种模式中的90种，其中75种（83％）是真实规则，7种是部分规则，8种（9％）是错误规则。与类似方法相比，对相同文库进行违规检测的实验导致假阳性减少28％。</p><p>Gruska等（2010）研究了跨项目异常检测的可能性。为此，作者引入了一种轻量级，与语言无关的解析器，适用于分析用几种语言编写的程序，语法类似（包括C，C ++，Java和PHP）。由于所提出的方法基于程序结构和函数调用，因此可以忽略源代码中存在的许多细节，并且解析器仅解析源代码的选定部分;这就是使解析器轻量级和语言无关的原因。解析过程包括几个步骤，包括创建令牌，识别结构和提取函数调用。类似于抽象语法树（AST）的专门设计的通用抽象表示用于存储由解析器提取的信息。抽象表示用于创建函数模型，这些函数模型是有限状态机，其中状态表示代码中的位置，转换是函数调用。此模型用于在特定函数中提取所有可能的函数调用序列以及其他相关信息，例如被调用函数的名称，参数数量，参数，返回值和目标。然后，将每个函数模型转换为一组时间属性，表示函数调用之间的值的流动。这是通过使用作者之前的工作中的JADET工具来实现的（Wasylkowski等人，2007）。扩展JADET工具以支持上述模型，并用于从功能模型中挖掘频繁的时间属性。概念分析方法用于异常检测，类似于JADET工具中使用的方法。最后，在呈现给用户之前对检测到的异常进行排序和过滤。为了进行评估，开发了6000多个开源Linux项目，以提取1600万个临时属性，反映正常的API使用情况。作者从分布中随机选择了20个项目，并应用了异常检测。从总共138个检测到的异常中，只有前25％是由作者手动评估的，这导致仅4个缺陷，7个代码异味和39个（78％）误报。作者还将其分析系统作为基于网络的服务提供给checkmycode.org，该服务目前已停止服务，截至2011年底。</p><p>Yamaguchi等人 （2013）提出了一个名为Chucky的系统，用于自动检测源代码中的缺失检查，旨在协助手动代码审计。 Chucky将机器学习技术与静态程序分析相结合，以确定缺失的检查。作者在源代码中区分了两种类型的安全检查：（1）检查实现安全逻辑（例如，访问控制）; （2）检查确保安全的API使用（例如，检查大小）。 Chucky采用了一个五步程序，为审核员选择的每个源和接收器执行。分析从基于岛语法的强大解析开始，其中为每个函数定义提取条件，赋值和API符号。其次，基于函数中API符号的相似性，使用最近邻和词袋技术来执行邻域发现。第三，执行轻量污染以仅确定与目标源或接收器相关联的那些检查。第四，基于受污染的条件将所有函数及其邻居嵌入向量空间中。最后，通过首先计算所有嵌入相邻向量的质心作为正态性模型来执行异常检测，然后基于其向量与其邻域的正常模型的距离计算每个函数的异常分数。基于异常分数对最终结果进行排序并呈现给用户。进行定性和定量评估以证明该方法的有效性，他们分析了几个开源项目代码中缺失的检查。作者报告说，Chucky在所有项目中都发现了几张丢失的支票，其中几乎所有前10名都报告了每项功能的异常，其中包含缺陷或安全漏洞。此外，在本研究过程中还使用Chucky发现了12个先前未知的漏洞（即0-day）。</p><h2 id="5-2-讨论"><a href="#5-2-讨论" class="headerlink" title="5.2 讨论"></a>5.2 讨论</h2><p>在上一小节中，我们回顾并总结了异常检测领域的一些研究，以发现软件缺陷和漏洞为异常行为。表2中还列出了本节中所有文章的概览，其中我们指定了每项工作的主要差异因素。</p><p><img src="/2019/04/02/Sofware-Vulnerability-Analysis-and-Discovery-Using-Machine-Learning-and-Data-Mining-Techniques-A-Survey/3.jpg" alt=""></p><p>如前所述，异常检测方法可用于解决由于API使用不当导致的技术软件漏洞，以及由于忽略条件或缺少检查而导致的逻辑漏洞。需要注意的一个重要事实是，此过程可以由工具自动执行，而无需指定安全策略或安全性规范。我们认为，这是异常检测方法最有希望的方面。但是，软件缺陷和漏洞发现的异常检测方法存在局限性：</p><ul><li>异常检测方法仅适用于成熟的软件系统。此限制是因为基本假设缺少检查或不正确的API使用是罕见事件，并且应用于安全对象的大多数条件以及软件项目中的API使用都是正确的。这种假设在成熟的软件项目中主要适用。</li><li>在代码库中必须经常进行条件检查或API使用，以便通过挖掘算法将其检测为模式。罕见的检查或API使用不太可能作为模式被挖掘，因此无法检测到偏差。所有利用频繁项集挖掘方法的工作都受此限制（例如，Li和Zhou（2005），Wasylkowski等（2007年），和Gruska等人（2010））。</li><li><p>有时，异常检测方法无法指定缺陷或漏洞的类型，因为这些方法只能说明给定代码不符合任何正常规则或模式，并且可能违反任何规则或模式。当然，可能存在实例明显违反单个规则或模式而不是任何其他实例的情况，在这种情况下，系统可以指定缺陷的类型甚至修复。</p></li><li><p>先前方法的高假阳性率表明这些系统尚不可靠，输出需要仔细的人工审核，这限制了异常检测系统的可用性。从高假阳性率中得到的一些值得注意的工作包括（Li和Zhou 2005; Wasylkowski等人2007; Chang等人2008）。</p></li></ul><p>异常检测方法的局限性并不仅限于软件缺陷和漏洞发现领域，许多其他应用领域也存在这些缺点。异常检测范式在网络入侵检测领域受到挑战;例如盖茨和泰勒（Gates and Taylor，2006）提出了一个具有挑衅性的讨论，他们质疑研究人员通常做出的一些假设。Sommer和Paxson（2010）还提供了关于采用异常检测方法进行网络入侵检测的挑战的讨论。 Chandola等人提供了关于不同应用领域中异常检测系统的挑战和不同方面的更一般性讨论（2009年）。</p><p>很明显，在使用异常检测的漏洞发现方面仍有进一步发展的空间。从先前研究的回顾中得出的一些可能的未来工作如下： </p><ul><li><p>先前关于缺陷和脆弱性发现的异常检测的工作中的普遍问题是高假阳性率。分析工具输出中的高误报率使其用户压倒无效。通过降低假阳性率来提高准确性对于未来的工作非常重要。 Thummalapenta和Xie（2009）的工作是这方面研究的一个例子，它提供了有趣的贡献。</p><ul><li>像Chucky（Yamaguchi等人，2013）这样以安全为重点的方法存在的一个问题是无法区分安全相关的异常（漏洞异常）和非漏洞的异常。这些方法可以成功地解决缺少检查和不正确的API使用缺陷，但并非所有这些缺陷都是安全漏洞。未来的工作可以提出新方法来帮助区分缺陷和安全漏洞，使结果与安全分析师更相关并提高可用性。</li><li>Graphs是丰富的表示，广泛用于程序分析，软件测试和软件漏洞发现领域。 Chang等（2008）研究了使用图挖掘和图匹配技术来发现软件中的缺失检查缺陷。如前所述，这项工作在提取规则和匹配实例方面取得了可喜的成果，但却产生了很高的误报率。最近的一项调查由Akoglu等人发表（2015），回顾了基于图的异常检测和描述的最新进展。在未来的工作中可以进一步研究用于漏洞发现的基于图的异常检测领域。</li></ul></li></ul><h1 id="6漏洞代码模式识别"><a href="#6漏洞代码模式识别" class="headerlink" title="6漏洞代码模式识别"></a>6漏洞代码模式识别</h1><h2 id="6-1最近工作总结"><a href="#6-1最近工作总结" class="headerlink" title="6.1最近工作总结"></a>6.1最近工作总结</h2><h2 id="6-2讨论"><a href="#6-2讨论" class="headerlink" title="6.2讨论"></a>6.2讨论</h2><h1 id="7其他方法"><a href="#7其他方法" class="headerlink" title="7其他方法"></a>7其他方法</h1><h1 id="8应用技术分析"><a href="#8应用技术分析" class="headerlink" title="8应用技术分析"></a>8应用技术分析</h1><h2 id="8-1特征工程和表示"><a href="#8-1特征工程和表示" class="headerlink" title="8.1特征工程和表示"></a>8.1特征工程和表示</h2><h2 id="8-2模型构建"><a href="#8-2模型构建" class="headerlink" title="8.2模型构建"></a>8.2模型构建</h2><h2 id="8-3模型评估"><a href="#8-3模型评估" class="headerlink" title="8.3模型评估"></a>8.3模型评估</h2><h1 id="9结论和未来工作"><a href="#9结论和未来工作" class="headerlink" title="9结论和未来工作"></a>9结论和未来工作</h1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;由于其中主要内容都是关于数据挖掘技术在源代码漏洞和分析中的使用总结，涉及到使用机器学习方法的较少，所以未翻译阅读完，后续再继续翻译。&lt;/strong&gt;&lt;/p&gt;
&lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;head
      
    
    </summary>
    
      <category term="论文" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/"/>
    
      <category term="数据挖掘" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"/>
    
      <category term="综述" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/%E7%BB%BC%E8%BF%B0/"/>
    
    
      <category term="综述" scheme="http://yama0xff.com/tags/%E7%BB%BC%E8%BF%B0/"/>
    
      <category term="2017年" scheme="http://yama0xff.com/tags/2017%E5%B9%B4/"/>
    
      <category term="数据挖掘" scheme="http://yama0xff.com/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"/>
    
  </entry>
  
  <entry>
    <title>A Survey on Source Code Review Using Machine Learning</title>
    <link href="http://yama0xff.com/2019/04/02/A-Survey-on-Source-Code-Review-Using-Machine-Learning/"/>
    <id>http://yama0xff.com/2019/04/02/A-Survey-on-Source-Code-Review-Using-Machine-Learning/</id>
    <published>2019-04-02T12:14:25.000Z</published>
    <updated>2019-04-02T13:49:23.662Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>源代码审查充分限制了软件系统的安全性。可伸缩性和精度对于代码审查工具的部署非常重要。但是，传统工具只能通过繁琐的大规模源代码审查来自动检测一些高误报和漏报的安全漏洞。各种脆弱点和漏洞在源代码中显示出特定的特征。机器学习系统建立了源代码的特征矩阵作为输入，包括变量，函数和文件，通过区分或生成方法生成ad-hoc标签，以自动和智能地查看源代码。无论编程语言如何，源代码本质上都是文本信息。安全和易受攻击的函数都可以从源代码凸出。幸运的是，已经开发了各种机器学习方法来学习和检测智能源代码安全审查中的脆弱点和漏洞。代码语义和句法特征的组合有助于在源代码审查期间对假阳性和假阴性的优化。在本文中，我们使用机器学习方法对与智能源代码安全性审查相关的文献进行了回顾。它说明了在源代码安全审查中接近ML的主要证据。我们相信机器学习及其分支机构将在源代码审查中脱颖而出。</p><table><thead><tr><th>relevant information</th><th></th></tr></thead><tbody><tr><td><em>作者</em></td><td>Wang Xiaomeng, Zhang Tao, Xin Wei,Hou Changyu</td></tr><tr><td><em>单位</em></td><td>China Information Technology Security Evaluation Center Beijing, China;China anhua technology Limited company Beijing, China</td></tr><tr><td><em>出处</em></td><td>2018 3rd International Conference on Information Systems Engineering</td></tr><tr><td><em>原文地址</em></td><td><a href="https://ieeexplore.ieee.org/document/8614720" target="_blank" rel="noopener">https://ieeexplore.ieee.org/document/8614720</a></td></tr><tr><td><em>源码地址</em></td><td></td></tr><tr><td><em>发表时间</em></td><td>2018年</td></tr></tbody></table><h1 id="I-介绍"><a href="#I-介绍" class="headerlink" title="I. 介绍"></a>I. 介绍</h1><p>​        本文介绍了机器学习（ML）在源代码审查中文献综述的研究成果。代码审查目标是发现错误，安全漏洞和违反程序规范。代码错误，弱点或漏洞在软件中很普遍，并且可能导致各种安全问题，包括死锁，信息泄露或系统崩溃，更严重的是，一些黑客攻击[1]。WannaCry勒索软件攻击是2017年5月WannaCry勒索软件发起的全球网络攻击[2]。该攻击于2017年5月12日星期五开始[3] [4]，据报道，在一天之内，已有150多个国家的230,000多台计算机受到感染。 [5] [6]英国国家健康服务（NHS）的部分地区受到感染，导致其在袭击期间仅在紧急情况下运行一些服务，西班牙的TelefónicaFedEx和Deutsche Bahn以及许多其他世界各国和公司[7]。中国的一些Windows操作系统已经被感染，而校园网用户已经是第一个遭受严重破坏的用户。大量的实验室数据和毕业设计已被锁定。一些大型企业的应用系统和数据库文件在加密后无法正常运行。这些袭击威胁到企业，政府和消费者，随着黑客犯罪对全球经济的年度成本增加，费率和成本也在增加。2017年，估计全球安全市场将超过1200亿[1]。因此，检测到更早的漏洞或错误，软件系统将更好。作为软件安全保护最重要的部分之一，源代码审查已经服务了数十年，并且已经通过ML和数据挖掘将更多智能方法植入到挖掘代码漏洞中。</p><p>​        在过去的十年中，ML在代码审查中得以蓬勃发展[8] [9] [10] [11]。本文描述和讨论了ML算法和应用的最新技术。机器学习已经在源代码安全任务中得到应用，例如代码推荐，源代码错误检测和代码检索。传统的机器学习系统利用手动特征工程来进行代码错误检测，这是标签只能临时的用于特定项目。随着机器学习的核心扩展，深度学习方法能够通过很少的手动操作捕获复杂的自下而上功能。深度学习可以智能地提取错误的代码特征，将程序特征与查询的特征匹配，并预测下一个可能代码的概率[1]。源代码最终是文本信息，主要涉及深度学习中的自然语言（NLP）研究。不幸的是，考虑到编程语言和自然语言之间的结构差异，现有的NLP算法对于代码表示是不合适的。为了提取适用的特征表示，需要整理现有方案和改进策略的缺陷[12]。</p><p>​        在本文中，我们从以下几个方面对源代码审查进行了详尽的概述：第二节简要介绍了经典的源代码分析(SCA)，包括典型的验证方法和进程流程。第三节说明了现有的机器学习SCA方法，如传统的机器学习方法和深度学习应用在源代码审查中。第四部分总结了整篇论文的一些结论，说明了存在的问题，并展示了一些未来的工作，并承认了本文的贡献者。</p><h1 id="II-经典的静态代码分析"><a href="#II-经典的静态代码分析" class="headerlink" title="II 经典的静态代码分析"></a>II 经典的静态代码分析</h1><p>​        静态代码分析（SCA）通常作为代码审查的一部分执行，并在安全开发生命周期（SDL）的实施阶段执行。 SCA的程序。 SCA通常是指通过使用数据流分析，污点分析，符号执行等技术的工具来试图发现“静态”（非运行）源代码中可能存在的漏洞。<br>​        假阳性和假阴性揭示了SCA的局限性。在分析与闭源组件或外部系统交互的应用程序时，可能会报告误报结果，因为如果没有源代码，则无法跟踪外部系统中的数据流，从而确保数据的完整性和安全性。静态代码分析工具的使用也可能由于工具不会报告漏洞导致漏报。如果在外部组件中发现新漏洞，或者分析工具不了解运行时环境以及是否已安全配置，则可能会发生这种情况。<br>​        以前的工作已经证明，经典SCA能够预测源代码漏洞，尽管有时会出现不可接受的误报和漏报。最近，人工智能，尤其是机器学习及其相关分支，对SCA的学术对话产生了重大影响，下一部分将对此进行研究。</p><p><img src="/2019/04/02/A-Survey-on-Source-Code-Review-Using-Machine-Learning/1.jpg" alt=""><br>图1.经典SCA的草图。从易受攻击的代码中提取的功能揭示了漏洞规则。模型构建有助于对程序进行建模。经典SCA探索数据流，符号执行，污点分析，模型检查和定理证明来审查源代码。审核结果需要通过认证和分类。最终，建立了漏洞收集。</p><h1 id="III-机器学习SCA"><a href="#III-机器学习SCA" class="headerlink" title="III 机器学习SCA"></a>III 机器学习SCA</h1><p>​        在过去十年中，ML在基于特征表示的智能代码审查中蓬勃发展。 ML任务可以分为传统的机器学习，深度学习和强化学习，如图2所示。传统的机器学习包括监督学习和无监督学习。对于监督学习，计算机将显示示例输入及其所需标签，目标是学习将输入映射到输出的一般规则或功能。然而，对于无监督学习，没有给学习算法赋予标签，使其自己在其输入中找到结构。无监督学习可以是特征学习过程。</p><p>​        深度学习使用多层非线性处理单元级联进行特征提取和转换[13]。每个连续层使用前一层的输出作为输入，以有监督和/或无监督的方式学习，学习对应于不同抽象级别的多个级别的表示，并利用某种形式的梯度下降通过反向传播进行训练[14] 。它们还可以包括在深度生成模型中逐层组织的潜在变量，例如Deep Belief Networks  和Deep Boltzmann Machines 中的节点。相比之下，强化学习似乎更加智能，计算机程序与必须执行某个目标的动态环境相互作用。该程序在奖励和惩罚方面提供反馈，因为它在问题空间中导航。这些输入来自在线或离线源代码存档。</p><p><img src="/2019/04/02/A-Survey-on-Source-Code-Review-Using-Machine-Learning/2.jpg" alt=""></p><p>图2.源代码在ML，DL和RL的审查项目中占主导地位。数据集和知识库管理ML和DL中静态分析的数据空间。虽然提取预处理和特征表示表面和潜在特征作为ML和DL训练的输入。 DL采用复杂的多层结构，如深度神经网络，与ML中的不同，利用简单的神经网络。 ML和DL都生成一个模型来预测它所属的输入源代码片。 RL提出了一些区别。源代码在预处理和特征表示中组装。结果输出到RL闭环，通过奖励和状态在环境行动的条件下实现目标。环境向知识库提供反馈，直到实现目标</p><h2 id="A-传统机器学习SCA"><a href="#A-传统机器学习SCA" class="headerlink" title="A.传统机器学习SCA"></a>A.传统机器学习SCA</h2><p>​        Internet上有各种源代码存档。这些档案通常由应用程序类别和各种编程语言组成。但是，手动组织源代码存储库并不是一件容易的事，因为它们会迅速增长到非常大的规模。用于归档源代码自动分类的机器学习方法被演示为11个应用主题和10种编程语言。对于局部分类，近年来来自Ibiblio和Sourceforge档案的C和C ++程序主导了研究。支持向量机（SVM）分类器在给定编程语言或特定类别的程序的示例上进行训练。源代码可以准确地自动分类为主题类别，并且可以被识别为特定的编程语言。群集假设和信息理论的基本假设被用来发现软件系统中语义连贯的主题[15]。生成主题的有用性通过人工判断凭经验验证。此外，一个案例研究表明，报告了在分析代码演变时所提出的方法的操作。与传统的主题建模技术相比，这种提出的方法产生了稳定，可解释和更具表现力的主题，而无需进行广泛的参数校准。仍然缺少在有限时间预算内进行OS规模计划评估的方法。 [3] <strong>VDiscovery</strong>，收集了轻量级的静态和动态功能，以预测测试用例是否可能包含ML上的软件漏洞。在静态级别，比较程序切片之间的相似性可能是个好主意。智能手机用户面临着一个安全困境：他们安装的许多应用程序都依赖于隐私敏感的数据，尽管它们可能来自可靠性难以判断的开发人员。研究人员已经使用越来越复杂的静态和动态分析工具解决了这个问题，以帮助评估应用程序如何使用私有用户数据[16]。<strong>SUSI</strong>提出一种新颖的机器学习指导方法，用于直接从任何Android API的代码中识别源和目的。给定一组手工注释的源和接收器，SUSI识别整个API中的其他源和接收器。为了提供更细粒度的信息，SUSI进一步对源和目的[17]进行了分类。输入验证不充分导致许多漏洞，因此省略或缺少检查可以找到发现安全漏洞的宝贵线索。 <strong>Chucky</strong>能够实时准确地识别丢失的校验，最终使我们能够发现其中两个项目中12个以前未知的漏洞[18]。由于算法密集型特性或对潜在大规模数据的应用，机器学习系统是独特的，因此值得特别考虑。进行实证研究以分析机器学习系统中的错误并报告错误类别与错误严重性之间的关系[19]。</p><h2 id="B-深度学习SCA"><a href="#B-深度学习SCA" class="headerlink" title="B. 深度学习SCA"></a>B. 深度学习SCA</h2><p>​        最近，深度学习极大地影响了SCA的审查。卷积神经网络（CNN）已经在处理各种NLP任务中获得了普及。特别是对于文本分类，深度学习模型取得了显着成果[1] [16] [18] [20]。所提出的模型使用字嵌入层，接着是具有多个滤波器的卷积层，最大池化层，最后是softmax层。采用非静态和随机初始化的嵌入层，因此从头开始训练载体。最常见的ML任务依赖于代表代码特征的手动特征设计。不幸的是，所有这些都在检索源代码的语义和句法解释方面遇到了挑战，这是构建准确预测模型的重要能力[1]。卷积网络能够进行恶意软件分类和分析。实现了由卷积和前馈神经构造组成的神经网络。该体系结构体现了一种分层特征提取方法，该方法将n-gram指令的卷积与从可移植可执行文件（PE）的头部派生的特征的简单矢量化相结合。评估结果表明，我们的方法优于基线方法，例如简单的前馈神经网络和支持向量机，因为它在精度和召回率方面达到了93％，即使在数据混淆的情况下也是如此[20]。</p><p>​        一种新兴的方法是将软件代码视为一种文本形式，并利用（NLP）技术自动提取特征。以前的工作使用BOW将源代码文件表示为与频率相关的代码令牌的集合。这些术语是用作其脆弱性预测模型的预测变量的特征。</p><p>​        经典NLP技术与深度学习结合使用被用于检测、分类非NLP应用和报告与人为约束语言（如编程语言及其编译对应语言）中发现的漏洞或不良编码实践相关的弱点[21]。在我们的结果中将NLP方法与信号处理方法进行比较和对比。它显示了用C，C ++和JAVA编写的开源软件的特定测试用例的有希望的结果。</p><p>​        源代码实际上是文本信息。机器学习中深度学习模型的最新进展为软件度量和BOW代表软件代码提供了强有力的替代方案。最广泛使用的深度学习模型之一是长期短期记忆（LSTM）[22]，这是一种特殊的递归神经网络，在学习文本和语音等顺序数据中的长期依赖性方面非常有效。 LSTM在许多应用中表现出突破性的性能，例如机器翻译，视频分析和速度识别[1]。一些研究人员提出了一种新颖的基于深度学习的方法来自动学习用于预测软件代码中的漏洞的功能，利用LSTM捕获源代码中的长的上下文关系，其中相关的代码元素分散得很远。建立了强大的深度长期短期记忆（LSTM）模型，以同步自动学习代码的语义和句法特征。同时，RNN编码器 - 解码器用于为给定的API相关自然语言查询生成API使用序列[23]。它可能涉及其他软件工程问题，如代码搜索和错误本地化。代码克隆检测也是软件维护和SCA的一个重要问题[24]。所提出的代码分析工具利用深度学习的优势，并自动将词汇层面挖掘的模式与句法层面挖掘的模式联系起来。</p><h1 id="IV-结论和未来工作"><a href="#IV-结论和未来工作" class="headerlink" title="IV 结论和未来工作"></a>IV 结论和未来工作</h1><p>本文代表了源代码审查中机器学习（ML）文献综述的研究成果。 ML和一些分支提出了一些新的想法来实现分类器，回归和代理来预测源代码漏洞，具有较低的误报和漏报。幸运的是，深度处理安全网络以随着数据量的增加自动调整和调整连接的能力将改善学习过程。特别是，这将允许我们自动化和使用网络专门从事某些领域。通过深入学习，安全系统可以通过尝试数十亿种组合并进行数百万次观察来自动学习。针对特定类别的问题，这是非常有希望的，但它不是一个灵丹妙药。仅仅因为一项技术使用深度学习并不意味着其他传统的AI和机器学习方法并不具有更高的价值或实用性。人工智能是一种多用途技术，我们可以在安全和其他行业中工作，学习，迭代和改进。不幸的是，没有找到通过强化学习来审查源代码的论文。主要原因是在审查过程中没有建立动态交互，但是，提出了将静态和动态方法结合起来测量源代码的有希望的方法。</p><p>最重要的是，漏洞数据规模不足仍然是一个挑战。跨文件，跨版本和跨项目需要占主导地位，因为对象大多不存在于训练集中。 ML，DL和RL的评论在源代码分析研究中一直走在前列。</p><h1 id="个人观点"><a href="#个人观点" class="headerlink" title="个人观点"></a>个人观点</h1><p>关于源代码漏洞发现总结的较少，所列举文献大多为关于机器学习和深度学习。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h1&gt;&lt;p&gt;源代码审查充分限制了软件系统的安全性。可伸缩性和精度对于代码审查工具的部署非常重要。但是，传
      
    
    </summary>
    
      <category term="论文" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/"/>
    
      <category term="fuzzing" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/fuzzing/"/>
    
      <category term="综述" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/fuzzing/%E7%BB%BC%E8%BF%B0/"/>
    
    
      <category term="2018年" scheme="http://yama0xff.com/tags/2018%E5%B9%B4/"/>
    
      <category term="fuzzing" scheme="http://yama0xff.com/tags/fuzzing/"/>
    
      <category term="综述" scheme="http://yama0xff.com/tags/%E7%BB%BC%E8%BF%B0/"/>
    
  </entry>
  
  <entry>
    <title>From automation to intelligence: Survey of research on vulnerability discovery techniques</title>
    <link href="http://yama0xff.com/2019/04/02/From-automation-to-intelligence-Survey-of-research-on-vulnerability-discovery-techniques/"/>
    <id>http://yama0xff.com/2019/04/02/From-automation-to-intelligence-Survey-of-research-on-vulnerability-discovery-techniques/</id>
    <published>2019-04-02T02:08:03.000Z</published>
    <updated>2019-04-02T03:15:25.137Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>近年来，随着软件规模和复杂度的日益增加，软件漏洞挖掘技术正逐渐向高度自动化和智能化演变，该文从传统漏洞挖掘技术和基于学习的智能化漏洞挖掘技术两方面深入调研和分析了相关的研究进展。首先，从静态和动态挖掘技术2方面详细介绍了传统漏洞挖掘技术的研究现状，涉及的技术包括模型检测、二进制比对、模糊测试、符号执行以及漏洞可利用性分析等，并分析了各项技术存在的问题，提出当前的研究难点是实现漏洞挖掘全自动化。然后，介绍了机器学习和深度学习技术在漏洞挖掘领域的应用，具体应用场景包括二进制函数识别、函数相似性检测、测试输入生成、路径约束求解等，并提出了其存在的机器学习算法不够健壮安全、算法选择依靠经验、数据样本不足、特征选择依赖专家知识等问题。最后，对未来研究工作进行了展望，提出应该围绕提高漏洞挖掘的精度和效率、提高自动化和智能化的程度这2方面展开工作。</p><table><thead><tr><th>relevant information</th><th></th></tr></thead><tbody><tr><td><em>作者</em></td><td>邹权臣，张涛，吴润浦, 马金鑫, 李美聪, 陈晨,侯长玉</td></tr><tr><td><em>单位</em></td><td>中国信息安全测评中心,空军工程大学 信息与导航学院,北京邮电大学 网络空间安全学院,北京中测安华科技有限公司</td></tr><tr><td><em>出处</em></td><td>清华大学学报</td></tr><tr><td><em>原文地址</em></td><td><a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#outline_anchor_17" target="_blank" rel="noopener">http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#outline_anchor_17</a></td></tr><tr><td><em>源码地址</em></td><td></td></tr><tr><td><em>发表时间</em></td><td>2018年</td></tr></tbody></table><h1 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h1><p>漏洞信息的不对称性已经成为导致网络战争中的实力对比悬殊的关键因素。从早年爆发的蠕虫王、冲击波、震荡波病毒，到近年来爆发的WannaCry病毒，都借助了软件或系统的安全漏洞进行传播。另外，高级的网络攻击(如APT攻击)甚至会基于多个漏洞交叉、组合使用，目的是绕过防火墙、杀毒软件、入侵检测系统等，摧毁隔离网的安全性，突破核心网络节点而进入内网，进行后续的渗透攻击(如窃取、修改、加密重要数据，摧毁核心设施等)。特别是未公开的0day漏洞常常被当成秘密的终极武器使用，有时候甚至能起到决定性的作用。</p><p>鉴于软件漏洞在网络攻防中的重要性，各大软件厂商及高校、科研院所的研究人员对漏洞挖掘技术展开了大量的研究。当前，常用的漏洞挖掘技术包括模型检测、模糊测试、符号执行、二进制比对等，这些传统的漏洞挖掘技术在理论研究上已经比较成熟，并已从各类软件中挖掘出大量漏洞。其中大部分的技术如模糊测试、符号执行等都已基本实现自动化，可以在不需要或较少的人工干预的前提下，针对被测试程序和输入数据的不同特点，借助各种程序动、静态分析技术，寻找分析深度和分析效率之间的平衡点，缓解代码覆盖率低、扩展性差等问题；目的是提高漏洞挖掘的效率，实现在更短的时间内发现更多或更深层次的漏洞。</p><p>机器学习、深度学习的研究进展带动了其在软件漏洞挖掘领域的应用，目前已经开展了一些探索性的工作，如二进制函数相似性识别、函数相似性检测、测试输入生成、路径约束求解等，这些应用为解决传统漏洞挖掘技术的瓶颈问题提供了新的思路，也使得软件漏洞挖掘逐渐变得智能化。随着机器学习、深度学习研究的爆炸式发展，以及这方面研究积累的数据集的增多，将可能成为软件漏洞挖掘技术发展的关键点之一。</p><p>本文以近年来软件漏洞挖掘技术所呈现出的自动化和智能化的趋势作为切入点，介绍了传统漏洞挖掘技术和基于学习的智能化漏洞挖掘技术的研究进展。首先，本文从静态和动态漏洞挖掘两方面对传统的漏洞挖掘技术进行了分类分析，指出了各自的优势和面临的问题；并介绍了漏洞可利用性分析以及自动化漏洞挖掘(如CGC大赛)的研究进展，指出漏洞挖掘的全自动化是当前研究的难点问题。然后，对基于学习的智能化软件漏洞挖掘技术进行了分类，并深入分析了二进制函数识别、函数相似性检测等不同应用场景的研究工作，归纳总结了其面临的机器学习算法不够健壮安全、算法选择依靠经验、数据样本不足、特征选择依赖专家知识等四大问题。最后进行了总结和展望，指出未来应在提高漏洞挖掘的精度和效率，以及自动化和智能化方面展开研究。</p><h1 id="2-传统漏洞挖掘技术"><a href="#2-传统漏洞挖掘技术" class="headerlink" title="2.传统漏洞挖掘技术"></a>2.传统漏洞挖掘技术</h1><p>传统的漏洞挖掘技术主要可分为静态和动态漏洞挖掘技术，漏洞可利用性分析也已经成为漏洞挖掘的重要环节，如[图 1]所示</p><p><img src="/2019/04/02/From-automation-to-intelligence-Survey-of-research-on-vulnerability-discovery-techniques/1.jpg" alt=""></p><h2 id="2-1-静态漏洞挖掘"><a href="#2-1-静态漏洞挖掘" class="headerlink" title="2.1 静态漏洞挖掘"></a>2.1 静态漏洞挖掘</h2><p>静态漏洞挖掘是指在不运行目标程序的前提下分析目标程序(源代码或二进制)的词法、语法和语义等，并结合程序的数据流、控制流信息，通过类型推导、安全规则检查、模型检测等技术挖掘程序中的漏洞。静态漏洞挖掘是常用的软件测试技术，在软件测试中占有非常重要的地位。具有代表性的静态漏洞挖掘工具有面向C/C++源码的Cppcheck[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b1" target="_blank" rel="noopener">1</a>]、FlawFinder[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b2" target="_blank" rel="noopener">2</a>], 面向PHP源码的RIPS[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b3" target="_blank" rel="noopener">3</a>], 面向JAVA源码的FindBugs[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b4" target="_blank" rel="noopener">4</a>]，以及能支持多种类型目标对象的著名商业化漏洞检测工具VeraCode[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b5" target="_blank" rel="noopener">5</a>]、Fortify[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b6" target="_blank" rel="noopener">6</a>]、Coverity[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b7" target="_blank" rel="noopener">7</a>]、Checkmarx[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b8" target="_blank" rel="noopener">8</a>]等。另外，LLVM[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b9" target="_blank" rel="noopener">9</a>]、Clang[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b10" target="_blank" rel="noopener">10</a>]等编译器也提供了大量的静态检测功能，能在编译阶段实现对源代码的安全性检查。</p><p>针对目标程序的不同形式，采用的静态分析技术也不尽相同。本节将按源代码和二进制2种目标程序分别介绍静态漏洞挖掘技术的研究现状。</p><p>面向源代码的漏洞挖掘主要采用基于中间表示的分析和基于逻辑推理的分析技术[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b11" target="_blank" rel="noopener">11</a>]。其中，基于中间表示的分析技术主要包括数据流分析、控制流分析、污点分析、符号执行等。Pixy[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b12" target="_blank" rel="noopener">12</a>]采用了取值分析、污点分析、指针别名分析等静态分析技术实现对PHP源码中的SQL注入和跨站脚本等漏洞的检测。Prefix[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b13" target="_blank" rel="noopener">13</a>]采用了静态符号执行技术模拟执行C/C++源码程序，并采用约束求解对程序中的部分路径进行检测。Melange[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b14" target="_blank" rel="noopener">14</a>]采用数据流分析的框架，通过对程序进行数据流、控制流等复杂分析检测安全相关的漏洞，并支持对大型C/C++源码程序的分析。K-Miner[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b15" target="_blank" rel="noopener">15</a>]利用内核代码中高度标准化的接口实现了可扩展性良好的指针分析以及全局的上下文敏感的分析技术，支持对空指针引用、指针释放后重引用(use-after-free, UAF)、指针重释放(double free)、双重检查锁定(double-checked lock)等内存崩溃漏洞的检测。基于逻辑推理的分析技术主要是指模型检测，如MOPS[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b16" target="_blank" rel="noopener">16</a>]、BLAST[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b17" target="_blank" rel="noopener">17</a>]、SLAM[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b18" target="_blank" rel="noopener">18</a>]是典型的面向C程序的模型检测工具，其基本思路是将程序结构抽象为状态机(布尔程序)，然后基于归纳的安全属性对状态机进行遍历，检测其中存在的漏洞。</p><p>面向二进制程序的静态漏洞的挖掘技术由于缺少源代码中的结构化信息，面临着值集分析(vaule-set analysis，VSA)[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b19" target="_blank" rel="noopener">19</a>]与控制流恢复[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b20" target="_blank" rel="noopener">20</a>-<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b25" target="_blank" rel="noopener">25</a>]不精确的问题。当前，二进制静态漏洞挖掘技术主要包括基于模式匹配和基于补丁比对的技术。其中，在基于模式匹配的漏洞挖掘技术方面，GUEB[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b26" target="_blank" rel="noopener">26</a>]提出了二进制程序中UAF漏洞模式，并基于此模式挖掘出了ProFTPD程序中的漏洞。具体而言，首先抽象出二进制函数中的内存模型，然后采用VSA分析技术追踪堆分配和释放指令相关的操作变量，并基于此建立UAF模式。LoongChecker[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b27" target="_blank" rel="noopener">27</a>]使用了称为半仿真的二进制静态漏洞挖掘技术。通过VSA分析和数据依赖分析(data dependence analysis，DDA)技术实现对变量地址的追踪和数据流依赖分析，并采用污点分析技术检测潜在的漏洞。Saluki[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b28" target="_blank" rel="noopener">28</a>]使用了路径敏感和上下文敏感的数据依赖分析，并采用完备的逻辑系统推理检测程序中的漏洞。在基于补丁比对的漏洞挖掘技术方面，PVDF[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b29" target="_blank" rel="noopener">29</a>]以二进制漏洞程序(带有权限提升漏洞)和补丁作为输入，从比对中提取多维属性描述的漏洞语义信息，并应用于后续的模糊测试中。BinHunt[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b30" target="_blank" rel="noopener">30</a>]通过对二进制程序和带补丁的二进制程序间的比对提取漏洞相关的语义信息。具体而言，就是把二进制程序翻译成中间表示，并在此基础上构建控制流图，基于控制流图对比程序间的差异，提取相关的约束，然后采用符号执行技术进行验证，以此找出补丁对应的漏洞。</p><p>静态漏洞挖掘技术直接对目标程序进行分析，不需要构造程序的执行环境，能提取较为完整的控制流等信息，可能发现动态漏洞挖掘技术难以发现的漏洞。但是，一方面，由于静态漏洞挖掘技术往往依赖于人工构造的漏洞模式，对先验知识依赖性较大；另一方面，因为无法获得程序实际动态运行过程中的上下文信息，静态漏洞挖掘技术具有精度低、误报率高的缺陷。</p><h2 id="2-2-动态漏洞挖掘"><a href="#2-2-动态漏洞挖掘" class="headerlink" title="2.2 动态漏洞挖掘"></a>2.2 动态漏洞挖掘</h2><p>动态漏洞挖掘技术是指在实际执行程序的基础上采用的分析技术，常用的动态漏洞挖掘技术包括模糊测试、符号执行等。</p><h3 id="2-2-1-模糊测试"><a href="#2-2-1-模糊测试" class="headerlink" title="2.2.1 模糊测试"></a>2.2.1 模糊测试</h3><p>模糊测试(fuzzing)是一种自动化或者半自动化的软件测试技术，通过构造随机的、非预期的畸形数据作为程序的输入，并监控程序执行过程中可能产生的异常，之后将这些异常作为分析的起点，确定漏洞的可利用性。模糊测试技术可扩展性好，能对大型商业软件进行测试，是当前最有效的用于挖掘通用程序漏洞的分析技术，已经被广泛用于如微软、谷歌和Adobe等主流软件公司的软件产品测试和安全审计，也是当前安全公司和研究人员用于挖掘漏洞的主要方法之一。</p><p>按程序内部结构分析的量级轻重程度分，模糊测试技术主要可以分为白盒、黑盒、灰盒模糊测试。其中，白盒模糊测试是在对被测试程程序内部结构、逻辑进行系统性分析的基础上进行测试；黑盒模糊测试把程序当成黑盒处理，不对程序内部进行分析；灰盒模糊测试介于黑盒和白盒模糊测试之间，在对程序进行轻量级分析的基础上进行测试。按样本生成方式划分，模糊测试的测试输入可分为基于变异和基于生成2种方式。其中，基于变异的模糊测试在修改已知测试输入的基础上生成新的测试用例，而基于生成的模糊测试则是直接在已知输入样本格式的基础上生成新的测试输入。</p><p>根据不同的研究侧重点，本文分别介绍基于变异的模糊测试、基于生成的模糊测试和其他优化策略。</p><h4 id="1-基于变异的模糊测试。"><a href="#1-基于变异的模糊测试。" class="headerlink" title="1) 基于变异的模糊测试。"></a>1) 基于变异的模糊测试。</h4><p>在基于变异的模糊测试方面，研究人员借助程序执行环境信息和程序分析技术，有导向性地辅助、引导模糊测试的变异，具有代表性的工作有AFL[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b31" target="_blank" rel="noopener">31</a>]、VUzzer[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b32" target="_blank" rel="noopener">32</a>]、Honggfuzz[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b33" target="_blank" rel="noopener">33</a>]、libFuzzer[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b34" target="_blank" rel="noopener">34</a>]、Steelix[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b35" target="_blank" rel="noopener">35</a>]、T-Fuzz[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b36" target="_blank" rel="noopener">36</a>]、AFLFast[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b37" target="_blank" rel="noopener">37</a>]、AFLGo[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b38" target="_blank" rel="noopener">38</a>]、Driller[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b39" target="_blank" rel="noopener">39</a>]等。</p><ul><li><strong>a) 代码覆盖率制导</strong></li></ul><p>AFL[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b31" target="_blank" rel="noopener">31</a>]使用进化算法(evolutionary algorithms)生成测试输入，在正常输入的基础上，通过简单的反馈回路的方式评估测试输入的质量。AFL会保留任何能触发新路径的测试输入，并对其进行变异及检查能否触发崩溃。AFL已经在Mozilla Firefox、FFmpeg、OpenSSL等软件中发现了大量的漏洞。但AFL也存在较大的缺陷：首先，变异的位置以及变异的方式是盲目的，缺少更进一步的筛选和变异策略，依赖这种方式很难发现深层次的漏洞；其次，通过哈希函数检测分支覆盖筛选种子的方式具有较高的误报率，其哈希位图(bitmap)只有64 kB大小，导致普遍存在哈希碰撞的情况，进而导致其分支覆盖统计存在漏报，进而影响种子筛选，间接影响了代码覆盖率的增长。CollFuzz[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b40" target="_blank" rel="noopener">40</a>]采用静态控制流图信息作为辅助，并设计了能避免哈希碰撞的基本块ID分配策略，从而实现比AFL更精确的分支覆盖检测。</p><ul><li><strong>b) 污点分析辅助</strong></li></ul><p>BuzzFuzz[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b41" target="_blank" rel="noopener">41</a>]使用动态污点分析技术自动定位影响程序脆弱点的测试输入中的字段，然后保留其他语法部分内容，只对这些字段进行变异。这样既能通过语法检查，也能有针对性地进行变异，提高漏洞挖掘的效率。TaintScope[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b42" target="_blank" rel="noopener">42</a>]使用污点分析技术推断程序中与校验和处理相关的代码，以此帮助模糊测试工具绕过校验和检查。</p><ul><li><strong>c) 符号执行制导</strong></li></ul><p>Driller[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b39" target="_blank" rel="noopener">39</a>]采用模糊测试和符号执行交替探索程序执行路径，解决模糊测试陷入代码覆盖率增长慢的情况，这样能引导模糊测试探索到程序更深层次的节点，也能直接避免符号执行可能带来的路径爆炸问题。但文[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b39" target="_blank" rel="noopener">39</a>]和[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b43" target="_blank" rel="noopener">43</a>]等的实验结果表明，使用符号执行对模糊测试中部分路径约束求解时，仍然有很大一部分路径出现求解失败的情况(文[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b39" target="_blank" rel="noopener">39</a>]实验中有41个测试程序陷入了较浅路径，使用符号执行对其求解时只有13个程序能够生成新的测试输入)。因此，基于符号执行增强的模糊测试技术仍然会受限于符号执行中的约束求解问题，符号执行的引入可能会弱化模糊测试本身的可扩展性。</p><ul><li><strong>d) 控制流和数据流信息制导</strong></li></ul><p>VUzzer[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b32" target="_blank" rel="noopener">32</a>]在“轻量级”的动、静态分析基础上提取了程序的控制流和数据流信息引导变异。具体而言，VUzzer先在静态控制流分析基础上计算基本块的权重，然后在动态执行时筛选权重更高即路径更深的执行路径对应的测试输入为种子文件，并用动态污点分析定位变异点。相比AFL、Driller，VUzzer有更好的种子筛选、路径探索策略以及污染点定位、变异策略，能定向引导探索更深的执行路径，并定点变异。在DARPA CGC和LAVA测试集以及部分常用应用程序上，VUzzer都取得了更好的效果(用更少的测试输入挖掘出了更多的漏洞)。Steelix[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b35" target="_blank" rel="noopener">35</a>]采用了轻量级的静态分析和二进制插桩技术提取代码覆盖率信息和魔术字节(magic byte)比较信息等作为程序状态信息引导变异。这种方式能在较小的开销下定位魔术字节在测试输入中的位置，进而辅助模糊测试工具更高效地生成能通过魔术字节检验的测试输入。</p><h4 id="2-基于生成的模糊测试。"><a href="#2-基于生成的模糊测试。" class="headerlink" title="2) 基于生成的模糊测试。"></a>2) 基于生成的模糊测试。</h4><p>基于生成的模糊测试主要基于模型或者语法生成能满足程序语法和语义检查的测试输入，常用于高度结构化的测试输入生成。</p><ul><li><strong>a) 基于模型的模糊测试</strong></li></ul><p>Peach[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b44" target="_blank" rel="noopener">44</a>]、Spike[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b45" target="_blank" rel="noopener">45</a>]是典型的基于模型的模糊测试工具(Peach也具有基于变异进行模糊测试的功能)，通过对输入格式定制编写数据模型(data model)和状态模型(state model)的方式指定输入数据的类型和依赖关系, 并结合变异策略生成测试输入。其中Peach通过编写配置文件实现对样本格式的约束，而Spike需要利用提供的编程接口来对样本格式进行约束。Pham等[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b46" target="_blank" rel="noopener">46</a>]结合输入模型和符号执行技术生成测试输入，使用符号执行鉴别输入格式约束能有效保证输入的合法性。</p><ul><li><strong>b) 基于语法的模糊测试</strong></li></ul><p>CSmith[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b47" target="_blank" rel="noopener">47</a>]根据C语言语法生成C程序源码，实现对C编译器的模糊测试。在C源码生成方面，CSmith随机选取符合生成规则和语法规则的C程序，这种方法能避免因未定义和未声明而导致编译报错的情况出现。LangFuzz[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b48" target="_blank" rel="noopener">48</a>]基于语法学习测试集中的代码片段，并进行片段重组生成新的测试输入。在测试输入集选择上，LangFuzz假设基于问题测试集重组生成的测试输入比随机收集的测试输入更有可能触发程序缺陷。IFuzzer[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b49" target="_blank" rel="noopener">49</a>]使用上下文无关的语言语法作为输入，并使用语法生成解析树，然后从测试集中抽取代码片段，并使用遗传进化算法对代码片段重组生成新的测试输入。Jsfunfuzz[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b50" target="_blank" rel="noopener">50</a>]使用了历史漏洞知识和硬编码规则生成测试输入，以Mozilla浏览器中的Javascript解释器为测试目标，发现了1 800多个缺陷。Dewey等[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b51" target="_blank" rel="noopener">51</a>]使用了称为约束逻辑编程(constraint logic programming, CLP)的技术生成测试输入。通过指定句法特征和语义行为，CLP能生成满足语法和语义合法性的测试输入。</p><h4 id="3-其他优化策略。"><a href="#3-其他优化策略。" class="headerlink" title="3) 其他优化策略。"></a>3) 其他优化策略。</h4><p>除了上述进展外，还有一些重要研究侧重于种子筛选策略优化[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b37" target="_blank" rel="noopener">37</a>-<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b38" target="_blank" rel="noopener">38</a>, <a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b52" target="_blank" rel="noopener">52</a>-<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b55" target="_blank" rel="noopener">55</a>]和调度策略优化[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b37" target="_blank" rel="noopener">37</a>-<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b38" target="_blank" rel="noopener">38</a>]。Rebert等[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b53" target="_blank" rel="noopener">53</a>]把种子筛选问题转化成整数线性规划问题，并以挖掘更多漏洞为目标提出了多种种子筛选策略。AFLFast[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b37" target="_blank" rel="noopener">37</a>]采用了把模糊测试问题建模为Markov模型，并采用特定的策略引导AFL优先选择低频路径和变异频率较低的文件作为种子文件进行变异，以此在相同的测试时间内探索更多的路径。AFLGo[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b38" target="_blank" rel="noopener">38</a>]采用了模拟退火(simulated annealing，SA)算法对能逼近特定目标位置的测试输入分配更高的能量，并优先选取高能量种子文件进行变异。AFLGo的实验结果表明，这种导向型灰盒模糊测试(directed greybox fuzzing，DFG)比符号执行引导的白盒模糊测试和非导向型模糊测试具有更好的性能、更高的代码覆盖率并可挖掘出更多的漏洞。</p><p>总体而言，模糊测试是当前挖掘漏洞最有效的方法，比其他漏洞挖掘技术更能应对复杂的程序，具有可扩展性好的优势。但在大规模漏洞分析测试中，模糊测试方法仍然依赖于种子输入的质量，依赖于对测试输入对象格式的深度理解和定制，存在测试冗余、测试攻击面模糊、测试路径盲目性较高等问题。另外，目前模糊测试也存在整体测试时间长、生成单个测试用例漏洞触发能力弱的问题。</p><h3 id="2-2-2-符号执行"><a href="#2-2-2-符号执行" class="headerlink" title="2.2.2 符号执行"></a>2.2.2 符号执行</h3><p>符号执行于20世纪70年代被提出[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b56" target="_blank" rel="noopener">56</a>-<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b59" target="_blank" rel="noopener">59</a>]，是一种能够系统性探索程序执行路径的程序分析技术，通过对程序执行过程中的被污染的分支条件及其相关变量的收集和翻译，生成路径约束条件，然后使用可满足模理论(SMT)求解器进行求解, 判断路径的可达性以及生成相应的测试输入。通过这种方式产生的测试输入与执行路径之间具有一对一的关系，能够避免冗余测试输入的产生，进而能有效解决模糊测试冗余测试用例过多导致的代码覆盖率增长慢的问题。</p><p>符号执行技术应用已经被学术和工业界应用在漏洞挖掘领域。自从符号执行特别是动态符号执行技术被提出以来，已经有很多相关的工具被应用到实际的软件测试当中，如SAGE[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b60" target="_blank" rel="noopener">60</a>]、S2E[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b61" target="_blank" rel="noopener">61</a>]、Mayhem[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b62" target="_blank" rel="noopener">62</a>]、KLEE[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b63" target="_blank" rel="noopener">63</a>]、Triton[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b64" target="_blank" rel="noopener">64</a>]、angr[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b65" target="_blank" rel="noopener">65</a>-<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b66" target="_blank" rel="noopener">66</a>]等。其中SAGE已经被应用到了微软内部的日常开发安全测试中，每天有上百台机器同时在运行此工具，并发现了Windows 7系统中三分之一的漏洞[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b60" target="_blank" rel="noopener">60</a>]。MergePoint[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b67" target="_blank" rel="noopener">67</a>]已经在Debian系统下发现上百个可利用漏洞。</p><p>虽然符号执行相比其他程序测试和分析技术有诸多的优势，但就当前的形势而言，要大规模应用到工业领域仍然还有很多问题需要解决。符号执行概念提出至今已有40多年，而现代符号执行技术特别是动态符号执行技术的提出也有10多年之久，但至今符号执行仍然难以在主流的软件测试和漏洞挖掘中占据主导地位，归因于以下尚待解决的难题。</p><h4 id="1-路径爆炸-path-explosion-问题。"><a href="#1-路径爆炸-path-explosion-问题。" class="headerlink" title="1) 路径爆炸(path explosion)问题。"></a>1) 路径爆炸(path explosion)问题。</h4><p>路径爆炸又称为状态爆炸(state explosion)，是指在程序运行过程中路径数随着分支条件的增多而出现指数级增长的情况。由于路径爆炸问题的存在，在大型复杂的程序中，符号执行容易出现代码覆盖率增长慢的问题，很难在合理有限的时间内遍历程序的所有执行路径。为了缓解这一问题，研究人员采用了具有制导性的启发式搜索以及状态空间简化等操作减少对冗余状态的探索。</p><p>启发式搜索(search heuristics)是一种以特定目标优先的路径搜索策略。符号执行过程中对路径的探索可以看成是对符号执行树的探索，在执行树中，从根节点到叶子节点的一条路径代表程序实际执行中的一条路径，而其中的分支节点则表示程序实际执行中的分支条件。大部分启发式技术都专注于避免因陷入某部分相似路径而导致代码覆盖率低增长的情况，以期获得更高的代码和路径覆盖。KLEE[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b63" target="_blank" rel="noopener">63</a>]中提出结合随机路径选择(random path selection)和覆盖优化搜索(coverage-optimized search)的混合搜索算法，2种路径选择方法交叉使用探索执行路径既能达到高代码覆盖率的目的，又能防止某种算法陷入困境导致路径探索无法进行。Ma等[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b68" target="_blank" rel="noopener">68</a>]提出了以指定行代码可达性(line reachability)为目标的搜索策略。以程序中某行或多行代码为目标，找出能够驱动程序执行这些代码的实际输入问题称为代码行可达性问题。Godefroid等[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b60" target="_blank" rel="noopener">60</a>]提出了代搜索(generational search)算法，在每一代新生成的路径约束中，对所有分支条件取反，然后能选择覆盖新代码块最多的测试输入作为新的种子输入。</p><p>状态空间简化通过相似路径合并、冗余路径删减的方式达到减少路径探测的目的。除了启发式探索程序执行路径之外，研究人员还提出了利用程序分析和软件验证等技术减少精简路径的措施来缓解路径爆炸问题。Godefroid等[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b69" target="_blank" rel="noopener">69</a>]采用了函数摘要的方式，对重用的函数提取约束组合(摘要)，实现对函数路径的组合执行，避免了多次重复符号执行带来的开销。Ramos等[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b70" target="_blank" rel="noopener">70</a>]提出的限定约束的符号执行(under-constrainted symbolic execution)采用了直接面向独立函数的符号执行技术，此技术限定了符号执行的范围，用精确度换取可扩展性的方式来提升符号执行的性能。Veritesting[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b67" target="_blank" rel="noopener">67</a>]采用了静态符号执行技术增强动态符号执行技术，实现路径合并和冗余路径删减。Boonstoppel等[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b71" target="_blank" rel="noopener">71</a>]提出了RWSet，从状态变量的相似性鉴别冗余性，如果当前状态的变量跟之前的路径变量一样，则会停止对当前状态的探索。</p><h4 id="2-约束求解问题。"><a href="#2-约束求解问题。" class="headerlink" title="2) 约束求解问题。"></a>2) 约束求解问题。</h4><p>约束求解问题是动态符号执行遇到的另一个瓶颈问题。在动态符号执行中，对路径约束条件可达性的判定以及相应测试输入生成都需要频繁地调用SMT求解器进行求解；而约束求解本身又是一个NP完全(NP-complete)问题，在最差的情况下求解NP完全问题的复杂度为指数级。频繁调用加上高的求解难度直接导致约束求解消耗了符号执行系统中的大部分资源。</p><p>当前约束求解问题可以归结为求解能力和求解效率问题。求解能力问题是指当前求解器对复杂约束条件处理能力的不足。例如对于浮点数运算、非线性运算等一些复杂运算的约束，求解器都不能很好地处理。而求解效率问题是指对于含有大量的约束条件的路径约束，求解器的性能会随着约束条件数量的增长而逐渐下降。这使得符号执行对大型程序进行分析时整体性能下降，从而影响其可扩展性。</p><p>针对约束求解的两大问题，研究人员提出了很多约束求解性能优化措施，主要可分为内部优化和外部优化。求解器内部优化是指通过优化求解器本身对约束条件处理能力和效率来提高符号执行的性能，虽然近年来这方面的研究已经取得了比较大的突破[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b72" target="_blank" rel="noopener">72</a>-<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b76" target="_blank" rel="noopener">76</a>]，但仍然严重依赖于可满足模理论以及NP完全问题的研究进展。求解器外部优化主要是指在调用约束求解器对路径约束求解之前的优化，是通过减少甚至避免符号查询的工作来增加符号执行性能的措施。例如，CUTE[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b77" target="_blank" rel="noopener">77</a>]和KLEE[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b63" target="_blank" rel="noopener">63</a>]采用了如表达式重写、符号值的实际替换、不相关约束的删除以及约束缓存等一系列措施，对路径约束进行精简和结果重用。而近年来在这方面的研究又有了不小的突破，包括Green[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b78" target="_blank" rel="noopener">78</a>]、Recal[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b79" target="_blank" rel="noopener">79</a>]、GeenTrie[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b80" target="_blank" rel="noopener">80</a>]、Memoise[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b81" target="_blank" rel="noopener">81</a>]等，这些工具的提出主要侧重于解决优化符号执行结果切分、标准化命名、约束式逻辑转化、求解结果的缓存、搜索和重用的效率问题。有关这些工具的实验结果表明：路径约束的精简能减轻约束求解的负担，而约束求解结果的缓存和重复使用能在同一程序的不同路径以及不同程序的不同路径间的约束求解问题上极大地减少对求解器的调用。</p><h4 id="3-其他问题。"><a href="#3-其他问题。" class="headerlink" title="3) 其他问题。"></a>3) 其他问题。</h4><p>除了上述2个问题之外，符号执行还面临着内存建模[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b62" target="_blank" rel="noopener">62</a>, <a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b65" target="_blank" rel="noopener">65</a>-<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b66" target="_blank" rel="noopener">66</a>]、环境交互[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b61" target="_blank" rel="noopener">61</a>, <a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b63" target="_blank" rel="noopener">63</a>, <a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b82" target="_blank" rel="noopener">82</a>-<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b83" target="_blank" rel="noopener">83</a>]、并行计算[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b67" target="_blank" rel="noopener">67</a>, <a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b84" target="_blank" rel="noopener">84</a>]等问题。</p><p>总体而言，基于符号执行的漏洞挖掘技术依赖于约束求解器的求解能力和效率，并受限于程序状态爆炸问题。另外，它在主动漏洞挖掘方面还依赖于在对程序进行分析的基础上构造预置条件(漏洞约束)。符号执行应用于大型程序是一个多种性能优化措施并行且不断地对性能调优的过程，虽然研究人员提出了一系列性能优化措施来改善符号执行的可扩展性，但当前业界和学术界普遍认为，单独使用符号执行技术对大型程序进行漏洞挖掘仍然比较困难。</p><h2 id="2-3-漏洞可利用性分析"><a href="#2-3-漏洞可利用性分析" class="headerlink" title="2.3 漏洞可利用性分析"></a>2.3 漏洞可利用性分析</h2><p>在漏洞可利用性判定方面，现有的一些工具如!exploitable[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b85" target="_blank" rel="noopener">85</a>]、gdb-exploitable[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b86" target="_blank" rel="noopener">86</a>]、ASan[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b87" target="_blank" rel="noopener">87</a>]等，已经可以对漏洞挖掘过程中的异常或崩溃的可利用性进行初步分类。例如，!exploitable对崩溃按可利用(exploitable)、高可利用(probably exploitable)、不可利用(probably not exploitable)、未知(unknown)进行评级划分，并提供了哈希去重功能。但上述工具具有误报率高的缺陷，实际验证的时候仍然需要具有丰富漏洞挖掘和分析经验的专家进行手工逆向分析、调试进行审核确认，并编写利用漏洞的验证程序。在崩溃样本量较大时，这种方式低效而且对分析人员具有较高要求。</p><p>在自动化漏洞利用生成方面，APEG [<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b88" target="_blank" rel="noopener">88</a>]使用了基于补丁对比的漏洞利用生成技术，该技术基于补丁定位漏洞位置，并采用切分技术(slicing technique)生成从输入源至漏洞点的路径约束，但APEG只适用于单检查点修补的补丁。Heelan等[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b89" target="_blank" rel="noopener">89</a>]提出了自动化提取控制流劫持的漏洞利用技术，但该技术只在提供崩溃输入和已知漏洞(如栈溢出覆盖EIP指针)的前提下适用。AGE[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b83" target="_blank" rel="noopener">83</a>]、Mayhem[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b90" target="_blank" rel="noopener">90</a>]采用预置条件的符号执行(pre-conditioned symbolic execution)技术寻找可利用的漏洞路径，并自动生成利用代码。但该技术只支持对栈溢出、格式化字符串等部分漏洞的检测；另外，其自动化生成的漏洞利用程序不支持绕过编译器或OS对抗机制如ASLR(address space layout randomization)、DEP(data execution prevention)、CFI(control-flow integrity)等。FlowStitch[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b91" target="_blank" rel="noopener">91</a>]采用了称为数据流缝合(data-flow stitching)的面向数据流的自动化漏洞利用生成技术，该技术在不改变程序控制流的情况下，利用已知的内存错误修改数据流中关键变量的方式构建漏洞利用程序。FlowStitch从已知漏洞程序中发现了多个未知的漏洞利用方式，自动生成的所有利用程序都能通过CFI和DEP, 并有部分能绕过ASLR, 进而实现信息泄露或权限提升。但该方案仍然依赖于已知的内存错误和相应的测试输入。</p><p>总体而言，漏洞可利用性判定、漏洞利用程序生成是制约实现漏洞挖掘自动化的主要瓶颈之一。</p><h2 id="2-4-自动化漏洞挖掘"><a href="#2-4-自动化漏洞挖掘" class="headerlink" title="2.4 自动化漏洞挖掘"></a>2.4 自动化漏洞挖掘</h2><p>2016年8月，美国国防部高等研究计划署(DARPA)举办了网络超级挑战赛(cyber grand challenge，CGC)大赛的决赛。参赛团队研发的网络推理系统(cyber reasoning system，CRS)具备自动化挖掘漏洞、自动部署补丁和进行系统防御的能力，可以快速有效地应对新的攻击，降低从攻击出现到防御生效之间的时间差，实现网络安全攻防系统的全自动化。CGC大赛提供了一个自动化的攻防比赛平台，所设置的科学的评测体系可以比较全面地评估CRS系统的自动化网络推理能力，也为以后的自动化、智能化网络攻防研究指明了方向。此外，大赛提供的赛题还成为后续研究的测试集，用于评估平台、工具的漏洞挖掘能力和性能，在关于VUzzer[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b32" target="_blank" rel="noopener">32</a>]、Steelix[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b35" target="_blank" rel="noopener">35</a>]、Driller[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b40" target="_blank" rel="noopener">40</a>]等的文献中都被采用。</p><p>但CGC大赛仍然有比较大的局限性。首先，比赛环境与真实环境有差别。为了简化比赛环境，增加可控性，为比赛定制开发的DECREE(DARPA experimental cybersecurity research evaluation environment)系统只提供了7个系统调用；其次，CRS系统漏洞挖掘能力有限，只能挖掘一些简单程序的低级漏洞，对于浏览器等比较复杂的大型程序还不能很好地分析和处理；最后，自动化、智能化能力有限，在大赛中各参赛队伍使用的仍然是传统的模糊测试、符号执行等技术，并结合预设的漏洞模式、攻击模式进行部署，没有使用机器学习、深度学习技术，缺乏自我学习的能力。CGC大赛离实现高度自动化甚至是智能化漏洞挖掘还有比较大的差距。</p><p>综上所述，模型检测、二进制比对、模糊测试、符号执行等传统技术是当前漏洞挖掘的主要手段，漏洞可利用性分析仍然依赖人工参与，以CGC大赛为代表的自动化漏洞挖掘研究离现实应用有比较大的差距，实现漏洞挖掘全自动化是当前研究的难点问题。</p><h1 id="3-基于学习的智能化漏洞挖掘技术"><a href="#3-基于学习的智能化漏洞挖掘技术" class="headerlink" title="3 基于学习的智能化漏洞挖掘技术"></a>3 基于学习的智能化漏洞挖掘技术</h1><p>机器学习、深度学习[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b92" target="_blank" rel="noopener">92</a>]已经广泛应用于图像识别、语音识别、自然语言处理、医学自动诊断、搜索引擎广告推送等众多的领域，并取得了大量突破性进展。在网络安全领域，也已经应用于恶意软件检测、垃圾邮件和网络钓鱼分类、账户异常检测和日志分析等场景。</p><p>受益于上述的研究进展，研究人员在近年来也开始采用机器学习技术缓解软件漏洞挖掘领域的一些瓶颈问题。通过采用现有的机器学习、深度学习等技术，帮助相应的漏洞挖掘工具、系统在海量的漏洞相关的数据中提取经验和知识，然后根据训练生成的模型对新的样本进行分类、预测，提高对软件漏洞挖掘的精度和效率。</p><h2 id="3-1-应用场景"><a href="#3-1-应用场景" class="headerlink" title="3.1 应用场景"></a>3.1 应用场景</h2><p>近年来已经有智能化漏洞挖掘技术研究基于机器学习、深度学习技术展开，如<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#Table1" target="_blank" rel="noopener">表 1</a>所示。从应用场景看，涉及了二进制程序函数识别、函数相似性检测、测试输入生成、测试输入筛选、路径约束求解等领域；从使用的机器学习算法看，这些工作中分别采用了逻辑回归、随机森林、长短时记忆网络(LSTM)、强化学习等多种机器学习、深度学习的算法；从发表年份看，这方面的研究成果从2014年开始发表在信息安全顶级会议上，自2017年以来其数量逐渐上升，并已经成为当前信息安全研究领域的热点。</p><p><img src="/2019/04/02/From-automation-to-intelligence-Survey-of-research-on-vulnerability-discovery-techniques/2.jpg" alt=""></p><h3 id="3-1-1-二进制程序函数识别"><a href="#3-1-1-二进制程序函数识别" class="headerlink" title="3.1.1 二进制程序函数识别"></a>3.1.1 二进制程序函数识别</h3><p>二进制程序函数识别是二进制分析的基础，对于软件漏洞分析与修复，甚至恶意软件检测、协议逆向等都至关重要。由于二进制代码缺少高级语言程序中的信息，函数的识别往往比较困难，现有的反汇编分析工具具有识别正确率低的缺陷。Bao等[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b93" target="_blank" rel="noopener">93</a>]提出了ByteWeight方案，采用机器学习算法实现对二进制程序函数的识别。具体而言，首先采用加权前缀树(weighted prefix tree)学习函数的签名，并通过签名匹配二进制片段的方式识别函数。其中，树中每个节点与二进制中的字节或指令相对应，而从根节点到某个既定节点的路径代表了可能的字节或指令序列，权重则表示了对数据集采用简单线性扫描算法学习到的字节或指令序列的置信度。在鉴别函数的同时，ByteWeight采用值集分析(value set analysis, VSA)和增量控制流恢复算法实现对函数边界的识别。此种方案可以获得比IDA Pro和BAP工具[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b94" target="_blank" rel="noopener">94</a>]更高的准确率。Shin等[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b95" target="_blank" rel="noopener">95</a>]用循环神经网络算法改进了ByteWeight的性能，在模型训练时间上有了数量级上的提升，并取得了更高的准确率。</p><h3 id="3-1-2-函数相似性检测"><a href="#3-1-2-函数相似性检测" class="headerlink" title="3.1.2 函数相似性检测"></a>3.1.2 函数相似性检测</h3><p>现代应用程序中，直接调用第三方函数可以节约开发成本、提高开发效率，是被广泛接受的开发惯例。但这种方式容易导致供应链安全风险，一旦被调用函数存在漏洞，则调用这一函数的程序也可能存在漏洞。通过函数相似性检测技术可以实现对不同程序间的同源性漏洞的检测，但当前基于图的相似度匹配的方法具有计算量大、准确率低的缺陷。Xu等[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b97" target="_blank" rel="noopener">97</a>]提出了Gemini方案，Gemini把函数控制流图CFG简化为带节点属性(数字特征)的控制流图(ACFG)，然后用Structure2vec算法转化为数字向量，使用Siamese网络架构训练，实现相似的函数距离近的目标，最后通过计算函数向量距离实现函数相似性的检测。Gemini能应用到跨平台的二进制函数相似性检测，并取得了比其他基于图相似性匹配的工具(如Genius[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b98" target="_blank" rel="noopener">98</a>])更高的准确率和检测效率。</p><h3 id="3-1-3-测试输入生成"><a href="#3-1-3-测试输入生成" class="headerlink" title="3.1.3 测试输入生成"></a>3.1.3 测试输入生成</h3><p>在软件漏洞挖掘中，构造代码覆盖率高或脆弱性导向型的测试输入能提高漏洞挖掘的效率和针对性。利用机器学习技术可以对海量测试样本进行分析、学习，并利用生成模型指导生成更高质量的测试输入样本。Godefroid等[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b99" target="_blank" rel="noopener">99</a>]首次把模糊测试中的高结构化样本生成问题转换成了NLP领域的文本生成问题，采用了Char-RNN(recurrent neural network)模型实现对PDF文件格式中的obj语法的学习，并用训练好的模型生成具有多样性的obj对象和PDF文件。She等[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b100" target="_blank" rel="noopener">100</a>]提出了采用深度神经网络指导模糊测试输入生成的方案Neuzz。Neuzz采用了CNN(convolutional neural network)学习连续可微的神经程序(neural program)，用来近似模拟目标程序中的实际逻辑，然后通过对学习好的神经程序求梯度的方式指导测试输入生成，以此取得对目标程序更高的分支覆盖。与AFL相比，Neuzz在6个不同的常用程序中多发现了70倍的分支，并多发现了36个缺陷。Bottinger等[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b101" target="_blank" rel="noopener">101</a>]提出了深度强化学习增强的模糊测试技术，借助Markov模型把模糊测试问题转化成强化学习问题，并利用Q-learning算法优化预定义的奖励函数。实验结果表明，使用深度强化学习增强的模糊测试技术比随机变异能取得更高的代码覆盖率。Nichols等[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b102" target="_blank" rel="noopener">102</a>]提出了生成对抗网络(GAN)增强模糊测试技术。该方案不依赖于大数据量的样本训练，并能比AFL的随机变异和基于LSTM模型引导的变异更高效地发现更多的路径。</p><h3 id="3-1-4-测试输入筛选"><a href="#3-1-4-测试输入筛选" class="headerlink" title="3.1.4 测试输入筛选"></a>3.1.4 测试输入筛选</h3><p>动态漏洞挖掘依赖于测试输入的实际运行来检测是否能触发崩溃或漏洞，当有海量样本需要被执行测试时，会非常耗时且低效。测试样本筛选的目的是从海量样本中选择更有可能触发新路径或触发漏洞的测试输入。使用机器学习技术通过对大量的测试样本进行处理，从而决定哪些应该被进一步分析，尽可能准确地对样本进行标记，然后再用于寻找安全漏洞。Rajpal等[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b103" target="_blank" rel="noopener">103</a>]使用LSTM、序列到序列(Seq2seq)等神经网络学习模糊测试过程中的历史变异样本及代码覆盖率等数据，训练出能指导对输入文件进行定向变异的模型。实验结果表明，使用这种方法能获得比随机变异更高的代码覆盖率。但文[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b103" target="_blank" rel="noopener">103</a>]中采用的热力图生成模型仅仅依赖于基础样本以及能带来代码覆盖率增长的变异样本，训练生成的模型并没有记录测试输入与变异点、变异方法、代码覆盖增长情况之间的关联信息，基于这种模型生成的热力图不能精确标注记录测试输入中变异点与代码覆盖之间的关联性，因此热力图可能带有误标注和漏标注。此外，Spieker等[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b104" target="_blank" rel="noopener">104</a>]还提出了采用强化学习的算法优先筛选漏洞导向型的测试用例，应用在持续集成(continuous integration, CI)及回归测试(regression test)中。</p><p>2.1.5 路径约束求解</p><p>模糊测试，特别是代码覆盖率制导的模糊测试(如AFL)，侧重于筛选可以覆盖新路径的样本为种子文件，但对种子文件变异时并没有充分利用程序数据流等信息指导变异，这使得变异盲目低效，生成样本冗余。现有的一些启发式优化工作如Steelix[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b35" target="_blank" rel="noopener">35</a>]能够对魔术字节跟踪定位，但无法对其他路径约束求解。具备路径约束求解能力是符号执行比模糊测试等漏洞挖掘技术更先进的体现，也使得符号执行在理论上具备了系统性探索程序执行路径的能力。但复杂程序中的路径爆炸问题带来的对SMT求解器的频繁调用，以及SMT求解器本身的能力和效率的不足，使得约束求解占用了符号执行中主要的性能开销，约束求解问题也成为符号执行中面临的主要瓶颈问题之一。Chen等[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b105" target="_blank" rel="noopener">105</a>]提出了Angora，采用污点追踪测试输入中影响条件分支的字节，然后使用梯度下降的方式对变异后生成的路径约束进行求解。这种方式避免了符号执行调用SMT求解器可能带来的开销以及复杂约束不可解的问题，但梯度下降对目标函数不可导或存在不可导点时，仍然会出现求解困难的问题。</p><h3 id="3-1-6-漏洞程序筛选"><a href="#3-1-6-漏洞程序筛选" class="headerlink" title="3.1.6 漏洞程序筛选"></a>3.1.6 漏洞程序筛选</h3><p>传统的漏洞挖掘技术如模糊测试、符号执行等已经成功地从各类软件中发现了大量的漏洞，但当被测试程序复杂且数量庞大的时候，使用这些技术挖掘漏洞显得效率低下。VDiscover[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b106" target="_blank" rel="noopener">106</a>]采用机器学习技术从大量的程序中快速筛选更有可能带有漏洞的程序。具体而言，VDiscover收集程序中的标准C库函数调用序列及其参数的动态值作为静态和动态特征，并对其做标注，然后采用带监督的机器学习算法(如随机森林，逻辑回归等)训练模型，当有新的被测试程序需要分类的时候，训练好的模型可以直接对提取的相应特征进行预判和标注。</p><p>VDiscover首次验证了采用机器学习技术筛选漏洞程序的可行性，但其采用人工定义和提取特征的方法具有较大的局限性。漏洞成因复杂，VDiscover提取的程序静态特征和动态特征并不能精确地表征各种类型的漏洞, 这可能造成较高的误报和漏报。另外，采用机器学习直接对漏洞程序进行预测的方式无法生成测试用例来动态验证漏洞。</p><h3 id="3-1-7-源代码漏洞点预测"><a href="#3-1-7-源代码漏洞点预测" class="headerlink" title="3.1.7 源代码漏洞点预测"></a>3.1.7 源代码漏洞点预测</h3><p>传统静态漏洞挖掘技术中，依赖于人工定义漏洞模式的检测方式经常会导致较高的漏报率。Li等[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b107" target="_blank" rel="noopener">107</a>]提出了VulDeePecker方案，采用BLSTM算法对C/C++源代码中的漏洞点进行预测。鉴于传统的漏洞分类过细导致难以抽象提取为特征的问题，其设计了能覆盖多种漏洞类型的特征，这种方式不以函数为粒度，只考虑数据流保留语义上关联的代码行作为代码小部件(code gadgets)对程序进行表征，然后转换成向量作为深度学习的输入。但VulDeePecker方案中，代码小部件转换成向量的过程存在较大的信息丢失问题；另外，该方案只支持对缓冲区溢出和资源管理相关的漏洞的检测。</p><h3 id="3-1-8-其他"><a href="#3-1-8-其他" class="headerlink" title="3.1.8 其他"></a>3.1.8 其他</h3><p>此外，机器学习还应用于模糊测试参数配置预测[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b108" target="_blank" rel="noopener">108</a>]和漏洞可利用性分析[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b109" target="_blank" rel="noopener">109</a>-<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b110" target="_blank" rel="noopener">110</a>]等场景中。</p><h2 id="3-2-面临的问题"><a href="#3-2-面临的问题" class="headerlink" title="3.2 面临的问题"></a>3.2 面临的问题</h2><h3 id="3-2-1-机器学习的局限性"><a href="#3-2-1-机器学习的局限性" class="headerlink" title="3.2.1 机器学习的局限性"></a>3.2.1 机器学习的局限性</h3><p>虽然以机器学习为代表的人工智能技术取得了非常瞩目的进展，但其本身也面临着巨大的挑战。基于机器学习的漏洞挖掘技术受限于算法本身的能力，也受限于算法本身的安全性和健壮性。</p><p>当前的机器学习技术并没有解决人工智能的核心问题，不是通向人工智能的最佳途径[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b111" target="_blank" rel="noopener">111</a>]。传统的机器学习技术需要人工设计、构建特征，然后转换成向量作为机器学习算法的输入，不具备对原始数据自动提取特征的能力，严重依赖于专家知识。深度学习具有在高维数据中自动提取特征的能力，并已经取得了广泛应用，但其仍然面临着持续学习、数据饥饿、可解释性等问题[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b111" target="_blank" rel="noopener">111</a>-<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b112" target="_blank" rel="noopener">112</a>]。</p><p>另外，当前的机器学习算法的安全性和健壮性问题也逐渐暴露出来。一方面，常用机器学习工具存在漏洞。Stevens等[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b113" target="_blank" rel="noopener">113</a>]利用模糊测试方法挖掘出了OpenCVScikit-Learn、NumPy等常用的机器学习软件的库文件中的堆溢出等漏洞，这些漏洞能导致Dos攻击或任意代码执行，或直接修改分类判定结果。另一方面，机器学习算法本身的健壮性问题容易导致对抗式攻击(adversarial attack)[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b114" target="_blank" rel="noopener">114</a>-<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b119" target="_blank" rel="noopener">119</a>]。对抗式攻击又称为对抗性训练或对抗性机器学习，通过在数据集中注入被污染的数据而欺骗模型做出错误的判断。此外，健壮性问题还容易导致污染攻击[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b120" target="_blank" rel="noopener">120</a>-<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b122" target="_blank" rel="noopener">122</a>]，逃逸攻击[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b123" target="_blank" rel="noopener">123</a>-<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b126" target="_blank" rel="noopener">126</a>]、模型倒置攻击[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b127" target="_blank" rel="noopener">127</a>-<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b128" target="_blank" rel="noopener">128</a>]，模型(参数)提取攻击[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b129" target="_blank" rel="noopener">129</a>-<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b131" target="_blank" rel="noopener">131</a>]等，这类攻击通常具有较高的隐蔽性。</p><h3 id="3-2-2-算法选择"><a href="#3-2-2-算法选择" class="headerlink" title="3.2.2 算法选择"></a>3.2.2 算法选择</h3><p>机器学习、深度学习虽然已经在图像识别、自然语言处理等领域已经有比较成熟的应用，但在漏洞挖掘领域，不同的应用场景下可能只适用于部分机器学习算法，甚至同一场景中，选择不同的适用算法也会导致结果的显著差异。但现有的研究工作大部分只凭经验选取了部分机器学习算法，并未对各类算法性能进行较系统性的比对。如在文[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b103" target="_blank" rel="noopener">103</a>, <a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b107" target="_blank" rel="noopener">107</a>]中采用了LSTM等循环神经网络算法实现可变长序列预测和文本生成，但当前CNN已经可以取得比LSTM更好的性能[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b132" target="_blank" rel="noopener">132</a>-<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b133" target="_blank" rel="noopener">133</a>]。其次，还要考虑根据数据量大小的问题，如果数据量小，人工指定规则的传统机器学习可能会有更好地性能。深度学习虽然能自动对各种简单的特征学习并组合成更加复杂的特征，在特征提取上比传统的机器学习算法具有更大的优势，但深度学习更适合大数据量的学习。另外，对同一种算法的不同参数配置也能产生不同的模型，需要在对模型进行评估的基础上选择泛化误差小的模型。</p><h3 id="3-2-3-数据收集"><a href="#3-2-3-数据收集" class="headerlink" title="3.2.3 数据收集"></a>3.2.3 数据收集</h3><p>机器学习、深度学习需要大量的样本，特别是深度学习在数据量不足时容易导致过拟合的问题。目前，在现有工作中针对不同应用场景和学习任务，收集的样本对象包括了二进制程序、PDF文件、C/C++源码、IOT固件等，这些数据的收集方式参差不齐，如模糊测试生成、符号执行生成、人工编译生成、网络爬虫等。对于常用的文件格式如DOC、PDF、SWF等，采用网络爬虫获取测试输入集是比较常用的方法。爬取方式可按特定文件扩展名(后缀)为筛选条件进行下载，或者按特定魔术字节或其他签名的方式下载，爬取的结果很容易就能达到TB数量级(如Skyfire[<a href="http://jst.tsinghuajournals.com/CN/rhhtml/20181206.htm#b133" target="_blank" rel="noopener">133</a>])。但对于其他数据如崩溃样本、漏洞程序等，因其具有稀缺性，存在收集困难的问题。当前缺少通用的、认可度较高的漏洞相关的数据集可供基于机器学习、深度学习的技术进行训练和测试。</p><p>收集漏洞相关的大数据集能为基于机器学习的智能化漏洞挖掘和分析提供学习素材，也关系到训练模型的效果。构建面向机器学习的大规模漏洞数据集对后续的研究将起到至关重要的作用，应当成为未来研究的重点问题之一。</p><h3 id="3-2-4-特征选择"><a href="#3-2-4-特征选择" class="headerlink" title="3.2.4 特征选择"></a>3.2.4 特征选择</h3><p>传统机器学习算法分类、预测的准确性既与数据量的大小有关，也依赖于从数据中提取的特征。在漏洞挖掘中，程序结构和执行信息与漏洞并没有直接的关联性，如何从程序中筛选出漏洞相关的显著特征、摒弃非显著特征，需要结合机器学习算法、程序执行环境及漏洞产生原理等多方面考虑。例如在二进制程序中，静态特征可以从调用图、控制流图、数据流图等获取(同时要考虑图信息获取不精确的问题)，动态特征可以通过插桩执行跟踪(trace)实际函数调用以及调用参数的方式捕获。另外，还要考虑动、静态特征提取时带来的开销和可扩展性问题。如在二进制程序中，对目标程序建立各种基于图的结构计算量较大，动态特征提取则依赖于实际执行插桩跟踪测试程序，而插桩特别是动态插桩会带来比较大的开销，甚至会影响程序实际执行时的内存空间布局。</p><p>综上所述，探索基于学习的漏洞挖掘技术，研究机器学习算法对软件漏洞挖掘中的不同应用场景的适用性，借助机器学习的分类、预测能力甚至深度学习的自动特征提取能力来缓解、突破传统技术的瓶颈问题，是当前智能化漏洞挖掘研究的热点和难点。</p><h1 id="4-结论与展望"><a href="#4-结论与展望" class="headerlink" title="4 结论与展望"></a>4 结论与展望</h1><p>本文分析了传统漏洞挖掘技术及基于学习的智能化漏洞挖掘技术的研究进展，针对这些技术呈现出的自动化、智能化的趋势及面临的问题进行了深入的调研分析、归类和总结。</p><p>下一步的研究应从以下2点展开：</p><ul><li><strong>1) 提高漏洞挖掘的效率与精度</strong></li></ul><p>漏洞挖掘是计算密集型的工作，与软件的规模和复杂度、硬件系统性能、采用的分析技术都有非常大的关联性，在研究实践中往往需要根据这些影响因素动态调整程序分析策略，在分析效率与分析深度之间取得较好的平衡和折中。一方面，需要研究轻量级分析技术、启发式状态空间探测技术(如脆弱路径筛选、低频路径筛选等)，在较小的开销内增强漏洞挖掘的导向性。另一方面，需要研究高效的规模化、并行化分析方法。漏洞挖掘在算法、分析数据存储和处理方面都有显著特征，现有的技术对大型复杂程序分析效率低下，没有充分利用高性能硬件设备提供的并行处理能力。探索规模化、并行化漏洞挖掘技术，增强对异构化计算资源的利用率，能很好应对大型复杂软件快速分析的需求。</p><ul><li><strong>2) 提高漏洞挖掘的自动化与智能化</strong></li></ul><p>在自动化方面，研究不依赖或较少依赖于人工参与的漏洞挖掘技术如漏洞利用程序自动生成、高结构化测试输入生成等仍然是当前研究的难点，这对实现全自动的漏洞挖掘甚至网络攻防都有重要的推进作用。在智能化方面，需要研究机器学习(如深度学习、强化学习、生成对抗网络等)在漏洞挖掘领域的应用。适用场景还应包括脆弱路径筛选、高结构化输入生成、约束求解配置预测等。基于机器学习的漏洞挖掘技术为解决传统漏洞挖掘技术的一些瓶颈问题提供了新途径，既能提升漏洞挖掘的自动化程度，也能提高漏洞挖掘的效率和精度。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h1&gt;&lt;p&gt;近年来，随着软件规模和复杂度的日益增加，软件漏洞挖掘技术正逐渐向高度自动化和智能化演变，该文
      
    
    </summary>
    
      <category term="论文" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/"/>
    
      <category term="fuzzing" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/fuzzing/"/>
    
      <category term="综述" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/fuzzing/%E7%BB%BC%E8%BF%B0/"/>
    
    
      <category term="2018年" scheme="http://yama0xff.com/tags/2018%E5%B9%B4/"/>
    
      <category term="综述" scheme="http://yama0xff.com/tags/%E7%BB%BC%E8%BF%B0/"/>
    
      <category term="Fuzzing" scheme="http://yama0xff.com/tags/Fuzzing/"/>
    
  </entry>
  
  <entry>
    <title>Fuzzing: Art, Science, and Engineering</title>
    <link href="http://yama0xff.com/2019/03/20/Fuzzing-Art-Science-and-Engineering/"/>
    <id>http://yama0xff.com/2019/03/20/Fuzzing-Art-Science-and-Engineering/</id>
    <published>2019-03-20T09:02:30.000Z</published>
    <updated>2019-03-28T01:19:43.406Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>在当今可用的众多软件漏洞发现技术中，模糊测试由于其概念简单，部署的低屏障以及发现现实世界软件漏洞的大量经验证据而一直非常受欢迎。虽然近年来研究人员和从业人员都为改进模糊测试投入了大量不同的努力，但这项工作的激增也使得难以获得全面和一致的模糊测试观点。为了帮助保存并使大量的模糊测量文献保持连贯性，本文提出了一种统一的，通用的模糊测试模型以及当前模糊文献的分类。我们通过调查相关文献和艺术，科学和工程方面的创新，有条不紊地探索模型模糊器的每个阶段的设计决策，使现代模糊器有效。</p><table><thead><tr><th>relevant information</th><th></th></tr></thead><tbody><tr><td><em>作者</em></td><td>VALENTIN J.M. MANÈS，HYUNGSEOK HAN,CHOONGWOO HAN,SANG KIL CHA∗,MANUEL EGELE,EDWARD J. SCHWARTZ,MAVERICK WOO,</td></tr><tr><td><em>单位</em></td><td></td></tr><tr><td><em>出处</em></td><td>CSUR‘19</td></tr><tr><td><em>原文地址</em></td><td><a href="https://github.com/wtwofire/database/blob/master/papers/fuzzing/Review/2019-fuzzing%EF%BC%9A%20Art%2C%20Science%2C%20and%20Engineering.pdf" target="_blank" rel="noopener">https://github.com/wtwofire/database/blob/master/papers/fuzzing/Review/2019-fuzzing%EF%BC%9A%20Art%2C%20Science%2C%20and%20Engineering.pdf</a></td></tr><tr><td><em>源码地址</em></td><td></td></tr><tr><td><em>发表时间</em></td><td>2019</td></tr></tbody></table><h1 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h1><p>自从20世纪90年代初引入[139]以来，模糊测试一直是发现软件安全漏洞的最广泛部署的技术之一。在高级别，模糊测试指的是重复运行程序和构造的输入的过程，该输入可能在语法上或语义上不正确。在实践中，攻击者通常在诸如漏洞利用生成和渗透测试的场景中部署模糊测试[20,102]; 2016年DARPA网络大挑战赛（CGC）的几支队伍也在他们的网络推理系统中使用模糊测试[9,33,87,184]。在这些活动的推动下，防御者开始使用模糊测试来试图在攻击者发现漏洞之前发现漏洞。例如，Adobe [1]，Cisco [2]，Google [5,14,55]和Microsoft [8,34]等知名厂商都将模糊测试作为其安全开发实践的一部分。最近，安全审计员[217]和开源开发人员[4]也开始使用模糊测试来衡量商品软件包的安全性，并为最终用户提供一些合适的保证形式。</p><p>模糊社区非常有活力。在撰写本文时，仅GitHub就拥有了超过一千个与模糊测试相关的公共存储库[80]。正如我们将要展示的那样，文献中还包含大量的模糊器（参见第7页的图1），并且越来越多的模糊测试研究出现在主要安全会议上（例如[33,48,164,165,199,206] ]）。此外，博客圈中充满了许多模糊测试的成功故事，其中一些还包含了我们认为是<a href="https://goo.gl/37GYKN" target="_blank" rel="noopener">精华</a>的东西，这些精华在文献中占有一席之地。</p><p>不幸的是，研究人员和从业人员在模糊测试方面的工作激增也带来了阻碍进展的警告信号。例如，一些模糊器的描述不会超出其源代码和手册页。因此，随着时间的推移，很容易忘记这些模糊测试中的设计决策和潜在的重要调整。此外，各种模糊器使用的术语中存在可观察到的碎片。例如，虽然AFL [211]使用术语“测试用例最小化”来指代减小崩溃输入大小的技术，但同样的技术在funfuzz中也被称为“测试用例减少”[143]。虽然BFF [45]包含一种称为“崩溃最小化”的技术，听起来非常相似，但崩溃最小化的目的实际上是最小化崩溃输入和原始种子文件之间不同的位数，而不是减少崩溃输入的大小。我们认为这种分散使得难以发现和传播 fuzzing 知识，从长远来看，这可能严重阻碍 fuzzing 研究的进展。</p><p>基于我们的研究和我们在模糊测试方面的个人经验，本文作者认为现在是整合和提炼模糊测试大量进展的黄金时间，其中许多是在2007-2008 [73,187,189]年出版的三本关于该主题的贸易书籍之后发生的 。我们注意到Li等人同时进行了调查。 [125]侧重于基于覆盖的模糊测试的最新进展，但我们的目标是提供有关该领域近期发展的综合研究。为此，我们将首先使用§2来展示我们的模糊术语和统一的模糊测试模型。坚持本文的目的，选择我们的模糊术语来密切反映当前的主要用法，我们的模型模糊器（算法1，第4页）旨在适应大量的模糊测试任务，如分类在目前的模糊文献（图1，第7页）。通过这种设置，我们将在§3-§7中有条不紊地探索模型模糊器的每个阶段，并在表1中详细介绍主要模糊器（第9页）。<br>在每个阶段，我们将调查相关文献来解释设计选择，讨论重要的权衡，并突出许多奇妙的工程努力，帮助使现代模糊器有效地完成他们的任务。</p><h1 id="2-系统化，分类和测试程序"><a href="#2-系统化，分类和测试程序" class="headerlink" title="2. 系统化，分类和测试程序"></a>2. 系统化，分类和测试程序</h1><p>术语“fuzz”最初由Miller等人创造。在1990年，它指的是“生成一个由目标程序消耗的随机字符流”的程序[139，p.4]。从那时起，模糊的概念及其动作 - “fuzzing” - 出现在各种各样的语境中，包括动态符号执行[84,207]，基于语法的测试用例生成[82,98,196]，权限测试[21,74]，行为测试[114,163,205]，表示依赖性测试[113]，函数检测[208]，健壮性评估[204]，漏洞利用开发[104]，GUI测试[181]，签名生成[66]和渗透测试[75,145]。为了使大量的模糊测试文献中的知识系统化，让我们首先提出从当前使用中提取的模糊测试术语。</p><h2 id="2-1-Fuzzing-amp-Fuzzing-Testing"><a href="#2-1-Fuzzing-amp-Fuzzing-Testing" class="headerlink" title="2.1 Fuzzing &amp; Fuzzing Testing"></a>2.1 Fuzzing &amp; Fuzzing Testing</h2><p>直观地说，fuzzing是使用“模糊输入”运行被测程序（PUT）的行为。Honoring Miller等人，我们认为模糊输入是PUT可能不期望的输入，即PUT可能错误处理的输入并且触发PUT开发者无意识的行为。为了捕捉这个想法，我们将术语fuzzing定义如下。</p><blockquote><p><strong>定义2.1（fuzzing）</strong>。模糊测试是使用从输入空间（“模糊输入空间”）采样的输入执行PUT，该输入空间突出了PUT的预期的输入空间。</p></blockquote><p>三个评论是有序的。首先，尽管通常看到模糊输入空间包含预期的输入空间，但这不是必需的 - 前者包含d的输入不在后者中就足够了。其次，在实践中，模糊测试几乎肯定会进行多次迭代;因此，在上面写“重复执行”仍然很准确。第三，抽样过程不一定是随机的，我们将在§5中看到.</p><p>Fuzz testing是一种利用fuzzing的软件测试技术。为了区别于其他人并尊重我们认为最突出的目标，我们认为它有一个特定的目标，即找到与安全相关的错误，其中包括程序崩溃。此外，我们还定义了fuzzer和fuzz campaign，这两者都是模糊测试中的常用术语。</p><blockquote><p><strong>定义2.2（Fuzz Testing）</strong>。Fuzz Testing是使用fuzzing，其目标是测试PUT违反安全策略的地方。<br><strong>定义2.3（Fuzzer）</strong>。Fuzzer是一种在PUT上执行fuzz testing的程序。<br><strong>定义2.4（Fuzz Campaign）</strong>。Fuzz Campaign是一个在有特定安全策略的PUT上的特定执行的Fuzzer。</p></blockquote><p>通过fuzzing campaign运行PUT的目的是找到违反所需安全策略的错误[23]。例如，早期fuzzer使用的安全策略仅测试生成的输入 - 测试用例 - 是否使PUT崩溃。但是，fuzz testing 实际上可用于测试任何可执行的安全策略，即EMenforceable [171]。决定执行是否违反安全策略的具体机制称为<strong>bug oracle</strong>。</p><blockquote><p><strong>定义2.5（Bug Oracle）</strong>。 bug oracle是一个程序，可能作为fuzzer的一部分，用于确定PUT的给定执行是否违反特定的安全策略。</p></blockquote><p> 我们将fuzzer实现的算法简称为<strong>“fuzz algorithm”</strong>。几乎所有 fuzz algorithm都依赖于PUT之外的一些参数（路径）。参数的每个具体设置都是<strong>fuzz configuration：</strong></p><blockquote><p><strong>定义2.6（Fuzz Configuration）</strong>。fuzz algorithm的fuzz configuration包括控制fuzz algorithm的参数值。</p></blockquote><p>Fuzz configuration通常被写为元组。请注意，fuzz configuration中的值类型取决于fuzz algorithm的类型。例如，将随机字节流发送到PUT [139]的fuzz algorithm具有简单的配置空间{（PUT）}。另一方面，复杂的fuzzer包含接受一组配置并随时间推移设置的算法 - 这包括添加和删除配置。例如，CERT BFF [45]在活动过程中改变了突变率和种子（在第5.2节中定义），因此其配置空间为{(PUT，s1，r1)，(PUT，s2，r2）,. … }。最后，对于每个配置，我们还允许fuzzer存储一些数据。例如，覆盖引导的模糊器可以存储每个配置的获得的覆盖范围。</p><h2 id="2-2-Paper-Selection-Criteria"><a href="#2-2-Paper-Selection-Criteria" class="headerlink" title="2.2 Paper Selection Criteria"></a>2.2 Paper Selection Criteria</h2><p>为了达到明确的范围，我们选择在2008年1月至2018年5月的4个主要安全会议和3个主要软件工程会议的最后一个议程中包括所有关于模糊测试的出版物。按字母顺序排列，前者包括（i）ACM会议计算机和通信安全（<code>CCS</code>），（ii）IEEE安全和隐私（<code>S＆P</code>）研讨会，（iii）网络和分布式系统安全研讨会（<code>NDSS</code>），以及（iv）USENIX安全研讨会（<code>USEC</code>）;后者包括（i）ACM国际软件工程基础研讨会（<code>FSE</code>），（ii）IEEE / ACM自动软件工程国际会议（<code>ASE</code>），以及（iii）国际软件工程会议（<code>ICSE</code>）。对于出现在其他场所或媒介中的作品，我们根据自己对其相关性的判断将它们包括在内。</p><p>正如§2.1中所提到的，fuzz testing与软件测试的区别仅在于它与安全相关。尽管瞄准安全漏洞并不意味着除了在理论上使用bug oracle之外的测试过程中存在差异，但所使用的技术在实践中通常会有所不同。在设计测试工具时，我们经常假设源代码的存在和PUT的知识。与fuzzer相比，这些假设通常会将工具的开发推向不同的形状。尽管如此，这两个领域仍然彼此纠缠不清。因此，当我们自己的判断力不足以区分它们时，我们遵循一个简单的经验法则：如果出版物中没有出现fuzz这个词，我们就不包括它。</p><h2 id="2-3-Fuzz-Testing-Algorithm"><a href="#2-3-Fuzz-Testing-Algorithm" class="headerlink" title="2.3 Fuzz Testing Algorithm"></a>2.3 Fuzz Testing Algorithm</h2><p>我们提出了一种用于fuzz testing的通用算法，算法1，我们想象它已经在模型fuzzer中实现。它足以适应现有的模糊测试技术，包括§2.4中定义的黑色，灰色和白盒模糊测试。算法1将一组fuzz configurations C和一个超时 t_limit 作为输入，并输出一组发现的错误B.它由两部分组成。第一部分是预处理功能，它在fuzz campaign开始时执行。第二部分是循环内的一系列五个函数：<strong>Schedule，InputGen，InputEval，ConfUpdate和Continue</strong>。此循环的每次执行都称为<strong>fuzz iteration</strong>，并且在单个测试用例上执行InputEval称为<strong>fuzz run</strong>。请注意，一些模糊器不会实现所有五个功能。例如，为了模拟Radamsa [95]，我们让ConfUpdate简单地返回C，即它不会更新C.</p><p><img src="/2019/03/20/Fuzzing-Art-Science-and-Engineering/1.Fuzz Test.jpg" alt="Fuzz Test"></p><p><strong>Preprocess（C）–&gt;C</strong></p><blockquote><p> 用户为Preprocess提供一组fuzz configurations作为输入，并返回一组可能已修改的fuzz configurations。根据fuzz algorithm，Preprocess可以执行各种操作，例如将检测代码插入PUT，或测量种子文件的执行速度。见§3</p></blockquote><p><strong>Schedule(C,telapsed,tlimit) –&gt; conf </strong></p><blockquote><p>Schedule接收当前的fuzz configurations，当前时间t_elapsed和超时t_limit作为输入，并选择要用于当前模糊迭代的fuzz configuration。见§4。</p></blockquote><p><strong>InputGen（conf）–&gt;tcs </strong></p><blockquote><p>InputGen将fuzz configurations作为输入，并返回一组具体测试用例 tcs 作为输出。生成测试用例时，InputGen使用conf中的特定参数。一些模糊测试器使用conf中的种子来生成测试用例，而其他模糊器则使用模型或语法作为参数。见§5。</p></blockquote><p><strong>InputEval (conf, tcs, Obug) –&gt; B′, execinfos</strong></p><blockquote><p>InputEval采用fuzz配置conf，一组测试用例 tcs 和一个bug oracle Obug作为输入。它在tcs上执行PUT并使用bug oracle O_bug检查执行是否违反了安全策略。然后它输出发现的错误集B’和关于每个fuzz运行的信息 execinfos。我们假设O_bug嵌入在我们的模型模糊器中。见§6。</p></blockquote><p><strong>ConfUpdate(C，conf，execinfos) –&gt; C </strong></p><blockquote><p>ConfUpdate采用一组fuzz configurations C，当前配置 conf，以及每个模糊运行的信息 execinfos作为输入。它可能会更新一组fuzz configurations C.例如，许多灰盒模糊器会根据execinfos减少C中的模糊配置数量。见§7。</p></blockquote><p><strong>Continue (C) –&gt;  {True, False} </strong></p><blockquote><p>Continue将一组fuzz configurations C作为输入，并输出一个布尔值，指示是否应该进行下一个模糊迭代。此功能对于模型白盒模糊器很有用，当没有更多路径可以发现时，它可以终止。</p></blockquote><h2 id="2-4-Fuzzers-的分类"><a href="#2-4-Fuzzers-的分类" class="headerlink" title="2.4  Fuzzers 的分类"></a>2.4  Fuzzers 的分类</h2><p>在本文中，我们根据模糊器在每个模糊运行中观察到的语义粒度将模糊器分为三组：黑盒，灰盒和白盒fuzzer。请注意，这与传统的软件测试不同，传统的软件测试只有两个主要类别（黑盒和白盒测试）[147]。正如我们将在§2.4.3中讨论的那样，灰盒模糊测试是白盒模糊测试的一种变体，它只能从每次模糊运行中获取一些部分信息。 </p><p>图1按时间顺序列出了现有fuzzer的分类。从Miller等人的开创性工作开始。 [139]，我们手动选择了在大型会议上出现或获得超过100个GitHub stars的流行fuzzer，并将其关系显示在图上。黑盒fuzzer位于图的左半部分，灰盒和白盒模糊器位于右半部分。</p><p><img src="/2019/03/20/Fuzzing-Art-Science-and-Engineering/2.jpg" alt="2"></p><p>表1详细介绍了主要会议上出现的每个主要fuzzer所使用的技术。由于空间限制，我们省略了几个主要的fuzzer。每个模糊器都投影在我们上面提到的模型模糊器的五个功能上，其中一个杂项部分提供了有关fuzzer的额外细节。第一列（检测粒度）表示基于静态或动态分析从PUT获取多少信息。当fuzzer在两个阶段使用不同类型的插桩时，出现两个圆圈。例如，SymFuzz [48]运行白盒分析作为预处理，以便为随后的黑盒活动提取信息，而Driller [184]在白盒和灰盒模糊之间交替进行。</p><ul><li><p><strong>第二列</strong>显示来源是否公开。</p></li><li><p><strong>第三列</strong>表示模糊器是否需要源代码才能运行。</p></li><li><p><strong>第四列</strong>指出了模糊器是否支持内存模糊测试（参见§3.1.2）。</p></li><li><p><strong>第五列</strong>是关于fuzzer是否可以推断模型（参见§5.1.2）。</p></li><li><p><strong>第六列</strong>显示了在Preprocess中，fuzzer是执行静态分析还是动态分析。<strong>第七列</strong>指示fuzzers是否支持处理多个种子，并执行调度。</p></li><li><p><strong>变异列</strong>指定fuzzers是否执行输入变异以生成测试用例。我们使用“半黑半白”来表示fuzzer根据执行反馈引导输入变异。基于模型的专栏是关于fuzzer是否基于模型生成测试用例。</p></li><li><p><strong>基于约束的列</strong>显示fuzzers执行符号分析以生成测试用例。<strong>污点分析列</strong>意味着模糊测试器利用污点分析来指导其测试用例生成过程。</p></li><li><p><strong>InputEval部分</strong>中的两列显示fuzzers是使用堆栈哈希还是使用代码覆盖率执行崩溃分类。</p></li><li><p><strong>ConfUpdate部分</strong>的第一列指示在ConfUpdate期间模糊器是否进化种子池，例如，向池中添加有趣的种子（参见§7.1）。 ConfUpdate部分的第二列是关于fuzzers是否以在线方式学习模型。最后，ConfUpdate部分的第三列显示了从种子池中删除种子（参见§7.2）。</p></li></ul><p><img src="/2019/03/20/Fuzzing-Art-Science-and-Engineering/3.jpg" alt="表1"></p><h3 id="2-4-1黑盒fuzzer"><a href="#2-4-1黑盒fuzzer" class="headerlink" title="2.4.1黑盒fuzzer"></a>2.4.1黑盒fuzzer</h3><p>术语“黑盒”通常用于软件测试[29,147]，fuzzing表示没有看到PUT内部的技术 - 这些技术只能观察PUT的输入/输出行为，将其视为一个黑盒子。在软件测试中，黑盒测试也称为IO驱动或数据驱动测试[147]。大多数传统的模糊器[6,13,45,46,96]属于这一类。一些现代模糊器，例如<code>funfuzz</code> [143]和<code>Peach</code> [70]，也考虑了有关输入的结构信息，以生成更有意义的测试用例，同时保持不检查PUT的特性。类似的直觉用于自适应随机测试[51]。</p><h3 id="2-4-2白盒Fuzzer"><a href="#2-4-2白盒Fuzzer" class="headerlink" title="2.4.2白盒Fuzzer"></a>2.4.2白盒Fuzzer</h3><p>在频谱的另一个极端，白盒模糊[84]通过分析PUT的内部和执行PUT时收集的信息来生成测试用例。因此，白盒模糊器能够系统地探索PUT的状态空间。术语白盒模糊是由Godefroid [81]在2007年引入的，它指的是动态符号执行（DSE），它是符号执行的变体[35,101,118]。在DSE中，符号和具体执行同时进行，其中具体的程序状态用于简化符号约束，例如，具体化系统调用。因此，DSE通常被称为concolic testing（具体的+符号的）[83,176]。此外，白盒模糊测试也被用于描述采用污点分析的模糊器[78]。<br>白盒模糊测试的开销通常远高于黑盒模糊测试的开销。这部分是因为DSE实现[22,42,84]经常采用动态插桩和SMT求解[142]。虽然DSE是一个活跃的研究领域[34,82,84,105,160]，但许多DSE不是白盒模糊器，因为它们的目的不是找到安全漏洞。因此，本文没有提供有关DSE的全面调查，我们将读者引用到最近的调查论文[16,173]以获取更多信息。</p><h3 id="2-4-3灰盒Fuzzer"><a href="#2-4-3灰盒Fuzzer" class="headerlink" title="2.4.3灰盒Fuzzer"></a>2.4.3灰盒Fuzzer</h3><p>一些安全专家[62,72,189]提出了一种中间方法，并将其称为灰盒模糊测试。通常，灰盒模糊器可以获得PUT内部和/或其执行的一些信息。与白盒模糊器不同，灰盒模糊器不具备PUT的完整语义;相反，他们可以对PUT执行轻量级静态分析和/或收集有关其执行的动态信息，例如覆盖范围。 Greybox模糊器使用信息近似来测试更多输入。尽管安全专家之间通常存在共识，但黑盒，灰盒和白盒模糊测试之间的区别并不总是很明显。黑盒模糊器可能仍会收集一些信息，而白盒模糊器通常被迫做一些近似。本次调查中的选择，特别是表1中的选择，是有争议的，但是作者最好的判断。</p><p>灰盒模糊器的早期示例是EFS [62]，它使用从每个模糊运行中收集的代码覆盖率来使用进化算法生成测试用例。 <code>Randoop</code> [155]也使用了类似的方法，但它没有针对安全漏洞。现代模糊器如<code>AFL</code> [211]和<code>VUzzer</code> [164]是此类别中的示例。</p><h1 id="3-预处理-PREPROCESS"><a href="#3-预处理-PREPROCESS" class="headerlink" title="3 预处理(PREPROCESS)"></a>3 预处理(PREPROCESS)</h1><p>一些模糊器在第一次模糊迭代之前修改了初始的fuzz configurations。这种预处理通常用于插桩PUT，清除潜在的冗余配置（即(seed selection)种子选择[165]），并修剪种子</p><h2 id="3-1-插桩（Instrumentation-）"><a href="#3-1-插桩（Instrumentation-）" class="headerlink" title="3.1 插桩（Instrumentation ）"></a>3.1 插桩（Instrumentation ）</h2><p>与黑盒模糊器不同，灰盒和白盒模糊器可以在InputEval执行模糊运行（参见§6），或者在运行时模糊内存内容时插桩PUT以收集执行反馈。虽然还有其他方法可以获取PUT内部的信息（例如处理器跟踪或系统调用[86,188]），但插桩通常是收集最有价值信息的方法，因此几乎完全定义了颜色。模糊（从表1的第一列）。</p><p>程序插桩可以是静态的也可以是动态的 - 前者在PUT运行之前发生，而后者在PUT运行时发生。由于静态检测在运行时之前发生，因此它通常比动态检测产生更少的运行时开销。</p><p>静态插桩通常在编译时在源代码或中间代码上执行。如果PUT依赖于库，则必须单独插桩它们，通常通过使用相同的插桩重新编译它们。除了基于源代码的插桩，研究人员还开发了二进制级静态插桩（即二进制重写）工具[71,122,218]。</p><p>虽然它比静态插桩具有更高的开销，但动态插桩的优势在于它可以轻松地插桩动态链接库，因为插桩是在运行时执行的。有几种众所周知的动态插桩工具，如<code>DynInst</code>[161]，<code>DynamoRIO</code> [38]，<code>Pin</code>[131]，<code>Valgrind</code> [152]和<code>QEMU</code> [30]。通常，动态插桩在运行时发生，这意味着它对应于模型中的InputEval。但为了方便读者，我们在本节中总结了静态和动态插桩。</p><p>给定的模糊器可以支持多种类型的插桩。例如，AFL在源代码级别使用修改后的编译器支持静态插桩，或者在QEMU的帮助下支持二进制级别的动态插桩[30]。使用动态插桩时，AFL可以插桩（1）PUT本身的可执行代码（默认设置），或者（2）PUT中的可执行代码和任何外部库（使用AFL_INST_LIBS选项）。第二个选项 - 插桩所有遇到的代码 - 可以报告外部库中代码的覆盖信息，从而提供有关覆盖范围的更完整的图像。但是，这反过来会导致AFL模糊外部库函数中的其他路径。</p><h3 id="3-1-1执行反馈（Execution-Feedback-）"><a href="#3-1-1执行反馈（Execution-Feedback-）" class="headerlink" title="3.1.1执行反馈（Execution Feedback. ）"></a>3.1.1执行反馈（Execution Feedback. ）</h3><p>灰盒模糊器通常将执行反馈作为输入来演化测试用例。 AFL及其后代通过检测PUT中的每个分支指令来计算分支覆盖。但是，它们将分支覆盖信息存储在一个byte向量中，这可能导致路径冲突。 <code>CollAFL</code> [77]最近通过引入一个新的路径敏感哈希函数来解决这个问题。同时，<code>LibFuzzer</code> [7]和<code>Syzkaller</code> [198]使用节点覆盖作为执行反馈。<code>Honggfuzz</code>[188]允许用户选择要使用的执行反馈。</p><h3 id="3-1-2-内存模糊测试（In-Memory-Fuzzing-）"><a href="#3-1-2-内存模糊测试（In-Memory-Fuzzing-）" class="headerlink" title="3.1.2 内存模糊测试（In-Memory Fuzzing ）"></a>3.1.2 内存模糊测试（In-Memory Fuzzing ）</h3><p>在测试大型程序时，有时需要仅模糊PUT的一部分而不为每个模糊迭代重新生成进程，以便最小化执行开销。例如，复杂（例如，GUI）应用程序在接受输入之前通常需要几秒钟的处理。模糊这些程序的一种方法是在初始化GUI之后拍摄PUT的快照。为了模糊新的测试用例，可以在将新测试用例直接写入内存并执行之前恢复内存快照。同样的直觉适用于涉及客户端和服务器之间的大量交互的模糊网络应用程序。这种技术称为内存模糊[97]。例如，<code>GRR</code> [86,194]在加载任何输入字节之前创建快照。这样，它可以跳过不必要的启动代码。 AFL还使用fork服务器来避免一些流程启动成本。尽管它与内存模糊测试具有相同的动机，但是fork服务器涉及为每个模糊迭代分离一个新进程（参见§6）。</p><p>一些模糊器[7,211]对函数执行内存模糊测试，而不会在每次迭代后恢复PUT的状态。我们称这种技术为内存API模糊测试。例如，AFL有一个名为persistent mode [213]的选项，它在循环中重复执行内存API模糊测试而不重新启动进程。在这种情况下，AFL忽略了在同一执行中被多次调用的函数的潜在副作用。</p><p>虽然有效的内存API模糊测试会受到不合理的模糊测试结果的影响：内存模糊测试中发现的错误（或崩溃）可能无法重现，因为（1）为目标函数构造有效的调用上下文并不总是可行的，并且（ 2）可能存在多个函数调用未捕获的副作用。请注意，内存中API模糊的健全性主要取决于入口点函数，找到这样的函数是一项具有挑战性的任务。</p><h3 id="3-1-3线程调度（Thread-Scheduling-）"><a href="#3-1-3线程调度（Thread-Scheduling-）" class="headerlink" title="3.1.3线程调度（Thread Scheduling ）"></a>3.1.3线程调度（Thread Scheduling ）</h3><p>竞争条件错误可能难以触发，因为它们依赖于可能不经常发生的非确定性行为。但是，通过显式控制线程的调度方式，也可以使用插桩来触发不同的非确定性程序行为[43,410,121,157,169,174,175]。现有工作表明，即使是随机调度线程也可以有效地找到竞争条件错误[174]。</p><h2 id="3-2-种子选择（seed-selection-problem）"><a href="#3-2-种子选择（seed-selection-problem）" class="headerlink" title="3.2 种子选择（seed selection problem）"></a>3.2 种子选择（seed selection problem）</h2><p>回忆§2，模糊器接收一组控制fuzzing algorithm行为的fuzz configurations。不幸的是，fuzz configurations的一些参数，例如基于突变的模糊器的种子，具有大的值域。例如，假设分析师模糊测试接受MP3文件作为输入的MP3播放器。有无数的有效MP3文件，这提出了一个自然的问题：我们应该使用哪些种子进行模糊测试？这个问题被称为(<strong>seed selection problem</strong> )种子选择问题[165]。</p><p>有几种方法和工具可以解决种子选择问题[70,165]。常见的方法是找到最大化覆盖度量的最小种子集，例如节点覆盖，并且该过程称为计算最小集。例如，假设当前配置集C由两个seeds s1和s2组成，它们覆盖PUT的以下地址：{s1→{10,20}，s2→{20,30}}。如果我们有第三个种子s3→{10,20,30}的执行速度与s1和s2一样快，那么人们可能会认为fuzz s3而不是s1和s2是有意义的，因为它直观地测试了更多程序逻辑以一半的执行时间成本。这种直觉得到了Miller的报告[140]的支持，该报告显示，代码覆盖率增加1％会使发现的错误百分比增加0.92％。如§7.2所述，此步骤也可以是ConfUpdate的一部分。</p><p>Fuzzers在实践中使用各种不同的覆盖度量。例如，AFL的minset基于分支覆盖，每个分支上都有一个对数计数器。该决定背后的基本原理是，只有当分支计数在数量级上不同时才允许它们被认为是不同的。 Honggfuzz [188]根据执行指令数，执行分支数和唯一基本块计算覆盖率。此度量标准允许模糊器向minset添加更长的执行时间，这有助于发现拒绝服务漏洞或性能问题。</p><h2 id="3-3-种子修剪（Seed-Trimming-）"><a href="#3-3-种子修剪（Seed-Trimming-）" class="headerlink" title="3.3 种子修剪（Seed Trimming ）"></a>3.3 种子修剪（Seed Trimming ）</h2><p>较小的种子可能消耗较少的内存并且意味着更高的吞吐量。因此，一些模糊器试图在模糊种子之前减小种子的尺寸，这称为种子修剪。种子修剪可以在Preprocess中的主模糊循环之前或作为ConfUpdate的一部分进行。使用种子修剪的一个值得注意的模糊器是AFL [211]，只要修改后的种子达到相同的覆盖范围，它就使用其代码覆盖率插桩迭代地移除一部分种子。同时，雷伯特等人 [165]报道，他们的size minset算法，通过给予较小的种子更高优先级来选择种子，与随机种子选择相比，导致更少数量的独特错误。</p><h2 id="3-4准备驱动程序"><a href="#3-4准备驱动程序" class="headerlink" title="3.4准备驱动程序"></a>3.4准备驱动程序</h2><p>应用程序当难以直接fuzz PUT时，准备一个模糊驱动程序是有意义的。这个过程在很大程度上是手动的，尽管这只在模糊测试活动开始时才进行一次。例如，当我们的目标是库时，我们需要准备一个调用库中函数的驱动程序。类似地，内核模糊器可能会模糊用户态应用程序来测试内核[28,117,154]。 <code>MutaGen</code> [115]利用其他程序（驱动程序）中包含的PUT知识进行模糊测试。具体来说，它使用动态程序切片来改变驱动程序本身，以生成测试用例。 <code>IoTFuzzer</code> [50]通过让驱动程序成为相应的智能手机应用程序来定位物联网设备。</p><h1 id="4-调度-SEHEDULING"><a href="#4-调度-SEHEDULING" class="headerlink" title="4 调度(SEHEDULING)"></a>4 调度(SEHEDULING)</h1><p>在模糊测试中，调度意味着为下一个模糊运行选择模糊配置。正如我们在§2.1中所解释的，每个配置的内容取决于模糊器的类型。对于简单的模糊器，调度可以很简单 - 例如，<code>zzuf</code> [96]在其默认模式下只允许一个配置（PUT和其他参数的默认值），因此根本没有决定。但对于更高级的模糊器，如<code>BFF</code> [45]和<code>AFLFast</code> [33]，他们成功的一个主要因素在于他们的创新调度算法。在本节中，我们将仅讨论黑盒和灰盒模糊测试的调度算法;白盒模糊测试中的调度需要符号执行器独有的复杂设置，我们将读者引用到[34]。</p><h2 id="4-1-Fuzz配置调度（FCS）问题-The-Fuzz-Configuration-Scheduling-FCS-Problem"><a href="#4-1-Fuzz配置调度（FCS）问题-The-Fuzz-Configuration-Scheduling-FCS-Problem" class="headerlink" title="4.1  Fuzz配置调度（FCS）问题(The Fuzz Configuration Scheduling (FCS) Problem)"></a>4.1  Fuzz配置调度（FCS）问题(The Fuzz Configuration Scheduling (FCS) Problem)</h2><p>调度的目标是分析当前可用的配置信息，并选择一个更有可能产生最有利结果的信息，例如，找到最多的唯一错误，或生成的输入集所达到的最大化覆盖范围。从根本上说，每个调度算法都面临相同的探索与剥削冲突，时间可以花费在收集关于每个配置的更准确信息上，以便为将来的决策（探索）提供信息，或者模糊当前被认为可以产生更有利结果的配置。 （利用）。 Woo等人 [206]将此固有冲突称为模糊配置调度（FCS）问题。</p><p>在我们的模型模糊器（算法1）中，函数Schedule基于（i）当前的模糊配置集 C，（ii）当前时间 t_elapsed，以及（iii）总时间预算 t_limit 来选择下一个配置。然后，此配置将用于下一次模糊运行。请注意，Schedule仅与决策有关。完成此决策的信息由 Preprocess 和 ConfUpdate 通过更新C获取。</p><h2 id="4-2-黑盒FCS-算法"><a href="#4-2-黑盒FCS-算法" class="headerlink" title="4.2 黑盒FCS 算法"></a>4.2 黑盒FCS 算法</h2><p>在黑盒设置中，FCS算法可以使用的唯一信息是配置的模糊结果 - 与其一起发现的崩溃和错误的数量以及到目前为止花费的时间。 <code>Householder</code>和<code>Foote</code> [100]是第一个研究如何在CERT BFF黑盒突变模糊器中利用这些信息的人[45]。他们假定应该优先选择观察成功率较高的配置（#bugs / #runs）。事实上，在替换BFF中的统一采样调度算法后，他们观察到在运行 ffmpeg 500万次中独特崩溃次数增加了85％，证明了更先进的FCS算法的潜在优势。</p><p>不久之后，Woo等人在多个方面改进了上述想法 [206]。首先，他们从[100]中的伯努利试验序列到<code>Weighted CouponCollector’s Problem with Unknown Weights</code>（WCCP / UW），改进了黑盒突变模糊测试的数学模型。前者假设每个配置具有固定的最终成功概率并且随着时间的推移而学习它，后者在衰减时明确地保持该概率的上限。其次，WCCP / UW模型自然会引领Woo等人去研究<code>multi-armed bandit</code>（MAB）问题的算法，这是一种流行的形式以应对决策科学中的探索与剥削冲突[31]。为此，他们能够设计MAB算法以准确地利用尚未发生衰减的配置。第三，他们观察到，在其他条件相同的情况下，让fuzzing更快的配置允许模糊器收集更多的独特错误，或者更快地降低其未来成功概率的上限。这激发了他们将配置的成功概率标准化为花费在其上的时间，从而使得更快的配置更加可取。第四，他们将BFF中模糊运行的编排从每个配置选择的固定运行次数（BFF用语中的“epochs”）改为每次选择的固定时间量。通过此更改，BFF不再需要在可重新选择之前花费更多时间在慢速配置中。通过组合上述内容，评估[206]显示使用与现有BFF相同的时间量发现的独特错误数量增加1.5倍。</p><h2 id="4-3-灰盒FCS算法"><a href="#4-3-灰盒FCS算法" class="headerlink" title="4.3 灰盒FCS算法"></a>4.3 灰盒FCS算法</h2><p>在灰盒设置中，FCS算法可以选择使用关于每种配置的更丰富的信息集，例如，在模糊配置时获得的覆盖范围。 AFL [211]是此类别的先行者，它基于进化算法（EA）。直观地，EA维持一组配置，每个配置具有一些“适应性”值。 EA选择合适的配置并将其应用于遗传转化，例如突变和重组，以产生后代，后代可能成为新的配置。假设是这些产生的配置更可能适合。</p><p>要在EA的上下文中理解FCS，我们需要定义<strong>（i）使配置适合的内容是什么，（ii）如何选择配置，以及（iii）如何使用所选配置</strong>。作为高级近似法，在执行控制流边缘的配置中，AFL认为包含最快和最小输入的那个适合（AFL用语中的“favorite”）。 AFL维护一个配置队列，从中选择下一个匹配配置，就好像队列是循环的一样。一旦选择了配置，AFL就会使其基本上以恒定的运行次数进行模糊处理。从FCS的角度来看，请注意快速配置的首选项与黑盒设置的[206]相同。</p><p>最近，Böhme等人的AFLFast [33]在上述三个方面的每个方面都改进了AFL。首先，AFLFast为输入添加了两个最重要的标准，使其成为“favorite”：（i）在执行控制流边缘的配置中，AFLFast倾向于选择最少的输入。这具有在执行该边缘的配置之间循环的效果，从而增加了探索。 （ii）当（i）中存在平局时，AFLFast倾向于选择其中执行最少路径的那个。这具有增加稀有路径的执行效果，这可能揭示更多未观察到的行为。其次，AFLFast放弃了AFL中的循环选择，而是根据优先级选择下一个拟合配置。特别是，如果选择配置的频率较低，或者在平局时，如果它运行的路径较少，则适配配置的优先级高于另一配置。与第一次改变的想法相同，这具有增加适合配置和稀有路径执行的探索的效果。第三，AFLFast根据能量计划确定所选配置的次数变量。 AFLFast中的FAST能量计划以较小的“能量”值开始，以确保配置之间的初始探索，并以指数方式增加到极限，以快速确保充分利用。此外，它还通过生成相同路径的生成输入的数量来标准化能量，从而促进对频率较低的模糊配置的探索。这些变化的总体影响非常显着 - 在24小时的评估中，Böhme等人观察到AFLFast发现了AFL没有发现的3个错误，并且在两者都发现的6个错误上比AFL快7倍。 AFLGo [32]通过修改其优先级来扩展AFLFast，以便针对特定的程序位置。 QTEP [200]使用静态分析来推断二进制文件的哪个部分更“错误”并优先考虑覆盖它们的配置。</p><h1 id="5-输入生成-INPUT-GENERATION"><a href="#5-输入生成-INPUT-GENERATION" class="headerlink" title="5.输入生成(INPUT GENERATION)"></a>5.输入生成(INPUT GENERATION)</h1><p>由于测试用例的内容直接控制是否触发bug，因此输入生成技术自然是模糊测试中最有影响力的设计决策之一。传统上，模糊器分为基于生成或基于突变的模糊器[187]。基于生成的模糊器基于给定模型生成测试用例，该模型描述了PUT期望的输入。我们在本文中称这种模糊器为基于模型的模糊器。另一方面，基于突变的模糊器通过改变给定的种子输入来产生测试案例。基于突变的模糊器通常被认为是无模型的，因为种子仅仅是示例输入，并且即使在大量数量下它们也不能完全描述PUT的预期输入空间。在本节中，我们将基于底层测试用例生成（InputGen）机制对模糊器使用的各种输入生成技术进行解释和分类。</p><h2 id="5-1基于模型（基于生成）的模糊器"><a href="#5-1基于模型（基于生成）的模糊器" class="headerlink" title="5.1基于模型（基于生成）的模糊器"></a>5.1基于模型（基于生成）的模糊器</h2><p>基于模型的模糊器基于给定模型生成测试用例，该模型描述了PUT可以接受的输入或执行，例如精确表征输入格式的语法或不太精确的约束,例如标识文件类型的magic值。</p><h3 id="5-1-1预定义模型"><a href="#5-1-1预定义模型" class="headerlink" title="5.1.1预定义模型"></a>5.1.1预定义模型</h3><p>一些模糊器使用可由用户配置的模型。例如，Peach [70]，PROTOS [112]和Dharma [3]接受用户提供的规范。 Autodafé [197]，Sulley [15]，SPIKE [13]和SPIKEfile [186]公开了API，允许分析师创建自己的输入模型。 Tavor [219]还接受以Extended Backus-Naur形式（EBNF）编写的输入规范，并生成符合相应语法的测试用例。类似地，诸如PROTOS [112]，SNOOZE [26]，KiF [12]和T-Fuzz [107]之类的网络协议模糊器也接受来自用户的协议规范。内核API模糊器[108,146,151,198,203]以系统调用模板的形式定义输入模型。这些模板通常指定系统调用期望作为输入的参数的数量和类型。在内核模糊测试中使用模型的想法源于Koopman等人 [119]开创性的工作，他们将操作系统的稳健性与一系列有限的手动选择的系统调用测试用例进行了比较。</p><p>其他基于模型的模糊器针对特定的语言或语法，并且该语言的模型内置于模糊器本身。例如，<code>cross_fuzz</code> [212]和<code>DOMfuzz</code> [143]生成随机文档对象模型（DOM）对象。同样，<code>jsfunfuzz</code> [143]基于其自己的语法模型生成随机但语法正确的JavaScript代码。 <code>QuickFuzz</code> [88]利用现有的Haskell库来描述生成测试用例时的文件格式。一些网络协议模糊器如<code>Frankencerts</code> [37]，TLS-Attacker [180]<code>，</code>tlsfuzzer <code>[116]</code>和<code>llfuzzer</code>[182]设计有特定网络协议模型，如TLS和NFC。 Dewey等人[63,64]提出了一种生成测试用例的方法，这些测试用例不仅语法正确，而且通过利用约束逻辑编程也具有语义多样性。<code>LangFuzz</code> [98]通过解析作为输入给出的一组种子来产生代码片段。然后它随机组合片段，并将种子与片段一起变异以生成测试用例。由于它提供了语法，因此它始终生成语法正确的代码。 LangFuzz应用于JavaScript和PHP。 BlendFuzz [210]基于与LangFuzz类似的想法，但它以XML和正则表达式解析器为目标。</p><h3 id="5-1-2-推断模型"><a href="#5-1-2-推断模型" class="headerlink" title="5.1.2 推断模型"></a>5.1.2 推断模型</h3><p>推断模型而不是依赖于预定义的逻辑或用户提供的模型获得牵引力。虽然有大量关于自动输入格式和协议逆向工程主题的已发表研究[25,41,57,60,128]，但只有少数模糊测试者利用这些技术。模型推断可以分两个阶段完成：<code>Preprocess</code>或<code>ConfUpdate</code>。<br>Preprocess中的模型推理。一些模糊推测器将模型推断为模糊运动之前的第一步。 TestMiner [61]使用代码中可用的数据来挖掘和预测合适的输入。 Skyfire [199]使用数据驱动方法从给定语法和一组输入样本生成一组种子。与以前的作品不同，他们的重点是生成一组语义上有效的新种子。 IMF [93]通过分析系统API日志来学习内核API模型，并生成使用推断模型调用一系列API调用的C代码。 Neural [56]和Learn＆Fuzz [85]使用基于神经网络的机器学习技术从给定的一组测试文件中学习模型，并使用推断的模型生成测试用例。Liu等人[129]提出了一种特定于文本输入的类似方法。</p><p>ConfUpdate中的模型推断。在每个模糊迭代中都有模糊器更新模型。 PULSAR [79]从捕获到的程序生成的一组的网络数据包中自动的推断出网络协议模型。然后，学习的网络协议用于模糊程序。 PULSAR在内部构建状态机，并映射哪个消息令牌与状态相关。此信息稍后用于生成覆盖状态机中更多状态的测试用例。 Doupé等人 [67]提出了一种通过观察I / O行为来推断Web服务的状态机的方法。然后使用推断的模型来扫描Web漏洞。Ruiter等人 [168]工作类似，但目标是TLS，并将其实施基于<code>LearnLib</code> [162]。最后，<code>GLADE</code> [27]从一组I / O样本中合成了一个无上下文语法，并使用推断的语法来模糊PUT。</p><h2 id="5-2-无模型（基于突变）的模糊器"><a href="#5-2-无模型（基于突变）的模糊器" class="headerlink" title="5.2 无模型（基于突变）的模糊器"></a>5.2 无模型（基于突变）的模糊器</h2><p>经典随机测试[19,92]在生成满足特定路径条件的测试用例时效率不高。假设有一个简单的C语句：if（input == 42）。如果输入是32位整数，则随机猜测正确输入值的概率是2的32次方之一。当我们考虑结构良好的输入（如MP3文件）时，情况会变得更糟。随机测试极不可能在合理的时间内生成有效的MP3文件作为测试用例。因此，MP3播放器将主要在到达程序的更深层部分之前的解析阶段拒绝从随机测试中生成的测试用例。</p><p>这个问题促使使用基于种子的输入生成以及白盒输入生成（见§5.3）。大多数无模型模糊器使用种子，它是PUT的输入，以便通过改变种子来生成测试用例。<br>种子通常是PUT支持的类型的结构良好的输入：文件，网络包或一系列UI事件。通过仅改变有效文件的一小部分，通常可以生成大多数有效的新测试用例，但也包含异常值以触发PUT的崩溃。有多种方法可用于改变种子，我们将在下面描述常见的方法。</p><h3 id="5-2-1-比特翻转"><a href="#5-2-1-比特翻转" class="headerlink" title="5.2.1 比特翻转"></a>5.2.1 比特翻转</h3><p>比特翻转是许多无模型模糊器使用的常用技术[6,95,96,188,211]。一些模糊器简单地翻转固定数量的比特，而其他模糊器确定随机翻转的比特数。为了随机改变种子，一些模糊器使用一个称为突变比的用户可配置参数，该参数确定单次执行InputGen时要翻转的位位置数。假设一个模糊器想要从给定的N位种子中翻转K个随机位。在这种情况下，模糊器的突变比是K / N.<br><code>SymFuzz</code>等 [48]表明模糊性能对突变率非常敏感，并且没有一个比率适用于所有PUT。有几种方法可以找到良好的突变率。 BFF [45]和FOE [46]使用每个种子的指数缩放比例集，并将更多迭代分配给证明在统计学上有效的突变比[100]。 SymFuzz [48]利用白盒程序分析来推断出良好的突变率。然而，请注意，所提出的技术仅考虑推断单个最佳突变比率。使用多个突变比率进行模糊测试比使用单个最佳比率进行模糊测试更有可能，这仍然是一个开放的研究挑战。</p><h3 id="5-2-2-算术变异"><a href="#5-2-2-算术变异" class="headerlink" title="5.2.2 算术变异"></a>5.2.2 算术变异</h3><p>AFL [211]和honggfuzz [188]包含另一个变异操作，它将所选字节序列视为整数，并对该值执行简单算术。然后使用计算的值替换所选的字节序列。关键的直觉是通过少量的数值来限制突变的影响。例如，AFL从种子中选择一个4字节的值，并将该值视为整数 i。然后用 i ± r 替换种子中的值，其中r是随机生成的小整数。 r的范围取决于模糊器，通常是用户可配置的。在AFL中，默认范围是：0≤r&lt;35。</p><h3 id="5-2-3-基于块的变"><a href="#5-2-3-基于块的变" class="headerlink" title="5.2.3 基于块的变"></a>5.2.3 基于块的变</h3><p>有几种基于块的变异方法，其中块是种子的字节序列：（1）将随机生成的块插入种子的随机位置[7,211]; （2）从种子中删除随机选择的块[7,95,188,211]; （3）用随机值替换随机选择的块[7,95,188,211]; （4）随机置换一系列块的顺序[7,95]; （5）通过附加随机区块来调整种子的大小[188]; （6）从种子中取一个随机块来插入/替换另一个种子的随机块[7,211]。</p><h3 id="5-2-4-基于字典的变异"><a href="#5-2-4-基于字典的变异" class="headerlink" title="5.2.4 基于字典的变异"></a>5.2.4 基于字典的变异</h3><p>一些模糊器使用具有潜在显着语义权重的一组预定义值，例如0或-1，以及用于变异的格式字符串。例如，AFL [211]，honggfuzz [188]和LibFuzzer [7]在变换整数时使用诸如0，-1和1的值。 Radamsa [95]使用Unicode字符串，GPF [6]使用格式字符（如％x和％s）来改变字符串。</p><h2 id="5-3-白盒模糊器"><a href="#5-3-白盒模糊器" class="headerlink" title="5.3 白盒模糊器"></a>5.3 白盒模糊器</h2><p>白盒模糊器也可以分为基于模型或无模型的模糊器。例如，传统的动态符号执行[24,84,105,134,184]在基于变异的模糊器中不需要任何模型，但一些符号执行器[82,117,160]利用输入模型，如输入语法指导符号执行。</p><p>虽然许多白盒模糊器包括Godefroid等人[84]的开创性工作使用动态符号执行来生成测试用例，但并非所有的白盒模糊器都是动态符号执行器。一些模糊器[48,132,170,201]利用白盒程序分析来查找有关PUT接受的输入的信息，以便将其与黑盒或灰盒模糊测试一起使用。在本小节的其余部分中，我们将基于其基础测试用例算法简要总结现有的白盒模糊测试技术。请注意，我们故意省略动态符号执行器，如[42,47,54,83,176,192]，除非他们明确称自己为§2.2中提到的模糊器。</p><h3 id="5-3-1-动态符号执行"><a href="#5-3-1-动态符号执行" class="headerlink" title="5.3.1 动态符号执行"></a>5.3.1 动态符号执行</h3><p>在高级别，经典的符号执行[35,101,118]运行一个带有符号值作为程序的输入，它代表所有可能的值。在执行PUT时，它会构建符号表达式，而不是评估具体值。每当它到达条件分支指令时，它在概念上分叉两个符号解释器，一个用于真正的分支，另一个用于假分支。对于每个路径，符号解释器为执行期间遇到的每个分支指令构建路径公式（或路径谓词）。如果存在执行所需路径的具体输入，则路径公式是可满足的。可以通过查询SMT求解器[142]来生成具体输入，以获得路径公式的解。动态符号执行是传统符号执行的变体，其中符号执行和具体执行同时运行。这个想法是具体的执行状态可以帮助减少符号约束的复杂性。除了应用于模糊测试之外，对动态符号执行的学术文献的广泛回顾超出了本文的范围。然而，动态符号执行的更广泛处理可以在[16,173]中找到。</p><h3 id="5-3-2-引导式模糊测试"><a href="#5-3-2-引导式模糊测试" class="headerlink" title="5.3.2 引导式模糊测试"></a>5.3.2 引导式模糊测试</h3><p>一些模糊器利用静态或动态程序分析技术来增强模糊测试的有效性。这些技术通常涉及两个阶段的模糊测试：（i）用于获得关于PUT的有用信息的昂贵程序分析，以及（ii）在先前分析的指导下生成测试用例。这在表1的第六列（第9页）中表示。例如，TaintScope [201]使用细粒度污点分析来查找“热字节”，这是流入关键系统调用或API调用的输入字节。其他安全研究人员提出了类似的想法[69,103]。 Dowser [91]在编译期间执行静态分析，以找到可能包含基于启发式的错误的循环。具体来说，它查找包含指针解引用的循环。然后，它使用污点分析计算输入字节和候选循环之间的关系。最后，Dowser运行动态符号执行，同时只使关键字节成为符号，从而提高性能。VUzzer [164]和GRT [132]利用静态和动态分析技术从PUT中提取控制和数据流特征，并使用它们来指导输入生成。 Angora [50]通过使用污点分析将每个路径约束与相应的字节相关联来改进“热字节”的想法。然后，它通过梯度下降算法进行搜索，以指导其突变以解决这些约束。</p><h3 id="5-3-3-PUT-突变"><a href="#5-3-3-PUT-突变" class="headerlink" title="5.3.3 PUT 突变"></a>5.3.3 PUT 突变</h3><p>模糊测试的一个实际挑战是绕过校验和验证。例如，当PUT在解析输入之前计算输入的校验和时，来自模糊器的大多数生成的测试用例将被PUT拒绝。为了应对这一挑战，TaintScope [201]提出了一种校验和感知模糊测试技术，该技术通过污点分析识别校验和测试指令，并修补PUT以绕过校验和验证。一旦发现程序崩溃，它们就会为输入生成正确的校验和，以生成一个崩溃未修改的PUT的测试用例。 Caballero [40]提出了一种称为拼接动态符号执行的技术，它可以在校验和存在的情况下生成测试用例。</p><p>T-Fuzz [158]扩展了这个想法，通过灰盒模糊来有效地穿透所有类型的条件分支。它首先构建一组非关键检查（NCC），这些检查是可以在不修改程序逻辑的情况下进行转换的分支。当模糊测试活动停止发现新路径时，它会选择NCC，对其进行转换，然后在修改后的PUT上重新启动模糊测试活动。最后，当发现崩溃模糊转换程序时，T-Fuzz尝试使用符号执行在原始程序上重建它。</p><h1 id="6-输入评估"><a href="#6-输入评估" class="headerlink" title="6. 输入评估"></a>6. 输入评估</h1><p>生成输入后，模糊器执行输入，并决定如何处理该输入。由于模糊测试的主要动机是发现违反安全策略的行为，因此模糊测试程序必须能够检测到执行违反安全策略的行为。该策略的实现称为bug oracle，O_bug（参见§2.1）。 oracle标记的输入通常在被分类后写入磁盘。如算法1所示，为模糊器生成的每个输入调用oracle。因此，oracle能够有效地确定输入是否违反安全策略是至关重要的。</p><p>回想一下§3，一些模糊器还在执行每个输入时收集附加信息，以改善模糊测试过程。 Preprocess和InputEval在许多模糊器中彼此紧密耦合，因为检测到的PUT（来自Preprocess）将在执行时输出附加信息（来自InputEval）。</p><h2 id="6-1执行优化"><a href="#6-1执行优化" class="headerlink" title="6.1执行优化"></a>6.1执行优化</h2><p>我们的模型考虑按顺序执行单个模糊迭代。虽然这种方法的直接实现只是在每次模糊迭代开始时开始新过程时加载PUT，但是可以显着加速重复加载过程。为此，现代模糊器提供了跳过这些重复加载过程的功能。例如，AFL [211]提供了一个fork-server，它允许每个新的模糊迭代从已经初始化的进程中fork。类似地，内存中模糊测试是优化执行速度的另一种方法，如第3.1.2节中所述。无论确切的机制如何，加载和初始化PUT的开销都会在很多次迭代中摊销。Xu等人 [209]通过设计一个替换fork（）的新系统调用，进一步降低了迭代的成本。</p><h2 id="6-2-Bug-Oracles"><a href="#6-2-Bug-Oracles" class="headerlink" title="6.2  Bug Oracles"></a>6.2  Bug Oracles</h2><p>与模糊测试一起使用的规范安全策略认为每个程序执行都会被致命信号（例如分段错误）终止。此策略检测到许多内存漏洞，因为使用无效值覆盖数据或代码指针的内存漏洞通常会导致分段错误或在取消引用时中止。此外，该策略高效且易于实现，因为操作系统允许模糊器在没有任何仪器的情况下捕获这种异常情况。</p><p>但是，传统的检测崩溃的策略不会检测到触发的每个内存漏洞。例如，如果堆栈缓冲区溢出使用有效的内存地址覆盖堆栈上的指针，则程序可能会运行完成且结果无效而不是崩溃，并且模糊器不会检测到此情况。为了缓解这种情况，研究人员提出了各种有效的程序转换，可以检测不安全或不需要的程序行为并中止程序。这些通常被称为<code>sanitizers</code>。</p><p><strong>内存和类型安全</strong>。内存安全错误可以分为两类：空间和时间。非正式地，当指针被访问到其预期范围之外时，会发生空间存储器错误。例如，缓冲区溢出和下溢是空间内存错误的典型示例。在指针不在有效后访问时会发生时间内存错误。例如，use-after-free 漏洞，当一片内存的指针被释放之后又被使用，这是典型的时间内存错误。</p><p><code>Address Sanitizer（ASan）</code>[177]是一个快速存储器错误检测器，可在编译时检测程序。 ASan可以检测空间和时间内存错误，平均减速仅为73％，使其成为基本碰撞安全带的有吸引力的替代品。 ASan采用了一个影子存储器，允许每个存储器地址在被解除引用之前被快速检查其有效性，从而允许它检测许多（但不是全部）不安全的存储器访问，即使它们不会使原始程序崩溃。 MEDS [94]通过利用64位虚拟空间提供的近乎无限的内存空间并创建<code>redzones</code>来改进ASAN。</p><p><code>SoftBound / CETS</code>[148,149]是另一种在编译过程中监控程序的内存错误检测器。然而，SoftBound / CETS不是像ASan那样跟踪有效的内存地址，而是将边界和时间信息与每个指针相关联，理论上可以检测所有空间和时间内存错误。然而，正如预期的那样，这种完整性带来了更高的平均开销116％[149]。</p><p><code>CaVer</code>[123]，<code>TypeSan</code>[90]和<code>HexType</code>[106]在编译期间插桩程序，以便它们可以检测C ++类型转换中的错误转换。当对象转换为不兼容的类型时，例如当基类的对象强制转换为派生类型时，会发生错误的转换。事实证明，CaVer可以扩展到Web浏览器，这些浏览器历来包含这种类型的漏洞，并且开销在7.6到64.6％之间。</p><p>另一类存储器安全保护是控制流完整性[10,11]（CFI），它在运行时检测原始程序中不可能的控制流转换。 CFI可用于检测非法修改程序控制流的测试用例。最近一个专注于防范CFI违规子集的项目已经进入主流gcc和clang编译器[191]。</p><p><strong>未定义的行为</strong>。诸如C之类的语言包含许多由语言规范未定义的行为。编译器可以以各种方式自由处理这些构造。在许多情况下，程序员可以（有意或无意地）编写他们的代码，这样它只对某些编译器实现是正确的。虽然这看起来似乎不太危险，但许多因素都会影响编译器如何实现未定义的行为，包括优化设置，体系结构，编译器甚至编译器版本。当编译器的未定义行为的实现与程序员的期望不匹配时，通常会出现漏洞和错误[202]。</p><p><code>Memory Sanitizer（MSan）</code>是一种工具，可以在编译期间检测程序，以检测由于在C和C ++中使用未初始化的内存而导致的未定义行为[183]。与ASan类似，MSan使用一个影子内存来表示每个可寻址位是否已初始化。 Memory Sanitizer的开销约为150％。</p><p><code>Undefied Behavior Sanitizer（UBSan）</code>[65]在编译时修改程序以检测未定义的行为。与其他专注于未定义行为的特定来源的检测工具不同，UBSan可以检测各种未定义的行为，例如使用未对齐的指针，除以零，解除引用空指针和整数溢出。</p><p><code>Thread Sanitizer（TSan）</code>[178]是一种编译时修改，它通过精度和性能之间的权衡来检测数据竞争。当两个线程同时访问共享内存位置并且至少一个访问是写入时，发生数据争用。这样的错误可能导致数据损坏，并且由于非确定性而极难重现。</p><p><strong>输入验证</strong>。测试输入验证漏洞（如XSS（跨站点脚本）和SQL注入漏洞）是一个具有挑战性的问题，因为它需要了解为Web浏览器和数据库引擎提供支持的非常复杂的解析器的行为。<code>KameleonFuzz</code> [68]通过使用真实Web浏览器解析测试用例，提取文档对象模型树，并将其与人工提取的XSS工具模式进行比较来检测成功的XSS攻击。 <code>μ4SQLi</code>[17]使用类似的技巧来检测SQL注入。由于无法从Web应用程序响应中可靠地检测SQL注入，因此μ4SQLi使用数据库代理拦截目标Web应用程序与数据库之间的通信，以检测输入是否触发了有害行为。</p><p><strong>语义差异</strong>。通常通过比较类似（但不同）的程序来发现语义错误。它通常被称为差分测试[135]，并被几个模糊器[37,53,159]使用。在这种情况下，bug oracle是作为一组类似的程序给出的。Jung等人 [111]引入了术语黑盒差分模糊测试，它测量了给定两个或更多不同输入的PUT输出之间的差异。根据输出之间的差异，它们检测PUT的信息泄漏。</p><h2 id="6-3-分类"><a href="#6-3-分类" class="headerlink" title="6.3 分类"></a>6.3 分类</h2><p>分类是分析和报告导致违反策略的测试用例的过程。分类可以分为三个步骤：重复数据删除，优先级排序和测试用例最小化。</p><h3 id="6-3-1-重复数据删除"><a href="#6-3-1-重复数据删除" class="headerlink" title="6.3.1 重复数据删除"></a>6.3.1 重复数据删除</h3><p>重复数据删除是从输出集中修剪与其它测试样例触发相同的错误的测试样例的过程，理想情况下，重复数据删除会返回一组测试用例，其中每个测试用例都会触发一个独特的错误。</p><p>由于多种原因，重复数据删除是大多数模糊器的重要组成部分。作为一种实际的实现方式，它通过在删除硬盘上存储重复的结果来避免浪费磁盘空间和其他资源。作为可用性考虑因素，重复数据删除使用户可以轻松了解存在多少不同的错误，并能够分析每个错误的示例。这对各种模糊用户都很有用；例如，攻击者可能只想查看可能导致可靠利用的“home run”漏洞。</p><p>目前在实践中使用了两种主要的重复数据删除实现：<code>堆栈回溯哈希</code>和<code>基于覆盖的重复数据删除</code>。</p><p><strong>堆栈回溯哈希</strong>(Stack Backtrace Hashing )。堆栈回溯哈希[141]是用于重复数据删除崩溃的最古老和最广泛使用的方法之一，其中自动化工具在崩溃时记录堆栈回溯，并根据该回溯的内容分配堆栈散列。例如，如果程序在函数foo中执行一行代码时崩溃，并且调用堆栈为main→d→c→b→a→foo，那么n = 5的堆栈回溯散列实现会将所有执行组合在一起回溯以d→c→b→a→foo结束。</p><p>堆栈哈希实现差别很大，从哈希中包含的堆栈帧数开始。一些实现使用一个[18]，三个[141,206]，五个[45,76]，或者没有任何限制[115]。实现方式也包括每个堆栈帧中包含的信息量。某些实现只会哈希函数的名称或地址，但其他实现将哈希名称和偏移量或行。这两个选项都不能很好地工作，因此一些实现[76,137]产生两个哈希：主要和次要哈希。主要哈希很可能将不同的崩溃组合在一起，因为它只散列函数名称，而次要散列更精确，因为它使用函数名称和行号，并且还包括无限数量的堆栈帧。</p><p>虽然堆栈回溯哈希被广泛使用，但它并非没有缺点。堆栈回溯哈希的基本假设是类似的崩溃是由类似的错误引起的，反之亦然，但据我们所知，这个假设从未被直接测试过。有一些理由怀疑它的真实性：在导致崩溃的代码附近不会发生一些崩溃。例如，导致堆损坏的漏洞可能仅在代码的不相关部分尝试分配内存时崩溃，而不是在发生堆溢出时崩溃。</p><p><strong>基于覆盖的重复数据删除</strong>（Coverage-based Deduplication ）。 AFL [211]是一种流行的灰盒模糊器，它采用高效的源代码检测器来记录PUT每次执行的边缘覆盖范围，并测量每个边缘的粗略命中计数。作为灰盒模糊器，AFL主要使用此覆盖信息来选择新的种子文件。但是，它也会导致相当独特的重复数据删除方案。正如其文档中所描述的那样，如果（i）碰撞覆盖了以前看不见的边缘，或者（ii）碰撞未覆盖所有早期碰撞中存在的边缘，AFL认为碰撞是唯一的。</p><p><strong>语义感知的重复数据删除</strong>。Cui等人[59]提出了一个名为RETracer的系统，根据从反向数据流分析中恢复的语义对崩溃进行分类。具体来说，在崩溃之后，RETracer会检查哪个指针导致崩溃，并以递归方式识别哪个指令为其分配了错误值。它最终找到一个具有最大帧级别的函数，并“blames”该函数。blames功能可用于群集崩溃。作者表明，他们的技术成功地将数百万个Internet Explorer bugs合并为一个，这些漏洞通过堆栈散列分散到大量不同的组中。</p><h3 id="6-3-2-优先级和可利用性"><a href="#6-3-2-优先级和可利用性" class="headerlink" title="6.3.2 优先级和可利用性"></a>6.3.2 优先级和可利用性</h3><p>优先级，a.k.a.fuzzer taming问题[52]，是根据严重性和唯一性对违反测试用例进行排名或分组的过程。传统上使用模糊测试来发现内存漏洞，在这种情况下，优先级更好地称为确定崩溃的可利用性。可利用性非正式地描述了攻击者能够为测试用例暴露的漏洞编写实际漏洞的可能性。防御者和攻击者都对可利用的漏洞感兴趣。防御者通常会在不可利用的漏洞之前修复可利用的漏洞，并且出于显而易见的原因，攻击者对可利用的漏洞感兴趣。</p><p>第一个可利用性排名系统之一是Microsoft的 <code></code>!exploitable` [137]，它的名字来自它提供的 !exploitable 的WinDbg命令名称。 ！exploitable采用了几种启发式方法，并配有简化的污点分析[153,173]。它按以下严重性等级对每次崩溃进行分类：EXPLOITABLE&gt; PROBABLY_EXPLOITABLE&gt; UNKNOWN&gt; NOT_LIKELY_EXPLOITABLE，其中x&gt; y表示x比y严重。虽然这些分类没有正式定义，但是可利用的非正式意图是保守和错误报告的东西比它更具可利用性。例如，！exploitable断定，如果执行非法指令，则崩溃是可利用的，这是基于攻击者能够劫持控制流的假设。另一方面，除零崩溃被视为NOT_LIKELY_EXPLOITABLE。</p><p>自从！exploitable被引入以来，已经提出了其他类似的基于规则的启发式系统，包括GDB [76]和Apple的<code></code>CrashWrangler `[18]的可利用插件。然而，它们的正确性尚未得到系统的研究和评估。</p><h3 id="6-3-3测试用例最小化"><a href="#6-3-3测试用例最小化" class="headerlink" title="6.3.3测试用例最小化"></a>6.3.3测试用例最小化</h3><p>分类的另一个重要部分是测试用例最小化。测试用例最小化是识别触发违规所必需的违规测试用例部分的过程，并且可选地产生比原始测试用例更小且更简单但仍然导致违规的测试用例。</p><p>一些模糊器使用自己的实现和算法。 BFF [45]包括针对模糊测试[99]的最小化算法，其尝试最小化与原始种子文件不同的比特数。AFL [211]还包括一个测试用例最小化器，它试图通过机会性地将字节设置为零并缩短测试用例的长度来简化测试用例。<code>Lithium</code>[167]是一种通用测试用例最小化工具，它通过尝试以指数递减的大小删除相邻行或字节的“块”来最小化文件。Lithium是由JavaScript模糊器（如jsfunfuzz [143]）生成的复杂测试案例推动的。</p><p>还有各种测试用例减少器，它们不是专门用于模糊测试，但仍可用于模糊测试识别的测试用例。这些包括格式不可知技术，如<code>delta调试</code>[216]，以及特定格式的专用技术，如<code>C-Reduce</code> [166]用于C / C ++文件。尽管专业技术明显受限于它们可以减少的文件类型，但它们的优势在于它们可以比通用技术更有效，因为它们了解它们试图简化的语法。</p><h1 id="7-配置更新-CONFIGURATION-UPDATING"><a href="#7-配置更新-CONFIGURATION-UPDATING" class="headerlink" title="7.配置更新(CONFIGURATION UPDATING )"></a>7.配置更新(CONFIGURATION UPDATING )</h1><p>ConfUpdate函数在区分黑盒模糊器与灰盒和白盒模糊器的行为方面起着关键作用。如算法1中所讨论的，ConfUpdate函数可以基于在当前模糊测试运行期间收集的配置和执行信息来修改配置集（C）。在最简单的形式中，ConfUpdate返回未修改的C参数。除了评估bug oracle O_bug之外，黑盒模糊器不执行任何程序自我测试，因此它们通常不会修改C，因为它们没有收集任何允许它们修改它的信息。</p><p>但是，灰色和白盒模糊器的主要区别在于它们更复杂的ConfUpdate函数实现，它允许它们包含新的模糊配置，或者删除可能已被取代的旧模糊配置。 ConfUpdate允许在一次迭代期间传输收集的信息，以便在将来的循环迭代期间使用。例如，白盒模糊器中的路径选择启发式通常会为每个生成的新测试用例创建一个新的模糊配置。</p><h2 id="7-1进化种子库更新"><a href="#7-1进化种子库更新" class="headerlink" title="7.1进化种子库更新"></a>7.1进化种子库更新</h2><p>进化算法（EA）是一种基于启发式的方法，涉及生物进化机制，如突变，重组和选择。尽管EA看似非常简单，但它构成了许多灰盒模糊器的基础[7,198,211]。他们维持一个种子库，这是在模糊测试期间EA演变的人口。选择要变异的种子和突变本身的过程分别在§4.3和§5中详述。</p><p>可以说，EA最重要的一步是将新配置添加到配置集C中，这对应于模糊测试的ConfUpdate步骤。大多数模糊器通常使用节点或分支覆盖作为适应度函数：如果测试用例发现新节点或分支，则将其添加到种子池中。 AFL [211]进一步考虑了分支机构被采取的次数。Angora[158]通过考虑每个分支的调用上下文来改进AFL的适应性标准。 Steelix [126]检查哪个输入偏移影响PUT的比较指令的过程以及进化种子池的代码覆盖率。</p><p>VUzzer [164]仅在发现新的非错误处理基本块时才向C添加配置。他们的见解是将时间投入到程序分析中，以获得特定应用知识，从而提高EA效率。具体地，VUzzer为每个基本块定义权重，并且配置的适合度是每个运动的基本块上的频率的对数的加权和。 VUzzer具有内置的程序分析功能，可将基本块分类为普通和错误处理（EH）块。根据经验，他们的假设是，遍历EH块表示漏洞的可能性较低，因为可能由于未处理的错误而发生错误。对于正常块，其权重与包含该块的CFG上的随机游走根据VUzzer定义的转移概率访问它的概率成反比。对于EH块，其权重为负，并且是基本块的数量与此配置所执行的EH块的数量之间的缩放比率。实际上，这使得VUzzer更喜欢采用上述随机游走所认为罕见的正常块的配置。</p><h2 id="7-2-维护Minset"><a href="#7-2-维护Minset" class="headerlink" title="7.2 维护Minset"></a>7.2 维护Minset</h2><p>由于能够创建新的模糊测试配置，因此还存在创建过多配置的风险。用于降低此风险的常见策略是维护最小化或最小化测试用例集，以最大化覆盖度量。在预处理期间也使用Minsetting，并在§3.2中有更详细的描述。</p><p>一些模糊器使用维护专用于配置更新的minset的变体。作为一个例子，AFL [211]使用剔除程序将minset配置标记为有利，而不是完全删除不在minset中的配置（这是Cyberdyne [86]所做的）。通过调度函数，有利的模糊测试配置被选择用于模糊测试的可能性显着提高。 AFL的作者指出“这在队列循环速度和测试用例多样性之间提供了合理的平衡”[215]。</p><h1 id="8-结束语"><a href="#8-结束语" class="headerlink" title="8. 结束语"></a>8. 结束语</h1><p>正如我们在§1中所阐述的那样，本文的第一个目标是提炼出对现代fuzzing文献的全面而连贯的观点。为此，我们首先提出了一个通用模型模糊器以方便我们解释当前使用中的多种形式的模糊测试。然后，我们使用图1（第7页）和表1（第9页）说明了对模糊器的丰富分类。我们通过讨论设计决策以及展示整个社区的众多成就，探索了模型模糊器的每个阶段。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h1&gt;&lt;p&gt;在当今可用的众多软件漏洞发现技术中，模糊测试由于其概念简单，部署的低屏障以及发现现实世界软件
      
    
    </summary>
    
      <category term="论文" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/"/>
    
      <category term="fuzzing" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/fuzzing/"/>
    
      <category term="综述" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/fuzzing/%E7%BB%BC%E8%BF%B0/"/>
    
    
      <category term="综述" scheme="http://yama0xff.com/tags/%E7%BB%BC%E8%BF%B0/"/>
    
      <category term="Fuzzing" scheme="http://yama0xff.com/tags/Fuzzing/"/>
    
  </entry>
  
  <entry>
    <title>Lord of the X86 Rings: A Portable User Mode Privilege Separation Architecture on X86</title>
    <link href="http://yama0xff.com/2019/02/15/Lord-of-the-X86-Rings-A-Portable-User-Mode-Privilege-Separation-Architecture-on-X86/"/>
    <id>http://yama0xff.com/2019/02/15/Lord-of-the-X86-Rings-A-Portable-User-Mode-Privilege-Separation-Architecture-on-X86/</id>
    <published>2019-02-15T09:09:42.000Z</published>
    <updated>2019-02-15T09:40:18.300Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>前heartbleed漏洞导致的敏感信息常泄露一直是人们要解决的问题，即如何保护程序中的隐私数据不被任意的访问到。研究人员想到的方法根本出发点为，将隐私数据隔离，即使存在程序漏洞，也不能任意访问到这些敏感数据。而将隐私数据存放于什么位置，是人们一直以来需要解决的问题。此前的解决办法包括，线程隔离，进程隔离，使用可以信执行区域(如Intel SGX)等。这些方法或者性能影响比较大，或者受限到CPU型号。<strong><em>而在这篇论文里作者使用Intel x86处理器一直以来存在的r0-r3四个特权等级来将数据隔离访问，一方面解决了处理器兼容问题(几乎所有Intel AMD处理器均支持这四个特权级别)，一方面解决了性能问题。</em></strong></p><table><thead><tr><th>relevant information</th><th></th></tr></thead><tbody><tr><td><em>作者</em></td><td>Hojoon Lee, Chihyun Song, Brent Byunghoon Kang</td></tr><tr><td><em>单位</em></td><td>CISPA Helmholtz Center i.G. GSIS, School of Computing, KAIST</td></tr><tr><td><em>出处</em></td><td>ACM CCS’18</td></tr><tr><td><em>原文地址</em></td><td><a href="https://github.com/wtwofire/database/blob/master/papers/reverse/2018-Lord%20of%20the%20X86%20Rings%20A%20Portable%20User%20Mode%20Privilege%20Separation%20Architecture%20on%20X86.pdf" target="_blank" rel="noopener">https://github.com/wtwofire/database/blob/master/papers/reverse/2018-Lord%20of%20the%20X86%20Rings%20A%20Portable%20User%20Mode%20Privilege%20Separation%20Architecture%20on%20X86.pdf</a></td></tr><tr><td><em>源码地址</em></td><td></td></tr><tr><td><em>发表时间</em></td><td>2018年</td></tr></tbody></table><h1 id="x86-特权级别及切换"><a href="#x86-特权级别及切换" class="headerlink" title="x86 特权级别及切换"></a>x86 特权级别及切换</h1><p>这篇论文带读者复习了x86处理器的环(ring)特权等级，门描述，GDT，LDT，段选择子，段间跳转等内容。而这篇论文的内容主要基于现代操作系统几乎没有用到的r1,r2两个特权等级。用户程序运行在R3等级，而操作系统内核运行在R0级别。用户程序不能访问到内核数据空间，原因在于页表的访问权限的限制。以下将内核页面权限简称S页面，将用户页面权限称为U页面。作者将用户的敏感数据及访问这些数据的代码放置于S页面，从而达到普通用户程序无法访问到敏感数据。然后将段代码所运行的特级等级设置于r1，从而阻止代码访问到内核数据。达到双向隔离。即普通程序无法访问到敏感代码数据，敏感代码无法访问到内核数据。</p><h1 id="权限访问控制"><a href="#权限访问控制" class="headerlink" title="权限访问控制"></a>权限访问控制</h1><p><img src="/2019/02/15/Lord-of-the-X86-Rings-A-Portable-User-Mode-Privilege-Separation-Architecture-on-X86/1.png" alt=""></p><p>如上图所示，作者将敏感数据代码所在特权等级(r2)称为PrivUser-mode。用户模式由于页面属性的限制不能访问到内核及PrivUser，而作者将R2所在段的段基地地址与段限写在固定的位置，使得PrivUser的代码不能访问到内核。用户可以将特殊的数据如密钥等标记为敏感数据从而存放在PrivUser所在的S页面中。而需要访问到这些敏感数据需要先将处理器提升到R2级别。作者将访问数据的函数同样放到PrivUser所在的内存中，调用这些函数首先需要一个跨段跳转提升处理器级别。然后在R2特权中执行函数。</p><p><img src="/2019/02/15/Lord-of-the-X86-Rings-A-Portable-User-Mode-Privilege-Separation-Architecture-on-X86/2.png" alt=""></p><p>如上图即为作者的跨段跳转示意图，作者借助r1作为一个跨段跳转板，原因是他将R2段中的L标志(32位兼容模式)置位了，而跨段跳转指令不允许从一个非32位段跳到一个32位段，而允许从一个非32位段返回32位段，因此先进入R1将特权等级提升，再通过段返回指令如(lret)到PrivUser mode。这里我不能理解为何要将PrivUser段设置为32位兼容模式，从而导致多需要R1层作为跨段跳转中转。</p><h1 id="编译套件"><a href="#编译套件" class="headerlink" title="编译套件"></a>编译套件</h1><p>作者将这套系统命名为LOTRx86。其中包含一系列的能够帮助用户编译保护隐私数据的软件。整个编译系统的流程如下图所示</p><p><img src="/2019/02/15/Lord-of-the-X86-Rings-A-Portable-User-Mode-Privilege-Separation-Architecture-on-X86/3.png" alt=""></p><p>作者定义了一个宏，这个宏接受函数名称和参数类型等作为参数，并对外导出一个调用接口。开发者将访问敏感数据的函数导出，然后在主程序中使用系统所提供的宏来访问这个函数。由于PrivUser层的数据代码是32位兼容的，因此作者直接将这段内容直接链接进可以执行文件中。并且作者修改了libc中的malloc等内存分配函数使得PrivUser中的函数分配的内存始终在PrivUser内存中。其中包含一个内核模块，其功能为初始化LDT，初始化PrivUser内存，写入跨段跳转中转指令等。</p><h1 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h1><p>作者使用Privcall与一些常规的系统调用作对比，并且使用运行多次程序与在一次程序中多次调用来模拟程序使用接口的频繁程度。从图中可以看出Privcall相对于一些常规系统调用所带来的开销并不高。</p><p>接下来作者将LOTRx86方法与其他的两种方法作比较，即使页面保护与进程隔离两种方法。可以看出LOTRx86所带来的开销小于另外两个方法。</p><p><img src="/2019/02/15/Lord-of-the-X86-Rings-A-Portable-User-Mode-Privilege-Separation-Architecture-on-X86/4.png" alt=""></p><h1 id="评价"><a href="#评价" class="headerlink" title="评价"></a>评价</h1><p>相对于传统的使用进程隔离，页面保护的方法，使用段隔离的方法带的开销的确是比较小的。方法比较新颖。但是除了作者提到的几个缺点：</p><ol><li>参数仅支持32位</li><li>不支持ASLR</li><li>不能与用户程序共享数据空间</li></ol><p>我觉得作者的论文来缺乏了一点：没有将所用到的段描述详细的描述出来。</p><p>另外我觉得作者的关于对敏感数据的访问定义不够好，我觉得对于敏感数据的访问，不应该以代码段或者说函数来看，而应该以程序运行的时间段来看。即不能说某个函数是可以访问敏感数据的，而应该说在程序运行的某个时间段是可以访问敏感数据的。由于这个定义的不够好，所以我发现作者的设计中的一个缺陷。比如某个访问敏感数据 的函数需要使用libc中的fread函数，那么由于访问控制的原因，那么fread函数同样必须位于PrivUser层，而这样正常的函数需要使用fread的函数又必须将这函数位置PrivUser层中，这样的关联导致大片的函数无法分开。而我提出我的一个想法：</p><ol><li>构造一个LDT或者GDT，将段基地址写为0而将段限写为用户空间地址最大值。将这个段特权等级设置为1或者2，对应的SS,CS,DS都设置为使用这个LDT或者GDT。</li><li>将敏感数据放置于S页面中，当程序需要访问到敏感数据时，使用一个段跨越跳转跳到这个转中，跳转地址写为下一条指令。那么程序的执行流程正常进行，但是特权等级却切换到了高的特权等级上。</li><li>当不再需要访问敏感数据时则伪造一个栈结构，跨段返回到下一条指令，这样程正常继续以低特权运行。</li></ol><p>这样做的好处有：</p><ol><li>作法简单，只需要定义两个宏用于平衡栈和跨段跳转及返回</li><li>由于段空间与用户空间重叠，因此可以直接访问用户空间数据</li><li>符合访问敏感数据的定义，即访问敏感数据的代码与正常代码在内存中存在于一块，不需要另外编写一个宏将这段函数放在另外一个地方，只是访问时的特权等级变了。这样我所提到的函数牵连问就不存在。</li><li>粒度更加可控，作者提出的粒度基于函数，即将整个函数作为访问敏感数据的代码块，而这里可以选择一小块代码，外包一个跨段宏和退段宏即可。</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h1&gt;&lt;p&gt;前heartbleed漏洞导致的敏感信息常泄露一直是人们要解决的问题，即如何保护程序中的隐私
      
    
    </summary>
    
      <category term="论文" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/"/>
    
      <category term="软件分析" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90/"/>
    
    
      <category term="2018年" scheme="http://yama0xff.com/tags/2018%E5%B9%B4/"/>
    
      <category term="防护" scheme="http://yama0xff.com/tags/%E9%98%B2%E6%8A%A4/"/>
    
      <category term="ACM CCS&#39;18" scheme="http://yama0xff.com/tags/ACM-CCS-18/"/>
    
  </entry>
  
  <entry>
    <title>Digtool: A Virtualization-Based Framework for Detecting Kernel Vulnerabilities</title>
    <link href="http://yama0xff.com/2019/02/15/Digtool-A-Virtualization-Based-Framework-for-Detecting-Kernel-Vulnerabilities/"/>
    <id>http://yama0xff.com/2019/02/15/Digtool-A-Virtualization-Based-Framework-for-Detecting-Kernel-Vulnerabilities/</id>
    <published>2019-02-15T07:53:36.000Z</published>
    <updated>2019-02-15T08:44:19.666Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>发现操作系统（OS）内核中的漏洞并对其进行修补对于操作系统安全至关重要。但是，缺乏有效的内核漏洞检测工具，尤其是对于Microsoft Windows等封闭源操作系统。在本文中，我们介绍了Digtool，一个有效的，仅二进制代码的内核漏洞检测框架。 Digtool构建于我们设计的虚拟化监视器之上，成功捕获内核执行的各种动态行为，例如内核对象分配，内核内存访问，线程调度和函数调用。通过这些行为，Digtool已经确定了45个零日漏洞，例如最近版本的Microsoft Windows的内核代码和设备驱动程序中的out–bounds访问，free-after-free和check-time-of-use-of-use ，包括Windows 7和Windows 10。</p><table><thead><tr><th>relevant information</th><th></th></tr></thead><tbody><tr><td><em>作者</em></td><td>Jianfeng Pan, Guanglu Yan, Xiaocao Fan</td></tr><tr><td><em>单位</em></td><td>IceSword Lab, 360 Internet Security Center</td></tr><tr><td><em>出处</em></td><td>USENIX’17</td></tr><tr><td><em>原文地址</em></td><td><a href="https://github.com/wtwofire/database/blob/master/papers/fuzzing/2017-Digtool%EF%BC%9AA%20Virtualization-Based%20Framework%20for%20Detecting%20Kernel%20Vulnerabilities.pdf" target="_blank" rel="noopener">https://github.com/wtwofire/database/blob/master/papers/fuzzing/2017-Digtool%EF%BC%9AA%20Virtualization-Based%20Framework%20for%20Detecting%20Kernel%20Vulnerabilities.pdf</a></td></tr><tr><td><em>源码地址</em></td><td>无，相关材料：<a href="https://www.usenix.org/sites/default/files/conference/protected-files/usenixsecurity17_slides_guanglu_yan.pdf" target="_blank" rel="noopener">Slide</a>,<a href="https://www.youtube.com/watch?v=EOhIxpcyAiw" target="_blank" rel="noopener">Video</a></td></tr><tr><td><em>发表时间</em></td><td>2017年</td></tr></tbody></table><h1 id="一、背景"><a href="#一、背景" class="headerlink" title="一、背景"></a>一、背景</h1><p>目前，自动化检测系统内核漏洞的工具比较少，而且，很多的工具都是只能检测开源的系统内核（例如：Linux操作系统），对于不开源的操作系统（例如：Microsoft Windows）则无能为力。因此，很有必要开发一款专用的系统内核漏洞检测工具，在二进制层面检测系统内核潜在的漏洞。漏洞检测工具通常分为两个方面：路径探测和漏洞识别，路径探测通常使用fuzzer工具，查找尽可能多的分支路径；漏洞识别则用于检测这些路径上可能存在的漏洞。而在这篇文章中，作者结合了这两个方面的技术，具体检测了内核中的以下四种漏洞类型：</p><h2 id="1-UNPROBE"><a href="#1-UNPROBE" class="headerlink" title="1. UNPROBE"></a><strong>1. UNPROBE</strong></h2><p>在这篇文章中，作者把未经检查的、从用户层传下来的输入缓冲区指针所造成的漏洞叫做UNPROBE。很多内核模块都可能会忽略对用户层的指针进行检查，特别是一些被嵌套的指针，而这种情况是非常危险的，因为它可能会导致非法内存引用、任意的内存读或者写等严重后果。</p><h2 id="2-TOCTTOU-Time-Of-Check-To-Time-Of-Use"><a href="#2-TOCTTOU-Time-Of-Check-To-Time-Of-Use" class="headerlink" title="2. TOCTTOU (Time-Of-Check-To-Time-Of-Use)"></a><strong>2. TOCTTOU (Time-Of-Check-To-Time-Of-Use)</strong></h2><p>TOCTTOU漏洞来源于对同一个用户层的数据进行多次的访问。在有些系统调用处理例程中，当它要访问某一个用户层数据的时候，它首先会检查这个数据是否合法，然后再使用它，这就会产生两次对该数据的访问，而在这两次访问之间就会存在一个攻击窗口，一旦这个攻击窗口被攻击者利用，就有可能导致非法内存引用、任意的内存读或者写等严重后果。</p><h2 id="3-UAF-Use-After-Free"><a href="#3-UAF-Use-After-Free" class="headerlink" title="3. UAF (Use-After-Free)"></a><strong>3. UAF (Use-After-Free)</strong></h2><p>UAF漏洞是由于使用了被释放的内存导致的。很多情况下，这种漏洞可能会导致本地提权。在Linux上，像AddressSanitizer这样的工具已经可以用于检测这类漏洞；在Windows上，微软自己开发的DriverVerifier也可以用于检测这种类型的漏洞，但是限制条件比较多。</p><h2 id="4-OOB-Out-Of-Bound-access"><a href="#4-OOB-Out-Of-Bound-access" class="headerlink" title="4. OOB (Out-Of-Bound access)"></a><strong>4. OOB (Out-Of-Bound access)</strong></h2><p>OOB漏洞是由于访问了目标内存块之外的内存导致的。该漏洞导致的后果跟UAF漏洞导致的后果一样，都可能会导致本地提权，并且用于检测这两种漏洞的工具也基本一样。</p><h1 id="二、提出的方法以及解决的问题"><a href="#二、提出的方法以及解决的问题" class="headerlink" title="二、提出的方法以及解决的问题"></a>二、提出的方法以及解决的问题</h1><p>像Windows这样的闭源操作系统，要检测系统中存在的漏洞，就不能再使用基于源码的检测工具，必须使用基于二进制代码的检测工具。因此，为了检测Windows内核中出现的以上四种漏洞类型，作者提出了一个基于二进制代码的检测框架：DigTool。该框架建立在作者自己设计的一个虚拟化监视器（Hypervisor）之上，用来捕获内核执行过程中的各种动态行为，例如：内核对象的分配、内核中的内存访问、线程调度和函数调用等，并基于这些行为，发掘系统中存在的漏洞。</p><h1 id="三、技术方法"><a href="#三、技术方法" class="headerlink" title="三、技术方法"></a>三、技术方法</h1><p><img src="/2019/02/15/Digtool-A-Virtualization-Based-Framework-for-Detecting-Kernel-Vulnerabilities/1.jpg" alt=""></p><p>DigTool的总体架构如图1所示，它的各个模块分布在系统的不同的层次当中，它们分别包括：Hypervisor中、客户机的内核中以及客户机的用户空间。通过箭头可以知道它们之间的各个模块的相互作用关系：细箭头所连接的两个模块表明它们之间有直接的调用关系或者是直接的传输信息通道，粗箭头表明两个模块之间通过某种事件触发机制进行间接的相互作用。</p><h2 id="1-Hypervisor-组件："><a href="#1-Hypervisor-组件：" class="headerlink" title="(1). Hypervisor 组件："></a><strong>(1). Hypervisor 组件：</strong></h2><p>DigTool不依赖于Xen、KVM等当前存在的Hypervisor，而是自己开发一个Hypervisor，它包含三个重要的组成部分：VMM（Virtual Machine Monitor）infrastructure、Interface detection 和 memory detection。</p><ul><li>虚拟机监控模块（VMM infrastructure）： 首先，它负责检测机器上的硬件环境和操作系统的版本等，以确保DigTool能正确的运行；然后，它再初始化Hypervisor，并把一个原始的操作系统加载到一个VM虚拟机当中运行。</li><li>接口检测（Interface detection）： 它负责监控用户层的应用程序在调用系统调用的时候传递到内核中的参数。在内核中，它跟踪这些参数被使用和被检查所发生的位置，以发掘潜在的漏洞。为了提高性能，DigTool并不是监控所有的系统调用，它只监控自己感兴趣的系统调用（通过配置文件进行配置）。因此，它限制了被监控的系统调用的范围，以检查特定的系统调用所产生的漏洞。</li><li>内存检测（Memory detection）： 该模块通过使用SPT（Shadow Page Table）技术，监控客户机操作系统内核中的非法内存访问。为了检测特定的内核模块（例如Win32k等），该模块可以通过调用相应的服务接口（Hypervisor提供给客户机操作系统内核的接口）来限制被监控的内核模块和地址范围。</li></ul><h2 id="2-Kernel-Space-组件："><a href="#2-Kernel-Space-组件：" class="headerlink" title="(2). Kernel-Space 组件："></a><strong>(2). Kernel-Space 组件：</strong></h2><p>DigTool在客户机操作系统内核中的所有模块被统称为：Middleware，它属于一个中间桥梁（或者说是一个中间件），用于连接Hypervisor和客户机用户空间程序，具有承上启下的作用。</p><ul><li>例如图1中，在Loader加载Fuzzer之前，可以通过用户空间中的configuration文件配置被检测的系统调用的范围，然后通过Middleware把相应的信息传送到Hypervisor，这就使得Hypervisor可以在Fuzzer进程空间中检测相应系统调用中的漏洞了。</li><li>对于接口检测，Middleware通过一个工作线程（Work thread）把所有的相关信息（包括系统调用号、事件类型、事件发生的时间、指令地址以及访问的内存）都记录到日志文件中。以便于日志分析模块（Log analyzer）可以通过日志文件分析并查找出相应的漏洞。</li><li>对于内存检测，Middleware通过Hook特定的内存操作函数，辅助内存检测模块矫正被检测的内存范围（因为DigTool只检测部分相关的内存范围），并且通过调用Hypervisor提供的接口来限制被监控的内存区域，以提高性能。另外，如果在这个过程中发现一个潜在的漏洞，Middleware还会中断客户机，使之进入单步调试模式，等待外部调试工具（例如 WinDbg）连接，并获取有用的上下文环境，辅助漏洞分析。</li></ul><h2 id="3-User-Space-组件："><a href="#3-User-Space-组件：" class="headerlink" title="(3). User-Space 组件："></a><strong>(3). User-Space 组件：</strong></h2><p>为了提高系统的稳定性和健壮性，作者把DigTool的一部分作用功能模块放到用户空间中，这些模块包括：Loader模块、Fuzzer模块和Log Analyzer模块。</p><ul><li>Loader模块，它负责装载一个特定的进程，给DigTool提供一个检测漏洞的进程环境。该模块还需要配置configuration文件，限制被检测的系统调用的范围等（要检测哪些系统调用就把这些系统调用添加到配置文件中）。</li><li>Fuzzer模块，该模块由Loader模块装载，通过Fuzzer模块调用系统调用，并通过调整系统调用的参数，探索尽可能多的路径，使得漏洞检测模块可以发掘尽可能多的漏洞。</li><li>Log Analyzer模块，该模块负责分析日志文件，分析代码中可能存在的漏洞。</li></ul><h1 id="四、实验评估"><a href="#四、实验评估" class="headerlink" title="四、实验评估"></a>四、实验评估</h1><h2 id="1-有效性评估"><a href="#1-有效性评估" class="headerlink" title="(1). 有效性评估"></a><strong>(1). 有效性评估</strong></h2><p>作者通过测试不同的软件产品来评估DigTool的有效性，这些产品包括Windows操作系统和一些反病毒软件，并且这些产品都是当时最新的版本。实验环境包括Windows 7和Windows 10。为了安全起见，在这篇文章中，作者使用的例子是当时发现的0Day漏洞，并且是已经被相应的厂商修复的漏洞。</p><h4 id="Detecting-Vulnerability-via-Interface："><a href="#Detecting-Vulnerability-via-Interface：" class="headerlink" title="Detecting Vulnerability via Interface："></a><strong>Detecting Vulnerability via Interface：</strong></h4><p>如表1所示，对于Avast Free Antivirus v11.2.2262、Dr. Web 11.0、AhnLab v8.0、Norman Security Suite v11.0.0和Spyware Detector v2.0.0.3这五个反病毒软件，被检测出存在UNPROBE漏洞的数量总共为23个。</p><p><img src="/2019/02/15/Digtool-A-Virtualization-Based-Framework-for-Detecting-Kernel-Vulnerabilities/Table1.jpg" alt=""></p><p>如表2所示，对于同样的五个反病毒软件，被检测出存在TOCTTOU漏洞的数量总共为18个。</p><p><img src="/2019/02/15/Digtool-A-Virtualization-Based-Framework-for-Detecting-Kernel-Vulnerabilities/Table2.jpg" alt=""></p><h4 id="Detecting-Vulerabiliry-via-Memory-Footprints"><a href="#Detecting-Vulerabiliry-via-Memory-Footprints" class="headerlink" title="Detecting Vulerabiliry via Memory Footprints:"></a><strong>Detecting Vulerabiliry via Memory Footprints:</strong></h4><p>为了检测UAF和OOB漏洞，作者选择32位的Windows 10为实验环境。检测这两类漏洞不再使用日志的形式，而是使用中断客户机系统的形式，即：当发现可能存在的漏洞的时候，中断客户机系统，等待调试工具连接，等调试工具连接上来之后，可以获取当前产生漏洞的位置对应的上下文环境，用于分析漏洞。但是这种方式的不足之处在于：它需要手工去分析漏洞。</p><p>在win32kfull.sys文件中，DigTool最先发现了MS16-123/CVE-2016-7211 CVE漏洞。</p><p>而对于OOB漏洞，作者使用DigTool发现了三个win32kbase中的CVE，它们分别是：MS16-090/CVE-2016-3252、MS16-034/CVE-2016-0096 和 MS16-151/CVE-2016-7260。</p><h2 id="2-效率评估"><a href="#2-效率评估" class="headerlink" title="(2). 效率评估"></a><strong>(2). 效率评估</strong></h2><p>目前，由于Bochspwn（一个基于Bochs模拟器的内核漏洞检测工具）只能检测前文中提到的四种漏洞类型的一类：TOCTTOU，因此，作者只能将DigTool与Bochspwn进行TOCTTOU漏洞测试比较。基于相同的环境下（相同的硬件、相同的操作系统版本、相同的系统调用参数和相同的测试程序），作者选用了十个最经常使用、最经常被反病毒软件Hook的系统调用的系统调用来测试性能开销。此外，为了测试结果的完整性，作者还选用了一个常用的软件WinRAR来加入这个测试实验当中，这两个工具的性能比较结果如图2所示。</p><p>在上图的实验结果中，作者分两种情况进行比较:“Unrecorded”和“Recorded”,具体如下：</p><h4 id="Unrecorded"><a href="#Unrecorded" class="headerlink" title="Unrecorded"></a><strong>Unrecorded</strong></h4><p>在这种测试模式下，在DigTool的配置文件中不添加任何的系统调用（相当于没有内存页面被监控），也不做任何的日志操作，但是在接口检测（Interface Detection）模块中的其它子功能是处于工作状态当中的。由于在检测TOCTTOU漏洞的时候，大部分系统调用和线程都处于不被监控状态，因此，该模式可以反映整个系统的基本性能开销，很适合与Bochspwn进行比较。</p><p>该模式下的性能开销比Windows模式（既没有DigTool，也没有Bochs）下慢2.18到5.03倍，比Bochspwn（操作系统运行在Bochs中）快45.4到156.5倍。对于WinRAR的测试结果，DigTool比Windows模式慢2.25倍，比Bochspwn模式快428.8倍。</p><h4 id="Recorded"><a href="#Recorded" class="headerlink" title="Recorded"></a><strong>Recorded</strong></h4><p>在这种测试模式下，相应的系统调用将被写入到配置文件中，并且相应的行为也会被记录下来（监控配置文件中指定的系统调用和相关的线程，对于无关的系统调用和线程都不做任何操作）。</p><p>该模式下的性能开销比Windows模式（既没有DigTool，也没有Bochs）下慢70到90倍，但任然比Bochspwn（操作系统运行在Bochs中）稍快。对于WinRAR的测试结果，这次测试使用极端情况，即：监控NT kernel中的所有系统调用。测试结果表明：DigTool比Windows模式慢13.45倍，比Bochspwn模式快71.8倍。</p><h1 id="五、优缺点"><a href="#五、优缺点" class="headerlink" title="五、优缺点"></a>五、优缺点</h1><h2 id="优点："><a href="#优点：" class="headerlink" title="优点："></a>优点：</h2><ul><li>DigTool相对于Bochspwn来说，在性能方面有很大的优势。不管是在“Unrecorded”模式还是“Recorded”模式下，DigTool都比Bochspwn快。</li><li>相对于DriverVerifier（一款微软开发的、用于检测Windows内核漏洞的工具），DigTool具有更好的弹性。在检测到一个可能的漏洞的时候，DriverVerifier会造成系统蓝屏死机（BSOD）,而且当这个潜在的漏洞在没有被修复之前，DriverVerifier就不能继续往下运行，因此无法同时检测多个漏洞；而DigTool则不会出现这种情况，DigTool在检测到潜在的漏洞的时候，只会记录漏洞发生的地点等一些有用的信息，不会造成系统蓝屏死机，并且可以同时检测多个漏洞。</li><li>对于OOB漏洞和UAF漏洞，DigTool在检测到潜在的漏洞的时候，可以直接中断客户机，等待外部调试器（如WinDbg等）连接，查看产生漏洞时刻的上下文，方便分析人员获取有用的信息；而DriverVerifier在检测到潜在的漏洞的时候，只能Crash客户机，并且无法获取产生漏洞时的上下文环境，若要分析产生漏洞的原因，分析人员还需要做额外的逆向分析工作，以确定漏洞产生的具体位置以及具体原因。</li><li>DigTool可以检测UNPROBE和TOCTTOU漏洞类型，而DriverVerifier则不可以。</li><li>在检测UAF和OOB漏洞的时候，如果漏洞没有造成系统崩溃，则DriverVerifier无法检测到它的存在。</li><li>DigTool发现了45个0Day内核漏洞。</li></ul><h2 id="缺点："><a href="#缺点：" class="headerlink" title="缺点："></a>缺点：</h2><ul><li>虽然DigTool的性能相对于Bochspwn好很多，但是，由于DigTool需要从Hypervisor和客户机之间频繁的进行切换，性能开销依然比较大。</li><li>DigTool的可移植性依然不是那么好，它目前只能运行Windows平台上。虽然DigTool的Hypervisor层与平台无关，但是它的Middleware层是与特定的平台相关的，要想使得DigTool在别的平台上能够运行，则必须修改它的Middleware。</li><li>DigTool目前只能检测四种漏洞类型：UNPROBE、TOCTTOU、UAF和OOB。对于其它的漏洞类型（例如：空指针解引用、双重释放等）却无法检测到。</li><li>该工具不是开源的工具，目前网上没有该工具的源代码。</li><li>该工具只能应用于内核漏洞检测，无法用于应用层的漏洞检测。</li></ul><h1 id="六、个人观点"><a href="#六、个人观点" class="headerlink" title="六、个人观点"></a>六、个人观点</h1><p>目前，已经存在很多用于检测漏洞的工具，既有收费的工具，又有免费的工具，不同的工具一般都有不同的用途，并且很多工具都只是检测具体的某一类或者是某几类漏洞。它们的检测方法也各不相同，有些基于源码检测，有些则基于二进制代码检测。而基于源码检测的工具比较多，这些工具大部分都是用于检测应用层的应用程序，以及开源的系统内核（例如Linux内核等）。很少有检测Windows内核漏洞的工具，因为Windows内核是闭源的，无法获取到它的源代码。</p><p>对于检测Windows内核漏洞，目前有一款功能非常受限的、微软开发的检测工具DriverVerifier，前文也提到，该工具的限制条件比较多，检测的漏洞类型也很少，因此，作者自己开发了一款检测Windows内核漏洞的工具：DigTool，作为DriverVerifier的补充工具。</p><p>DigTool主要关注两个部分的内容，一个是系统调用入口，当应用程序调用系统调用的时候，可能会由于各种原因，导致非法的、或者是不适当的参数被传入到系统内核中，如果内核代码不能处理好外部传入的参数，攻击者就可能会利用这些入口点，来获得额外的权限，这可能会导致系统内核沦陷。另一种情况是，内核代码如果对内存操作不当，也可能会导致严重的后果（例如，系统可能会出现崩溃、拒绝服务等现象）。</p><p>DigTool是基于二进制代码的一个漏洞检测工具，它的总体架构分为三个组成部分（Hypervisor Component、Kernel-Space Component 和 User-Space Component），其中Hypervisor Component是与平台无关的，而另外两个部分是与平台相关的，如果我们能够把它的Kernel-Space Component（其实就是它的Middleware部分）移植到别的系统上（例如MacOS、Linux OS等），那么，我们也可以利用作者的这个工具检测别的系统上的漏洞。虽然DigTool的User-Space Component也是与平台相关的，但是这部分的移植相对于Middleware来说简单的多，因此，DigTool的可移植性主要体现在它的Middleware上。</p><p>作者的DigTool目前已经可以检测四种漏洞类型（UNPROBE、TOCTTOU、UAF和OOB），如果稍作改进，可能也会比较容易检测双重释放等类型的漏洞，因为作者的这个工具可以检测到任意的内存地址空间。作者在文章中说道，当检测OOB漏洞的时候，作者使用AVL树来保存已经分配的内存区域，如果一片内存区域已经被释放，则它将会从AVL树中被移除，如果再次释放该内存区域，则DigTool会首先在AVL树中查找该内存区域，若找到，则释放（一般不可能）；若没有找到，则表明已经被释放，或者是没有该内存区域，即：可以发现双重释放类型的漏洞。但是，有一个很大的问题限制了这个想法，那就是：作者的DigTool不开源，我们无法获取到他的源代码，因此，我们也就无法在他的这个工具上做二次开发。</p><p>​                                                                                                                                                               <strong><em>转载于GoSSIP</em></strong></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h1&gt;&lt;p&gt;发现操作系统（OS）内核中的漏洞并对其进行修补对于操作系统安全至关重要。但是，缺乏有效的内核
      
    
    </summary>
    
      <category term="论文" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/"/>
    
      <category term="fuzzing" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/fuzzing/"/>
    
    
      <category term="fuzzing" scheme="http://yama0xff.com/tags/fuzzing/"/>
    
      <category term="2017年" scheme="http://yama0xff.com/tags/2017%E5%B9%B4/"/>
    
      <category term="内核" scheme="http://yama0xff.com/tags/%E5%86%85%E6%A0%B8/"/>
    
      <category term="USENIX&#39;17" scheme="http://yama0xff.com/tags/USENIX-17/"/>
    
  </entry>
  
  <entry>
    <title>SoK: Security Evaluation of Home-Based IoT Deployments</title>
    <link href="http://yama0xff.com/2019/02/15/SoK-Security-Evaluation-of-Home-Based-IoT-Deployments/"/>
    <id>http://yama0xff.com/2019/02/15/SoK-Security-Evaluation-of-Home-Based-IoT-Deployments/</id>
    <published>2019-02-15T02:37:32.000Z</published>
    <updated>2019-02-15T03:10:26.749Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>智能家居在安全方面一直表现得不尽人意，究其原因，在于IoT系统相对于传统的嵌入式系统，还引入了智能终端和网络，这就导致了其本身暴露了更多的攻击面。本文通过总结大量论文来帮助研究人员和从业者更好的理解针对智能家居的攻击技术，缓解措施，以及利益相关者应该如何解决这些问题。最后作者利用这些方法评估了45款智能家居设备，并将实验数据公布在<a href="https://yourthings.info./" target="_blank" rel="noopener">https://yourthings.info%E3%80%82</a></p><table><thead><tr><th>relevant information</th><th></th></tr></thead><tbody><tr><td><em>作者</em></td><td>Omar Alrawi、Chaz Lever、Manos Antonakakis、Fabian Monrose†</td></tr><tr><td><em>单位</em></td><td>Georgia Institute of Technology</td></tr><tr><td><em>出处</em></td><td>S&amp;P’19</td></tr><tr><td><em>原文地址</em></td><td><a href="https://github.com/wtwofire/database/blob/master/papers/IOT/2019-SoK%EF%BC%9ASecurity%20Evaluation%20of%20Home-Based%20IoT%20Deployments.pdf" target="_blank" rel="noopener">https://github.com/wtwofire/database/blob/master/papers/IOT/2019-SoK%EF%BC%9ASecurity%20Evaluation%20of%20Home-Based%20IoT%20Deployments.pdf</a></td></tr><tr><td><em>源码地址</em></td><td></td></tr><tr><td><em>发表时间</em></td><td>2019年</td></tr></tbody></table><h1 id="方法论"><a href="#方法论" class="headerlink" title="方法论"></a>方法论</h1><h2 id="抽象模型"><a href="#抽象模型" class="headerlink" title="抽象模型"></a>抽象模型</h2><p><img src="/2019/02/15/SoK-Security-Evaluation-of-Home-Based-IoT-Deployments/1.jpg" alt=""></p><ul><li>V: A(apps)、C(cloud)、D(devices)</li><li>E: communication</li></ul><h2 id="安全特性"><a href="#安全特性" class="headerlink" title="安全特性"></a>安全特性</h2><h3 id="攻击面"><a href="#攻击面" class="headerlink" title="攻击面"></a>攻击面</h3><ul><li>Device<ul><li>Vulnerable services</li><li>Weak authentications</li><li>Default configurations（出厂设置）</li></ul></li><li>Mobile application (Android, iOS)<ul><li>Permissions: over-privileged</li><li>Programming: 密码学误用</li><li>Data protection: API keys, passwords, hard-coded keys</li></ul></li><li>Communication (local, Internet)<ul><li>Encryption</li><li>MITM</li></ul></li><li>Cloud<ul><li>Vulnerable services</li><li>Weak authentications</li><li>Encryption</li></ul></li></ul><h3 id="缓解措施"><a href="#缓解措施" class="headerlink" title="缓解措施"></a>缓解措施</h3><ul><li>patching</li><li>framework: 重构</li></ul><h3 id="利益相关"><a href="#利益相关" class="headerlink" title="利益相关"></a>利益相关</h3><ul><li>vendors</li><li>end-user</li></ul><p>其实还可以细分，芯片厂商，物联网平台，经销商，第三方的开发者等，来定义谁来负责解决谁的问题。</p><h2 id="分类的方法"><a href="#分类的方法" class="headerlink" title="分类的方法"></a>分类的方法</h2><ul><li>Merit: 创新性、有效性</li><li>Scope: 集中在讨论安全性（攻击性和防御性）</li><li>Impact: 影响力</li><li>Disruption: 揭示了一个新的领域</li></ul><h2 id="威胁模型"><a href="#威胁模型" class="headerlink" title="威胁模型"></a>威胁模型</h2><p>只考虑Internet protocol network attacker，不考虑low-energy based devices，作者认为攻击所需要的资源在大多数家庭都没有。同时如果能hacking hub devices，就默认exploit了所有的low-energy based devices。（这里就限制了讨论的范围）</p><h1 id="相关的研究"><a href="#相关的研究" class="headerlink" title="相关的研究"></a>相关的研究</h1><p><img src="/2019/02/15/SoK-Security-Evaluation-of-Home-Based-IoT-Deployments/2.jpg" alt=""></p><h2 id="Device"><a href="#Device" class="headerlink" title="Device"></a>Device</h2><ol><li>Attack Vectors 设备上暴露的引脚可以让攻击者轻而易举的获得权限，不安全的配置会加剧漏洞的产生， 而缺少或弱的身份认证是最容易出现的问题，这些都导致设备上的安全问题被频繁曝出。<ul><li>August Smart Lock，硬编码的密钥、debug接口</li><li>cloud-based cameras，强口令但是是mac地址的base64编码</li><li>Sonos device，在高端口开了后门服务，并且没有认证</li><li>厂商集成第三方库的安全使得其很难保证整体的安全性</li><li>Philips Hue device，通过侧信道攻击得到master key，配合协议的漏洞完成蠕虫</li></ul></li><li>Mitigations 要想解决以上问题，就要求vendor通过设备更新来打patch，要求security by design。<ul><li>Fear and logging in the internet of things</li><li>SmartAuth，识别IoT应用的权限，这个主要是针对SmartThings和Apple Home</li><li>FlowFence，把应用分成sensitive和non-sensitive两部分，这部分需要开发者来做。</li></ul></li><li>Stakeholders Vendors有责任patch和update有漏洞的设备，但也要授权给end-user一定的权限，比如可以关闭某些有问题的服务。<ul><li>SmartAuth提供一种可以导出认证规则的方式，但只能vendor来做。</li><li>Sonos device允许用户使用网络隔离的方式来缓解漏洞。</li></ul></li></ol><h2 id="Mobile-Application"><a href="#Mobile-Application" class="headerlink" title="Mobile Application"></a>Mobile Application</h2><ol><li>Attack Vectors over-privileges、programming error、hard-coded sensitive information<ul><li>August Smart Lock，作者用敏感信息dump密钥</li><li>IoTFuzzer，利用app来对设备做fuzzing，当然也可以利用app做攻击</li><li>用app来收集设备的有关信息，然后重新配置路由器的防火墙，使得设备处于公网</li><li>Hanguard，app宽松的安全假设导致设备的隐私泄露（App作为设备的入口，厂商往往默认App所处的网络是可信的）</li></ul></li><li>Mitigations<ul><li>基于角色的访问控制</li></ul></li><li>Stakeholders mobile的安全依赖user和vendor，user往往有权限控制的权利，同时user应该遵守从app store上下载app。vendor应该解决programming error并且安全存储数据。</li></ol><h2 id="Cloud-Endpoint"><a href="#Cloud-Endpoint" class="headerlink" title="Cloud Endpoint"></a>Cloud Endpoint</h2><ol><li>Attack Vectors<ul><li>August Smart Lock，cloud端实现的不安全的API导致越权</li><li>cloud没有对固件的更新包签名</li><li>web的xss漏洞，username枚举。。</li><li>AutoForge，伪造app的请求，实现爆破密码，token劫持等</li></ul></li><li>Mitigations<ul><li>身份认证</li><li>细粒度的访问控制</li></ul></li><li>Stakeholders 由于云平台一般只有厂商管理，所以cloud上的基础设施和API实现的安全应该由他们来负责。</li></ol><h2 id="Communication"><a href="#Communication" class="headerlink" title="Communication"></a>Communication</h2><p>classes of protocols <em> Internet protocol </em> low-energy protocol</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Zigbee</span><br><span class="line">Z-Wave</span><br><span class="line">luetooth-LE</span><br></pre></td></tr></table></figure><p>Application layer protocols，DNS、HTTP、UPnP、NTP</p><ol><li><p>Attack Vectors</p><ul><li><p>EDNS解析 导致信息泄露</p></li><li><p>用NTP的MITM攻击绕过HSTS</p></li><li><p>UPnP实现时缺少认证，内存破坏漏洞等问题</p></li><li><p>TLS/SSL， TLS 1.0的IV问题，TLS RC4的问题</p></li><li><p>BLE、Zigbee、Z-Wave，协议设计本身的问题</p></li><li><p>LE的重放攻击更容易</p></li></ul></li><li><p>Mitigations </p><ul><li>对于HTTP，UPnP，DNS和NTP协议，放弃使用不安全的协议，使用最新的协议。</li><li>为有实现缺陷的TLS/SSL，升级服务器端和客户端库到最新版本应解决漏洞。</li><li>对于基于LE的通信，第一代Zigbee和Z-Wave协议有严重的缺陷，并且缓解方案有限。供应商可以禁用这些协议。</li><li>最近也有研究者发现通过监控物联网设备的流量，可以侧信道出一些隐私数据。 Apthorpe 等设计了如何在家中构造流量网络来防止旁道攻击。</li></ul></li><li><p>Stakeholders </p><ul><li>互联网服务提供商（ISP）可以看到基于IP的协议的数据包，但它们不是负任何缓解。 对于ISP来说，他们必须提供其相应的义务（这个我理解是比如说Mira DDoS，ISP虽然不能阻止设备发出去的恶意流量，但是他可以ban掉设备访问C&amp;C域名）。</li><li>对于LE协议，供应商可以缓解禁用易受攻击的设备的配对。</li></ul></li></ol><h1 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h1><p>作者对45款比较流行的不同的设备进行了各方面的评估。这些设备主要包括</p><ul><li>appliances</li><li>cameras</li><li>home assistants</li><li>home automation</li><li>media</li><li>network devices</li></ul><p>实验配置的网络环境，包含一个linux machine用于监听所有的流量和一个路由器（包含Wi-Fi热点）。对流量抓包后分析，对device和cloud使用漏扫分析，对app使用自动化审计工具。这里存在几个难点，</p><ul><li>设备自动更新 – 手动关掉</li><li>云平台的分类 – 人工识别，排除CDN</li><li>无线流量分析 – Wireless to wireless，</li><li>iOS应用解密 – 砸壳</li><li>…</li><li></li></ul><p><img src="/2019/02/15/SoK-Security-Evaluation-of-Home-Based-IoT-Deployments/3.png" alt=""></p><p>MobSF(Mobile Security Framework）、Qark，Kryptowire这些针对app的漏洞扫描器。45个设备有42个有app，其中包含41个Android平台，42个iOS平台。24个Over-privileged。15个包含硬编码的API key。17个使用了硬编码的key和IV。 </p><p><img src="/2019/02/15/SoK-Security-Evaluation-of-Home-Based-IoT-Deployments/4.png" alt=""></p><p>Nessus Scanner扫描。45个设备4000个域名。这些域名包括 基于云的服务（950）， 第三方的服务。CDN（1287） 混合，使用了AWS，Azure的服务的厂商（630） ，未知（1288）。</p><p><img src="/2019/02/15/SoK-Security-Evaluation-of-Home-Based-IoT-Deployments/5.png" alt=""></p><p>Nessus Scanner扫描，分析设备的操作系统，服务，漏洞等。在45个设备中发现了84个服务，39个有issue。这些服务主要是SSH，UPnP，HTTP，DNS，Telnet，RTSP。这些issues包括</p><ul><li>错误配置的TLS/SSL, 比如自签名的证书、过期的证书、短的密钥。</li><li>UPnp未授权访问。</li></ul><p><img src="/2019/02/15/SoK-Security-Evaluation-of-Home-Based-IoT-Deployments/6.png" alt=""></p><p>Nessus Monitor，ntop-ng，Wireshark，sslsplit。用sslsplit做MITM。43个D-C，35个A-C，27个A-D（LAN）。IP 通信包括DNS（41）、HTTP（38）、UPnP（21）和私有的协议（5）。</p><p>MITM: D-C(4), A-C(2), A-D(20) Encryption: D-C(40), A-C(24), A-D(7) </p><p><img src="/2019/02/15/SoK-Security-Evaluation-of-Home-Based-IoT-Deployments/7.png" alt=""></p><p>缓解措施</p><ul><li>Device 通过安全信道更新并确保更新内容的完整性。设备在激活前可以检查配置是否正确并安全。设备应该保证只与验证过身份的设备交互。</li><li>Mobile 敏感信息，比如API key应该在安装的时候导出并秘密存起来。密码算法应该尽量使用成熟的第三方库实现。</li><li>Cloud 厂商应该尽量使用商业化的云平台。通过API管理endpoint的配置。不应该再支持不安全的协议。</li><li>Communication 验证endpoint的身份，防止中间人攻击。保护通信协议的完整性。</li></ul><p>​                                                                                                                                                               <strong><em>转载于GoSSIP</em></strong></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h1&gt;&lt;p&gt;智能家居在安全方面一直表现得不尽人意，究其原因，在于IoT系统相对于传统的嵌入式系统，还引入
      
    
    </summary>
    
      <category term="论文" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/"/>
    
      <category term="IOT" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/IOT/"/>
    
    
      <category term="综述" scheme="http://yama0xff.com/tags/%E7%BB%BC%E8%BF%B0/"/>
    
      <category term="IOT" scheme="http://yama0xff.com/tags/IOT/"/>
    
      <category term="S&amp;P&#39;19" scheme="http://yama0xff.com/tags/S-P-19/"/>
    
      <category term="2019年" scheme="http://yama0xff.com/tags/2019%E5%B9%B4/"/>
    
  </entry>
  
</feed>
