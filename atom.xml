<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>yama0xff&#39;s blog</title>
  
  <subtitle>CYBERSECURITY  BETWEEN 0 AND 1</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yama0xff.com/"/>
  <updated>2019-02-14T08:29:19.648Z</updated>
  <id>http://yama0xff.com/</id>
  
  <author>
    <name>yama0xff</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Towards Paving the Way for Large-Scale Windows Malware Analysis: Generic Binary Unpacking With Orders-of-Magnitude Performance Boost</title>
    <link href="http://yama0xff.com/2019/02/14/Towards-Paving-the-Way-for-Large-Scale-Windows-Malware-Analysis-Generic-Binary-Unpacking-With-Orders-of-Magnitude-Performance-Boost/"/>
    <id>http://yama0xff.com/2019/02/14/Towards-Paving-the-Way-for-Large-Scale-Windows-Malware-Analysis-Generic-Binary-Unpacking-With-Orders-of-Magnitude-Performance-Boost/</id>
    <published>2019-02-14T07:51:11.000Z</published>
    <updated>2019-02-14T08:29:19.648Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>windows的软件脱壳本来已经在多年前已经被讨论得非常多了，目前安全学术会议上关于脱壳的论文非常少，然而这篇关于脱壳的论文还能在2018年被CCS所录取，足见他的方法之高效。此前关于脱壳的方法大多是跟踪脱壳时期的内存代码写入执行的变化，从而跟踪被加密代码的解密流程从而追溯到OEP。这也是对于分析脱壳的一个最为直观的方法，<strong><em>在这篇论文里作者提出来通过跟踪IAT(函数导入表)被恢复和引用的情况来追溯OEP，并且达到很理想的效果。作者将这款工具称为BinUnpack。</em></strong></p><table><thead><tr><th>relevant information</th><th></th></tr></thead><tbody><tr><td><em>作者</em></td><td>Binlin Cheng , Jiang Ming, Jianming Fu, Guojun Peng, Ting Chen, Xiaosong Zhang , Jean-Yves Marion</td></tr><tr><td><em>单位</em></td><td>Wuhan University , Hubei Normal University, University of Texas at Arlington, University of Electronic Science and Technology of China, LORIA</td></tr><tr><td><em>出处</em></td><td>ACM CCS’18</td></tr><tr><td><em>原文地址</em></td><td><a href="https://github.com/wtwofire/database/blob/master/papers/reverse/2018-Towards%20Paving%20the%20Way%20for%20Large-Scale%20Windows%20Malware%20Analysis%20Generic%20Binary%20Unpacking%20With%20Orders-of-Magnitude%20Performance%20Boost.pdf" target="_blank" rel="noopener">https://github.com/wtwofire/database/blob/master/papers/reverse/2018-Towards%20Paving%20the%20Way%20for%20Large-Scale%20Windows%20Malware%20Analysis%20Generic%20Binary%20Unpacking%20With%20Orders-of-Magnitude%20Performance%20Boost.pdf</a></td></tr><tr><td><em>源码地址</em></td><td></td></tr><tr><td><em>发表时间</em></td><td>2018年</td></tr></tbody></table><h1 id="IAT在脱壳中角色"><a href="#IAT在脱壳中角色" class="headerlink" title="IAT在脱壳中角色"></a>IAT在脱壳中角色</h1><p>IAT即为PE文件中的函数地址导入表，加壳软件会在对一个软件进行加壳时将IAT抹去，然后在运行解密时通过LoadLibrary和GetProcess两函数或者功能相同的函数再恢复，最后将控制权移交OEP。解密代码为了满足自身需要，通常也有一个自己的IAT，但是与原IAT位置并不在同一内存区域中，通常这个IAT的导入函数个数也要小得多，甚至只有一两个。作者的思路是，一旦某个函数调用是通过原IAT进行的，那么就表明这个时候，原代码已经完成了解密，这个时候往前回溯，即可找到OEP。</p><h1 id="Anti-Hook"><a href="#Anti-Hook" class="headerlink" title="Anti-Hook"></a>Anti-Hook</h1><p>为了跟踪函数的调用情况，hook是必不可少的，然而现在的加壳软件大多会检测函数hook并且存在许多反hook机制，这里记录一下加壳软件中用到的anti-hook方法。</p><p>首先Hook分为内核hook与用户层Hook,由于现在恶意软件想要加载内核模块越发困难，所以作者并没有考虑内核hook情况，这篇论文里，作者假设内核是安全的，未被加壳软件所修改。</p><p>用户层Hook分为以下几种：</p><ol><li>Stolen code. 即将所需要调用的函数代码从内存或者直接从文件系统中复制出来单独执行，这样.inlinehooke,iat,eat类型的Hook全部失效。</li><li>Child process,process hollowing.将脱壳行为分解到两个进程中进行，这样由于进程地址空间隔离，父进程hook全部失效。</li><li>Crash hooking module. 给api函数故意传入错误的参数，如果函数被Hook,则不能正确处理错误而程序崩溃 ，没有被Hook则能正确处理异常。以此可以检测是否被hook。</li><li>Integrity check. 使用哈希校验所调用模块的完整性。</li></ol><h1 id="Anti-anti-hook"><a href="#Anti-anti-hook" class="headerlink" title="Anti-anti-hook"></a>Anti-anti-hook</h1><p>作者设计了一个内核用户态混合的dll劫持系统来完成对函数的hook。作者通过逆向Loadlibrary发现，在内核中它最终需要将dll映射到进程的地址空间，而使用的内核函数是LdrMapDll。函数流程如下：</p><p><img src="/2019/02/14/Towards-Paving-the-Way-for-Large-Scale-Windows-Malware-Analysis-Generic-Binary-Unpacking-With-Orders-of-Magnitude-Performance-Boost/1.png" alt=""></p><p>作者修改内核使得NtMapViewOfSection加载定制的Hook版本dll，同时使得返回值变为STATUS_IMAGE_NOT_AT_BASE。这样第16行的NtMapViewOfSection也会被执行，这样定制的dll被加载进内存。另外有些加壳作者并不使用内存映射进行加载dll，而是使用读取文件如readfile读取dll，复制到内存，这样作者同样修改内存中这部分代码，使得加载的dll为定制的dll。</p><p>这样做能防住上述的提到的几种方法的anti-hook：</p><ol><li>Stolen code. 由于被加载时已经是被定制的dll，或者从文件系统读时都是被定制的dll，所以stolen code复制的代码依然是改变后的hook代码。</li><li>Child process,process hollowing. 同理，修改内核对于每个进程都生效。</li><li>Crash hooking module。这点作者认为正确处理了异常，存疑。</li><li>Integrity check。作者说借鉴使用了一种别人的方法，使得读取dll时读到的内容为原dll，执行时执行的是定制的dll，具体方法待研究。</li></ol><h1 id="Find-OEP"><a href="#Find-OEP" class="headerlink" title="Find OEP"></a>Find OEP</h1><p><img src="/2019/02/14/Towards-Paving-the-Way-for-Large-Scale-Windows-Malware-Analysis-Generic-Binary-Unpacking-With-Orders-of-Magnitude-Performance-Boost/2.png" alt=""></p><p>在结合了IAT与dll hijacking之后，寻找OEP的过程可以用上图来进行表示，首先进程加载时，加载的dll，包括系统dll，如Kernel32.dll,user32.dll等都被换成了作者定制的带hook版本。脱壳时一旦检测到某个函数调用来自原IAT，则进行回溯查找OEP及内存dump。由于可能存在加多个壳情况，即可能会更换IAT，但是这个IAT并不属于最开始被加壳的程序而是属于内层壳，这里作者的作法是，当切换IAT时则进行dump和回溯操作。</p><p><img src="/2019/02/14/Towards-Paving-the-Way-for-Large-Scale-Windows-Malware-Analysis-Generic-Binary-Unpacking-With-Orders-of-Magnitude-Performance-Boost/3.png" alt=""></p><h1 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h1><p>实验环境：laptop with an Intel Core i3-36100 processor (Quad Core,3.70GHz) and 8GB memory, running Windows 7.</p><p>作者使用VirusTotal检测结果来作为脱壳效果的检测结果。即对于一个不加壳的恶意软件，VirusTotal检测结果为n，被脱壳的检测结果越接近n则说明脱壳效果越好。</p><p>作者利用一款未被加壳的恶意软件hupigon.eyf，并用不同的壳对他进行加密，然后使用CoDisasm, PinDemonium, Arancino, BinUnpack四款脱壳工具进行脱壳。结果送VirusTotal进行检测，并记录脱壳所用到的时间。</p><p><img src="/2019/02/14/Towards-Paving-the-Way-for-Large-Scale-Windows-Malware-Analysis-Generic-Binary-Unpacking-With-Orders-of-Magnitude-Performance-Boost/4.png" alt=""></p><p>从图中可以看到，BinUpack的检测结果要远远高于其他三种脱壳工具。另外脱壳所用的到时间也缩短了一两个数量级。对于同一个软件加多个不同的壳，BinUpack的表现依然很出色，脱壳时间始终小于1s。而面对商业强壳Themida时，BinUnpack表现依然良好，VirusTotal检测结果能达到33，34这个级别，而其他三种壳都没有脱壳成功。</p><p>最后作者收集了271095个恶意软件进行测试，依然表现不俗。</p><h1 id="评价"><a href="#评价" class="headerlink" title="评价"></a>评价</h1><p>这篇论文对于脱壳来说实在是一篇不可多得好的好文。我觉得他的主要贡献在于出发点十分新颖，就在大家都认为脱壳方向已经被讨论得差不多的时候，能够另辟蹊径从IAT出发，合理的运用各种已知的成果。最终达到非常好的效果，这是非常难得的。另外关于这篇论文里面所提到的各种关于脱壳方面的知识，对于逆向人员来说也是一个非常不错的参考。对于文章里唯一有点不解的地方在于内核的hook，具体为如何去做这个Hook，要不要载原dll，参数怎么改，能写得更清楚就好了。另外有一点疑惑在于，如果一个壳故意的通过原IAT进行伪造的函数调用，那么，在检测到这种IAT调用时，可能原代码并未解密，那么这种情况我觉得论文里面没有很好的阐述，只是提到只要需要多次检测，但是检测只是发生在IAT切换的时候，伪造调用时发现IAT切换，但是代码并未解密，而后IAT不会切换，那么，何时进行检测呢？</p><p>​                                                                            <strong><em>转载于GoSSIP</em></strong></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h1&gt;&lt;p&gt;windows的软件脱壳本来已经在多年前已经被讨论得非常多了，目前安全学术会议上关于脱壳的论
      
    
    </summary>
    
      <category term="论文" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/"/>
    
      <category term="软件分析" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90/"/>
    
    
      <category term="2018年" scheme="http://yama0xff.com/tags/2018%E5%B9%B4/"/>
    
      <category term="脱壳" scheme="http://yama0xff.com/tags/%E8%84%B1%E5%A3%B3/"/>
    
      <category term="ACM CCS&#39;18" scheme="http://yama0xff.com/tags/ACM-CCS-18/"/>
    
  </entry>
  
  <entry>
    <title>HEAPHOPPER: Bringing Bounded Model Checking to Heap Implementation Security</title>
    <link href="http://yama0xff.com/2019/02/14/HEAPHOPPER-Bringing-Bounded-Model-Checking-to-Heap-Implementation-Security/"/>
    <id>http://yama0xff.com/2019/02/14/HEAPHOPPER-Bringing-Bounded-Model-Checking-to-Heap-Implementation-Security/</id>
    <published>2019-02-14T02:01:28.000Z</published>
    <updated>2019-02-14T02:31:15.088Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>堆元数据攻击已成为攻击者利用内存损坏漏洞的主要方式之一。虽然堆实现开发人员已经引入了缓解来防止和检测损坏，但攻击者仍然可以解决这些问题。在某种程度上，这是因为这些缓解是在没有原则基础的情况下创建和评估的，因此在许多情况下会导致堆元数据防御的复杂，低效和无效尝试。<strong><em>在本文中，我们提出了HEAPHOPPER，一种基于模型检查和符号执行的自动化方法，用于分析存在内存损坏时堆实现的可利用性。</em></strong>使用HEAPHOPPER，我们能够对不同的，广泛使用的堆实现进行系统分析，找到它们中令人惊讶的弱点。例如，我们的结果显示了ptmalloc中新引入的缓存机制（大多数Linux发行版使用的堆分配器实现）如何显著削弱其安全性。此外，HEAPHOPPER指导我们实施和评估对ptmalloc安全性的改进，用有效防御替代最近无效的缓解特定形式的堆元数据损坏的尝试。</p><table><thead><tr><th>relevant information</th><th></th></tr></thead><tbody><tr><td><em>作者</em></td><td>Moritz Eckert , Antonio Bianchi, Ruoyu Wang, Yan Shoshitaishvili , Christopher Kruegel , and Giovanni Vigna</td></tr><tr><td><em>单位</em></td><td>University of California, Santa Barbara, The University of Iowa, Arizona State University</td></tr><tr><td><em>出处</em></td><td>USENIX Security‘18</td></tr><tr><td><em>原文地址</em></td><td><a href="https://github.com/wtwofire/database/blob/master/papers/exploitation/2018-HEAPHOPPER%20Bringing%20Bounded%20Model%20Checking%20to%20Heap%20Implementation%20Security.pdf" target="_blank" rel="noopener">https://github.com/wtwofire/database/blob/master/papers/exploitation/2018-HEAPHOPPER%20Bringing%20Bounded%20Model%20Checking%20to%20Heap%20Implementation%20Security.pdf</a></td></tr><tr><td><em>源码地址</em></td><td><a href="https://github.com/angr/heaphopper" target="_blank" rel="noopener">https://github.com/angr/heaphopper</a></td></tr><tr><td><em>发表时间</em></td><td>2018年</td></tr></tbody></table><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>作者通过使用符号执行技术，自动化分析堆分配器，根据配置文件定义的情况可以自动生成不同exploitation primitive 的POC</p><p><img src="/2019/02/14/HEAPHOPPER-Bringing-Bounded-Model-Checking-to-Heap-Implementation-Security/1.png" alt=""></p><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>当程序逻辑存在漏洞时可以攻击堆分配器拿到程序控制权。为了缓解这些攻击，各大堆分配器都在内部进行了安全检查，然而并没有一个标准能评估加入一个补丁是否能缓解攻击。</p><p>以glibc的补丁为例</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment">/* Take a chunk off a bin list */</span></span><br><span class="line"> <span class="meta">#<span class="meta-keyword">define</span> unlink(AV, P, BK, FD) &#123;                                            \</span></span><br><span class="line">+    <span class="keyword">if</span> (__builtin_expect (chunksize(P) != prev_size (next_chunk(P)), <span class="number">0</span>))      \</span><br><span class="line">+      malloc_printerr (check_action, <span class="string">"corrupted size vs. prev_size"</span>, P, AV);  \</span><br><span class="line">     FD = P-&gt;fd;                                                                      \</span><br><span class="line">     BK = P-&gt;bk;                                                                      \</span><br><span class="line">     <span class="keyword">if</span> (__builtin_expect (FD-&gt;bk != P || BK-&gt;fd != P, <span class="number">0</span>))</span><br></pre></td></tr></table></figure><p>补丁作者加入了一个对size的检查，然而这可以被轻松的绕过，具体利用见</p><p><a href="https://github.com/shellphish/how2heap/blob/master/glibc_2.26/poison_null_byte.c" target="_blank" rel="noopener">poison_null_byte.c</a></p><p>因此作者通过符号执行技术对堆的交互进行了建模，从而可以自动化的评估堆分配器在特定情况下达到exploitation primitive的条件。</p><h1 id="生成堆交互模型"><a href="#生成堆交互模型" class="headerlink" title="生成堆交互模型"></a>生成堆交互模型</h1><h2 id="堆事务"><a href="#堆事务" class="headerlink" title="堆事务"></a>堆事务</h2><p>作者将会修改堆的状态的操作定义为事务，对堆的交互分为两种：直接交互和间接交互</p><p>直接交互指分配器功能，如malloc，free</p><p>间接交互指修改分配的内存区域，比如overflow</p><h3 id="malloc-M"><a href="#malloc-M" class="headerlink" title="malloc(M)"></a>malloc(M)</h3><p>HEAPHOPPER 通过传递一个符号化变量对malloc申请的大小进行建模。</p><p>一个不可约束的值可能会导致路径爆炸和约束复杂，因此将大小设置为了一个具体的范围，因此符号执行单元将会使用symbolic-but-constrained 变量作为传递给malloc的参数。</p><p>通常根据堆分配器不同的执行路径来确定大小，作者开发了一个工具根据libc的执行路径来确定大小选择（然而并没有看见这个工具，源码里面也有提及）。</p><h3 id="free-F"><a href="#free-F" class="headerlink" title="free(F)"></a>free(F)</h3><p>如果之前执行过多个malloc事务，HEAPHOPPER将会生成一个不同的序列将其中的每一个作为free事务的参数</p><h3 id="overflow-O"><a href="#overflow-O" class="headerlink" title="overflow(O)"></a>overflow(O)</h3><p>在模型中，一个overflow代表一个和堆的间接的交互。作者通过在malloc出的chunk的末尾插入符号内存来实现overflow。和free事务类似，HEAPHOPPER将会为先前分配的chunk创建一个不同的序列作为overflow的目标。和malloc同样的原因，需要限制溢出的长度。在这将会把overflow的大小作为symbolic-but-constrained 处理。HEAPHOPPER 还支持根据不同的场景将overflow的字节设定为特定的范围。</p><h3 id="use-after-free-UAF"><a href="#use-after-free-UAF" class="headerlink" title="use-after-free (UAF)"></a>use-after-free (UAF)</h3><p>我们通过将符号内存写入已经free的chunk作为UAF事务。和之前的事务相似，HEAPHOPPER需要为之前free过的chunk创建一个不同的序列，将有限的字节的数据写到内存中。</p><h3 id="double-free-DF"><a href="#double-free-DF" class="headerlink" title="double-free (DF)"></a>double-free (DF)</h3><p>double-free被建模为对之前释放过的内存执行free</p><h3 id="fake-free-FF"><a href="#fake-free-FF" class="headerlink" title="fake-free (FF)"></a>fake-free (FF)</h3><p>fake-free是释放一个假的，攻击者自定义的chunk。它被建模为free一个完全符号化的内存区域。这个符号化区域的大小必须有个限制。如果可能的话，符号执行单元将会自动确定符号区域的值能通过堆分配器的检查。</p><h3 id="堆交互模型"><a href="#堆交互模型" class="headerlink" title="堆交互模型"></a>堆交互模型</h3><p>HEAPHOPPER 将结合之前描述的堆事务生成一个交互列表，每个交互对应着堆模型的一条路径。HEAPHOPPER 通过创建所有可能的事务序列的排列来生成交互列表。</p><p>在这一步主要关注如何减少生成的事务序列而不丢失会导致产生exploitation primitives 的事务序列。因此，我们假设至少一次对堆进行了误操作（直接或间接），并且假设对堆的良性使用不会产生任何问题。此外，还排除了只有一个间接交互作为事务序列结束的情况，因为间接交互无法修改堆本身，修改堆本身至少需要一个直接交互。两个会对同一区域放置符号内存的的事务之间必须有影响这片内存的事务。</p><h1 id="模型检测"><a href="#模型检测" class="headerlink" title="模型检测"></a>模型检测</h1><h2 id="识别安全违规行为"><a href="#识别安全违规行为" class="headerlink" title="识别安全违规行为"></a>识别安全违规行为</h2><h3 id="Overlapping-Allocation-OA"><a href="#Overlapping-Allocation-OA" class="headerlink" title="Overlapping Allocation (OA)"></a>Overlapping Allocation (OA)</h3><p>HEAPHOPPER 使用 SMT求解程序去判断如下条件是否为真</p><p>∃B : ((A ≤ B)∧(A+sizeof(A) &gt; B))∨((A ≥ B)∧(B+sizeof(B) &gt; A))</p><p>A为申请的内存，B为已申请的内存</p><h3 id="Non-Heap-Allocation-NHA"><a href="#Non-Heap-Allocation-NHA" class="headerlink" title="Non-Heap Allocation (NHA)"></a>Non-Heap Allocation (NHA)</h3><p>提前记录堆分配器使用brk和mmap返回的地址，从而确定堆的范围</p><h3 id="Arbitrary-Write-AW-and-AWC"><a href="#Arbitrary-Write-AW-and-AWC" class="headerlink" title="Arbitrary Write (AW and AWC)"></a>Arbitrary Write (AW and AWC)</h3><p>在调用malloc，free时通过检测符号内存区域是否有写入来判断是否有AW或AWC。具体来说,我们查询约束求解器检查是否可以指定的写入特定的内存区域。</p><h1 id="局限性"><a href="#局限性" class="headerlink" title="局限性"></a>局限性</h1><h2 id="模型限制"><a href="#模型限制" class="headerlink" title="模型限制"></a>模型限制</h2><p>当前情况下需要手动指定攻击者可以执行的事务。HEAPHOPPER无法对可能发生但是HEAPHOPPER中没有实现的攻击场景进行推理。之前为了减少符号执行样本的数量加入了一些限制条件，这可能会导致HEAPHOPPER错过一些利用。其次一些攻击需要执行很多事务才能把堆设置为理想的状态</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h1&gt;&lt;p&gt;堆元数据攻击已成为攻击者利用内存损坏漏洞的主要方式之一。虽然堆实现开发人员已经引入了缓解来防
      
    
    </summary>
    
      <category term="论文" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/"/>
    
      <category term="自动化利用" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/%E8%87%AA%E5%8A%A8%E5%8C%96%E5%88%A9%E7%94%A8/"/>
    
    
      <category term="2018年" scheme="http://yama0xff.com/tags/2018%E5%B9%B4/"/>
    
      <category term="exploitation" scheme="http://yama0xff.com/tags/exploitation/"/>
    
      <category term="heap" scheme="http://yama0xff.com/tags/heap/"/>
    
      <category term="符号执行" scheme="http://yama0xff.com/tags/%E7%AC%A6%E5%8F%B7%E6%89%A7%E8%A1%8C/"/>
    
      <category term="USENIX&#39;18" scheme="http://yama0xff.com/tags/USENIX-18/"/>
    
  </entry>
  
  <entry>
    <title>Check It Again: Detecting Lacking-Recheck Bugs in OS Kernels</title>
    <link href="http://yama0xff.com/2019/02/05/Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels/"/>
    <id>http://yama0xff.com/2019/02/05/Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels/</id>
    <published>2019-02-05T11:05:47.000Z</published>
    <updated>2019-02-14T08:26:26.352Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>论文中，作者主要介绍分析操作系统内核中的LRC（lacking-recheck）类型bug。并介绍了自己设计的一个静态分析系统LRSan（在Linux上实现），用于检测操作系统内核中的LRC bug。<strong><em>本文的主要贡献： 1. 定义了LRC bugs，并第一次展示了关于LRC bug的深入研究。 2. 实现一个自动化的LRC bug检测系统（LRSan），基于LLVM，使用在Linux内核上，可以检测内核中的LRC bug。LRSan运用了很多新的程序静态分析技术。结果显示LRSan在Linux内核发现了2808个LRC case，检测耗时为4小时。并且作者会将它开源。 3. 识别Security check（SC）和相关Critical variable（CV）的方法。 4. 发现了Linux内核中的19个新的LRC bug。</em></strong></p><table><thead><tr><th>relevant information</th><th></th></tr></thead><tbody><tr><td><em>作者</em></td><td>Wenwen Wang, Kangjie Lu, and Pen-Chung Yew</td></tr><tr><td><em>单位</em></td><td>University of Minnesota</td></tr><tr><td><em>出处</em></td><td>CCS’18</td></tr><tr><td><em>原文地址</em></td><td></td></tr><tr><td><em>源码地址</em></td><td></td></tr><tr><td><em>发表时间</em></td><td>2018年</td></tr></tbody></table><h1 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h1><p>如下图所示是LRC Bug形成的流程。</p><p><img src="/2019/02/05/Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels/E:/github\hexo\source\_posts\Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels\1.jpg" alt=""></p><p>如下图所示是一个LRC Bug的例子，其中的val就是<em>CV</em>。在第10行中val被进行了security check，但是在第16至19行中val被进行了修改，在第22行中val又被使用了，然而在使用前没有进行recheck。</p><p><img src="/2019/02/05/Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels/E:/github\hexo\source\_posts\Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels\2.jpg" alt=""></p><p>LRC bug的特点： – 拥有一个check-use chain。即执行路径中有对变量进行安全检查，并在之后对变量进行使用。 – 变量有被修改的可能. 变量在过了前面的security check后，在check-use chain中被修改。 – 缺少recheck。在变量过了安全检查后，如果在使用前又进行了安全检查，那即是在中间被修改了，也是安全的。因此缺少recheck也是LRC bug的成因之一。</p><p>作者在文章中还具体符号化定义了Security check、Use、Modification、Lacking recheck。</p><h2 id="1-1-Security-check"><a href="#1-1-Security-check" class="headerlink" title="1.1 Security check"></a>1.1 Security check</h2><p>Security check需要满足两个条件（作者通过观察总结的规律）才能被认定为是Security check： – 拥有一个条件语句，紧随其后的是两个分支：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">一个分支肯定会返回error code（condition 1）</span><br><span class="line">另一个分支有可能不返回error code（condition 2）</span><br></pre></td></tr></table></figure><h2 id="1-2-Modification1"><a href="#1-2-Modification1" class="headerlink" title="1.2 Modification1"></a>1.2 Modification1</h2><p>在执行路径上，通常变量的的security check和使用是比较复杂也可能比较远的，尤其是在处理涉及到用户空间和内核空间的多个变量时，因此LRC Bug在操作系统内核中是很常见的。</p><p>对security-checked变量的修改可能由如下一些情况导致： 1. Kernel race：操作系统内核通常为线程进程维护了很多共享的数据结构。通常来说很难保证Security checked variable不被修改。 2. User race：从用户空间抓取数据通常很容易被通过用户空间的多进程来进行修改。 3. Logic errors：一些逻辑问题可能导致线程本身不正确地将security-checked variable给修改了。 4. Semantic errors：例如类型转换和整数溢出的一些语义错误可能导致security-checked variable被修改。</p><h1 id="2-LRSan设计"><a href="#2-LRSan设计" class="headerlink" title="2. LRSan设计"></a>2. LRSan设计</h1><p>LRSan的整个结构和Workflow如下图所示，输入为内核源码编译后的LLVM IR。LRSan预处理时会构建一个全局的call-graph，用来进行inter-procedural analysis，并且标注了error codes。</p><p><img src="/2019/02/05/Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels/E:/github\hexo\source\_posts\Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels\3.jpg" alt=""></p><p>LRsan设计的4个关键部分： 1. Security check identification 2. Critical variable inference 3. check-use chain construction 4. modification inference。</p><h2 id="2-1-Automated-Security-Check-Identification"><a href="#2-1-Automated-Security-Check-Identification" class="headerlink" title="2.1 Automated Security Check Identification"></a>2.1 Automated Security Check Identification</h2><p>作者将security check认为是一个条件语句（例如if语句）。因此检测Secruity check就是查找这样的条件语句。</p><ol><li>搜集所有的error code，构建一个error-code CFG（ECFG），ECFG可以快速地判断出某一个执行路径是否会返回error code。ECFG的示例如下图所示。</li><li>通过前面提到的两个判断Security check的条件，来决定找到的条件语句是否是Security check。</li></ol><p><img src="/2019/02/05/Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels/E:/github\hexo\source\_posts\Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels\4.jpg" alt=""></p><h2 id="2-2-Recursive-Critical-Variable-Inference"><a href="#2-2-Recursive-Critical-Variable-Inference" class="headerlink" title="2.2 Recursive Critical Variable Inference"></a>2.2 Recursive Critical Variable Inference</h2><p>在前面的步骤中可以得到一个Security check set，通过这个set能直接得到Critcal variable set(CSet)，然后再通过CSet去找到更多的<em>CV</em>，查找的原则是越多越好（更少的假阴性，这里用的是反向的污点分析）。</p><p>例如下图，hdr是最先找到的<em>CV</em>，然后又将arg和buf都标记为<em>CV</em>。</p><p><img src="/2019/02/05/Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels/E:/github\hexo\source\_posts\Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels\8.jpg" alt=""></p><p>查找终止的条件是在寻找的过程中中碰到了<strong>hard-to-track values</strong>，例如全局变量，堆上的对象，用户空间的对象，这些可能是来自shared data，external source，如果把这些也标记上，会使得查找更加困难。</p><h2 id="2-3-Check-Use-Chain-Construction"><a href="#2-3-Check-Use-Chain-Construction" class="headerlink" title="2.3 Check-Use Chain Construction"></a>2.3 Check-Use Chain Construction</h2><p>这一步为<em>CSet</em>中的每个变量构建<strong>Check-use chain</strong>。<strong>Check-use chain</strong>可以用一个四元组来表示&lt;<em>SC, CV , Iu , PSet</em>&gt;。</p><p><em>Iu</em>：<em>CV</em>在<em>SC</em>后的第一次使用 <em>PSet</em>：<em>SC</em>后的一系列执行路径（到<em>Iu</em>结束）</p><p>构建<strong>Check-use chain</strong>的方法：污点追踪找到<em>Iu</em>，遍历<strong>CFG</strong>去收集一系列从<em>SC</em>开始，<em>Iu</em>结束的执行路径，这些执行路径的结果记为<em>PSet</em>。</p><p>这里还使用了LLVM里的Alias analysis来寻找一些隐式的use</p><h2 id="2-4-Modification-Analysis"><a href="#2-4-Modification-Analysis" class="headerlink" title="2.4 Modification Analysis"></a>2.4 Modification Analysis</h2><p>在找到了<strong>Check-use chain</strong> &lt;<em>SC, CV , I u , PSet</em>&gt;后，这一步的目的是识别潜在的对<em>CV</em>的修改（<strong>Check-use chain</strong>里找）。</p><p>主要检测的修改操作： 1. <em>CV</em>被修改成了一个新的值，通过一个普通的store指令 2. <em>CV</em>被例如memcpy或者copy_from_user等函数进行了修改。</p><p>如果找到了这样的修改，LRSan会再进一步检测这次修改之后是否有有critical variable进行recheck。最后将没有recheck的情况就认定为是LRC case。</p><h1 id="3-LRSan实现"><a href="#3-LRSan实现" class="headerlink" title="3. LRSan实现"></a>3. LRSan实现</h1><p>作者基于LLVM 6.0.0实现了LRSan。整个实现中包括两个独立的pass（大约3000行代码）。First pass是用来收集和准备静态分析锁需要的信息，例如构建global CFG，alias results。Second pass是用来进行静态分析检测LRC case的。</p><p>作者成功编译了16593个module，只有6个编译失败了。</p><p>过滤部分false positive： 1. <em>CV</em>被修改成的是一个常量 2. <em>CV</em>被修改成的是一个可以过Security check的变量 3. mutex-style check</p><h1 id="4-评估"><a href="#4-评估" class="headerlink" title="4. 评估"></a>4. 评估</h1><h2 id="4-1-Effectiveness"><a href="#4-1-Effectiveness" class="headerlink" title="4.1 Effectiveness"></a>4.1 Effectiveness</h2><p>如下图所示是LRSan检测后导出的检测结果。</p><p><img src="/2019/02/05/Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels/E:/github\hexo\source\_posts\Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels\5.jpg" alt=""></p><p>如下图所示，是LRSan在Linux kernel里找到的19个LRC bug。</p><p><img src="/2019/02/05/Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels/E:/github\hexo\source\_posts\Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels\6.jpg" alt=""></p><h2 id="4-2-Efficieny"><a href="#4-2-Efficieny" class="headerlink" title="4.2 Efficieny"></a>4.2 Efficieny</h2><p>LRSan测试时所用的LLVM IR是用Linux-4.17的源码编译的。作者实验时用的host为一个主存32G的Ubuntu16.04，Quad-Core 3.5 GHz Intel Xeon E5-1620 v4处理器，总共用了4个小时。其中超过80%的时间都是用在first pass（例如信息收集），因为first pass需要构建一个全局的CFG，并收集alias-analysis results。first pass实际上只需要运行一次，因此可以对它的结果进行重用，从而节省时间。</p><h1 id="5-Limitation"><a href="#5-Limitation" class="headerlink" title="5. Limitation"></a>5. Limitation</h1><h2 id="5-1-False-Positives"><a href="#5-1-False-Positives" class="headerlink" title="5.1 False Positives"></a>5.1 False Positives</h2><ol><li>Checked modification，符号执行来过滤</li><li>Satisfiable modification，符号执行来过滤</li><li>Uncontrollable modification，污点追踪来过滤</li><li>Transient check，作者手工排查</li><li>Unconfirmed race：source variable是一个shared variable（例如全局变量），即有可能被其他的线程进程修改，这是作者未来的工作</li><li>Other：静态分析的一些缺陷导致的false positives</li></ol><p><img src="/2019/02/05/Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels/E:/github\hexo\source\_posts\Check-It-Again-Detecting-Lacking-Recheck-Bugs-in-OS-Kernels\7.jpg" alt=""></p><h2 id="5-2-False-Negatives"><a href="#5-2-False-Negatives" class="headerlink" title="5.2 False Negatives"></a>5.2 False Negatives</h2><p>作者在查找security check时是基于失败后会返回error code，但是也有可能不返回error code。另外编译失败的一些kernel module也可能导致False negatives。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h1&gt;&lt;p&gt;论文中，作者主要介绍分析操作系统内核中的LRC（lacking-recheck）类型bug。
      
    
    </summary>
    
      <category term="论文" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/"/>
    
      <category term="fuzzing" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/fuzzing/"/>
    
    
      <category term="2018年" scheme="http://yama0xff.com/tags/2018%E5%B9%B4/"/>
    
      <category term="CCS’18" scheme="http://yama0xff.com/tags/CCS%E2%80%9918/"/>
    
      <category term="Lacking-Recheck Bugs" scheme="http://yama0xff.com/tags/Lacking-Recheck-Bugs/"/>
    
      <category term="Kernels" scheme="http://yama0xff.com/tags/Kernels/"/>
    
  </entry>
  
  <entry>
    <title>Automated Detection Exploitation and Elimination of Double-Fetch Bugs Using Modern CPU Features</title>
    <link href="http://yama0xff.com/2019/02/05/Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features/"/>
    <id>http://yama0xff.com/2019/02/05/Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features/</id>
    <published>2019-02-05T02:50:59.000Z</published>
    <updated>2019-02-14T08:30:14.383Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>Double-fetch bugs 是一种特殊的条件竞争，在高权限线程的time-of-check和time-of-use之间，低权限线程能够修改共享的内存，导致高权限线程访问的内存产生不一致。本文作者提出了一种检测，利用并消除double-fetch bugs的技术DECAF和Dropit。总体来说，<strong><em>贡献如下：1. 把cache attack与kernel fuzzing结合起来。2. 首个自动化的挖掘double-fetch bugs的方法。3. 利用的成功率高达97%。4.利用Hardware Transactional Memory的特性，消除double-fetch bugs。5.方法对fuzz TEE也有效。</em></strong></p><table><thead><tr><th>relevant information</th><th></th></tr></thead><tbody><tr><td><em>作者</em></td><td>Michael Schwarz, Daniel Gruss, Moritz Lipp, Clémentine Maurice, Thomas Schuster, Anders Fogh, Stefan Mangard</td></tr><tr><td><em>单位</em></td><td>Graz University of Technology, CNRS, G DATA Advanced Analytic</td></tr><tr><td><em>出处</em></td><td>AsiaCCS’18</td></tr><tr><td><em>原文地址</em></td><td></td></tr><tr><td><em>源码地址</em></td><td></td></tr><tr><td><em>发表时间</em></td><td>2018年</td></tr></tbody></table><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>现代操作系统的安全依赖操作系统kernel提供隔离性，在对kernel的攻击中，条件竞争是一个很难解决的问题。Double-fetch bugs 就是一种特殊的条件竞争。kernel两次访问同一块内存，首先检查数据的合法性，第二次就使用它，那在这两者之间，内存可能被修改。 Double Fetches有个明显的特征是要访问两次内存。如果数据在cache中，就从cache中读，如果不在就从主存中读到cache中，基于cache的攻击，比如著名的Flush+Reload攻击，可以利用CPU的这个特性来检测Double Fetches。</p><p>Intel TSX的hardware transactional memory特性能够保证当数据被读进transaction后，数据不能被任何transaction之外的操作修改。这种特性被用来实现安全加固，比如在这个场景中就可以天然的防御Double Fetch bugs。</p><p><img src="/2019/02/05/Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features/E:/github\hexo\source\_posts\Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features\1.jpg" alt=""></p><ul><li>通过Flush+Reload边信道检测double fetches</li><li>判断double fetches是否能够被利用</li><li>通过hardware transactional memory消除double fetch bugs</li></ul><h1 id="检测"><a href="#检测" class="headerlink" title="检测"></a>检测</h1><p>主要思想是监控cache访问syscall的参数（比如指针，结构体中的指针），筛选出这些指针后，另起一个Flush+Reload线程对这些指针进行监控。</p><p>效果如下所示，可以明显的看到两次cache的访问。</p><p><img src="/2019/02/05/Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features/E:/github\hexo\source\_posts\Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features\2.jpg" alt=""></p><h2 id="多次cache-hit的分类"><a href="#多次cache-hit的分类" class="headerlink" title="多次cache hit的分类"></a>多次cache hit的分类</h2><p>影响cache acess pattern的因素</p><ul><li>size of data type</li><li>parameter reuse</li></ul><h2 id="检测的概率"><a href="#检测的概率" class="headerlink" title="检测的概率"></a>检测的概率</h2><p>检测成功的概率取决于两次访问时间的间隔。因为本身Flush+Reload需要把数据从cache中清掉，这要消耗大概200多个CPU周期，这就要保证double fetch的两次访问间隔至少要是Flush+Reload两倍的的时间才行。 </p><p><img src="/2019/02/05/Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features/E:/github\hexo\source\_posts\Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features\3.jpg" alt=""></p><h2 id="TrinityDECAF"><a href="#TrinityDECAF" class="headerlink" title="TrinityDECAF"></a>TrinityDECAF</h2><p>作者基于trinity这个kernel syscall fuzz框架，实现了 TrinityDECAF，架构如图，基于trinity，为每个syscall的参数实现了一个监控的进程。</p><p><img src="/2019/02/05/Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features/E:/github\hexo\source\_posts\Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features\4.jpg" alt=""></p><h1 id="利用"><a href="#利用" class="headerlink" title="利用"></a>利用</h1><p>Flush-Reload or Flush+Flush</p><p>fuzz策略</p><ul><li>参数值改成0</li><li>翻转最低有效比特</li><li>增加值</li><li>参数值改为随机值</li></ul><h1 id="消除"><a href="#消除" class="headerlink" title="消除"></a>消除</h1><p>作者实现了Dropit的库，这个是基于硬件的特性，hardware transactional memory保证了两次内存访问之间不能再对该内存修改。实现起来也很简单，使用Intel TSX的XBEGIN和XEND指令讲存在bug的代码包起来即可。</p><p><img src="/2019/02/05/Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features/E:/github\hexo\source\_posts\Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features\5.jpg" alt=""></p><h1 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h1><h2 id="DECAF"><a href="#DECAF" class="headerlink" title="DECAF"></a>DECAF</h2><p>已知漏洞CVE-2016-6516 </p><p><img src="/2019/02/05/Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features/E:/github\hexo\source\_posts\Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features\6.jpg" alt=""></p><ul><li>可行性</li></ul><p><img src="/2019/02/05/Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features/E:/github\hexo\source\_posts\Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features\7.jpg" alt=""></p><ul><li>有效性</li></ul><p><img src="/2019/02/05/Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features/E:/github\hexo\source\_posts\Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features\8.jpg" alt=""></p><ul><li>利用的成功率</li></ul><p><img src="/2019/02/05/Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features/E:/github\hexo\source\_posts\Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features\9.jpg" alt=""></p><ul><li>在TEE上fuzz</li></ul><p><img src="/2019/02/05/Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features/E:/github\hexo\source\_posts\Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features\10.jpg" alt=""></p><ul><li>使用dropit和不使用的比较</li></ul><p><img src="/2019/02/05/Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features/E:/github\hexo\source\_posts\Automated-Detection-Exploitation-and-Elimination-of-Double-Fetch-Bugs-Using-Modern-CPU-Features\11.jpg" alt=""></p><p>参考于GoSSIP.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h1&gt;&lt;p&gt;Double-fetch bugs 是一种特殊的条件竞争，在高权限线程的time-of-ch
      
    
    </summary>
    
      <category term="论文" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/"/>
    
      <category term="fuzzing" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/fuzzing/"/>
    
    
      <category term="Double-Fetch Bugs" scheme="http://yama0xff.com/tags/Double-Fetch-Bugs/"/>
    
      <category term="AsiaCCS&#39;18" scheme="http://yama0xff.com/tags/AsiaCCS-18/"/>
    
      <category term="2018年" scheme="http://yama0xff.com/tags/2018%E5%B9%B4/"/>
    
  </entry>
  
  <entry>
    <title>VUzzer: Application-aware Evolutionary Fuzzing</title>
    <link href="http://yama0xff.com/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/"/>
    <id>http://yama0xff.com/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/</id>
    <published>2019-01-29T09:49:47.000Z</published>
    <updated>2019-01-29T13:06:48.164Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>Fuzzing是一种有效的软件测试技术，用于查找错误。考虑到实际应用程序的大小和复杂性，现代模糊器往往是可扩展的，但在探索执行更深层次的错误或者能够在应用程序中深入渗透但不具有可扩展性方面无效。在本文中，我们提出了一种应用程序感知的进化模糊测试策略，它不需要任何有关应用程序或输入格式的先验知识。<strong>为了最大化覆盖范围并探索更深入的路径，我们利用基于静态和动态分析的控制和数据流特征来推断应用程序的基本属性。</strong>与应用程序无关的方法相比，这可以更快地生成有趣的输入。我们在VUzzer中实现我们的模糊测试策略并在三个不同的数据集上进行评估：DARPA Grand Challenge二进制文件（CGC），一组实际应用程序（二进制输入解析器）和最近发布的LAVA数据集。在所有这些数据集中，通过快速查找几个现有和新的错误，VUzzer产生的结果明显优于最先进的模糊器。</p><table><thead><tr><th>relevant information</th><th></th></tr></thead><tbody><tr><td><em>作者</em></td><td>Sanjay Rawat, Vivek Jain, Ashish Kumar, Lucian Cojocar,Cristiano Giuffrida and Herbert Bos</td></tr><tr><td><em>单位</em></td><td>Computer Science Institute, Vrije Universiteit Amsterdam;Amsterdam Department of Informatics  International Institute of Information Technology, Hyderabad</td></tr><tr><td><em>出处</em></td><td>NDSS ’17</td></tr><tr><td><em>原文地址</em></td><td><a href="https://github.com/wtwofire/database/blob/master/papers/fuzzing/2017-VUzzer%20Application-aware%20Evolutionary%20Fuzzing.pdf" target="_blank" rel="noopener">https://github.com/wtwofire/database/blob/master/papers/fuzzing/2017-VUzzer%20Application-aware%20Evolutionary%20Fuzzing.pdf</a></td></tr><tr><td><em>源码地址</em></td><td><a href="https://github.com/vusec/vuzzer" target="_blank" rel="noopener">https://github.com/vusec/vuzzer</a></td></tr><tr><td><em>发表时间</em></td><td>2017年</td></tr></tbody></table><h1 id="论文简略概括："><a href="#论文简略概括：" class="headerlink" title="论文简略概括："></a>论文简略概括：</h1><p><img src="/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/17.png" alt=""></p><p><strong><em>其它相关源码地址：</em></strong></p><p>污点分析数据存储结构：<a href="https://github.com/lemire/EWAHBoolArray" target="_blank" rel="noopener">https://github.com/lemire/EWAHBoolArray</a></p><p>AFLPIN: <a href="https://github.com/mothran/aflpin" target="_blank" rel="noopener">https://github.com/mothran/aflpin</a></p><p>AFLFAST: <a href="https://github.com/mboehme/aflfast" target="_blank" rel="noopener">https://github.com/mboehme/aflfast</a></p><p>DECREE: <a href="https://github.com/CyberGrandChallenge/cgc-releasedocumentation/blob/master/walk-throughs/pin-for-decree.md" target="_blank" rel="noopener">https://github.com/CyberGrandChallenge/cgc-releasedocumentation/blob/master/walk-throughs/pin-for-decree.md</a></p><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>在本文中，我们介绍了VUzzer，一个应用程序感知的进化模糊器，它既可扩展又可快速发现执行中的漏洞。与优化输入生成过程以最大速率生成输入的方法相比，我们的工作探索了设计领域的一个新点，我们在前端做更多的工作，产生更少但更好的输入。关键的直觉是我们可以通过基于控制和数据流应用功能的“智能”突变反馈回路来提高通用模糊器的效率，而无需采用可扩展性较低的符号执行。我们展示了我们可以通过在模糊运行期间对应用程序进行轻量级静态和动态分析来提取这些功能。我们的控制流功能允许VUzzer优先考虑深度（并因此感兴趣）路径，并在改变输入时优先考虑频繁（因此无趣）路径的优先级。我们的数据流功能允许VUzzer准确地确定改变这些输入的位置和方式。</p><p>由于其应用感知突变策略，VUzzer比现有的模糊器更有效。我们评估了VUzzer在三个不同数据集上的表现：a）DARPA CGC二进制文件[15]，这是一组人工创建的交互式程序，旨在评估错误发现技术; b）一组具有不同复杂程度的Linux程序（djpeg，mpg321，pdf2svg，gif2png，tcpdump，tcptrace）和c）最近发布的来自LAVA团队的二进制文件[17]，许多Linux实用程序都有几个注入的错误。在我们对不同数据集的实验中，我们通过生成数量级较少的输入来表现优于AFL，同时发现更多崩溃。例如，在mpg3211中，我们通过执行23K输入发现300次独特崩溃，而883K输入则通过AFL找到19次独特崩溃。</p><p>贡献：我们做出以下贡献：</p><p>1）我们表明现代模糊器可以“更智能”而不需要采用符号执行（难以扩展）。我们的应用感知突变策略将AFL等最先进的模糊器的输入生成过程提高了几个数量级。</p><p>2）我们提出了几个应用程序特征来支持有意义的输入变异。</p><p>3）我们在三个不同的数据集上评估VUzzer，一个实现我们方法的功能齐全的模糊器，并表明它非常有效。</p><p>4）为了促进该领域的进一步研究和支持开放科学，我们开放我们VUzzer原型的源代码，可在<a href="https://www.vusec.net/projects/fuzzing获得。" target="_blank" rel="noopener">https://www.vusec.net/projects/fuzzing获得。</a></p><h1 id="总体描述"><a href="#总体描述" class="headerlink" title="总体描述"></a>总体描述</h1><p>为了解决上一节中提到的挑战，我们提出了VUzzer，一种应用程序感知的进化模糊器。图1概述了其主要组件。</p><p>由于VUzzer是一个进化模糊器，因此有一个反馈循环可以帮助从旧的输入中获得新的输入。生成新输入时，VUzzer会根据其在上一轮输入上的执行情况来考虑应用程序的特征。通过考虑这些特性，我们使反馈回路“智能”并帮助模糊器找到具有高频率的非零IG的输入。</p><p><img src="/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/1.png" alt=""></p><h2 id="1-特征"><a href="#1-特征" class="headerlink" title="1. 特征"></a>1. 特征</h2><p><strong>数据流特征</strong>：数据流特征提供有关应用程序中输入数据和计算之间关系的信息。 VUzzer使用诸如污点分析之类的众所周知的技术来提取它们，并使用它们根据输入中某些偏移处的数据类型来推断输入的结构。例如，它通过检测x86 ISA的cmp系列的每个指令来确定分支的字节（“分支约束”），以确定它使用哪些输入字节（偏移）以及它与哪些值进行比较。通过这种方式，VUzzer可以确定哪些偏移对于变异感兴趣以及在这些偏移处使用哪些值（在第I部分中提供问题的部分答案）。 VUzzer现在能够通过更频繁地定位此类偏移并通过在这些偏移处使用预期值来满足分支约束来更明智地进行变异。这样做可以解决魔术字节的问题，而无需使用符号执行。</p><p>同样，VUzzer监视lea指令以检查索引操作数是否被污染。如果是这样，它可以确定相应偏移处的值是int类型并相应地改变输入。除了这两个简单但功能强大的特征外，还有许多其他功能。</p><p><strong>控制流特征</strong>：控制流特征允许VUzzer推断某些执行路径的重要性。例如，图2显示了清单3中代码的简化CFG。执行错误块的输入通常是不感兴趣。因此，识别这样的错误处理块可以加速感兴趣输入的生成。我们将在以下部分中展示如何检测错误处理代码。目前，我们假设我们可以启发式地识别包含错误处理程序的基本块。</p><p>另一个例子涉及嵌套块的可达性。到达块F的任何输入更有可能比到达块H的输入更深入到代码中，因为后者不是嵌套的。我们使用控制流特征来对路径进行去优先级和优先级排序。由于枚举应用程序中的所有可能路径是不可行的，我们通过为各个基本块分配权重来实现此度量。具体而言，作为错误处理代码一部分的基本块获得负权重，而难以到达的代码区域中的基本块获得更高权重。</p><p><img src="/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/2.png" alt=""></p><p>图1显示了单次模糊测试包含几个步骤。 VUzzer期望有效输入的初始池SI，称为种子输入。第一步是执行过程内静态分析以获得一些控制流和数据流特征（第III-B节），然后是主要的进化模糊循环。在本节的其余部分，我们将介绍描述整个过程的所有步骤。</p><h2 id="2-静态分析器"><a href="#2-静态分析器" class="headerlink" title="2.  静态分析器"></a>2.  静态分析器</h2><p>在模糊测试过程开始时，我们使用轻量级过程内静态分析来（i）通过扫描应用程序的二进制代码来获得cmp指令的立即值，以及（ii）计算应用程序二进制文件基本块的权重。</p><p>应用程序代码中cmp指令中存在的许多立即值通常表示应用程序期望输入在某些偏移处具有许多这些值。例如，清单3中对程序的分析产生了每个基本块的权重列表LBB和包含{0xEF，0xFD，％，@，MAZE}的字节序列的列表Limm。为了确定基本块权重，我们将每个函数的CFG建模为马尔可夫模型，并计算到达函数中每个基本块b的概率pb。然后我们计算每个基本块b的权重wb为1 / pb。因此，到达基本块的概率越低，权重越高。使用该模型，每个基本块的概率和权重显示在图2中的每个节点旁边（参见第IV-A3节）。我们观察到，例如，到达基本块G的概率小于到达基本块F的概率，而基本块F的概率低于基本块H.VUzzer在模糊循环的后续步骤中使用这些列表。</p><h2 id="3-主fuzzing循环"><a href="#3-主fuzzing循环" class="headerlink" title="3.  主fuzzing循环"></a>3.  主fuzzing循环</h2><p>我们通过使用算法1中的步骤来描述主fuzzing循环。在主循环开始之前，我们用一组种子输入SI执行应用程序以推断出一组初始的控制流和数据流特征。对于SI中的所有输入，我们运行动态污点分析（DTA）以捕获有效输入的共同特征。具体来说，我们这样做是为了前面提到的魔术字节和错误处理代码检测。使用这些功能，我们生成一个初始输入总体，作为算法1中INITIALIZE步骤的一部分。请注意，我们的魔术字节检测确保这些新输入跨越第一次这样的应用程序检查。由于DTA具有很高的开销，我们在主循环开始后尽可能少地使用它。</p><p><strong>输入执行</strong>：我们使用上一步中的每个输入执行应用程序，并生成相应的已执行基本块的跟踪。如果任何输入执行以前未见过的的基本块，我们会污染输入并使用DTA通过监视应用程序的数据流功能来推断其结构属性。</p><p><strong>适应度计算</strong>：在算法1的EVALUATE步骤中，我们计算每个输入的适应度作为执行的基本块的频率的加权和。我们使用权重列表LBB在基本块上分配权重。属于错误处理代码的基本块会产生负权重 - 现在我们仍然假设我们可以识别这些基本块。该适应度计算背后的直觉是为执行具有较高权重的基本块的输入提供高分，从而对相应路径进行优先级排序，同时还执行具有高频率的某些基本块以捕获大循环。例如，让我们考虑两个路径p1和p2，分别由两个输入i1和i2执行，使得p1 = A-&gt; B - &gt; D - &gt;E - &gt;H - &gt;J和p2 = A - &gt;B - &gt;D - &gt;E - &gt;F - &gt;J.为简单起见，让我们假设错误处理基本块J得到权重-1并且每个基本块的执行频率为1.使用图2中的权重，p1和p2的频率的加权和为7 （1 + 1 + 2 + 2 + 2-1）和9（1 + 1 + 2 + 2 + 4-1）。因此，输入i2获得更高的适应度分数，并且将比i1更多地参与生成新输入。该步骤最终生成按其适应度分数降序排列的输入排序列表。</p><p><strong>遗传算子和新输入生成</strong>：这是我们模糊测试策略中最后也是最重要的功能，包括算法1中的SELECT，RECOMBINE和MUTATE步骤。这些子步骤一起负责生成有趣的输入。在主循环的每次迭代中，我们通过组合和突变SI的输入，所有受污染的输入以及Lf的前n％来生成新一代输入。我们将此集称为ROOT集。</p><p>具体来说，我们通过交叉和变异生成新的输入。首先，我们从ROOT中随机选择两个输入（父项）并应用交叉来生成两个新输入（子项）。具有固定概率，这两个输入进一步经历突变。 Mutation使用多个子操作，例如删除，替换和在给定输入中的某些偏移处插入字节。变异运算符利用数据流功能生成新值。例如，在插入或替换字节时，它使用来自Limm的字符来生成不同长度的字节序列。类似地，选择来自当前输入的父项的各种偏移用于突变。因此，如果存在任何魔术字节，它们将在结果输入中的适当偏移处被替换。</p><p>这个循环的输入生成一直持续到我们满足终止条件。目前，我们在发现崩溃或VUzzer达到预先配置的代数时终止。</p><h1 id="设计与实现"><a href="#设计与实现" class="headerlink" title="设计与实现"></a>设计与实现</h1><h2 id="1-实现细节"><a href="#1-实现细节" class="headerlink" title="1. 实现细节"></a>1. 实现细节</h2><p><strong>1）动态污点分析（DTA）</strong>：DTA是VUzzer的核心，因为它在发展新输入方面发挥着重要作用。这也是将VUzzer与现有模糊器区分开来的技术。 DTA用于监视应用程序内受污染的输入（例如，网络包，文件等）的流动。在程序执行期间，DTA可以确定哪些存储器位置和寄存器依赖于受污染的输入。根据粒度，DTA可以将受污染的值追溯到输入中的各个偏移量。 VUzzer使用DTA跟踪cmp和lea指令中使用的污染输入偏移。对于每个执行的cmp指令cmp op1，op2（op1和op2可以是寄存器，存储器或立即操作数），DTA确定op1和/或op2是否被一组偏移污染。我们的DTA实现能够在字节级别跟踪污点。对于给定的受污染操作数op，DTA为op的每个字节提供污点信息。</p><p><strong>2）魔术字节检测</strong>：基于我们对具有魔术字节的文件格式的理解，我们假设魔术字节是输入字符串中固定偏移处的固定字节序列。我们已经在几种具有魔术字节的文件格式上验证了这一假设，例如jpeg，gif，pdf，elf和ppm。由于VUzzer是给定应用程序的一些有效输入的可用性，我们在模糊测试开始时在这些输入上使用DTA的结果。由于应用程序期望输入包含魔术字节，因此DTA在cmp指令上的结果将包含对魔术字节的相应检查。</p><p>例如，清单3中的代码在输入文件的开头需要一个魔术字节0xFDEF。因此，DTA将捕获两条cmp指令 - cmp reg，0xFD，reg受到偏移0的污染，cmp reg，0xEF，reg受到偏移量1的污染。如果对这个程序我们有一个有效输入的集合，我们可以在所有相应的执行中观察这两条cmp指令。相反，如果对于一组有效输入，我们在所有输入的DTA结果中得到cmpi =（oi; vi），vi是偏移oi的魔术字节的一部分。</p><p>在魔术字节检测期间，对于给定的cmpi指令，如果相应的值取决于每个字节的多个偏移，我们不认为这种偏移是魔术字节候选。例如，对于给定的cmp指令，如果DTA检测到|Tji|&gt; 1，我们从魔术字节占位符的任何进一步考虑中排除这些偏移（ÎTji）。这种情况表明相应操作数的值可以从那些偏移ÎTji处的污染值导出。对多个字节的依赖打破了魔术字节是固定（常量）字节序列的假设。我们将所有这些偏移的集合表示为Oother。</p><p><strong>3）基本块权重计算</strong>：从基于覆盖的fuzzing角度来看，每条可行路径对于遍历都很重要。一个简单的模糊测试策略是花费同等的努力为所有可行路径生成输入。但是，由于存在控制结构，某些路径的可达性可能与其他路径的可达性不同。如果我们有嵌套的控制结构，这种情况就会频繁出现[41]。因此，与其他输入相比，任何运行这种难以触及的代码的输入都应该得到更多奖励。</p><p>我们通过为嵌套控制结构中包含的基本块指定更高权重来合并此奖励。由于枚举过程间级别的所有路径都难以缩放，我们的分析在过程间级别，即，我们计算包含在函数内的每个基本块的权重。稍后，我们收集并添加由给定输入执行的路径中所有基本块的权重。通过这种策略，我们通过将几个过程内路径分数拼接在一起来模拟过程间路径的分数。</p><p>如果我们认为特定基本块的输入到下一个基本块的转换取决于某个概率，我们可以从控制流图（CFG）中导出一个称为马尔可夫过程的概率模型用于输入行为。马尔可夫过程是一个随机过程，其中给定试验的结果仅取决于过程的当前状态[30]。我们将函数的CFG建模为马尔可夫过程，其中每个基本块具有基于其与其他基本块的连接的概率。</p><p>对于给定的基本块，我们为其所有输出边分配相等的概率。因此，如果out（b）表示基本块b的所有输出边缘的集合，则∀eb <em> Î out（b）; prob（eb </em>）= 1/|out（b）|。基本块b的转移概率（似然）计算如下：</p><p><img src="/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/11.png" alt=""></p><p>其中prod（b）是b的所有前辈的集合。我们使用定点迭代算法来计算与CFG中的每个基本块相关联的概率。 CFG的root基本块初始化概率为1。通过为每个后备项分配固定概率1来处理循环，从而忽略后备本身的影响（即，我们将循环展平以加速定点计算）。从等式1，每个基本块b的权重由下式给出：</p><p><img src="/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/12.png" alt=""></p><p><strong>4）错误处理代码检测</strong>：如前所述，在模糊测试期间，大多数突变输入将执行最终处于某种错误状态的路径。对这些执行路径进行优先级排序是提高创建有趣输入的机会的关键一步。我们的错误处理检测启发式依赖于有效输入的可用性，这是VUzzer的先决条件。由于我们的错误处理检测取决于应用程序的动态行为，因此它以增量方式检测错误处理基本块。</p><p><strong><em>初始分析</em></strong>：对于每个有效输入iÎSI，我们收集由i执行的基本块的集合BB（i）。设ValidBB表示所有有效输入的所有这些已执行基本块的并集。然后我们创建一组完全随机的输入，表示为TR。对于此集合中的每个输入，我们根据基本块收集其执行跟踪。如果在来自TR的输入的每次执行中存在并且它不存在于ValidBB中，则假定来自这样的一组执行的基本块是错误处理基本块（即，属于错误处理代码）。直觉是因为SI是一组有效输入，所以不会触发错误处理代码。因此，ValidBB将仅包含与有效路径对应的基本块。由于TR是一组完全随机的输入，它们很可能在执行期间被错误处理代码捕获。</p><p>我们是一种非常保守的错误处理基本块检测策略，因为如果某些输入被不同的错误处理代码捕获，我们可能会错过几个基本块。尽管如此，请注意，我们永远不会将与有效路径对应的基本块分类为错误处理基本块。更正式的表示如下</p><p><img src="/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/13.png" alt=""></p><p>EHB就是错误处理基本块集合。</p><p><strong><em>增量分析</em></strong>：我们观察到，由于我们的错误处理检测策略基于应用程序的动态行为，因此在初始分析期间不会触发所有错误处理代码。随着输入的发展，它们会探索更多路径，从而遇到新的错误处理代码。出于这个原因，我们在后来的模糊测试迭代期间启动增量分析。在我们的实验设置中，我们观察到，随着我们进行更多的模糊测试迭代，新的错误处理代码实例的数量减少了。这反映了软件具有有限数量的错误处理代码实例的直觉，这些代码实例在应用程序的不同部分中重用。因此，当我们执行更多迭代时，我们减少运行增量分析的频率。</p><p>我们的增量分析背后的直觉是观察到，随着模糊测试的进行，大多数新生成的输入最终会触发一些错误处理代码。在给定的迭代中，让I成为迭代中生成的输入集。让大多数量由|I|的n％量化。我们的（离线）实验表明，n = 90是一个合理的选择。设BB（I）是由I中的输入执行的所有基本块的集合。如果它与来自I的输入少与n％的相关联，且它不在V alidBB集中，则将来自BB（I）的基本块b分类为错误处理基本块。更正式地说，让P（I）表示I的幂集。然后</p><p><img src="/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/14.png" alt=""></p><p><strong><em>错误处理基本块的权重计算</em></strong>：在检测到错误处理基本块（EHB）之后，我们希望对包含此类块的路径进行优先级排序。我们通过惩罚相应的输入来实现这一点，以便这些输入参与下一代的机会较少。为此，每个EHB都给出负权重，这会影响相应输入的适合度（见第IV-A5节）。然而，这种策略本身并不充分，因为与输入执行的基本区块总数相比，EHB只是少数，因此这么小的数量将产生微不足道的影响。我们通过定义影响系数μ（可调参数）来解决这个问题，影响系数μ决定单个错误处理基本块可以使多少（非错误处理）基本块无效。直观地，该参数确定，一旦输入进入错误处理代码，任何相应基本块在计算适合度分数时的贡献必须减少因子μ。对于给定的输入i，我们使用以下公式进行重量计算。</p><p><img src="/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/15.png" alt=""></p><p>其中|BB（i）|是由输入i执行的所有基本块的编号，|EHB（i）|是由i执行的所有错误处理基本块的编号，并且0.1≤μ≤1.0。</p><p><strong>5）适应度计算</strong>：适应度计算是进化算法最重要的组成部分之一。这对于实现反馈回路至关重要，这为下一步的输入生成提供了动力。一旦产生新的输入，其参与产生新输入的机会取决于其适合度。</p><p>VUzzer以两种方式评估输入的适应性。如果输入的执行导致发现新的非EHB基本块，则输入有资格参与下一代。这类似于AFL（额外使用EHB组）。然而，如前所述，这种适应度测量认为所有新发现的路径相等，这是有问题的。输入的重要性（以及因此适应性）取决于其执行的路径的兴趣度，而该路径又取决于相应基本块的权重。因此，我们将输入i的适应度fi定义为捕获所有相应基本块权重的效果的函数。</p><p><img src="/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/16.png" alt=""></p><p>其中BB（i）是由输入i执行的基本块的集合，Freq（b）是当由i执行时基本块b的执行频率，Wb是基本块b的权重（通过使用等式2），li是输入i的长度，LMAX是输入长度的预配置限制。 LMAX用于解决输入膨胀现象。在遗传算法的说法中，两个适应度标准（即发现新基本块的能力和更高的fi）都对应于探索和开发的概念 - 发现新的基本块表示新的方向（即探索）和较高的fi表示基本块的较高执行频率（以及其他因素）（即，在相同方向上的利用）。</p><p><strong>6）输入生成</strong>：VUzzer的输入生成由交叉和变异两部分组成，它们不是互斥的，即交叉以固定的概率跟随在变异之后。</p><p>交叉：交叉是一种简单的操作，其中从前一代中选择两个父输入，并生成两个新的子输入。</p><p>变异：变异是一种更复杂的操作，它涉及若干子操作以将给定的父输入改变为相应的子输入。该过程在以下步骤中详述：</p><ul><li><p>步骤1：从集合Oother中随机选择受污染的偏移量并在这些偏移量处插入字符串。字符串由从集合Limm获得的字节组成。</p></li><li><p>步骤2：从集合Llea中随机选择偏移量并通过用有趣的整数值（例如0，MAX UINT，负数）替换它们来改变来自步骤1的字符串中的这种偏移量。</p></li><li><p>步骤3：对于父输入的所有受污染的cmp指令，如果op1 ≠ op2的值，则将步骤2中字符串中受污染偏移的值替换为op2的值，否则将以固定概率替换受污染的值字节由随机字节序列组成。</p></li><li><p>步骤4：将魔术字节放置在由我们的魔术字节检测器确定的相应偏移处。</p></li></ul><h2 id="2-实现细节"><a href="#2-实现细节" class="headerlink" title="2. 实现细节"></a>2. 实现细节</h2><p>VUzzer的核心功能是在<strong><em>Python 2.7</em></strong>中实现的。一些实现的分析，例如错误处理基本块检测的增量分析，是内存密集型的，因此我们还利用了更新版本（如<strong><em>BitVector3</em></strong>）提供的高效数据结构。 VUzzer内部由两个主要组件组成，包括静态和动态分析，如下面进一步详述。</p><p><strong>静态分析</strong>：VUzzer在IDA [27]中实现了两种静态分析（常量字符串提取和基本块权重计算）。分析是使用IDAPython [18]用Python编写的。</p><p><strong>动态分析</strong>：VUzzer在Pin动态分析框架的顶部实现了动态分析（基本块跟踪和DTA）[31]。对于基本块跟踪，我们实现了一个pintool来记录执行期间遇到的每个基本块及其频率。我们的pintool可以根据需要有选择地跟踪某些库执行的基本块。选择性库监控允许我们减少执行跟踪开销并专注于预期的应用程序代码。</p><p>我们的DTA实现基于Stamatogiannakis等[46]提出的<strong><em>DataTracker</em></strong>，后者又基于LibDFT [29]。由于LibDFT只能处理32位应用程序，因此当前的VUzzer原型只能用于模糊32位应用程序（也用于我们的评估）。请注意，这不是一个基本限制，事实上，我们正在VUzzer中实现64位支持。任何更新版本将在<a href="https://www.vusec.net/projects/fuzzing上提供。" target="_blank" rel="noopener">https://www.vusec.net/projects/fuzzing上提供。</a></p><p>为了使其适合我们的目的，我们还对DataTracker进行了一些更改：</p><ul><li><p>在DataTracker中，与每个内存位置关联的污点标记被建模为元组：&lt;ufd，file_offeset&gt;，即唯一文件描述符和与该描述符关联的文件的偏移量。这些元组中的每一个都是64位长（ufd为32位，file_offset为32位）。每个内存位置都有一组与之关联的元组，以确定偏移量和内存位置受污染的文件。我们将其更改为<strong>EWAHBoolArray type</strong>，它是一种压缩的bitset数据类型。由于我们只需要来自一个（输入）文件的数据流信息，因此我们修改了DataTracker以仅通过该文件传播污点。因此，在我们的修改版本中，与每个存储器位置相关联的污点标签被建模为仅包含偏移的EWAHBoolArray。因此，我们的实现速度至少快2倍，并且使用的内存比DataTracker少几倍。</p></li><li><p>我们为cmp系列指令添加了插桩回调，如CMP，CMPSW，CMPSB，CMPSL和lea指令，以捕获计算中涉及的操作数的字节级污点信息。</p></li><li><p>我们为每个实现的系统调用重写了钩子，并为一些额外的系统调用添加了钩子，例如pread64，dup2，dup3，mmap2等。为了评估我们在DARPA数据集[15]上的性能，我们还实现了基于DECREE的钩子系统调用，与普通的Linux系统调用不同。</p></li></ul><p><strong>crash分类</strong>：一旦模糊测试开始产生崩溃，它可能会继续产生更多的崩溃，并且应该有一些机制来区分由于不同的错误（或相同的错误但不同的实例）导致的崩溃。为了确定崩溃的唯一性，<strong>VUzzer使用由Molnar等人提出的堆栈散列的变体[37]</strong>。在我们的pintool中，我们实现了一个环形缓冲区，用于跟踪最后5个函数调用以及在崩溃之前执行的最后10个基本块。我们计算此缓冲区的哈希值，每次遇到新的崩溃时，我们将新生成的哈希值与旧的哈希值进行比较，以确定报告的崩溃是否是新的唯一崩溃。</p><h1 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h1><p>为了测量我们提出的模糊测量技术的有效性，本节介绍了对VUzzer的评估。为了将VUzzer显示给各种应用程序，我们选择在三个不同的数据集上测试VUzzer A. DARPA CGC二进制文件[15]，B. [43]中使用的二进制格式的杂项应用程序，C.最近的一组错误二进制文件由LAVA [17]生成。</p><p>我们在配备32位2核Intel CPU和4 GB RAM的Ubuntu 14.04 LTS系统上进行了实验。对于DARPA CGC数据集，（提供的）环境是具有称为DECREE的自定义OS的VM。我们要强调的是，我们的主要评估目标是展示VUzzer在识别错误（可能深埋在执行中）的效率，其输入比AFL等最先进的模糊器少得多。我们当前的VUzzer原型并不像AFL那样针对快速输入执行进行优化，因此我们不寻求这方面的比较。</p><h2 id="A-DARPA-CGC数据集"><a href="#A-DARPA-CGC数据集" class="headerlink" title="A.  DARPA CGC数据集"></a>A.  DARPA CGC数据集</h2><p>作为Cyber Grand Challenge的一部分，DARPA发布了一组二进制文件，这些二进制文件在一个名为DECREE的自定义操作系统中运行。共有131个二进制文件，其中注入了各种类型的错误。但是，由于以下原因，我们无法在所有这些上运行VUzzer：</p><ul><li><p>通过接受来自STDIN的输入，所有二进制文件本质上都是交互式的。一旦启动，其中许多人会提供一个菜单来选择一个动作，包括退出选项。此外，在许多情况下，有多个菜单（在程序的不同状态下）具有不同的退出选项。由于VUzzer需要生成完全随机输入的步骤（错误处理代码检测，第IV-A4节），执行此类输入会使应用程序循环，查找有效选项，包括退出选项。这会导致应用程序永远运行。这是一个接口问题，而不是我们的模糊测试方法的基本限制。</p></li><li><p>其中一些二进制文件是使用浮点指令编译的，这些指令LibDFT不能处理，因此VUzzer无法获得正确的数据流信息。</p></li><li><p>由于VUzzer基于Pin [32]，我们按照给定的程序在DECREE5中运行pintools。但是，我们无法使用Pin运行一些二进制文件。</p></li><li><p>某些二进制文件涉及与其他二进制文件的交互，而VUzzer无法处理这些二进制文件。 </p></li></ul><p>在考虑了上面提到的障碍之后，我们总共留下了63个二进制文件。为了与AFL进行比较，我们还运行了AFLPIN，一种基于pintool的AFL实现。 AFLPIN具有与AFL相同的模糊引擎，但是获取执行跟踪的机制不同。我们选择使用AFLPIN代替AFL是为了与SUT具有相同的接口机制，即通过文件描述符0（STDIN）将输入传递给pintool。</p><p>VUzzer在29个CGC二进制文件中发现了崩溃，而AFLPIN只发现了23个崩溃。由于每个CGC也附带修补版本，我们通过运行修补程序版本的二进制文件来验证VUzzer发现的每个错误，以避免进一步崩溃。最重要的结果是这两个模糊器中每次崩溃的执行输入数量。我们运行两个模糊器最多6个小时。图4描绘了两个模糊器发现崩溃（总共13个）的情况的执行次数，证明VUzzer与AFL相比可以显着修剪搜索空间。</p><p>在对特定二进制NRFIN_00015进行模糊测试时，我们观察到以离散方式计算适应度分数fi的重要性。此二进制文件中的漏洞是循环中缓冲区溢出的典型情况。我们观察到在第18次迭代之后，没有发现新的BB，但是fi保持增加，表明典型的循环执行行为。在第63次迭代（总执行次数13K），我们到达缓冲区的边界。 AFLPIN无法检测到这次崩溃。</p><p>我们注意到，我们目前对该数据集的结果是适度的，特别是在Driller [47]报告的结果中。我们进一步调查了结果，发现了一些可能会影响我们当前VUzzer原型在CGC上的性能的特性。</p><ul><li><p>在多个二进制文件中，只有通过执行给定菜单中的一组非常特定的操作才能达到错误状态。例如，在CROMU_00001应用程序中，必须执行以下操作：登录A - &gt;向用户B发送许多消息 - &gt;登录B - &gt;检查消息。目前，VUzzer无法重复序列。</p></li><li><p>有效输入的概念很模糊。回想一下，我们使用每个CGC二进制文件以XML文件形式提供的整个会话作为一个输入。因此，基本上没有无效输入的概念。因此，我们无法充分利用VUzzer的全部功能。</p></li><li><p>与上述相关的是有趣的抵消问题。由于CGC二进制文件是交互式的，因此输入本质上是一个探索应用程序状态的序列，它可能因输入而异。例如，其中一个二进制文件允许用户加载文件。处理文件时会触发该错误。相应的文件加载菜单可以出现在输入中的任何位置，因此文件中的偏移量与输入中加载的位置相关，因此很难自动推理偏移量。</p></li></ul><p>鉴于上述问题，我们认为VUzzer不适合交互式程序，主要是因为它与这些程序的接口机制不佳。</p><p><img src="/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/3.png" alt=""></p><h2 id="B-LAVA数据集"><a href="#B-LAVA数据集" class="headerlink" title="B.  LAVA数据集"></a>B.  LAVA数据集</h2><p>在最近的一篇论文中，Dolan-Gavitt等人。开发了一种注入难以触及的故障的技术，并创建了一些Linux实用程序的错误版本[17]，用于测试基于模糊测试和符号执行的错误查找解决方案。我们使用LAVA-M数据集[17]来评估VUzzer。该数据集由4个Linux实用程序-base64，who，uniq和md5sum组成，每个注入多个故障（每个实用程序使用相同的二进制文件）。 LAVA论文报告了在这些有缺陷的应用程序上评估基于覆盖的模糊器（FUZZER），符号执行和基于SAT的方法（SES）的结果。</p><p>为了提高可读性，我们重申表II中原始LAVA论文的结果。表II中的最后一列显示了VUzzer产生的结果。显示的数字是VUzzer识别的唯一错误。在md5sum的情况下，我们无法运行VUzzer，因为它在第一轮输入生成时崩溃，而不允许程序解析更多任何输入。 LAVA二进制文件中的每个注入故障都有一个ID，并且在每个二进制文件由于该故障而崩溃之前，ID将打印在标准输出上。这使我们能够精确识别VUzzer触发的故障。表III报告了VUzzer为每个LAVA二进制文件触发的故障的ID。</p><p><img src="/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/4.png" alt=""></p><p>我们的LAVA数据集结果中出现了一些有趣的点。大多数LAVA注入的断层都是基于人工注入的路径条件，如lava到达特定路径并触发bug。由于其数据流功能，VUzzer非常好地捕获了这一点。例如，在base64模糊测试期间，我们了解到前四个字节应该是’val或lav’以跟随特定路径。类似地，我们发现最后几个字节应包含以下任何值以采用不同的路径：las [，lat\x1b，Wsal等。应该注意，LAVA注入的大多数路径约束都是多字节约束。这种约束对于AFL在执行中更深入地造成了严重的问题（如[16]中所述）。另一个有趣的观点是VUzzer对who的表现。 LAVA文件中使用的模糊器甚至找不到一个bug，而VUzzer发现了几个独特的崩溃。</p><p><img src="/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/5.png" alt=""></p><p>总体而言，在两个人工数据集中，VUzzer报告了令人鼓舞的结果，尽管正如预期的那样，它确实与DARPA CGC数据集中的交互式程序相悖。我们现在继续在实际程序中评估VUzzerz，这些程序也被其他模糊器考虑过。</p><h2 id="C-各种应用程序（VA）数据集"><a href="#C-各种应用程序（VA）数据集" class="headerlink" title="C.  各种应用程序（VA）数据集"></a>C.  各种应用程序（VA）数据集</h2><p>我们使用真实世界程序的数据集（djpeg / eog，tcpdump，tcptrace，pdf2svg，mpg321，gif2png）来评估VUzzer的性能。Rebert等人还对这些程序进行了评估，以报告几个错误[43]，因此我们将这些程序纳入我们的评估中，用于比较目的。对于这些程序中的每一个，我们在Ubuntu 14.04中使用vanilla发行版。我们注意到，通过评估这些实用程序，我们还针对一些著名的库，如libpcap，libjpeg，libpoppler和libpng。每个程序最多24小时模糊。为了突出VUzzer的性能，我们还在这些应用程序上运行了AFL。表IV显示了在VA数据集上运行VUzzer和AFL的结果，VUzzer在发现的唯一崩溃次数和触发此类崩溃所需的输入数量方面明显优于AFL。</p><p><img src="/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/6.png" alt=""></p><p>图5详细描述了24小时内崩溃的分布情况。每个图的x轴显示每2小时采样的累计崩溃总和。如图所示，对于几乎所有应用程序，VUzzer在后续的模糊测试中不断发现崩溃，而AFL在几次初始迭代后很快就耗尽了精力。这是因为在后期阶段，AFL无法找到新的（更深的）路径，而VUzzer能够在探索新路径时学习分支约束，因此能够在模糊测试的后期阶段发现崩溃。图5中另一个有趣的注意事项是，与AFL相比，VUzzer不仅能够以更少的输入找到崩溃，而且还可以在更短的时间内完成（参见图5中垂直线的位置）。我们想再次说明我们还没有优化VUzzer来实现快速输入。我们认为存在多种提高VUzzer执行速度的技术，例如，在单个模糊迭代中使用类似AFL的fork服务器，或者在多个核心或机器上分配并发模糊工作者。</p><p><img src="/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/7.png" alt=""></p><h2 id="D-Crash-Triage分析"><a href="#D-Crash-Triage分析" class="headerlink" title="D.  Crash - Triage分析"></a>D.  Crash - Triage分析</h2><p>Fuzzers倾向于产生大量崩溃。修复与崩溃相关的每个错误都是一个耗时但有利可图的过程。提供给软件开发人员的唯一信息是应用程序的版本号和崩溃本身。当然，错误修补工作投入到更多（安全性）关键的错误中。</p><p>！Exploitable [19]是CERT提出的一种工具，它建立在GDB之上，并使用启发式方法来评估由bug引起的崩溃的可利用性。启发式算法基于崩溃位置，内存操作（读取或写入）以及应用程序触发的信号。虽然这种分析不合理，但它简单，快速，并提供了崩溃严重程度的提示。我们使用！Exploitable工具对VUzzer在此数据集上发现的崩溃进行排名。表五列出了我们的结果。</p><p>如表中所示，由于！Exploitable工具的简单性，大多数情况都被标记为未知。没有一个案例被标记为可能可利用。最后，VUzzer在tcptrace中发现的每次崩溃似乎都是可利用的。我们调查了tcptrace中的一个崩溃，并且有一种看似明显的方法来利用它：漏洞是对堆缓冲区的越界写入。写入的边界和数据受到污染（即，受攻击者控制）。</p><p><img src="/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/8.png" alt=""></p><p>了进一步分析VUzzer发现的错误的质量，我们测量了crash与所涉及的库之间的距离（如果有的话）。位于库中的错误可能会包含在使用该库的任何应用程序中，因此这些错误具有高优先级。我们还需要记住，这些是未知的错误，因此其中许多可能是0-day。当我们发现大量独特崩溃时，尽早报告最重要的崩溃是一个优先事项，因此我们依靠自动分析来估计错误的严重性。简而言之，如果库中发生崩溃，那么报告就是一个严重的错误。但是，有时在用户应用程序中会出现错误，但错误的真正原因在于应用程序使用的库。因此，当在应用程序代码中观察到崩溃时，我们还测量距上一次库调用的距离。</p><p>崩溃与库之间的距离由两个指标衡量。首先，我们计算崩溃和最后一次库调用之间执行的指令数。直觉是最终导致崩溃的计算（及其副作用）可能源于库调用。其次，我们计算崩溃和最后一次库调用之间的堆栈帧数。作为一个例子，使用驻留在主应用程序中的输出函数钩子的库（例如 tcpdump，tcptrace，mpg321）被这种启发式方法所覆盖。表VI列出了我们的分析结果。</p><p><img src="/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/9.png" alt=""></p><p>mpg321中的所有崩溃都发生在（libid3tag）库中。发行版维护者对libid3tag库进行了大量修补（补丁级别为10）。这表明该库已知包含许多错误。 gif2png总是在应用程序内部崩溃。高数据的指标均证实了这一点。 pdf2svg大部分时间都在libpoppler中崩溃。堆栈帧距离为3，因为信号从Linux的vdso通过标准库路由。 tcpdump和tcptrace使用相同的（libpcap）库，但由于tcpdump显示网络流的内容，因此它与库的距离更远。</p><p>基于上述分析，我们认为VUzzer报告的许多崩溃事件都发现了0-day漏洞，我们目前正在向开源社区进行负责任的披露。表七提供了迄今为止我们分析和报告的一些错误的信息。</p><p><img src="/2019/01/29/VUzzer-Application-aware-Evolutionary-Fuzzing/10.png" alt=""></p><h1 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h1><p>在前面的部分中，我们已经强调了VUzzer和AFL之类的状态模糊器之间的一些主要区别。在本节中，我们调查了最近在模糊测试领域的其他研究工作。这使我们能够突出显示与现有工作相关的一些功能和差异。</p><h2 id="A-基于搜索的进化输入生成"><a href="#A-基于搜索的进化输入生成" class="headerlink" title="A.  基于搜索的进化输入生成"></a>A.  基于搜索的进化输入生成</h2><p>使用进化算法进行输入生成是软件工程中一个经过深入探索的研究领域[7]，[34]。已经尝试使用进化算法进行输入生成以发现应用程序中的漏洞[25]，[42]，[45]。不同之处在于，这些方法假定应用程序的先验知识集中在导致程序易受攻击部分的路径上。这个属性使这些方法更接近定向模糊测试，因此，我们的模糊测试策略大大偏离它们。与VUzzer不同，与AFL类似，这些方法使用的反馈循环不会尝试将应用程序行为与输入结构相关联以增强输入生成。</p><h2 id="B-Whitebox模糊测试方法"><a href="#B-Whitebox模糊测试方法" class="headerlink" title="B.   Whitebox模糊测试方法"></a>B.   Whitebox模糊测试方法</h2><p>Whitebox模糊测试是通过考虑应用程序的属性来提高传统随机模糊测试性能的最早尝试之一。有许多方法可以使模糊测试更有效，例如，通过应用符号执行和动态污点分析来解决分支约束[20] - [24]，[26]。虽然VUzzer在很多方面都与这些方法不同，但根本的区别仍然是符号执行的使用。与VUzzer类似，Ganesh等人提出的BuzzFuzz [20]利用动态污点分析，但用途完全不同。BuzzFuzz是一个定向模糊器，因此，它不会尝试学习每条路径的约束。它使用污点分析来检测影响代码中危险点的字节，如库调用参数，并在输入中改变这些字节以触发异常行为。大多数这些方法还需要源代码的可用性来执行分析。</p><h2 id="C-Blackbox-Graybox模糊测试方法"><a href="#C-Blackbox-Graybox模糊测试方法" class="headerlink" title="C.  Blackbox / Graybox模糊测试方法"></a>C.  Blackbox / Graybox模糊测试方法</h2><p>尽管简单且完全与应用程序无关，但Blackbox模糊器，如Peach [1]，Sulley [39]和Radamsa [40]已经发现了实际应用程序中的错误。但是，在整篇论文中，我们已经讨论了这种模糊器的局限性。</p><p>最近，基于符号和模仿执行的模糊测试方法在“智能”模糊测试领域占主导地位[12]，[38]，[47]，[51]。 Mayhem [12]是CMU的一个系统，用于自动查找二进制代码中可利用的错误，它使用多种程序分析技术（包括符号执行）来推理给定输入的应用程序行为。这与VUzzer的思想相似。但是，由于VUzzer的目标与Mayhem的目标不同，VUzzer不需要重量级的程序分析技术，而是通过应用基于轻量级程序分析的启发式方法来推断输入的重要属性。同样，Driller [47]使用混合的concolic执行技术[33]通过解决分支约束来进行更深入的路径探索来辅助模糊测试。在[28]中，Kargen’等提出一种不同的方法来生成模糊输入。对于正在测试的给定应用程序，他们的方法通过注入影响输出的故障来修改另一个输入生成器应用程序。使用此策略，错误程序生成变异输入。但是，目前尚不清楚这些突变输入是否确实会影响应用程序消耗这些输入的方式。 TaintScope [49] - 校验和感知模糊器 - 使用污点分析来推断校验和处理代码，这进一步有助于模糊旁路校验和检查。在模糊测试时，VUzzer也可以从这种（补充）技术中受益。在最近的一项工作[8]（与我们的工作同时进行）中，AFLFAST的作者提出了一种基于马尔可夫模型的技术来识别低频路径，以便将模糊测试的重点放在该方向上。部分由VUzzer使用的启发式算法是对由最大输入数量执行的路径进行优先级排序。 VUzzer的错误处理基本块检测技术与此类似，虽然权重很轻。 VUzzer应用其他数据和控制流功能来加速输入生成。</p><p>还有其他一些技术来增强模糊测试[11]，[43]，[51]。 VUzzer还可以通过多种方式从这些方法中受益。例如，种子选择[43]可以帮助VUzzer从一组良好的种子输入开始。</p><h1 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h1><p>本文认为，模糊测试的关键优势在于实现轻量级，可扩展的错误查找技术，并且应用重量级和不可扩展的技术（如基于符号执行的方法）不是提高基于覆盖fuzzing的性能的最终解决方案。在研究了几种现有的通用（黑/灰盒）模糊器（包括最先进的AFL模糊器）后，我们注意到它们往往与应用程序无关，这使得它们在发现根深蒂固的错误方面效率较低。应用程序不可知策略的关键限制是它们无法更快地生成有趣的输入。我们通过模糊化应用程序感知测试过程来解决这个问题。</p><p>我们利用应用程序的控制和数据流特征来推断输入的几个有趣属性。控制流特征允许我们对某些路径进行优先级排序和优先级排序，从而使输入生成成为受控过程。我们通过为基本块分配权重并为输入实现权重感知适应性策略来实现这一点。</p><p>通过使用动态污点分析，我们还监控应用程序的多个数据流特征，使我们能够推断输入的结构属性。例如，这为我们提供了有关输入中的哪些偏移在几个分支条件下使用，哪些值用作分支约束等的信息。我们在反馈循环中使用这些属性来生成新输入。</p><p>我们在一个名为VUzzer的开源原型中实现了我们的模糊测试技术，并在几个应用程序上对其进行了评估。我们还将其性能与AFL的性能进行了比较，结果表明，在几乎所有测试案例中，与AFL相比，VUzzer能够在少于一个数量级的输入下发现错误。这具体表明，通过分析应用行为来推断输入属性是一种可行且可扩展的策略，可以提高模糊性能，并为该领域的未来研究提供有希望的方向。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h1&gt;&lt;p&gt;Fuzzing是一种有效的软件测试技术，用于查找错误。考虑到实际应用程序的大小和复杂性，现代
      
    
    </summary>
    
      <category term="论文" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/"/>
    
      <category term="fuzzing" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/fuzzing/"/>
    
    
      <category term="fuzzing" scheme="http://yama0xff.com/tags/fuzzing/"/>
    
      <category term="污点分析" scheme="http://yama0xff.com/tags/%E6%B1%A1%E7%82%B9%E5%88%86%E6%9E%90/"/>
    
      <category term="LAVA" scheme="http://yama0xff.com/tags/LAVA/"/>
    
      <category term="pin" scheme="http://yama0xff.com/tags/pin/"/>
    
      <category term="静态分析" scheme="http://yama0xff.com/tags/%E9%9D%99%E6%80%81%E5%88%86%E6%9E%90/"/>
    
      <category term="动态分析" scheme="http://yama0xff.com/tags/%E5%8A%A8%E6%80%81%E5%88%86%E6%9E%90/"/>
    
      <category term="CFG" scheme="http://yama0xff.com/tags/CFG/"/>
    
      <category term="NDSS&#39;17" scheme="http://yama0xff.com/tags/NDSS-17/"/>
    
      <category term="2017年" scheme="http://yama0xff.com/tags/2017%E5%B9%B4/"/>
    
  </entry>
  
  <entry>
    <title>NAR-Miner Discovering Negative Association Rules from Code</title>
    <link href="http://yama0xff.com/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/"/>
    <id>http://yama0xff.com/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/</id>
    <published>2019-01-28T09:18:28.000Z</published>
    <updated>2019-01-28T09:55:24.772Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>从基于数据挖掘技术的源代码推断编程规则已被证明对检测软件错误是有效的。现有研究侧重于以A⇒B的形式发现积极规则，表明当操作A出现时，操作B也应该在这里。不幸的是，负面规则（A⇒¬B），表明程序元素之间的相互抑制或冲突关系，没有得到应有的重视。事实上，违反这些负面规则也会导致严重的错误。在本文中，我们提出了一种名为NAR-Miner的新方法，可以从大规模系统中自动提取负关联编程规则，并检测它们的违规行为来发现bug。然而，挖掘负面规则面临着比挖掘正面规则更严重的规则爆炸问题。大多数获得的负面规则都是无趣的，并且可能导致不可接受的错误警报。<strong>为了解决这个问题，我们设计了一个语义约束的挖掘算法，将规则挖掘集中在具有强语义关系的元素上。此外，我们引入信息熵来排列候选负面规则并突出有趣的规则</strong>。因此，我们有效地缓解了规则爆炸问题。我们实现NAR-Miner并将其应用于Linux内核（v4.12-rc6）。实验表明，不感兴趣的规则大大减少，检测到的17个违规行为已被确认为真正的错误并被内核社区修补。我们还将NAR-Miner应用于PostgreSQL，OpenSSL和FFmpeg，并发现了六个真正的错误。</p><table><thead><tr><th>relevant information</th><th></th></tr></thead><tbody><tr><td><em>作者</em></td><td>Pan Bian, Bin Liang,/Wenchang Shi,Jianjun Huang,Yan Cai</td></tr><tr><td><em>单位</em></td><td>School of Information, Renmin University of China; Key Laboratory of DEKE, Renmin University of China Beijing, China; State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences Beijing, China</td></tr><tr><td><em>出处</em></td><td></td></tr><tr><td><em>原文地址</em></td><td><a href="https://github.com/wtwofire/database/blob/master/papers/mine/2018-NAR-Miner%20Discovering%20Negative%20Association%20Rules%20from%20Code.pdf" target="_blank" rel="noopener">https://github.com/wtwofire/database/blob/master/papers/mine/2018-NAR-Miner%20Discovering%20Negative%20Association%20Rules%20from%20Code.pdf</a></td></tr><tr><td><em>源码地址</em></td><td></td></tr><tr><td><em>发表时间</em></td><td>2018年</td></tr></tbody></table><h1 id="1-引言"><a href="#1-引言" class="headerlink" title="1. 引言"></a>1. 引言</h1><p>静态错误/漏洞检测技术通常需要一些先验知识（即检测规则或漏洞签名）[9,13,17,19]。近年来，已经广泛证明了关于bug /漏洞检测的代码挖掘方法是非常有效的[1,4,6,7,14,20,25-27,29,30,36,38,44,47， 49,51-53,57,60]。这些方法自动从程序源代码中提取隐式编程规则，并进一步检测违反这些规则的错误或漏洞。通常，在代码挖掘期间，程序源代码首先被转换为项集[6,25,26,49]，图[7,34,57]或其他形式。接下来，将数据挖掘算法应用于变换后的格式以提取模式（例如，频繁项目集或子图）并推断编程规则。最后一步是检测违反推断规则的行为。例如，PR-Miner [25]和AntMiner [26]从Linux内核挖掘频繁项目集以提取关联规则（作为检测规则）并检测到许多未知错误。</p><p>这些现有研究的基本思想是利用统计数据来编制程序元素，并附带源代码的关系。这种关系表现为积极的编程模式。也就是说，在目标项目中，一些程序元素经常一起出现（达到给定的阈值）或者它们之间存在某种联系。例如，PR-Miner [25]和AntMiner [26]都以A⇒B的形式提取正关联规则，表明在函数内，当程序元素A出现时，元素B也应该出现。因此，如果函数实现违反规则（即，包含A而不包括B），则预期潜在的错误。已经提出了类似的技术来检测潜在的对象滥用错误[53]和控制结构之后缺少的程序元素[7]，已经推断出API的正确使用[60]。所有这些方法都针对一组具有相互支持关系的邻接程序元素，即积极关联。</p><p>然而，在实践中我们观察到一些隐式编程模式以A⇒¬B的形式表现为负关联。也就是说，当A出现时，B不应出现，反之亦然。从这个意义上说，否定规则反映了A和B之间的相互抑制或冲突关系。违反负面规则也可能导致严重的错误。通常不可能手动识别项目中的所有否定规则，尤其是像Linux内核这样的大规模规则。但据我们所知，现有方法没有可以自动从源代码中提取负面规则以进行错误检测。最先进的基于挖掘的解决方案只能提取积极的编程规则。与指示频繁模式的积极规则相比，否定规则通常更隐含，相应的错误更隐蔽。例如，图1中的错误已存在于Linux内核中超过10年（即，在Linux-2.6.4或更早版本中提供）。因此，开发一种自动提取隐式否定编程规则以检测相关错误和漏洞的有效方法既具有挑战性又迫切。</p><p>在本文中，我们提出NAR-Miner解决上述问题。最重要的想法是通过不频繁的模式挖掘来推断有趣的负关联规则，并进一步将相应的违规行为检测为潜在的程序错误。基本上，由于负面规则的性质[56]，直接挖掘不常见的模式以提取负面规则将产生大量规则。我们称之为规则爆炸问题。这些规则中的大多数对于错误检测都是无趣的，即它们不包含任何真实的应用程序逻辑，并且违反它们不会导致错误或程序质量问题。因此，基于这些不感兴趣的规则的检测结果将产生不可接受的误报。例如，直接将现有的负规则挖掘算法[43,46,61]应用于Linux内核将提取多达数十万条规则和数百万条违规行为。在有限的人力资源下进行人工审计变得不可能。为了解决规则爆炸问题，我们提出了一种语义约束的负关联编程规则挖掘算法，以避免尽可能地产生过多的不感兴趣的规则。此外，我们利用信息熵来识别易于导致不感兴趣的规则的一般函数。这一步有助于进一步遏制可能不感兴趣的规则。因此，NAR-Miner可以有效地缓解规则爆炸问题并获得理想的有趣规则来检测潜在的错误。</p><p>我们实现了NAR-Miner的原型，并首先在Linux内核（v4.12-rc6）上进行评估。实验表明，基于语义约束的负规则挖掘和基于信息熵的规则过滤在减少不感兴趣的规则数量方面表现良好。也就是说，它减少了46％的无趣规则（即，在200个排名靠前的负面规则中从198到107）。特别是，它在排名前50位的负面规则中实现了62％的真正正面率。NAR-Miner报告了违反排名最高的200条规则的356条违规行为。我们手动检查结果并发现23个可疑错误和数十个质量问题。我们向Linux内核维护者报告可疑错误。其中17个已被确认为真正的错误，相应的补丁已合并到最新版本（例如，v4.16）。我们进一步将NAR-Miner应用于PostgreSQL v10.3，OpenSSL v1.1.1和FFmpeg v3.4.2。从排名靠前的规则和违规行为中，我们手动识别出六个可疑错误，所有这些错误都由相应的维护人员进行了确认和修复</p><p>本文的主要贡献如下：</p><ul><li><p>据我们所知，我们的工作是第一个专注于从源代码中提取负面编程规则以检测错误的工作。它扩展了基于挖掘的错误检测技术的能力。</p></li><li><p>我们提出了一种通过在规则挖掘中引入程序语义并使用信息熵来识别一般函数来缓解规则爆炸问题的方法，该方法可以有效地提取用于错误检测的理想的有趣负编程规则。</p></li><li><p>我们针对真实世界的大型软件项目实现了NAR-Miner原型。我们将该工具应用于四个大型系统（即Linux内核，PostgreSQL，OpenSSL和FFmpeg）并引发相当多的错误，其中23个已被确认。</p></li></ul><h1 id="2-动机示例"><a href="#2-动机示例" class="headerlink" title="2.动机示例"></a>2.动机示例</h1><p>我们使用来自Linux内核（v4.12-rc6）的简化代码片段来激励我们的方法。在图1中，函数lapbeth_new_device在第5行调用alloc_netdev为网络设备分配一块内存。然后在第8行，在内联函数中调用netdev_priv以获取私有数据的起始地址并将其存储到变量lapbeth。如图1所示，lapbeth指向先前分配的内存中的位置。如果设备注册在第11行失败，则将释放设备的内存块。由变量ndev指向的已分配内存在第21行首先释放，然后在第23行释放私有数据。从代码片段突出显示从内存分配到空闲的执行序列中的关键操作，并相应地描述相应的内存状态。我们使用红色水平线来描述通过free_netdev和kfree的蓝色垂直线释放内存。通过图示，可以很容易地看出代码中存在双重错误。</p><p><img src="/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/1.png" alt=""></p><p>传统的静态检测方法难以在大规模系统（例如Linux内核）中发现此错误和其他类似错误，因为所需的错误模式或规则是特定于应用程序并且难以收集。现有的基于挖掘的方法也无法报告错误。例如，最先进的方法AntMiner [26]提取正关联规则并检查违规。在Linux内核中，我们发现在对alloc_netdev的90次调用中，共有77次出现{alloc_netdev，free_netdev}（85.6％）。并且在533个调用实例中只有一次调用free_netdev后跟kfree（0.2％）。 AntMiner将{alloc_netdev}⇒{free_netdev}视为一个正规则，最小置信度阈值为85％[26]。但是，图1中的代码同时调用alloc_netdev和free_netdev，因此是对规则的支持，而不是违反。因此，上述错误未被发现。此外，由于低信任度（0.2％«85％），AntMiner不会将{free_netdev}⇒{kfree}视为有效规则（即，以最小置信度阈值来消除）。因此，AntMiner无法将“kfree跟随free_netdev”报告为错误。</p><p>从上面的分析中，通过分析元素之间的伴随关系来检测图1中的错误是非常困难甚至是不可能的。实质上，与bug密切相关的两个程序元素（即free_netdev和kfree）是负相关的。通过统计分析可以发现这种知识。具体来说，我们发现在大多数情况下（大约99.8％）在Linux内核中，free_netdev后面没有kfree，我们了解到开发人员大多都知道在free_netdev之后调用kfree可能是不必要的或导致严重问题的情况。受此启发，相对少量的配对事件可被视为异常。</p><p>我们利用不频繁的项集挖掘算法来推断负关联规则并应用规则来检测它们的违规（例如，图1中的那个）。在挖掘和检测期间，我们还考虑了程序语义（例如，数据流信息）。在我们的示例中，kfree与free_netdev共享数据，并且它们的外观一起被视为不常见的模式。因此，我们推断出一个负面规则{free_netdev}⇒¬{kfree}。将规则应用于我们的示例可发现相应的错误（表2中的错误12＃）</p><h1 id="3-我们的方法"><a href="#3-我们的方法" class="headerlink" title="3.我们的方法"></a>3.我们的方法</h1><h2 id="3-1概述"><a href="#3-1概述" class="headerlink" title="3.1概述"></a>3.1概述</h2><p>我们提出了NAR-Miner，目标是检测程序包含一些操作（例如两个函数调用）的错误，这些操作被认为不会出现在一起，该方法不需要任何先验知识。NAR-Miner的高层理念是采用数据挖掘技术从源代码中推断出负关联规则并检测其违规行为。</p><p>图2显示了NAR-Miner的概述。它首先为挖掘阶段准备数据。与大多数基于挖掘的方法类似[6,25,26,49,60]，我们仅从每个单独的函数中提取编程规则，即在程序内，以避免过于复杂的分析。识别每个函数内的程序元素及其语义关系并将其转换为事务，然后将其存储在数据库（称为事务数据库）中。接下来，它从数据库中挖掘频繁且不频繁的项集，它们表示程序元素集。然后，它从挖掘的项集中推断出负关联规则，并利用函数的置信度和熵自动对规则进行排序。最后，它检测违反推断规则的情况，并将排名最高的规则报告为审计的潜在错误。</p><p><img src="/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/2.png" alt=""></p><h2 id="3-2挑战"><a href="#3-2挑战" class="headerlink" title="3.2挑战"></a>3.2挑战</h2><p>以前的研究[43,46,61]表明只有少数表现出负相关关系很有意思的模式。他们通过计算支持和信任来识别有趣规则的技术不能直接用于代码挖掘。构造有趣的负关联规则的程序元素应该在它们的语义中相互压制，而不是偶尔出现在一起。我们的实证研究表明，直接应用Wu等人提出的算法。 [56]从Linux内核中提取的事务数据库生成183,712个负关联规则（参见§4.2.2），而其中99％在采样分析中不感兴趣。报告的违规行为多达309,689起，这使得人工审核变得不可能。我们称之为规则爆炸问题，并将其视为提取负关联规则的主要挑战。我们将以下两个方面归结为规则爆炸的根本原因。</p><ol><li><p>现有的负关联规则挖掘方法[43,45,56,61]主要针对购物篮，医学诊断，蛋白质序列等。对于这类数据，来自挖掘单位的任何两个元素（例如，购物收据）除属于同一单位外，没有任何特定关系。换句话说，挖掘单元的元素是同类的。然而，在程序元素之间，通常存在各种语义关系，例如数据依赖性。忽略这样的关系可能会导致许多不感兴趣的规则由语义上独立的元素组成，这些元素实际上并没有相互抑制，而是偶尔出现在一起。</p></li><li><p>大型项目通常包含一定数量的通用API，几乎可用于所有编程环境，例如Linux中的printk和isalpha。它们可能巧合地与其他操作配对以形成关联规则。即使考虑到挖掘期间的强语义关系（例如，数据依赖性），这些API仍然可能导致许多负面无趣的规则。实际上，API越普遍，它与其他操作的相互抑制就越少。</p></li></ol><p>基于以上见解，我们如下缓解规则爆炸问题。 （1）考虑到如上所述的程序元素的本质，我们将规则挖掘集中在具有强语义关系（例如，数据依赖性）的程序元素上，以尽可能地减少不感兴趣的规则。 （2）我们使用信息熵来衡量API的普遍性，并用它来排列挖掘的候选负面规则。涉及高普遍性API的不感兴趣规则将被排除在最终审计之外。</p><h2 id="3-3数据准备"><a href="#3-3数据准备" class="headerlink" title="3.3数据准备"></a>3.3数据准备</h2><p>NAR-Miner将程序元素转换为事务并将它们存储到数据库中。在本文中，我们关注两种程序元素：函数调用和条件检查，因为许多错误是由函数或条件错误引起的[1,6,21,26,33,38,47,57]。如前所述，我们的目标是从事务中提取负关联规则，其元素具有强大的语义关系。如果它们之间存在数据关联，我们定义两个元素以具有强大的语义关系，包括数据依赖性和数据共享[7]。详细地说，给定两个语句s1和s2，如果s2使用s1中定义的值（即数据依赖），或者它们都出现在同一个执行路径上并使用相同的非常量值（即数据共享），我们说他们在语义上有很强的相关性。程序元素的语义关系通过数据流分析[3,15]来识别。</p><p>NAR-Miner的预处理器建立在GCC（v4.8.2）前端之上，该前端以SSA形式[12]提供控制流图和中间表示，用于数据流分析。图3（a）显示了一段代码，图3（b）显示了相应SSA形式的中间表示。 NAR-Miner可以判断is_valid，foo和bar是依赖于第2行的read2的数据。由于is_valid和foo在同一个执行路径中，因此它们具有数据共享关系。因为foo和bar之间没有路径，所以它们不被认为是语义相关的。</p><p>为了简化挖掘阶段，然后将中间表示转换为事务数据库。每个函数定义都映射到一个事务。事务由两部分组成：程序元素和这些元素之间的一组语义关系。在转储到数据库之前，每个程序元素都被规范化。函数调用用不带参数的函数名表示;如果条件语句中的变量保留某些函数的返回值，或者在其他情况下保留其数据类型，则使用“RET”重命名，如许多挖掘方法[6,7,25,26,57,58]中所做的那样。例如，图3中的条件表达式归一化为“RET == 0”。两个程序元素之间的语义关系表示为事务中的元组。例如，元组（foo，is_valid）表示函数foo和is_valid具有一些语义关系。图3（c）显示了代码片段的语义关系，其中节点表示程序元素，边缘表示关系（黑线表示数据依赖性、红线表示数据共享）。</p><p>我们将每个程序元素映射到一个唯一的整数，因此挖掘被应用于整数集以提高性能，因为大量的字符串等价比较是耗时的。</p><p><img src="/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/3.png" alt=""></p><h2 id="3-4提取频繁和不频繁的项集"><a href="#3-4提取频繁和不频繁的项集" class="headerlink" title="3.4提取频繁和不频繁的项集"></a>3.4提取频繁和不频繁的项集</h2><p>很少调用的程序元素总是很少与其他程序元素一起出现，并且会导致大量的负面模式。然而，这些模式在统计学中毫无意义[56]。因此，我们专注于挖掘负面模式，这些模式的元素经常单独出现但很少发生在一起。对于负关联规则A⇒¬B，其前因（即A）和后续（即B）是频繁的，但它们的组合（即（A∪B））是不频繁的。在本节中，我们将提出我们的算法来提取有趣的频繁和不频繁的项集，并将在下一节中解释如何生成否定规则。</p><p>提取频繁和不频繁项集的现有算法仅依赖于事务数据库中项集的出现[43,46,61]。他们都没有考虑元素之间的语义关系。直接将它们应用于§3.3中生成的数据库将导致大量无趣的规则。据我们所知，没有不常见的项集挖掘算法可以直接应用于我们的工作中。为了解决这个问题，我们设计了一个语义约束的挖掘算法，该算法侧重于提取与语义相关的强项集。强语义相关项集中的元素在语义上都彼此相关，例如，具有数据依赖性或数据共享关系。</p><p>我们基于众所周知的Apriori算法[2]设计我们的算法，该算法应用自下而上的方法通过将较小的频繁项目集合在一起来生成相对较大的候选项集。自下而上方法背后的原则是Apriori属性：频繁项集的任何子集也是频繁的。在我们的例子中，强语义相关项集的任何子集也与强语义相关，因为子集中的任何两个元素必须在语义上相关。因此，强大的语义相关项集也符合Apriori属性，可以自下而上的方式挖掘。</p><p>算法1中显示了我们挖掘频繁和不频繁的强语义相关项集的算法。除了事务数据库，它还要求用户指定两个参数：最小频率支持mfs和最大频率支持mis。如果项集的支持大于或等于mf s，则认为项集是频繁的，如果项集的支持小于或等于mis，则项集是不频繁的。算法的输出是所有频繁项目集（FI）和感兴趣的不频繁项目集（IIs）。</p><p><img src="/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/4.png" alt=""></p><p>在开始时，算法扫描事务数据库以找出所有频繁的1项集（第3行）。然后它试图从频繁的（k-1）-itemsets（第4~14行）中发现频繁且不频繁的k-项集。 k项目集包含k个项目。首先，它通过连接频繁（k-1）-项来生成感兴趣的候选k项集（参见第5行）。如果它们具有k-2个共同项，则可以连接两个（k-1）-itemsets。假设两个可连接（k-1）-itemsets是{i1，…，ik-2，ik-1}和{i1，…，ik-2，ik}，则连接结果是k-itemset {i1，…，ik-2，ik-1，ik}。其次，该算法利用Apriori属性来修剪具有不频繁子项集的k项集（第6行）。之后，调用函数count_support来计算每个k-itemset的支持（第8行）。如果项目集的支持不小于mfs，则将项目集插入Lk（第10行），即一组频繁的k项目集;否则，如果它的支持不大于mis，则将其插入不频繁的k项集Nk集（第12行）。应该注意，支持为0的项集自然会被忽略。 Lk和Nk分别与FI和IIs（第15行）合并。然后，频繁项目集Lk用于生成更大的项集Lk + 1和Nk + 1。当Lk对于某个k为空时，算法终止，并输出收集的频繁/不频繁项集（第17行）。</p><p>函数count_support扫描数据库以计算项集I的支持（第19~27行）。如果事务支持I（第23行），计数器将增加1。当且仅当它包含I中的所有项目以及所包含项目之间的所有可能关系时（表示为关系（I）），事务支持I。例如，图3中的事务支持itemset {foo，is_valid}，因为它不仅包括两个项foo和is_valid，还包括它们之间的语义关系，即元组（foo，is_valid）。但是，事务不支持itemset {foo，bar}，因为它不包含元组（foo，bar）。</p><p>为了挖掘像{kfree}⇒¬{kfree}这样的规则，我们还提取了像{g，g}这样的2项集，其中g经常被调用，但是在同一函数中它的两个调用实例在语义上很少相关。这有助于NAR-Miner找到表2中的错误14＃（参见§4.2.3）。</p><h2 id="3-5生成负关联规则"><a href="#3-5生成负关联规则" class="headerlink" title="3.5生成负关联规则"></a>3.5生成负关联规则</h2><p>负关联规则A⇒¬B意味着两个频繁项集A和B很少出现在同一事务中。也就是说，（A∪B）很少见。事实上，规则的前因和后果实际上是不常见的项目集的不相交分区。一种直接的负关联规则生成方法是从不频繁的项集I中找出所有对，如&lt;A，B&gt;，其中A∪B= I且A∩B=∅。它使用规则A⇒¬B的统一来确定其不频繁。这种说法的定义如下：</p><p><img src="/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/5.png" alt=""></p><p>其中，支持（A∪¬B）是支持A∪¬B，支持A但不支持A∪B的事务数量。因此，我们有支持（A∪¬B）=支持（A）-支持（A∪B）=支持（A）-支持（I），其中I =A∪B。因此，等式1可以改写为：</p><p><img src="/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/6.png" alt=""></p><p>从具有n个元素（n≥2）的不频繁项集I中，通过直接应用上述方法可以生成最多2个（n-1）个负关联规则。但是，对它们的违反是完全相同的，即支持项目集I的事务。因此，在面向错误检测的应用程序中仅跟踪它们中的一个就足够了。注意，从编程的角度来看，规则A⇒¬B意味着B中的元素不应出现在包含A的上下文中。如果反转规则B⇒¬A不感兴趣，则其违规总是误报，因为存在B并不意味着拒绝A.受此启发，在几乎所有情况下，如果我们期望支持不频繁项集I的事务成为真正的错误，那么从I派生的所有负关联规则应该是有趣的。因此，我们可以选择具有最低置信度的规则来表示这些规则。将置信度作为衡量标准，其他规则如果有趣则会很有趣。</p><p>实际编程中的逻辑通常非常复杂。一些挖掘的规则可能不适用于编程实践。根据它们检测到的违规通常是误报。一般方法是对挖掘的规则进行排名，使得有趣的规则排名最高，而无趣的规则排在最低位。现有工作主要根据他们的置信度对规则进行排名（高信任规则排名最高）。然而，这种信任仅反映了几个有限元素之间的（负/正）相关性。实际上，编程规则的有趣性也与其元素是否集中在某些上下文有关。也就是说，如果元素的调用上下文趋向于更加同类，则由它组成的规则更可能是有趣的。否则，如果元素在非常不同的上下文中使用，则它更通用，并且更可能与各种元素一起出现。在本文中，我们使用一般性来表明元素的上下文有多不同。一般而言，规则由具有高一般性的元素组成，更可能是无趣的元素。</p><p>我们引入信息熵来定量测量元素的一般性。对于程序元素g的调用实例，我们通过g依赖的元素和依赖于g的元素两个来描述它的上下文。我们在g的所有调用实例中提取这些元素并将它们放入包中。包的信息熵反映了调用实例的不同，可以用来衡量g的一般性。包的信息熵（表示为H（g））可以通过等式3计算:</p><p><img src="/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/8.png" alt=""></p><p>其中pi是包中第i个元素的频率; N是g的调用实例数。项集的熵是每个元素的熵的总和。</p><p>根据每个程序元素的一般性，负关联规则R的兴趣度可以测量为：</p><p><img src="/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/10.png" alt=""></p><p>其中H（gi）是元素gi的信息熵。</p><p>我们在算法2中形成了生成负关联规则的方法。该算法将§3.4中提取的频繁项集FI和不频繁项集II以及用户指定的阈值min_conf作为输入。它返回负关联规则NARs的集合。它首先为具有最低置信度的每个不频繁项集I生成代表性规则（第3~5行）。从等式2可以看出，A的支持越小，A⇒¬B的置信度就越低。因此，我们选择支持最小的I子集来生成代表性规则。然后，计算规则的置信度（第6行）并根据阈值min_conf（第7行）进行检查。信息熵用于衡量潜在有趣规则的兴趣（第10行）。最后，负关联规则按其兴趣的降序排序。</p><p><img src="/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/11.png" alt=""></p><h2 id="3-6检测违规行为"><a href="#3-6检测违规行为" class="headerlink" title="3.6检测违规行为"></a>3.6检测违规行为</h2><p>违反负关联规则R：A⇒¬B的是那些支持项集A∪B的事务。直接的方法是直接扫描数据库以找出包含项集A和B的所有事务。但是，这样的枚举方法这非常耗时，特别是对于拥有数十万事务的数据库而言。为了加快检测过程，我们采用了PR-Miner [25]中使用的技巧。在生成频繁且不频繁的项目集时，NAR-Miner还会收集支持它们的事务。我们使用支持者（I）来指示支持项集I的所有事务。然后，违反负关联规则R的集合恰好是支持者（A∪B）。</p><h1 id="4-评估"><a href="#4-评估" class="headerlink" title="4.评估"></a>4.评估</h1><h2 id="4-1实验设置"><a href="#4-1实验设置" class="headerlink" title="4.1实验设置"></a>4.1实验设置</h2><p>我们将NAR-Miner实现为原型系统，以检测大规模C程序中的错误。我们在众所周知的Linux内核（v4.12-rc6）上评估NAR-Miner。 Linux内核已被广泛用作基于挖掘的错误检测方法的评估目标（TOE）[6,14,20,20,22,24-26,30,42,46-48,57,60]。选择Linux内核作为我们的目标的主要原因是我们想要通过检测以前工作中找不到的一些真正的错误来检查我们方法的有效性。 Linux-v4.12-rc6是实验时的最新版本。它包含24,919个C和19,295个标题文件，包括376,680个函数和15,501,651行代码（LoC）。</p><p>为了验证NAR-Miner是否可以应用于其他系统中的错误检测，我们还从不同的域中选择了三种流行的大型C系统：PostgreSQL v10.3，OpenSSL v1.1.1和FFmpeg v3.4.2。 PostgreSQL是一个开源数据库，OpenSSL是一个用于安全通信的库，FFmpeg是一个用于编码/解码多媒体文件的框架。许多错误检测方法选择它们作为评估的目标[19,20,25,35,57]。</p><p>NAR-Miner需要指定三个参数：（1）频繁项集的最小支持阈值（即mfs），（2）不频繁项集的最大支持阈值（即mis），以及（3）有趣的负面规则最小置信度阈值（即min_conf）。通常，如果项目集是具有较高支持的频繁项目集或具有较低支持的不频繁项目集，则项目集将更有趣。此外，较高的最低限度可以进一步消除无趣的负面规则。实际上，不同的参数设置可能导致无法报告某些实际错误或产生过多的错误警报。用户可以保守地或积极地根据检测策略调整这些参数。为了确定合理的参数，我们进行了[6,25,26,49,60]中的实证研究。具体而言，通过抽样分析，当排名前10位的负面规则中有一半以上是有趣的规则时，参数设置被认为是可接受的。在这项研究中，我们将mf设置为15，将mis设置为5，将min_conf设置为85％。在我们的实验中，默认参数设置适用于四种不同的TOE（参见§4.2和§4.3）。</p><h2 id="4-2检测Linux内核中的错误"><a href="#4-2检测Linux内核中的错误" class="headerlink" title="4.2检测Linux内核中的错误"></a>4.2检测Linux内核中的错误</h2><h3 id="4-2-1预处理源代码"><a href="#4-2-1预处理源代码" class="headerlink" title="4.2.1预处理源代码"></a>4.2.1预处理源代码</h3><p>NAR-Miner花了大约77分钟来解析内核源代码并将其转换为事务数据库。在所有函数定义中，有333,248个函数包含一些程序元素（即函数调用或条件检查）。转换后，每个函数定义都映射到数据库中的事务。该数据库包括227,246个不同的元素，其中每个元素对应于函数调用或条件检查。其中，6,203个频繁出现在多个事务中。</p><h3 id="4-2-2挖掘负面规则的有效性"><a href="#4-2-2挖掘负面规则的有效性" class="headerlink" title="4.2.2挖掘负面规则的有效性"></a>4.2.2挖掘负面规则的有效性</h3><p>为了评估包含语义约束规则挖掘和基于信息熵的规则排序的方法的有效性，我们进行了三个实验：NAR-Miner–，NARMiner-，NAR-Miner。每个实验中采用的方法解释如下：</p><ol><li><p>NAR-Miner–：挖掘算法不考虑项目之间的语义关系，挖掘的规则根据其对应性进行排序;</p></li><li><p>NAR-Miner-：基于NAR-Miner–，项目之间的语义关系被用作约束来消除弱语义相关项集;</p></li><li><p>NAR-Miner：基于NAR-Miner-，我们引入信息熵来衡量负关联编程规则的趣味性。该实验评估了NAR-Miner的全部功能。</p></li></ol><p>我们在表1中显示了实验结果，包括频繁项目集（#FI），不频繁项目集（#IIs）的数量，推断的负关联规则的数量，检测到的违规数量以及挖掘，排名和检测的时间成本（时间）很快。</p><p>比较NAR-Miner–和NAR-Miner-或NAR-Miner的结果，我们观察到采用语义约束的挖掘减少了一个数量级的规则和违规总数（＃All列减少约88％） ）。规则爆炸问题在很大程度上得到了缓解。</p><p>由于时间有限，我们在每个实验中手动检查200个排名靠前的负关联规则。这些规则按照他们在NAR-Miner–和NAR-Miner-中的可信度排名，而他们在NAR-Miner中的兴趣则排名靠前。负关联规则如果真的很有意义则标记为“True”，违反它会导致错误或质量问题。例如，{free_netdev}⇒¬{kfree}是一个有趣的（“True”）规则，因为违反它将导致潜在的双重释放错误，例如§2中讨论的错误。在NAR-Miner中，前200条规则中只有2条被认为是有趣的规则。换句话说，其中99％导致违规检测的错误警报。这种有趣规则率低的主要原因是由这些规则组成的程序元素通常在语义上彼此独立。对于下面的例子，虽然在NAR-Miner中排名第一，并且具有99.96％的置信度，但规则{static_key_false}⇒¬{atomic_read}是无趣的，因为这两个函数将完全独立的变量作为包含他们的程序中的实际参数，他们并没有真正压制对方。</p><p><img src="/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/12.png" alt=""></p><p>引入语义约束的挖掘将NAR-Miner-中的误报率降低到90.5％，然而，这仍然太高而不能在实践中被接受。虽然推断规则具有语义相关的所有程序元素，但是一些元素非常通用，并且可以在违规不会导致错误的各种上下文中使用。例如，函数iowrite32是在它们一起出现时依赖于readl的数据，在Linux内核中只出现一次，并且推断出规则{iowrite32}⇒¬{readl}。该规则在NAR-Miner-中排名第8位，并且在99.64％的情况下排名第一，但仍然无趣，因为这两种功能都以各种方式使用，并且它们的组合不会导致任何错误。</p><p>NAR-Miner使用信息熵来测量函数的一般性。 iowrite32和readl分别为5.9和4.6。规则{iowrite32}⇒¬{readl}的有趣性是9.5％，小到足以排名低。以这种方式，大多数不感兴趣的规则被分配低兴趣度值并因此被排在底部，同时潜在有趣的规则被分配具有相对高的兴趣度值并且在顶部排名。在NAR-Miner中，前200个负面规则中有93个标记为“真”，几乎是NAR-Miner-中数字的5倍。特别是，在前50个中有31个“真正的”负规则。真阳性率为62％。也就是说，我们可以在不到两次手动审计中找到一个有趣的规则，这在实际的错误检测中是可以接受的，而不是针对Linux内核等真实的大型系统。</p><p>我们还检查了违反前200条推断规则的情况。从表1中的Violations和#Bugs列中，我们观察到更多报告的违规和由于应用基于语义约束的挖掘和基于信息熵的排序而导致的错误，这最终增强了NAR-Miner的能力，使其能够推断出更多有趣的规则（列#True和TP Rate）</p><p><img src="/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/13.png" alt=""></p><p>4.2.3检测违规行为</p><p>针对NAR-Miner提取的21,166个负关联规则，检测到37,453个违规。我们根据规则的排名手动检查报告的负关联规则及其违规。为了从检测中获得最大的收益，我们选择排名靠前的规则进行审核，因为违反这些规则更可能是真正的错误。我们在一个人一天内检查了200个排名靠前的负面关联规则和相应的356个违规行为（参见表1中的最后一行）。</p><p>我们发现了23个可疑错误和数十个程序质量问题，例如冗余条件检查和计算。由于Linux内核维护者经常忽略质量问题，我们只向Linux内核维护者提交23个可疑错误的补丁。到目前为止，这些补丁中有17个已经被内核维护者所认可和接受。</p><p>表2中列出了确认的bugs，其中包含错误（函数），违反的规则（违规规则）以及三个实验中的规则排名。最后一列显示了这些bug的补丁ID和我们在PatchWork站点上的补丁。在这些发现的bug中，六个（2＃，3＃，8＃，12＃，13＃和14＃）在内核2.6中出现，两个（3＃和12＃）甚至潜伏了10年以上。</p><p><img src="/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/14.png" alt=""></p><p>这些bug总共违反了12个负关联规则。如果按照排名进行排名，则只有其中一个在前200条规则范围内（NAR-Miner-列中为12＃）。但是使用信息熵对规则进行排名会使所有这些规则都进入前200名（NAR-Miner）。这一观察结果表明，将信息熵引入排名对于突出有趣的规则非常有用。我们还观察到这些规则中只有2个是在NAR-Miner–中提取的（“NA”表示没有命中），其他规则都缺失。例如，缺少规则{free_netdev}⇒¬{kfree}（12＃），因为有106个函数同时调用free_netdev和kfree。在不考虑语义关系的情况下，项集{free_netdev，kfree}的支持是106，这远远高于预定阈值mis = 5。</p><p>因此，它不会被视为不常见的项目集，因此无法推断出负关联规则。然而，凭借语义约束的挖掘和信息熵，NAR-Miner成功地推断出规则并发现相应的错误（图1）。因此，我们声称语义约束的挖掘不仅可以帮助减少误报，还可以减少误报。</p><h3 id="4-2-4与基于正规则挖掘的方法的比较"><a href="#4-2-4与基于正规则挖掘的方法的比较" class="headerlink" title="4.2.4与基于正规则挖掘的方法的比较"></a>4.2.4与基于正规则挖掘的方法的比较</h3><p>在实践中，违反负规则的某些错误也可能违反相应的积极规则。因此，应该通过基于负面和正面规则挖掘的方法来检测这样的错误。我们调查是否会发生这种情况。我们选择表2中的17个错误作为基线，进行另一个实验，从§4.2.2中挖掘出的266,449个频繁项目集中使用与NAR-Miner相同的mfs和min_conf设置来推断出正关联规则，然后检测违规规则，如[25]和[26]中所做的那样。手动检查显示检测到17个错误中的3个（表2中的2＃，3＃和15＃），而其他14个错误（约82.4％）丢失。然后，我们使用语义约束的挖掘来增强基于正规则挖掘的方法，即考虑程序元素之间的数据关系。发现了另外两个错误（5＃和14＃），但仍有12个错误（约70.6％）未被发现。因此，我们声称虽然语义约束的挖掘能够帮助基于正规则挖掘的方法检测更多错误，但基于负规则挖掘的方法可以专门发现许多基于正规则挖掘的方法无法实现的错误。</p><h2 id="4-3检测其他系统中的bug"><a href="#4-3检测其他系统中的bug" class="headerlink" title="4.3检测其他系统中的bug"></a>4.3检测其他系统中的bug</h2><p>NAR-Miner进一步应用于PostgreSQL v10.3，OpenSSL v1.1.1和FFmpeg v3.4.2。 NAR-Miner分别从PostgreSQL，OpenSSL和FFmpeg中提取了690,382和335个负面规则。我们在§4.2中手动检查排名靠前的负面规则（不超过50个）及其在每个系统中的违规行为。因此，我们确定了六次违规（每个目标两次），并将其报告给相应的社区。到目前为止，所有六个可疑错误都被相应的系统维护人员修复了。有关详细信息，请参阅邮件列表[41]中PostgreSQL的错误报告，ID为＃15104和＃15105，OpenSSL来自问题列表[40]，ID为＃5567和＃5568，以及来自邮件列表的FFmpeg [39] ID为＃7074和＃7075。实验证明NAR-Miner不限于特定的目标系统（例如，Linux内核），而是可以用于在各种大规模C系统中发现真正的错误。</p><h2 id="4-4案例研究"><a href="#4-4案例研究" class="headerlink" title="4.4案例研究"></a>4.4案例研究</h2><p>在本节中，我们将说明NAR-Miner的能力与基于肯定关联规则（PAR）挖掘的方法在PostgreSQL中的＃15105问题上进行比较。</p><p>在PostgreSQL中，函数OpenTransientFile分配一个文件描述符并将其存储到全局维护的已分配文件列表中。返回描述符必须与CloseTransientFile一起释放，它会在关闭之前从列表中删除描述符。直接使用close会使列表保留已发布的描述符，并可能导致释放后使用的错误。从统计上来说，在PostgreSQL v10.3中，OpenTransientFile在28个函数中被调用。在27个函数中，其返回值传递给CloseTransientFile，但在1函数中，其返回值直接传递给close，从而产生负关联规则{OpenTransientFile}⇒¬{close}和正关联规则{OpenTransientFile}⇒{ CloseTransientFile}具有相同的96.4％的置信度。</p><p>图4显示了函数dsm_impl_mmap，该函数错误地将在第4行用OpenTransientFile分配的文件名描述符fd传递给沿路径的第12行关闭。它违反了上述负面规则，因此被NAR-Miner报告。但是，从伴随分析的角度来看，因为在某些路径上，fd在第8和第16行正确传递给CloseTransientFile，这符合上述正规则的要求。因此，有缺陷的代码确实是支持而不是违反规则。我们通过用CloseTransientFile（fd）替换第12行来解决这个问题，如图4所示。修补程序已经被维护者接受了</p><p><img src="/2019/01/28/NAR-Miner-Discovering-Negative-Association-Rules-from-Code/15.png" alt=""></p><h1 id="5-讨论和限制"><a href="#5-讨论和限制" class="headerlink" title="5.讨论和限制"></a>5.讨论和限制</h1><p><strong>负面规则与正面规则</strong>。在本文中，我们主要基于负关联规则而不是正关联规则来检测错误。但是，这两种方法没有必要的矛盾。由于他们专注于不同类型的编程规则，因此它们可以相互补充。从错误检测的角度来看，我们的方法能够提取负面的编程规则并检测基于挖掘正关联规则的方法无法揭示的错误，反之亦然。理论上，两种方法的组合可以表现出更好的检测性能（更少的漏报率）。</p><p>此外，与挖掘积极规则相比，挖掘负面规则通常伴随着产生更多无趣的规则，导致大量的误报。在这种情况下，同一程序的积极规则可以帮助减少它们。例如，如果一段代码违反了否定规则但满足了正规则，则相应的负面规则的违反不太可能成为真正的错误。我们可以降低其排名以避免这种违规行为。类似地，基于正规则的错误检测也可能面临相同的挑战（即，报告误报）。因此，在这种情况下，一个直截了当的问题是，这两种方法是否有助于减少误报？我们将在未来进一步研究。</p><p><strong>规则爆炸</strong>。实质上，负关联规则挖掘中的规则爆炸问题无法完全解决。在本文中，我们采用了一种相对直接的方法。具体来说，我们利用元素之间的语义关系来消除挖掘过程中绝大多数不感兴趣的规则，然后使用信息熵来衡量规则的有趣性，以便进一步突出显示潜在的有趣规则。但是，可能存在多种解决方案。例如，我们可以进一步量化程序元素之间的语义关系的强度，以重新改善挖掘结果。除了数据依赖和数据共享关系之外，还可以利用其他关系，例如控制流关系。这些潜在的改进可以进一步缓解规则爆炸问题，从而降低手动审计效率。这也是我们未来的工作之一。</p><p><strong>挖掘算法</strong>。在本文中，我们采用项集挖掘算法来提取负编程规则。实际上，对于某些类型的编程规则，其他形式的表示和挖掘算法可能更合适。例如，使用序列来表示顺序敏感的编程逻辑[1,29,53,55]比使用项目集更合适。然而，基于序列的算法在发现对顺序不敏感的编程逻辑方面具有较差的鲁棒性。如果我们能够有效地确定编程模式是否对顺序敏感，则可以采用目标算法来挖掘相关规则。这将是我们未来的工作之一。</p><h1 id="6-相关工作"><a href="#6-相关工作" class="headerlink" title="6.相关工作"></a>6.相关工作</h1><p>程序分析已被广泛而成功地用于错误发布。例如，模型检查可以使用目标系统的模型和规范自动验证有限状态系统的正确性属性[10]。由于为目标系统编写模型的成本很高，因此开发实验级模型检查器并在系统代码中发现实际错误[32,59]。研究人员还利用程序分析来检测违反特定规则的行为。通常，向工具提供一组编程规则，其静态地或动态地检查目标系统是否违反给定规则。 Pasareanu和Rungta开发了SPF，通过将符号执行引入到模型检查中来生成Java程序的测试用例[37]。恩格勒等人。提出了使用系统特定编译器扩展[13]静态检查系统规则的技术，而FindBugs作为独立工具运行，以检查Java字节码中错误模式的出现[11]。 Livshits和Lams [28]将用户提供的漏洞规范转换为静态分析器，并使用它们来检测用Java编写的Web应用程序中的漏洞，例如SQL注入和跨站点脚本。此外，Molnar等人。利用动态测试生成来检查二进制程序中的整数错误，检查特定断言的违规情况[31]。尽管它们在解决错误方面取得了成功，但这些方法在很大程度上取决于系统的模型或错误的模式，例如高级API语义[50]，我们称之为先验知识。没有这种知识，他们就无法发现错误。相反，我们的工作会自动发现知识，然后根据收集的知识检测错误。</p><p>还提供了可以从目标系统自动提取知识的技术。 Engler等人提出的先驱工作。采用统计分析来推断给定规则模板的时间规则，检测错误而不指定具体规则[14]。 Kremenek等人使用因子图通过结合不同的信息来源推断程序的规范[22]。这两种方法仅限于推断具有预定模板的规则和必须由用户提供的特定知识。一些方法依赖于挖掘规则中的某些领域知识，并且专门用于推断关键API [1,16,36,49,53,55]或安全敏感函数[47,58]的规则。它们还要求用户提供领域知识以促进挖掘过程。但是，NAR-Miner在根据程序中包含的关联规则（隐式）提取规则时不需要用户提供先验知识。</p><p>最近，研究人员利用数据挖掘算法从真实的大型系统中提取更多一般规则[4,7,8,21,23-25,27,29,30,33,34,44,54,58]。这些基于挖掘的技术背后的首要思想是：在大多数情况下，程序是正确的，因此任何异常都可能是错误。通常，这些方法首先推断出来自目标系统的频繁出现的模式，并将这些模式视为开发人员在编码时应遵循的（隐式）规则。然后，他们发现任何违反这些规则的行为都是潜在的错误。推断的模式可以是正面的也可以是负面的。例如，PR-Miner [25]和AntMiner [26]提取了强制关联规则，强制配对表面的程序行为。Chang等通过从程序控制流中挖掘频繁关联的子图并检查偶发违规来检测缺失的代码结构[7]。 Yun等。根据不同API之间挖掘的语义正关联规则推断出API的正确用法[60]。与这些方法不同，NAR-Miner专注于从源代码中挖掘负关联规则，并检测违反这些规则的错误。也可以从动态执行跟踪中提取类似的规则。Beschastnikh等开发了Synoptic，从系统执行日志中生成时间系统不变量[5]。</p><p>Wang等人开发了Bugram，它使用n-gram语言模型来测量令牌序列的概率，并将低概率序列视为异常，即潜在的错误[52]。Bugram还可以检测由相互抑制的程序元素共同引起的某些错误。但是，由于序列窗口的大小有限，Bugram很难捕获涉及长距离程序元素的错误。</p><p>挖掘负关联规则已应用于购物篮，蛋白质序列和金融数据等数据[18]。对于这样的数据，两个元素之间的关系比对关系贡献不同强度的程序元素的关系简单得多。Wu等人提出了算法，以有效和高效地挖掘大型数据库中的负关联规则[56]。Zhou和Yau提出了一种组合算法来挖掘有趣的关联规则，减少了大量的否定规则[61]。NAR-Miner也可以采用这些算法作为基本挖掘算法，但需要处理程序语义以减少不感兴趣的规则。</p><h1 id="7-结论"><a href="#7-结论" class="headerlink" title="7.结论"></a>7.结论</h1><p>数据挖掘技术已广泛用于推断编程规则，然后根据规则检测软件错误。现有方法已经证明，正关联规则（表明相关的程序元素必须一起出现）对于通过检查违规来检测错误是有用的。然而，拒绝所涉及的程序元素的共同出现的负关联规则大多被忽略。我们提出NAR-Miner从源代码中挖掘负关联规则。我们引入程序语义来指导挖掘阶段。我们还利用函数熵对候选规则进行排名并突出显示有趣的规则。通过这种方式，NAR-Miner显着减少了不感兴趣的规则的数量，并在一定程度上缓解了规则爆炸问题。我们在四个流行的大型系统上评估原型，并发现了相当多的错误，其中一些已被维护者所困扰。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h1&gt;&lt;p&gt;从基于数据挖掘技术的源代码推断编程规则已被证明对检测软件错误是有效的。现有研究侧重于以A⇒B
      
    
    </summary>
    
      <category term="论文" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/"/>
    
      <category term="数据挖掘" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"/>
    
    
      <category term="2018年" scheme="http://yama0xff.com/tags/2018%E5%B9%B4/"/>
    
      <category term="数据挖掘" scheme="http://yama0xff.com/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"/>
    
      <category term="漏洞检测" scheme="http://yama0xff.com/tags/%E6%BC%8F%E6%B4%9E%E6%A3%80%E6%B5%8B/"/>
    
      <category term="源代码" scheme="http://yama0xff.com/tags/%E6%BA%90%E4%BB%A3%E7%A0%81/"/>
    
  </entry>
  
  <entry>
    <title>Superset Disassembly: Statically Rewriting X86 Binaries Without Heuristics Disassembly</title>
    <link href="http://yama0xff.com/2019/01/27/Superset-Disassembly-Statically-Rewriting-X86-Binaries-Without-Heuristics-Disassembly/"/>
    <id>http://yama0xff.com/2019/01/27/Superset-Disassembly-Statically-Rewriting-X86-Binaries-Without-Heuristics-Disassembly/</id>
    <published>2019-01-27T07:33:23.000Z</published>
    <updated>2019-02-14T08:29:43.126Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>静态代码重写是系统安全应用的一项核心技术，它的使用场景包括性能分析，优化和软件错误定位等。之前的许多静态二进制程序重写方法，例如CCFIR, PITTSFIELD, Google’s Native Client, BinCFI, UROBOROS等，在保证重写正确时，提出了有关二进制程序的许多假定，例如完全正确的反汇编，编译器要求，调试符号等等，给实际应用在Commercial off-the-shelf（COTS）二进制程序上制造了困难。作者提供了<code>multiverse</code>，一个新的二进制程序重写器，它不基于上述的任何假定并能够重写intel x86 COTS程序。在COTS二进制程序重写中，存在着两大挑战： （1）如何反汇编二进制代码并包含所有合法指令 （2）如何重新汇编重写后的指令并保留原程序的语义。<strong><code>multiverse</code>使用了两种技术分别解决这两大挑战：（1）superset disassembly：通过对所有offset起始的地址进行反汇编获得合法代码的superset。 （2）instruction rewriter：通过替换控制流转移指令，中转到一个映射表，能够将原程序中所有的指令重定位到任意其他位置。</strong></p><table><thead><tr><th>relevant information</th><th></th></tr></thead><tbody><tr><td><em>作者</em></td><td>Erick Bauman，Zhiqiang Lin，Kevin W. Hamlen 单位：University of Texas at Dallas.</td></tr><tr><td><em>单位</em></td><td>University of Texas at Dallas</td></tr><tr><td><em>出处</em></td><td>NDSS’18</td></tr><tr><td><em>原文地址</em></td><td><a href="https://github.com/wtwofire/database/blob/master/papers/reverse/2018-Superset%20Disassembly%EF%BC%9AStatically%20Rewriting%20x86%20Binaries%20Without%20Heuristics.pdf" target="_blank" rel="noopener">https://github.com/wtwofire/database/blob/master/papers/reverse/2018-Superset%20Disassembly%EF%BC%9AStatically%20Rewriting%20x86%20Binaries%20Without%20Heuristics.pdf</a></td></tr><tr><td><em>源码地址</em></td><td><a href="https://github.com/utds3lab/multiverse" target="_blank" rel="noopener">https://github.com/utds3lab/multiverse</a></td></tr><tr><td><em>发表时间</em></td><td>2018年</td></tr></tbody></table><h1 id="背景与概述"><a href="#背景与概述" class="headerlink" title="背景与概述"></a>背景与概述</h1><p>作者的目的是为了发展一种二进制转化方法，改善现有二进制程序转化方法的实用性和通用性。为了表达简洁，也因为x86的程序更少开源。同时之前的许多代码转化方法也以x86程序为目标，作者的方法集中与主流编译器编译的linux 32位x86程序，同时不适用dlopen等动态载入库和自修改代码。</p><h2 id="挑战"><a href="#挑战" class="headerlink" title="挑战"></a>挑战</h2><p>在编写一个通用的二进制程序重写器时存在着许多挑战：</p><p><strong>C1</strong>：识别和重定位静态内存地址 编译后的二进制程序代码包含许多固定地址，很多指向全局变量。代码重写在移动这些目标时，必须同时更新它们的引用。在反汇编代码中和地址段中识别这些地址常量是非常困难的，因为整数值和这些地址常量在语法上并没有明显的区别。</p><p><strong>C2</strong>：处理动态计算的内存地址<br>在程序中还存在许多动态计算的内存地址。由于地址计算方式比较复杂，生成间接控制流转换表(iCFT)非常困难。重映射iCFT对于二进制程序重写是一个核心挑战。</p><p><strong>C3</strong>：区分代码和数据<br>代码和数据在二进制文件中没有语法上的区别，在现代处理器中，为了优化性能，许多数据被放在代码段中。这给反汇编带来一些困难。</p><p><strong>C4</strong>：作为参数的函数指针<br>作为函数指针的参数如果在目标函数中没有正确识别并且更新到改写后的地址，那么重写后的程序在执行时很可能会调用已经被之前的函数地址，令执行失败。同时，识别函数地址也非常困难。</p><p><strong>C5</strong>：处理位置无关代码<br>主流编译器生成了许多位置无关代码。这些代码会根据自身地址和相对位置寻找其他的执行代码。如果改变了它们的相对位置，那么在执行时就有可能失败。</p><h2 id="核心想法"><a href="#核心想法" class="headerlink" title="核心想法"></a>核心想法</h2><p>基于之前的二进制重写方法，作者系统化了下面的这些想法来针对性地解决上面的挑战</p><p><strong>S1</strong>：保持原有数据空间的完好无损<br>保持程序中数据段原有的位置和内容，这个方法之前也被用在许多二进制重写器中，例如SECONDWRITE和BINCFI</p><p><strong>S2</strong>：创建一个从原有代码空间到新的重写代码空间的映射<br>作者在这个映射中忽略常用的地址计算中 基址+偏移 的方法，只考虑最后获得的最终地址，并将这个地址与重写后的代码地址进行对应。作者对于原有地址空间中的每个代码段地址都找到了一个映射，这样就简单的解决了动态计算的内存地址问题。</p><p><strong>S3</strong>：暴力反汇编所有可能的代码<br>为了解决反汇编可能存在缺失的问题，作者对于从代码段开始的每个偏移，都进行了反汇编直到遇上非法指令，或者已经反汇编过的地址。原程序中执行的所有代码必定是暴力反汇编获得的代码的子集。</p><p><strong>S4</strong>：重写所有用户级别的代码<br>通过重写所有用户级别的代码，可以在函数指针被调用处利用原程序与重写程序之间的地址映射，将指向原程序地址空间的函数指针映射到重写后的地址空间。</p><p><strong>S5</strong>：重写所有call指令以解决pic代码 在查看了x86指令集后，所有的pic代码计算方式在32位x86指令集中，都使用call指令来获得当前地址，作者改写了所有call指令，令其push一个未重写时的地址在栈上，被利用于计算地址时，即可以获得原有计算应得的地址，再由iCFT进行统一处理。</p><h2 id="系统Overview"><a href="#系统Overview" class="headerlink" title="系统Overview"></a>系统Overview</h2><p>基于上面的想法，作者实现了<code>multiverse</code>，正如下面的图片中显示，<code>multiverse</code>系统包含两个分开的步骤，映射和重写：</p><p><img src="/2019/01/27/Superset-Disassembly-Statically-Rewriting-X86-Binaries-Without-Heuristics-Disassembly/1.png" alt="图片1"></p><p>在映射阶段，superset disassembler是用下面所示的算法对代码段开始的每个offset进行反汇编，删除重复的代码并在尾部设置一个跳转指令。可以注意的是，在反汇编中，作者删除了从非法指令向前到最后一条控制转移指令的代码内容：</p><p><img src="/2019/01/27/Superset-Disassembly-Statically-Rewriting-X86-Binaries-Without-Heuristics-Disassembly/2.png" alt="图2"></p><p><code>multiverse</code>修改了反汇编获得的代码中占位符长度过短的jcc，jmp指令，因为它们原来的指令很可能长度不够填充新的跳转地址。在这之后，即可以确定所有重写后的指令长度和位置，此时所有的跳转指令依旧包含着占位符地址。</p><p>在重写阶段，<code>multiverse</code>根据重写后的地址位置和原程序地址创建一个本地代码的映射表。映射表的键值是原程序中的内存地址，值则对应着新的代码空间中的地址。 对于重写程序中的直接跳转，<code>multiverse</code>根据映射表将其修改为新的地址。 对于间接跳转，<code>multiverse</code>将其中转到一个搜索映射表的函数中。函数的输入，跳转目标处于原程序的代码空间中。这个函数通过对应映射表找到新代码空间中的对应地址，并执行跳转。 对于外部函数或地址的跳转。由于这些地址在本地映射表中对应。如下图所示，映射函数将在全局映射表中寻找它所处的代码文件并在其对应的映射表中寻找对应地址。</p><p><img src="/2019/01/27/Superset-Disassembly-Statically-Rewriting-X86-Binaries-Without-Heuristics-Disassembly/3.png" alt="图3"></p><p>为了处理位置无关代码和函数指针，<code>multiverse</code>对于所有的call和ret指令都进行了修改。 通过这样的方式，重写后的代码可以任意的安排指令和基本块位置。 最终<code>multiverse</code>利用重写后的代码生成一个新的elf文件。</p><h1 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h1><p>作者基于许多python库，包括python-capstone，pyelftools,pwntools实现了<code>multiverse</code>，包含超过3000行python代码和超过150行汇编代码。同时，基于重写所处的Linux环境，作者对于动态加载器和VDSO进行了特殊处理。</p><h1 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h1><p>作者使用了所有的SPECint 2006 benchmark程序，共12个，作为测试程序集。测试的机器使用一台ubuntu 14.04.1 lts，Intel i7-2600 cpu，4GB RAM。</p><h2 id="有效性"><a href="#有效性" class="headerlink" title="有效性"></a>有效性</h2><p>作者执行了<code>multiverse</code>重写后的所有程序，并和未重写的版本进行对应，所有重写后的程序都正确的执行完毕，输出和未重写的版本同样的结果。</p><p>下表描述了重写后的程序的详细信息：</p><p><img src="/2019/01/27/Superset-Disassembly-Statically-Rewriting-X86-Binaries-Without-Heuristics-Disassembly/4.png" alt="图4"></p><p>有趣的是，对于代码段，所有重写后的程序的代码段长度大约都是原程序的4-5倍，这很可能与x86指令的平均长度有关。同时，表中所有的.newtext段长度都没有包括大约4MB的全局映射表大小，对于代码段长度较小的case，例如429.mcf，这导致了较大的size overhead。</p><h2 id="开销"><a href="#开销" class="headerlink" title="开销"></a>开销</h2><p>作者在原来的benchmark程序和重写后的程序上运行了10遍，以对程序重写后的性能进行一个衡量，结果如下表所示：</p><p><img src="/2019/01/27/Superset-Disassembly-Statically-Rewriting-X86-Binaries-Without-Heuristics-Disassembly/5.png" alt="图5"></p><p>对于大部分的测试程序来说，时间overhead不超过100%，平均的性能overhead为60.42%。对于471.omnetpp 和 483.xalancbmk，性能损耗较高，这两个程序使用c++语言编写，对类函数和库函数的频繁调用在重写时带来了大量的性能损耗。</p><p>接着作者比较了不同优化措施对性能带来的影响，例如只不重写外部函数库，或者对回调函数进行特殊处理，对位置无关代码进行特殊处理。结果如下图所示：</p><p><img src="/2019/01/27/Superset-Disassembly-Statically-Rewriting-X86-Binaries-Without-Heuristics-Disassembly/6.png" alt="图6"></p><p>可以发现，通过对位置无关代码进行特殊处理（假设程序只使用get_pc_thunk函数），可以获得巨大的性能提升。</p><p>作者测试了使用<code>multiverse</code>进行插桩带来的性能开销，并和常用的工具pin进行了比较，两者都执行对于指令数统计的插桩。</p><p><img src="/2019/01/27/Superset-Disassembly-Statically-Rewriting-X86-Binaries-Without-Heuristics-Disassembly/7.png" alt="图7"></p><p>在大部分情况下，使用<code>multiverse</code>在程序重写中静态进行插桩带来的性能消耗比使用pin来的低，在以下情况下，由于pin对于插桩内部代码进行分析，使用pin的插桩性能损耗稍微好一些。</p><p>最后，作者测试了使用<code>multiverse</code>作为安全应用工具的性能，作者使用<code>multiverse</code>编写了一个shadow stack，并与用pin编写的工具相比较。使用<code>multiverse</code>编写的具有巨大的性能优势。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>作者通过使用了superset disassemble和 instruction rewriter两项技术，开发了<code>multiverse</code>系统，提供了一个不依赖启发式分析的二进制软件重写工具，并且通过对比，证明这个工具在安全应用的性能上，和当前主流的二进制插桩框架PIN相比更有优势。</p><hr><p><em>论文翻译内容转载至GoSSIP.</em></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h1&gt;&lt;p&gt;静态代码重写是系统安全应用的一项核心技术，它的使用场景包括性能分析，优化和软件错误定位等。之
      
    
    </summary>
    
      <category term="论文" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/"/>
    
      <category term="软件分析" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90/"/>
    
    
      <category term="2018年" scheme="http://yama0xff.com/tags/2018%E5%B9%B4/"/>
    
      <category term="二进制反汇编" scheme="http://yama0xff.com/tags/%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%8F%8D%E6%B1%87%E7%BC%96/"/>
    
      <category term="静态重写技术" scheme="http://yama0xff.com/tags/%E9%9D%99%E6%80%81%E9%87%8D%E5%86%99%E6%8A%80%E6%9C%AF/"/>
    
      <category term="NDSS&#39;18" scheme="http://yama0xff.com/tags/NDSS-18/"/>
    
  </entry>
  
  <entry>
    <title>Angora: Efficient Fuzzing by Principled Search</title>
    <link href="http://yama0xff.com/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/"/>
    <id>http://yama0xff.com/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/</id>
    <published>2019-01-25T08:31:20.000Z</published>
    <updated>2019-01-28T09:55:32.592Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>​    Fuzzing是一种用于查找软件错误的流行技术。然而，最先进的模糊器的性能还有很多不足之处。基于符号执行的模糊器产生高质量输入但运行缓慢，而基于随机变异的模糊器运行速度快但难以产生高质量输入。我们提出了一种新的基于突变的模糊器Angora，它的性能远远超过了最先进的模糊器。Angora的主要目标是通过解决路径约束来增加分支覆盖率而无需符号执行。<strong>为了有效地解决路径约束，我们引入了几个关键技术：可扩展的字节级污点跟踪，上下文敏感的分支计数，基于梯度下降的搜索和输入长度探索</strong>。在LAVA-M数据集上，Angora发现了几乎所有注入的错误，发现了比我们比较的任何其他模糊器更多的错误，并且发现错误是程序中第二好的模糊器的8倍。Angora还发现了LAVA作者注射但却无法触发的103个错误。我们还在八个流行的，成熟的开源程序上测试了Angora。Angora分别在file，jhead，nm，objdump和size中发现了6,52,29,40和48个新错误。我们测量了Angora的覆盖范围，并评估了其关键技术如何促成其令人印象深刻的性能。</p><table><thead><tr><th style="text-align:left">relevant information</th><th></th></tr></thead><tbody><tr><td style="text-align:left"><em>作者</em></td><td>Peng Chen, Hao Chen</td></tr><tr><td style="text-align:left"><em>单位</em></td><td>ShanghaiTech University, University of California, Davis</td></tr><tr><td style="text-align:left"><em>出处</em></td><td>IEEE S&amp;P’18</td></tr><tr><td style="text-align:left"><em>原文地址</em></td><td><a href="https://github.com/wtwofire/database/blob/master/papers/fuzzing/2018Angora%20Efficient%20Fuzzing%20by%20Principled%20Search.pdf" target="_blank" rel="noopener">https://github.com/wtwofire/database/blob/master/papers/fuzzing/2018Angora%20Efficient%20Fuzzing%20by%20Principled%20Search.pdf</a></td></tr><tr><td style="text-align:left"><em>源码地址</em></td><td><a href="https://github.com/AngoraFuzzer/Angora" target="_blank" rel="noopener">https://github.com/AngoraFuzzer/Angora</a></td></tr><tr><td style="text-align:left"><em>发表时间</em></td><td>2018年</td></tr></tbody></table><h1 id="1-简介"><a href="#1-简介" class="headerlink" title="1 简介"></a>1 简介</h1><p>​    Fuzzing是一种用于查找软件错误的流行技术。基于覆盖的模糊器面临着如何创建输入以探索程序状态的关键挑战。一些模糊器使用符号执行来解决路径约束[5,8]，但符号执行很慢，无法有效地解决许多类型的约束[6]。为了避免这些问题，AFL不使用符号执行或任何重量级程序分析[1]。它对程序进行插桩，以观察哪些输入探索新的程序分支，并将这些输入作为进一步变异的种子。 AFL在程序执行时产生很低的开销，但是它创建的大多数输入都是无效的（即，它们无法探索新的程序状态），因为它盲目地改变输入而不利用程序中的数据流。几个模糊器为AFL添加了启发式算法来解决简单的判断，例如“魔术字节”[25,19]，但它们无法解决其他路径约束。</p><p>​    我们设计并实现了一个名为Angora的模糊器，它通过解决路径约束而不使用符号执行来探索程序的状态。Angora跟踪未探测的分支并尝试解决这些分支上的路径约束。我们引入了以下技术来有效地解决路径约束。</p><ul><li><p>上下文敏感的分支覆盖。 AFL使用上下文敏感分支覆盖来近似程序状态。我们的经验表明，为分支覆盖添加上下文使Angora能够更普遍地探索程序状态（第3.2节）。</p></li><li><p>可扩展的字节级污点跟踪。大多数路径约束仅依赖于输入中的几个字节。通过跟踪哪些输入字节流入每个路径约束，Angora只改变这些字节而不是整个输入，因此大大减少了探索空间（第3.3节）。</p></li><li><p>基于梯度下降搜索。当改变输入以满足路径约束时，Angora避免了符号执行，这是昂贵的并且不能解决许多类型的约束。相反，Angora使用机器学习中流行的梯度下降算法来解决路径约束（第3.4节）。</p></li><li><p>类型和形状推断。输入中的许多字节共同用作程序中的单个值，例如，在程序中用作32位有符号整数的输入中的四个字节的组。为了允许梯度下降有效搜索，Angora定位上述组并推断其类型（第3.5节）。</p></li><li><p>输入长度探索。只有当输入的长度超过某个阈值时，程序才可以探索某些状态，但是符号执行和梯度下降都不能告诉模糊器何时增加输入的长度。 Angora检测输入长度何时可能影响路径约束，然后充分增加输入长度（第3.6节）。</p></li></ul><p>​        Angora大大超过了最先进的模糊器。表1比较了Angora与其他模糊器在LAVA-M数据集上发现的漏洞[9]。Angora在数据集中的每个程序中发现了更多错误。特别是，Angora发现了1541个漏洞，是第二个最好的模糊器Steelix发现的漏洞数量的8倍。此外，Angora发现了LAVA作者注射但却无法触发的103个错误。我们还在八个流行的，成熟的开源程序上测试了Angora。Angora分别在file，jhead，nm，objdump和size中发现了6,52,29,40和48个新错误（表5）。我们测量了Angora的覆盖范围，并评估了其关键技术如何促成其令人印象深刻的性能。</p><p><img src="/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/p1.png" alt="p1"></p><h1 id="2-背景：AFL"><a href="#2-背景：AFL" class="headerlink" title="2 背景：AFL"></a>2 背景：AFL</h1><p>​    模糊测试是一种自动测试技术，用于查找错误。 American Fuzzy Lop（AFL）[1]是一种基于突变的灰盒模糊器。 AFL采用轻量级编译时插桩和遗传算法来自动发现可能触发目标程序中新内部状态的测试用例。作为基于覆盖率的模糊器，AFL生成输入以遍历程序中的不同路径来触发错误。</p><h2 id="2-1-分支覆盖范围"><a href="#2-1-分支覆盖范围" class="headerlink" title="2.1 分支覆盖范围"></a>2.1 分支覆盖范围</h2><p>​    AFL通过一组分支来测量路径。在每次运行期间，AFL计算每个分支执行的次数。它将分支表示为元组（lprev; lcur），其中lprev和lcur分别是条件语句之前和之后的基本块的ID。AFL通过使用轻量级检测获取分支覆盖率信息。在编译时在每个分支点注入插桩。对于每次运行，AFL分配路径跟踪表以计算每个条件语句的每个分支执行的次数。表的索引是分支的散列，h（lprev; lcur），其中h是散列函数。</p><p>​    AFL还在不同的运行中保留全局分支覆盖表。每个条目都包含一个8位向量，用于记录分支在不同运行中执行的次数。该向量b中的每个位表示一个范围：b0,……,b7分别代表范围[1]，[2]，[3]，[4; 7]，[8; 15]，[16; 31]，[32; 127]，[128; ∞）。例如，如果设置了b3，则表示存在执行此分支执行4到7次的运行，包括。</p><p>​    AFL比较路径跟踪表和分支覆盖表，以启发式方式确定新输入是否触发程序的新内部状态。如果发生以下任一情况，输入将触发新的内部状态：</p><ul><li><p>程序执行新分支，即路径跟踪表具有此分支的条目，但分支覆盖表没有此分支的条目。</p></li><li><p>存在一个分支，其中当前运行中执行的此分支的次数n与先前的任何运行不同。 AFL通过检查表示n的范围的位是否被设置在分支覆盖表中的相应位向量中来近似地确定这一点。</p></li></ul><h2 id="2-2-变异策略"><a href="#2-2-变异策略" class="headerlink" title="2.2 变异策略"></a>2.2 变异策略</h2><p>​    AFL随机应用以下变异[3]。</p><ul><li><p>位或字节翻转。</p></li><li><p>尝试设置“有趣”的字节，单字或双字。</p></li><li><p>将小整数加到或减去字节，单字或双字。</p></li><li><p>完全随机的单字节集。</p></li><li><p>块删除，通过覆盖或插入来复制块，或块memset。</p></li><li><p>在随机位置拼接两个不同的输入文件。</p></li></ul><h1 id="3-设计"><a href="#3-设计" class="headerlink" title="3 设计"></a>3 设计</h1><h2 id="3-1-概述"><a href="#3-1-概述" class="headerlink" title="3.1 概述"></a>3.1 概述</h2><p>​    AFL和其他类似的fuzzer使用分支覆盖作为度量。但是，在计算分支覆盖范围时，它们没有考虑调用上下文。我们的经验表明，没有上下文，分支覆盖将无法充分探索程序状态。因此，我们建议使用上下文敏感分支覆盖作为覆盖度量（第3.2节）。</p><p>​    算法1显示了Angora的两个阶段：插桩和fuzzing循环。在fuzzing循环的每次迭代期间，Angora选择一个未探测的分支并搜索探索该分支的输入。我们介绍了以下关键技术，以有效地找到输入。</p><ul><li><p>对于大多数条件语句，其判断仅受输入中的几个字节的影响，因此改变整个输入将是徒劳的。因此，在探索分支时，Angora会确定哪些输入字节流入相应的判断，并专注于仅改变这些字节（第3.3节）。</p></li><li><p>确定要改变的输入字节后，Angora需要决定如何改变它们。使用基于随机或启发式的突变不能有效地找到令人满意的值。相反，我们将分支上的路径约束视为输入上黑盒函数的约束，并且我们调整梯度下降算法来解决约束（第3.4节）。</p></li><li><p>在梯度下降期间，我们在其参数上评估blackbox函数，其中一些参数由多个字节组成。例如，当输入中的四个连续字节总是作为整数流一起用于条件语句时，我们应该将这四个字节视为函数的单个参数而不是四个独立参数。为了实现这一目标，我们需要推断输入中的哪些字节统一用作单个值以及值的类型是什么（第3.5节）。</p></li><li><p>仅仅改变输入中的字节是不够的。只有在输入超过阈值后才会触发一些错误，但这会在决定输入长度时产生两难。如果输入太短，则可能不会触发某些错误。但如果输入太长，程序可能运行得太慢。大多数模糊器使用临时方法改变输入的长度。相比之下，Angora使用代码检测程序，该代码检测较长输入何时可以探索新分支并确定所需的最小长度（第3.6节）。</p></li></ul><p><img src="/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/图2.png" alt="图2"></p><p>​    图1显示了fuzzing条件语句的步骤图。图2中的程序演示了这些步骤。</p><ul><li><p>字节级污点跟踪：当使用字节级污点跟踪对第2行的条件语句进行模糊测试时，Angora确定字节1024-1031流入此表达式，因此它仅改变这些字节。</p></li><li><p>基于梯度下降的搜索算法：Angora需要分别找到在第2行上运行条件语句的两个分支的输入。Angora将条件语句中的表达式视为输入x上的函数f（x），并使用梯度下降来找到两个输入x和x’，使得f（x）&gt; 0且f（x’）≤0。</p></li><li><p>形状和类型推断：f（x）是向量x上的函数。在梯度下降期间，Angora分别计算f的每个分量的f的偏导数，因此它必须确定每个分量及其类型。在第2行，Angora确定x由两个组件组成，每个组件由输入中的四个字节组成，并具有32位有符号整数类型。</p></li><li><p>输入长度探索：除非输入至少有1032个字节，否则main不会调用foo。我们不是盲目地尝试更长的输入，而是检测从输入读取的常用函数，并确定更长的输入是否会探索新的状态。例如，如果初始输入短于1024字节，则第12行上的条件语句将执行true分支。</p></li></ul><p>​       由于fread的返回值与1024进行比较，因此Angora知道只有至少1024字节长的输入才能探索错误分支。类似地，第16行和第19行的检测指示Angora将输入扩展到至少1032个字节以执行函数foo。</p><p><img src="/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/图3.png" alt="图3"></p><p><img src="/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/图4.png" alt="图4"></p><h2 id="3-2-上下文敏感的分支计数"><a href="#3-2-上下文敏感的分支计数" class="headerlink" title="3.2 上下文敏感的分支计数"></a>3.2 上下文敏感的分支计数</h2><p>​    第2节描述了AFL的分支覆盖表。它的设计有几个优点。首先，它节省空间。分支数量与程序大小呈线性关系。其次，使用范围来计算分支执行在关于不同执行计数是否指示了程序新的内部状态提供了良好启发。当执行计数很小（例如，小于4）时，计数的任何变化都是显着的。然而，当执行计数很大（例如，大于32）时，变化必须足够大以被认为是重要的。</p><p>​    但这种设计有局限性。由于AFL的分支对上下文不敏感，因此它们无法区分不同上下文中同一分支的执行，这可能会忽略程序新的内部状态。图3说明了这个问题。考虑第3行分支的覆盖范围。在第一次运行期间，程序采用输入“10”。当它在第19行调用f（）时，它在第4行执行true分支。之后，当它在第21行调用f（）时，它在第10行执行false分支。由于AFL对分支的定义是上下文不敏感的，它认为两个分支都已执行。之后，当程序采用新输入“01”时，AFL认为此输入不会触发新的内部状态，因为第4行和第10行的分支都在上一次运行中执行。但实际上这个新输入触发了一个新的内部状态，因为当输入[2] == 1时它将导致第6行崩溃。</p><p>​    我们将上下文合并到分支的定义中。我们将分支定义为元组（lprev, lcur, context），其中l prev和lcur分别是条件语句之前和之后的基本块的ID，context是h（stack）其中h是散列函数，并且stack包含调用堆栈的状态。例如，让图3中的程序首先在输入10上运行。在它从第19行进入f（）之后，它将执行分支（l3; l4; [l19]）。然后，在从第21行进入f（）之后，它将执行分支（l3; l10; [l21]）。相反，当程序在输入“01”上执行时，它将执行分支（l3; l10; [l19]），然后执行（l3; l4; [l21]）。通过将调用上下文合并到分支的定义中，Angora可以检测到第二次运行会触发新的内部状态，这将在改变输入时[2]时导致第6行产生carsh。</p><p>​    向分支添加上下文会增加独特分支的数量，这在发生深度递归时可能会很明显。我们当前的实现通过选择用于计算调用堆栈的散列的特定函数h来缓解该问题，其中h计算堆栈上所有调用位置的ID的xor。当Angora插桩程序时，它会为每个调用点分配一个随机ID。因此，当函数f递归调用自身时，无论Angora将同一调用站点的ID推送到调用堆栈多少次，h（堆栈）最多输出两个唯一值，在函数f中这最多会使独特分支的数量增加一倍。我们对现实世界程序的评估表明，在结合上下文后，独特分支的数量增加了多达7.21倍（表7），以换取改进代码覆盖的好处（图7）。</p><h2 id="3-3-字节级别的污点跟踪"><a href="#3-3-字节级别的污点跟踪" class="headerlink" title="3.3 字节级别的污点跟踪"></a>3.3 字节级别的污点跟踪</h2><p>​    Angora的目标是创建执行未开发分支的输入。当它尝试执行未探测的分支时，它必须知道输入中的哪些字节偏移影响分支的谓词。因此，Angora需要字节级别的污点跟踪。然而，污点跟踪是昂贵的，尤其是在单独跟踪每个字节时，因此AFL避免了它。我们的主要观点是，在大多数程序运行中都不需要进行污点跟踪。一旦我们对输入运行了污点跟踪（图1中的步骤1），我们就可以记录哪些字节偏移流入每个条件语句。然后，当我们改变这些字节时，我们可以在没有污点跟踪的情况下运行程序。这通过其许多突变来分摊一个输入上的污点跟踪成本，这使得Angora具有与AFL类似的输入执行吞吐量（第5.6节）。</p><p>​    Angora将程序中的每个变量x与污点标签tx相关联，污点标签tx表示输入中可能流入x的字节偏移量。污点标签的数据结构对其内存占用量有很大影响。一个简单的实现是将每个污点标签表示为位向量，其中每个位i表示输入中的第i个字节。然而，由于该位向量的大小在输入的大小上线性增长，因此该数据结构对于大输入将是禁止的，但是在某些程序中找到错误需要大量输入。</p><p>​    为了减少污点标签的大小，我们可以将位向量存储在表中，并使用表中的索引作为污点标签。只要表中条目数的对数远小于最长位向量的长度（通常是这种情况），我们就可以大大减小污点标签的大小。</p><p>​    但是，这种数据结构带来了新的挑战。污点标签必须支持以下操作：</p><ul><li><p>INSERT（b）：插入位向量b并返回其标签。</p></li><li><p>FIND（t）：返回污点标签t的位向量。</p></li><li><p>UNION（tx; ty）：返回污点标签，表示污点标签tx和ty的位向量的并集。</p></li></ul><p>​       FIND代价很低，但UNION很高。 UNION采取以下步骤。首先，它找到两个标签的位向量并计算它们的联合u。这一步代价很低。接下来，它搜索表以确定u是否已存在。如果没有，它会增加u。但如何高效搜索？线性搜索会很昂贵。或者，我们可以构建一个位向量的哈希集，但是如果它们中有很多并且每个位向量都很长，那么计算哈希码和存储哈希集的空间就会花费很多时间。由于UNION是我们在算术表达式中跟踪污染数据时的常见操作，因此它必须是高效的。注意，我们不能使用UNION-FIND数据结构，因为矢量不是不相交的，即两个不同的位矢量可能在同一位置具有1。</p><p>​    我们提出了一种新的数据结构，用于存储位向量,允许有效INSERT，FIND和UNION。对于每个位向量，数据结构使用无符号整数为其分配唯一标签。当程序插入新的位向量时，数据结构会为其分配下一个可用的无符号整数。</p><p>​    数据结构包含两个组件。</p><ul><li><p>二叉树将位向量映射到其标签。每个位向量b由级别为|b|的唯一树节点vb表示，其中|b|是b的长度。 vb存储b的标签。要从根到达vb，检查b0,b1…顺序。如果bi为0，则转到左边的子节点;否则，去右边的子节点。每个节点都包含一个指向其父节点的后向指针，以允许我们从vb开始检索位向量。</p></li><li><p>查找表将标签映射到其位向量。标签是该表的索引，相应的条目指向表示该标签的位向量的树节点。</p></li></ul><p>​       在该数据结构中，树中的所有叶子表示位向量，并且没有内部节点表示位向量。但是，树中的许多节点可能是不必要的。例如，如果向量x00 <em>在树中但没有向量x0 [01] </em> 1 [01] <em>在树中，其中x是任何位序列，那么就不必在节点之后存储任何节点表示x，因为x只有一个是叶子的结点，而这个叶子代表x00 </em>。这里我们使用正则表达式的通用符号，其中x *表示x重复零次或多次，[xy]表示x或y。这个观察允许我们在将一个向量插入树中时修剪向量，如下所示：</p><ol><li><p>删除向量的所有尾随0。</p></li><li><p>跟踪向量中的位，从第一位到最后一位，遍历树。</p></li></ol><ul><li><p>如果位为0，请跟随左节点</p></li><li><p>否则，请跟随右节点。</p></li><li><p>如果节点不存在，请创建它。</p></li></ul><ol start="3"><li>将向量的标签存储在我们访问的最后一个节点中。</li></ol><p>​       算法2详细描述了这种插入操作。</p><p>​    算法3和算法4分别描述了FIND和UNION操作。请注意，当我们创建节点时，最初它不包含标签。稍后，如果此节点是我们插入位向量时访问的最后一个节点，我们将位向量的标签存储在此节点中。通过此优化，此树具有以下属性：</p><ul><li><p>每个叶节点都包含一个标签。</p></li><li><p>内部节点可能包含标签。我们可能会在没有标签的内部节点中存储标签，但我们永远不会在任何内部节点中替换标签。</p></li></ul><p>​        该数据结构极大地减少了用于存储位向量的存储器占用。设每个位向量的长度为n，并设有l个位向量。如果我们天真地将所有位向量存储在查找表中，则需要O（nl）空间。但是，在我们的数据结构中，树中的节点数是O（l）。每个节点可以存储最多一个索引到查找表。由于查找表具有l个条目并且每个条目是指针并且因此具有固定大小，因此查找表的大小是O（l），并且查找表的每个索引具有O（log 1）位。因此，总空间要求为O（l·log l）。</p><p><img src="/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/图5.jpg" alt="图5"></p><h2 id="3-4-基于梯度下降的搜索算法"><a href="#3-4-基于梯度下降的搜索算法" class="headerlink" title="3.4 基于梯度下降的搜索算法"></a>3.4 基于梯度下降的搜索算法</h2><p>​    字节级污点跟踪发现输入流中的哪些字节偏移成为条件语句。但是如何改变输入以运行未探索的分支语句？大多数模糊测试者随机地或使用粗略的启发式方法改变输入，但这些策略不太可能快速找到合适的输入值。相比之下，我们将此视为搜索问题，并利用机器学习中的搜索算法。我们在实现中使用了梯度下降，但其他搜索算法也可能有效。</p><p>​    在这种方法中，我们将用于执行分支断定看作黑盒函数f（x）的约束，其中x是输入中流入判断的值的向量，并且f（）捕获计算在从程序开始到此判断的路径。 f（x）有三种类型的约束：</p><ol><li><p>f（x）&lt;0。</p></li><li><p>f（x）&lt;= 0。</p></li><li><p>f（x）== 0。</p></li></ol><p>​       表2显示我们可以将所有形式的比较转换为上述三种类型的约束。如果条件语句的判断包含逻辑运算符&amp;&amp;或||，则Angora会将语句拆分为多个条件语句。例如，它将（a &amp;&amp; b）{s} else {t}拆分为if（a）{if（b）{s} else {t}} else {t}。</p><p>​    算法5显示了搜索算法。从初始x0开始，找到x使得f（x）满足约束。请注意，为了满足每种类型的约束，我们需要最小化f（x），并且我们使用梯度下降来实现此目的。</p><p>​    梯度下降找到函数f（x）的最小值。该方法是迭代的。每次迭代都从x开始，计算∇xf（x）（x处的f（x）的梯度），并将x更新为x-ε∇xf（x），其中ε是学习率。</p><p>​    在训练神经网络时，研究人员使用梯度下降来找到一组最小化训练误差的权重。然而，梯度下降的问题在于它有时可能会陷入局部最小值，而不是全局最小值。幸运的是，这在模糊测试中通常不是问题，因为我们只需要找到足够好的输入x而不是全局最优x。例如，如果约束是f（x）&lt;0，那么我们只需要找到一个x，其中f（x）&lt;0而不是f（x）是全局最小值。</p><p>然而，当将梯度下降应用于模糊时，我们面临着独特的挑战。梯度下降需要计算梯度∇xf（x）。在神经网络中，我们可以用分析形式编写∇xf（x）。然而，在模糊测试中，我们没有f（x）的分析形式。其次，在神经网络中，f（x）是连续函数，因为x包含网络的权重，但在模糊中f（x）通常是离散函数。这是因为典型程序中的大多数变量都是离散的，因此x中的大多数元素都是离散的。</p><p>​    我们使用数值近似解决了这些问题。 f（x）的梯度是唯一的矢量场，其每个点x处的任意单位矢量v的点积是f沿v的方向导数。我们用δf(x) /δ（xi）= f（x+δv i）-f（x））/δ逼近每个方向导数其中δ是小的正值（例如，1），vi是第i维的单位矢量。为了计算每个方向导数，我们需要运行程序两次，一次使用原始输入x，一次使用扰动输入x + δvi。在第二次运行中，程序可能无法到达计算f（x +δvi）的程序点，因为程序在较早的条件语句中采用了不同的分支。当发生这种情况时，我们将δ设置为小的负值（例如，-1）并尝试再次计算f（x +δvi）。如果成功，我们会根据它计算方向导数。否则，我们将导数设置为零，指示梯度下降不要在此方向上移动x。计算梯度的时间与矢量x的长度成比例，因为Angora分别计算每个方向导数。第3.5节将描述如何通过合并在程序中用作单个值的连续字节来减少x的长度。</p><p>​    理论上，梯度下降可以解决任何约束。实际上，梯度下降可以解决约束的速度取决于数学函数的复杂性。</p><ul><li><p>如果f（x）是单调的或凸的，那么即使f（x）具有复杂的分析形式，梯度下降也可以快速找到解。例如，考虑约束f（x）&lt;0，其中f（x）使用一些多项式系列近似log（x）。由于复杂的分析形式，符号执行很难解决这种约束。但是，梯度很容易解决，因为f（x）是单调的。</p></li><li><p>如果梯度下降的局部最小值满足约束，则查找解决方案也很快。</p></li><li><p>如果局部最小值不满足约束条件，则Angora必须随机走到另一个值x并从那里开始递减渐变，希望找到满足约束的另一个局部最小值。</p></li></ul><p>​       请注意，Angora不会生成f（x）的分析形式，而是运行程序来计算f（x）。</p><p><img src="/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/图6.png" alt="图6"></p><h2 id="3-5形状和类型推断"><a href="#3-5形状和类型推断" class="headerlink" title="3.5形状和类型推断"></a>3.5形状和类型推断</h2><p>​    天真地，我们可以让输入中的x中的每个元素成一个字节流入到判断处。但是，由于类型不匹配，这会导致梯度下降问题。例如，让程序将输入中的四个连续字节b3b2b1b0视为整数，并让xi表示该整数值。当计算f（x +δvi）时，我们应该将δ加到这个整数。但是如果我们天真地将每个字节b3，b2，b1，b0分配给x中的不同元素，那么我们将在每个字节上计算f（x +δvi），但这是不合适的。</p><p>​    程序将这些字节组合为单个值并仅使用表达式中的组合值，因此当我们向除最低有效字节之外的任何字节添加小的δ时，我们将显着更改此组合值，这将导致计算的偏导数是一个不正确的真实值的近似。</p><p>​    为了避免这个问题，我们必须确定（1）输入中的哪些字节总是一起用作程序中的单个值，以及（2）值的类型是什么。我们称第一个问题为形状推理，第二个问题类型推断，并在动态污点分析过程中解决它们。</p><p>​    对于形状推断，最初输入中的所有字节都是独立的。在污点分析期间，当指令将输入字节序列读入变量，其中序列的大小与基本类型的大小匹配（例如，1,2,4,8字节）时，Angora将这些字节标记为属于相同的值。当冲突发生时，Angora使用最小的尺寸。对于类型推断，Angora依赖于对值进行操作的指令的语义。例如，如果指令对有符号整数进行操作，则Angora将相应的操作数推断为有符号整数。当相同的值同时用作有符号和无符号类型时，Angora将其视为无符号类型。请注意，当Angora无法推断出值的精确大小和类型时，这并不能防止梯度下降找到解决方案 - 搜索只需要更长的时间。</p><p><img src="/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/图7.png" alt="图7"></p><h2 id="3-6-输入长度探索"><a href="#3-6-输入长度探索" class="headerlink" title="3.6 输入长度探索"></a>3.6 输入长度探索</h2><p>​    与大多数其他模糊器一样，Angora开始使用尽可能小的输入进行模糊测试。但是，仅当输入长于阈值时才执行某些分支。这给模糊器带来了两难境地。如果模糊器使用太短的输入，则无法探索这些分支。但如果它使用太长的输入，程序可能运行缓慢甚至内存不足。大多数工具使用临时方法尝试不同长度的输入。相比之下，Angora只有在这样做才能探索新的分支时才会增加输入长度。</p><p>​    在污点跟踪期间，Angora将类似read的函数调用中的目标内存与输入中的相应字节偏移相关联。它还使用特殊标签标记来自读取调用的返回值。如果在条件语句中使用返回值并且不满足约束，则Angora会增加输入长度，以便读取调用可以获取它请求的所有字节。例如，在图2中，如果第12行的条件语句为false，则Angora会扩展输入长度，以便fread可以读取它请求的所有1024个字节。我们的标准并非详尽无遗，因为程序可以消耗输入并以我们未预料到的方式检查其长度，但是一旦我们发现它们就很容易将这些标准添加到Angora。</p><h1 id="4-实现"><a href="#4-实现" class="headerlink" title="4  实现"></a>4  实现</h1><h2 id="4-1-插桩"><a href="#4-1-插桩" class="headerlink" title="4.1 插桩"></a>4.1 插桩</h2><p>​    对于每个要模糊的程序，Angora通过使用LLVM Pass [18]检测程序来生成相应的可执行文件。</p><ul><li><p>插桩收集条件语句的基本信息，并通过污点分析将条件语句链接到其对应的输入字节偏移。在每个输入上，Angora只运行此步骤一次（而不是在改变此输入时）。</p></li><li><p>记录执行跟踪以识别新输入。</p></li><li><p>在运行时支持上下文（第3.2节）。</p></li><li><p>在判定中收集表达式值（第3.4节）。</p></li></ul><p>​       为了支持3.3节中描述的可扩展字节级污点跟踪，我们通过扩展DataFlowSanitizer（DFSan）[21]为Angora实现了污点跟踪。我们为FIND和UNION操作实现了缓存设施，显着加快了污点跟踪。</p><p>​    Angora依赖于LLVM 4.0.0（包括DFSan）。它的LLVM pass包含820行C ++代码，不包括DFSan，运行时有1950行C ++代码，包括用于存储污点标签的数据结构以及用于污染输入和跟踪条件语句的钩子。</p><p>​    除了具有两个分支的if语句之外，LLVM IR还支持switch语句，这可能会引入多个分支。在我们的实现中，为方便起见，Angora将每个switch语句转换为if语句序列。</p><p>​    Angora识别libc函数，用于在条件语句中出现时比较字符串和数组。</p><p>​    例如，Angora将“strcmp（x，y）”转换为“x strcmp y”，其中strcmp是Angora理解的特殊比较运算符。</p><h2 id="4-2-Fuzzer"><a href="#4-2-Fuzzer" class="headerlink" title="4.2 Fuzzer"></a>4.2 Fuzzer</h2><p>​    我们以4488行Rust代码中实现了Angora。我们使用fork server [30]和CPU绑定等技术优化了Angora。</p><h1 id="5-评估"><a href="#5-评估" class="headerlink" title="5 评估"></a>5 评估</h1><p>​    我们分三个步骤评估了Angora。首先，我们将Angora的性能与其他最先进的模糊器进行了比较。然后，我们测量了Angora的测试覆盖率及其在现实世界程序中发现未知错误的能力。最后，我们评估了它的关键新颖特征。</p><p>​    我们在64位Ubuntu 16.04 LTS的Intel Xeon E5-2630 v3和256 GB内存的服务器上运行了所有实验。尽管Angora可以同时对多个内核上的程序进行模糊处理，但我们将其配置为在评估期间仅在一个内核上模糊该程序，以将其性能与其他模糊器进行比较。我们对每个实验进行了五次运行并报告了平均性能。</p><h2 id="5-1-Angora与其他模糊器进行比较"><a href="#5-1-Angora与其他模糊器进行比较" class="headerlink" title="5.1 Angora与其他模糊器进行比较"></a>5.1 Angora与其他模糊器进行比较</h2><p>​    比较模糊器的最终指标是它们发现错误的能力。一个好的测试集应该包含具有实际错误的真实程序。 LAVA是一种通过在程序源代码中注入大量实际错误来生成真实语料库的技术[9]。作者通过在每个程序中注入多个错误来创建语料库 LAVA-M。 LAVA-M由四个GNU coreutils程序组成：uniq，base64，md5sum和who。每个注入的bug都有一个唯一的ID，在触发bug时会打印出来。</p><p>​    我们将Angora与以下最先进的模糊器进行了比较：</p><ul><li><p>FUZZER（基于覆盖的模糊器）和SES（符号执行和SAT求解）。 LAVA的作者将它们都运行了5个小时[9]。</p></li><li><p>VUzzer：使用“魔术字节”策略的模糊器[25]。它的作者报告了LAVA-M程序中发现的错误数量，但没有报告运行时间。</p></li><li><p>Steelix：一个模糊器在LAVAM上表现优于VUzzer [19]。作者通过运行模糊器5小时报告了LAVA-M程序中发现的错误数量。[11]</p></li><li><p>AFL 2.51b：撰写本文时的最新版AFL。我们运行AFL五个小时，我们为AFL提供了一个CPU核心，用于对每个程序进行模糊测试。</p></li><li><p>Angora：我们使用与AFL相同的设置（每个程序一个CPU核心）。</p></li></ul><p>​       表1比较了所有模糊器发现的错误。AFL表现最差，在所有程序中总共发现了10个错误。 VUzzer的作者无法在md5sum上运行它，因为LAVA作者错误地修改了md5sum，导致它在所有输入上崩溃。我们向LAVA作者证实了这个问题并修复了它。 Steelix是第二个最好的模糊器，它发现了base64中几乎所有的错误，但是在uniq中28个中只有7个注入了错误，57个md5sum注入了错误中的28个，2136个中有194个注入了错误。Angora大大超过了Steelix，发现了uniq，base64和md5sum中的所有错误，并且2136中的1443个注入了错误。</p><p>​    LAVA为每个注入的bug分配一个唯一的ID，该ID在触发错误时打印。文件验证的错误列出了LAVA作者在创建LAVA时能够触发的所有注入错误。Angora不仅发现了uniq，base64，md5sum中列出的所有错误以及大多数列出的错误，还列出了103个未列出的错误（LAVA作者注入但无法触发的错误）。表3显示了这些未列出的错误的ID。表4显示了Angora发现的列出和未列出的错误的细分。</p><p><img src="/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/图8.png" alt="图8"></p><p>​    图4显示了Angora在who中随着时间的推移发现的错误累积数量。我们没有显示其他模糊器的结果，因为他们发现who没有错误。图4显示，最初Angora很快发现了错误，在不到五分钟内发现了1000个错误。然后发现速度减慢，但在总共2136个列出的错误中，它仅在45分钟内发现超过1500个错误。</p><p>​    我们接下来解释为什么Angora发现了比下一个最好的模糊器更多的错误。首先，LAVA使用“魔术字节”来保护包含错误的分支，但是一些魔术字节不是直接从输入复制而是从输入计算。由于VUzzer和Steelix的“魔术字节”策略只能将魔术字节直接复制到输入，因此该策略无法创建探索这些分支的输入。相比之下，Angora跟踪流入判定的输入字节偏移，然后通过梯度下降而不是假设“魔术字节”或输入与判定之间的任何其他特殊关系来改变这些偏移，因此Angora可以找到探索这些的输入分支机构。其次，VUzzer盲目地尝试“魔术字节”策略，一旦魔术字节中的一个与随机突变后的输入中的字节匹配，Steelix就会关注“魔术字节”策略。相比之下，Angora安排其所有计算能力来解决未探测分支上的路径约束，因此它可以覆盖更多分支，因此可以快速找到LAVA-M中的大部分注入错误。</p><p><img src="/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/图9.png" alt="图9"></p><h2 id="5-2-在未修改的真实程序中评估Angora"><a href="#5-2-在未修改的真实程序中评估Angora" class="headerlink" title="5.2 在未修改的真实程序中评估Angora"></a>5.2 在未修改的真实程序中评估Angora</h2><p>​    Angora在LAVA上的表现令人印象深刻，不仅发现了大部分列出的错误，还发现了许多未列出的错误。然而，它的怀疑论者可能会争辩说这些bug是人为注入的。为了解决这个问题，我们使用最新版本评估了八个流行的开源程序。由于这些成熟的，受欢迎的程序已经过广泛测试，我们预计它们几乎没有残留物崩溃的错误。因此，除了测量发现的新错误的数量外，我们还测量了Angora对这些程序的报道。我们使用了gcov，它记录了输入中程序中执行的所有行和分支[14]。我们将由Angora生成的每个输入馈送到用gcov编译的程序以获得累积代码覆盖率，并且afl-cov3允许我们自动执行此操作。我们还在这些程序上运行AFL进行比较。表5显示了使用一个CPU内核运行Angora和AFL五小时后的结果。我们通过AFL的afl-cmin -C命令重复删除了崩溃。</p><p>​    表5显示Angora在线路覆盖范围，分支覆盖范围以及每个程序发现崩溃时表现优于AFL。在文件，jhead，nm，objdump和大小中，AFL发现了0,19,12,4,6个独特的崩溃，而Angora分别发现了6,52,29,40和48个独特的崩溃。对比度在jhead最为突出，Angora的线路覆盖率提高了127.4％，分支覆盖率提高了144.0％。</p><p>​    图5比较了Angora和AFL随时间的累积线和分支覆盖率。它表明Angora在任何时候都覆盖了比AFL更多的线和分支。Angora优越覆盖的原因在于它可以探索复杂条件语句的两个分支。例如，图6显示了文件中的这样一个语句，其中Angora成功地探索了两个分支，但AFL无法探索真正的分支。在接下来的部分中，我们将评估Angora的每个关键特性如何有助于其卓越的性能。</p><p><img src="/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/图10.png" alt="图10"></p><p><img src="/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/图11.png" alt="图11"></p><p>5.3上下文相关的分支计数</p><p>​    <strong>5.3.1</strong> <strong>性能</strong>。 3.2节介绍了上下文相关分支计数。我们相信在不同的函数调用上下文中区分相同的分支会发现更多的错误。为了评估这个假设，我们分别使用上下文相关的分支计数和上下文不相关的分支计数来运行Angora。表6显示Angora发现6个错误具有上下文相关的分支计数，但在上下文不相关中它没有错误。图7显示从30分钟开始到模糊测试，Angora始终覆盖更多具有上下文相关分支计数的累积行。我们发现了几个真实世界的例子，其中上下文相关的分支计数允许Angora探索更多路径。例如，图8显示了程序文件中readelf.c文件中的代码片段。函数getu32在多个上下文中调用，它根据swap参数返回不同的结果。如果没有上下文相关的分支计数，Angora将无法在所有调用上下文中探索条件语句的两个分支。</p><p>​    <strong>5.3.2</strong> <strong>哈希碰撞</strong>。与AFL类似，Angora将分支计数存储在哈希表中。当Angora在计算分支覆盖率时合并调用上下文时，它会在哈希表中插入更多的唯一分支，因此我们必须增加哈希表的大小以保持较低的冲突率。</p><p>​    我们评估了5.2节中描述的真实世界程序中有多少独特的分支上下文相关性。 AFL的作者观察到，唯一分支（没有上下文）的数量通常在2k到10k之间，而具有216个bucket的哈希表应该足以满足常见情况[30]。表7显示合并上下文相关度将唯一分支的数量增加了至多8倍，这要求我们将散列表的大小增加8倍以具有相同的预期散列冲突率。默认情况下，Angora在其哈希表中分配220个bucket，这是AFL中哈希表的16倍，对大多数程序来说应该足够了。虽然在不再适合缓存时增加哈希表可能是有害的，但不像AFL那样遍历哈希表以查找新路径并优先处理覆盖许多基本块的输入，对于每个输入，Angora只遍历哈希表一次找到新的路径。因此，Angora受哈希表大小增长的影响较小，如第5.6节中的执行速度所示。</p><p><img src="/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/图12.png" alt="图12"></p><h2 id="5-4-基于梯度下降的搜索"><a href="#5-4-基于梯度下降的搜索" class="headerlink" title="5.4 基于梯度下降的搜索"></a>5.4 基于梯度下降的搜索</h2><pre><code>第3.4节描述了如何使用梯度下降来解决条件语句中的约束。我们将梯度下降与另外两种策略进行了比较：随机变异，VUzzer的魔术字节加随机变异。为了排除测量中的其他变量，我们确保三种策略接收相同的输入：我们收集了AFL在5.2节中生成的输入，并将它们作为模糊的唯一输入提供给Angora。我们分别使用上述三种策略运行Angora两小时。</code></pre><p>​    表8显示梯度下降解决了比所有程序中的其他两个策略更多的约束。如第5.1节的最后一段所述，“魔术字节”策略无法解决其值未直接从输入复制的约束。例如，图6中的变量descsz用于程序中的许多约束，但它不是直接从输入复制的，因此“魔术字节”策略没有帮助。</p><h2 id="5-5-输入长度探测"><a href="#5-5-输入长度探测" class="headerlink" title="5.5  输入长度探测"></a>5.5  输入长度探测</h2><p>​    第3.6节描述了当Angora观察到路径约束可能取决于长度时，按需增加输入的长度，而AFL和相关的模糊器随机增加输入长度。我们基于两个标准比较了这两种策略：</p><ul><li><p>策略增加输入长度的次数是多少？在这个战略创造的投入中，有多少是有用的？如果输入直接或在某些突变后探索新分支，则输入有用。</p></li><li><p>这些有用输入的平均长度是多少？</p></li></ul><p>​       我们分别用我们提出的策略和随机策略运行Angora五小时。表9显示Angora的策略将输入长度增加了大约两个数量级，比随机策略少了几个数量级，但它在所有情况下都发现了更有用的输入，除了两个：在readpng它发现总共46个中有用输入少3个，并且在jhead上，既没有策略发现任何有用的输入，因为jhead只解析图像的标题，因此不受图像数据长度的影响。表9还显示，虽然Angora的策略产生了更多有用的输入，但它在每个测试程序上平均产生较短的输入。较短的输入使许多程序运行得更快。该评估表明，Angora的战略比随机战略产生更高质量的投入。</p><p><img src="/2019/01/25/Angora-Efficient-Fuzzing-by-Principled-Search/图13.png" alt="图13"></p><p>5.6 执行速度</p><p>Angora的污染追踪代价很高。然而，Angora为每个输入运行一次污染跟踪，然后改变输入并多次运行程序而没有污点跟踪，因此一次性成本是摊销的。由于分支计数主导了没有污点跟踪的插桩代码的运行时间，因此Angora插桩程序的运行速度与其AFL插桩版本的运行速度大致相同。表10显示AFL以比Angora略高的速率执行输入。然而，由于Angora产生更高质量的输入，更有可能探索新的分支，Angora有更好的覆盖范围，并发现明显更多的错误，如前所示。</p><p><img src="file:///C:\Users\admin\AppData\Local\Temp\msohtmlclip1\01\clip_image002.jpg" alt="img"></p><h1 id="6-相关工作"><a href="#6-相关工作" class="headerlink" title="6 相关工作"></a>6 相关工作</h1><h2 id="6-1种子输入优先级"><a href="#6-1种子输入优先级" class="headerlink" title="6.1种子输入优先级"></a>6.1种子输入优先级</h2><p>​    基于突变的fuzzer的一个重要优化是明智地选择种子输入。雷伯特等人[26]制定并推理了种子选择调度问题。他们基于PeachFuzzer设计并评估了六种不同的种子选择算法[23]。算法使用不同的特征来最小化种子输入集，例如执行时间和文件大小。结果表明，种子选择算法采用的启发式方法比完全随机抽样方法表现更好。 AFLFast [4]观察到大多数模糊测试都使用了相同的几条“高频”路径。他们使用马尔可夫链来识别“低频”路径。 AFLFast优先考虑包含此类路径的输入。VUzzer [25]使用控制流功能来建模路径，以优先考虑路径难以到达的输入。此外，VUzzer检测到错误处理基本块，并优先考虑不包含这些基本块的有效输入。相比之下，Angora选择其路径包含具有未探索分支的条件语句的输入。这是一种更为通用的策略，在探索高频路径后，它会自动指示Angora专注于低频路径。</p><h2 id="6-2-基于污点的模糊测试"><a href="#6-2-基于污点的模糊测试" class="headerlink" title="6.2 基于污点的模糊测试"></a>6.2 基于污点的模糊测试</h2><p>​    污点跟踪有很多用途，例如分析恶意软件行为[24]，检测和防止信息泄漏[10,29]和调试软件[22,12]。它也可以用于模糊测试。基于污点的模糊器分析应用程序如何处理输入以确定应修改输入的哪个部分。其中一些模糊器[13,2,17]旨在将输入文件中安全敏感代码中使用的值定位，然后对输入文件的这些部分进行模糊处理以触发崩溃。例如，BuzzFuzz [13]使用污点定位来查找哪些输入字节由他们定义的“攻击点”处理。 Dowser [17]认为可能导致缓冲区溢出的代码是安全敏感代码。换句话说，这些模糊器旨在利用可到达路径中的错误。Woo等人。提到了在探索与利用之间的权衡[32]。Angora可以结合这些技术来开发探索的路径。 Taintscope [31]使用污点分析来推断校验和处理代码，并通过控制流程更改绕过这些检查，因为通过改变输入很难满足这些检查。</p><p>​    VUzzer [25]是一个应用程序感知模糊器，它使用污点分析来定位输入文件中“魔术字节”的位置，然后将这些魔术字节分配给输入中的固定位置。 VUzzer只有在连续出现在输入中时才能找到魔术字节。 Steelix [19]通过学习魔术字节位于输入中的程序状态以及如何有效地改变输入以匹配魔术字节来改进VUzzer。相比之下，Angora应用字节级污点跟踪来获取流入每个条件语句的输入中的字节偏移，然后改变这些字节以满足未探测分支的条件，因此Angora可以有效地找到更多类型的值。魔术字节，例如，非连续魔术字节或魔术字节，不是直接从输入复制而是从输入计算。此外，VUzzer使用压缩的位设置数据结构来表示污点标签，其中每个位对应于输入中的唯一字节偏移。因此，对于具有复杂输入字节偏移模式的值，污点标签的大小很大，因为它们无法有效压缩。相比之下，Angora将字节偏移存储在树中，并将索引作为污染标签用于树中，因此无论标签中有多少输入字节偏移，污点标签的大小都是常量。例如，当几个值的污点标签具有相同的字节偏移时，VUzzer会在每个污点标签中重复存储这些字节偏移，但Angora只在树中存储这些字节偏移一次，从而大大减少了内存消耗。</p><p>​    Angora有效表示污点标签的数据结构类似于简化有序二元决策图（roBDD）。 roBDD用于表示动态切片[33]和数据谱系[20]，但据我们所知，Angora是第一个使用这种想法有效地表示污点标签的。</p><h2 id="6-3-符号辅助模糊测试"><a href="#6-3-符号辅助模糊测试" class="headerlink" title="6.3 符号辅助模糊测试"></a>6.3 符号辅助模糊测试</h2><p>​    动态符号执行为目标应用程序提供了高度语义洞察力。由于这些技术知道如何触发所需的程序状态，因此它们可用于直接查找程序中的漏洞。符号执行实现的经典方法以最大化代码覆盖率以查找崩溃[5,8]。但路径爆炸和约束求解的挑战使符号执行难以扩展[6,27]。一些工具试图通过将其与模糊测试[15,16,7,28]相结合来缓解这一障碍。 DART [15]和SAGE [16]使用动态符号执行引擎来修改模糊测试中的输入。 SYMFUZZ [7]利用对执行跟踪的符号分析来检测输入中位置之间的依赖关系，然后使用此依赖关系来计算最佳突变率以指导模糊测试。 Driller [28]只有在AFL模糊不清时才使用动态符号执行。但是，它们都继承了符号执行的可伸缩性问题。相比之下，Angora不使用符号执行，并且可以有效地在大型程序上找到许多错误。</p><h1 id="7-结论"><a href="#7-结论" class="headerlink" title="7 结论"></a>7 结论</h1><p>​    我们设计并实现了Angora，这是一种强大的基于突变的模糊器，可以产生高质量的输入，这得益于以下关键技术：可扩展的字节级污点跟踪，上下文敏感的分支计数，基于梯度下降的搜索算法，形状和类型推断和输入长度探索。Angora在很大程度上超越了其他最先进的模糊器。它发现了比LAVA-M上的其他模糊器明显更多的错误，发现了当他们准备数据集时LAVA作者无法触发的103个错误，以及8个流行的，成熟的开源程序中总共175个新错误。我们的评估显示，Angora将模糊测试的标准提升到了一个新的水平。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h1&gt;&lt;p&gt;​    Fuzzing是一种用于查找软件错误的流行技术。然而，最先进的模糊器的性能还有很多
      
    
    </summary>
    
      <category term="论文" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/"/>
    
      <category term="fuzzing" scheme="http://yama0xff.com/categories/%E8%AE%BA%E6%96%87/fuzzing/"/>
    
    
      <category term="2018年" scheme="http://yama0xff.com/tags/2018%E5%B9%B4/"/>
    
      <category term="fuzzing" scheme="http://yama0xff.com/tags/fuzzing/"/>
    
      <category term="污点分析" scheme="http://yama0xff.com/tags/%E6%B1%A1%E7%82%B9%E5%88%86%E6%9E%90/"/>
    
      <category term="LAVA" scheme="http://yama0xff.com/tags/LAVA/"/>
    
      <category term="梯度下降算法" scheme="http://yama0xff.com/tags/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95/"/>
    
      <category term="S&amp;P&#39;18" scheme="http://yama0xff.com/tags/S-P-18/"/>
    
      <category term="LLVM" scheme="http://yama0xff.com/tags/LLVM/"/>
    
  </entry>
  
</feed>
